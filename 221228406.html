<!DOCTYPE html> <html lang="en" class="" id="rgw37_56aba233d3dc4"> <head > <meta charset="utf-8"/> <meta http-equiv="content-type" content="text/html; charset=UTF-8"/> <meta name="Rg-Request-Token" id="Rg-Request-Token" content="Sw6bxbJtiYaZ0q91DwyCL3T05lDS0SnlzsZr12KIEoUi7O3douie7NtsEPzJBTao1czOSGBrcFDmRnSS0HkRZk8JCzfe9Y3Yitgpu21Mxez0UxVv99Y+j+cB/lRr7gTGYRQAuFU0DucQeUlvdjA0Lfwow9WtbvJOI3LF/JGHWI7k9vg3ntvLrhB1bjwF/SE7d8dLbCQhwhluACKJqGGUsEa82h0LFzE9GP0p4fxExYSYrziwqOt0bVQcR0PWwACpTmSt2A6uXXUjoZjxTF5dc5m39yWRrLCHNZUErG69xvA="/> <meta http-equiv="expires" content="0"/> <link rel="apple-touch-icon" sizes="57x57" href="https://www.researchgate.net/apple-touch-icon-57x57.png"> <link rel="apple-touch-icon" sizes="60x60" href="https://www.researchgate.net/apple-touch-icon-60x60.png"> <link rel="apple-touch-icon" sizes="72x72" href="https://www.researchgate.net/apple-touch-icon-72x72.png"> <link rel="apple-touch-icon" sizes="76x76" href="https://www.researchgate.net/apple-touch-icon-76x76.png"> <link rel="apple-touch-icon" sizes="114x114" href="https://www.researchgate.net/apple-touch-icon-114x114.png"> <link rel="apple-touch-icon" sizes="120x120" href="https://www.researchgate.net/apple-touch-icon-120x120.png"> <link rel="apple-touch-icon" sizes="144x144" href="https://www.researchgate.net/apple-touch-icon-144x144.png"> <link rel="apple-touch-icon" sizes="152x152" href="https://www.researchgate.net/apple-touch-icon-152x152.png"> <link rel="apple-touch-icon" sizes="180x180" href="https://www.researchgate.net/apple-touch-icon-180x180.png"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-32x32.png" sizes="32x32"> <link rel="icon" type="image/png" href="https://www.researchgate.net/android-chrome-192x192.png" sizes="192x192"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-96x96.png" sizes="96x96"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-16x16.png" sizes="16x16"> <link rel="shortcut icon" type="image/x-icon" href="https://c5.rgstatic.net/m/2390829798215018/images/favicon.ico"/> <link rel="manifest" href="https://www.researchgate.net/manifest.json"> <meta name="msapplication-TileColor" content="#da532c"> <meta name="msapplication-TileImage" content="https://www.researchgate.net/mstile-144x144.png"> <meta name="theme-color" content="#444444"> <link rel="search" type="application/opensearchdescription+xml" title="ResearchGate search" href="https://www.researchgate.net/application.DownloadOpenSearchPlugin.html"/> <link rel="meta" type="application/rdf+xml" title="ICRA labels" href="https://www.researchgate.net/application.DownloadLabels.html"/> <link rel="http://oexchange.org/spec/0.8/rel/related-target" type="application/xrd+xml" href="https://www.researchgate.net/application.DownloadOExchange.html"/> <base href="https://www.researchgate.net/"/> <script>
    var rgConfig = {
        correlationId: "rgreq-22b68cfd-4074-4224-bc5d-d4c3ff1d186c",
        accountId: "",
        module: "publicliterature",
        action: "publicliterature.PublicPublicationDetails",
        page: "publicationDetail",
        product: "publications",
        continent: "Asia",
        stylesHome: "//c5.rgstatic.net/m/",
        staticHost: "c5.rgstatic.net",
        longRunningRequestIdentifier: "LongRunningRequest.publicliterature.PublicPublicationDetails",
        longRunningRequestFp: "e9e5bbe1366c7ee8c8e41d02f793c884ac9be19b"
    };
    window.rootUrl = "https://www.researchgate.net/";
</script> <link rel="canonical" href="https://www.researchgate.net/publication/221228406_Multiobjective_Optimization_on_a_Budget_of_250_Evaluations" />
<link rel="dns-prefetch" href="//c5.rgstatic.net" />
<link rel="dns-prefetch" href="//i1.rgstatic.net" />
<meta property="twitter:card" content="summary" />
<meta property="twitter:site" content="@ResearchGate" />
<meta property="og:title" content="Multiobjective Optimization on a Budget of 250 Evaluations" />
<meta property="og:description" content="In engineering and other 'real-world' applications, multiobjective opti- mization problems must frequently be tackled on a tight evaluation budget ó tens or hundreds of function evaluations,..." />
<meta property="og:site_name" content="ResearchGate" />
<meta property="og:image" content="https://i1.rgstatic.net/publication/221228406_Multiobjective_Optimization_on_a_Budget_of_250_Evaluations/links/00b495225ac557f688000000/smallpreview.png" />
<meta property="og:url" content="https://www.researchgate.net/publication/221228406_Multiobjective_Optimization_on_a_Budget_of_250_Evaluations" />
<meta property="rg:id" content="PB:221228406" />
<meta name="DC.identifier" scheme="DCTERMS.URI" content="http://dx.doi.org/10.1007/978-3-540-31880-4_13" />
<meta name="gs_meta_revision" content="1.1" />
<meta name="citation_title" content="Multiobjective Optimization on a Budget of 250 Evaluations" />
<meta name="citation_author" content="Joshua D. Knowles" />
<meta name="citation_author" content="Evan J. Hughes" />
<meta name="citation_conference_title" content="Evolutionary Multi-Criterion Optimization, Third International Conference, EMO 2005, Guanajuato, Mexico, March 9-11, 2005, Proceedings" />
<meta name="citation_publication_date" content="2005/01/01" />
<meta name="citation_journal_title" content="Lecture Notes in Computer Science" />
<meta name="citation_issn" content="0302-9743" />
<meta name="citation_volume" content="3410" />
<meta name="citation_firstpage" content="176" />
<meta name="citation_lastpage" content="190" />
<meta name="citation_doi" content="10.1007/978-3-540-31880-4_13" />
<meta name="citation_pdf_url" content="https://www.researchgate.net/profile/Evan_Hughes/publication/221228406_Multiobjective_Optimization_on_a_Budget_of_250_Evaluations/links/00b495225ac557f688000000.pdf" />
<meta name="citation_abstract_html_url" content="https://www.researchgate.net/publication/221228406_Multiobjective_Optimization_on_a_Budget_of_250_Evaluations" />
<meta name="citation_fulltext_html_url" content="https://www.researchgate.net/publication/221228406_Multiobjective_Optimization_on_a_Budget_of_250_Evaluations" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<link href="//c5.rgstatic.net/m/22664197317151888/styles/rg.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/21004998181197492/styles/rg2.css" type="text/css" rel="stylesheet"/>
<!--[if lt IE 9]><link href="//c5.rgstatic.net/m/238176252723686/styles/ie.css" type="text/css" rel="stylesheet"/><![endif]-->
<link href="//c5.rgstatic.net/m/217752362214895/styles/modules/publicprofile.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/21993347442549/styles/pow/publicliterature/FollowPublicationPromo.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/282514599719602/styles/pow/application/PdfJsReader.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/23819663151220/styles/pow/publicliterature/PublicationInlineReader.css" type="text/css" rel="stylesheet"/>
<script src="//c5.rgstatic.net/m/2321000301012716/javascript/vendor/webfontloader/webfontloader.js" type="text/javascript"></script>
 <script>(function(i,s,o,g,r,a,m){i["GoogleAnalyticsObject"]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,"script","//www.google-analytics.com/analytics.js","ga");
 ga("create","UA-58591210-1");ga("set","anonymizeIp",true);ga('set', 'dimension1', 'publication full-text');ga('set', 'dimension2', 'Conference Paper');ga('set', 'dimension3', 'Logged out');ga('set', 'dimension4', 'https');ga("send","pageview");</script>
  <script> WebFontConfig = { custom: { families: ['source_sans_pro_italic', 'source_sans_pro_bold', 'source_sans_pro', 'martel'], urls : ['//c5.rgstatic.net/m/231392577336386/styles/fonts.css'] } }; WebFont.load(WebFontConfig); </script><noscript></noscript>

<title>Multiobjective Optimization on a Budget of 250 Evaluations (PDF Download Available)</title>
<meta name="description" content="Official Full-Text Publication: Multiobjective Optimization on a Budget of 250 Evaluations on ResearchGate, the professional network for scientists."/>
<meta name="keywords" content="scientific network, scientific platform, scientific community, research partner, research collaboration, journal articles, international collaboration, find researcher, lifescience researcher, interdisciplinary research, research collaboration"/>
</head>
<body class="use-svg-icons logged-out">
<div id="page-container">
<script type="text/javascript">var googletag = googletag || {}; googletag.cmd = googletag.cmd || [];
(function() { var gads = document.createElement("script"); gads.async = true; gads.type = "text/javascript"; var useSSL = "https:" == document.location.protocol; gads.src = (useSSL ? "https:" : "http:") + "//www.googletagservices.com/tag/js/gpt.js"; var node =document.getElementsByTagName("script")[0]; node.parentNode.insertBefore(gads, node); })();</script><div id="main" class="logged-out-header-support">
<div id="content" class="">

<noscript>
<div class="c-box-warning full-width-element" style="text-align: center; ">
    <div style="margin: auto; padding:10px;" class="container">
        <b>For full functionality of ResearchGate it is necessary to enable JavaScript.
            Here are the <a href="http://www.enable-javascript.com/" rel="nofollow" target="_blank">
                instructions how to enable JavaScript in your web browser</a>.</b>
    </div>
</div>
</noscript>

<div id="rgw1_56aba233d3dc4" itemscope itemtype="http://schema.org/ScholarlyArticle"><div class="publication-wrapper publication-wrapper-onecol" id="rgw2_56aba233d3dc4" itemscope itemtype="http://schema.org/ScholarlyArticle"> <div class="c-col-content"> <div class="c-content"> <div class="clearfix">  <div class="publication-header"> <div id="rgw5_56aba233d3dc4">  <div class="type-label"> Conference Paper   </div> <span class="Z3988" title="ctx_ver=Z39.88-2004&rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&rfr_id=info%3Asid%2Fresearchgate.net%3Aresearchgate&rft_id=info%3Adoi%2F10.1007%2F978-3-540-31880-4_13&rft.atitle=Multiobjective%20Optimization%20on%20a%20Budget%20of%20250%20Evaluations&rft.title=Lecture%20Notes%20in%20Computer%20Science&rft.jtitle=Lecture%20Notes%20in%20Computer%20Science&rft.volume=3410&rft.date=2005&rft.pages=176-190&rft.issn=0302-9743&rft.au=Joshua%20D.%20Knowles%2CEvan%20J.%20Hughes&rft.genre=inProceedings"></span> <h1 class="pub-title" itemprop="name">Multiobjective Optimization on a Budget of 250 Evaluations</h1> <meta itemprop="headline" content="Multiobjective Optimization on a Budget of 250 Evaluations">  <meta itemprop="image" content="https://i1.rgstatic.net/publication/221228406_Multiobjective_Optimization_on_a_Budget_of_250_Evaluations/links/00b495225ac557f688000000/smallpreview.png">  <div id="rgw8_56aba233d3dc4" class="publication-detail-author-list"> <div> <ul class="clearfix js-people-list">  <li id="rgw9_56aba233d3dc4" itemprop="author" itemscope itemtype="http://schema.org/Person"> <a itemprop="sameAs" href="profile/Joshua_Knowles" class="pub-detail-item account-item"> <div class="indent-left"> <div class="people-img"> <img  src="https://i1.rgstatic.net/ii/profile.image/AS%3A272291355426850%401441930726775_m/Joshua_Knowles.png" title="Joshua Damian Knowles" alt="Joshua Damian Knowles" height="20px" width="20px" style="height: 20px;"/> </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Joshua Damian Knowles</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item  remove-action-indent   " id="rgw10_56aba233d3dc4" data-account-key="Joshua_Knowles">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="profile/Joshua_Knowles"> <img class="lazyload" data-src="https://i1.rgstatic.net/ii/profile.image/AS%3A272291355426850%401441930726775_l/Joshua_Knowles.png" title="Joshua Damian Knowles" alt="Joshua Damian Knowles" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">     </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="profile/Joshua_Knowles" class="display-name">Joshua Damian Knowles</a>    </h5> <div class="truncate-single-line meta">   <a class="meta ga-top-coauthor-institution" href="institution/University_of_Birmingham" title="University of Birmingham">University of Birmingham</a>     </div>  <a href="javascript:" class="btn btn-promote btn-large people-item-contact-author js-contact-author">Message author</a>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>  <li id="rgw11_56aba233d3dc4" itemprop="author" itemscope itemtype="http://schema.org/Person"> <a itemprop="sameAs" href="profile/Evan_Hughes" class="pub-detail-item account-item"> <div class="indent-left"> <div class="people-img"> <img  src="https://i1.rgstatic.net/ii/profile.image/AS%3A276959826333699%401443043776220_m/Evan_Hughes.png" title="Evan Hughes" alt="Evan Hughes" height="20px" width="20px" style="height: 20px;"/> </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Evan Hughes</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item  remove-action-indent   " id="rgw12_56aba233d3dc4" data-account-key="Evan_Hughes">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="profile/Evan_Hughes"> <img class="lazyload" data-src="https://i1.rgstatic.net/ii/profile.image/AS%3A276959826333699%401443043776220_l/Evan_Hughes.png" title="Evan Hughes" alt="Evan Hughes" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">     </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="profile/Evan_Hughes" class="display-name">Evan Hughes</a>    </h5> <div class="truncate-single-line meta">    <span class="meta">White Horse Radar Limited</span>    </div>  <a href="javascript:" class="btn btn-promote btn-large people-item-contact-author js-contact-author">Message author</a>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>   </ul> <div class="js-loading"></div>  </div> </div> <div class="pub-details js-pub-details">      DOI:&nbsp;10.1007/978-3-540-31880-4_13     Conference: Evolutionary Multi-Criterion Optimization, Third International Conference, EMO 2005, Guanajuato, Mexico, March 9-11, 2005, Proceedings      <div class="pub-source"> Source: <a href="http://dblp.uni-trier.de/db/conf/emo/emo2005.html#KnowlesH05" rel="nofollow">DBLP</a> </div>  </div> <div id="rgw13_56aba233d3dc4" class="pub-abstract">  <div class="clearfix">   <div style="max-height: 54px;" class="js-expander-container js-expander-collapsed">  <p itemprop="description"> <strong>ABSTRACT</strong> <div>In engineering and other 'real-world' applications, multiobjective opti- mization problems must frequently be tackled on a tight evaluation budget &oacute; tens or hundreds of function evaluations, rather than thousands. In this paper, we in- vestigate two algorithms that use advanced initialization and search strategies to operate better under these conditions. The rst algorithm, Bin MSOPS, uses a bi- nary search tree to divide up the decision space, and tries to sample from the largest empty regions near 't' solutions. The second algorithm, ParEGO, begins with so- lutions in a latin hypercube and updates a Gaussian processes surrogate model of the search landscape after every function evaluation, which it uses to estimate the solution of largest expected improvement. The two algorithms are tested using a benchmark suite of nine functions of two and three objectives &oacute; on a budget of only 250 function evaluations each, in total. Results indicate that the two algo- rithms search the space in very different ways and this can be used to understand performance differences. Both algorithms perform well but ParEGO comes out on top in seven of the nine test cases after 100 function evaluations, and on six after the rst 250 evaluations.</div> </p>  </div>  </div>   </div>      <div class="action-container"> <div id="rgw14_56aba233d3dc4" class="follow-publication-promo"> <table> <tr> <td class="follow-publication-promo-text-cell"> <p>Get notified about updates to this publication</p> <a class="btn btn-large btn-promote js-follow-publication ga-follow-publication-new-promo">Follow publication</a> </td> <td> <div class="follow-publication-publication-image"></div> </td> </tr> </table> </div>  <div class="clear"></div> <div class="share-dialog-container" style="display: none;">  </div> </div> </div> <div style="margin-left: -20px; margin-right: -20px;">  </div> </div>  <div class="publication-detail-dfp-container rf"> <div id="rgw28_56aba233d3dc4">  </div> </div>  </div>  <div class="clearfix"> <div class="pdf-js-container clearfix " id="rgw29_56aba233d3dc4">  <div class="pdf-js-header js-sticky-header clear">  <a class="blue-link js-download rf btn btn-promote" href="https://www.researchgate.net/profile/Evan_Hughes/publication/221228406_Multiobjective_Optimization_on_a_Budget_of_250_Evaluations/links/00b495225ac557f688000000.pdf?inViewer=0&amp;pdfJsDownload=0&amp;origin=publication_detail">Download full-text</a>  <h3>Full-text</h3> <span class="publication-info">  <span class="js-doi-container" style="display: none;"> DOI: <span class="js-doi"></span> &middot; </span> Available from: <a class="js-name" href="profile/Evan_Hughes">Evan Hughes</a>   </span>  </div>  <div class="social-share-container"><div id="rgw31_56aba233d3dc4" class="social-share js-social-share"> <div class="social-share-heading">Share</div>  <a id="rgw32_56aba233d3dc4" href="javascript:" title="Share on Facebook" class="link-nostyle js-share-item share-icon "  data-url="http://www.facebook.com/share.php?u={{url}}{{#title}}&amp;t={{title}}{{/title}}" data-width="600" data-height="350" data-name="Facebook"> <span class="share-icon ico-share-facebook-round reset-background ga-share-blog-facebook"></span> </a>  <a id="rgw33_56aba233d3dc4" href="javascript:" title="Share on Twitter" class="link-nostyle js-share-item share-icon "  data-url="http://twitter.com/intent/tweet?text={{#title}}{{title}}: {{/title}}{{url}}&amp;via=researchgate" data-width="600" data-height="350" data-name="Twitter"> <span class="share-icon ico-share-twitter-round reset-background ga-share-blog-twitter"></span> </a>  <a id="rgw34_56aba233d3dc4" href="javascript:" title="Share on Google+" class="link-nostyle js-share-item share-icon "  data-url="https://plus.google.com/share?url={{url}}" data-width="600" data-height="600" data-name="Google+"> <span class="share-icon ico-share-gplus-round reset-background ga-share-blog-gplus"></span> </a>  <a id="rgw35_56aba233d3dc4" href="javascript:" title="Share on LinkedIn" class="link-nostyle js-share-item share-icon "  data-url="http://www.linkedin.com/shareArticle?mini=true&amp;url={{url}}{{#title}}&amp;title={{title}}{{/title}}&amp;source=ResearchGate" data-width="520" data-height="570" data-name="LinkedIn"> <span class="share-icon ico-share-linkedin-round reset-background ga-share-blog-linkedin"></span> </a>  <a id="rgw36_56aba233d3dc4" href="javascript:" title="Share on Reddit" class="link-nostyle js-share-item share-icon "  data-url="https://www.reddit.com/submit?url={{url}}{{#title}}&amp;title={{title}}{{/title}}" data-width="600" data-height="600" data-name="Reddit"> <span class="share-icon ico-share-reddit reset-background ga-share-blog-reddit"></span> </a>  </div></div>    <iframe id="rgw30_56aba233d3dc4" src="https://www.researchgate.net/c/o1q2er/javascript/lib/pdfjs/web/viewer.html?file=https%3A%2F%2Fwww.researchgate.net%2Fprofile%2FEvan_Hughes%2Fpublication%2F221228406_Multiobjective_Optimization_on_a_Budget_of_250_Evaluations%2Flinks%2F00b495225ac557f688000000.pdf%3FinViewer%3D1%26pdfJsDownload%3D1%26origin%3Dpublication_detail" allowfullscreen frameborder="0" style="width: 100%; height: 100%; box-sizing: border-box;"></iframe>    </div> <noscript> <div id="rgw27_56aba233d3dc4"  itemprop="articleBody">  <p>Page 1</p> <p>Multiobjective Optimization on a Budget of 250<br />Evaluations<br />Joshua Knowles<br />?<br />and Evan J. Hughes<br />?<br />?<br />School of Chemistry, University of Manchester, Faraday Building, Sackville Street, PO Box 88,<br />Manchester M60 1QD, UK. Email:j.knowles@manchester.ac.uk<br />Cranfield University, Shrivenham, Swindon SN6 8LA, UK<br />?<br />Abstract. In engineering and other ‘real-world’ applications, multiobjective opti-<br />mization problems must frequently be tackled on a tight evaluation budget — tens<br />or hundreds of function evaluations, rather than thousands. In this paper, we in-<br />vestigate two algorithms that use advanced initialization and search strategies to<br />operate better under these conditions. The first algorithm, Bin MSOPS, uses a bi-<br />nary search tree to divide up the decision space, and triesto sample from the largest<br />empty regions near ‘fit’ solutions. The second algorithm, ParEGO, begins with so-<br />lutions in a latin hypercube and updates a Gaussian processes surrogate model of<br />the search landscape after every function evaluation, which it uses to estimate the<br />solution of largest expected improvement. The two algorithms are tested using a<br />benchmark suite of nine functions of two and three objectives — on a budget of<br />only 250 function evaluations each, in total. Results indicate that the two algo-<br />rithms search the space in very different ways and this can be used to understand<br />performance differences. Both algorithms perform well but ParEGO comes out on<br />top in seven of the nine test cases after 100 function evaluations, and on six after<br />the first 250 evaluations.<br />Keywords: multiobjective optimization, expensive black-box functions, ParEGO,<br />DACE, Bin MSOPS, landscape approximation, response surfaces, test suites<br />1Introduction<br />The vast majority of research effort in developing modern multiobjective evolutionary<br />algorithms (MOEAs) has concentrated on improving algorithm performance and effi-<br />ciency on runs, typically, of ten thousand function evaluations or more. In this paper, we<br />considermultiobjectiveproblemswhere a ‘budget’of at most 250 evaluationsis imposed<br />because of the expensive nature of evaluating candidate solutions. More specifically, we<br />are interested in problems where most or all of the features described in Fig.1 are true.<br />Features 1–4 limit the numbers of function evaluations possible, while features 5–8<br />make it reasonable to apply global search techniques rather than either random search or<br />hillclimbing. Problems exhibiting these features include various combinatorial biochem-<br />istry and materials science applications [6,26], as well as instrument set-up optimization<br />in analytical chemistry [20,24]. In [20], a standard MOEA, PESA-II, was successfully<br />used to substantially improve the settings of a GC-MS spectrometer, using just 180 eval-<br />uations. However, it is clear that given such a restricted number of evaluations, and no</p>  <p>Page 2</p> <p>2<br />1. the time taken to perform one evaluation is of the order of minutes or hours,<br />2. only one evaluation can be performed at one time (no parallelism is possible),<br />3. the total number of evaluations to be performed is limited by financial considerations,<br />4. no realistic simulator or other method of approximating the full evaluation is readily<br />available,<br />5. noise is low (repeated evaluations yield very similar results),<br />6. the overall gains in quality (or reductions in cost) that can be achieved are high,<br />7. the search landscape is multimodal but not highly rugged,<br />8. the dimensionality of the search space is low-to-medium,<br />9. the problem has multiple, possibly incommensurable, objectives.<br />Fig.1. Features exhibited by problems of interest<br />particularrestriction on computationaloverhead(since each experimentrequires 20 min-<br />utes), a search strategy that more carefully considers each evaluation would be more<br />appropriate.<br />Scanning the optimization literature reveals that a sparse but varied array of different<br />techniques (that were proposed or could be used) for economizing on evaluations in<br />multiobjective optimization has already been examined. One strand in this focuses on<br />the use of neural networks for modeling the search landscape during optimization, in<br />order to replace some real function evaluations with approximated ones [19,8,9], or to<br />replacestandardvariationoperatorswithadaptiveones[1].Thesimplerconceptoffitness<br />inheritance has also been investigated in multiobjective optimization to economize on<br />function evaluations [2,5]. And a third strand is to use Bayesian network and/or other<br />probabilistic model-building algorithms in a multiobjective scenario, e.g. [17].<br />However, while the above methods may offer some performance gains over stan-<br />dard MOEAs when function evaluations are expensive, not one of the studies above<br />has demonstrated a significant performance advantage within the challenging evalua-<br />tion budget we are interested in here. In this paper, we present and compare two recently<br />proposed algorithms that take very different approaches to this challenge. The first algo-<br />rithm, Binary-MSOPS, which is summarized below, is based on two separate pieces of<br />workpreviouslypublishedbythesecondauthor[11,12].Thesecondalgorithm,ParEGO,<br />was first described in a recent technical report [16], and is described here again in some<br />detail.We evaluatethese algorithmsovera rangeofproblemsand,unlikein otherstudies,<br />we focus explicitly on the first 250 evaluations only.<br />The rest of the paper is organized as follows. Sections 2 and 3 describe the two<br />algorithms, while 4, 5 and 6 detail the test functions, performance assessment methods<br />and parameter settings of the algorithms, respectively. Section 7 presents results and<br />section 8 discusses findings and concludes.<br />2Binary-MSOPS<br />The Binary-MSOPS algorithm is based primarily on the Binary Search Algorithm [11],<br />summarized below. This method, which can be combined with almost any fitness as-</p>  <p>Page 3</p> <p>3<br />1<br />2<br />3<br />4<br />5<br />6<br />7<br />Fig.2. The Binary Search process illustrated in a two dimensional decision space, with the first<br />seven search points shown. The box around the third point indicates a small distance around a ‘fit’<br />point, and how this intersects with several empty regions<br />signment scheme, attempts to improve decision space sampling to ensure that promis-<br />ing regions are not missed or over-sampled in the early stages of the search, and to ex-<br />plicitly balance exploitation and exploration. Combining this with the MSOPS ranking<br />method [12] — a computationally efficient means of assigning fitness in multiobjective<br />optimization,based on target vectors —, Binary-MSOPS is both efficient and frugalwith<br />evaluations.<br />2.1Binary Search Algorithm<br />The overall strategy of Bin MSOPS uses a binary search tree [11] to divide the decision<br />space into empty regions, allowing the largest empty region to be approximated. The<br />search tree is constructed as shown in Fig. 2 by generating a point at random within a<br />chosen hypercube, then dividing the hypercube along the dimension that yields the most<br />‘cube-like’ subspaces.<br />The basic algorithm for constructing the binary search tree (and generating new so-<br />lutions) works by repeatedly choosing an exploration or exploitation step:<br />Exploration: Next point is generated at random within the largest empty region (i.e.<br />global search),<br />Exploitation: Next point is generated within the largest empty region that is within a<br />small distance of a selected good point (i.e. local search),<br />where the choice is random but biased by a parameter specifying the exploration/ex-<br />ploitation ratio.<br />The identification of a local region for exploitation is illustrated in Fig. 2. A small<br />offset distanceis used to generate a hypercube of interest about the chosen point<br />(chosen with tournament selection). The small hypercube is placed around the point of<br />interest simply to provide an efficient means of identifying large neighbouring regions.<br />A new point is then generated at random using a normal distribution in the largest region<br />that intersects the hypercube.<br />???</p>  <p>Page 4</p> <p>4<br />At each iteration, the tree search to find the largest empty region is at worst<br />where is the number of evaluation points so far and<br />Treepruningcanleadto<br />Thus a computational explosion is avoided.<br />???<br />?????,<br />??<br />is the number of dimensions.<br />???<br />???????<br />?<br />?????performanceforexploitation,andat worst<br />???<br />?????.<br />2.2 Population ranking by MSOPS<br />In order to decide which are ‘good’ points, the entire population is ranked, and a tour-<br />nament between a random subset of the population, based on rank value, decides on the<br />next solution to update. In order to control the computational complexity, a non-Pareto<br />ranking approach has been applied, that like ParEGO (see next section), is also capable<br />of handling many-objective problems. For this, the Multiple Single Objective Sampling<br />(MSOPS) [12], with<br />time complexity, has been used.<br />The concept of MSOPS is to generate a set of<br />performance of every individual in the population, of size<br />based on a conventional aggregation method. As aggregation methods (e.g. weighted<br />min-max,<br />each of the performance metrics is fast.<br />Thus each of the<br />members of the population has a set of<br />how well the population member satisfied the range of target conditions. The scores are<br />held in a score matrix,<br />corresponds to one target vector (each column containing<br />the best performing population member on the corresponding target vector being given<br />a rank of 1, and the worst a rank of. The rank values are stored in a matrix<br />row of the rank matrixmay now be sorted, with the ranks for each population member<br />placed in ascending order. Thematrix now holds in the first column the highest rank<br />achievedfor each populationmemberacross the set of target vectors.The second column<br />will hold the second highest rank achieved etc. Thus the matrix<br />the population, with the most fit being the solution that achieved the most scores that<br />were ranked 1, etc.<br />The flexibility of the approach is such that the target vectors can be arbitrary, either<br />generated using some structure, or generated at random within certain limits. As the<br />ranking method employed is based on the number of target vectors that are satisfied the<br />best, a solution at the edge of the objective space will often satisfy vectors that cannot be<br />attained. Thus the focus of the optimization is naturally drawn to interesting regions of<br />surface such as the boundary of the optimization surface and discontinuities.<br />???<br />???????<br />?<br />?????<br />?<br />target vectors, and evaluate the<br />, for every target vector,<br />?<br />? -constraint,goal attainment etc.) are very simple to process, the calculation of<br />?<br />?<br />scores that indicate<br />? , which has dimensions<br />???<br />? . Each column of the matrix<br />entries) and is ranked, with<br />?<br />?<br />?<br />? . Each<br />?<br />?<br />?<br />may be used to rank<br />3 ParEGO: landscape modeling using Gaussian processes<br />Learning a cost landscape from a set of solution/cost pairs is variously called surro-<br />gate, approximate or meta- modeling in the literature [13]. In design engineering, meta-<br />modelingis usuallyknownas theresponsesurfacemethod[18],andinvolvesfittinga low<br />order polynomial via some form of least squares regression. A closely related approach,<br />deriving from geology, is Kriging, whereby Gaussian process models are parameterized<br />by maximum likelihood estimation. A particular example of this is known as the Design</p>  <p>Page 5</p> <p>5<br />and Analysis of Computer Experiments (DACE) model [22], which forms the basis of<br />the EGO search algorithm [14]. EGO has been designed specifically for optimization on<br />a very restricted evaluation budget: e.g. in [14], four low-dimensional multimodal test<br />functions are optimized to within 1% of optimal in the order of 100 function evaluations.<br />The EGO algorithm begins by first generating a number of solutions in a latin hy-<br />percube, and by then finding the maximum likelihood DACE model that best explains<br />these solutions (making use of some suitable optimization algorithm). To generate a new<br />solution to evaluate, EGO searches for the solution that maximizes what Jones et al [14]<br />call “the expected improvement” — the expected value of that part of the standard er-<br />ror curve that lies below the best cost sampled so far. This effectively means that EGO<br />weighs up both the predicted value of solutions, and the error in this prediction, in order<br />to findthe onethat has the greatestpotentialto improvetheminimumcost.EGO does not<br />just choose the solution that the model predicts would minimize the cost. Rather, it auto-<br />matically balances exploitation and exploration: where a solution has low predicted cost<br />and low error, it may not be as desirable as a solution whose predicted cost is higher but<br />whose associated error of prediction is also higher. Once a new solution has been chosen<br />and evaluated (using the true, expensive cost function),the DACE model is updated with<br />this new information, and the next solution is chosen using this updated model.<br />The EGO algorithmcouldbe extendedforuse with multiobjectiveoptimizationprob-<br />lems in a number of different ways. One simple approach recently proposed by the first<br />author in [16] (and that has the advantage of scaling to many objectives), converts the<br />differentcost valuesofa solutionintoa singlecostvia aparameterizedscalarizingweight<br />vector. By choosing a different (parameterization of the) weight vector at each iteration<br />of the search, an approximation to the whole Pareto front can be gradually built up. This<br />multiobjective extension of EGO is called ParEGO.<br />ParEGO begins by normalizing the<br />estimated) limits of the cost space, so that each cost function lies in the range [0,1].<br />Then, at each iteration of the algorithm, a weight vector<br />from the set of evenly distributed vectors defined by:<br />?<br />? cost functions with respect to the known (or<br />? is drawn uniformly at random<br />? ?&quot;!<br />?<br />?<br />??#<br />?%$<br />#<br />?&amp;$(&#39;)&#39;(&#39;*$<br />#,+<br />?.-0/<br />+<br />132<br />?<br />#<br />1<br />?547698;:<br />determines how many vectors there are in<br />is then computed using the augmented<br />$<br />#<br />1<br />?<br />?=&lt;0&gt;<br />$<br />?@?BA<br />&#39;C&#39;<br />&gt;;D<br />$<br />(1)<br />with<br />total [10]. The scalar cost of a solution<br />Tchebycheff function [23]:<br />-<br />?<br />-<br />?FEHGJI<br />+LK<br />?<br />+?K<br />?BM , so that the choice of<br />&gt;<br />N0OP?RQ<br />?<br />N%OS?TQ<br />?<br />?VUXW?Y<br />1<br />?=#<br />1?Z<br />N<br />1<br />?TQ<br />?3?\[^]`_<br />1<br />#<br />1?Z<br />N<br />1<br />?TQ<br />?<br />$<br />:<br />?<br />4<br />&#39;a&#39;<br />?<br />(2)<br />where<br />all minima are proper Pareto optima, and which we set to<br />previously visited solutions are computed and, using all or a selection of these, a DACE<br />model of the landscape is constructed by maximum likelihood. The solution that maxi-<br />mizes the expected improvement with respect to this DACE model is determined. This<br />becomes the next point, and is evaluated on the real, expensive cost function, completing<br />one iteration of ParEGO.<br />N<br />1istherawcostvalueonobjective<br />:<br />and<br />]<br />isasmallpositivevalue,whichensures<br />A<br />&#39;<br />A&amp;b. The scalar costs of all</p>  <p>Page 6</p> <p>6<br />Algorithm 1 ParEGO pseudocode<br />1: procedure PAREGO(<br />2:<br />3:<br />for each<br />4:<br />5:<br />end for<br />6:<br />while not finished do<br />7:<br />NEWLAMBDA<br />8:<br />9:<br />10:<br />11:<br />12:<br />13:<br />end while<br />14: end procedure<br />c ,<br />d ,<br />e ,<br />f )<br />gLhji?hlk?m;n<br />LATINHYPERCUBE<br />s)std?uvs do<br />opd0q<br />/* Initialize using procedure: line 15 */<br />r in<br />s to<br />w*hji3hxkrpmjn<br />EVALUATE<br />opgLhji?hlkrTmTy?c;q<br />/* See line 36 */<br />zBnoTe{y|f(q<br />/* See line 19 */<br />/* See line 22 */<br />/* See line 28 */<br />}~i(d?*{n<br />DACE<br />EVOLALG<br />opgLhji?hlk?mTyJw*hji?hlk?mTy?z\q<br />EVALUATE<br />gjnop}~i(d?(RyHgLhji?hlkRmq<br />gLhji?hlk?mjngLhi3hlkRm0?gj.<br />w0n opgj?y?c;q<br />w(hi3hlkRm;nw*hji3hxk?m0~*w?*`<br />15: procedure LATINHYPERCUBE(<br />16:divide each dimension of search space into<br />17:<br />return<br />18: end procedure<br />d )<br />s?sdus ‘rows’ of equal width<br />s?sdus vectors<br />g such that no two share the same ‘row’ in any dimension<br />19: procedure NEWLAMBDA(<br />20:<br />return a<br />amongst all those defined by equation 1<br />21: end procedure<br />e ,<br />f )<br />e -dimensional scalarizing weight vector chosen uniformly at random from<br />22: procedure DACE(<br />23:compute the scalar fitness<br />24:choose a subset of the population based on the computed scalar fitness values<br />25:maximize the likelihood of the DACE model for the chosen population subset<br />26:<br />return the parameters of the maximum likelihood DACE model<br />27: end procedure<br />gLhi3hlkpm ,<br />w(hi3hlkRm ,<br />z )<br />c) of every cost vector in<br />w(hi3hlkRm , using equation 2<br />28: procedure EVOLALG(<br />29:initializeatemporary population ofsolution vectors, someasmutants of<br />purely randomly<br />30:<br />while set number of evaluations not exceeded do<br />31:evaluate the expected improvement of solutions using the model<br />32: select, recombine and mutate to form new population<br />33:<br />end while<br />34:<br />return best evolved solution<br />35: end procedure<br />}~i(d?( ,<br />gLhji?hlkRm )<br />g?hji3hxk?m andothers<br />36: procedure EVALUATE(<br />37: call the expensive evaluation function<br />38:<br />return true cost vector<br />39: end procedure<br />g ,<br />c )<br />c with the solution vector<br />g<br />w of solution<br />g</p>  <p>Page 7</p> <p>7<br />Population size: 20 solutions<br />Population update: steady state (one offspring produced per generation, from either a<br />crossover or cloning event, followed by a mutation)<br />Generations/evaluations: 10,000 evaluations<br />Reproductive selection: binary tournament without replacement<br />Crossover: simulated binary crossover [3] with probability 0.2, producing one offspring<br />Mutation: decision value shifted by<br />from<br />probability, is<br />Replacement: offspring replaces (first) parent if it is better, else it is discarded<br />Initialization: 5 solutions are mutantsaof the 5 best solutions evaluated on the real fitness<br />function under the prevailing<br />vector; the remaining 15 solutions are generated in a<br />latin hypercube in decision space<br />s?st?0 , where<br /> is drawn uniformly at random<br />oT????s?y*s*q ,<br /> is the range of the decision variable, and<br />h{ , the per-gene mutation<br />s**d .<br />z<br />aThe mutation is carried out as described above except that mutants are checked to ensure<br />they are different than parents.<br />Fig.3. The EA used in ParEGO to search for the ‘best’ next solution<br />Pseudocodefor the entire ParEGO algorithmis givenin Algorithm1. The Nelder and<br />Meads downhill simplex algorithm is used (with 20 restarts) to maximize the likelihood<br />of the DACE model (line 25 of Algorithm 1). The evolutionary algorithm used within<br />ParEGO to search for the solution that maximizes the expected improvement (line 28) is<br />implemented as detailed in Fig. 3.<br />In practice, on a very expensive cost function, all solutions previously evaluated<br />should be used to update the DACE model, at every iteration. However, to save com-<br />putational overhead in our experiments (because of the need to do 21 runs on a large<br />number of functions to collect performance data), we used a simple, heuristic method<br />of choosing a subset of the solutions evaluated to update the model, as follows: At each<br />iteration: (i) if the iteration number<br />uated so far, are used to update the model; and (ii) if<br />solutions is used, where the first half of them are the best<br />ing scalarizing vector and the other half are selected at random without replacement.<br />Further details of the parameter settings used in ParEGO are given in Section 6.<br />H|? is less than 25, all<br />404<br />??<br />solutions under the prevail-<br />4<br />[<br />H|) solutions eval-<br />H|? V¡<br />b<br />a subset of<br />404<br />?<br />4<br />[<br />¡<br />b<br />:<br />?<br />4Test function suite<br />4.1Notes on the selection of functions<br />A number of good attempts at designing test function suites and/or general schemes for<br />test function generation have been proposed in the multiobjective optimization litera-<br />ture, of which those described in [4,21,25] are some of the best. We make a selection<br />of nine test functions, borrowing from these, and adapting some of them slightly for<br />our purposes. Overall, our suite contains functions from two to eight decision variables;<br />functions with a very low density of solutions at the Pareto front; functions with locally</p>  <p>Page 8</p> <p>8<br />KNO1 [16] Features: Two decision variables; two objectives; Fifteen locally optimal<br />Pareto fronts.<br />OKA1 [21] Features: Two decision variables; two objectives; Pareto optima lie on curve;<br />density of solutions low at PF.<br />OKA2 [21] Features: Three decision variables; two objectives; Pareto optima lie on spiral-<br />shaped curve; density of solutions very low at PF.<br />VLMOP2 [25] Features: Two decision variables; two objectives; concave PF.<br />VLMOP3 [25] Features: Two decision variables; three objectives; disconnected Pareto op-<br />timal set and PF is a curve ‘following a convoluted path through objective space’.<br />DTLZ1a, adapted from [4] Features: Six decision variables; two objectives; local optima<br />on the way to the PF.<br />DTLZ2a and DTLZ4a, adapted from [4] Features: Eight decision variables; three objec-<br />tives; DTLZ4abiasesthedensity distributionof solutions toward the<br />planes.<br />DTLZ7a, adapted from [4] Features: Eight decision variables, three objectives; four dis-<br />connected regions in the Pareto front (in objective space).<br />c)¢%u?c<br />?and<br />c<br />?<br />u.c<br />?<br />Fig.4. Summary of the nine test functions<br />optimal Pareto fronts; functions where the Pareto set follows a complicated curve in the<br />decision space; functions where the Pareto front is disconnected in objective space; and<br />functions where the density of points parallel to the Pareto front is non-uniformly dis-<br />tributed. There is thus a good deal of variety in the difficulties that they pose. We have<br />nonetheless been restrictive in some particular aspects: all functions are unconstrained<br />and while difficult, are not overly high-dimensional (in decision space), and have a rea-<br />sonable, rather than pathological degree of ruggedness. And, we have kept to functions<br />of two and three objectives only. These restrictions accord with our description (in Sec-<br />tion 1) of certain kinds of expensive engineering/scientific problem, where we hope to<br />obtain good results in a very small number of function evaluations. We do not reproduce<br />the equations of all functions here but they can be found in [16] and are summarized in<br />Fig. 4.<br />5 Selected performance analysis techniques<br />In accordance with the analyses presented in [27], we choose the hypervolume indicator<br />to assess the approximation sets obtained by Bin MSOPS and ParEGO. We supplement<br />these tabulated values and significance levels with a visual representation based on sum-<br />mary attainment surfaces, for some of the 2-objective functions.<br />5.1Hypervolume indicator<br />The hypervolume indicator assesses the size (hypervolume or Lebesgue integral) of the<br />region weakly dominated by an approximations set, thus larger values indicate better<br />nondominated sets. It is “the only unary indicator we are aware of that is capable of</p>  <p>Page 9</p> <p>9<br />-10<br />-8<br />-6<br />-4<br />-2<br /> 0<br /> 2<br />-10-8-6-4-2 0 2<br />minimize f2<br />minimize f1<br />Exact attainment surfaces - 2d<br />best<br />median<br />worst<br />1<br />2<br />3<br />4<br />5<br />Fig.5. Five sets of nondominated points and the best, median and worst attainment surfaces that<br />they define. The interpretation of the median attainment surface is that, for every point on it (in-<br />dependently), a point (weakly) dominating this was obtained in at least<br />sets. Similarly, the worst attainment surface indicates the level achieved in<br />best attainment surface indicates the level achieved by the aggregation of all sets. In this study, the<br />best attainment surface is irrelevant and is not included in plotted results<br />£)?¤<br />of the nondominated<br />of the sets. The<br />s)L¤<br />detecting that<br />are two approximation sets.<br />The weakly dominated region being measured must be bounded from above in some<br />way, and for this some point<br />in the sample set. In order to choose a boundingpoint for application of the hypervolume<br />indicator, we use the following method. First, the collection of nondominated point sets<br />from all runs of both algorithms (on the relevant function) are aggregated into a single<br />superset. Then, the ideal and the anti-ideal point of this superset are found.The bounding<br />point is then the anti-ideal point shifted by<br />¥<br />is not worse than<br />¦<br />for all pairs<br />¥V§<br />[better than]<br />¦ ” [27], where<br />¥<br />and<br />¦<br />¨ is chosen, which must be itself dominated by every point<br />© times the range, in each objective:<br />ª<br />?<br />?=¨<br />?<br />$<br />¨<br />?<br />$)&#39;(&#39;)&#39;*$<br />¨<br />+<br />?<br />$<br />with<br />¨<br />1<br />?VUXW?Y<br />1<br />[<br />©;?T«B¬&amp;Q<br />1<br /><br />U?­a®<br />1<br />?<br />$<br />:<br />?<br />4<br />&#39;C&#39;<br />?<br />$<br />where<br />objective, found within the superset. We use<br />For the analysis of multiple runs, we compute the hypervolume indicator of each<br />individual run, and report the mean and the standard deviation of these. Since the dis-<br />tribution of Bin MSOPS’ and ParEGO’s results are not necessarily normal, we use the<br />Mann-Whitneyrank-sum test to indicate if there is a statistically significant difference in<br />the position of the two distributions.<br />U?W?Y<br />1and<br />U?­C®<br />1are the maximum and minimum value, respectively, on the<br />:th<br />©<br />?<br />A<br />&#39;<br />A<br />4<br />here.<br />5.2Median and worst summary attainment surface plots<br />A summary attainment surface is a visual way of summarizing a number of runs of a<br />multiobjective optimizer, based on the notion of an attainment surface [7]. For illustra-</p>  <p>Page 10</p> <p>10<br />Table 1. ParEGO parameter settings, where<br />d is the number of decision variables<br />Parameter<br />Initial population in latin hypercube<br />Total maximum evaluations<br />Number of scalarizing vectors<br />Scalarizing function<br />Internal GA evals per iteration<br />Crossover probability<br />Real-value mutation probability<br />Real-value SBX parameter<br />Real-value mutation parameter<br />setting<br />s?sdus<br />250<br />11 (for 2 objectives), 15 (for 3 objectives)<br />augmented Tchebycheff<br />¯(?\?)<br />10<br />50<br />0.2<br />s*(d<br />tion, we plot five sets of nondominated points and their exact sample median, best and<br />worst, summary attainment surfaces in Fig. 5.<br />For the two-objective problems in this paper, we give the median and worst attain-<br />ment surfaces only of ParEGO and of Bin MSOPS on the same plot, with ParEGO’s two<br />surfaces shown in solid and Bin MSOPS’s two surfaces shown with dashed lines. We do<br />not give plots for the three-objective problems here, because of space restrictions.<br />6Experimental details<br />To evaluate Bin MSOPS and ParEGO on the test suite, each algorithm is run 21 times,<br />and all solutions visited are stored. The nondominated sets achieved after a particular<br />numberoffunctionevaluationscanthenbedeterminedandusedtoestimateperformance.<br />6.1Bin MSOPS parameter settings<br />Weighted Min-Max was used as the aggregation method within the MSOPS ranking<br />algorithm. The weighted min-max scoreof<br />#,° is the weight for the<br />&gt;<br />? objectives is calculated using (3),where<br /> th objective value,<br />N0° .<br />&gt;<br />?<br />+<br />UXW%Y<br />°<br />2<br />?<br />??#<br />°<br />N<br />°<br />?<br />$<br />(3)<br />A set of objective weights constitutes a single target vector.<br />Thirty target vectors were used, spaced so that the angle to their nearest neighbour<br />was constant across the set of 30. Thus in trials with 3 objectives, the set of weight<br />vectors, although evenly spaced, was non-unique.<br />To choose a ‘good’ point, a tournament size with a maximum of 20, without replace-<br />ment, was used throughout all the experiments.<br />A search interval (see figure 2) of<br />on the coverage area of allowable cells of<br />variables in the range [0,1]). If the cells near to the chosen ‘good’ point were below the<br />cell area limit, a search was performed to find the nearest cell that is large enough to<br />?<br />?<br />?<br />A<br />&#39;<br />A<br />¡ was used and a lower limit was set<br />(in normalized decision space with all<br />A<br />&#39;<br />A0Ab<br />?</p>  <p>Page 11</p> <p>11<br />split. The lower limit promotesa wider search aroundinteresting points, but does prevent<br />a tight-formation search occurring, which may be detrimental in problems with a very<br />low density at the Pareto set (e.g. test function OKA1).<br />Initially, the algorithm performed a global exploration search for approximately the<br />first 20 points, then global exploration was performed 6% of the time.<br />6.2 ParEGO parameter settings<br />The full set of parameter settings used in all runs of ParEGO are given in Table 1. These<br />were determined empirically from a few exploratory trials.<br />7 Results<br />Tables 2 and 3 present the results of applyingthe hypervolumeindicator to the 21 runs of<br />Bin MSOPS and ParEGO after, respectively, 100 and 250 function evaluations. Because<br />it is notpossibleto usethese valuesincomparisonswith otheralgorithms,we makeavail-<br />able the raw results at [15]. Note also that the appearance of the hypervolumedecreasing<br />from 100 to 250 evaluations on some problems is only due to the choice of a different<br />bound point (see above).<br />Fig. 5 and 6 visualize the median and worst summary attainment surfaces of the 21<br />runs of both algorithms on selected 2-objective problems. Fig. 7 and 8 show the deci-<br />sion space points visited by the first run of the two algorithms on KNO1 and OKA1,<br />respectively.<br />From these results a number of observations can be made:<br />– ParEGO is statistically significantly better than Bin MSOPS on seven of the nine<br />functions at 100 evaluations, and on six of the nine functions after 250 evaluations,<br />underthe hypervolumeindicator.(cf. [16],where ParEGO was better than a standard<br />setup of NSGA-II with population size 20 on all test functions under two different<br />indicators).<br />– The standard deviations of the two algorithms are generally comparable, with a<br />large difference evident on only one problem, DTLZ1a, at 250 evaluations (2 or-<br />ders of magnitudeless deviationfor ParEGO). Results reportedin [16] indicatedthat<br />ParEGO’s standard deviationswere frequentlyone or two ordersof magnitudelower<br />than NSGA-II’s on these problems, so the results here show that Bin MSOPS is per-<br />formingcomparativelyrobustly— an important featureon problemswhere only one<br />run may be possible.<br />– Fig. 5 and 6 indicate that ParEGO run for 250 evaluations is superior to a random<br />search of 1000 evaluations on the difficult OKA1 and OKA2 functions, where there<br />is a low density of solutions near the Pareto front. On OKA1, ParEGO’s median<br />attainment surface dominates all 1000 randomly generated points and on OKA2,<br />even ParEGO’s worst attainment surface does.<br />– Fig. 7 and 8 demonstrate that the search patterns of Bin MSOPS and ParEGO are<br />very different, and generally complementary. It is clear that while Bin MSOPS at-<br />temptstogetanevencoverageofthesearchspace,bothgloballyandlocally,ParEGO</p>  <p>Page 12</p> <p>12<br /> 0<br /> 5<br /> 10<br /> 15<br /> 20<br /> 0  2 4  6 8<br />f1<br /> 10 12 14 16<br />f2<br />KNO1: BIN_MSOPS vs. ParEGO<br />BIN_MSOPS: 250 evals<br />ParEGO: 250 evals<br />Pareto front<br /> 0<br /> 0.5<br /> 1<br /> 1.5<br /> 2<br /> 2.5<br /> 3<br /> 3.5<br /> 4<br /> 4.5<br /> 5<br /> 0 1 2  3 4 5 6<br />f2<br />f1<br />OKA1: Bin_MSOPS vs. ParEGO<br />BIN_MSOPS: 250 evals<br />ParEGO: 250 evals<br />Pareto front<br />Fig.6. Attainment surface plot on the KNO1 function after 250 function evaluations (left), and<br />attainment surface plot with PF and 1000 random search points also shown on the OKA1 function<br />after 250 function evaluations (right)<br />-1<br /> 0<br /> 1<br /> 2<br /> 3<br /> 4<br /> 5<br />-4-3-2-1 0<br />f1<br /> 1 2 3 4<br />f2<br />OKA2: Bin_MSOPS vs. ParEGO<br />BIN_MSOPS: 250 evals<br />ParEGO: 250 evals<br />PF<br /> 0<br /> 0.2<br /> 0.4<br /> 0.6<br /> 0.8<br /> 1<br /> 1.2<br /> 0 0.2 0.4 0.6<br />f1<br /> 0.8  1 1.2<br />f2<br />VLMOP2: BIN_MSOPS vs. ParEGO<br />BIN_MSOPS: 250 evals<br />ParEGO: 250 evals<br />Fig.7. Attainment surface plot on OKA2 after 250 function evaluations, with the true PF and 1000<br />random search points also shown (left),and attainment surface plot on VLMOP2 after 250 function<br />evaluations (right)<br />operates by combining a well-spread global search with full exploitation of local<br />‘niches’ (highly fit regions). This explains the far superior performance of ParEGO<br />on the test functions with either low density at the Pareto front, local Pareto fronts or<br />severediscontinuities.Fig. 7 (right)is a goodexample,however,of a smoother,more<br />dense function where Bin MSOPS has provided good even coverage, but ParEGO<br />has focused too much on local niches. Fig. 8 really shows how ParEGO homes in on<br />parts of the true Pareto set more aggressively,but sometimes fails to spread across it.<br />8 Summary and conclusion<br />In many optimization scenarios, the number of fitness evaluations that can be performed<br />is severely limited by cost or other constraints. In this study, the performance of two</p>  <p>Page 13</p> <p>13<br />Table 2. Mean and SD values of the hypervolume indicator after 100 evaluations of Bin MSOPS /<br />ParEGO from 21 runs of each. Larger values indicate better performance. The distributions of the<br />values are tested using the Mann-Whitney rank sum test. The<br />indicated. ParEGO is significantly better than Bin MSOPS unless stated<br />± values and significance level are<br />Function Bin MSOPS mean (SD) ParEGO mean (SD)<br />OKA114.8496 (0.571733)<br />OKA213.6773 (1.53528)<br />KNO186.9879 (5.9303)<br />VLMOP2 0.317661 (0.00440428) 0.307027 (0.00564198) -4.792169<br />VLMOP3 7.22865 (0.681038)<br />DTLZ1a 185317 (2573.43)<br />DTLZ2a 3.85168 (0.139089)<br />DTLZ4a 0.533989 (0.0394657)<br />DTLZ7a 10.5544 (1.7988)<br />² -value<br />-5.546841<br />-5.546841<br />-3.735627<br />significance<br />17.9532 (0.372966)<br />19.7183 (0.887686)<br />78.4856 (7.24012)<br />³9´´µ<br />³9´´µ<br />³9´´µ<br />Bin MSOPS wins<br />Bin MSOPS wins<br />³9´´µ<br />7.61652 (0.157667)<br />189262 (209.001)<br />3.97869 (0.0890044)<br />0.673329 (0.263526)<br />12.9893 (0.655795)<br />-1.547078<br />-5.521685<br />-3.358291<br />-2.477840<br />-4.490300<br />³9´¶µ<br />³9´´µ<br />³9´´µ<br />³9´´µ<br />³9´´µ<br />Table 3. Mean and SD values of the hypervolume indicator after 250 evaluations of Bin MSOPS /<br />ParEGO from 21 runs of each. Larger values indicate better performance. The distributions of the<br />values are tested using the Mann-Whitney rank sum test. The<br />indicated. ParEGO is significantly better than Bin MSOPSunless stated<br />± values and significance level are<br />Function Bin MSOPS mean (SD) ParEGO mean (SD)<br />OKA114.8169 (0.446187)<br />OKA213.9093 (1.13887)<br />KNO194.972 (1.70367)<br />VLMOP2 0.324363 (0.000664073) 0.310789 (0.00398408) -5.546841<br />VLMOP3 4.94459 (0.0599138)<br />DTLZ1a 63980.6 (602.738)<br />DTLZ2a 2.79582 (0.0960357)<br />DTLZ4a 0.111108 (0.124952)<br />DTLZ7a 10.6171 (1.26015)<br />² -value<br />-5.219816<br />-5.546841<br />-5.521685<br />significance<br />15.9849 (0.372917)<br />18.4416 (0.467239)<br />84.2247 (5.5432)<br />³?´t´tµ<br />³?´t´µ<br />³X´´µ<br />Bin MSOPS wins<br />Bin MSOPS wins<br />Bin MSOPS wins<br />³?´t´tµ<br />4.75726 (0.113527)<br />64869.6 (6.98978)<br />3.08818 (0.0276524)<br />1.67242 (0.478067)<br />18.1657 (0.431554)<br />-4.892791<br />-5.546841<br />-5.546841<br />-5.521685<br />-5.546841<br />³?´t´tµ<br />³?´t´tµ<br />³?´t´tµ<br />³?´t´tµ<br />³?´t´tµ<br /> 0<br /> 0.5<br /> 1<br /> 1.5<br /> 2<br /> 2.5<br /> 3<br /> 0 0.5 1 1.5<br />x1<br /> 2 2.5 3<br />x2<br />KNO1 Decision Space: Bin_MSOPS and ParEGO<br />Bin_MSOPS<br />ParEGOPFlocal PF<br />Local PSPareto set<br />-2<br />-1<br /> 0<br /> 1<br /> 2<br /> 3<br /> 4<br /> 5<br /> 6<br /> 1 2  3 4 5 6  7 8<br />x2<br />x1<br />OKA1 Decision Space: Bin_MSOPS and ParEGO<br />Bin_MSOPS<br />ParEGO<br />Pareto set<br />Fig.8. Decision space points visited by Bin MSOPS and ParEGO on KNO1 and OKA1. ParEGO<br />fares worse on the former because it focuses too much on getting exactly on the PF instead of<br />spreading out along it, while Bin MSOPS extends further along it. But ParEGO’s strategy does<br />better than Bin MSOPS’son OKA1 because points a small way off the Pareto set in decision space<br />are far from the PF in objective space</p>  <p>Page 14</p> <p>14<br />advanced multiobjective optimization algorithms, Bin MSOPS and ParEGO, was mea-<br />sured on much shorter runs than used in most previous MOEA studies. A suite of nine<br />difficult, but low-dimensional, multiobjective test functions of limited ruggedness were<br />used to evaluate and compare the algorithms. The results of the comparison indicated<br />that ParEGO’s use of a surrogate model to establish both the expected multiobjective<br />cost of candidate solutions and the uncertainty in these predictions, enables rapid ad-<br />vances in the early phase of the optimization process. The less directed search performed<br />by Bin MSOPS is good, but can fail to capitalize effectively on previously gathered in-<br />formation when the solution density at the Pareto front is low.<br />Overall, the experimentsreportedhere can serve as a benchmarkfor other algorithms<br />aimed at these type of expensive, low-dimensional multiobjective problems. To facilitate<br />thecomparisonofBin MSOPSandParEGOwithothermethods,rawresultsareavailable<br />at [15]. Comparisons of ParEGO with NSGA-II can already be found in [16].<br />Future work will focus on three possible extensions. 1. an adaptive update of the<br />scalarizing vectors to get a better distribution on the Pareto front; 2. constraint handling<br />mechanisms; and 3. investigation of a hybrid between Bin MSOPS and ParEGO that<br />might offer a good combination of computational efficiency and high performance in<br />short-to-mediumrun lengths (say up to 500 evaluations) for problems where evaluations<br />are faster but still otherwise limited.<br />Acknowledgments JK is supported by a David Phillips fellowship from the Biotech-<br />nology and Biological Sciences Research Council (BBSRC), UK. Thanks to J. Handl for<br />proof-readingand ParEGO implementation advice.<br />References<br />1. D. B¨ uche, G. Guidati, P. Stoll, and P. Kourmoursakos. Self-organizing maps for Pareto op-<br />timization of airfoils. In Parallel Problem Solving from Nature—PPSN VII, pages 122–131,<br />September 2002. Springer-Verlag.<br />2. J.-J. Chen, D. E. Goldberg, S.-Y. Ho, and K. Sastry. Fitness inheritance in multi-objective<br />optimization.In Proceedings of the Genetic and Evolutionary Computation Conference<br />(GECCO’2002), pages 319–326, July 2002. Morgan Kaufmann Publishers.<br />3. K. Deb and H. Beyer. Self-adaptive genetic algorithms with simulated binary crossover. Evo-<br />lutionary Computation, 9(2):197–221, 2001.<br />4. K. Deb, L. Thiele, M. Laumanns, and E. Zitzler. Scalable test problems for evolutionary<br />multi-objective optimization. Technical Report 112, Computer Engineering and Networks<br />Laboratory (TIK), Swiss Federal Institute of Technology (ETH), Zurich, Switzerland, 2001.<br />5. E. I. Ducheyne, B. De Baets, and R. De Wulf. Is fitness inheritance useful for real-world<br />applications? InEvolutionary Multi-CriterionOptimization.Second International Conference,<br />EMO 2003, pages 31–42, April 2003. Springer.<br />6. J. R. G. Evans, M. J. Edirisinghe, and P. V. C. J. Eames. Combinatorial searches of inorganic<br />materials using the inkjet printer: science philosophy and technology. Journal of the European<br />Ceramic Society, 21:2291–2299, 2001.<br />7. C.M. Fonsecaand P. J.Fleming. On theperformance assessment and comparison of stochastic<br />multiobjective optimizers. In Parallel Problem Solving from Nature—PPSN IV, pages 584–<br />593, 1996. Springer-Verlag.</p>  <p>Page 15</p> <p>15<br />8. A. Gaspar-Cunha and A. Vieira. A multi-objective evolutionary algorithm using neural net-<br />works to approximate fitness evaluations. International Journal of Computers, Systems, and<br />Signals, 2004 (in press).<br />9. A. Gaspar-Cunha and A. S. Vieira. A hybrid multi-objective evolutionary algorithm using an<br />inverse neural network. Hybrid Metaheuristics (HM 2004) Workshop at ECAI 2004, pages<br />25-30, 2004. http://iridia.ulb.ac.be/ hm2004/proceedings/<br />10. M. P. Hansen and A. Jaszkiewicz. Evaluating the quality of approximations of the nondomi-<br />nated set. Technical Report IMM-REP-1998-7, Technical University of Denmark, 1998.<br />11. E. J. Hughes. Multi-objective binary search optimisation. In Second International Confer-<br />ence on Evolutionary Multi-Criterion Optimisation, EMO’03, pages 102–117, April 2003.<br />Springer.<br />12. E. J. Hughes. Multiple single objective Pareto sampling. In Congress on Evolutionary Com-<br />putation 2003, pages 2678–2684, December 2003. IEEE.<br />13. Y. Jin, M. Olhofer, and B. Sendhoff. A framework for evolutionary optimization with ap-<br />proximate fitness functions. IEEE Transactions on Evolutionary Computation, 6(5):481–494,<br />2002.<br />14. D. Jones, M. Schonlau, and W. Welch. Efficient global optimization of expensive black-box<br />functions. Journal of Global Optimization, 13:455–492, 1998.<br />15. Knowles’ webpage. http://dbk.ch.umist.ac.uk/knowles/<br />16. J. Knowles. ParEGO: A hybrid algorithm with on-line landscape approximation for expensive<br />multiobjective optimization problems. Technical Report TR-COMPSYSBIO-2004-01, Uni-<br />versity of Manchester, UK, 2004. Available from http://dbk.ch.umist.ac.uk/knowles/pubs.html<br />17. M. Laumanns and J. Ocenasek. Bayesian optimization algorithms for multi-objective opti-<br />mization. In Parallel Problem Solving from Nature—PPSN VII, pages 298–307, September<br />2002. Springer-Verlag.<br />18. R. Myers and D. Montgomery. Response Surface Methodology. Wiley, New York, 1995.<br />19. P. K. S. Nain and K. Deb. A computationally effective multi-objective search and optimization<br />technique using coarse-to-fine grain modeling. Technical Report Kangal Report No. 2002005,<br />IITK, Kanpur, India, 2002.<br />20. S. O’Hagan, W. Dunn, M. Brown, J. Knowles, and D. Kell. Closed-loop, multiobjective opti-<br />mization of analytical instrumentation: gas chromatography/time-of-flight mass spectrometry<br />of the metabolomes of human serum and of yeast fermentations. Analytical Chemistry, 2004<br />(in press). http://pubs.acs.org/cgi-bin/asap.cgi/ancham/asap/html/ac049146x.html<br />21. T. Okabe, Y. Jin, M. Olhofer, and B. Sendhoff. On test functions for evolutionary multi-<br />objective optimization. InParallel ProblemSolving fromNature VIII,pages 792–802, Septem-<br />ber 2004, Springer.<br />22. J. Sacks, W. Welch, T. Mitchell, and H. Wynn. Design and analysis of computer experiments<br />(with discussion). Statistical Science, 4:409–435, 1989.<br />23. R. E. Steuer and E.-U. Choo. An interactive weighted Tchebycheff procedure for multiple<br />objective programming. Mathematical Programming, 25:326–344, 1983.<br />24. S. Vaidyanathan, D. I. Broadhurst, D. B. Kell, and R. Goodacre. Explanatory optimization of<br />protein mass spectrometry via genetic search. Analytical Chemistry, 75(23):6679–6686, 2003.<br />25. D. A. V. Veldhuizen and G. B. Lamont. Multiobjective evolutionary algorithm test suites.<br />In Proceedings of the 1999 ACM Symposium on Applied Computing, pages 351–357, 1999.<br />ACM.<br />26. D. Weuster-Botz and C. Wandrey. Medium optimization by genetic algorithm for continuous<br />production of formate dehydrogenase. Process Biochemistry, 30:563–571, 1995.<br />27. E. Zitzler, L. Thiele, M. Laumanns, C. M. Fonseca, and V. G. da Fonseca. Performance as-<br />sessment of multiobjective optimizers: An analysis and review. IEEE Transactions on Evolu-<br />tionary Computation, 7(2):117–132, April 2003.</p>  <a href="https://www.researchgate.net/profile/Evan_Hughes/publication/221228406_Multiobjective_Optimization_on_a_Budget_of_250_Evaluations/links/00b495225ac557f688000000.pdf">Download full-text</a> </div> <div id="rgw19_56aba233d3dc4" class="c-box pub-resource-container js-toggle" style=""> <h4 class="lf js-expand-list"><small><a href="javascript:" class="lf">View other sources <span class="ico-expand-list"></span></a></small></h4> <h4 class="lf js-collapse-list hidden"><small><a href="javascript:" class="lf">Hide other sources <span class="ico-collapse-list"></span></a></small></h4> <div class="clear"></div> <div class="scroll-wrapper hidden"> <ul class="files-list c-list" id="rgw20_56aba233d3dc4">  <li class="c-list-item pub-resource-item"  data-type="fulltext" id="rgw21_56aba233d3dc4"> <span class="ico-pub"></span> <div class="file-content"> <div class="download"> <a href="profile/Evan_Hughes/publication/221228406_Multiobjective_Optimization_on_a_Budget_of_250_Evaluations/links/00b495225ac557f688000000.pdf" class="publication-viewer" title="00b495225ac557f688000000.pdf">00b495225ac557f688000000.pdf</a> </div>  <div class="details">  <span> Available from <a href="profile/Evan_Hughes">Evan Hughes</a> &middot; Jan 21, 2016 </span>   </div>    </div> </li>  <li class="c-list-item pub-resource-item"  data-type="fulltext" id="rgw22_56aba233d3dc4"> <span class="ico-pub"></span> <div class="file-content"> <div class="download"> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.106.3062&amp;amp;rep=rep1&amp;amp;type=pdf" target="_blank" rel="nofollow" class="publication-viewer" title="Multiobjective Optimization on a Budget of 250 Evaluations">Multiobjective Optimization on a Budget of 250 Eva...</a> </div>  <div class="details">   Available from <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.106.3062&amp;amp;rep=rep1&amp;amp;type=pdf" target="_blank" rel="nofollow">citeseerx.ist.psu.edu</a>  </div>    </div> </li>  </ul> </div> </div> </noscript> <div class="clearfix"> <div class="action-container">  </div> <div class="pub-legal"> Data provided are for informational purposes only. Although carefully collected, accuracy cannot be guaranteed. The impact factor represents a rough estimation of the journal's impact factor and does not reflect the actual current impact factor. Publisher conditions are provided by RoMEO. Differing provisions from the publisher's actual policy or licence agreement may be applicable. </div>   </div> </div> <div class="clearfix">     <div id="rgw24_56aba233d3dc4" class="c-box pub-resource-container js-toggle" style="display: none;"> <h4 class="lf js-expand-list"><small><a href="javascript:" class="lf">View other sources <span class="ico-expand-list"></span></a></small></h4> <h4 class="lf js-collapse-list hidden"><small><a href="javascript:" class="lf">Hide other sources <span class="ico-collapse-list"></span></a></small></h4> <div class="clear"></div> <div class="scroll-wrapper hidden"> <ul class="files-list c-list" id="rgw25_56aba233d3dc4">  </ul> </div> </div>   <div id="rgw15_56aba233d3dc4" class="similar-publications"> <h2>Similar Publications</h2> <ul class="list-bordered">  <li class="c-list-item li-publication-teaser" id="rgw16_56aba233d3dc4"> <div> <h5> <a href="publication/221228457_Noisy_Multiobjective_Optimization_on_a_Budget_of_250_Evaluations" class="color-inherit ga-similar-publication-title"><span class="publication-title">Noisy Multiobjective Optimization on a Budget of 250 Evaluations</span></a>  </h5>  <div class="authors"> <a href="researcher/8111149_Joshua_D_Knowles" class="authors ga-similar-publication-author">Joshua D. Knowles</a>, <a href="researcher/6802819_David_Corne" class="authors ga-similar-publication-author">David Corne</a>, <a href="researcher/70005306_Alan_P_Reynolds" class="authors ga-similar-publication-author">Alan P. Reynolds</a>  </div>  </div> <div class="clear"></div> </li>  <li class="c-list-item li-publication-teaser" id="rgw17_56aba233d3dc4"> <div> <h5> <a href="publication/220702165_Multiobjective_Optimization_on_a_Limited_Budget_of_Evaluations_Using_Model-Assisted_mathcalS_-Metric_Selection" class="color-inherit ga-similar-publication-title"><span class="publication-title">Multiobjective Optimization on a Limited Budget of Evaluations Using Model-Assisted $\mathcal{S}$ -Metric Selection</span></a>  </h5>  <div class="authors"> <a href="researcher/11556719_Wolfgang_Ponweiser" class="authors ga-similar-publication-author">Wolfgang Ponweiser</a>, <a href="researcher/22462338_Tobias_Wagner" class="authors ga-similar-publication-author">Tobias Wagner</a>, <a href="researcher/78214747_Dirk_Biermann" class="authors ga-similar-publication-author">Dirk Biermann</a>, <a href="researcher/11556718_Markus_Vincze" class="authors ga-similar-publication-author">Markus Vincze</a>  </div>  </div> <div class="clear"></div> </li>  <li class="c-list-item li-publication-teaser" id="rgw18_56aba233d3dc4"> <div> <h5> <a href="publication/266891652_A_Brief_Introduction_to_A_Brief_Introduction_to_Multiobjective_Optimization_Multiobjective_Optimization_Techniques_Techniques" class="color-inherit ga-similar-publication-title"><span class="publication-title">A Brief Introduction to A Brief Introduction to Multiobjective Optimization Multiobjective Optimization Techniques Techniques</span></a>  </h5>  <div class="authors"> <a href="researcher/8933238_Maurizio_Palesi" class="authors ga-similar-publication-author">Maurizio Palesi</a>  </div>  </div> <div class="clear"></div> </li>  </ul> </div> </div> </div> </div> </div></div></div>
<div class="clear"></div><div id="rgw38_56aba233d3dc4" class="default-footer"> <div id="footer" class="clearfix"> <span class="footer-left"> &copy; 2008&dash;2016 researchgate.net. All rights reserved. </span> <span class="footer-right"> <a href="https://www.researchgate.net/about">About us</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="https://www.researchgate.net/contact">Contact us</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="careers">Careers</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="developers">Developers</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="blog" target="_blank">News</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="application.PrivacyPolicy.html">Privacy</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="application.TermsAndConditions.html">Terms</a> <span class="footer-link-separator" style="padding: 0 5px;">&nbsp;|&nbsp;</span> <a href="advertising?_ref=ft">Advertising</a> <span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="recruiters?_ref=ft">Recruiting</a> </span> </div>  </div></div>
<div id="rgw39_56aba233d3dc4">  <div class="header-wrapper-logged-out"> <div id="header"> <div class="header-content"> <a href="" class="g-l-logo"> <svg width="149" height="19"> <image xlink:href="https://c5.rgstatic.net/m/235107188705592/images/template/brand-header-logo.svg" src="https://c5.rgstatic.net/m/238113351022438/images/template/brand-header-logo.png" width="149" height="19"/> </svg> </a> <a href="" class="g-l-logo-ico"> <svg width="127" height="17" viewbox="0 0 127 22"> <image xlink:href="https://c5.rgstatic.net/m/235107188705592/images/template/brand-header-logo.svg" src="https://c5.rgstatic.net/m/238113351022438/images/template/brand-header-logo.png" width="127" height="17"/> </svg> </a> <div id="rgw40_56aba233d3dc4" class="header-login-wrapper js-header-login"> <div class="dropdown-right-align"> <div class="login-signup-container lf"> <a href="https://www.researchgate.net/signup.SignUp.html?ev=su_chnl_index&amp;hdrsu=1&amp;_sg=TZhU2mIUdK8EgvHb4geFbGut4Gg7rp0jAZ2GvtNm_LVoaXFe1hFFEs159IaSSH33" class="dropdown-toggle lf">Join for free</a> </div> <div class="dropdown lf" style="height: 20px;"> <a href="https://www.researchgate.net/application.Login.html" class="js-login-url dropdown-toggle lf">Log in <span class="caret"></span></a> <div class="dropdown-menu"> <div class="header-login-form-wrapper"> <!--[if IE 6]><p class="box-warning" style="margin-bottom: 0;">Sorry, ResearchGate no longer supports the version of Internet Explorer you are using. <a href="http://whatbrowser.org/" rel="nofollow" target="_blank">Update your web browser</a> and then log in. </p><![endif]--> <form method="post" action="https://www.researchgate.net/application.Login.html" class="form-big header-login-form js-login-form" name="loginForm" id="headerLoginForm"> <input type="hidden" name="request_token" value="BP69bFBxXbSrqUYhI6tOcjY/ZrIP8Lwon+lVdQOGrpcfrTHRpy0/+yGbOg5uDxQlVQtAGjXzEi+FFw0sr848YLeKIPDLcCBSXDxwfb7qg4bchQrnLkdlAaMiDLCl6SXM+TRWuNzKVp9csWBpzxx6A/C7fB/RxdZt9sBcpHSDVo3Ag+lNEr9TC96CdwvJQPwRv7jELAQn/QWdw6YjTFGZ6NO0Ae4ly9nZNvcX3kPvSTftblVpd8GwGKOuDQFhDvq8n1GORi209PruidFfY1wC+RBm7thDmGcYqYfM0gHOb9Q="/> <input type="hidden" name="urlAfterLogin" value="publication/221228406_Multiobjective_Optimization_on_a_Budget_of_250_Evaluations"/> <input type="hidden" name="invalidPasswordCount" value="0"/> <input type="hidden" name="headerLogin" value="yes"/> <label for="input-header-login">Email</label> <div class="login-input"> <div class="info-tip-wrapper"> <span class="ico-info js-info"></span> </div> <input type="email" value="" name="login" class="login js-login-input text" id="input-header-login" tabindex="1"/> </div> <div class="clear"></div> <label class="lf" for="input-header-password"> Password </label> <a class="rf forgot-password js-forgot-password" href="application.LostPassword.html">Forgot password?</a> <div class="clear"></div> <input type="password" value="" name="password" class="password js-password-input text" id="input-header-password" tabindex="2"/> <div class="clear"></div> <label class="remember-me" for="headerLoginCookie"> <input type="checkbox" checked="checked" value="yes" name="setLoginCookie" class="lf checkbox" id="headerLoginCookie" tabindex="3"/> Keep me logged in </label> <div class="clear"></div> <input value="Log in" name="loginSubmit" class="btn btn-promote btn-fullwidth btn-large allow-leave js-submit-button" type="submit" tabindex="4"/> </form> <div class="connectors"> <div class="text">or log in with</div> <div class="connector-actions"> <a href="connector/linkedin/" class="li-connect js-li-connect" data-redirect-url="cHVibGljYXRpb24vMjIxMjI4NDA2X011bHRpb2JqZWN0aXZlX09wdGltaXphdGlvbl9vbl9hX0J1ZGdldF9vZl8yNTBfRXZhbHVhdGlvbnM%3D"> <span class="icon ico-linkedin-round-grey"></span> <span class="icon ico-linkedin-round"></span> </a> <a href="connector/facebook/" class="fb-connect middle js-fb-connect" data-redirect-url="cHVibGljYXRpb24vMjIxMjI4NDA2X011bHRpb2JqZWN0aXZlX09wdGltaXphdGlvbl9vbl9hX0J1ZGdldF9vZl8yNTBfRXZhbHVhdGlvbnM%3D"> <span class="icon ico-facebook-round-grey"></span> <span class="icon ico-facebook-round"></span> </a> <a href="connector/google/" class="g-connect js-g-connect" data-redirect-url="cHVibGljYXRpb24vMjIxMjI4NDA2X011bHRpb2JqZWN0aXZlX09wdGltaXphdGlvbl9vbl9hX0J1ZGdldF9vZl8yNTBfRXZhbHVhdGlvbnM%3D"> <span class="icon ico-google-round-grey"></span> <span class="icon ico-google-round"></span> </a> </div> </div> </div> </div> </div> </div> </div> </div> </div> <script type="application/ld+json">
{ "@context" : "http://schema.org",
  "@type" : "Organization",
  "name" : "ResearchGate",
  "url" : "http://www.researchgate.net",
  "logo" : "http://www.researchgate.net/images/template/rg_logo_square_brand.png",
  "sameAs" : [ "https://www.facebook.com/ResearchGate",
    "https://twitter.com/ResearchGate",
    "https://plus.google.com/+researchgate",
    "https://www.linkedin.com/company/researchgate"] 
}
</script> </div> </div><div class="c-signup-bar" id="rgw41_56aba233d3dc4"> <div class="banner-contents">   <span class="message">ResearchGate is the professional network for scientists and researchers.</span> <a href="signup.SignUp.html?ev=su_banner" class="btn btn-large btn-promote">Join for free</a>  </div> </div></div>
<script>
rgConfig.backendTime = 573;
</script>
<script src="//c5.rgstatic.net/m/2277196935388619/javascript/lib/yui3/yui/yui-min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/21832295316281274/javascript/yuiLoaderConfig-min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/23178613132105398/javascript/vendor/babel-core/browser-polyfill.min.js" type="text/javascript"></script>
<script>
(function (){
if (typeof YRG === "undefined") {
var xmlHttpRequest = new XMLHttpRequest();
xmlHttpRequest.open("post", "go.Error.html");
xmlHttpRequest.setRequestHeader("Content-Type", "application/json");
xmlHttpRequest.setRequestHeader("Accept", "application/json"); var loadedScripts = "";
if (window.performance && window.performance.getEntriesByType) {
    var result = [];
    var resources = performance.getEntriesByType("resource");
    for (var i in resources) {
        if (resources.hasOwnProperty(i)) {
            result.push({
                name: resources[i].name,
                duration: resources[i].duration
            });
        }
    }
    loadedScripts += "&loadedScripts=" + encodeURIComponent(JSON.stringify(result));
}
if (typeof YUI === "undefined") {
    loadedScripts += "&yuiLoaded=false";
} else {
    loadedScripts += "&yuiLoaded=true";
}
xmlHttpRequest.send("Type=InformationException&message=" + encodeURIComponent("Error loading YUI") + loadedScripts);
}
})();
</script>
<script>if (typeof YRG !== 'undefined') { YRG.use('rg-base',function(Y){Y.applyConfig({ignore: ["css-rg","css-rg2","css-ie","css-modules-publicprofile","css-pow-publicliterature-FollowPublicationPromo","css-pow-application-PdfJsReader","css-pow-publicliterature-PublicationInlineReader"]});Y.use(["rg.core.pagespeed.Monitoring"],function(Y){(function(){Y.rg.createInitialWidget({"data":{"content":{"data":{"profileSmallHeader":{"data":{"profileBadge":{"data":{"fullname":"Joshua Damian Knowles","imageUrl":"https:\/\/i1.rgstatic.net\/ii\/profile.image\/AS%3A272291355426850%401441930726775_m\/Joshua_Knowles.png","profileStats":[],"profileFollowButton":null,"profileReputationScoreNumber":null,"profileUrl":"profile\/Joshua_Knowles","institution":"University of Birmingham","institutionUrl":false,"widgetId":"rgw4_56aba233d3dc4"},"id":"rgw4_56aba233d3dc4","partials":[],"templateName":"publicprofile\/stubs\/ProfileBadge.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicprofile.ProfileBadge.html?accountId=1291523","viewClass":null,"yuiModules":["css-modules-publicprofile"],"stylesheets":["modules\/publicprofile.css"],"_isYUI":true},"widgetId":"rgw3_56aba233d3dc4"},"id":"rgw3_56aba233d3dc4","partials":[],"templateName":"publicprofile\/stubs\/ProfileSmallHeader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicprofile.ProfileSmallHeader.html?publicationUid=221228406","viewClass":null,"yuiModules":["css-modules-publicprofile"],"stylesheets":["modules\/publicprofile.css"],"_isYUI":true},"publication":{"data":{"publicationUid":221228406,"title":"Multiobjective Optimization on a Budget of 250 Evaluations","journalTitle":"Lecture Notes in Computer Science","journalDetailsTooltip":{"data":{"journalTitle":"Lecture Notes in Computer Science","journalAbbrev":"Lect Notes Comput Sci","publisher":"Springer Verlag","issn":"0302-9743","impactFactor":"0.51","fiveYearImpactFactor":"0.00","citedHalfLife":"0.00","immediacyIndex":"0.00","eigenFactor":"0.00","articleInfluence":"0.00","widgetId":"rgw6_56aba233d3dc4"},"id":"rgw6_56aba233d3dc4","partials":[],"templateName":"publicliterature\/stubs\/JournalInfo.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.JournalInfo.html?issn=0302-9743","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"affiliation":false,"type":"Conference Paper","details":{"doi":"10.1007\/978-3-540-31880-4_13","conferenceInfos":"Conference: Evolutionary Multi-Criterion Optimization, Third International Conference, EMO 2005, Guanajuato, Mexico, March 9-11, 2005, Proceedings"},"source":{"sourceUrl":"http:\/\/dblp.uni-trier.de\/db\/conf\/emo\/emo2005.html#KnowlesH05","sourceName":"DBLP"},"publicationActions":null,"publicationCoins":{"data":{"tags":[{"key":"ctx_ver","value":"Z39.88-2004"},{"key":"rft_val_fmt","value":"info:ofi\/fmt:kev:mtx:journal"},{"key":"rfr_id","value":"info:sid\/researchgate.net:researchgate"},{"key":"rft_id","value":"info:doi\/10.1007\/978-3-540-31880-4_13"},{"key":"rft.atitle","value":"Multiobjective Optimization on a Budget of 250 Evaluations"},{"key":"rft.title","value":"Lecture Notes in Computer Science"},{"key":"rft.jtitle","value":"Lecture Notes in Computer Science"},{"key":"rft.volume","value":"3410"},{"key":"rft.date","value":"2005"},{"key":"rft.pages","value":"176-190"},{"key":"rft.issn","value":"0302-9743"},{"key":"rft.au","value":"Joshua D. Knowles,Evan J. Hughes"},{"key":"rft.genre","value":"inProceedings"}],"widgetId":"rgw7_56aba233d3dc4"},"id":"rgw7_56aba233d3dc4","partials":[],"templateName":"publicliterature\/stubs\/PublicationCoins.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationCoins.html?publicationUid=221228406","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationAuthors":{"data":{"publicationUid":221228406,"peopleItems":[{"data":{"authorNameOnPublication":"Joshua Damian Knowles","accountUrl":"profile\/Joshua_Knowles","accountKey":"Joshua_Knowles","imageUrl":"https:\/\/i1.rgstatic.net\/ii\/profile.image\/AS%3A272291355426850%401441930726775_m\/Joshua_Knowles.png","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Joshua Damian Knowles","profile":{"professionalInstitution":{"professionalInstitutionName":"University of Birmingham","professionalInstitutionUrl":"institution\/University_of_Birmingham"}},"professionalInstitutionName":"University of Birmingham","professionalInstitutionUrl":"institution\/University_of_Birmingham","url":"profile\/Joshua_Knowles","imageUrl":"https:\/\/i1.rgstatic.net\/ii\/profile.image\/AS%3A272291355426850%401441930726775_l\/Joshua_Knowles.png","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":false,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":true,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"accountKey":"Joshua_Knowles","hasInfoPopup":false,"hasTeaserPopup":true,"showContactAuthorButton":true,"widgetId":"rgw10_56aba233d3dc4"},"id":"rgw10_56aba233d3dc4","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAccountItem.html?entityId=1291523&enableUnfollow=0&imageSize=l&enableFollowButton=0&showContactAuthorButton=1","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"accountInstitution":"University of Birmingham","score":null,"largeTooltip":false,"useRebrandedImageStyle":null,"authorCount":2,"accountCount":2,"publicationUid":221228406,"widgetId":"rgw9_56aba233d3dc4"},"id":"rgw9_56aba233d3dc4","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAccountItem.html","templateExtensions":[],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAccountItem.html?accountId=1291523&context=pubdetail_authors_xflw&showContactAuthorButton=1&authorCount=2&accountCount=2&publicationUid=221228406","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true},{"data":{"authorNameOnPublication":"Evan Hughes","accountUrl":"profile\/Evan_Hughes","accountKey":"Evan_Hughes","imageUrl":"https:\/\/i1.rgstatic.net\/ii\/profile.image\/AS%3A276959826333699%401443043776220_m\/Evan_Hughes.png","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Evan Hughes","profile":{"professionalInstitution":{"professionalInstitutionName":"White Horse Radar Limited","professionalInstitutionUrl":false}},"professionalInstitutionName":"White Horse Radar Limited","professionalInstitutionUrl":false,"url":"profile\/Evan_Hughes","imageUrl":"https:\/\/i1.rgstatic.net\/ii\/profile.image\/AS%3A276959826333699%401443043776220_l\/Evan_Hughes.png","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":false,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":true,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"accountKey":"Evan_Hughes","hasInfoPopup":false,"hasTeaserPopup":true,"showContactAuthorButton":true,"widgetId":"rgw12_56aba233d3dc4"},"id":"rgw12_56aba233d3dc4","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAccountItem.html?entityId=3449957&enableUnfollow=0&imageSize=l&enableFollowButton=0&showContactAuthorButton=1","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"accountInstitution":"White Horse Radar Limited","score":null,"largeTooltip":false,"useRebrandedImageStyle":null,"authorCount":2,"accountCount":2,"publicationUid":221228406,"widgetId":"rgw11_56aba233d3dc4"},"id":"rgw11_56aba233d3dc4","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAccountItem.html","templateExtensions":[],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAccountItem.html?accountId=3449957&context=pubdetail_authors_xflw&showContactAuthorButton=1&authorCount=2&accountCount=2&publicationUid=221228406","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true}],"hasMore":false,"nextOffset":6,"useRebrandedImageStyle":null,"widgetId":"rgw8_56aba233d3dc4"},"id":"rgw8_56aba233d3dc4","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorList.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorList.html?publicationUid=221228406&context=pubdetail_authors_xflw&showContactAuthorButton=1","viewClass":"views.publicliterature.PublicationDetailAuthorListView","yuiModules":["rg.views.publicliterature.PublicationDetailAuthorListView"],"stylesheets":[],"_isYUI":true},"publicationAbstract":{"data":{"publicationUid":221228406,"abstract":"<noscript><\/noscript><div>In engineering and other 'real-world' applications, multiobjective opti- mization problems must frequently be tackled on a tight evaluation budget &oacute; tens or hundreds of function evaluations, rather than thousands. In this paper, we in- vestigate two algorithms that use advanced initialization and search strategies to operate better under these conditions. The rst algorithm, Bin MSOPS, uses a bi- nary search tree to divide up the decision space, and tries to sample from the largest empty regions near 't' solutions. The second algorithm, ParEGO, begins with so- lutions in a latin hypercube and updates a Gaussian processes surrogate model of the search landscape after every function evaluation, which it uses to estimate the solution of largest expected improvement. The two algorithms are tested using a benchmark suite of nine functions of two and three objectives &oacute; on a budget of only 250 function evaluations each, in total. Results indicate that the two algo- rithms search the space in very different ways and this can be used to understand performance differences. Both algorithms perform well but ParEGO comes out on top in seven of the nine test cases after 100 function evaluations, and on six after the rst 250 evaluations.<\/div>","canEdit":false,"isAdmin":false,"isArtifact":false,"showFullAbstract":false,"widgetId":"rgw13_56aba233d3dc4"},"id":"rgw13_56aba233d3dc4","partials":[],"templateName":"publicliterature\/stubs\/PublicationAbstract.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationAbstract.html?publicationUid=221228406","viewClass":"views.publicliterature.PublicationAbstractView","yuiModules":["rg.views.publicliterature.PublicationAbstractView"],"stylesheets":[],"_isYUI":true},"publicationKeywords":null,"publicationState":null,"isGuest":true,"isAdminEditingAllowed":false,"isArtifact":false,"figureListWidget":null,"previewImage":"https:\/\/i1.rgstatic.net\/publication\/221228406_Multiobjective_Optimization_on_a_Budget_of_250_Evaluations\/links\/00b495225ac557f688000000\/smallpreview.png","nativeAdDisclosure":null,"showFollowPublicationButton":false,"followPublicationPromo":{"data":{"widgetId":"rgw14_56aba233d3dc4"},"id":"rgw14_56aba233d3dc4","partials":[],"templateName":"publicliterature\/stubs\/FollowPublicationPromo.html","templateExtensions":[],"attrs":{"context":null,"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.FollowPublicationPromo.html","viewClass":null,"yuiModules":["css-pow-publicliterature-FollowPublicationPromo"],"stylesheets":["pow\/publicliterature\/FollowPublicationPromo.css"],"_isYUI":true},"widgetId":"rgw5_56aba233d3dc4"},"id":"rgw5_56aba233d3dc4","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailItem.html","templateExtensions":["generalHelpers"],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailItem.html?publicationUid=221228406&showActionBar=0&showContactAuthorButton=1&showRequestFulltextExperience=0&showNoRgAuthorsRequestFulltextExperience=0&showFollowPublicationPromo=1","viewClass":"views.publicliterature.PublicationDetailItemView","yuiModules":["rg.views.publicliterature.PublicationDetailItemView"],"stylesheets":[],"_isYUI":true},"similarPublications":{"data":{"publicationListItems":[{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":8111149,"url":"researcher\/8111149_Joshua_D_Knowles","fullname":"Joshua D. Knowles","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":6802819,"url":"researcher\/6802819_David_Corne","fullname":"David Corne","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":70005306,"url":"researcher\/70005306_Alan_P_Reynolds","fullname":"Alan P. Reynolds","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Conference Paper","publicationDate":"Jan 2009","journal":null,"showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/221228457_Noisy_Multiobjective_Optimization_on_a_Budget_of_250_Evaluations","usePlainButton":true,"publicationUid":221228457,"feedStubs":null,"hasFeedStubs":false,"impactPoints":false,"url":"publication\/221228457_Noisy_Multiobjective_Optimization_on_a_Budget_of_250_Evaluations","title":"Noisy Multiobjective Optimization on a Budget of 250 Evaluations","displayTitleAsLink":true,"authors":[{"id":8111149,"url":"researcher\/8111149_Joshua_D_Knowles","fullname":"Joshua D. Knowles","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":6802819,"url":"researcher\/6802819_David_Corne","fullname":"David Corne","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":70005306,"url":"researcher\/70005306_Alan_P_Reynolds","fullname":"Alan P. Reynolds","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["Evolutionary Multi-Criterion Optimization, 5th International Conference, EMO 2009, Nantes, France, April 7-10, 2009. Proceedings; 01\/2009"],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Conference Paper","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/221228457_Noisy_Multiobjective_Optimization_on_a_Budget_of_250_Evaluations","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/221228457_Noisy_Multiobjective_Optimization_on_a_Budget_of_250_Evaluations\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw16_56aba233d3dc4"},"id":"rgw16_56aba233d3dc4","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=221228457","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":11556719,"url":"researcher\/11556719_Wolfgang_Ponweiser","fullname":"Wolfgang Ponweiser","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":22462338,"url":"researcher\/22462338_Tobias_Wagner","fullname":"Tobias Wagner","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":78214747,"url":"researcher\/78214747_Dirk_Biermann","fullname":"Dirk Biermann","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":11556718,"url":"researcher\/11556718_Markus_Vincze","fullname":"Markus Vincze","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Conference Paper","publicationDate":"Sep 2008","journal":null,"showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/220702165_Multiobjective_Optimization_on_a_Limited_Budget_of_Evaluations_Using_Model-Assisted_mathcalS_-Metric_Selection","usePlainButton":true,"publicationUid":220702165,"feedStubs":null,"hasFeedStubs":false,"impactPoints":false,"url":"publication\/220702165_Multiobjective_Optimization_on_a_Limited_Budget_of_Evaluations_Using_Model-Assisted_mathcalS_-Metric_Selection","title":"Multiobjective Optimization on a Limited Budget of Evaluations Using Model-Assisted $\\mathcal{S}$ -Metric Selection","displayTitleAsLink":true,"authors":[{"id":11556719,"url":"researcher\/11556719_Wolfgang_Ponweiser","fullname":"Wolfgang Ponweiser","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":22462338,"url":"researcher\/22462338_Tobias_Wagner","fullname":"Tobias Wagner","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":78214747,"url":"researcher\/78214747_Dirk_Biermann","fullname":"Dirk Biermann","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":11556718,"url":"researcher\/11556718_Markus_Vincze","fullname":"Markus Vincze","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["Parallel Problem Solving from Nature - PPSN X, 10th International Conference Dortmund, Germany, September 13-17, 2008, Proceedings; 09\/2008"],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Conference Paper","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/220702165_Multiobjective_Optimization_on_a_Limited_Budget_of_Evaluations_Using_Model-Assisted_mathcalS_-Metric_Selection","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/220702165_Multiobjective_Optimization_on_a_Limited_Budget_of_Evaluations_Using_Model-Assisted_mathcalS_-Metric_Selection\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw17_56aba233d3dc4"},"id":"rgw17_56aba233d3dc4","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=220702165","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":8933238,"url":"researcher\/8933238_Maurizio_Palesi","fullname":"Maurizio Palesi","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"","journal":null,"showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/266891652_A_Brief_Introduction_to_A_Brief_Introduction_to_Multiobjective_Optimization_Multiobjective_Optimization_Techniques_Techniques","usePlainButton":true,"publicationUid":266891652,"feedStubs":null,"hasFeedStubs":false,"impactPoints":false,"url":"publication\/266891652_A_Brief_Introduction_to_A_Brief_Introduction_to_Multiobjective_Optimization_Multiobjective_Optimization_Techniques_Techniques","title":"A Brief Introduction to A Brief Introduction to Multiobjective Optimization Multiobjective Optimization Techniques Techniques","displayTitleAsLink":true,"authors":[{"id":8933238,"url":"researcher\/8933238_Maurizio_Palesi","fullname":"Maurizio Palesi","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":[],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/266891652_A_Brief_Introduction_to_A_Brief_Introduction_to_Multiobjective_Optimization_Multiobjective_Optimization_Techniques_Techniques","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/266891652_A_Brief_Introduction_to_A_Brief_Introduction_to_Multiobjective_Optimization_Multiobjective_Optimization_Techniques_Techniques\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw18_56aba233d3dc4"},"id":"rgw18_56aba233d3dc4","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=266891652","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"viewClass":"sidebar","widgetId":"rgw15_56aba233d3dc4"},"id":"rgw15_56aba233d3dc4","partials":[],"templateName":"publicliterature\/stubs\/SimilarPublications.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.SimilarPublications.html?referencePublicationId=221228406&view=sidebar","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationFulltextPreview":null,"publicationResourcesFulltext":{"data":{"publicationUid":221228406,"publicationResourceList":{"data":{"publicationResourceItems":[{"data":{"publicationUid":221228406,"publicationType":"inProceedings","linkId":"00b495225ac557f688000000","fileName":"00b495225ac557f688000000.pdf","fileUrl":"profile\/Evan_Hughes\/publication\/221228406_Multiobjective_Optimization_on_a_Budget_of_250_Evaluations\/links\/00b495225ac557f688000000.pdf","name":"Evan Hughes","nameUrl":"profile\/Evan_Hughes","canRemove":false,"fileIcon":"ico-pub","canPreview":true,"hasPublisherLink":null,"hasMetaData":true,"hide":false,"fulltext":"ico-pub","origin":"publication_list","isLastLink":false,"isUserLink":true,"uploadDate":"Jan 21, 2016","fileSize":"277.11 KB","widgetId":"rgw21_56aba233d3dc4"},"id":"rgw21_56aba233d3dc4","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceItem.html","templateExtensions":["generalHelpers"],"attrs":{"fileRequiredPublicationTypes":["code","coverPage","experimentFindings","method","negativeResults","presentation","rawData","researchProposal","workingPaper","artifact","dataset"]},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceItem.html?publicationUid=221228406&linkId=00b495225ac557f688000000&hide=0&disableJavascript=disableJavascript&useAlternativeTemplate=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"publicationUid":221228406,"publicationType":"inProceedings","linkId":"0fe1288b0cf29ea7bb934db1","fileName":"Multiobjective Optimization on a Budget of 250 Evaluations","fileUrl":"http:\/\/citeseerx.ist.psu.edu\/viewdoc\/download?doi=10.1.1.106.3062&amp;rep=rep1&amp;type=pdf","name":"citeseerx.ist.psu.edu","nameUrl":"http:\/\/citeseerx.ist.psu.edu\/viewdoc\/download?doi=10.1.1.106.3062&amp;rep=rep1&amp;type=pdf","canRemove":false,"fileIcon":"ico-pub","canPreview":true,"hasPublisherLink":null,"hasMetaData":true,"hide":false,"fulltext":"ico-pub","origin":"publication_list","isLastLink":false,"isUserLink":false,"widgetId":"rgw22_56aba233d3dc4"},"id":"rgw22_56aba233d3dc4","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceItem.html","templateExtensions":["generalHelpers"],"attrs":{"fileRequiredPublicationTypes":["code","coverPage","experimentFindings","method","negativeResults","presentation","rawData","researchProposal","workingPaper","artifact","dataset"]},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceItem.html?publicationUid=221228406&linkId=0fe1288b0cf29ea7bb934db1&hide=0&disableJavascript=disableJavascript&useAlternativeTemplate=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"widgetId":"rgw20_56aba233d3dc4"},"id":"rgw20_56aba233d3dc4","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceList.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceList.html?publicationUid=221228406&limit=3&disableJavascript=disableJavascript&type=fulltextFile","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"resourceCount":2,"hidden":false,"showMore":false,"fulltext":true,"publicationDownloadCount":{"data":{"value":64,"valueFormatted":"64","widgetId":"rgw23_56aba233d3dc4"},"id":"rgw23_56aba233d3dc4","partials":[],"templateName":"publicliterature\/stubs\/PublicationDownloadCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDownloadCount.html?publicationUid=221228406","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw19_56aba233d3dc4"},"id":"rgw19_56aba233d3dc4","partials":[],"templateName":"publicliterature\/stubs\/PublicationResources.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResources.html?publicationUid=221228406&type=fulltextFile&disableJavascript=1","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationResourcesAttachments":{"data":{"publicationUid":221228406,"publicationResourceList":{"data":{"publicationResourceItems":[],"widgetId":"rgw25_56aba233d3dc4"},"id":"rgw25_56aba233d3dc4","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceList.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceList.html?publicationUid=221228406&limit=3&disableJavascript=disableJavascript&type=attachmentFile","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"resourceCount":0,"hidden":true,"showMore":false,"fulltext":false,"publicationDownloadCount":{"data":{"value":64,"valueFormatted":"64","widgetId":"rgw26_56aba233d3dc4"},"id":"rgw26_56aba233d3dc4","partials":[],"templateName":"publicliterature\/stubs\/PublicationDownloadCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDownloadCount.html?publicationUid=221228406","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw24_56aba233d3dc4"},"id":"rgw24_56aba233d3dc4","partials":[],"templateName":"publicliterature\/stubs\/PublicationResources.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResources.html?publicationUid=221228406&type=attachmentFile","viewClass":"views.publicliterature.PublicationResourcesView","yuiModules":["rg.views.publicliterature.PublicationResourcesView"],"stylesheets":[],"_isYUI":true},"publicationText":{"data":{"hide":false,"pages":[{"page":1,"text":"Multiobjective Optimization on a Budget of 250\nEvaluations\nJoshua Knowles\n?\nand Evan J. Hughes\n?\n?\nSchool of Chemistry, University of Manchester, Faraday Building, Sackville Street, PO Box 88,\nManchester M60 1QD, UK. Email:j.knowles@manchester.ac.uk\nCranfield University, Shrivenham, Swindon SN6 8LA, UK\n?\nAbstract. In engineering and other \u2018real-world\u2019 applications, multiobjective opti-\nmization problems must frequently be tackled on a tight evaluation budget \u2014 tens\nor hundreds of function evaluations, rather than thousands. In this paper, we in-\nvestigate two algorithms that use advanced initialization and search strategies to\noperate better under these conditions. The first algorithm, Bin MSOPS, uses a bi-\nnary search tree to divide up the decision space, and triesto sample from the largest\nempty regions near \u2018fit\u2019 solutions. The second algorithm, ParEGO, begins with so-\nlutions in a latin hypercube and updates a Gaussian processes surrogate model of\nthe search landscape after every function evaluation, which it uses to estimate the\nsolution of largest expected improvement. The two algorithms are tested using a\nbenchmark suite of nine functions of two and three objectives \u2014 on a budget of\nonly 250 function evaluations each, in total. Results indicate that the two algo-\nrithms search the space in very different ways and this can be used to understand\nperformance differences. Both algorithms perform well but ParEGO comes out on\ntop in seven of the nine test cases after 100 function evaluations, and on six after\nthe first 250 evaluations.\nKeywords: multiobjective optimization, expensive black-box functions, ParEGO,\nDACE, Bin MSOPS, landscape approximation, response surfaces, test suites\n1Introduction\nThe vast majority of research effort in developing modern multiobjective evolutionary\nalgorithms (MOEAs) has concentrated on improving algorithm performance and effi-\nciency on runs, typically, of ten thousand function evaluations or more. In this paper, we\nconsidermultiobjectiveproblemswhere a \u2018budget\u2019of at most 250 evaluationsis imposed\nbecause of the expensive nature of evaluating candidate solutions. More specifically, we\nare interested in problems where most or all of the features described in Fig.1 are true.\nFeatures 1\u20134 limit the numbers of function evaluations possible, while features 5\u20138\nmake it reasonable to apply global search techniques rather than either random search or\nhillclimbing. Problems exhibiting these features include various combinatorial biochem-\nistry and materials science applications [6,26], as well as instrument set-up optimization\nin analytical chemistry [20,24]. In [20], a standard MOEA, PESA-II, was successfully\nused to substantially improve the settings of a GC-MS spectrometer, using just 180 eval-\nuations. However, it is clear that given such a restricted number of evaluations, and no"},{"page":2,"text":"2\n1. the time taken to perform one evaluation is of the order of minutes or hours,\n2. only one evaluation can be performed at one time (no parallelism is possible),\n3. the total number of evaluations to be performed is limited by financial considerations,\n4. no realistic simulator or other method of approximating the full evaluation is readily\navailable,\n5. noise is low (repeated evaluations yield very similar results),\n6. the overall gains in quality (or reductions in cost) that can be achieved are high,\n7. the search landscape is multimodal but not highly rugged,\n8. the dimensionality of the search space is low-to-medium,\n9. the problem has multiple, possibly incommensurable, objectives.\nFig.1. Features exhibited by problems of interest\nparticularrestriction on computationaloverhead(since each experimentrequires 20 min-\nutes), a search strategy that more carefully considers each evaluation would be more\nappropriate.\nScanning the optimization literature reveals that a sparse but varied array of different\ntechniques (that were proposed or could be used) for economizing on evaluations in\nmultiobjective optimization has already been examined. One strand in this focuses on\nthe use of neural networks for modeling the search landscape during optimization, in\norder to replace some real function evaluations with approximated ones [19,8,9], or to\nreplacestandardvariationoperatorswithadaptiveones[1].Thesimplerconceptoffitness\ninheritance has also been investigated in multiobjective optimization to economize on\nfunction evaluations [2,5]. And a third strand is to use Bayesian network and\/or other\nprobabilistic model-building algorithms in a multiobjective scenario, e.g. [17].\nHowever, while the above methods may offer some performance gains over stan-\ndard MOEAs when function evaluations are expensive, not one of the studies above\nhas demonstrated a significant performance advantage within the challenging evalua-\ntion budget we are interested in here. In this paper, we present and compare two recently\nproposed algorithms that take very different approaches to this challenge. The first algo-\nrithm, Binary-MSOPS, which is summarized below, is based on two separate pieces of\nworkpreviouslypublishedbythesecondauthor[11,12].Thesecondalgorithm,ParEGO,\nwas first described in a recent technical report [16], and is described here again in some\ndetail.We evaluatethese algorithmsovera rangeofproblemsand,unlikein otherstudies,\nwe focus explicitly on the first 250 evaluations only.\nThe rest of the paper is organized as follows. Sections 2 and 3 describe the two\nalgorithms, while 4, 5 and 6 detail the test functions, performance assessment methods\nand parameter settings of the algorithms, respectively. Section 7 presents results and\nsection 8 discusses findings and concludes.\n2Binary-MSOPS\nThe Binary-MSOPS algorithm is based primarily on the Binary Search Algorithm [11],\nsummarized below. This method, which can be combined with almost any fitness as-"},{"page":3,"text":"3\n1\n2\n3\n4\n5\n6\n7\nFig.2. The Binary Search process illustrated in a two dimensional decision space, with the first\nseven search points shown. The box around the third point indicates a small distance around a \u2018fit\u2019\npoint, and how this intersects with several empty regions\nsignment scheme, attempts to improve decision space sampling to ensure that promis-\ning regions are not missed or over-sampled in the early stages of the search, and to ex-\nplicitly balance exploitation and exploration. Combining this with the MSOPS ranking\nmethod [12] \u2014 a computationally efficient means of assigning fitness in multiobjective\noptimization,based on target vectors \u2014, Binary-MSOPS is both efficient and frugalwith\nevaluations.\n2.1Binary Search Algorithm\nThe overall strategy of Bin MSOPS uses a binary search tree [11] to divide the decision\nspace into empty regions, allowing the largest empty region to be approximated. The\nsearch tree is constructed as shown in Fig. 2 by generating a point at random within a\nchosen hypercube, then dividing the hypercube along the dimension that yields the most\n\u2018cube-like\u2019 subspaces.\nThe basic algorithm for constructing the binary search tree (and generating new so-\nlutions) works by repeatedly choosing an exploration or exploitation step:\nExploration: Next point is generated at random within the largest empty region (i.e.\nglobal search),\nExploitation: Next point is generated within the largest empty region that is within a\nsmall distance of a selected good point (i.e. local search),\nwhere the choice is random but biased by a parameter specifying the exploration\/ex-\nploitation ratio.\nThe identification of a local region for exploitation is illustrated in Fig. 2. A small\noffset distanceis used to generate a hypercube of interest about the chosen point\n(chosen with tournament selection). The small hypercube is placed around the point of\ninterest simply to provide an efficient means of identifying large neighbouring regions.\nA new point is then generated at random using a normal distribution in the largest region\nthat intersects the hypercube.\n???"},{"page":4,"text":"4\nAt each iteration, the tree search to find the largest empty region is at worst\nwhere is the number of evaluation points so far and\nTreepruningcanleadto\nThus a computational explosion is avoided.\n???\n?????,\n??\nis the number of dimensions.\n???\n???????\n?\n?????performanceforexploitation,andat worst\n???\n?????.\n2.2 Population ranking by MSOPS\nIn order to decide which are \u2018good\u2019 points, the entire population is ranked, and a tour-\nnament between a random subset of the population, based on rank value, decides on the\nnext solution to update. In order to control the computational complexity, a non-Pareto\nranking approach has been applied, that like ParEGO (see next section), is also capable\nof handling many-objective problems. For this, the Multiple Single Objective Sampling\n(MSOPS) [12], with\ntime complexity, has been used.\nThe concept of MSOPS is to generate a set of\nperformance of every individual in the population, of size\nbased on a conventional aggregation method. As aggregation methods (e.g. weighted\nmin-max,\neach of the performance metrics is fast.\nThus each of the\nmembers of the population has a set of\nhow well the population member satisfied the range of target conditions. The scores are\nheld in a score matrix,\ncorresponds to one target vector (each column containing\nthe best performing population member on the corresponding target vector being given\na rank of 1, and the worst a rank of. The rank values are stored in a matrix\nrow of the rank matrixmay now be sorted, with the ranks for each population member\nplaced in ascending order. Thematrix now holds in the first column the highest rank\nachievedfor each populationmemberacross the set of target vectors.The second column\nwill hold the second highest rank achieved etc. Thus the matrix\nthe population, with the most fit being the solution that achieved the most scores that\nwere ranked 1, etc.\nThe flexibility of the approach is such that the target vectors can be arbitrary, either\ngenerated using some structure, or generated at random within certain limits. As the\nranking method employed is based on the number of target vectors that are satisfied the\nbest, a solution at the edge of the objective space will often satisfy vectors that cannot be\nattained. Thus the focus of the optimization is naturally drawn to interesting regions of\nsurface such as the boundary of the optimization surface and discontinuities.\n???\n???????\n?\n?????\n?\ntarget vectors, and evaluate the\n, for every target vector,\n?\n? -constraint,goal attainment etc.) are very simple to process, the calculation of\n?\n?\nscores that indicate\n? , which has dimensions\n???\n? . Each column of the matrix\nentries) and is ranked, with\n?\n?\n?\n? . Each\n?\n?\n?\nmay be used to rank\n3 ParEGO: landscape modeling using Gaussian processes\nLearning a cost landscape from a set of solution\/cost pairs is variously called surro-\ngate, approximate or meta- modeling in the literature [13]. In design engineering, meta-\nmodelingis usuallyknownas theresponsesurfacemethod[18],andinvolvesfittinga low\norder polynomial via some form of least squares regression. A closely related approach,\nderiving from geology, is Kriging, whereby Gaussian process models are parameterized\nby maximum likelihood estimation. A particular example of this is known as the Design"},{"page":5,"text":"5\nand Analysis of Computer Experiments (DACE) model [22], which forms the basis of\nthe EGO search algorithm [14]. EGO has been designed specifically for optimization on\na very restricted evaluation budget: e.g. in [14], four low-dimensional multimodal test\nfunctions are optimized to within 1% of optimal in the order of 100 function evaluations.\nThe EGO algorithm begins by first generating a number of solutions in a latin hy-\npercube, and by then finding the maximum likelihood DACE model that best explains\nthese solutions (making use of some suitable optimization algorithm). To generate a new\nsolution to evaluate, EGO searches for the solution that maximizes what Jones et al [14]\ncall \u201cthe expected improvement\u201d \u2014 the expected value of that part of the standard er-\nror curve that lies below the best cost sampled so far. This effectively means that EGO\nweighs up both the predicted value of solutions, and the error in this prediction, in order\nto findthe onethat has the greatestpotentialto improvetheminimumcost.EGO does not\njust choose the solution that the model predicts would minimize the cost. Rather, it auto-\nmatically balances exploitation and exploration: where a solution has low predicted cost\nand low error, it may not be as desirable as a solution whose predicted cost is higher but\nwhose associated error of prediction is also higher. Once a new solution has been chosen\nand evaluated (using the true, expensive cost function),the DACE model is updated with\nthis new information, and the next solution is chosen using this updated model.\nThe EGO algorithmcouldbe extendedforuse with multiobjectiveoptimizationprob-\nlems in a number of different ways. One simple approach recently proposed by the first\nauthor in [16] (and that has the advantage of scaling to many objectives), converts the\ndifferentcost valuesofa solutionintoa singlecostvia aparameterizedscalarizingweight\nvector. By choosing a different (parameterization of the) weight vector at each iteration\nof the search, an approximation to the whole Pareto front can be gradually built up. This\nmultiobjective extension of EGO is called ParEGO.\nParEGO begins by normalizing the\nestimated) limits of the cost space, so that each cost function lies in the range [0,1].\nThen, at each iteration of the algorithm, a weight vector\nfrom the set of evenly distributed vectors defined by:\n?\n? cost functions with respect to the known (or\n? is drawn uniformly at random\n? ?\"!\n?\n?\n??#\n?%$\n#\n?&$(')'('*$\n#,+\n?.-0\/\n+\n132\n?\n#\n1\n?547698;:\ndetermines how many vectors there are in\nis then computed using the augmented\n$\n#\n1\n?\n?=<0>\n$\n?@?BA\n'C'\n>;D\n$\n(1)\nwith\ntotal [10]. The scalar cost of a solution\nTchebycheff function [23]:\n-\n?\n-\n?FEHGJI\n+LK\n?\n+?K\n?BM , so that the choice of\n>\nN0OP?RQ\n?\nN%OS?TQ\n?\n?VUXW?Y\n1\n?=#\n1?Z\nN\n1\n?TQ\n?3?\\[^]`_\n1\n#\n1?Z\nN\n1\n?TQ\n?\n$\n:\n?\n4\n'a'\n?\n(2)\nwhere\nall minima are proper Pareto optima, and which we set to\npreviously visited solutions are computed and, using all or a selection of these, a DACE\nmodel of the landscape is constructed by maximum likelihood. The solution that maxi-\nmizes the expected improvement with respect to this DACE model is determined. This\nbecomes the next point, and is evaluated on the real, expensive cost function, completing\none iteration of ParEGO.\nN\n1istherawcostvalueonobjective\n:\nand\n]\nisasmallpositivevalue,whichensures\nA\n'\nA&b. The scalar costs of all"},{"page":6,"text":"6\nAlgorithm 1 ParEGO pseudocode\n1: procedure PAREGO(\n2:\n3:\nfor each\n4:\n5:\nend for\n6:\nwhile not finished do\n7:\nNEWLAMBDA\n8:\n9:\n10:\n11:\n12:\n13:\nend while\n14: end procedure\nc ,\nd ,\ne ,\nf )\ngLhji?hlk?m;n\nLATINHYPERCUBE\ns)std?uvs do\nopd0q\n\/* Initialize using procedure: line 15 *\/\nr in\ns to\nw*hji3hxkrpmjn\nEVALUATE\nopgLhji?hlkrTmTy?c;q\n\/* See line 36 *\/\nzBnoTe{y|f(q\n\/* See line 19 *\/\n\/* See line 22 *\/\n\/* See line 28 *\/\n}~i(d?*\u0080{n\nDACE\nEVOLALG\nopgLhji?hlk?mTyJw*hji?hlk?mTy?z\\q\nEVALUATE\ngj\u0081\u0082\u0084\u0083\u0085nop}~i(d?(\u0080RyHgLhji?hlkRm\u0086q\ngLhji?hlk?mjn\u0087gLh\u0088i3hlkRm0\u0089?\u008a\u0084gj\u0081\u0082\u0084\u0083.\u008b\nw0\u0081\u0082\u0084\u0083\u0085n opgj\u0081\u0082\u0084\u0083?y?c;q\nw(h\u0088i3hlkRm;n\u008cw*hji3hxk?m0\u0089~\u008a*w?\u0081\u0082*\u0083`\u008b\n15: procedure LATINHYPERCUBE(\n16:divide each dimension of search space into\n17:\nreturn\n18: end procedure\nd )\ns?s\u008dd\u008eu\u008fs \u2018rows\u2019 of equal width\ns?s\u008dd\u008eu\u0090s vectors\ng such that no two share the same \u2018row\u2019 in any dimension\n19: procedure NEWLAMBDA(\n20:\nreturn a\namongst all those defined by equation 1\n21: end procedure\ne ,\nf )\ne -dimensional scalarizing weight vector chosen uniformly at random from\n22: procedure DACE(\n23:compute the scalar fitness\n24:choose a subset of the population based on the computed scalar fitness values\n25:maximize the likelihood of the DACE model for the chosen population subset\n26:\nreturn the parameters of the maximum likelihood DACE model\n27: end procedure\ngLh\u0088i3hlkpm ,\nw(h\u0088i3hlkRm ,\nz )\nc)\u0091 of every cost vector in\nw(h\u0088i3hlkRm , using equation 2\n28: procedure EVOLALG(\n29:initializeatemporary population ofsolution vectors, someasmutants of\npurely randomly\n30:\nwhile set number of evaluations not exceeded do\n31:evaluate the expected improvement of solutions using the model\n32: select, recombine and mutate to form new population\n33:\nend while\n34:\nreturn best evolved solution\n35: end procedure\n}~i(d?(\u0080 ,\ngLhji?hlkRm )\ng?hji3hxk?m andothers\n36: procedure EVALUATE(\n37: call the expensive evaluation function\n38:\nreturn true cost vector\n39: end procedure\ng ,\nc )\nc with the solution vector\ng\nw of solution\ng"},{"page":7,"text":"7\nPopulation size: 20 solutions\nPopulation update: steady state (one offspring produced per generation, from either a\ncrossover or cloning event, followed by a mutation)\nGenerations\/evaluations: 10,000 evaluations\nReproductive selection: binary tournament without replacement\nCrossover: simulated binary crossover [3] with probability 0.2, producing one offspring\nMutation: decision value shifted by\nfrom\nprobability, is\nReplacement: offspring replaces (first) parent if it is better, else it is discarded\nInitialization: 5 solutions are mutantsaof the 5 best solutions evaluated on the real fitness\nfunction under the prevailing\nvector; the remaining 15 solutions are generated in a\nlatin hypercube in decision space\n\u0092\u008es\u0084\u0093?st\u0094?\u00940\u0095\u0096\u0097\u0095\u0098 , where\n\u0096 is drawn uniformly at random\noT\u0094?\u0095\u0094?\u0094?\u0094?s?y*s*q ,\n\u0098 is the range of the decision variable, and\nh{\u0099 , the per-gene mutation\ns*\u0093*d .\nz\naThe mutation is carried out as described above except that mutants are checked to ensure\nthey are different than parents.\nFig.3. The EA used in ParEGO to search for the \u2018best\u2019 next solution\nPseudocodefor the entire ParEGO algorithmis givenin Algorithm1. The Nelder and\nMeads downhill simplex algorithm is used (with 20 restarts) to maximize the likelihood\nof the DACE model (line 25 of Algorithm 1). The evolutionary algorithm used within\nParEGO to search for the solution that maximizes the expected improvement (line 28) is\nimplemented as detailed in Fig. 3.\nIn practice, on a very expensive cost function, all solutions previously evaluated\nshould be used to update the DACE model, at every iteration. However, to save com-\nputational overhead in our experiments (because of the need to do 21 runs on a large\nnumber of functions to collect performance data), we used a simple, heuristic method\nof choosing a subset of the solutions evaluated to update the model, as follows: At each\niteration: (i) if the iteration number\nuated so far, are used to update the model; and (ii) if\nsolutions is used, where the first half of them are the best\ning scalarizing vector and the other half are selected at random without replacement.\nFurther details of the parameter settings used in ParEGO are given in Section 6.\n\u009aH\u009b|\u009c?\u009d is less than 25, all\n404\n??\u009e\nsolutions under the prevail-\n4\n[\n\u009aH\u009b|\u009c)\u009d solutions eval-\n\u009aH\u009b|\u009c?\u009d\u00a0\u009fV\u00a1\nb\na subset of\n404\n?\u008e\u009e\n4\n[\n\u00a1\nb\n:\n?\n4Test function suite\n4.1Notes on the selection of functions\nA number of good attempts at designing test function suites and\/or general schemes for\ntest function generation have been proposed in the multiobjective optimization litera-\nture, of which those described in [4,21,25] are some of the best. We make a selection\nof nine test functions, borrowing from these, and adapting some of them slightly for\nour purposes. Overall, our suite contains functions from two to eight decision variables;\nfunctions with a very low density of solutions at the Pareto front; functions with locally"},{"page":8,"text":"8\nKNO1 [16] Features: Two decision variables; two objectives; Fifteen locally optimal\nPareto fronts.\nOKA1 [21] Features: Two decision variables; two objectives; Pareto optima lie on curve;\ndensity of solutions low at PF.\nOKA2 [21] Features: Three decision variables; two objectives; Pareto optima lie on spiral-\nshaped curve; density of solutions very low at PF.\nVLMOP2 [25] Features: Two decision variables; two objectives; concave PF.\nVLMOP3 [25] Features: Two decision variables; three objectives; disconnected Pareto op-\ntimal set and PF is a curve \u2018following a convoluted path through objective space\u2019.\nDTLZ1a, adapted from [4] Features: Six decision variables; two objectives; local optima\non the way to the PF.\nDTLZ2a and DTLZ4a, adapted from [4] Features: Eight decision variables; three objec-\ntives; DTLZ4abiasesthedensity distributionof solutions toward the\nplanes.\nDTLZ7a, adapted from [4] Features: Eight decision variables, three objectives; four dis-\nconnected regions in the Pareto front (in objective space).\nc)\u00a2%u?c\n?and\nc\n?\nu.c\n?\nFig.4. Summary of the nine test functions\noptimal Pareto fronts; functions where the Pareto set follows a complicated curve in the\ndecision space; functions where the Pareto front is disconnected in objective space; and\nfunctions where the density of points parallel to the Pareto front is non-uniformly dis-\ntributed. There is thus a good deal of variety in the difficulties that they pose. We have\nnonetheless been restrictive in some particular aspects: all functions are unconstrained\nand while difficult, are not overly high-dimensional (in decision space), and have a rea-\nsonable, rather than pathological degree of ruggedness. And, we have kept to functions\nof two and three objectives only. These restrictions accord with our description (in Sec-\ntion 1) of certain kinds of expensive engineering\/scientific problem, where we hope to\nobtain good results in a very small number of function evaluations. We do not reproduce\nthe equations of all functions here but they can be found in [16] and are summarized in\nFig. 4.\n5 Selected performance analysis techniques\nIn accordance with the analyses presented in [27], we choose the hypervolume indicator\nto assess the approximation sets obtained by Bin MSOPS and ParEGO. We supplement\nthese tabulated values and significance levels with a visual representation based on sum-\nmary attainment surfaces, for some of the 2-objective functions.\n5.1Hypervolume indicator\nThe hypervolume indicator assesses the size (hypervolume or Lebesgue integral) of the\nregion weakly dominated by an approximations set, thus larger values indicate better\nnondominated sets. It is \u201cthe only unary indicator we are aware of that is capable of"},{"page":9,"text":"9\n-10\n-8\n-6\n-4\n-2\n 0\n 2\n-10-8-6-4-2 0 2\nminimize f2\nminimize f1\nExact attainment surfaces - 2d\nbest\nmedian\nworst\n1\n2\n3\n4\n5\nFig.5. Five sets of nondominated points and the best, median and worst attainment surfaces that\nthey define. The interpretation of the median attainment surface is that, for every point on it (in-\ndependently), a point (weakly) dominating this was obtained in at least\nsets. Similarly, the worst attainment surface indicates the level achieved in\nbest attainment surface indicates the level achieved by the aggregation of all sets. In this study, the\nbest attainment surface is irrelevant and is not included in plotted results\n\u00a3)\u0094?\u00a4\nof the nondominated\nof the sets. The\ns\u0084\u0094)\u0094L\u00a4\ndetecting that\nare two approximation sets.\nThe weakly dominated region being measured must be bounded from above in some\nway, and for this some point\nin the sample set. In order to choose a boundingpoint for application of the hypervolume\nindicator, we use the following method. First, the collection of nondominated point sets\nfrom all runs of both algorithms (on the relevant function) are aggregated into a single\nsuperset. Then, the ideal and the anti-ideal point of this superset are found.The bounding\npoint is then the anti-ideal point shifted by\n\u00a5\nis not worse than\n\u00a6\nfor all pairs\n\u00a5V\u00a7\n[better than]\n\u00a6 \u201d [27], where\n\u00a5\nand\n\u00a6\n\u00a8 is chosen, which must be itself dominated by every point\n\u00a9 times the range, in each objective:\n\u00aa\n?\n?=\u00a8\n?\n$\n\u00a8\n?\n$)'(')'*$\n\u00a8\n+\n?\n$\nwith\n\u00a8\n1\n?VUXW?Y\n1\n[\n\u00a9;?T\u00abB\u00ac&Q\n1\n\u009e\nU?\u00ada\u00ae\n1\n?\n$\n:\n?\n4\n'C'\n?\n$\nwhere\nobjective, found within the superset. We use\nFor the analysis of multiple runs, we compute the hypervolume indicator of each\nindividual run, and report the mean and the standard deviation of these. Since the dis-\ntribution of Bin MSOPS\u2019 and ParEGO\u2019s results are not necessarily normal, we use the\nMann-Whitneyrank-sum test to indicate if there is a statistically significant difference in\nthe position of the two distributions.\nU?W?Y\n1and\nU?\u00adC\u00ae\n1are the maximum and minimum value, respectively, on the\n:th\n\u00a9\n?\nA\n'\nA\n4\nhere.\n5.2Median and worst summary attainment surface plots\nA summary attainment surface is a visual way of summarizing a number of runs of a\nmultiobjective optimizer, based on the notion of an attainment surface [7]. For illustra-"},{"page":10,"text":"10\nTable 1. ParEGO parameter settings, where\nd is the number of decision variables\nParameter\nInitial population in latin hypercube\nTotal maximum evaluations\nNumber of scalarizing vectors\nScalarizing function\nInternal GA evals per iteration\nCrossover probability\nReal-value mutation probability\nReal-value SBX parameter\nReal-value mutation parameter\nsetting\ns?s\u008dd\u008eu\u0090s\n250\n11 (for 2 objectives), 15 (for 3 objectives)\naugmented Tchebycheff\n\u00af(\u0094?\u0094\\\u0094?\u0094)\u0094\n10\n50\n0.2\ns*\u0093(d\ntion, we plot five sets of nondominated points and their exact sample median, best and\nworst, summary attainment surfaces in Fig. 5.\nFor the two-objective problems in this paper, we give the median and worst attain-\nment surfaces only of ParEGO and of Bin MSOPS on the same plot, with ParEGO\u2019s two\nsurfaces shown in solid and Bin MSOPS\u2019s two surfaces shown with dashed lines. We do\nnot give plots for the three-objective problems here, because of space restrictions.\n6Experimental details\nTo evaluate Bin MSOPS and ParEGO on the test suite, each algorithm is run 21 times,\nand all solutions visited are stored. The nondominated sets achieved after a particular\nnumberoffunctionevaluationscanthenbedeterminedandusedtoestimateperformance.\n6.1Bin MSOPS parameter settings\nWeighted Min-Max was used as the aggregation method within the MSOPS ranking\nalgorithm. The weighted min-max scoreof\n#,\u00b0 is the weight for the\n>\n? objectives is calculated using (3),where\n\u009a th objective value,\nN0\u00b0 .\n>\n?\n+\nUXW%Y\n\u00b0\n2\n?\n??#\n\u00b0\nN\n\u00b0\n?\n$\n(3)\nA set of objective weights constitutes a single target vector.\nThirty target vectors were used, spaced so that the angle to their nearest neighbour\nwas constant across the set of 30. Thus in trials with 3 objectives, the set of weight\nvectors, although evenly spaced, was non-unique.\nTo choose a \u2018good\u2019 point, a tournament size with a maximum of 20, without replace-\nment, was used throughout all the experiments.\nA search interval (see figure 2) of\non the coverage area of allowable cells of\nvariables in the range [0,1]). If the cells near to the chosen \u2018good\u2019 point were below the\ncell area limit, a search was performed to find the nearest cell that is large enough to\n?\n?\n?\nA\n'\nA\n\u00a1 was used and a lower limit was set\n(in normalized decision space with all\nA\n'\nA0A\u0088b\n?"},{"page":11,"text":"11\nsplit. The lower limit promotesa wider search aroundinteresting points, but does prevent\na tight-formation search occurring, which may be detrimental in problems with a very\nlow density at the Pareto set (e.g. test function OKA1).\nInitially, the algorithm performed a global exploration search for approximately the\nfirst 20 points, then global exploration was performed 6% of the time.\n6.2 ParEGO parameter settings\nThe full set of parameter settings used in all runs of ParEGO are given in Table 1. These\nwere determined empirically from a few exploratory trials.\n7 Results\nTables 2 and 3 present the results of applyingthe hypervolumeindicator to the 21 runs of\nBin MSOPS and ParEGO after, respectively, 100 and 250 function evaluations. Because\nit is notpossibleto usethese valuesincomparisonswith otheralgorithms,we makeavail-\nable the raw results at [15]. Note also that the appearance of the hypervolumedecreasing\nfrom 100 to 250 evaluations on some problems is only due to the choice of a different\nbound point (see above).\nFig. 5 and 6 visualize the median and worst summary attainment surfaces of the 21\nruns of both algorithms on selected 2-objective problems. Fig. 7 and 8 show the deci-\nsion space points visited by the first run of the two algorithms on KNO1 and OKA1,\nrespectively.\nFrom these results a number of observations can be made:\n\u2013 ParEGO is statistically significantly better than Bin MSOPS on seven of the nine\nfunctions at 100 evaluations, and on six of the nine functions after 250 evaluations,\nunderthe hypervolumeindicator.(cf. [16],where ParEGO was better than a standard\nsetup of NSGA-II with population size 20 on all test functions under two different\nindicators).\n\u2013 The standard deviations of the two algorithms are generally comparable, with a\nlarge difference evident on only one problem, DTLZ1a, at 250 evaluations (2 or-\nders of magnitudeless deviationfor ParEGO). Results reportedin [16] indicatedthat\nParEGO\u2019s standard deviationswere frequentlyone or two ordersof magnitudelower\nthan NSGA-II\u2019s on these problems, so the results here show that Bin MSOPS is per-\nformingcomparativelyrobustly\u2014 an important featureon problemswhere only one\nrun may be possible.\n\u2013 Fig. 5 and 6 indicate that ParEGO run for 250 evaluations is superior to a random\nsearch of 1000 evaluations on the difficult OKA1 and OKA2 functions, where there\nis a low density of solutions near the Pareto front. On OKA1, ParEGO\u2019s median\nattainment surface dominates all 1000 randomly generated points and on OKA2,\neven ParEGO\u2019s worst attainment surface does.\n\u2013 Fig. 7 and 8 demonstrate that the search patterns of Bin MSOPS and ParEGO are\nvery different, and generally complementary. It is clear that while Bin MSOPS at-\ntemptstogetanevencoverageofthesearchspace,bothgloballyandlocally,ParEGO"},{"page":12,"text":"12\n 0\n 5\n 10\n 15\n 20\n 0  2 4  6 8\nf1\n 10 12 14 16\nf2\nKNO1: BIN_MSOPS vs. ParEGO\nBIN_MSOPS: 250 evals\nParEGO: 250 evals\nPareto front\n 0\n 0.5\n 1\n 1.5\n 2\n 2.5\n 3\n 3.5\n 4\n 4.5\n 5\n 0 1 2  3 4 5 6\nf2\nf1\nOKA1: Bin_MSOPS vs. ParEGO\nBIN_MSOPS: 250 evals\nParEGO: 250 evals\nPareto front\nFig.6. Attainment surface plot on the KNO1 function after 250 function evaluations (left), and\nattainment surface plot with PF and 1000 random search points also shown on the OKA1 function\nafter 250 function evaluations (right)\n-1\n 0\n 1\n 2\n 3\n 4\n 5\n-4-3-2-1 0\nf1\n 1 2 3 4\nf2\nOKA2: Bin_MSOPS vs. ParEGO\nBIN_MSOPS: 250 evals\nParEGO: 250 evals\nPF\n 0\n 0.2\n 0.4\n 0.6\n 0.8\n 1\n 1.2\n 0 0.2 0.4 0.6\nf1\n 0.8  1 1.2\nf2\nVLMOP2: BIN_MSOPS vs. ParEGO\nBIN_MSOPS: 250 evals\nParEGO: 250 evals\nFig.7. Attainment surface plot on OKA2 after 250 function evaluations, with the true PF and 1000\nrandom search points also shown (left),and attainment surface plot on VLMOP2 after 250 function\nevaluations (right)\noperates by combining a well-spread global search with full exploitation of local\n\u2018niches\u2019 (highly fit regions). This explains the far superior performance of ParEGO\non the test functions with either low density at the Pareto front, local Pareto fronts or\nseverediscontinuities.Fig. 7 (right)is a goodexample,however,of a smoother,more\ndense function where Bin MSOPS has provided good even coverage, but ParEGO\nhas focused too much on local niches. Fig. 8 really shows how ParEGO homes in on\nparts of the true Pareto set more aggressively,but sometimes fails to spread across it.\n8 Summary and conclusion\nIn many optimization scenarios, the number of fitness evaluations that can be performed\nis severely limited by cost or other constraints. In this study, the performance of two"},{"page":13,"text":"13\nTable 2. Mean and SD values of the hypervolume indicator after 100 evaluations of Bin MSOPS \/\nParEGO from 21 runs of each. Larger values indicate better performance. The distributions of the\nvalues are tested using the Mann-Whitney rank sum test. The\nindicated. ParEGO is significantly better than Bin MSOPS unless stated\n\u00b1 values and significance level are\nFunction Bin MSOPS mean (SD) ParEGO mean (SD)\nOKA114.8496 (0.571733)\nOKA213.6773 (1.53528)\nKNO186.9879 (5.9303)\nVLMOP2 0.317661 (0.00440428) 0.307027 (0.00564198) -4.792169\nVLMOP3 7.22865 (0.681038)\nDTLZ1a 185317 (2573.43)\nDTLZ2a 3.85168 (0.139089)\nDTLZ4a 0.533989 (0.0394657)\nDTLZ7a 10.5544 (1.7988)\n\u00b2 -value\n-5.546841\n-5.546841\n-3.735627\nsignificance\n17.9532 (0.372966)\n19.7183 (0.887686)\n78.4856 (7.24012)\n\u00b39\u00b4\u008d\u00b4\u0084\u00b5\n\u00b39\u00b4\u008d\u00b4\u0084\u00b5\n\u00b39\u00b4\u008d\u00b4\u0084\u00b5\nBin MSOPS wins\nBin MSOPS wins\n\u00b39\u00b4\u008d\u00b4\u0084\u00b5\n7.61652 (0.157667)\n189262 (209.001)\n3.97869 (0.0890044)\n0.673329 (0.263526)\n12.9893 (0.655795)\n-1.547078\n-5.521685\n-3.358291\n-2.477840\n-4.490300\n\u00b39\u00b4\u008d\u00b6\u0084\u00b5\n\u00b39\u00b4\u008d\u00b4\u0084\u00b5\n\u00b39\u00b4\u008d\u00b4\u0084\u00b5\n\u00b39\u00b4\u008d\u00b4\u0084\u00b5\n\u00b39\u00b4\u008d\u00b4\u0084\u00b5\nTable 3. Mean and SD values of the hypervolume indicator after 250 evaluations of Bin MSOPS \/\nParEGO from 21 runs of each. Larger values indicate better performance. The distributions of the\nvalues are tested using the Mann-Whitney rank sum test. The\nindicated. ParEGO is significantly better than Bin MSOPSunless stated\n\u00b1 values and significance level are\nFunction Bin MSOPS mean (SD) ParEGO mean (SD)\nOKA114.8169 (0.446187)\nOKA213.9093 (1.13887)\nKNO194.972 (1.70367)\nVLMOP2 0.324363 (0.000664073) 0.310789 (0.00398408) -5.546841\nVLMOP3 4.94459 (0.0599138)\nDTLZ1a 63980.6 (602.738)\nDTLZ2a 2.79582 (0.0960357)\nDTLZ4a 0.111108 (0.124952)\nDTLZ7a 10.6171 (1.26015)\n\u00b2 -value\n-5.219816\n-5.546841\n-5.521685\nsignificance\n15.9849 (0.372917)\n18.4416 (0.467239)\n84.2247 (5.5432)\n\u00b3?\u00b4t\u00b4t\u00b5\n\u00b3?\u00b4t\u00b4\u0084\u00b5\n\u00b3X\u00b4\u008d\u00b4\u0084\u00b5\nBin MSOPS wins\nBin MSOPS wins\nBin MSOPS wins\n\u00b3?\u00b4t\u00b4t\u00b5\n4.75726 (0.113527)\n64869.6 (6.98978)\n3.08818 (0.0276524)\n1.67242 (0.478067)\n18.1657 (0.431554)\n-4.892791\n-5.546841\n-5.546841\n-5.521685\n-5.546841\n\u00b3?\u00b4t\u00b4t\u00b5\n\u00b3?\u00b4t\u00b4t\u00b5\n\u00b3?\u00b4t\u00b4t\u00b5\n\u00b3?\u00b4t\u00b4t\u00b5\n\u00b3?\u00b4t\u00b4t\u00b5\n 0\n 0.5\n 1\n 1.5\n 2\n 2.5\n 3\n 0 0.5 1 1.5\nx1\n 2 2.5 3\nx2\nKNO1 Decision Space: Bin_MSOPS and ParEGO\nBin_MSOPS\nParEGOPFlocal PF\nLocal PSPareto set\n-2\n-1\n 0\n 1\n 2\n 3\n 4\n 5\n 6\n 1 2  3 4 5 6  7 8\nx2\nx1\nOKA1 Decision Space: Bin_MSOPS and ParEGO\nBin_MSOPS\nParEGO\nPareto set\nFig.8. Decision space points visited by Bin MSOPS and ParEGO on KNO1 and OKA1. ParEGO\nfares worse on the former because it focuses too much on getting exactly on the PF instead of\nspreading out along it, while Bin MSOPS extends further along it. But ParEGO\u2019s strategy does\nbetter than Bin MSOPS\u2019son OKA1 because points a small way off the Pareto set in decision space\nare far from the PF in objective space"},{"page":14,"text":"14\nadvanced multiobjective optimization algorithms, Bin MSOPS and ParEGO, was mea-\nsured on much shorter runs than used in most previous MOEA studies. A suite of nine\ndifficult, but low-dimensional, multiobjective test functions of limited ruggedness were\nused to evaluate and compare the algorithms. The results of the comparison indicated\nthat ParEGO\u2019s use of a surrogate model to establish both the expected multiobjective\ncost of candidate solutions and the uncertainty in these predictions, enables rapid ad-\nvances in the early phase of the optimization process. The less directed search performed\nby Bin MSOPS is good, but can fail to capitalize effectively on previously gathered in-\nformation when the solution density at the Pareto front is low.\nOverall, the experimentsreportedhere can serve as a benchmarkfor other algorithms\naimed at these type of expensive, low-dimensional multiobjective problems. To facilitate\nthecomparisonofBin MSOPSandParEGOwithothermethods,rawresultsareavailable\nat [15]. Comparisons of ParEGO with NSGA-II can already be found in [16].\nFuture work will focus on three possible extensions. 1. an adaptive update of the\nscalarizing vectors to get a better distribution on the Pareto front; 2. constraint handling\nmechanisms; and 3. investigation of a hybrid between Bin MSOPS and ParEGO that\nmight offer a good combination of computational efficiency and high performance in\nshort-to-mediumrun lengths (say up to 500 evaluations) for problems where evaluations\nare faster but still otherwise limited.\nAcknowledgments JK is supported by a David Phillips fellowship from the Biotech-\nnology and Biological Sciences Research Council (BBSRC), UK. Thanks to J. Handl for\nproof-readingand ParEGO implementation advice.\nReferences\n1. D. B\u00a8 uche, G. Guidati, P. Stoll, and P. Kourmoursakos. Self-organizing maps for Pareto op-\ntimization of airfoils. In Parallel Problem Solving from Nature\u2014PPSN VII, pages 122\u2013131,\nSeptember 2002. Springer-Verlag.\n2. J.-J. Chen, D. E. Goldberg, S.-Y. Ho, and K. Sastry. Fitness inheritance in multi-objective\noptimization.In Proceedings of the Genetic and Evolutionary Computation Conference\n(GECCO\u20192002), pages 319\u2013326, July 2002. Morgan Kaufmann Publishers.\n3. K. Deb and H. Beyer. Self-adaptive genetic algorithms with simulated binary crossover. Evo-\nlutionary Computation, 9(2):197\u2013221, 2001.\n4. K. Deb, L. Thiele, M. Laumanns, and E. Zitzler. Scalable test problems for evolutionary\nmulti-objective optimization. Technical Report 112, Computer Engineering and Networks\nLaboratory (TIK), Swiss Federal Institute of Technology (ETH), Zurich, Switzerland, 2001.\n5. E. I. Ducheyne, B. De Baets, and R. De Wulf. Is fitness inheritance useful for real-world\napplications? InEvolutionary Multi-CriterionOptimization.Second International Conference,\nEMO 2003, pages 31\u201342, April 2003. Springer.\n6. J. R. G. Evans, M. J. Edirisinghe, and P. V. C. J. Eames. Combinatorial searches of inorganic\nmaterials using the inkjet printer: science philosophy and technology. Journal of the European\nCeramic Society, 21:2291\u20132299, 2001.\n7. C.M. Fonsecaand P. J.Fleming. On theperformance assessment and comparison of stochastic\nmultiobjective optimizers. In Parallel Problem Solving from Nature\u2014PPSN IV, pages 584\u2013\n593, 1996. Springer-Verlag."},{"page":15,"text":"15\n8. A. Gaspar-Cunha and A. Vieira. A multi-objective evolutionary algorithm using neural net-\nworks to approximate fitness evaluations. International Journal of Computers, Systems, and\nSignals, 2004 (in press).\n9. A. Gaspar-Cunha and A. S. Vieira. A hybrid multi-objective evolutionary algorithm using an\ninverse neural network. Hybrid Metaheuristics (HM 2004) Workshop at ECAI 2004, pages\n25-30, 2004. http:\/\/iridia.ulb.ac.be\/ hm2004\/proceedings\/\n10. M. P. Hansen and A. Jaszkiewicz. Evaluating the quality of approximations of the nondomi-\nnated set. Technical Report IMM-REP-1998-7, Technical University of Denmark, 1998.\n11. E. J. Hughes. Multi-objective binary search optimisation. In Second International Confer-\nence on Evolutionary Multi-Criterion Optimisation, EMO\u201903, pages 102\u2013117, April 2003.\nSpringer.\n12. E. J. Hughes. Multiple single objective Pareto sampling. In Congress on Evolutionary Com-\nputation 2003, pages 2678\u20132684, December 2003. IEEE.\n13. Y. Jin, M. Olhofer, and B. Sendhoff. A framework for evolutionary optimization with ap-\nproximate fitness functions. IEEE Transactions on Evolutionary Computation, 6(5):481\u2013494,\n2002.\n14. D. Jones, M. Schonlau, and W. Welch. Efficient global optimization of expensive black-box\nfunctions. Journal of Global Optimization, 13:455\u2013492, 1998.\n15. Knowles\u2019 webpage. http:\/\/dbk.ch.umist.ac.uk\/knowles\/\n16. J. Knowles. ParEGO: A hybrid algorithm with on-line landscape approximation for expensive\nmultiobjective optimization problems. Technical Report TR-COMPSYSBIO-2004-01, Uni-\nversity of Manchester, UK, 2004. Available from http:\/\/dbk.ch.umist.ac.uk\/knowles\/pubs.html\n17. M. Laumanns and J. Ocenasek. Bayesian optimization algorithms for multi-objective opti-\nmization. In Parallel Problem Solving from Nature\u2014PPSN VII, pages 298\u2013307, September\n2002. Springer-Verlag.\n18. R. Myers and D. Montgomery. Response Surface Methodology. Wiley, New York, 1995.\n19. P. K. S. Nain and K. Deb. A computationally effective multi-objective search and optimization\ntechnique using coarse-to-fine grain modeling. Technical Report Kangal Report No. 2002005,\nIITK, Kanpur, India, 2002.\n20. S. O\u2019Hagan, W. Dunn, M. Brown, J. Knowles, and D. Kell. Closed-loop, multiobjective opti-\nmization of analytical instrumentation: gas chromatography\/time-of-flight mass spectrometry\nof the metabolomes of human serum and of yeast fermentations. Analytical Chemistry, 2004\n(in press). http:\/\/pubs.acs.org\/cgi-bin\/asap.cgi\/ancham\/asap\/html\/ac049146x.html\n21. T. Okabe, Y. Jin, M. Olhofer, and B. Sendhoff. On test functions for evolutionary multi-\nobjective optimization. InParallel ProblemSolving fromNature VIII,pages 792\u2013802, Septem-\nber 2004, Springer.\n22. J. Sacks, W. Welch, T. Mitchell, and H. Wynn. Design and analysis of computer experiments\n(with discussion). Statistical Science, 4:409\u2013435, 1989.\n23. R. E. Steuer and E.-U. Choo. An interactive weighted Tchebycheff procedure for multiple\nobjective programming. Mathematical Programming, 25:326\u2013344, 1983.\n24. S. Vaidyanathan, D. I. Broadhurst, D. B. Kell, and R. Goodacre. Explanatory optimization of\nprotein mass spectrometry via genetic search. Analytical Chemistry, 75(23):6679\u20136686, 2003.\n25. D. A. V. Veldhuizen and G. B. Lamont. Multiobjective evolutionary algorithm test suites.\nIn Proceedings of the 1999 ACM Symposium on Applied Computing, pages 351\u2013357, 1999.\nACM.\n26. D. Weuster-Botz and C. Wandrey. Medium optimization by genetic algorithm for continuous\nproduction of formate dehydrogenase. Process Biochemistry, 30:563\u2013571, 1995.\n27. E. Zitzler, L. Thiele, M. Laumanns, C. M. Fonseca, and V. G. da Fonseca. Performance as-\nsessment of multiobjective optimizers: An analysis and review. IEEE Transactions on Evolu-\ntionary Computation, 7(2):117\u2013132, April 2003."}],"fullTextUrl":"https:\/\/www.researchgate.net\/profile\/Evan_Hughes\/publication\/221228406_Multiobjective_Optimization_on_a_Budget_of_250_Evaluations\/links\/00b495225ac557f688000000.pdf","widgetId":"rgw27_56aba233d3dc4"},"id":"rgw27_56aba233d3dc4","partials":[],"templateName":"publicliterature\/stubs\/PublicationText.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationText.html?publicationUid=221228406&hide=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationDetailAd":{"data":{"googleDfpSlot":null,"widgetId":"rgw28_56aba233d3dc4"},"id":"rgw28_56aba233d3dc4","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAd.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAd.html?publicationUid=221228406&slotId=336x280_Publications_ATF_Right&collapseSlotMode=never&fallbackContainerEnabled=1","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationRelations":null,"publicationRelationsReverse":null,"publicationUid":221228406,"showSignUpDialog":false,"selectNewSignUpDialog":false,"publicationQuestions":null,"publicationCitations":null,"publicationReviewPromo":null,"publicationUsedInReviews":null,"publicationPdfJsReader":{"data":{"isPreview":false,"licenseUrl":null,"licenseInfo":null,"defaultLinkData":{"linkId":"00b495225ac557f688000000","name":"Evan Hughes","date":null,"nameLink":"profile\/Evan_Hughes","filename":"","downloadLink":"https:\/\/www.researchgate.net\/profile\/Evan_Hughes\/publication\/221228406_Multiobjective_Optimization_on_a_Budget_of_250_Evaluations\/links\/00b495225ac557f688000000.pdf?inViewer=0&pdfJsDownload=0&origin=publication_detail","viewerUrl":"https:\/\/www.researchgate.net\/profile\/Evan_Hughes\/publication\/221228406_Multiobjective_Optimization_on_a_Budget_of_250_Evaluations\/links\/00b495225ac557f688000000.pdf?inViewer=1&pdfJsDownload=1&origin=publication_detail","downloadHash":"106f14b2262d641807dfea988ce1d608","showFileSizeNote":false,"fileSize":"277.11 KB","noFollow":false,"isDefault":true,"doi":null},"displayableLinks":[{"linkId":"00b495225ac557f688000000","name":"Evan Hughes","date":null,"nameLink":"profile\/Evan_Hughes","filename":"","downloadLink":"https:\/\/www.researchgate.net\/profile\/Evan_Hughes\/publication\/221228406_Multiobjective_Optimization_on_a_Budget_of_250_Evaluations\/links\/00b495225ac557f688000000.pdf?inViewer=0&pdfJsDownload=0&origin=publication_detail","viewerUrl":"https:\/\/www.researchgate.net\/profile\/Evan_Hughes\/publication\/221228406_Multiobjective_Optimization_on_a_Budget_of_250_Evaluations\/links\/00b495225ac557f688000000.pdf?inViewer=1&pdfJsDownload=1&origin=publication_detail","downloadHash":"106f14b2262d641807dfea988ce1d608","showFileSizeNote":false,"fileSize":"277.11 KB","noFollow":false,"isDefault":true,"doi":null}],"hasDisplayableLinks":false,"reader":{"data":{"pdfCommentsActive":false,"publicationType":"Conference Paper","onlyRenderFirstPage":false,"readMoreExperimentGoal":"goalPublicationPdfClicksReadMore","readMoreExperimentViewId":null,"comments":null,"figures":[],"figureAssetIds":[],"figureOverlayUrls":{"clickOnOverlay":"publication.PublicationFigures.html?_sg=w9rYd-FQ8rVWzyTeMLYshNyckiG9k7OEZK7FOcSauYNru78SPu6q1cX46Pi8KwHbm1t63gjdc_RW_YM4f3nxJA.kiJ9DSTKTpr6YnU1IDjBB6XVCTgk7b93xvPjN16DXPzP_iNkbf-zLaAnrIlhsLTsgEKJh2VXjFjQC5wBa8zbVA","clickOnPill":"publication.PublicationFigures.html?_sg=-IiEK_kjkXaebLKquXrFcsrIRdjCeZLuPoBL8KOTrH2WP4EVO2jMAJg2Z1kY5qcgT6vJ-Uvn0j0eFwknF14qBw._LG-ic_rJcRBPHIZc-YtTHT-DaXeJ6g-Zv_8zGtxcf09mwPmxyysNL3lf3AlvE9RKSnCr0yCg1ORi-1T_qVmIQ"},"canSelect":false,"javascriptPath":"https:\/\/www.researchgate.net\/c\/o1q2er\/","downloadUrl":"https%3A%2F%2Fwww.researchgate.net%2Fprofile%2FEvan_Hughes%2Fpublication%2F221228406_Multiobjective_Optimization_on_a_Budget_of_250_Evaluations%2Flinks%2F00b495225ac557f688000000.pdf%3FinViewer%3D1%26pdfJsDownload%3D1%26origin%3Dpublication_detail","viewerUrl":"https:\/\/www.researchgate.net\/c\/o1q2er\/javascript\/lib\/pdfjs\/web\/viewer.html","commentEndpoint":"https:\/\/www.researchgate.net\/rgformat\/api\/comment","experimentEndpoint":"https:\/\/www.researchgate.net\/rgformat\/api\/experiment?key=EsNyC_6WMYa04JL9icLZqud_GbxSBLS5LNW7C_CgFnsGfKhzW7pjQdzzUsb3jCM_J5CjeSKTihCirfZuJrPAzw","urlHash":"13d52c0429d8afc89b31451135644a43","downloadTrackUrl":"application.PdfJsReader.ajaxTrackDownload.html?msrp=WYVUrvEyMeQNZZVyajP7NI7rn2N3TP9fr9uwRcWBBfJibSgnuLjDHkl_WPHXhG25Hbytyp3LEw-V0P-rHAWMoKJoUY5woEeDMVv7k3zvNT8.IhUn7AJiefZj4sTcLeNJLwBbhbnHdAgkpizzGkBfz3KJ56c5fjolWManigDQgGopdv0DY9wWpNxJqUgkcWjhsQ.Wi08K9O11iTDo_HeloxIJGcM1kW_2wx6ZNXDPhjqZew0oMFp_8UAG4HyuurKB3AE4an-Ki6m-AjgNvwFSfok3A","viewportMilestoneTrackUrl":"application.PdfJsReader.ajaxTrackViewportMilestone.html","linkId":"00b495225ac557f688000000","trackedDownloads":{"00b495225ac557f688000000":{"v":false,"d":false}},"assetId":"AS:102913179389959@1401547822596","readerDocId":null,"assetType":"fulltext","interactionType":{"comment":"comment","highlight":"highlight"},"publicationUid":221228406,"commentCursorPromo":null,"widgetId":"rgw30_56aba233d3dc4"},"id":"rgw30_56aba233d3dc4","partials":[],"templateName":"application\/stubs\/PdfJsReader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PdfJsReader.html?fileHref=https%3A%2F%2Fwww.researchgate.net%2Fprofile%2FEvan_Hughes%2Fpublication%2F221228406_Multiobjective_Optimization_on_a_Budget_of_250_Evaluations%2Flinks%2F00b495225ac557f688000000.pdf%3FinViewer%3D1%26pdfJsDownload%3D1%26origin%3Dpublication_detail&assetId=AS%3A102913179389959%401401547822596&publicationUid=221228406&linkId=00b495225ac557f688000000&onlyShowFirstPage=0","viewClass":null,"yuiModules":["css-pow-application-PdfJsReader"],"stylesheets":["pow\/application\/PdfJsReader.css"],"_isYUI":true},"showHeader":true,"title":"Multiobjective Optimization on a Budget of 250 Evaluations","publicationType":"Conference Paper","downloadTrackUrl":"publicliterature.PublicationInlineReader.ajaxTrackDownload.html?msrp=KHu4gR_EPKCdRl8gFmY0C1Zo154rd5XiYOF4RLvOJOg5EEVk3OutLCksvSZFrtSEe301Bq4dkp5r-H1WgttEWoRVqhxmSuCMR4Ls8WUYvuM.jmCYgoMlw_OyN-NGmfIO1GF2ygl9Sgi-vLgNuhA_9uqXNzxDWIBjxor0kl6gY6iOmggBdVQ-x5lWAfidrgdJZQ.4NJkC6nnUSjHi-on7KTHzPBFCLEoGJy8UCgFtsrOM7OEXS-S0sJ2dFtOeaa7Z9MudnxvGsmEPVX7-hq2fagIcQ","publicationUid":221228406,"trackedDownloads":{"00b495225ac557f688000000":{"v":false,"d":false}},"inlinePdf":false,"publicationComments":null,"showDownloadButton":true,"socialShare":{"data":{"shareItems":[{"data":{"name":"Facebook","url":"http:\/\/www.facebook.com\/share.php?u={{url}}{{#title}}&t={{title}}{{\/title}}","width":600,"height":350,"useUtmTags":true,"utmSource":"facebook","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareFacebook.ajaxTrackSocialShare.html","widgetId":"rgw32_56aba233d3dc4"},"id":"rgw32_56aba233d3dc4","partials":{"shareIcon":"application\/stubs\/partials\/shareFacebookBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareFacebook.html?provider=Facebook&shareIcon=shareIconBlog&utmSource=facebook&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"Twitter","url":"http:\/\/twitter.com\/intent\/tweet?text={{#title}}{{title}}: {{\/title}}{{url}}&via=researchgate","width":600,"height":350,"useUtmTags":true,"utmSource":"twitter","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareTwitter.ajaxTrackSocialShare.html","widgetId":"rgw33_56aba233d3dc4"},"id":"rgw33_56aba233d3dc4","partials":{"shareIcon":"application\/stubs\/partials\/shareTwitterBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareTwitter.html?provider=Twitter&shareIcon=shareIconBlog&utmSource=twitter&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"Google+","url":"https:\/\/plus.google.com\/share?url={{url}}","width":600,"height":600,"useUtmTags":true,"utmSource":"googleplus","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareGooglePlus.ajaxTrackSocialShare.html","widgetId":"rgw34_56aba233d3dc4"},"id":"rgw34_56aba233d3dc4","partials":{"shareIcon":"application\/stubs\/partials\/shareGooglePlusBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareGooglePlus.html?provider=Google%2B&shareIcon=shareIconBlog&utmSource=googleplus&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"LinkedIn","url":"http:\/\/www.linkedin.com\/shareArticle?mini=true&url={{url}}{{#title}}&title={{title}}{{\/title}}&source=ResearchGate","width":520,"height":570,"useUtmTags":true,"utmSource":"linkedin","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareLinkedIn.ajaxTrackSocialShare.html","widgetId":"rgw35_56aba233d3dc4"},"id":"rgw35_56aba233d3dc4","partials":{"shareIcon":"application\/stubs\/partials\/shareLinkedInBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareLinkedIn.html?provider=LinkedIn&shareIcon=shareIconBlog&utmSource=linkedin&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"Reddit","url":"https:\/\/www.reddit.com\/submit?url={{url}}{{#title}}&title={{title}}{{\/title}}","width":600,"height":600,"useUtmTags":true,"utmSource":"reddit","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareReddit.ajaxTrackSocialShare.html","widgetId":"rgw36_56aba233d3dc4"},"id":"rgw36_56aba233d3dc4","partials":{"shareIcon":"application\/stubs\/partials\/shareRedditBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareReddit.html?provider=Reddit&shareIcon=shareIconBlog&utmSource=reddit&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true}],"widgetId":"rgw31_56aba233d3dc4"},"id":"rgw31_56aba233d3dc4","partials":[],"templateName":"application\/stubs\/SocialShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.SocialShare.html?campaign=shareFullTextPublication&trackClick=1&shareIcon=shareIconBlog","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw29_56aba233d3dc4"},"id":"rgw29_56aba233d3dc4","partials":[],"templateName":"publicliterature\/stubs\/PublicationInlineReader.html","templateExtensions":["generalHelpers"],"attrs":{"showFulltextDownloadedSignupDialog":true,"preSignUpDialogContext":null,"requestFulltext":false},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationInlineReader.html","viewClass":"views.publicliterature.PublicationInlineReaderView","yuiModules":["rg.views.publicliterature.PublicationInlineReaderView","css-pow-publicliterature-PublicationInlineReader"],"stylesheets":["pow\/publicliterature\/PublicationInlineReader.css"],"_isYUI":true},"useFulltextOptimizedLayout":false,"publicationActions":null,"requestFulltextPromo":null,"currentUrl":"publication\/221228406_Multiobjective_Optimization_on_a_Budget_of_250_Evaluations","isLeaderboardAd":false,"enableStickyBox":null,"googleDfpSlotMobileBottom":null,"fullTextExitPopup":null,"showExitPopupDialog":false,"widgetId":"rgw2_56aba233d3dc4"},"id":"rgw2_56aba233d3dc4","partials":{"romeo_legal_notice":"publicliterature\/stubs\/partials\/romeo_legal_notice.html"},"templateName":"publicliterature\/stubs\/PublicPublicationDetails_NewLayout.html","templateExtensions":["generalHelpers"],"attrs":{"publicationUid":221228406},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicPublicationDetailsOld.html?publicationUid=221228406&isTestOldDesign=0","viewClass":"views.publicliterature.PublicPublicationDetailsOldView","yuiModules":["rg.views.publicliterature.PublicPublicationDetailsOldView"],"stylesheets":[],"_isYUI":true},"widgetId":"rgw1_56aba233d3dc4"},"id":"rgw1_56aba233d3dc4","partials":[],"templateName":"publicliterature\/stubs\/PublicPublicationDetails.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicPublicationDetails.html","viewClass":"views.publicliterature.PublicPublicationDetailsView","yuiModules":["rg.views.publicliterature.PublicPublicationDetailsView"],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"uaClass":"","headPrefix":[],"rootUrl":"https:\/\/www.researchgate.net\/","requestToken":"Sw6bxbJtiYaZ0q91DwyCL3T05lDS0SnlzsZr12KIEoUi7O3douie7NtsEPzJBTao1czOSGBrcFDmRnSS0HkRZk8JCzfe9Y3Yitgpu21Mxez0UxVv99Y+j+cB\/lRr7gTGYRQAuFU0DucQeUlvdjA0Lfwow9WtbvJOI3LF\/JGHWI7k9vg3ntvLrhB1bjwF\/SE7d8dLbCQhwhluACKJqGGUsEa82h0LFzE9GP0p4fxExYSYrziwqOt0bVQcR0PWwACpTmSt2A6uXXUjoZjxTF5dc5m39yWRrLCHNZUErG69xvA=","faviconCdnUrl":"https:\/\/c5.rgstatic.net\/m\/2390829798215018\/images\/favicon.ico","headerOutput":"<noscript><\/noscript><link rel=\"canonical\" href=\"https:\/\/www.researchgate.net\/publication\/221228406_Multiobjective_Optimization_on_a_Budget_of_250_Evaluations\" \/>\n<link rel=\"dns-prefetch\" href=\"\/\/c5.rgstatic.net\" \/>\n<link rel=\"dns-prefetch\" href=\"\/\/i1.rgstatic.net\" \/>\n<meta property=\"twitter:card\" content=\"summary\" \/>\n<meta property=\"twitter:site\" content=\"@ResearchGate\" \/>\n<meta property=\"og:title\" content=\"Multiobjective Optimization on a Budget of 250 Evaluations\" \/>\n<meta property=\"og:description\" content=\"In engineering and other 'real-world' applications, multiobjective opti- mization problems must frequently be tackled on a tight evaluation budget \u00f3 tens or hundreds of function evaluations,...\" \/>\n<meta property=\"og:site_name\" content=\"ResearchGate\" \/>\n<meta property=\"og:image\" content=\"https:\/\/i1.rgstatic.net\/publication\/221228406_Multiobjective_Optimization_on_a_Budget_of_250_Evaluations\/links\/00b495225ac557f688000000\/smallpreview.png\" \/>\n<meta property=\"og:url\" content=\"https:\/\/www.researchgate.net\/publication\/221228406_Multiobjective_Optimization_on_a_Budget_of_250_Evaluations\" \/>\n<meta property=\"rg:id\" content=\"PB:221228406\" \/>\n<meta name=\"DC.identifier\" scheme=\"DCTERMS.URI\" content=\"http:\/\/dx.doi.org\/10.1007\/978-3-540-31880-4_13\" \/>\n<meta name=\"gs_meta_revision\" content=\"1.1\" \/>\n<meta name=\"citation_title\" content=\"Multiobjective Optimization on a Budget of 250 Evaluations\" \/>\n<meta name=\"citation_author\" content=\"Joshua D. Knowles\" \/>\n<meta name=\"citation_author\" content=\"Evan J. Hughes\" \/>\n<meta name=\"citation_conference_title\" content=\"Evolutionary Multi-Criterion Optimization, Third International Conference, EMO 2005, Guanajuato, Mexico, March 9-11, 2005, Proceedings\" \/>\n<meta name=\"citation_publication_date\" content=\"2005\/01\/01\" \/>\n<meta name=\"citation_journal_title\" content=\"Lecture Notes in Computer Science\" \/>\n<meta name=\"citation_issn\" content=\"0302-9743\" \/>\n<meta name=\"citation_volume\" content=\"3410\" \/>\n<meta name=\"citation_firstpage\" content=\"176\" \/>\n<meta name=\"citation_lastpage\" content=\"190\" \/>\n<meta name=\"citation_doi\" content=\"10.1007\/978-3-540-31880-4_13\" \/>\n<meta name=\"citation_pdf_url\" content=\"https:\/\/www.researchgate.net\/profile\/Evan_Hughes\/publication\/221228406_Multiobjective_Optimization_on_a_Budget_of_250_Evaluations\/links\/00b495225ac557f688000000.pdf\" \/>\n<meta name=\"citation_abstract_html_url\" content=\"https:\/\/www.researchgate.net\/publication\/221228406_Multiobjective_Optimization_on_a_Budget_of_250_Evaluations\" \/>\n<meta name=\"citation_fulltext_html_url\" content=\"https:\/\/www.researchgate.net\/publication\/221228406_Multiobjective_Optimization_on_a_Budget_of_250_Evaluations\" \/>\n<meta name=\"viewport\" content=\"width=device-width,initial-scale=1\" \/>\n<link href=\"\/\/c5.rgstatic.net\/m\/22664197317151888\/styles\/rg.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/21004998181197492\/styles\/rg2.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<!--[if lt IE 9]><link href=\"\/\/c5.rgstatic.net\/m\/238176252723686\/styles\/ie.css\" type=\"text\/css\" rel=\"stylesheet\"\/><![endif]-->\n<link href=\"\/\/c5.rgstatic.net\/m\/217752362214895\/styles\/modules\/publicprofile.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/21993347442549\/styles\/pow\/publicliterature\/FollowPublicationPromo.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/282514599719602\/styles\/pow\/application\/PdfJsReader.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/23819663151220\/styles\/pow\/publicliterature\/PublicationInlineReader.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<script src=\"\/\/c5.rgstatic.net\/m\/2321000301012716\/javascript\/vendor\/webfontloader\/webfontloader.js\" type=\"text\/javascript\"><\/script>\n <script>(function(i,s,o,g,r,a,m){i[\"GoogleAnalyticsObject\"]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,\"script\",\"\/\/www.google-analytics.com\/analytics.js\",\"ga\");\n ga(\"create\",\"UA-58591210-1\");ga(\"set\",\"anonymizeIp\",true);ga('set', 'dimension1', 'publication full-text');ga('set', 'dimension2', 'Conference Paper');ga('set', 'dimension3', 'Logged out');ga('set', 'dimension4', 'https');ga(\"send\",\"pageview\");<\/script>\n","webfont":"<noscript><\/noscript><script> WebFontConfig = { custom: { families: ['source_sans_pro_italic', 'source_sans_pro_bold', 'source_sans_pro', 'martel'], urls : ['\/\/c5.rgstatic.net\/m\/231392577336386\/styles\/fonts.css'] } }; WebFont.load(WebFontConfig); <\/script>\n","correlationId":"rgreq-22b68cfd-4074-4224-bc5d-d4c3ff1d186c","accountId":null,"module":"publicliterature","action":"publicliterature.PublicPublicationDetails","page":"publicationDetail","product":"publications","backendTime":558,"continent":"Asia","stylesHome":"\/\/c5.rgstatic.net\/m\/","staticHost":"c5.rgstatic.net","useEarlyFlush":false,"longRunningRequestIdentifier":"LongRunningRequest.publicliterature.PublicPublicationDetails","longRunningRequestFp":"e9e5bbe1366c7ee8c8e41d02f793c884ac9be19b","widgetId":"rgw37_56aba233d3dc4"},"id":"rgw37_56aba233d3dc4","partials":[],"templateName":"application\/stubs\/StaticHeader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.StaticHeader.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){
            Y.rg.core.pagespeed.Monitoring.monitorPage("\/\/glassmoni.researchgate.net", "publicliterature.PublicPublicationDetails.run.html.loggedOut.get", "59de9668d07aeb77ab4de5f24d382b5d199d2437", "rgreq-22b68cfd-4074-4224-bc5d-d4c3ff1d186c", "cc9e4e9ec7e02b9e508d06be03deb66459fe5ae0");
        
            Y.rg.core.pagespeed.Monitoring.monitorPage("\/\/glassmoni.researchgate.net", "publicationDetail.loggedOut", "ed1993d9e20f6cefa83edacaa24401a18c071aea", "rgreq-22b68cfd-4074-4224-bc5d-d4c3ff1d186c", "cc9e4e9ec7e02b9e508d06be03deb66459fe5ae0");
        })();
(function(){Y.rg.createInitialWidget({"data":{"year":"2016","inlinePromo":null,"isAdmin":false,"contactUrl":"https:\/\/www.researchgate.net\/contact","aboutUsUrl":"https:\/\/www.researchgate.net\/about","widgetId":"rgw38_56aba233d3dc4"},"id":"rgw38_56aba233d3dc4","partials":[],"templateName":"application\/stubs\/DefaultFooter.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.DefaultFooter.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"headerLogin":{"data":{"urlAfterLogin":"publication\/221228406_Multiobjective_Optimization_on_a_Budget_of_250_Evaluations","requestToken":"BP69bFBxXbSrqUYhI6tOcjY\/ZrIP8Lwon+lVdQOGrpcfrTHRpy0\/+yGbOg5uDxQlVQtAGjXzEi+FFw0sr848YLeKIPDLcCBSXDxwfb7qg4bchQrnLkdlAaMiDLCl6SXM+TRWuNzKVp9csWBpzxx6A\/C7fB\/RxdZt9sBcpHSDVo3Ag+lNEr9TC96CdwvJQPwRv7jELAQn\/QWdw6YjTFGZ6NO0Ae4ly9nZNvcX3kPvSTftblVpd8GwGKOuDQFhDvq8n1GORi209PruidFfY1wC+RBm7thDmGcYqYfM0gHOb9Q=","loginUrl":"https:\/\/www.researchgate.net\/application.Login.html","signupUrl":"https:\/\/www.researchgate.net\/signup.SignUp.html?ev=su_chnl_index&hdrsu=1&_sg=TZhU2mIUdK8EgvHb4geFbGut4Gg7rp0jAZ2GvtNm_LVoaXFe1hFFEs159IaSSH33","encodedUrlAfterLogin":"cHVibGljYXRpb24vMjIxMjI4NDA2X011bHRpb2JqZWN0aXZlX09wdGltaXphdGlvbl9vbl9hX0J1ZGdldF9vZl8yNTBfRXZhbHVhdGlvbnM%3D","signupCallToAction":"Join for free","widgetId":"rgw40_56aba233d3dc4"},"id":"rgw40_56aba233d3dc4","partials":{"partial":"application\/stubs\/partials\/headerLoginDefault.html"},"templateName":"application\/stubs\/HeaderLogin.html","templateExtensions":[],"attrs":{"goal":"milestoneHeaderLoginSeen"},"widgetUrl":"https:\/\/www.researchgate.net\/application.HeaderLogin.html","viewClass":"views.application.HeaderLoginView","yuiModules":["rg.views.application.HeaderLoginView"],"stylesheets":[],"_isYUI":true},"cookieConsent":null,"logoSvgSrc":"https:\/\/c5.rgstatic.net\/m\/235107188705592\/images\/template\/brand-header-logo.svg","logoFallbackSrc":"https:\/\/c5.rgstatic.net\/m\/238113351022438\/images\/template\/brand-header-logo.png","widgetId":"rgw39_56aba233d3dc4"},"id":"rgw39_56aba233d3dc4","partials":{"schemaSocialProfiles":"application\/stubs\/partials\/schemaSocialProfiles.html"},"templateName":"application\/stubs\/HeaderLoggedOut.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.HeaderLoggedOut.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"logEvent":"su_banner","specialCopy":false,"widgetId":"rgw41_56aba233d3dc4"},"id":"rgw41_56aba233d3dc4","partials":[],"templateName":"application\/stubs\/LoggedOutBanner.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.LoggedOutBanner.html","viewClass":"views.application.LoggedOutBannerView","yuiModules":["rg.views.application.LoggedOutBannerView"],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.core.util.ParameterFilter.filter(["ev","cp","ch","ref","dbw","pli","loginT","uid","claimChannel","enrichId","enrichSource","utm_source","utm_medium","utm_campaign","el","ci"]);})();
});}); } else { throw 'YRG was not loaded when attaching widgets'; }</script><script> dataLayer = [{"pageCategory":"publication full-text","publicationType":"Conference Paper","eventCategory":"Publication page"}]; </script> <noscript><iframe src="//www.googletagmanager.com/ns.html?id=GTM-MKVKH7" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-MKVKH7');</script><script>(function(e){function n(n,t,o,a){"use strict";var i=e.document.createElement("link"),r=t||e.document.getElementsByTagName("script")[0],d=e.document.styleSheets;return i.rel="stylesheet",i.href=n,i.media="only x",a&&(i.onload=a),r.parentNode.insertBefore(i,r),i.onloadcssdefined=function(e){for(var t,o=0;d.length>o;o++)d[o].href&&d[o].href.indexOf(n)>-1&&(t=!0);t?e():setTimeout(function(){i.onloadcssdefined(e)})},i.onloadcssdefined(function(){i.media=o||"all"}),i}function t(e,n){e.onload=function(){e.onload=null,n&&n.call(e)},"isApplicationInstalled"in navigator&&"onloadcssdefined"in e&&e.onloadcssdefined(n)}var o=function(a,i){"use strict";if(a&&3===a.length){var r=e.Image,d=!(!document.createElementNS||!document.createElementNS("http://www.w3.org/2000/svg","svg").createSVGRect||!document.implementation.hasFeature("http://www.w3.org/TR/SVG11/feature#Image","1.1")||e.opera&&-1===navigator.userAgent.indexOf("Chrome")||-1!==navigator.userAgent.indexOf("Series40")),c=new r;c.onerror=function(){o.method="png",o.href=a[2],n(a[2])},c.onload=function(){var e=1===c.width&&1===c.height,r=a[e&&d?0:e?1:2];o.method=e&&d?"svg":e?"datapng":"png",o.href=r,t(n(r),i)},c.src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///ywAAAAAAQABAAACAUwAOw==",document.documentElement.className+=" grunticon"}};o.loadCSS=n,o.onloadCSS=t,e.grunticon=o})(this);grunticon(["https://c5.rgstatic.net/c/o1q2er/styles/icons/_header-ico.svg.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_header-ico.png.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_header-ico.fallback.scss"]);grunticon(["https://c5.rgstatic.net/c/o1q2er/styles/icons/_admin-ico.svg.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_admin-ico.png.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_admin-ico.fallback.scss"]);grunticon(["https://c5.rgstatic.net/c/o1q2er/styles/icons/_ico.svg.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_ico.png.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_ico.fallback.scss"]);</script></body>
</html>
