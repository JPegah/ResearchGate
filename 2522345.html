<!DOCTYPE html> <html lang="en" class="" id="rgw25_56ab9f94c85e2"> <head > <meta charset="utf-8"/> <meta http-equiv="content-type" content="text/html; charset=UTF-8"/> <meta name="Rg-Request-Token" id="Rg-Request-Token" content="BD0A4ZSsp3XdbAXxF7mEDHcccywARjmVcqbJukAZbCHCraw4MAu+vX0JwXVye8cei+PC+pon0btuTEsdnYTbJAVihq8Zt/tP9d+j+o7a3oK7Cckmn4DQnaPVMiQplkkUHqRjDD4Jwxz+JoYJdIc9GhQoa7lCMTwJWdLGDvgmHg3HIUcsAOcOD/6tiYAqZVS6112Ng3V/S6U0nZ+242q6gC+duF7VutclIH9qvHbxYHrnFiJiBEldUUfJ67jAfV3qGImYxpTcLvF/VTsfgsXUCAYljnRlLfyuCuaWY2O7/jg="/> <meta http-equiv="expires" content="0"/> <link rel="apple-touch-icon" sizes="57x57" href="https://www.researchgate.net/apple-touch-icon-57x57.png"> <link rel="apple-touch-icon" sizes="60x60" href="https://www.researchgate.net/apple-touch-icon-60x60.png"> <link rel="apple-touch-icon" sizes="72x72" href="https://www.researchgate.net/apple-touch-icon-72x72.png"> <link rel="apple-touch-icon" sizes="76x76" href="https://www.researchgate.net/apple-touch-icon-76x76.png"> <link rel="apple-touch-icon" sizes="114x114" href="https://www.researchgate.net/apple-touch-icon-114x114.png"> <link rel="apple-touch-icon" sizes="120x120" href="https://www.researchgate.net/apple-touch-icon-120x120.png"> <link rel="apple-touch-icon" sizes="144x144" href="https://www.researchgate.net/apple-touch-icon-144x144.png"> <link rel="apple-touch-icon" sizes="152x152" href="https://www.researchgate.net/apple-touch-icon-152x152.png"> <link rel="apple-touch-icon" sizes="180x180" href="https://www.researchgate.net/apple-touch-icon-180x180.png"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-32x32.png" sizes="32x32"> <link rel="icon" type="image/png" href="https://www.researchgate.net/android-chrome-192x192.png" sizes="192x192"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-96x96.png" sizes="96x96"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-16x16.png" sizes="16x16"> <link rel="shortcut icon" type="image/x-icon" href="https://c5.rgstatic.net/m/2390829798215018/images/favicon.ico"/> <link rel="manifest" href="https://www.researchgate.net/manifest.json"> <meta name="msapplication-TileColor" content="#da532c"> <meta name="msapplication-TileImage" content="https://www.researchgate.net/mstile-144x144.png"> <meta name="theme-color" content="#444444"> <link rel="search" type="application/opensearchdescription+xml" title="ResearchGate search" href="https://www.researchgate.net/application.DownloadOpenSearchPlugin.html"/> <link rel="meta" type="application/rdf+xml" title="ICRA labels" href="https://www.researchgate.net/application.DownloadLabels.html"/> <link rel="http://oexchange.org/spec/0.8/rel/related-target" type="application/xrd+xml" href="https://www.researchgate.net/application.DownloadOExchange.html"/> <base href="https://www.researchgate.net/"/> <script>
    var rgConfig = {
        correlationId: "rgreq-914b5ea7-aac9-4569-9c97-529fce868539",
        accountId: "",
        module: "publicliterature",
        action: "publicliterature.PublicPublicationDetails",
        page: "publicationDetail",
        product: "publications",
        continent: "Asia",
        stylesHome: "//c5.rgstatic.net/m/",
        staticHost: "c5.rgstatic.net",
        longRunningRequestIdentifier: "LongRunningRequest.publicliterature.PublicPublicationDetails",
        longRunningRequestFp: "e9e5bbe1366c7ee8c8e41d02f793c884ac9be19b"
    };
    window.rootUrl = "https://www.researchgate.net/";
</script> <link rel="canonical" href="https://www.researchgate.net/publication/2522345_Bayesian_Factor_Regression_Models_in_the_Large_p_Small_n_Paradigm" />
<link rel="dns-prefetch" href="//c5.rgstatic.net" />
<link rel="dns-prefetch" href="//i1.rgstatic.net" />
<meta property="twitter:card" content="summary" />
<meta property="twitter:site" content="@ResearchGate" />
<meta property="og:title" content="Bayesian Factor Regression Models in the &quot;Large p, Small n&quot; Paradigm" />
<meta property="og:description" content="TOR REGRESSION MODELS 1.1 SVD Regression Begin with the linear model y = X# + # where y is the n-vector of responses, X is the n p matrix of predictors, # is the p-vector regression parameter, and..." />
<meta property="og:site_name" content="ResearchGate" />
<meta property="og:image" content="https://i1.rgstatic.net/publication/2522345_Bayesian_Factor_Regression_Models_in_the_Large_p_Small_n_Paradigm/links/0e5fab20f0c41c4932e308d6/smallpreview.png" />
<meta property="og:url" content="https://www.researchgate.net/publication/2522345_Bayesian_Factor_Regression_Models_in_the_Large_p_Small_n_Paradigm" />
<meta property="rg:id" content="PB:2522345" />
<meta name="DC.identifier" scheme="DCTERMS.URI" content="http://dx.doi.org/" />
<meta name="gs_meta_revision" content="1.1" />
<meta name="citation_title" content="Bayesian Factor Regression Models in the &quot;Large p, Small n&quot; Paradigm" />
<meta name="citation_author" content="Mike West" />
<meta name="citation_publication_date" content="2002/08/10" />
<meta name="citation_volume" content="7" />
<meta name="citation_abstract_html_url" content="https://www.researchgate.net/publication/2522345_Bayesian_Factor_Regression_Models_in_the_Large_p_Small_n_Paradigm" />
<meta name="citation_fulltext_html_url" content="https://www.researchgate.net/publication/2522345_Bayesian_Factor_Regression_Models_in_the_Large_p_Small_n_Paradigm" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<link href="//c5.rgstatic.net/m/22664197317151888/styles/rg.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/21004998181197492/styles/rg2.css" type="text/css" rel="stylesheet"/>
<!--[if lt IE 9]><link href="//c5.rgstatic.net/m/238176252723686/styles/ie.css" type="text/css" rel="stylesheet"/><![endif]-->
<link href="//c5.rgstatic.net/m/217752362214895/styles/modules/publicprofile.css" type="text/css" rel="stylesheet"/>
<script src="//c5.rgstatic.net/m/2321000301012716/javascript/vendor/webfontloader/webfontloader.js" type="text/javascript"></script>
 <script>(function(i,s,o,g,r,a,m){i["GoogleAnalyticsObject"]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,"script","//www.google-analytics.com/analytics.js","ga");
 ga("create","UA-58591210-1");ga("set","anonymizeIp",true);ga('set', 'dimension1', 'publication slurped');ga('set', 'dimension2', 'Article');ga('set', 'dimension3', 'Logged out');ga('set', 'dimension4', 'https');ga("send","pageview");</script>
  <script> WebFontConfig = { custom: { families: ['source_sans_pro_italic', 'source_sans_pro_bold', 'source_sans_pro', 'martel'], urls : ['//c5.rgstatic.net/m/231392577336386/styles/fonts.css'] } }; WebFont.load(WebFontConfig); </script><noscript></noscript>

<title>Bayesian Factor Regression Models in the &quot;Large p, Small n&quot; Paradigm</title>
<meta name="description" content="Bayesian Factor Regression Models in the &quot;Large p, Small n&quot; Paradigm on ResearchGate, the professional network for scientists."/>
<meta name="keywords" content="scientific network, scientific platform, scientific community, research partner, research collaboration, journal articles, international collaboration, find researcher, lifescience researcher, interdisciplinary research, research collaboration"/>
</head>
<body class="use-svg-icons logged-out">
<div id="page-container">
<script type="text/javascript">var googletag = googletag || {}; googletag.cmd = googletag.cmd || [];
(function() { var gads = document.createElement("script"); gads.async = true; gads.type = "text/javascript"; var useSSL = "https:" == document.location.protocol; gads.src = (useSSL ? "https:" : "http:") + "//www.googletagservices.com/tag/js/gpt.js"; var node =document.getElementsByTagName("script")[0]; node.parentNode.insertBefore(gads, node); })();</script><div id="main" class="logged-out-header-support">
<div id="content" class="">

<noscript>
<div class="c-box-warning full-width-element" style="text-align: center; ">
    <div style="margin: auto; padding:10px;" class="container">
        <b>For full functionality of ResearchGate it is necessary to enable JavaScript.
            Here are the <a href="http://www.enable-javascript.com/" rel="nofollow" target="_blank">
                instructions how to enable JavaScript in your web browser</a>.</b>
    </div>
</div>
</noscript>

<div id="rgw1_56ab9f94c85e2" itemscope itemtype="http://schema.org/ScholarlyArticle"><div class="publication-wrapper publication-wrapper-onecol" id="rgw2_56ab9f94c85e2" itemscope itemtype="http://schema.org/ScholarlyArticle"> <div class="c-col-content"> <div class="c-content"> <div class="clearfix">  <div class="publication-header"> <div id="rgw6_56ab9f94c85e2">  <div class="type-label"> Article   </div> <span class="Z3988" title="ctx_ver=Z39.88-2004&rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&rfr_id=info%3Asid%2Fresearchgate.net%3Aresearchgate&rft.atitle=Bayesian%20Factor%20Regression%20Models%20in%20the%20%26quot%3BLarge%20p%2C%20Small%20n%26quot%3B%20Paradigm&rft.title=Bayesian%20Stat.&rft.jtitle=Bayesian%20Stat.&rft.volume=7&rft.date=2002&rft.au=Mike%20West&rft.genre=article"></span> <h1 class="pub-title" itemprop="name">Bayesian Factor Regression Models in the &quot;Large p, Small n&quot; Paradigm</h1> <meta itemprop="headline" content="Bayesian Factor Regression Models in the &quot;Large p, Small n&quot; Paradigm">  <meta itemprop="image" content="https://i1.rgstatic.net/publication/2522345_Bayesian_Factor_Regression_Models_in_the_Large_p_Small_n_Paradigm/links/0e5fab20f0c41c4932e308d6/smallpreview.png">  <div id="rgw8_56ab9f94c85e2" class="publication-detail-author-list"> <div> <ul class="clearfix js-people-list">  <li id="rgw9_56ab9f94c85e2"> <a href="researcher/10014083_Mike_West" class="pub-detail-item author-item" itemprop="author" itemscope itemtype="http://schema.org/Person"> <div class="indent-left"> <div class="people-img">  <img src="https://c5.rgstatic.net/m/2951093203564/images/template/default/profile/profile_default_s.jpg" title="Mike West" alt="Mike West" height="20px" width="20px" style="height: 20px;"/>  </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Mike West</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item   not-claimed " id="rgw10_56ab9f94c85e2">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="researcher/10014083_Mike_West"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="Mike West" alt="Mike West" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">       </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="researcher/10014083_Mike_West" class="display-name">Mike West</a>    </h5> <div class="truncate-single-line meta">   </div>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>   </ul> <div class="js-loading"></div>  </div> </div> <div class="pub-details js-pub-details">     Bayesian Stat   <meta itemprop="datePublished" content="2002-08">  08/2002;  7.             <div class="pub-source"> Source: <a href="http://citeseer.ist.psu.edu/525895.html" rel="nofollow">CiteSeer</a> </div>  </div> <div id="rgw11_56ab9f94c85e2" class="pub-abstract">  <div class="clearfix">   <p itemprop="description"> <strong>ABSTRACT</strong> <div>TOR REGRESSION MODELS 1.1 SVD Regression Begin with the linear model y = X# + # where y is the n-vector of responses, X is the n p matrix of predictors, # is the p-vector regression parameter, and # , # I) is the n-vector error term. Of key interest are cases when p &gt;&gt; n, when X is &quot;long and skinny.&quot; The standard empirical factor (principal component) regression is best represented using the reduced singular-value decomposition (SVD) of X, namely X = FA where F is the nk factor matrix (columns are factors, rows are samples) and A is the k p SVD &quot;loadings&quot; matrix, subject to AA # = I and F # F = D where D is the diagonal matrix of k positive singular values, arranged in decreasing order. This reduced form assumes factors with zero singular values have been ignored without loss; k with equality only if all singular values are positive. Now the regression transforms via X# = F# where # = A# is the k-vector of regression parameters for the factor variables, representing</div> </p>  </div>   </div>      <div class="action-container">   <div class="clear"></div> <div class="share-dialog-container" style="display: none;">  </div> </div> </div> <div style="margin-left: -20px; margin-right: -20px;">  </div> </div>  <div class="publication-detail-dfp-container rf"> <div id="rgw24_56ab9f94c85e2">  </div> </div>  </div>  <div class="clearfix">  <noscript> <div id="rgw23_56ab9f94c85e2"  itemprop="articleBody">  <p>Page 1</p> <p>Bayesian Factor Regression Models<br />in the “Large p, Small n” Paradigm<br />MIKE WEST<br />ISDS, Duke University, Durham, NC 27708, USA<br />mw@isds.duke.edu<br />SUMMARY<br />I discuss Bayesianfactor regressionmodels and prediction with very many explanatory variables.<br />Such problems arise in many areas; my motivating applications are in studies of gene expression<br />in functional genomics. I first discuss empirical factor (principal components) regression, and<br />the use of general classes of shrinkage priors, with an example. These models raise foundational<br />questions for Bayesians, and related practical issues, due to the use of design-dependent priors<br />and the need to recover inferences on the effects of the original, high-dimensional predictors.<br />I then discuss latent factor models for high-dimensional variables, and regression approaches<br />in which low-dimensional latent factors are the predictor variables. These models generalise<br />empirical factor regression, provide for more incisive evaluation of factor structure underlying<br />high-dimensional predictors, and resolve the philosophical and practical issues in empirical<br />factor models by casting the latter as limiting special cases. Finally, I turn to questions of prior<br />specification in these models, and introduce sparse latent factor models to induce substantively<br />relevant structure in the high-dimensional distributions of predictors. Embedding such sparse<br />latent factor models in factor regressions provides a novel approach to variable selection with<br />very many predictors. The paper concludes with an example of sparse factor analysis of gene<br />expression data and comments about further research.<br />Keywords:<br />DIMENSION REDUCTION, GENE EXPRESSION ANALYSIS, HIGH-DIMENSIONAL<br />COVARIATES, LATENT FACTOR MODELS, SHRINKAGE PRIORS.<br />1. EMPIRICAL FACTOR REGRESSION MODELS<br />1.1 SVD Regression<br />Begin with the linear model y = Xβ + ? where y is the n−vector of responses, X is the<br />n×p matrix of predictors, β is the p−vector regression parameter, and ? ∼ N(?|,σ2I)<br />is the n−vector error term. Of key interest are cases when p &gt;&gt; n, when X is “long and<br />skinny.” The standard empirical factor (principal component) regression is best repre-<br />sented using the reduced singular-value decomposition (SVD) of X, namely X = FA<br />where F is the n×k factor matrix (columns are factors, rows are samples) and A is the<br />k × p SVD “loadings” matrix, subject to AA?= I and F?F = D2where D is the di-<br />agonal matrix of k positive singular values, arranged in decreasing order. This reduced<br />form assumes factors with zero singular values have been ignored without loss; k ≤ n<br />with equality only if all singular values are positive. Now the regression transforms<br />via Xβ = Fθ where θ = Aβ is the k−vector of regression parameters for the factor<br />variables, representing a possibly massive dimension reduction from p to k parameters.<br />Inherently, observing y provides information only on the underlying factor regres-<br />sion parameters θ, so prior specification directly in factor space has become common.<br />Generalised shrinkage (or ridge regression) priors on θ have become popular as MCMC</p>  <p>Page 2</p> <p>2<br />Mike West<br />methods now permit their routine use. A particularly flexible class of such priors as-<br />sumes independent T distributions for the elements θ1,...,θk of θ, so allowing for<br />varying degrees of shrinkage in each of the orthogonal factor dimensions. Independent<br />priors are suggested in view of orthogonality of the factors. A particular example has<br />θi∼ N(θi|0,ci/φi) where φi∼ Ga(φi|r/2,r/2) independently, for some r &gt; 0; the tun-<br />ing parameter r is the degree-of-freedom parameter for the implied T distribution for θi<br />that follows on marginalisation over the random precision φi. Here the ciare specified<br />weights that may be used, for example, to indicate the prior view that higher-order fac-<br />tors are expected to play lesser roles in the regression – often, though not necessarily,<br />the case. In the first example below this is the case, and the model uses ci= i−2, for<br />example. This also allows for removal of factors in prior specification, by setting a ci<br />to zero. Analyses typically also adopt inverse gamma priors for the error variance σ2.<br />These models are evidently easily implemented using MCMC. The complete condi-<br />tional posterior for θ given the φiis multivariate normal, and the φiare conditionally<br />independent gamma variates given θ. The example below – like many others I have<br />explored – utilises this to generate sequences of posterior samples for θ and the φi, and<br />MCMC convergence is generally clean and swift.<br />1.2 Coherence and Inference on Original Regression Parameters<br />A fundamental issue – philosophical and practical – arises from the explicit design-, and<br />sample size-, dependence of the empirical factor model. The key θ parameter is directly<br />defined as a function of X and β. The former dependency raises, for Bayesians, the<br />foundational question of whether this is in fact a valid Bayesian model. The parameter<br />definition changes as the sample size and design changes; the specification of priors over<br />these design-dependent parameters must be coherent with respect to changing n and<br />X. I address and answer this, fully and affirmatively, in Section 2.<br />A related practical issue is that of inference on the original regression parameters β.<br />The framework has priors and posteriors for θ, but leaves open questions of “inverting”<br />the dimension-reducing map to make inferences on β. The many-one map θ = Aβ has<br />multiple generalised inverses β = A?θ + b for all p−vectors b such that Ab = 0. Again,<br />this issue is fully resolved in Section 2. Here, simply note that, for predictive purposes,<br />the choice of b is irrelevant. A canonical choice of generalised inverse is the standard<br />“least-norm” inverse based on b = 0, i.e., β∗= A?θ. The analysis in the example below<br />uses β∗; again, Section 2 explains and justifies this properly. Posterior samples for θ<br />trivially imply samples for β∗which may be summarised for inference.<br />One interesting connection to make is that the prior on β∗implied by the prior on<br />θ of Section 1.1 above is a generalisation of the g−prior of Zellner (1986). Given condi-<br />tional N(θi|0,ci/φi) priors, the implied prior for β = β∗is (massively singular) normal<br />with density proportional to exp{−β?A?GAβ/2}, where G is diagonal with elements<br />φi/ci. This makes explicit the design-dependency of the prior and also the individual<br />scaling in each of the singular factor dimensions. The Zellner g−prior corresponds to<br />taking G = gD2for some positive scalar g &gt; 0. I therefore refer to this approach as<br />defining a class of generalised singular g−priors (or gsg−priors).</p>  <p>Page 3</p> <p>Bayesian Factor Regression Models<br />3<br />1.3 Prediction<br />Prediction is practically straightforward, though raises foundational questions related<br />to the design-dependency issue. Technically, response values to be predicted are simply<br />treated as missing values to be imputed, and the MCMC analysis is trivially extended to<br />sample these values at each iteration. That is, y is partitioned into a vector of training<br />samples, yt, and a vector of validation cases yv to be predicted; the design matrix<br />is conformably partitioned as [Xt;Xv].The MCMC imputes yv from the implied<br />(normal) conditional posterior. This requires that the model is specified and analysed<br />conditional on all predictor values, including Xv, and the empirical factor regression<br />model is based on decomposition of the full X matrix. As a result, the factors F are<br />evaluated based on predictors Xvas well as Xt; thus Xvforms part of the model and<br />prior structure even though the corresponding responses are missing. One message is<br />that required predictor values must be contemplated prior to analysis, or analysis fully<br />repeated if new predictions are required.<br />Again, this apparent issue is interpreted and resolved in Section 2 where the empiri-<br />cal model is understood to arise from a more elaborate latent factor regression model. In<br />the example now, this approach is simply adopted for prediction of validation samples.<br />1.4 Example: Analysis of Biscuit Dough Data<br />This example concerns biscuit dough data analysed in Brown et al (1999), and orig-<br />inally in Osborne et al (1984). The study aims to predict biscuit dough constituents<br />based on spectral characteristics of dough measured using near infrared (NIR) spec-<br />troscopy. Hence the predictor for each dough sample is a reflectance spectrum on a grid<br />of wavelengths. The analysis here uses the same data as Brown et al (although their<br />framework is multivariate). The response chosen here is fat content of dough samples,<br />the predictors are p = 300 NIR reflectance measures at equally spaced wavelengths<br />over 1202−2400 nanometres (nm), and there are 39 training samples and 39 validation<br />cases to be predicted. The fat content response is standardised, and here the predictors<br />are centred, based on the means and standard deviations in the training sample. The<br />centred spectra are graphed in Figure 1.<br />1200 14001600 18002000 22002400<br />−0.2<br />−0.15<br />−0.1<br />−0.05<br />0<br />0.05<br />0.1<br />0.15<br />0.2<br />0.25<br />0.3<br />wavelength (nm)<br />standardised spectrum<br />Figure 1.<br />Centred spectra predictors of 78 biscuit dough samples</p>  <p>Page 4</p> <p>4<br />Mike West<br />Several analyses have been studied, varying the tuning parameters r and ci. A<br />summary of analysis with r = 5 and ci= i−2is given here; analyses with r between 1<br />and 10 give substantially similar results, and r = 5 is marginally optimal as measured<br />simply by the mean square prediction error computed in the validation sample. The<br />prior for σ−2is unit mean exponential, reflecting the known range of the standardised<br />response data but otherwise representing a relatively diffuse prior. The singular values<br />of the 300×78 matrix X decay rapidly and are truncated to zero, with the corresponding<br />factors dropped, past the point where 99.995% of the total variation, as measured by<br />the cumulative sum of squares of the di, is accounted for; this leads to k = 16 factors<br />in the model, with ci = 0 for i &gt; 16. This reduced number is consistent with the<br />inherent smoothness of the predictor variable, and will generally be experienced when<br />predictors are curves. The MCMC analysis summarised has 20,000 samples selected<br />from a run of 100,000 by choosing every fifth sample, and following a burn-in of 1,000<br />samples. Convergence is swift and clean, consistent with experiences with a range of<br />other examples and MCMC experiments.<br />0246810121416<br />−15<br />−10<br />−5<br />0<br />5<br />10<br />15<br />20<br />25<br />theta<br />factor index<br />Figure 2.<br />Biscuit dough analysis: Estimates of empirical factor regression coefficients θ<br />Figures 2 and 3 graph the approximate posterior means of θ and β∗= A?θ, re-<br />spectively, the former with equal-tails 90% posterior intervals. Figure 3 uses asterisks<br />to mark the ten β∗<br />small cluster at just over 1700nm, at values 1718, 1722, 1726, 1730 and 1734. These are<br />noteworthy since, as remarked by Brown et al, this is a region where fat is known to<br />have a characteristic absorbance; Brown et al identify the point 1718nm too. In Figure<br />1 it is possible to discern small wiggles in the spectra in this wavelength region.<br />Figure 4 addresses prediction and model assessment via display of data plotted<br />against fitted and predicted values; training data are indicated by asterisks, and val-<br />idation data by circles. The close concordance between observed and fitted/predicted<br />values (as well as several other exploratory residual analyses, not reported) give no<br />reason to question model fit. Of particular interest is the fact that the out-of-sample<br />predictions are very accurate indeed. In fact, on the basis of simple mean square pre-<br />diction errors, this analysis improves on results of Brown et al, albeit only marginally.<br />ivalues with largest absolute posterior means. Of these, there is a</p>  <p>Page 5</p> <p>Bayesian Factor Regression Models<br />5<br />120014001600 18002000 2200 2400<br />−6<br />−4<br />−2<br />0<br />2<br />4<br />6<br />wavelength (nm)<br />beta<br />Figure 3.<br />Biscuit dough analysis: Estimates of wavelength regression coefficients β∗<br />−3−2 −1<br />fitted and predicted values<br />0123<br />−3<br />−2<br />−1<br />0<br />1<br />2<br />3<br />response y<br />Figure 4.<br />Biscuit dough analysis: Response versus fitted and predicted values<br />This analysis has been repeated using the full p = 700 wavelengths in the original<br />data set, rather than the 300 selected by Brown et al. This results in substantially<br />similar posterior means for the β∗over a finer grid of wavelengths, and with the largest<br />absolute values of posterior means all peaked around the key 1718nm position.</p>  <p>Page 6</p> <p>6<br />Mike West<br />2. LATENT FACTOR REGRESSION MODELS<br />Empirical factor decompositions suffer a number of drawbacks, chief among which is the<br />confounding of noise in the inherent empirical estimation of common factors. Formal<br />latent factor models address this directly, aiming to extract variation that is idiosyn-<br />cratic to each variable and decouple these “noise” components from the assessment of<br />underlying common factor structure. Here I note the theoretical structure of latent<br />factor models and define a class of factor regression models that naturally relate un-<br />derlying latent structure in high-dimensional predictors to responses. I show that the<br />empirical model of Section 1 arises as a limiting case; this explains and justifies the<br />design-dependency issues discussed in Section 1.<br />Write xifor the ithcolumn of X and consider the latent factor model (e.g., Aguilar<br />and West, 2000; Lopes and West, 1999)<br />xi= Bλi+ νi<br />(1)<br />where<br />λi∼ N(λi|0,∆2) and<br />νi∼ N(νi|0,Ψ2).<br />(2)<br />Here λiis a k−vector of uncertain latent factors for case i, B is a p×k factor loadings<br />matrix parameter, and νiis a vector of idiosyncratic noise terms; both ∆ and Ψ are<br />diagonal. The number of factors is fixed and k &lt;&lt; p. With appropriate identifying<br />constraints on B, this is an estimable model that attributes common structure in X to<br />underlying k−dimensional factors, and isolates variation that is purely idiosyncratic in<br />the νiterms. MCMC based Bayesian analysis, and aspects of identification and prior<br />specification, appear in Lopes and West (1999) and, in more elaborate factor models<br />in time series, in Aguilar and West (2000).<br />Now assume that the responses y = (y1,...,yn)?relate directly to the k latent<br />factors; for each i,<br />yi= λ?<br />where<br />The original design variables xiprovide information on the latent variables through<br />(1), but do not enter the regression; yiis conditionally independent of xigiven λi. One<br />implication is that idiosyncratic variation in X now has no influence on the regression.<br />In Section 3 I discuss and exemplify analysis of the latent factor model alone; space<br />here precludes full development of analysis and examples of the linked factor regression<br />models, but it is of key interest to consider a theoretical limiting special case under the<br />natural prior specification θ ∼ N(θ|0,G−1) with diagonal precision matrix G.<br />Equations (1-3) imply a joint normal distribution for (yi,xi,λi), and hence an<br />implied conditional distribution for yigiven only xiand the model parameters. After<br />some algebra, this is<br />(yi|xi) ∼ N(yi|x?<br />where β = Ψ−2BCθ with C−1= ∆−2+ B?Ψ−2B. Clearly the implied regression of<br />yi on xi is linear, with a theoretically implied and unique extension of the (low-<br />dimensional) factor regression parameter θ to the (high-dimensional) predictor regres-<br />sion parameter β. Further, under the specific prior for θ, there is a unique (singular<br />normal) prior implied for β.<br />Consider now the special case in which Ψ = sI, and in which identification is<br />enforced by assuming B to be orthogonal. Then C is diagonal with elements s2d2<br />d2<br />iθ + ?i<br />?i∼ N(?i|0,σ2).<br />(3)<br />iβ,σ2+ θ?Cθ)(4)<br />i/(s2+<br />i) where the diare the elements of the diagonal matrix ∆. Now take the limit as s → 0,</p>  <p>Page 7</p> <p>Bayesian Factor Regression Models<br />7<br />so that the latent factors explain essentially all the variation in the predictors. Then<br />(1) reduces to xi= Bλior, in matrix form, X = ΛB?where Λ has rows λ?<br />n ≥ k, this recovers the SVD decomposition of X with B = A?, and this limiting special<br />case of the latent factor model defines the empirical factor model. In this limit, it also<br />easily follows that β = A?θ. Under the chosen prior N(θ |0,G−1) with G diagonal, it<br />follows that β has precisely the gsg−prior of Section 1.2.<br />Hence, this special limiting case of a formal latent factor model leads to the SVD<br />regression and the gsg−prior. The tie-up is exact, and explains away the issues of<br />design-, and sample size-, dependence of the parameter and prior, and of recovering<br />inferences on the regression in the original predictor variables. Inference on β flows<br />directly from that on θ. All predictor values for validation cases must be included in<br />the analysis of training data as they inform, under (1), on parameters of the latent<br />factor model and therefore, indirectly, on values of the latent factors underlying the<br />training data.<br />i. Assuming<br />3. SPARSE FACTOR MODELS<br />3.1 Motivating Applications in Gene Expression Profiling<br />Original motivation for this work comes from gene expression analysis in which<br />predictors are genes and p may range up to 30,000. Our studies (Spang et al 2001; West<br />et al 2000, 2001) involve binary regression. A probit model is trivially constructed by<br />treating the yi as latent and observing only indicators of yi&gt; 0. Logistic and other<br />variants are also standard extensions (Albert and Johnson, 1999, ch. 3). Our use of<br />generalised shrinkage priors and high-dimensional predictors since 1999 is innovative,<br />and has been used in gene expression profiling for nearly three years now (1999-2002);<br />as reflected by several presentations at the 2002 Valencia VII conference alone, our<br />approach has been influential in statistics as well as bioinformatics.<br />In gene expression profiling, the predictor variables are recorded expression levels of<br />individual genes, and the responses are clinical or physiological outcomes. Inherently,<br />multiple biological factors underlie patterns of gene expression variation, so latent factor<br />approaches are natural – we imagine that latent factors reflect individual biological<br />functions (gene networks or pathways). This is also a motivating context for sparse<br />models. Each biological factor involves a number of genes, perhaps a few to a few<br />hundred, but not all genes; so each column of B will have many zeros. Similarly, a<br />given gene may play roles in one or a small number of biological pathways, but will not<br />be involved in all; so each row of B will have many zeros. It is therefore substantively<br />appropriate to use priors that induce sparsity in B.<br />3.2 Bayesian Specification of Sparse Factor Models<br />Our Bayesian approach to defining sparse factor structure uses priors on the elements<br />Bij (gene i, factor j) of B that induce zeros with high probability. Within column<br />(factor) j, take the Bijto be independent with priors<br />πjδ0(Bij) + (1 − πj)N(Bij|0,1)<br />where πjhas a prior heavily concentrated near 1. Note that the unit scale of the normal<br />component is convenient; the arbitrary scale of factor j is already accommodated in<br />the variance parameter d2<br />analysis extends existing approaches that utilise normal priors on B (Aguilar and West,<br />j. Assuming specified priors on all model parameters, MCMC</p>  <p>Page 8</p> <p>8<br />Mike West<br />2000; Lopes and West, 1999) to incorporate these new mixture priors, and include<br />sampling of the πj. The analysis is inherently parallelisable; MCMC sequences through<br />columns of B (i.e., through factors), and within each column the (many) elements<br />Bij are, a posteriori, conditionally independent given values of the prior and model<br />parameters, latent factors and data. Hence, for fixed j, the set of p values Bij (i =<br />1,...,p), may be sampled efficiently, in parallel. Some consideration of identification<br />constraints is needed; we may use the popular lower triangular method (see above<br />references) that simply fixes k(k + 1)/2 selected elements of B at 0 or 1, and then use<br />the mixture prior for the remaining (many) elements.<br />3.3 Example: Factors in Breast Cancer Gene Expression Data<br />Some illustration comes from analysis of expression levels of p = 6128 genes measured<br />(using Affymetrix DNA microarrays) on n = 49 breast cancer tumour samples. The<br />data comes from the study reported in West et al (2000, 2001) and Spang et al (2001),<br />where full details of the data and context may be found. Here I discuss some aspects<br />of a new analysis using the sparse latent factor model, with k = 25 factors. Additional<br />prior specifications include priors on the variances d2<br />idiosyncratic variances ψ2<br />specified via independent Ga(·|0.01,0.01)) priors on reciprocal variances. Finally, the<br />use of a prior on πj that heavily favours very high values is critical in enforcing very<br />many zeros in the loadings matrix; here, with p = 6128 and k = 25, analysis utilises<br />πj∼ Be(πj|999,1).<br />Figure 5 displays posterior means of the values of four of the factors, chosen as<br />those four with largest values of the posterior means of the d2<br />top down. The values of the factors (vertical axis) are plotted against sample number<br />(horizontal axis). The first factor is essentially zero apart from on samples (tumours)<br />7,8,11 and 46, and the second essentially zero but for cases 7 and 8. These four cases<br />had been much explored in earlier analyses, and, relative to most of the data, have<br />quite apparent differences in large numbers of genes. The second factor shows that<br />cases 7 and 8 share a common pattern of covariation not exhibited by 11 and 46. These<br />four cases, and particularly 7 and 8, are in fact questionable due to concerns about the<br />quality of the DNA microarray hybridisation; in analyses in West et al (2001) cases 7<br />and 8 had been held out due to these data quality concerns. It is of interest here to note<br />that the full data analysis using the sparse factor model is itself capable of identifying<br />these questionable cases, and protecting inferences on other factors from their effects.<br />The third factor plotted is of key interest in connection with comparison of oestro-<br />gen receptor (ER) status of tumours. We had earlier developed binary factor regression<br />models to predictively discriminate ER status based on a selected set of about 50-100<br />genes (West et al 2000, 2001; Spang et al 2001). That analysis format is effective but<br />involves the pre-selection of smaller numbers of discriminatory genes, and one motivat-<br />ing interest in sparse factor models is the potential to automate variable selection at<br />the factor loading level. This potential is realised and evident here. The third factor is<br />color coded: red indicates ER positive tumours, blue ER negative. Factor 3 evidently<br />separates the two groups quite well, with four cases (16,31,40,43) in the mid-ground.<br />Earlier analysis using gene screening had identified these four cases, and follow-on in-<br />vestigations reversed the ER status determination of number 31, so the analysis is in<br />fact discriminating cases very well based on this factor alone.<br />jof the latent factors and the<br />i(the elements of the diagonal matrix Ψ); these are each<br />jand plotted from the</p>  <p>Page 9</p> <p>Bayesian Factor Regression Models<br />9<br />For comparison, Figure 6 displays the four dominant empirical SVD factors (princi-<br />pal components) from the 6128 genes. Factors 1 and 2 bear resemblance to those from<br />the model-based analysis, though the identification of questionable samples via two<br />“outlier factors” is significantly obscured by the confounding of idiosyncratic noise in<br />gene expression levels - a key inherent and limiting feature of empirical factor analyses<br />with many variables. The third empirical factor certainly relates to the ER discrimi-<br />nation, but again the signal is obscured and much less clearly defined than it is in the<br />model-based analysis.<br />05 10152025 30 35 404550<br />−2<br />0<br />2<br />4<br />05 10 1520 25 3035 40 4550<br />−5<br />0<br />5<br />05 10 1520 253035 4045 50<br />−4<br />−2<br />0<br />2<br />05 101520 2530 35 4045 50<br />−4<br />−2<br />0<br />2<br />Figure 5.<br />Four factors in sparse factor analysis of gene expression data<br />05 101520 25303540 4550<br />−0.5<br />0<br />0.5<br />1<br />05 1015 20 25303540 4550<br />−0.5<br />0<br />0.5<br />051015 2025 3035 40 4550<br />−0.5<br />0<br />0.5<br />05 101520 253035 4045 50<br />−0.5<br />0<br />0.5<br />Figure 6.<br />Four factors in SVD of gene expression data</p>  <p>Page 10</p> <p>10<br />Mike West<br />4. ADDITIONAL COMMENTS<br />Sparse factor regression models offer a promising framework for dimension reduction<br />in predictor space and for regression variable selection with many predictors.<br />small number of latent factors associate with the response (as in the breast cancer ER<br />study, where a single factor is primarily implicated) then a sparse factor model implies<br />that only those genes with non-zero loadings on those factors are relevant; variable<br />selection is then induced, automatically. In the ER study, only 60 genes have posterior<br />probability of non-zero values exceeding 0.5; most of these genes show up in our prior<br />studies and those of other groups exploring ER pathways in breast cancer.<br />Further, I have explored the full analysis of the sparse factor model combined with<br />binary regression in cross-validation studies of both ER and lymph node (LN) status<br />with this breast cancer data, comparing with results in West et al (2001). This prior<br />work uses gene selection/screening and SVD factor regression. The cross-validation<br />predictions are very similar, perhaps even slightly better with the sparse factor model.<br />I stress that this model uses all 6128 genes whereas our prior published analysis selects<br />100 based on correlation with ER or LN status, so removing noise via ad-hoc preliminary<br />variable selection. The comparability of predictions is very strong evidence for the<br />efficacy of the sparse modelling approach in dealing formally – and automatically – with<br />that most critical and challenging variable selection problem. Further development and<br />experience with this approach is needed, but these results are encouraging.<br />One challenging question is the identification, or estimation, of the number of fac-<br />tors. In some studies, simply increasing k and exploring posterior estimates of factors<br />and their variances suffices (Aguilar and West, 2000), though the problem remains an<br />open research area and utilising formal approaches is a challenge (Lopes and West,<br />1999). In the sparse factor model, using too few factors confounds higher-order struc-<br />ture in the factors being estimated and, in particular, induces likelihood functions that<br />very strongly suggest non-zero factor loadings for many gene-factor combinations than<br />might be expected on scientific grounds; this seems to be simply an artifact of the use of<br />too few factors. Though simple to diagnose, this problem is far from simple to resolve<br />as fitting large numbers of factors is significantly challenging in terms of computa-<br />tion. One current development is the implementation of these analysis on a distributed<br />machine (Beowulf cluster) which will aid progress on this challenging problem.<br />If a<br />ACKNOWLEDGEMENTS<br />This research was partially supported by the NSF (grants DMS-0102227 and DMS-<br />0112340). Some aspects of the work relate to collaborations with Ming Liao and Hed-<br />ibert Lopes. I am grateful to Marina Vanucci for provision of the biscuit dough data,<br />and for useful conversations with Jim Berger, Merlise Clyde and Rainer Spang.</p>  <p>Page 11</p> <p>Bayesian Factor Regression Models<br />11<br />REFERENCES<br />Albert, J. and Johnson, V.E. (1999) Ordinal Data Models. New York: Springer-Verlag.<br />Aguilar, O. and West, M. (2000) Bayesian dynamic factor models and portfolio allocation. Journal of<br />Business and Economic Statistics 18, 338-357.<br />Brown, P.J., Fearn, T. and Vannucci, M. (1999) The choice of variables in multivariate regression: a<br />non-conjugate Bayesian decision theory approach. Biometrika, 86, 635-648.<br />Lopes, H., and West, M. (1999) Model uncertainty in factor analysis. ISDS Discussion Paper #98-38.<br />Submitted for publication.<br />Osborne, B.G., Feran, T., Miller, A.R. and Douglas, S. (1984) Applications of near infrared reflectance<br />spectroscopy to compositional analysis of biscuits and biscuit doughs. J. Sci. Food Agric., 35, 99-105.<br />Spang, R., Zuzan, H., West. M., Nevins, J.R., Blanchette, C. and Marks, J.R. (2001) Prediction and<br />uncertainty in the analysis of gene expression profiles. In Silico Biology, 2, 0033.<br />West, M., Blanchette, C., Dressman, H., Huang, E., Ishida, S., Spang, R., Zuzan, H., Marks, J.R. and<br />Nevins, J.R. (2001) Predicting the clinical status of human breast cancer utilizing gene expression<br />profiles. Proceedings of the National Academy of Sciences, 98, 11462-11467.<br />West, M., Nevins, J.R., Marks, J.R, Spang, R. and Zuzan, H. (2000) DNA microarray data analysis and<br />regression modeling for genetic expression profiling. (Submitted for publication).<br />Zellner, A. (1986) On assessing prior distributions and Bayesian regression analysis with g−prior distri-<br />butions. In Bayesian Inference and Decision Techniques: Essays in Honor of Bruno de Finetti, (eds:<br />P.K. Goel and A. Zellner), pp233-243. Amsterdam: North-Holland.</p>   </div> <div id="rgw16_56ab9f94c85e2" class="c-box pub-resource-container js-toggle" style=""> <h4 class="lf js-expand-list"><small><a href="javascript:" class="lf">View other sources <span class="ico-expand-list"></span></a></small></h4> <h4 class="lf js-collapse-list hidden"><small><a href="javascript:" class="lf">Hide other sources <span class="ico-collapse-list"></span></a></small></h4> <div class="clear"></div> <div class="scroll-wrapper hidden"> <ul class="files-list c-list" id="rgw17_56ab9f94c85e2">  <li class="c-list-item pub-resource-item"  data-type="fulltext" id="rgw18_56ab9f94c85e2"> <span class="ico-pub"></span> <div class="file-content"> <div class="download"> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.18.3036&amp;amp;rep=rep1&amp;amp;type=pdf" target="_blank" rel="nofollow" class="publication-viewer" title="Bayesian Factor Regression Models in the &quot;Large p, Small n&quot; Paradigm">Bayesian Factor Regression Models in the &quot;Lar...</a> </div>  <div class="details">   Available from <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.18.3036&amp;amp;rep=rep1&amp;amp;type=pdf" target="_blank" rel="nofollow">psu.edu</a>  </div>    </div> </li>  </ul> </div> </div> </noscript> <div class="clearfix"> <div class="action-container">  </div> <div class="pub-legal"> Data provided are for informational purposes only. Although carefully collected, accuracy cannot be guaranteed. The impact factor represents a rough estimation of the journal's impact factor and does not reflect the actual current impact factor. Publisher conditions are provided by RoMEO. Differing provisions from the publisher's actual policy or licence agreement may be applicable. </div>   </div> </div> <div class="clearfix">     <div id="rgw20_56ab9f94c85e2" class="c-box pub-resource-container js-toggle" style="display: none;"> <h4 class="lf js-expand-list"><small><a href="javascript:" class="lf">View other sources <span class="ico-expand-list"></span></a></small></h4> <h4 class="lf js-collapse-list hidden"><small><a href="javascript:" class="lf">Hide other sources <span class="ico-collapse-list"></span></a></small></h4> <div class="clear"></div> <div class="scroll-wrapper hidden"> <ul class="files-list c-list" id="rgw21_56ab9f94c85e2">  </ul> </div> </div>   <div id="rgw12_56ab9f94c85e2" class="similar-publications"> <h2>Similar Publications</h2> <ul class="list-bordered">  <li class="c-list-item li-publication-teaser" id="rgw13_56ab9f94c85e2"> <div> <h5> <a href="publication/289601286_Cost-of-illness_analysis_and_regression_modeling_in_cystic_fibrosis_a_retrospective_prevalence-based_study" class="color-inherit ga-similar-publication-title"><span class="publication-title">Cost-of-illness analysis and regression modeling in cystic fibrosis: a retrospective prevalence-based study</span></a>  </h5>  <div class="authors"> <a href="researcher/2049393730_Tomas_Mlcoch" class="authors ga-similar-publication-author">Tomáš Mlčoch</a>, <a href="researcher/38307118_Jiri_Klimes" class="authors ga-similar-publication-author">Jiří Klimeš</a>, <a href="researcher/2014054695_Libor_Fila" class="authors ga-similar-publication-author">Libor Fila</a>, <a href="researcher/39280698_Vera_Vavrova" class="authors ga-similar-publication-author">Věra Vávrová</a>, <a href="researcher/32948395_Veronika_Skalicka" class="authors ga-similar-publication-author">Veronika Skalická</a>, <a href="researcher/2019501797_Marek_Turnovec" class="authors ga-similar-publication-author">Marek Turnovec</a>, <a href="researcher/75775513_Veronika_Krulisova" class="authors ga-similar-publication-author">Veronika Krulišová</a>, <a href="researcher/2092932904_Jitka_Jircikova" class="authors ga-similar-publication-author">Jitka Jirčíková</a>, <a href="researcher/38388047_Dana_Zemkova" class="authors ga-similar-publication-author">Dana Zemková</a>, <a href="researcher/2092791202_Klara_Vilimovska_Dedeckova" class="authors ga-similar-publication-author">Klára Vilimovská Dědečková</a>, <a href="researcher/2092846193_Alena_Bilkova" class="authors ga-similar-publication-author">Alena Bílková</a>, <a href="researcher/2092809848_Vladimira_Fruehaufova" class="authors ga-similar-publication-author">Vladimíra Frühaufová</a>, <a href="researcher/2092928336_Lukas_Homola" class="authors ga-similar-publication-author">Lukáš Homola</a>, <a href="researcher/2092866744_Zuzana_Friedmannova" class="authors ga-similar-publication-author">Zuzana Friedmannová</a>, <a href="researcher/2092824769_Radovan_Drnek" class="authors ga-similar-publication-author">Radovan Drnek</a>, <a href="researcher/2092894753_Pavel_Drevinek" class="authors ga-similar-publication-author">Pavel Dřevínek</a>, <a href="researcher/2004488904_Tomas_Dolezal" class="authors ga-similar-publication-author">Tomáš Doležal</a>, <a href="researcher/48178785_Milan_Macek" class="authors ga-similar-publication-author">Milan Macek</a>  </div>  </div> <div class="clear"></div> </li>  <li class="c-list-item li-publication-teaser" id="rgw14_56ab9f94c85e2"> <div> <h5> <a href="publication/281059314_Fixed-Size_Confidence_Regions_in_High-Dimensional_Sparse_Linear_Regression_Models" class="color-inherit ga-similar-publication-title"><span class="publication-title">Fixed-Size Confidence Regions in High-Dimensional Sparse Linear Regression Models</span></a>  </h5>  <div class="authors"> <a href="researcher/43380898_Ching-Kang_Ing" class="authors ga-similar-publication-author">Ching-Kang Ing</a>, <a href="researcher/2072761855_Tze_Leung_Lai" class="authors ga-similar-publication-author">Tze Leung Lai</a>  </div>  </div> <div class="clear"></div> </li>  <li class="c-list-item li-publication-teaser" id="rgw15_56ab9f94c85e2"> <div> <h5> <a href="publication/277023228_TPRM_Tensor_partition_regression_models_with_applications_in_imaging_biomarker_detection" class="color-inherit ga-similar-publication-title"><span class="publication-title">TPRM: Tensor partition regression models with applications in imaging biomarker detection</span></a>  </h5>  <div class="authors"> <a href="researcher/2034575269_Michelle_Miranda" class="authors ga-similar-publication-author">Michelle Miranda</a>, <a href="researcher/11154265_Hongtu_Zhu" class="authors ga-similar-publication-author">Hongtu Zhu</a>, <a href="researcher/10433168_Joseph_G_Ibrahim" class="authors ga-similar-publication-author">Joseph G. Ibrahim</a>  </div>  </div> <div class="clear"></div> </li>  </ul> </div> </div> </div> </div> </div></div></div>
<div class="clear"></div><div id="rgw26_56ab9f94c85e2" class="default-footer"> <div id="footer" class="clearfix"> <span class="footer-left"> &copy; 2008&dash;2016 researchgate.net. All rights reserved. </span> <span class="footer-right"> <a href="https://www.researchgate.net/about">About us</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="https://www.researchgate.net/contact">Contact us</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="careers">Careers</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="developers">Developers</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="blog" target="_blank">News</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="application.PrivacyPolicy.html">Privacy</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="application.TermsAndConditions.html">Terms</a> <span class="footer-link-separator" style="padding: 0 5px;">&nbsp;|&nbsp;</span> <a href="advertising?_ref=ft">Advertising</a> <span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="recruiters?_ref=ft">Recruiting</a> </span> </div>  </div></div>
<div id="rgw27_56ab9f94c85e2">  <div class="header-wrapper-logged-out"> <div id="header"> <div class="header-content"> <a href="" class="g-l-logo"> <svg width="149" height="19"> <image xlink:href="https://c5.rgstatic.net/m/235107188705592/images/template/brand-header-logo.svg" src="https://c5.rgstatic.net/m/238113351022438/images/template/brand-header-logo.png" width="149" height="19"/> </svg> </a> <a href="" class="g-l-logo-ico"> <svg width="127" height="17" viewbox="0 0 127 22"> <image xlink:href="https://c5.rgstatic.net/m/235107188705592/images/template/brand-header-logo.svg" src="https://c5.rgstatic.net/m/238113351022438/images/template/brand-header-logo.png" width="127" height="17"/> </svg> </a> <div id="rgw28_56ab9f94c85e2" class="header-login-wrapper js-header-login"> <div class="dropdown-right-align"> <div class="login-signup-container lf"> <a href="https://www.researchgate.net/signup.SignUp.html?ev=su_chnl_index&amp;hdrsu=1&amp;_sg=a-ug55A_HrrpygIJpUptuPV9HUQkt6hlP7MrvZ9jwaVKuAQYPqjtJwp2L_C7o4tE" class="dropdown-toggle lf">Join for free</a> </div> <div class="dropdown lf" style="height: 20px;"> <a href="https://www.researchgate.net/application.Login.html" class="js-login-url dropdown-toggle lf">Log in <span class="caret"></span></a> <div class="dropdown-menu"> <div class="header-login-form-wrapper"> <!--[if IE 6]><p class="box-warning" style="margin-bottom: 0;">Sorry, ResearchGate no longer supports the version of Internet Explorer you are using. <a href="http://whatbrowser.org/" rel="nofollow" target="_blank">Update your web browser</a> and then log in. </p><![endif]--> <form method="post" action="https://www.researchgate.net/application.Login.html" class="form-big header-login-form js-login-form" name="loginForm" id="headerLoginForm"> <input type="hidden" name="request_token" value="KEZ00dhvlNiN/izliU14g1phydRUUrjgJbea6yEnRFamwqV6dkAfEP1jvm9A+a+8jHG9HTCbIQmrwrHA4XF5HXWDMKoTChthn5JByoHuB2Qz+Ex2jFZWFKLDEoy9eyvwAUCg3bTT0HYjTkIWl2hnYXDAabJ6xYzZECqBgle9YtoNfUniFk8qBcKki53BJC7ww0nIxAT8uCLuJnWE98/kPAn8OOcKN5bD1D+CKhvYJ70EhrMuGUWkXk1jdLncL+QwLoTXvtafO7xGpV0FSkxuUNMzOXJyAVEN+dI6LcQyIgI="/> <input type="hidden" name="urlAfterLogin" value="publication/2522345_Bayesian_Factor_Regression_Models_in_the_Large_p_Small_n_Paradigm"/> <input type="hidden" name="invalidPasswordCount" value="0"/> <input type="hidden" name="headerLogin" value="yes"/> <label for="input-header-login">Email</label> <div class="login-input"> <div class="info-tip-wrapper"> <span class="ico-info js-info"></span> </div> <input type="email" value="" name="login" class="login js-login-input text" id="input-header-login" tabindex="1"/> </div> <div class="clear"></div> <label class="lf" for="input-header-password"> Password </label> <a class="rf forgot-password js-forgot-password" href="application.LostPassword.html">Forgot password?</a> <div class="clear"></div> <input type="password" value="" name="password" class="password js-password-input text" id="input-header-password" tabindex="2"/> <div class="clear"></div> <label class="remember-me" for="headerLoginCookie"> <input type="checkbox" checked="checked" value="yes" name="setLoginCookie" class="lf checkbox" id="headerLoginCookie" tabindex="3"/> Keep me logged in </label> <div class="clear"></div> <input value="Log in" name="loginSubmit" class="btn btn-promote btn-fullwidth btn-large allow-leave js-submit-button" type="submit" tabindex="4"/> </form> <div class="connectors"> <div class="text">or log in with</div> <div class="connector-actions"> <a href="connector/linkedin/" class="li-connect js-li-connect" data-redirect-url="cHVibGljYXRpb24vMjUyMjM0NV9CYXllc2lhbl9GYWN0b3JfUmVncmVzc2lvbl9Nb2RlbHNfaW5fdGhlX0xhcmdlX3BfU21hbGxfbl9QYXJhZGlnbQ%3D%3D"> <span class="icon ico-linkedin-round-grey"></span> <span class="icon ico-linkedin-round"></span> </a> <a href="connector/facebook/" class="fb-connect middle js-fb-connect" data-redirect-url="cHVibGljYXRpb24vMjUyMjM0NV9CYXllc2lhbl9GYWN0b3JfUmVncmVzc2lvbl9Nb2RlbHNfaW5fdGhlX0xhcmdlX3BfU21hbGxfbl9QYXJhZGlnbQ%3D%3D"> <span class="icon ico-facebook-round-grey"></span> <span class="icon ico-facebook-round"></span> </a> <a href="connector/google/" class="g-connect js-g-connect" data-redirect-url="cHVibGljYXRpb24vMjUyMjM0NV9CYXllc2lhbl9GYWN0b3JfUmVncmVzc2lvbl9Nb2RlbHNfaW5fdGhlX0xhcmdlX3BfU21hbGxfbl9QYXJhZGlnbQ%3D%3D"> <span class="icon ico-google-round-grey"></span> <span class="icon ico-google-round"></span> </a> </div> </div> </div> </div> </div> </div> </div> </div> </div> <script type="application/ld+json">
{ "@context" : "http://schema.org",
  "@type" : "Organization",
  "name" : "ResearchGate",
  "url" : "http://www.researchgate.net",
  "logo" : "http://www.researchgate.net/images/template/rg_logo_square_brand.png",
  "sameAs" : [ "https://www.facebook.com/ResearchGate",
    "https://twitter.com/ResearchGate",
    "https://plus.google.com/+researchgate",
    "https://www.linkedin.com/company/researchgate"] 
}
</script> </div> </div><div class="c-signup-bar" id="rgw29_56ab9f94c85e2"> <div class="banner-contents">   <span class="message">ResearchGate is the professional network for scientists and researchers.</span> <a href="signup.SignUp.html?ev=su_banner" class="btn btn-large btn-promote">Join for free</a>  </div> </div></div>
<script>
rgConfig.backendTime = 374;
</script>
<script src="//c5.rgstatic.net/m/2277196935388619/javascript/lib/yui3/yui/yui-min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/21832295316281274/javascript/yuiLoaderConfig-min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/23178613132105398/javascript/vendor/babel-core/browser-polyfill.min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/2198378204065/javascript/min/lib/error_logging.js" type="text/javascript"></script>
<script>
(function (){
if (typeof YRG === "undefined") {
var xmlHttpRequest = new XMLHttpRequest();
xmlHttpRequest.open("post", "go.Error.html");
xmlHttpRequest.setRequestHeader("Content-Type", "application/json");
xmlHttpRequest.setRequestHeader("Accept", "application/json"); var loadedScripts = "";
if (window.performance && window.performance.getEntriesByType) {
    var result = [];
    var resources = performance.getEntriesByType("resource");
    for (var i in resources) {
        if (resources.hasOwnProperty(i)) {
            result.push({
                name: resources[i].name,
                duration: resources[i].duration
            });
        }
    }
    loadedScripts += "&loadedScripts=" + encodeURIComponent(JSON.stringify(result));
}
if (typeof YUI === "undefined") {
    loadedScripts += "&yuiLoaded=false";
} else {
    loadedScripts += "&yuiLoaded=true";
}
xmlHttpRequest.send("Type=InformationException&message=" + encodeURIComponent("Error loading YUI") + loadedScripts);
}
})();
</script>
<script>if (typeof YRG !== 'undefined') { YRG.use('rg-base',function(Y){Y.applyConfig({ignore: ["css-rg","css-rg2","css-ie","css-modules-publicprofile"]});Y.use(["rg.core.pagespeed.Monitoring"],function(Y){(function(){Y.rg.createInitialWidget({"data":{"content":{"data":{"profileSmallHeader":{"data":{"profileBadge":{"data":{"profileUrl":"researcher\/10014083_Mike_West","fullname":"Mike West","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2549355721578\/images\/template\/default\/profile\/profile_default_m.png","profileStats":[null,{"data":{"publicationCount":1,"widgetId":"rgw5_56ab9f94c85e2"},"id":"rgw5_56ab9f94c85e2","partials":[],"templateName":"publicliterature\/stubs\/PublicLiteratureAuthorPublicationCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicLiteratureAuthorPublicationCount.html?authorUid=10014083","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},null],"widgetId":"rgw4_56ab9f94c85e2"},"id":"rgw4_56ab9f94c85e2","partials":[],"templateName":"publicprofile\/stubs\/ProfileBadge.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicLiteratureAuthorBadge.html?authorUid=10014083","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw3_56ab9f94c85e2"},"id":"rgw3_56ab9f94c85e2","partials":[],"templateName":"publicprofile\/stubs\/ProfileSmallHeader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicprofile.ProfileSmallHeader.html?publicationUid=2522345","viewClass":null,"yuiModules":["css-modules-publicprofile"],"stylesheets":["modules\/publicprofile.css"],"_isYUI":true},"publication":{"data":{"publicationUid":2522345,"title":"Bayesian Factor Regression Models in the \"Large p, Small n\" Paradigm","journalTitle":false,"journalDetailsTooltip":false,"affiliation":false,"type":"Article","details":{"journalInfos":{"journal":"Bayesian Stat","publicationDate":"08\/2002;","publicationDateRobot":"2002-08","article":"7."}},"source":{"sourceUrl":"http:\/\/citeseer.ist.psu.edu\/525895.html","sourceName":"CiteSeer"},"publicationActions":null,"publicationCoins":{"data":{"tags":[{"key":"ctx_ver","value":"Z39.88-2004"},{"key":"rft_val_fmt","value":"info:ofi\/fmt:kev:mtx:journal"},{"key":"rfr_id","value":"info:sid\/researchgate.net:researchgate"},{"key":"rft.atitle","value":"Bayesian Factor Regression Models in the \"Large p, Small n\" Paradigm"},{"key":"rft.title","value":"Bayesian Stat."},{"key":"rft.jtitle","value":"Bayesian Stat."},{"key":"rft.volume","value":"7"},{"key":"rft.date","value":"2002"},{"key":"rft.au","value":"Mike West"},{"key":"rft.genre","value":"article"}],"widgetId":"rgw7_56ab9f94c85e2"},"id":"rgw7_56ab9f94c85e2","partials":[],"templateName":"publicliterature\/stubs\/PublicationCoins.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationCoins.html?publicationUid=2522345","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationAuthors":{"data":{"publicationUid":2522345,"peopleItems":[{"data":{"authorUrl":"researcher\/10014083_Mike_West","authorNameOnPublication":"Mike West","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg","imageSize":"s","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Mike West","profile":{"professionalInstitution":{"professionalInstitutionName":false,"professionalInstitutionUrl":null}},"professionalInstitutionName":false,"professionalInstitutionUrl":null,"url":"researcher\/10014083_Mike_West","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":true,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":false,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"widgetId":"rgw10_56ab9f94c85e2"},"id":"rgw10_56ab9f94c85e2","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAuthorItem.html?entityId=10014083&imageSize=l&enableAuthorInviteButton=0","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"largeTooltip":false,"useRebrandedImageStyle":null,"widgetId":"rgw9_56ab9f94c85e2"},"id":"rgw9_56ab9f94c85e2","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorItem.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorItem.html?authorUid=10014083&authorNameOnPublication=Mike%20West","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true}],"hasMore":false,"nextOffset":6,"useRebrandedImageStyle":null,"widgetId":"rgw8_56ab9f94c85e2"},"id":"rgw8_56ab9f94c85e2","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorList.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorList.html?publicationUid=2522345&context=pubdetail_authors_xflw&showContactAuthorButton=1","viewClass":"views.publicliterature.PublicationDetailAuthorListView","yuiModules":["rg.views.publicliterature.PublicationDetailAuthorListView"],"stylesheets":[],"_isYUI":true},"publicationAbstract":{"data":{"publicationUid":2522345,"abstract":"<noscript><\/noscript><div>TOR REGRESSION MODELS 1.1 SVD Regression Begin with the linear model y = X# + # where y is the n-vector of responses, X is the n p matrix of predictors, # is the p-vector regression parameter, and # , # I) is the n-vector error term. Of key interest are cases when p &gt;&gt; n, when X is &quot;long and skinny.&quot; The standard empirical factor (principal component) regression is best represented using the reduced singular-value decomposition (SVD) of X, namely X = FA where F is the nk factor matrix (columns are factors, rows are samples) and A is the k p SVD &quot;loadings&quot; matrix, subject to AA # = I and F # F = D where D is the diagonal matrix of k positive singular values, arranged in decreasing order. This reduced form assumes factors with zero singular values have been ignored without loss; k with equality only if all singular values are positive. Now the regression transforms via X# = F# where # = A# is the k-vector of regression parameters for the factor variables, representing<\/div>","canEdit":false,"isAdmin":false,"isArtifact":false,"showFullAbstract":true,"widgetId":"rgw11_56ab9f94c85e2"},"id":"rgw11_56ab9f94c85e2","partials":[],"templateName":"publicliterature\/stubs\/PublicationAbstract.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationAbstract.html?publicationUid=2522345","viewClass":"views.publicliterature.PublicationAbstractView","yuiModules":["rg.views.publicliterature.PublicationAbstractView"],"stylesheets":[],"_isYUI":true},"publicationKeywords":null,"publicationState":null,"isGuest":true,"isAdminEditingAllowed":false,"isArtifact":false,"figureListWidget":null,"previewImage":"https:\/\/i1.rgstatic.net\/publication\/2522345_Bayesian_Factor_Regression_Models_in_the_Large_p_Small_n_Paradigm\/links\/0e5fab20f0c41c4932e308d6\/smallpreview.png","nativeAdDisclosure":null,"showFollowPublicationButton":false,"followPublicationPromo":"","widgetId":"rgw6_56ab9f94c85e2"},"id":"rgw6_56ab9f94c85e2","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailItem.html","templateExtensions":["generalHelpers"],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailItem.html?publicationUid=2522345&showActionBar=0&showContactAuthorButton=1&showRequestFulltextExperience=0&showNoRgAuthorsRequestFulltextExperience=0&showFollowPublicationPromo=0","viewClass":"views.publicliterature.PublicationDetailItemView","yuiModules":["rg.views.publicliterature.PublicationDetailItemView"],"stylesheets":[],"_isYUI":true},"similarPublications":{"data":{"publicationListItems":[{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":2049393730,"url":"researcher\/2049393730_Tomas_Mlcoch","fullname":"Tom\u00e1\u0161 Ml\u010doch","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":38307118,"url":"researcher\/38307118_Jiri_Klimes","fullname":"Ji\u0159\u00ed Klime\u0161","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2014054695,"url":"researcher\/2014054695_Libor_Fila","fullname":"Libor Fila","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":{"id":39280698,"url":"researcher\/39280698_Vera_Vavrova","fullname":"V\u011bra V\u00e1vrov\u00e1","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},"surplusAuthors":14,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Jan 2016","journal":"The European Journal of Health Economics","showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/289601286_Cost-of-illness_analysis_and_regression_modeling_in_cystic_fibrosis_a_retrospective_prevalence-based_study","usePlainButton":true,"publicationUid":289601286,"feedStubs":null,"hasFeedStubs":false,"impactPoints":"2.10","url":"publication\/289601286_Cost-of-illness_analysis_and_regression_modeling_in_cystic_fibrosis_a_retrospective_prevalence-based_study","title":"Cost-of-illness analysis and regression modeling in cystic fibrosis: a retrospective prevalence-based study","displayTitleAsLink":true,"authors":[{"id":2049393730,"url":"researcher\/2049393730_Tomas_Mlcoch","fullname":"Tom\u00e1\u0161 Ml\u010doch","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":38307118,"url":"researcher\/38307118_Jiri_Klimes","fullname":"Ji\u0159\u00ed Klime\u0161","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2014054695,"url":"researcher\/2014054695_Libor_Fila","fullname":"Libor Fila","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":39280698,"url":"researcher\/39280698_Vera_Vavrova","fullname":"V\u011bra V\u00e1vrov\u00e1","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":32948395,"url":"researcher\/32948395_Veronika_Skalicka","fullname":"Veronika Skalick\u00e1","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2019501797,"url":"researcher\/2019501797_Marek_Turnovec","fullname":"Marek Turnovec","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":75775513,"url":"researcher\/75775513_Veronika_Krulisova","fullname":"Veronika Kruli\u0161ov\u00e1","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2092932904,"url":"researcher\/2092932904_Jitka_Jircikova","fullname":"Jitka Jir\u010d\u00edkov\u00e1","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":38388047,"url":"researcher\/38388047_Dana_Zemkova","fullname":"Dana Zemkov\u00e1","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2092791202,"url":"researcher\/2092791202_Klara_Vilimovska_Dedeckova","fullname":"Kl\u00e1ra Vilimovsk\u00e1 D\u011bde\u010dkov\u00e1","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2092846193,"url":"researcher\/2092846193_Alena_Bilkova","fullname":"Alena B\u00edlkov\u00e1","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2092809848,"url":"researcher\/2092809848_Vladimira_Fruehaufova","fullname":"Vladim\u00edra Fr\u00fchaufov\u00e1","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2092928336,"url":"researcher\/2092928336_Lukas_Homola","fullname":"Luk\u00e1\u0161 Homola","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2092866744,"url":"researcher\/2092866744_Zuzana_Friedmannova","fullname":"Zuzana Friedmannov\u00e1","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2092824769,"url":"researcher\/2092824769_Radovan_Drnek","fullname":"Radovan Drnek","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2092894753,"url":"researcher\/2092894753_Pavel_Drevinek","fullname":"Pavel D\u0159ev\u00ednek","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2004488904,"url":"researcher\/2004488904_Tomas_Dolezal","fullname":"Tom\u00e1\u0161 Dole\u017eal","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":48178785,"url":"researcher\/48178785_Milan_Macek","fullname":"Milan Macek","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["The European Journal of Health Economics 01\/2016;  DOI:10.1007\/s10198-015-0759-9"],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/289601286_Cost-of-illness_analysis_and_regression_modeling_in_cystic_fibrosis_a_retrospective_prevalence-based_study","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/289601286_Cost-of-illness_analysis_and_regression_modeling_in_cystic_fibrosis_a_retrospective_prevalence-based_study\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw13_56ab9f94c85e2"},"id":"rgw13_56ab9f94c85e2","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=289601286","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":43380898,"url":"researcher\/43380898_Ching-Kang_Ing","fullname":"Ching-Kang Ing","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2072761855,"url":"researcher\/2072761855_Tze_Leung_Lai","fullname":"Tze Leung Lai","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Jul 2015","journal":"Sequential Analysis","showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/281059314_Fixed-Size_Confidence_Regions_in_High-Dimensional_Sparse_Linear_Regression_Models","usePlainButton":true,"publicationUid":281059314,"feedStubs":null,"hasFeedStubs":false,"impactPoints":"0.50","url":"publication\/281059314_Fixed-Size_Confidence_Regions_in_High-Dimensional_Sparse_Linear_Regression_Models","title":"Fixed-Size Confidence Regions in High-Dimensional Sparse Linear Regression Models","displayTitleAsLink":true,"authors":[{"id":43380898,"url":"researcher\/43380898_Ching-Kang_Ing","fullname":"Ching-Kang Ing","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2072761855,"url":"researcher\/2072761855_Tze_Leung_Lai","fullname":"Tze Leung Lai","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["Sequential Analysis 07\/2015; 34(3). DOI:10.1080\/07474946.2015.1063258"],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/281059314_Fixed-Size_Confidence_Regions_in_High-Dimensional_Sparse_Linear_Regression_Models","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/281059314_Fixed-Size_Confidence_Regions_in_High-Dimensional_Sparse_Linear_Regression_Models\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw14_56ab9f94c85e2"},"id":"rgw14_56ab9f94c85e2","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=281059314","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":2034575269,"url":"researcher\/2034575269_Michelle_Miranda","fullname":"Michelle Miranda","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":11154265,"url":"researcher\/11154265_Hongtu_Zhu","fullname":"Hongtu Zhu","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":10433168,"url":"researcher\/10433168_Joseph_G_Ibrahim","fullname":"Joseph G. Ibrahim","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"May 2015","journal":null,"showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/277023228_TPRM_Tensor_partition_regression_models_with_applications_in_imaging_biomarker_detection","usePlainButton":true,"publicationUid":277023228,"feedStubs":null,"hasFeedStubs":false,"impactPoints":false,"url":"publication\/277023228_TPRM_Tensor_partition_regression_models_with_applications_in_imaging_biomarker_detection","title":"TPRM: Tensor partition regression models with applications in imaging biomarker detection","displayTitleAsLink":true,"authors":[{"id":2034575269,"url":"researcher\/2034575269_Michelle_Miranda","fullname":"Michelle Miranda","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":11154265,"url":"researcher\/11154265_Hongtu_Zhu","fullname":"Hongtu Zhu","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":10433168,"url":"researcher\/10433168_Joseph_G_Ibrahim","fullname":"Joseph G. Ibrahim","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":[],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/277023228_TPRM_Tensor_partition_regression_models_with_applications_in_imaging_biomarker_detection","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/277023228_TPRM_Tensor_partition_regression_models_with_applications_in_imaging_biomarker_detection\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw15_56ab9f94c85e2"},"id":"rgw15_56ab9f94c85e2","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=277023228","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"viewClass":"sidebar","widgetId":"rgw12_56ab9f94c85e2"},"id":"rgw12_56ab9f94c85e2","partials":[],"templateName":"publicliterature\/stubs\/SimilarPublications.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.SimilarPublications.html?referencePublicationId=2522345&view=sidebar","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationFulltextPreview":null,"publicationResourcesFulltext":{"data":{"publicationUid":2522345,"publicationResourceList":{"data":{"publicationResourceItems":[{"data":{"publicationUid":2522345,"publicationType":"article","linkId":"0e5fab20f0c41c4932e308d6","fileName":"Bayesian Factor Regression Models in the \"Large p, Small n\" Paradigm","fileUrl":"http:\/\/citeseerx.ist.psu.edu\/viewdoc\/download?doi=10.1.1.18.3036&amp;rep=rep1&amp;type=pdf","name":"psu.edu","nameUrl":"http:\/\/citeseerx.ist.psu.edu\/viewdoc\/download?doi=10.1.1.18.3036&amp;rep=rep1&amp;type=pdf","canRemove":false,"fileIcon":"ico-pub","canPreview":true,"hasPublisherLink":null,"hasMetaData":true,"hide":false,"fulltext":"ico-pub","origin":"publication_list","isLastLink":true,"isUserLink":false,"widgetId":"rgw18_56ab9f94c85e2"},"id":"rgw18_56ab9f94c85e2","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceItem.html","templateExtensions":["generalHelpers"],"attrs":{"fileRequiredPublicationTypes":["code","coverPage","experimentFindings","method","negativeResults","presentation","rawData","researchProposal","workingPaper","artifact","dataset"]},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceItem.html?publicationUid=2522345&linkId=0e5fab20f0c41c4932e308d6&hide=0&disableJavascript=disableJavascript&useAlternativeTemplate=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"widgetId":"rgw17_56ab9f94c85e2"},"id":"rgw17_56ab9f94c85e2","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceList.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceList.html?publicationUid=2522345&limit=3&disableJavascript=disableJavascript&type=fulltextFile","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"resourceCount":1,"hidden":false,"showMore":false,"fulltext":true,"publicationDownloadCount":{"data":{"value":3,"valueFormatted":"3","widgetId":"rgw19_56ab9f94c85e2"},"id":"rgw19_56ab9f94c85e2","partials":[],"templateName":"publicliterature\/stubs\/PublicationDownloadCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDownloadCount.html?publicationUid=2522345","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw16_56ab9f94c85e2"},"id":"rgw16_56ab9f94c85e2","partials":[],"templateName":"publicliterature\/stubs\/PublicationResources.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResources.html?publicationUid=2522345&type=fulltextFile&disableJavascript=1","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationResourcesAttachments":{"data":{"publicationUid":2522345,"publicationResourceList":{"data":{"publicationResourceItems":[],"widgetId":"rgw21_56ab9f94c85e2"},"id":"rgw21_56ab9f94c85e2","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceList.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceList.html?publicationUid=2522345&limit=3&disableJavascript=disableJavascript&type=attachmentFile","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"resourceCount":0,"hidden":true,"showMore":false,"fulltext":false,"publicationDownloadCount":{"data":{"value":3,"valueFormatted":"3","widgetId":"rgw22_56ab9f94c85e2"},"id":"rgw22_56ab9f94c85e2","partials":[],"templateName":"publicliterature\/stubs\/PublicationDownloadCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDownloadCount.html?publicationUid=2522345","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw20_56ab9f94c85e2"},"id":"rgw20_56ab9f94c85e2","partials":[],"templateName":"publicliterature\/stubs\/PublicationResources.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResources.html?publicationUid=2522345&type=attachmentFile","viewClass":"views.publicliterature.PublicationResourcesView","yuiModules":["rg.views.publicliterature.PublicationResourcesView"],"stylesheets":[],"_isYUI":true},"publicationText":{"data":{"hide":false,"pages":[{"page":1,"text":"Bayesian Factor Regression Models\nin the \u201cLarge p, Small n\u201d Paradigm\nMIKE WEST\nISDS, Duke University, Durham, NC 27708, USA\nmw@isds.duke.edu\nSUMMARY\nI discuss Bayesianfactor regressionmodels and prediction with very many explanatory variables.\nSuch problems arise in many areas; my motivating applications are in studies of gene expression\nin functional genomics. I first discuss empirical factor (principal components) regression, and\nthe use of general classes of shrinkage priors, with an example. These models raise foundational\nquestions for Bayesians, and related practical issues, due to the use of design-dependent priors\nand the need to recover inferences on the effects of the original, high-dimensional predictors.\nI then discuss latent factor models for high-dimensional variables, and regression approaches\nin which low-dimensional latent factors are the predictor variables. These models generalise\nempirical factor regression, provide for more incisive evaluation of factor structure underlying\nhigh-dimensional predictors, and resolve the philosophical and practical issues in empirical\nfactor models by casting the latter as limiting special cases. Finally, I turn to questions of prior\nspecification in these models, and introduce sparse latent factor models to induce substantively\nrelevant structure in the high-dimensional distributions of predictors. Embedding such sparse\nlatent factor models in factor regressions provides a novel approach to variable selection with\nvery many predictors. The paper concludes with an example of sparse factor analysis of gene\nexpression data and comments about further research.\nKeywords:\nDIMENSION REDUCTION, GENE EXPRESSION ANALYSIS, HIGH-DIMENSIONAL\nCOVARIATES, LATENT FACTOR MODELS, SHRINKAGE PRIORS.\n1. EMPIRICAL FACTOR REGRESSION MODELS\n1.1 SVD Regression\nBegin with the linear model y = X\u03b2 + ? where y is the n\u2212vector of responses, X is the\nn\u00d7p matrix of predictors, \u03b2 is the p\u2212vector regression parameter, and ? \u223c N(?|,\u03c32I)\nis the n\u2212vector error term. Of key interest are cases when p >> n, when X is \u201clong and\nskinny.\u201d The standard empirical factor (principal component) regression is best repre-\nsented using the reduced singular-value decomposition (SVD) of X, namely X = FA\nwhere F is the n\u00d7k factor matrix (columns are factors, rows are samples) and A is the\nk \u00d7 p SVD \u201cloadings\u201d matrix, subject to AA?= I and F?F = D2where D is the di-\nagonal matrix of k positive singular values, arranged in decreasing order. This reduced\nform assumes factors with zero singular values have been ignored without loss; k \u2264 n\nwith equality only if all singular values are positive. Now the regression transforms\nvia X\u03b2 = F\u03b8 where \u03b8 = A\u03b2 is the k\u2212vector of regression parameters for the factor\nvariables, representing a possibly massive dimension reduction from p to k parameters.\nInherently, observing y provides information only on the underlying factor regres-\nsion parameters \u03b8, so prior specification directly in factor space has become common.\nGeneralised shrinkage (or ridge regression) priors on \u03b8 have become popular as MCMC"},{"page":2,"text":"2\nMike West\nmethods now permit their routine use. A particularly flexible class of such priors as-\nsumes independent T distributions for the elements \u03b81,...,\u03b8k of \u03b8, so allowing for\nvarying degrees of shrinkage in each of the orthogonal factor dimensions. Independent\npriors are suggested in view of orthogonality of the factors. A particular example has\n\u03b8i\u223c N(\u03b8i|0,ci\/\u03c6i) where \u03c6i\u223c Ga(\u03c6i|r\/2,r\/2) independently, for some r > 0; the tun-\ning parameter r is the degree-of-freedom parameter for the implied T distribution for \u03b8i\nthat follows on marginalisation over the random precision \u03c6i. Here the ciare specified\nweights that may be used, for example, to indicate the prior view that higher-order fac-\ntors are expected to play lesser roles in the regression \u2013 often, though not necessarily,\nthe case. In the first example below this is the case, and the model uses ci= i\u22122, for\nexample. This also allows for removal of factors in prior specification, by setting a ci\nto zero. Analyses typically also adopt inverse gamma priors for the error variance \u03c32.\nThese models are evidently easily implemented using MCMC. The complete condi-\ntional posterior for \u03b8 given the \u03c6iis multivariate normal, and the \u03c6iare conditionally\nindependent gamma variates given \u03b8. The example below \u2013 like many others I have\nexplored \u2013 utilises this to generate sequences of posterior samples for \u03b8 and the \u03c6i, and\nMCMC convergence is generally clean and swift.\n1.2 Coherence and Inference on Original Regression Parameters\nA fundamental issue \u2013 philosophical and practical \u2013 arises from the explicit design-, and\nsample size-, dependence of the empirical factor model. The key \u03b8 parameter is directly\ndefined as a function of X and \u03b2. The former dependency raises, for Bayesians, the\nfoundational question of whether this is in fact a valid Bayesian model. The parameter\ndefinition changes as the sample size and design changes; the specification of priors over\nthese design-dependent parameters must be coherent with respect to changing n and\nX. I address and answer this, fully and affirmatively, in Section 2.\nA related practical issue is that of inference on the original regression parameters \u03b2.\nThe framework has priors and posteriors for \u03b8, but leaves open questions of \u201cinverting\u201d\nthe dimension-reducing map to make inferences on \u03b2. The many-one map \u03b8 = A\u03b2 has\nmultiple generalised inverses \u03b2 = A?\u03b8 + b for all p\u2212vectors b such that Ab = 0. Again,\nthis issue is fully resolved in Section 2. Here, simply note that, for predictive purposes,\nthe choice of b is irrelevant. A canonical choice of generalised inverse is the standard\n\u201cleast-norm\u201d inverse based on b = 0, i.e., \u03b2\u2217= A?\u03b8. The analysis in the example below\nuses \u03b2\u2217; again, Section 2 explains and justifies this properly. Posterior samples for \u03b8\ntrivially imply samples for \u03b2\u2217which may be summarised for inference.\nOne interesting connection to make is that the prior on \u03b2\u2217implied by the prior on\n\u03b8 of Section 1.1 above is a generalisation of the g\u2212prior of Zellner (1986). Given condi-\ntional N(\u03b8i|0,ci\/\u03c6i) priors, the implied prior for \u03b2 = \u03b2\u2217is (massively singular) normal\nwith density proportional to exp{\u2212\u03b2?A?GA\u03b2\/2}, where G is diagonal with elements\n\u03c6i\/ci. This makes explicit the design-dependency of the prior and also the individual\nscaling in each of the singular factor dimensions. The Zellner g\u2212prior corresponds to\ntaking G = gD2for some positive scalar g > 0. I therefore refer to this approach as\ndefining a class of generalised singular g\u2212priors (or gsg\u2212priors)."},{"page":3,"text":"Bayesian Factor Regression Models\n3\n1.3 Prediction\nPrediction is practically straightforward, though raises foundational questions related\nto the design-dependency issue. Technically, response values to be predicted are simply\ntreated as missing values to be imputed, and the MCMC analysis is trivially extended to\nsample these values at each iteration. That is, y is partitioned into a vector of training\nsamples, yt, and a vector of validation cases yv to be predicted; the design matrix\nis conformably partitioned as [Xt;Xv].The MCMC imputes yv from the implied\n(normal) conditional posterior. This requires that the model is specified and analysed\nconditional on all predictor values, including Xv, and the empirical factor regression\nmodel is based on decomposition of the full X matrix. As a result, the factors F are\nevaluated based on predictors Xvas well as Xt; thus Xvforms part of the model and\nprior structure even though the corresponding responses are missing. One message is\nthat required predictor values must be contemplated prior to analysis, or analysis fully\nrepeated if new predictions are required.\nAgain, this apparent issue is interpreted and resolved in Section 2 where the empiri-\ncal model is understood to arise from a more elaborate latent factor regression model. In\nthe example now, this approach is simply adopted for prediction of validation samples.\n1.4 Example: Analysis of Biscuit Dough Data\nThis example concerns biscuit dough data analysed in Brown et al (1999), and orig-\ninally in Osborne et al (1984). The study aims to predict biscuit dough constituents\nbased on spectral characteristics of dough measured using near infrared (NIR) spec-\ntroscopy. Hence the predictor for each dough sample is a reflectance spectrum on a grid\nof wavelengths. The analysis here uses the same data as Brown et al (although their\nframework is multivariate). The response chosen here is fat content of dough samples,\nthe predictors are p = 300 NIR reflectance measures at equally spaced wavelengths\nover 1202\u22122400 nanometres (nm), and there are 39 training samples and 39 validation\ncases to be predicted. The fat content response is standardised, and here the predictors\nare centred, based on the means and standard deviations in the training sample. The\ncentred spectra are graphed in Figure 1.\n1200 14001600 18002000 22002400\n\u22120.2\n\u22120.15\n\u22120.1\n\u22120.05\n0\n0.05\n0.1\n0.15\n0.2\n0.25\n0.3\nwavelength (nm)\nstandardised spectrum\nFigure 1.\nCentred spectra predictors of 78 biscuit dough samples"},{"page":4,"text":"4\nMike West\nSeveral analyses have been studied, varying the tuning parameters r and ci. A\nsummary of analysis with r = 5 and ci= i\u22122is given here; analyses with r between 1\nand 10 give substantially similar results, and r = 5 is marginally optimal as measured\nsimply by the mean square prediction error computed in the validation sample. The\nprior for \u03c3\u22122is unit mean exponential, reflecting the known range of the standardised\nresponse data but otherwise representing a relatively diffuse prior. The singular values\nof the 300\u00d778 matrix X decay rapidly and are truncated to zero, with the corresponding\nfactors dropped, past the point where 99.995% of the total variation, as measured by\nthe cumulative sum of squares of the di, is accounted for; this leads to k = 16 factors\nin the model, with ci = 0 for i > 16. This reduced number is consistent with the\ninherent smoothness of the predictor variable, and will generally be experienced when\npredictors are curves. The MCMC analysis summarised has 20,000 samples selected\nfrom a run of 100,000 by choosing every fifth sample, and following a burn-in of 1,000\nsamples. Convergence is swift and clean, consistent with experiences with a range of\nother examples and MCMC experiments.\n0246810121416\n\u221215\n\u221210\n\u22125\n0\n5\n10\n15\n20\n25\ntheta\nfactor index\nFigure 2.\nBiscuit dough analysis: Estimates of empirical factor regression coefficients \u03b8\nFigures 2 and 3 graph the approximate posterior means of \u03b8 and \u03b2\u2217= A?\u03b8, re-\nspectively, the former with equal-tails 90% posterior intervals. Figure 3 uses asterisks\nto mark the ten \u03b2\u2217\nsmall cluster at just over 1700nm, at values 1718, 1722, 1726, 1730 and 1734. These are\nnoteworthy since, as remarked by Brown et al, this is a region where fat is known to\nhave a characteristic absorbance; Brown et al identify the point 1718nm too. In Figure\n1 it is possible to discern small wiggles in the spectra in this wavelength region.\nFigure 4 addresses prediction and model assessment via display of data plotted\nagainst fitted and predicted values; training data are indicated by asterisks, and val-\nidation data by circles. The close concordance between observed and fitted\/predicted\nvalues (as well as several other exploratory residual analyses, not reported) give no\nreason to question model fit. Of particular interest is the fact that the out-of-sample\npredictions are very accurate indeed. In fact, on the basis of simple mean square pre-\ndiction errors, this analysis improves on results of Brown et al, albeit only marginally.\nivalues with largest absolute posterior means. Of these, there is a"},{"page":5,"text":"Bayesian Factor Regression Models\n5\n120014001600 18002000 2200 2400\n\u22126\n\u22124\n\u22122\n0\n2\n4\n6\nwavelength (nm)\nbeta\nFigure 3.\nBiscuit dough analysis: Estimates of wavelength regression coefficients \u03b2\u2217\n\u22123\u22122 \u22121\nfitted and predicted values\n0123\n\u22123\n\u22122\n\u22121\n0\n1\n2\n3\nresponse y\nFigure 4.\nBiscuit dough analysis: Response versus fitted and predicted values\nThis analysis has been repeated using the full p = 700 wavelengths in the original\ndata set, rather than the 300 selected by Brown et al. This results in substantially\nsimilar posterior means for the \u03b2\u2217over a finer grid of wavelengths, and with the largest\nabsolute values of posterior means all peaked around the key 1718nm position."},{"page":6,"text":"6\nMike West\n2. LATENT FACTOR REGRESSION MODELS\nEmpirical factor decompositions suffer a number of drawbacks, chief among which is the\nconfounding of noise in the inherent empirical estimation of common factors. Formal\nlatent factor models address this directly, aiming to extract variation that is idiosyn-\ncratic to each variable and decouple these \u201cnoise\u201d components from the assessment of\nunderlying common factor structure. Here I note the theoretical structure of latent\nfactor models and define a class of factor regression models that naturally relate un-\nderlying latent structure in high-dimensional predictors to responses. I show that the\nempirical model of Section 1 arises as a limiting case; this explains and justifies the\ndesign-dependency issues discussed in Section 1.\nWrite xifor the ithcolumn of X and consider the latent factor model (e.g., Aguilar\nand West, 2000; Lopes and West, 1999)\nxi= B\u03bbi+ \u03bdi\n(1)\nwhere\n\u03bbi\u223c N(\u03bbi|0,\u22062) and\n\u03bdi\u223c N(\u03bdi|0,\u03a82).\n(2)\nHere \u03bbiis a k\u2212vector of uncertain latent factors for case i, B is a p\u00d7k factor loadings\nmatrix parameter, and \u03bdiis a vector of idiosyncratic noise terms; both \u2206 and \u03a8 are\ndiagonal. The number of factors is fixed and k << p. With appropriate identifying\nconstraints on B, this is an estimable model that attributes common structure in X to\nunderlying k\u2212dimensional factors, and isolates variation that is purely idiosyncratic in\nthe \u03bditerms. MCMC based Bayesian analysis, and aspects of identification and prior\nspecification, appear in Lopes and West (1999) and, in more elaborate factor models\nin time series, in Aguilar and West (2000).\nNow assume that the responses y = (y1,...,yn)?relate directly to the k latent\nfactors; for each i,\nyi= \u03bb?\nwhere\nThe original design variables xiprovide information on the latent variables through\n(1), but do not enter the regression; yiis conditionally independent of xigiven \u03bbi. One\nimplication is that idiosyncratic variation in X now has no influence on the regression.\nIn Section 3 I discuss and exemplify analysis of the latent factor model alone; space\nhere precludes full development of analysis and examples of the linked factor regression\nmodels, but it is of key interest to consider a theoretical limiting special case under the\nnatural prior specification \u03b8 \u223c N(\u03b8|0,G\u22121) with diagonal precision matrix G.\nEquations (1-3) imply a joint normal distribution for (yi,xi,\u03bbi), and hence an\nimplied conditional distribution for yigiven only xiand the model parameters. After\nsome algebra, this is\n(yi|xi) \u223c N(yi|x?\nwhere \u03b2 = \u03a8\u22122BC\u03b8 with C\u22121= \u2206\u22122+ B?\u03a8\u22122B. Clearly the implied regression of\nyi on xi is linear, with a theoretically implied and unique extension of the (low-\ndimensional) factor regression parameter \u03b8 to the (high-dimensional) predictor regres-\nsion parameter \u03b2. Further, under the specific prior for \u03b8, there is a unique (singular\nnormal) prior implied for \u03b2.\nConsider now the special case in which \u03a8 = sI, and in which identification is\nenforced by assuming B to be orthogonal. Then C is diagonal with elements s2d2\nd2\ni\u03b8 + ?i\n?i\u223c N(?i|0,\u03c32).\n(3)\ni\u03b2,\u03c32+ \u03b8?C\u03b8)(4)\ni\/(s2+\ni) where the diare the elements of the diagonal matrix \u2206. Now take the limit as s \u2192 0,"},{"page":7,"text":"Bayesian Factor Regression Models\n7\nso that the latent factors explain essentially all the variation in the predictors. Then\n(1) reduces to xi= B\u03bbior, in matrix form, X = \u039bB?where \u039b has rows \u03bb?\nn \u2265 k, this recovers the SVD decomposition of X with B = A?, and this limiting special\ncase of the latent factor model defines the empirical factor model. In this limit, it also\neasily follows that \u03b2 = A?\u03b8. Under the chosen prior N(\u03b8 |0,G\u22121) with G diagonal, it\nfollows that \u03b2 has precisely the gsg\u2212prior of Section 1.2.\nHence, this special limiting case of a formal latent factor model leads to the SVD\nregression and the gsg\u2212prior. The tie-up is exact, and explains away the issues of\ndesign-, and sample size-, dependence of the parameter and prior, and of recovering\ninferences on the regression in the original predictor variables. Inference on \u03b2 flows\ndirectly from that on \u03b8. All predictor values for validation cases must be included in\nthe analysis of training data as they inform, under (1), on parameters of the latent\nfactor model and therefore, indirectly, on values of the latent factors underlying the\ntraining data.\ni. Assuming\n3. SPARSE FACTOR MODELS\n3.1 Motivating Applications in Gene Expression Profiling\nOriginal motivation for this work comes from gene expression analysis in which\npredictors are genes and p may range up to 30,000. Our studies (Spang et al 2001; West\net al 2000, 2001) involve binary regression. A probit model is trivially constructed by\ntreating the yi as latent and observing only indicators of yi> 0. Logistic and other\nvariants are also standard extensions (Albert and Johnson, 1999, ch. 3). Our use of\ngeneralised shrinkage priors and high-dimensional predictors since 1999 is innovative,\nand has been used in gene expression profiling for nearly three years now (1999-2002);\nas reflected by several presentations at the 2002 Valencia VII conference alone, our\napproach has been influential in statistics as well as bioinformatics.\nIn gene expression profiling, the predictor variables are recorded expression levels of\nindividual genes, and the responses are clinical or physiological outcomes. Inherently,\nmultiple biological factors underlie patterns of gene expression variation, so latent factor\napproaches are natural \u2013 we imagine that latent factors reflect individual biological\nfunctions (gene networks or pathways). This is also a motivating context for sparse\nmodels. Each biological factor involves a number of genes, perhaps a few to a few\nhundred, but not all genes; so each column of B will have many zeros. Similarly, a\ngiven gene may play roles in one or a small number of biological pathways, but will not\nbe involved in all; so each row of B will have many zeros. It is therefore substantively\nappropriate to use priors that induce sparsity in B.\n3.2 Bayesian Specification of Sparse Factor Models\nOur Bayesian approach to defining sparse factor structure uses priors on the elements\nBij (gene i, factor j) of B that induce zeros with high probability. Within column\n(factor) j, take the Bijto be independent with priors\n\u03c0j\u03b40(Bij) + (1 \u2212 \u03c0j)N(Bij|0,1)\nwhere \u03c0jhas a prior heavily concentrated near 1. Note that the unit scale of the normal\ncomponent is convenient; the arbitrary scale of factor j is already accommodated in\nthe variance parameter d2\nanalysis extends existing approaches that utilise normal priors on B (Aguilar and West,\nj. Assuming specified priors on all model parameters, MCMC"},{"page":8,"text":"8\nMike West\n2000; Lopes and West, 1999) to incorporate these new mixture priors, and include\nsampling of the \u03c0j. The analysis is inherently parallelisable; MCMC sequences through\ncolumns of B (i.e., through factors), and within each column the (many) elements\nBij are, a posteriori, conditionally independent given values of the prior and model\nparameters, latent factors and data. Hence, for fixed j, the set of p values Bij (i =\n1,...,p), may be sampled efficiently, in parallel. Some consideration of identification\nconstraints is needed; we may use the popular lower triangular method (see above\nreferences) that simply fixes k(k + 1)\/2 selected elements of B at 0 or 1, and then use\nthe mixture prior for the remaining (many) elements.\n3.3 Example: Factors in Breast Cancer Gene Expression Data\nSome illustration comes from analysis of expression levels of p = 6128 genes measured\n(using Affymetrix DNA microarrays) on n = 49 breast cancer tumour samples. The\ndata comes from the study reported in West et al (2000, 2001) and Spang et al (2001),\nwhere full details of the data and context may be found. Here I discuss some aspects\nof a new analysis using the sparse latent factor model, with k = 25 factors. Additional\nprior specifications include priors on the variances d2\nidiosyncratic variances \u03c82\nspecified via independent Ga(\u00b7|0.01,0.01)) priors on reciprocal variances. Finally, the\nuse of a prior on \u03c0j that heavily favours very high values is critical in enforcing very\nmany zeros in the loadings matrix; here, with p = 6128 and k = 25, analysis utilises\n\u03c0j\u223c Be(\u03c0j|999,1).\nFigure 5 displays posterior means of the values of four of the factors, chosen as\nthose four with largest values of the posterior means of the d2\ntop down. The values of the factors (vertical axis) are plotted against sample number\n(horizontal axis). The first factor is essentially zero apart from on samples (tumours)\n7,8,11 and 46, and the second essentially zero but for cases 7 and 8. These four cases\nhad been much explored in earlier analyses, and, relative to most of the data, have\nquite apparent differences in large numbers of genes. The second factor shows that\ncases 7 and 8 share a common pattern of covariation not exhibited by 11 and 46. These\nfour cases, and particularly 7 and 8, are in fact questionable due to concerns about the\nquality of the DNA microarray hybridisation; in analyses in West et al (2001) cases 7\nand 8 had been held out due to these data quality concerns. It is of interest here to note\nthat the full data analysis using the sparse factor model is itself capable of identifying\nthese questionable cases, and protecting inferences on other factors from their effects.\nThe third factor plotted is of key interest in connection with comparison of oestro-\ngen receptor (ER) status of tumours. We had earlier developed binary factor regression\nmodels to predictively discriminate ER status based on a selected set of about 50-100\ngenes (West et al 2000, 2001; Spang et al 2001). That analysis format is effective but\ninvolves the pre-selection of smaller numbers of discriminatory genes, and one motivat-\ning interest in sparse factor models is the potential to automate variable selection at\nthe factor loading level. This potential is realised and evident here. The third factor is\ncolor coded: red indicates ER positive tumours, blue ER negative. Factor 3 evidently\nseparates the two groups quite well, with four cases (16,31,40,43) in the mid-ground.\nEarlier analysis using gene screening had identified these four cases, and follow-on in-\nvestigations reversed the ER status determination of number 31, so the analysis is in\nfact discriminating cases very well based on this factor alone.\njof the latent factors and the\ni(the elements of the diagonal matrix \u03a8); these are each\njand plotted from the"},{"page":9,"text":"Bayesian Factor Regression Models\n9\nFor comparison, Figure 6 displays the four dominant empirical SVD factors (princi-\npal components) from the 6128 genes. Factors 1 and 2 bear resemblance to those from\nthe model-based analysis, though the identification of questionable samples via two\n\u201coutlier factors\u201d is significantly obscured by the confounding of idiosyncratic noise in\ngene expression levels - a key inherent and limiting feature of empirical factor analyses\nwith many variables. The third empirical factor certainly relates to the ER discrimi-\nnation, but again the signal is obscured and much less clearly defined than it is in the\nmodel-based analysis.\n05 10152025 30 35 404550\n\u22122\n0\n2\n4\n05 10 1520 25 3035 40 4550\n\u22125\n0\n5\n05 10 1520 253035 4045 50\n\u22124\n\u22122\n0\n2\n05 101520 2530 35 4045 50\n\u22124\n\u22122\n0\n2\nFigure 5.\nFour factors in sparse factor analysis of gene expression data\n05 101520 25303540 4550\n\u22120.5\n0\n0.5\n1\n05 1015 20 25303540 4550\n\u22120.5\n0\n0.5\n051015 2025 3035 40 4550\n\u22120.5\n0\n0.5\n05 101520 253035 4045 50\n\u22120.5\n0\n0.5\nFigure 6.\nFour factors in SVD of gene expression data"},{"page":10,"text":"10\nMike West\n4. ADDITIONAL COMMENTS\nSparse factor regression models offer a promising framework for dimension reduction\nin predictor space and for regression variable selection with many predictors.\nsmall number of latent factors associate with the response (as in the breast cancer ER\nstudy, where a single factor is primarily implicated) then a sparse factor model implies\nthat only those genes with non-zero loadings on those factors are relevant; variable\nselection is then induced, automatically. In the ER study, only 60 genes have posterior\nprobability of non-zero values exceeding 0.5; most of these genes show up in our prior\nstudies and those of other groups exploring ER pathways in breast cancer.\nFurther, I have explored the full analysis of the sparse factor model combined with\nbinary regression in cross-validation studies of both ER and lymph node (LN) status\nwith this breast cancer data, comparing with results in West et al (2001). This prior\nwork uses gene selection\/screening and SVD factor regression. The cross-validation\npredictions are very similar, perhaps even slightly better with the sparse factor model.\nI stress that this model uses all 6128 genes whereas our prior published analysis selects\n100 based on correlation with ER or LN status, so removing noise via ad-hoc preliminary\nvariable selection. The comparability of predictions is very strong evidence for the\nefficacy of the sparse modelling approach in dealing formally \u2013 and automatically \u2013 with\nthat most critical and challenging variable selection problem. Further development and\nexperience with this approach is needed, but these results are encouraging.\nOne challenging question is the identification, or estimation, of the number of fac-\ntors. In some studies, simply increasing k and exploring posterior estimates of factors\nand their variances suffices (Aguilar and West, 2000), though the problem remains an\nopen research area and utilising formal approaches is a challenge (Lopes and West,\n1999). In the sparse factor model, using too few factors confounds higher-order struc-\nture in the factors being estimated and, in particular, induces likelihood functions that\nvery strongly suggest non-zero factor loadings for many gene-factor combinations than\nmight be expected on scientific grounds; this seems to be simply an artifact of the use of\ntoo few factors. Though simple to diagnose, this problem is far from simple to resolve\nas fitting large numbers of factors is significantly challenging in terms of computa-\ntion. One current development is the implementation of these analysis on a distributed\nmachine (Beowulf cluster) which will aid progress on this challenging problem.\nIf a\nACKNOWLEDGEMENTS\nThis research was partially supported by the NSF (grants DMS-0102227 and DMS-\n0112340). Some aspects of the work relate to collaborations with Ming Liao and Hed-\nibert Lopes. I am grateful to Marina Vanucci for provision of the biscuit dough data,\nand for useful conversations with Jim Berger, Merlise Clyde and Rainer Spang."},{"page":11,"text":"Bayesian Factor Regression Models\n11\nREFERENCES\nAlbert, J. and Johnson, V.E. (1999) Ordinal Data Models. New York: Springer-Verlag.\nAguilar, O. and West, M. (2000) Bayesian dynamic factor models and portfolio allocation. Journal of\nBusiness and Economic Statistics 18, 338-357.\nBrown, P.J., Fearn, T. and Vannucci, M. (1999) The choice of variables in multivariate regression: a\nnon-conjugate Bayesian decision theory approach. Biometrika, 86, 635-648.\nLopes, H., and West, M. (1999) Model uncertainty in factor analysis. ISDS Discussion Paper #98-38.\nSubmitted for publication.\nOsborne, B.G., Feran, T., Miller, A.R. and Douglas, S. (1984) Applications of near infrared reflectance\nspectroscopy to compositional analysis of biscuits and biscuit doughs. J. Sci. Food Agric., 35, 99-105.\nSpang, R., Zuzan, H., West. M., Nevins, J.R., Blanchette, C. and Marks, J.R. (2001) Prediction and\nuncertainty in the analysis of gene expression profiles. In Silico Biology, 2, 0033.\nWest, M., Blanchette, C., Dressman, H., Huang, E., Ishida, S., Spang, R., Zuzan, H., Marks, J.R. and\nNevins, J.R. (2001) Predicting the clinical status of human breast cancer utilizing gene expression\nprofiles. Proceedings of the National Academy of Sciences, 98, 11462-11467.\nWest, M., Nevins, J.R., Marks, J.R, Spang, R. and Zuzan, H. (2000) DNA microarray data analysis and\nregression modeling for genetic expression profiling. (Submitted for publication).\nZellner, A. (1986) On assessing prior distributions and Bayesian regression analysis with g\u2212prior distri-\nbutions. In Bayesian Inference and Decision Techniques: Essays in Honor of Bruno de Finetti, (eds:\nP.K. Goel and A. Zellner), pp233-243. Amsterdam: North-Holland."}],"widgetId":"rgw23_56ab9f94c85e2"},"id":"rgw23_56ab9f94c85e2","partials":[],"templateName":"publicliterature\/stubs\/PublicationText.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationText.html?publicationUid=2522345&hide=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationDetailAd":{"data":{"googleDfpSlot":null,"widgetId":"rgw24_56ab9f94c85e2"},"id":"rgw24_56ab9f94c85e2","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAd.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAd.html?publicationUid=2522345&slotId=336x280_Publications_ATF_Right&collapseSlotMode=never&fallbackContainerEnabled=1","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationRelations":null,"publicationRelationsReverse":null,"publicationUid":2522345,"showSignUpDialog":false,"selectNewSignUpDialog":false,"publicationQuestions":null,"publicationCitations":null,"publicationReviewPromo":null,"publicationUsedInReviews":null,"publicationPdfJsReader":null,"useFulltextOptimizedLayout":false,"publicationActions":null,"requestFulltextPromo":null,"currentUrl":"publication\/2522345_Bayesian_Factor_Regression_Models_in_the_Large_p_Small_n_Paradigm","isLeaderboardAd":false,"enableStickyBox":null,"googleDfpSlotMobileBottom":null,"fullTextExitPopup":null,"showExitPopupDialog":false,"widgetId":"rgw2_56ab9f94c85e2"},"id":"rgw2_56ab9f94c85e2","partials":{"romeo_legal_notice":"publicliterature\/stubs\/partials\/romeo_legal_notice.html"},"templateName":"publicliterature\/stubs\/PublicPublicationDetails_NewLayout.html","templateExtensions":["generalHelpers"],"attrs":{"publicationUid":2522345},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicPublicationDetailsOld.html?publicationUid=2522345&isTestOldDesign=0","viewClass":"views.publicliterature.PublicPublicationDetailsOldView","yuiModules":["rg.views.publicliterature.PublicPublicationDetailsOldView"],"stylesheets":[],"_isYUI":true},"widgetId":"rgw1_56ab9f94c85e2"},"id":"rgw1_56ab9f94c85e2","partials":[],"templateName":"publicliterature\/stubs\/PublicPublicationDetails.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicPublicationDetails.html","viewClass":"views.publicliterature.PublicPublicationDetailsView","yuiModules":["rg.views.publicliterature.PublicPublicationDetailsView"],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"uaClass":"","headPrefix":[],"rootUrl":"https:\/\/www.researchgate.net\/","requestToken":"BD0A4ZSsp3XdbAXxF7mEDHcccywARjmVcqbJukAZbCHCraw4MAu+vX0JwXVye8cei+PC+pon0btuTEsdnYTbJAVihq8Zt\/tP9d+j+o7a3oK7Cckmn4DQnaPVMiQplkkUHqRjDD4Jwxz+JoYJdIc9GhQoa7lCMTwJWdLGDvgmHg3HIUcsAOcOD\/6tiYAqZVS6112Ng3V\/S6U0nZ+242q6gC+duF7VutclIH9qvHbxYHrnFiJiBEldUUfJ67jAfV3qGImYxpTcLvF\/VTsfgsXUCAYljnRlLfyuCuaWY2O7\/jg=","faviconCdnUrl":"https:\/\/c5.rgstatic.net\/m\/2390829798215018\/images\/favicon.ico","headerOutput":"<noscript><\/noscript><link rel=\"canonical\" href=\"https:\/\/www.researchgate.net\/publication\/2522345_Bayesian_Factor_Regression_Models_in_the_Large_p_Small_n_Paradigm\" \/>\n<link rel=\"dns-prefetch\" href=\"\/\/c5.rgstatic.net\" \/>\n<link rel=\"dns-prefetch\" href=\"\/\/i1.rgstatic.net\" \/>\n<meta property=\"twitter:card\" content=\"summary\" \/>\n<meta property=\"twitter:site\" content=\"@ResearchGate\" \/>\n<meta property=\"og:title\" content=\"Bayesian Factor Regression Models in the &quot;Large p, Small n&quot; Paradigm\" \/>\n<meta property=\"og:description\" content=\"TOR REGRESSION MODELS 1.1 SVD Regression Begin with the linear model y = X# + # where y is the n-vector of responses, X is the n p matrix of predictors, # is the p-vector regression parameter, and...\" \/>\n<meta property=\"og:site_name\" content=\"ResearchGate\" \/>\n<meta property=\"og:image\" content=\"https:\/\/i1.rgstatic.net\/publication\/2522345_Bayesian_Factor_Regression_Models_in_the_Large_p_Small_n_Paradigm\/links\/0e5fab20f0c41c4932e308d6\/smallpreview.png\" \/>\n<meta property=\"og:url\" content=\"https:\/\/www.researchgate.net\/publication\/2522345_Bayesian_Factor_Regression_Models_in_the_Large_p_Small_n_Paradigm\" \/>\n<meta property=\"rg:id\" content=\"PB:2522345\" \/>\n<meta name=\"DC.identifier\" scheme=\"DCTERMS.URI\" content=\"http:\/\/dx.doi.org\/\" \/>\n<meta name=\"gs_meta_revision\" content=\"1.1\" \/>\n<meta name=\"citation_title\" content=\"Bayesian Factor Regression Models in the &quot;Large p, Small n&quot; Paradigm\" \/>\n<meta name=\"citation_author\" content=\"Mike West\" \/>\n<meta name=\"citation_publication_date\" content=\"2002\/08\/10\" \/>\n<meta name=\"citation_volume\" content=\"7\" \/>\n<meta name=\"citation_abstract_html_url\" content=\"https:\/\/www.researchgate.net\/publication\/2522345_Bayesian_Factor_Regression_Models_in_the_Large_p_Small_n_Paradigm\" \/>\n<meta name=\"citation_fulltext_html_url\" content=\"https:\/\/www.researchgate.net\/publication\/2522345_Bayesian_Factor_Regression_Models_in_the_Large_p_Small_n_Paradigm\" \/>\n<meta name=\"viewport\" content=\"width=device-width,initial-scale=1\" \/>\n<link href=\"\/\/c5.rgstatic.net\/m\/22664197317151888\/styles\/rg.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/21004998181197492\/styles\/rg2.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<!--[if lt IE 9]><link href=\"\/\/c5.rgstatic.net\/m\/238176252723686\/styles\/ie.css\" type=\"text\/css\" rel=\"stylesheet\"\/><![endif]-->\n<link href=\"\/\/c5.rgstatic.net\/m\/217752362214895\/styles\/modules\/publicprofile.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<script src=\"\/\/c5.rgstatic.net\/m\/2321000301012716\/javascript\/vendor\/webfontloader\/webfontloader.js\" type=\"text\/javascript\"><\/script>\n <script>(function(i,s,o,g,r,a,m){i[\"GoogleAnalyticsObject\"]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,\"script\",\"\/\/www.google-analytics.com\/analytics.js\",\"ga\");\n ga(\"create\",\"UA-58591210-1\");ga(\"set\",\"anonymizeIp\",true);ga('set', 'dimension1', 'publication slurped');ga('set', 'dimension2', 'Article');ga('set', 'dimension3', 'Logged out');ga('set', 'dimension4', 'https');ga(\"send\",\"pageview\");<\/script>\n","webfont":"<noscript><\/noscript><script> WebFontConfig = { custom: { families: ['source_sans_pro_italic', 'source_sans_pro_bold', 'source_sans_pro', 'martel'], urls : ['\/\/c5.rgstatic.net\/m\/231392577336386\/styles\/fonts.css'] } }; WebFont.load(WebFontConfig); <\/script>\n","correlationId":"rgreq-914b5ea7-aac9-4569-9c97-529fce868539","accountId":null,"module":"publicliterature","action":"publicliterature.PublicPublicationDetails","page":"publicationDetail","product":"publications","backendTime":356,"continent":"Asia","stylesHome":"\/\/c5.rgstatic.net\/m\/","staticHost":"c5.rgstatic.net","useEarlyFlush":false,"longRunningRequestIdentifier":"LongRunningRequest.publicliterature.PublicPublicationDetails","longRunningRequestFp":"e9e5bbe1366c7ee8c8e41d02f793c884ac9be19b","widgetId":"rgw25_56ab9f94c85e2"},"id":"rgw25_56ab9f94c85e2","partials":[],"templateName":"application\/stubs\/StaticHeader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.StaticHeader.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){
            Y.rg.core.pagespeed.Monitoring.monitorPage("\/\/glassmoni.researchgate.net", "publicliterature.PublicPublicationDetails.run.html.loggedOut.get", "59de9668d07aeb77ab4de5f24d382b5d199d2437", "rgreq-914b5ea7-aac9-4569-9c97-529fce868539", "0446ab85609881507d2d4198ebc8b4219a3b98f5");
        
            Y.rg.core.pagespeed.Monitoring.monitorPage("\/\/glassmoni.researchgate.net", "publicationDetail.loggedOut", "ed1993d9e20f6cefa83edacaa24401a18c071aea", "rgreq-914b5ea7-aac9-4569-9c97-529fce868539", "0446ab85609881507d2d4198ebc8b4219a3b98f5");
        })();
(function(){Y.rg.createInitialWidget({"data":{"year":"2016","inlinePromo":null,"isAdmin":false,"contactUrl":"https:\/\/www.researchgate.net\/contact","aboutUsUrl":"https:\/\/www.researchgate.net\/about","widgetId":"rgw26_56ab9f94c85e2"},"id":"rgw26_56ab9f94c85e2","partials":[],"templateName":"application\/stubs\/DefaultFooter.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.DefaultFooter.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"headerLogin":{"data":{"urlAfterLogin":"publication\/2522345_Bayesian_Factor_Regression_Models_in_the_Large_p_Small_n_Paradigm","requestToken":"KEZ00dhvlNiN\/izliU14g1phydRUUrjgJbea6yEnRFamwqV6dkAfEP1jvm9A+a+8jHG9HTCbIQmrwrHA4XF5HXWDMKoTChthn5JByoHuB2Qz+Ex2jFZWFKLDEoy9eyvwAUCg3bTT0HYjTkIWl2hnYXDAabJ6xYzZECqBgle9YtoNfUniFk8qBcKki53BJC7ww0nIxAT8uCLuJnWE98\/kPAn8OOcKN5bD1D+CKhvYJ70EhrMuGUWkXk1jdLncL+QwLoTXvtafO7xGpV0FSkxuUNMzOXJyAVEN+dI6LcQyIgI=","loginUrl":"https:\/\/www.researchgate.net\/application.Login.html","signupUrl":"https:\/\/www.researchgate.net\/signup.SignUp.html?ev=su_chnl_index&hdrsu=1&_sg=a-ug55A_HrrpygIJpUptuPV9HUQkt6hlP7MrvZ9jwaVKuAQYPqjtJwp2L_C7o4tE","encodedUrlAfterLogin":"cHVibGljYXRpb24vMjUyMjM0NV9CYXllc2lhbl9GYWN0b3JfUmVncmVzc2lvbl9Nb2RlbHNfaW5fdGhlX0xhcmdlX3BfU21hbGxfbl9QYXJhZGlnbQ%3D%3D","signupCallToAction":"Join for free","widgetId":"rgw28_56ab9f94c85e2"},"id":"rgw28_56ab9f94c85e2","partials":{"partial":"application\/stubs\/partials\/headerLoginDefault.html"},"templateName":"application\/stubs\/HeaderLogin.html","templateExtensions":[],"attrs":{"goal":"milestoneHeaderLoginSeen"},"widgetUrl":"https:\/\/www.researchgate.net\/application.HeaderLogin.html","viewClass":"views.application.HeaderLoginView","yuiModules":["rg.views.application.HeaderLoginView"],"stylesheets":[],"_isYUI":true},"cookieConsent":null,"logoSvgSrc":"https:\/\/c5.rgstatic.net\/m\/235107188705592\/images\/template\/brand-header-logo.svg","logoFallbackSrc":"https:\/\/c5.rgstatic.net\/m\/238113351022438\/images\/template\/brand-header-logo.png","widgetId":"rgw27_56ab9f94c85e2"},"id":"rgw27_56ab9f94c85e2","partials":{"schemaSocialProfiles":"application\/stubs\/partials\/schemaSocialProfiles.html"},"templateName":"application\/stubs\/HeaderLoggedOut.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.HeaderLoggedOut.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"logEvent":"su_banner","specialCopy":false,"widgetId":"rgw29_56ab9f94c85e2"},"id":"rgw29_56ab9f94c85e2","partials":[],"templateName":"application\/stubs\/LoggedOutBanner.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.LoggedOutBanner.html","viewClass":"views.application.LoggedOutBannerView","yuiModules":["rg.views.application.LoggedOutBannerView"],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.core.util.ParameterFilter.filter(["ev","cp","ch","ref","dbw","pli","loginT","uid","claimChannel","enrichId","enrichSource","utm_source","utm_medium","utm_campaign","el","ci"]);})();
});}); } else { throw 'YRG was not loaded when attaching widgets'; }</script><script> dataLayer = [{"pageCategory":"publication slurped","publicationType":"Article","eventCategory":"Publication page"}]; </script> <noscript><iframe src="//www.googletagmanager.com/ns.html?id=GTM-MKVKH7" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-MKVKH7');</script><script>(function(e){function n(n,t,o,a){"use strict";var i=e.document.createElement("link"),r=t||e.document.getElementsByTagName("script")[0],d=e.document.styleSheets;return i.rel="stylesheet",i.href=n,i.media="only x",a&&(i.onload=a),r.parentNode.insertBefore(i,r),i.onloadcssdefined=function(e){for(var t,o=0;d.length>o;o++)d[o].href&&d[o].href.indexOf(n)>-1&&(t=!0);t?e():setTimeout(function(){i.onloadcssdefined(e)})},i.onloadcssdefined(function(){i.media=o||"all"}),i}function t(e,n){e.onload=function(){e.onload=null,n&&n.call(e)},"isApplicationInstalled"in navigator&&"onloadcssdefined"in e&&e.onloadcssdefined(n)}var o=function(a,i){"use strict";if(a&&3===a.length){var r=e.Image,d=!(!document.createElementNS||!document.createElementNS("http://www.w3.org/2000/svg","svg").createSVGRect||!document.implementation.hasFeature("http://www.w3.org/TR/SVG11/feature#Image","1.1")||e.opera&&-1===navigator.userAgent.indexOf("Chrome")||-1!==navigator.userAgent.indexOf("Series40")),c=new r;c.onerror=function(){o.method="png",o.href=a[2],n(a[2])},c.onload=function(){var e=1===c.width&&1===c.height,r=a[e&&d?0:e?1:2];o.method=e&&d?"svg":e?"datapng":"png",o.href=r,t(n(r),i)},c.src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///ywAAAAAAQABAAACAUwAOw==",document.documentElement.className+=" grunticon"}};o.loadCSS=n,o.onloadCSS=t,e.grunticon=o})(this);grunticon(["https://c5.rgstatic.net/c/o1q2er/styles/icons/_header-ico.svg.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_header-ico.png.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_header-ico.fallback.scss"]);grunticon(["https://c5.rgstatic.net/c/o1q2er/styles/icons/_admin-ico.svg.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_admin-ico.png.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_admin-ico.fallback.scss"]);grunticon(["https://c5.rgstatic.net/c/o1q2er/styles/icons/_ico.svg.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_ico.png.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_ico.fallback.scss"]);</script></body>
</html>
