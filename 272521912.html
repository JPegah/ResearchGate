<!DOCTYPE html> <html lang="en" class="" id="rgw35_56aba2012c1a1"> <head > <meta charset="utf-8"/> <meta http-equiv="content-type" content="text/html; charset=UTF-8"/> <meta name="Rg-Request-Token" id="Rg-Request-Token" content="07few6ZTQjghhwRlN9ANPp2wUqeW6KTC12vzcpAcKhCEQQWCJ4dazoQaos6dkxxyZFjW7qgN1r4jbSGyUrPxfiZ6SCQEOJv3sfWpB72vhGsqv3kiWpFuG5I7ZzFbtal3KLTaBPCo7D1xxhALFPTO/CYpjAiwFTbWlmG0/tIQ/ttsA0vXkhVVbFgYq5iuU/R861kKbPICdOcc5mvJK50zUj/4jzuACQu8/JWArjLmwpwgACQGQTA41L4U7ipzB9WA37QoXQy4aq4ggCPQqj+/9uELDUqEOU5pkS98ouxK3SQ="/> <meta http-equiv="expires" content="0"/> <link rel="apple-touch-icon" sizes="57x57" href="https://www.researchgate.net/apple-touch-icon-57x57.png"> <link rel="apple-touch-icon" sizes="60x60" href="https://www.researchgate.net/apple-touch-icon-60x60.png"> <link rel="apple-touch-icon" sizes="72x72" href="https://www.researchgate.net/apple-touch-icon-72x72.png"> <link rel="apple-touch-icon" sizes="76x76" href="https://www.researchgate.net/apple-touch-icon-76x76.png"> <link rel="apple-touch-icon" sizes="114x114" href="https://www.researchgate.net/apple-touch-icon-114x114.png"> <link rel="apple-touch-icon" sizes="120x120" href="https://www.researchgate.net/apple-touch-icon-120x120.png"> <link rel="apple-touch-icon" sizes="144x144" href="https://www.researchgate.net/apple-touch-icon-144x144.png"> <link rel="apple-touch-icon" sizes="152x152" href="https://www.researchgate.net/apple-touch-icon-152x152.png"> <link rel="apple-touch-icon" sizes="180x180" href="https://www.researchgate.net/apple-touch-icon-180x180.png"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-32x32.png" sizes="32x32"> <link rel="icon" type="image/png" href="https://www.researchgate.net/android-chrome-192x192.png" sizes="192x192"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-96x96.png" sizes="96x96"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-16x16.png" sizes="16x16"> <link rel="shortcut icon" type="image/x-icon" href="https://c5.rgstatic.net/m/2390829798215018/images/favicon.ico"/> <link rel="manifest" href="https://www.researchgate.net/manifest.json"> <meta name="msapplication-TileColor" content="#da532c"> <meta name="msapplication-TileImage" content="https://www.researchgate.net/mstile-144x144.png"> <meta name="theme-color" content="#444444"> <link rel="search" type="application/opensearchdescription+xml" title="ResearchGate search" href="https://www.researchgate.net/application.DownloadOpenSearchPlugin.html"/> <link rel="meta" type="application/rdf+xml" title="ICRA labels" href="https://www.researchgate.net/application.DownloadLabels.html"/> <link rel="http://oexchange.org/spec/0.8/rel/related-target" type="application/xrd+xml" href="https://www.researchgate.net/application.DownloadOExchange.html"/> <base href="https://www.researchgate.net/"/> <script>
    var rgConfig = {
        correlationId: "rgreq-110399e0-6e67-4236-a9d9-d0de2fdb66bb",
        accountId: "",
        module: "publicliterature",
        action: "publicliterature.PublicPublicationDetails",
        page: "publicationDetail",
        product: "publications",
        continent: "Asia",
        stylesHome: "//c5.rgstatic.net/m/",
        staticHost: "c5.rgstatic.net",
        longRunningRequestIdentifier: "LongRunningRequest.publicliterature.PublicPublicationDetails",
        longRunningRequestFp: "e9e5bbe1366c7ee8c8e41d02f793c884ac9be19b"
    };
    window.rootUrl = "https://www.researchgate.net/";
</script> <link rel="canonical" href="https://www.researchgate.net/publication/272521912_Predictive_Entropy_Search_for_Bayesian_Optimization_with_Unknown_Constraints" />
<link rel="dns-prefetch" href="//c5.rgstatic.net" />
<link rel="dns-prefetch" href="//i1.rgstatic.net" />
<meta property="twitter:card" content="summary" />
<meta property="twitter:site" content="@ResearchGate" />
<meta property="og:title" content="Predictive Entropy Search for Bayesian Optimization with Unknown Constraints" />
<meta property="og:description" content="Unknown constraints arise in many types of expensive black-box optimization
problems. Several methods have been proposed recently for performing Bayesian
optimization with constraints, based on..." />
<meta property="og:site_name" content="ResearchGate" />
<meta property="og:image" content="https://i1.rgstatic.net/publication/272521912_Predictive_Entropy_Search_for_Bayesian_Optimization_with_Unknown_Constraints/links/54ed277b0cf28f3e65356839/smallpreview.png" />
<meta property="og:url" content="https://www.researchgate.net/publication/272521912_Predictive_Entropy_Search_for_Bayesian_Optimization_with_Unknown_Constraints" />
<meta property="rg:id" content="PB:272521912" />
<meta name="DC.identifier" scheme="DCTERMS.URI" content="http://dx.doi.org/" />
<meta name="gs_meta_revision" content="1.1" />
<meta name="citation_title" content="Predictive Entropy Search for Bayesian Optimization with Unknown Constraints" />
<meta name="citation_author" content="José Miguel Hernández-Lobato" />
<meta name="citation_author" content="Michael A. Gelbart" />
<meta name="citation_author" content="Matthew W. Hoffman" />
<meta name="citation_author" content="Ryan P. Adams" />
<meta name="citation_author" content="Zoubin Ghahramani" />
<meta name="citation_publication_date" content="2015/02/18" />
<meta name="citation_abstract_html_url" content="https://www.researchgate.net/publication/272521912_Predictive_Entropy_Search_for_Bayesian_Optimization_with_Unknown_Constraints" />
<meta name="citation_fulltext_html_url" content="https://www.researchgate.net/publication/272521912_Predictive_Entropy_Search_for_Bayesian_Optimization_with_Unknown_Constraints" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<link href="//c5.rgstatic.net/m/22664197317151888/styles/rg.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/21004998181197492/styles/rg2.css" type="text/css" rel="stylesheet"/>
<!--[if lt IE 9]><link href="//c5.rgstatic.net/m/238176252723686/styles/ie.css" type="text/css" rel="stylesheet"/><![endif]-->
<link href="//c5.rgstatic.net/m/217752362214895/styles/modules/publicprofile.css" type="text/css" rel="stylesheet"/>
<script src="//c5.rgstatic.net/m/2321000301012716/javascript/vendor/webfontloader/webfontloader.js" type="text/javascript"></script>
 <script>(function(i,s,o,g,r,a,m){i["GoogleAnalyticsObject"]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,"script","//www.google-analytics.com/analytics.js","ga");
 ga("create","UA-58591210-1");ga("set","anonymizeIp",true);ga('set', 'dimension1', 'publication slurped');ga('set', 'dimension2', 'Article');ga('set', 'dimension3', 'Logged out');ga('set', 'dimension4', 'https');ga("send","pageview");</script>
  <script> WebFontConfig = { custom: { families: ['source_sans_pro_italic', 'source_sans_pro_bold', 'source_sans_pro', 'martel'], urls : ['//c5.rgstatic.net/m/231392577336386/styles/fonts.css'] } }; WebFont.load(WebFontConfig); </script><noscript></noscript>

<title>Predictive Entropy Search for Bayesian Optimization with Unknown Constraints</title>
<meta name="description" content="Predictive Entropy Search for Bayesian Optimization with Unknown Constraints on ResearchGate, the professional network for scientists."/>
<meta name="keywords" content="scientific network, scientific platform, scientific community, research partner, research collaboration, journal articles, international collaboration, find researcher, lifescience researcher, interdisciplinary research, research collaboration"/>
</head>
<body class="use-svg-icons logged-out">
<div id="page-container">
<script type="text/javascript">var googletag = googletag || {}; googletag.cmd = googletag.cmd || [];
(function() { var gads = document.createElement("script"); gads.async = true; gads.type = "text/javascript"; var useSSL = "https:" == document.location.protocol; gads.src = (useSSL ? "https:" : "http:") + "//www.googletagservices.com/tag/js/gpt.js"; var node =document.getElementsByTagName("script")[0]; node.parentNode.insertBefore(gads, node); })();</script><div id="main" class="logged-out-header-support">
<div id="content" class="">

<noscript>
<div class="c-box-warning full-width-element" style="text-align: center; ">
    <div style="margin: auto; padding:10px;" class="container">
        <b>For full functionality of ResearchGate it is necessary to enable JavaScript.
            Here are the <a href="http://www.enable-javascript.com/" rel="nofollow" target="_blank">
                instructions how to enable JavaScript in your web browser</a>.</b>
    </div>
</div>
</noscript>

<div id="rgw1_56aba2012c1a1" itemscope itemtype="http://schema.org/ScholarlyArticle"><div class="publication-wrapper publication-wrapper-onecol" id="rgw2_56aba2012c1a1" itemscope itemtype="http://schema.org/ScholarlyArticle"> <div class="c-col-content"> <div class="c-content"> <div class="clearfix">  <div class="publication-header"> <div id="rgw8_56aba2012c1a1">  <div class="type-label"> Article   </div> <span class="Z3988" title="ctx_ver=Z39.88-2004&rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&rfr_id=info%3Asid%2Fresearchgate.net%3Aresearchgate&rft.atitle=Predictive%20Entropy%20Search%20for%20Bayesian%20Optimization%20with%20Unknown%20Constraints&rft.date=2015&rft.au=Jos%C3%A9%20Miguel%20Hern%C3%A1ndez-Lobato%2CMichael%20A.%20Gelbart%2CMatthew%20W.%20Hoffman%2CRyan%20P.%20Adams%2CZoubin%20Ghahramani&rft.genre=article"></span> <h1 class="pub-title" itemprop="name">Predictive Entropy Search for Bayesian Optimization with Unknown Constraints</h1> <meta itemprop="headline" content="Predictive Entropy Search for Bayesian Optimization with Unknown Constraints">  <meta itemprop="image" content="https://i1.rgstatic.net/publication/272521912_Predictive_Entropy_Search_for_Bayesian_Optimization_with_Unknown_Constraints/links/54ed277b0cf28f3e65356839/smallpreview.png">  <div id="rgw10_56aba2012c1a1" class="publication-detail-author-list"> <div> <ul class="clearfix js-people-list">  <li id="rgw11_56aba2012c1a1"> <a href="researcher/59382974_Jose_Miguel_Hernandez-Lobato" class="pub-detail-item author-item" itemprop="author" itemscope itemtype="http://schema.org/Person"> <div class="indent-left"> <div class="people-img">  <img src="https://c5.rgstatic.net/m/2951093203564/images/template/default/profile/profile_default_s.jpg" title="José Miguel Hernández-Lobato" alt="José Miguel Hernández-Lobato" height="20px" width="20px" style="height: 20px;"/>  </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">José Miguel Hernández-Lobato</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item   not-claimed " id="rgw12_56aba2012c1a1">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="researcher/59382974_Jose_Miguel_Hernandez-Lobato"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="José Miguel Hernández-Lobato" alt="José Miguel Hernández-Lobato" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">       </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="researcher/59382974_Jose_Miguel_Hernandez-Lobato" class="display-name">José Miguel Hernández-Lobato</a>    </h5> <div class="truncate-single-line meta">   </div>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>  <li id="rgw13_56aba2012c1a1"> <a href="researcher/2043445261_Michael_A_Gelbart" class="pub-detail-item author-item" itemprop="author" itemscope itemtype="http://schema.org/Person"> <div class="indent-left"> <div class="people-img">  <img src="https://c5.rgstatic.net/m/2951093203564/images/template/default/profile/profile_default_s.jpg" title="Michael A. Gelbart" alt="Michael A. Gelbart" height="20px" width="20px" style="height: 20px;"/>  </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Michael A. Gelbart</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item   not-claimed " id="rgw14_56aba2012c1a1">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="researcher/2043445261_Michael_A_Gelbart"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="Michael A. Gelbart" alt="Michael A. Gelbart" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">       </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="researcher/2043445261_Michael_A_Gelbart" class="display-name">Michael A. Gelbart</a>    </h5> <div class="truncate-single-line meta">   </div>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>  <li id="rgw15_56aba2012c1a1"> <a href="researcher/2049681119_Matthew_W_Hoffman" class="pub-detail-item author-item" itemprop="author" itemscope itemtype="http://schema.org/Person"> <div class="indent-left"> <div class="people-img">  <img src="https://c5.rgstatic.net/m/2951093203564/images/template/default/profile/profile_default_s.jpg" title="Matthew W. Hoffman" alt="Matthew W. Hoffman" height="20px" width="20px" style="height: 20px;"/>  </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Matthew W. Hoffman</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item   not-claimed " id="rgw16_56aba2012c1a1">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="researcher/2049681119_Matthew_W_Hoffman"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="Matthew W. Hoffman" alt="Matthew W. Hoffman" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">       </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="researcher/2049681119_Matthew_W_Hoffman" class="display-name">Matthew W. Hoffman</a>    </h5> <div class="truncate-single-line meta">   </div>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>  <li id="rgw17_56aba2012c1a1"> <a href="researcher/71165702_Ryan_P_Adams" class="pub-detail-item author-item" itemprop="author" itemscope itemtype="http://schema.org/Person"> <div class="indent-left"> <div class="people-img">  <img src="https://c5.rgstatic.net/m/2951093203564/images/template/default/profile/profile_default_s.jpg" title="Ryan P. Adams" alt="Ryan P. Adams" height="20px" width="20px" style="height: 20px;"/>  </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Ryan P. Adams</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item   not-claimed " id="rgw18_56aba2012c1a1">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="researcher/71165702_Ryan_P_Adams"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="Ryan P. Adams" alt="Ryan P. Adams" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">       </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="researcher/71165702_Ryan_P_Adams" class="display-name">Ryan P. Adams</a>    </h5> <div class="truncate-single-line meta">   </div>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>  <li id="rgw19_56aba2012c1a1"> <a href="researcher/8159937_Zoubin_Ghahramani" class="pub-detail-item author-item" itemprop="author" itemscope itemtype="http://schema.org/Person"> <div class="indent-left"> <div class="people-img">  <img src="https://c5.rgstatic.net/m/2951093203564/images/template/default/profile/profile_default_s.jpg" title="Zoubin Ghahramani" alt="Zoubin Ghahramani" height="20px" width="20px" style="height: 20px;"/>  </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Zoubin Ghahramani</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item   not-claimed " id="rgw20_56aba2012c1a1">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="researcher/8159937_Zoubin_Ghahramani"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="Zoubin Ghahramani" alt="Zoubin Ghahramani" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">       </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="researcher/8159937_Zoubin_Ghahramani" class="display-name">Zoubin Ghahramani</a>    </h5> <div class="truncate-single-line meta">   </div>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>   </ul> <div class="js-loading"></div>  </div> </div> <div class="pub-details js-pub-details">        <meta itemprop="datePublished" content="2015-02">  02/2015;               <div class="pub-source"> Source: <a href="http://arxiv.org/abs/1502.05312" rel="nofollow">arXiv</a> </div>  </div> <div id="rgw21_56aba2012c1a1" class="pub-abstract">  <div class="clearfix">   <div style="max-height: 54px;" class="js-expander-container js-expander-collapsed">  <p itemprop="description"> <strong>ABSTRACT</strong> <div>Unknown constraints arise in many types of expensive black-box optimization<br />
problems. Several methods have been proposed recently for performing Bayesian<br />
optimization with constraints, based on the expected improvement (EI)<br />
heuristic. However, EI can lead to pathologies when used with constraints. For<br />
example, in the case of decoupled constraints---i.e., when one can<br />
independently evaluate the objective or the constraints---EI can encounter a<br />
pathology that prevents exploration. Additionally, computing EI requires a<br />
current best solution, which may not exist if none the data collected so far<br />
satisfy the constraints. By contrast, information-based approaches do not<br />
suffer from these failure modes. In this paper, we present a new<br />
information-based method called Predictive Entropy Search with unknown<br />
Constraints (PESC). We analyze the performance of PESC and show that it<br />
compares favorably to EI-based approaches on synthetic and benchmark problems,<br />
as well as several real-world examples. We demonstrate that PESC is an<br />
effective algorithm that provides a promising direction towards a unified<br />
solution for constrained Bayesian optimization.</div> </p>  </div>  </div>   </div>      <div class="action-container">   <div class="clear"></div> <div class="share-dialog-container" style="display: none;">  </div> </div> </div> <div style="margin-left: -20px; margin-right: -20px;">  </div> </div>  <div class="publication-detail-dfp-container rf"> <div id="rgw34_56aba2012c1a1">  </div> </div>  </div>  <div class="clearfix">  <noscript> <div id="rgw33_56aba2012c1a1"  itemprop="articleBody">  <p>Page 1</p> <p>Predictive Entropy Search for Bayesian<br />Optimization with Unknown Constraints<br />Jos´ e Miguel Hern´ andez-Lobato1<br />Harvard University, Cambridge, MA 02138 USA<br />JMH@SEAS.HARVARD.EDU<br />Michael A. Gelbart1<br />Harvard University, Cambridge, MA 02138 USA<br />MGELBART@SEAS.HARVARD.EDU<br />Matthew W. Hoffman<br />University of Cambridge, Cambridge, CB2 1PZ, UK<br />MWH30@CAM.AC.UK<br />Ryan P. Adams<br />Harvard University, Cambridge, MA 02138 USA<br />RPA@SEAS.HARVARD.EDU<br />Zoubin Ghahramani<br />University of Cambridge, Cambridge, CB2 1PZ, UK<br />ZOUBIN@ENG.CAM.AC.UK<br />Abstract<br />Unknown constraints arise in many types of ex-<br />pensive black-box optimization problems. Sev-<br />eral methods have been proposed recently for<br />performing Bayesian optimization with con-<br />straints, based on the expected improvement (EI)<br />heuristic. However, EI can lead to pathologies<br />when used with constraints. For example, in the<br />case of decoupled constraints—i.e., when one<br />can independently evaluate the objective or the<br />constraints—EI can encounter a pathology that<br />preventsexploration. Additionally, computingEI<br />requires a current best solution, which may not<br />exist if none the data collected so far satisfy the<br />constraints. By contrast, information-based ap-<br />proaches do not suffer from these failure modes.<br />In this paper, we present a new information-<br />based method called Predictive Entropy Search<br />with unknown Constraints (PESC). We analyze<br />the performance of PESC and show that it com-<br />pares favorably to EI-based approaches on syn-<br />thetic and benchmark problems, as well as sev-<br />eral real-world examples. We demonstrate that<br />PESC is an effective algorithm that provides a<br />promising direction towards a unified solution<br />for constrained Bayesian optimization.<br />1Authors contributed equally.<br />1. Introduction<br />We are interested in finding the global maximum x?of an<br />objective function f(x) over some bounded domain, typi-<br />cally X ⊂ Rd, subject to the non-negativity of a series of<br />constraint functions c1,...,cK. This can be formalized as<br />max<br />x∈Xf(x)<br />s.t.<br />c1(x) ≥ 0,...,cK(x) ≥ 0.<br />(1)<br />However, f and c1,...,cK are unknown and can only<br />be evaluated pointwise via expensive queries to black-<br />boxes that provide noise-corrupted evaluations of f and<br />c1,...,cK. Note that we are assuming f and each of the<br />constraints ckare defined over the entire space X. We seek<br />to find a solution to (1) with as few queries as possible.<br />Bayesian optimization methods approach this type of prob-<br />lem by building a Bayesian model of the unknown objec-<br />tive function and/or constraints, using this model to com-<br />puteanacquisitionfunctionthatrepresentshowusefuleach<br />inpuy x is thought to be as a next evaluation, and then max-<br />imizing this acquisition function to select the next input for<br />function evaluation (see Brochu et al., 2010).<br />In this we work we extend Predictive Entropy Search (PES)<br />(Hern´ andez-Lobato et al., 2014) to solve (1), an approach<br />that we call Predictive Entropy Search with unknown Con-<br />straints (PESC). PESC is a sequential optimization method,<br />which, after N evaluations of f and c1,...,cK, proposes<br />to evaluate these functions at the location xN+1, such<br />that xN+1approximately maximizes the expected informa-<br />tion gain about the value of the constrained maximizer x?.<br />We compute this information gain by conditioning on<br />arXiv:1502.05312v1  [stat.ML]  18 Feb 2015</p>  <p>Page 2</p> <p>Predictive Entropy Search with Unknown Constraints<br />the data Dk<br />notes the objective data and k = 1,...,K denotes the con-<br />straints. We assume that f and c1,...,cKfollow indepen-<br />dent Gaussian process (GP) priors (see, e.g., Rasmussen &amp;<br />Williams, 2006) and that observation noise is i.i.d. Gaus-<br />sian with mean zero and variance σ2<br />used probabilistic models for Bayesian nonparametric re-<br />gression which provide a flexible framework for working<br />with unknown response surfaces.<br />N= {(x1,yk<br />1),...,(xN,yk<br />N)} where k = 0 de-<br />k. GPs are widely-<br />While previous approaches to the problem of Bayesian op-<br />timization with unknown constraints have been proposed,<br />most are variants of expected improvement (EI) (Mockus<br />et al., 1978; Jones et al., 1998).<br />Schonlau et al. (1998), one method of extending EI to<br />the constrained setting considers the expected feasible im-<br />provement, where the constraints are given as above; such<br />approaches have recently been independently developed in<br />Gelbart et al. (2014); Gardner et al. (2014); Snoek (2013).<br />Alternatively Gramacy &amp; Lee (2010) consider the inte-<br />grated change in expected improvement of all points in the<br />searchspacewithrespecttoadensitygivenbytheprobabil-<br />ity of feasibility. Picheny (2014) considers the probability<br />of improvement under a similar measure. Finally, Gramacy<br />et al. (2014) propose to combine EI with the augmented La-<br />grangian approach for constrained numerical optimization.<br />Initially proposed by<br />Thestrategiesusedbythesemethodstoselectthenexteval-<br />uation point are all based on the expected level of improve-<br />ment. As discussed below, however, this expectation is not<br />always well defined in the presence of constraints. In con-<br />trast to this previous work, the main contribution of this<br />paper is to develop an approach (PESC) that is always well<br />defined. PESC achieves this by building a Bayesian op-<br />timization acquisition function around information gain in<br />the constrained setting, as described in Section 3.<br />2. Expected improvement with constraints<br />The Expected Improvement (EI) heuristic measures the ex-<br />pected amount by which observing at x leads to improve-<br />ment over the current best value or incumbent η:<br />?<br />Because all constraints must be satisfied at a new query<br />point in order for improvement (of the solution) to oc-<br />cur. Approaches that compute the feasible expected im-<br />provement are obtained by discounting the original EI with<br />the posterior probability of a constraint violation. The re-<br />sulting acquisition function—which we call Expected Im-<br />provement with unknown Constraints (EIC)—is given by<br />EI(x|η,D0) =max(0,f(x) − η)p(f(x)|D0)df(x).<br />α(x) = EI(x|η,D0)<br />K<br />?<br />k=1<br />p(ck(x) ≥ 0|Dk),<br />(2)<br />In the unconstrained case, η is usually the maximum of<br />the posterior mean of f (Brochu et al., 2010). In the con-<br />strained case, η is the largest value of the posterior mean<br />of f such that all the constraints are satisfied at the corre-<br />sponding location. However, since information about the<br />constraints may only be available through noisy measure-<br />ments, we may never be certain that the constraints are sat-<br />isfiedatanyparticularlocation. Toavoidthisproblem, Gel-<br />bart et al. (2014) consider a location x to be feasible only<br />if all the constraints are satisfied at x with high posterior<br />probability, that is, if<br />∀k ∈ {1,...,K}, p(ck(x) ≥ 0|Dk) ≥ 1 − δk,<br />for small positive confidence thresholds δk. This is called<br />a probabilistic constraint. Under this new formulation, η is<br />the largest value of the posterior mean for f such that (3) is<br />satisfied at the corresponding location. However, when no<br />point in the search space is feasible under the above defini-<br />tion, η doesnotexistandtheEIcannotbecomputed. Inthis<br />case, Gelbart et al. (2014) ignore the factor EI(x|η,D0) in<br />(2) and only consider the posterior probability of the con-<br />straints being satisfied. The resulting acquisition function<br />focuses only on searching for a feasible location and ig-<br />nores learning about the objective f.<br />(3)<br />Note that when used with probabilistic constraints, EIC is<br />not the true expected improvement of the best feasible so-<br />lution. This is clear because the EIC does not depend on δk.<br />Computing the true EI is not sensible due to the following<br />pathology: asinglenoisyobservationofconstraintsatisfac-<br />tion may be insufficient to push the overall posterior prob-<br />ability of satisfaction above 1 − δk; thus a myopic strategy<br />like EI may see zero potential improvement from a single<br />evaluation and EI may be uniformly zero.<br />Furthermore, Gelbartetal.(2014)identifyapathologywith<br />EI when one is able to separately evaluate the objective<br />or the constraints, i.e., the decoupled case. The best so-<br />lution x?must satisfy a conjunction of high objective value<br />and high (non-negative) constraint values. By only evalu-<br />ating the objective or a single constraint, this conjunction<br />cannot be satisfied by a single observation under a myopic<br />search policy. Thus, the new observed x cannot become<br />the new incumbent as a result of a decoupled observation<br />and the expected improvement is zero. Therefore standard<br />EIC fails in the decoupled setting. Gelbart et al. (2014) cir-<br />cumvent this pathology by treating decoupling as a special<br />case and using a two-stage acquisition function: first, x is<br />chosen with EIC, and then the task (whether to evaluate the<br />objective or one of the constraints) is chosen with Entropy<br />Search (Hennig &amp; Schuler, 2012) given x. This approach<br />does not take full advantage of the available information in<br />the way a joint selection of x and the task would.<br />Our new method, PESC, does not suffer from these<br />pathologies. First, the PESC acquisition function does not</p>  <p>Page 3</p> <p>Predictive Entropy Search with Unknown Constraints<br />depend on the current best feasible solution, so it can op-<br />erate coherently even when there is not yet a feasible solu-<br />tion. Second, PESC naturally separates the contribution of<br />each task (objective or constraint) in its acquisition func-<br />tion. As a result, no pathology arises in the decoupled case<br />and, thus, no ad hoc modifications to the acquisition func-<br />tion are required. Furthermore, in addition to its increased<br />generality, our experiments show that PESC performs fa-<br />vorably when compared to EIC even in the basic setting of<br />joint evaluations to which EIC is most suited.<br />3. Predictive entropy search with constraints<br />We seek to maximize information about the location x?,<br />the constrained global maximum, whose posterior distribu-<br />tion is p(x?|D0<br />let DN= {(xn,yn)}n≤N denote all the observations up<br />to step N, where ynis a vector collecting the objective and<br />constraint observations at step n. The next query xN+1<br />can then be defined as that which maximizes the expected<br />reduction in the differential entropy H[·] of the posterior<br />on x?. We can write the PESC acquisition function as<br />N,...,DK<br />N). In the coupled setting we will<br />α(x) = H[x?|DN] − Ey{H[x?|DN∪ (x,y)]}<br />where the expectation is taken with respect to the posterior<br />distribution on the noisy evaluations of f and c1,...,cK<br />at x, that is, p(y|DN,x).<br />The exact computation of the above expression is infeasi-<br />ble in practice. Instead, we follow Houlsby et al. (2012);<br />Hern´ andez-Lobato et al. (2014) and take advantage of the<br />symmetry of mutual information, rewriting this acquisition<br />function as the mutual information between y and x?given<br />the collected data DN. That is,<br />α(x) = H[y|DN,x] − Ex?{H[y|DN,x,x?]}<br />where the expectation is now with respect to the poste-<br />rior p(x?|DN) and where p(y|DN,x,x?) is the posterior<br />predictive distribution for objective and constraint values<br />given past data and the location of the global solution to<br />the constrained optimization problem x?. We call this dis-<br />tribution the conditioned predictive distribution (CPD).<br />(4)<br />(5)<br />The first term on the right-hand side of (5) is straightfor-<br />ward to compute: it is the entropy of the predictive dis-<br />tribution of independent Gaussians. This is one half of the<br />sumofthelogpredictivevariancesplus1<br />However, the second term has to be approximated. For<br />this, wefirstapproximatetheexpectationbyaveragingover<br />samples of x?approximately drawn from p(x?|DN). To<br />sample x?, we first approximately draw f and c1,...,cK<br />from their GP posteriors using a finite parameterization of<br />these functions. Then we solve a constrained optimization<br />problem using the sampled functions. The solution to this<br />2(K+1)log(2πe).<br />problem is the sample of x?. This optimization approach<br />is an extension of the approach described in more detail<br />by Hern´ andez-Lobato et al. (2014), extended to the con-<br />strained setting. For each value of x?generated by this<br />procedure, we approximate the CPD p(y|DN,x,x?) as de-<br />scribed in the next section.<br />3.1. Approximating the CPD<br />Let z = [f(x),c1(x),...,cK(x)]Tdenote the concate-<br />nated vector of the noise-free objective and constraint val-<br />ues at x. We can approximate the CPD by first approx-<br />imating the posterior predictive distribution of z condi-<br />tioned on DN, x, and x?, which we call the noise free CPD<br />(NFCPD),andthenconvolvingthatapproximationwithad-<br />ditive Gaussian noise of variance σ2<br />can be informally written as<br />0,...,σ2<br />K. The NFCPD<br />p(z|DN,x,x?) ∝<br />?<br />?<br />δ[z0− f(x)]<br />??K<br />k=1Θ[ck(x?)]<br />1 −?K<br />k=1δ[zk− ck(x)]<br />?<br />x??=x?<br />???K<br />?<br />Θ[f(x?) − f(x?)] +<br />????K<br />?<br />k=1Θ[ck(x?)<br />k=1Θ[ck(x?)]<br />?<br />p(f,c1,...,cK|DN)df dc1... dck<br />where Θ denotes the Heaviside step function, and the inte-<br />gral above marginalizes out the infinite dimensional quanti-<br />ties f, c1,...,cKwhich encode the objective and the con-<br />straint functions. These infinite dimensional vectors are<br />sampled from p(f,c1,...,ck|DN), given as infinite, multi-<br />variate Gaussian distributions. The Dirac delta functions in<br />thesecondlineof(6)projecttheseinfinitedimensionalvec-<br />tors to their corresponding values at x. The infinite product<br />in the middle lines of (6) guarantee that x?is the global<br />solution, by taking value one when f(x?) is smaller than<br />f(x?) for all feasible x??= x?and zero otherwise.<br />(6)<br />We find a Gaussian approximation to (6) in several steps.<br />We first approximate the infinite product with one that is<br />finite dimensional, only evaluated at those locations where<br />the objective has been observed. Let f denote the (N +1)-<br />dimensional vector containing objective function evalua-<br />tions at x?and x1,...,xN, and define constraint vectors<br />c1,...,cKsimilarly. We can then obtain a finite dimen-<br />sional approximation to the relevant factors of (6) as<br />q1(f,c1,...,cK) =<br />?n<br />k=1Θ[ck0]<br />i=1<br />???K<br />k=1Θ[cki]<br />?<br />?<br />Θ[f0− fi] +<br />?<br />1 −?K<br />k=1Θ[cki]<br />??<br />(7)<br />??K<br />where p(f,c1,...,cK|DN) is the GP predictive distribu-<br />tion for objective and constraint values. Because (7) is<br />not tractable, we approximate the normalized version of q1<br />p(f,c1,...,cK|DN)</p>  <p>Page 4</p> <p>Predictive Entropy Search with Unknown Constraints<br />with a product of Gaussians using expectation propagation<br />(EP) (Minka, 2001). In particular, we obtain<br />Z−1<br />1q1(f,c1,...,cK) ≈ q2(f,c1,...,cK) =<br />N(f|m0,V0)?K<br />where Z1is the normalization constant of q1and (mk,Vk)<br />for k = 0,...,K are the mean and covariance terms deter-<br />mined by EP. Details on the implementation of EP can be<br />found in the supplementary material, however roughly this<br />algorithm proceeds by iteratively refining individual fac-<br />tors to fit the joint distribution where a single Gaussian has<br />been replaced by its true (but intractable) factor. Given q2,<br />we can approximate (6) by<br />?<br />???K<br />q2(f,c1,...,cK)df dc1 ··· dcK,<br />where p(z|f,c1,...,cK) is a K + 1 dimensional, Gaus-<br />sian conditional distribution given by the GP priors<br />on f,c1,...,cKand Z2is a normalization constant. This<br />conditional distribution approximates the deltas in the sec-<br />ond line of (6). Note that, in the third line of (9), we have<br />introduced one of the factors forming the infinite product in<br />(6). This is the factor corresponding to the point x at which<br />we are making predictions and guarantees that z0= f(x)<br />is smaller than f0= f(x?) when all the constraints are sat-<br />isfied at x—i.e., when zk= ck(x) ≥ 0 for all k. After<br />marginalizing out f and c1,...,cKwe move from (9) to<br />our final approximation of the NFCPD:<br />k=1N(ck|mk,Vk),<br />(8)<br />p(z|DN,x,x?) ≈ Z−1<br />2<br />p(z|f,c1,...,cK)<br />?<br />k=1Θ[zk]<br />?<br />Θ[f0− z0] +1 −?K<br />k=1Θ[zk]<br />??<br />(9)<br />p(z|DN,x,x?) ≈<br />Z−1<br />2<br />????K<br />N([z0,f0]|m?<br />Details on how to compute the means m?<br />variances v?<br />vector m?<br />in the supplementary material.<br />k=1Θ[zk]<br />?<br />Θ[f0− z0] +<br />0,V?<br />?<br />1 −?K<br />k,v?<br />k=1Θ[zk]<br />??<br />(10)<br />0)?K<br />k=1N(zk|m?<br />k)df0.<br />1,...,mK and<br />1,...,v?<br />0and the 2×2 covariance matrix V?<br />K, as well as the 2-dimensional mean<br />0can be found<br />3.2. The PESC acquisition function<br />The normalization constant Z2in (9) and (10) can be com-<br />puted analytically. This allows us to obtain the marginal<br />variances of the right-hand-side of (10) by computing the<br />gradient of logZ2with respect to m?<br />v?<br />responding expressions are included in the supplementary<br />material. If we assume independence in the NFCPD (6),<br />we can then approximate the entropy in the CPD by per-<br />forming the following operations. First, we add the noise<br />variances σ2<br />0, V?<br />0, m?<br />1,...,mK,<br />1,...,v?<br />Kusing formula 5.13 in Minka (2001). The cor-<br />0,σ2<br />1,...,σ2<br />Kto the marginal variances of the<br />right-hand-side of (10) and second, after assuming Gaus-<br />sianity, we sum one half of the logarithm of the resulting<br />variances and finally add<br />2<br />quisition function, which approximates (4), is then<br />(K+1)<br />log(2πe). The PESC ac-<br />α(x) =<br />?<br />?K<br />1<br />M<br />?M<br />k=1<br />i=1g[vPD<br />?<br />f(x),vCPD<br />?N<br />f<br />(x|x(i)<br />? )]<br />?<br />+<br />1<br />N<br />n=1g[vPD<br />k(x),vCPD<br />k<br />(x|x(i)<br />? )]<br />?<br />,<br />(11)<br />where M is the number of samples drawn from p(x?|DN),<br />x(i)<br />vPD<br />the noisy evaluations of f and ck at x, respectively,<br />and vCPD<br />fk<br />marginal variances of the CPD for the noisy evaluations<br />of f and ckat x given that x?= x(i)<br />(11) over the GP hyper-parameters can be done efficiently<br />as in Hern´ andez-Lobato et al. (2014).<br />? is the i-th of these samples, g(a,b) =1<br />f(x) and vPD<br />2(loga − logb),<br />k(x) are the predictive variances for<br />(x|x(i)<br />? ) and vCPD<br />(x|x(i)<br />? ) are the approximated<br />? . Marginalization of<br />The PESC acquisition function is additive in the expected<br />amount of information that is obtained from the evalua-<br />tion of each task (objective or constraint) at any partic-<br />ular location x. For example, the expected information<br />gain obtained from the evalation of f at x is given by<br />the term<br />N<br />other K terms in (11) measure the corresponding contri-<br />bution from evaluating each of the constraints. This allows<br />PESC to easily address the decoupled scenario when one<br />can independently evaluate the different functions at dif-<br />ferent locations. In other words, Equation (11) is a sum<br />of individual acquisition functions, one for each function<br />that we can evaluate. Existing methods for Bayesian opti-<br />mization with unknown constraints (described in the next<br />section) do not possess this desirable property. Finally, the<br />complexity of PESC is of order O(MKN3) in the coupled<br />setting. As with unconstrained PES, this is dominated by<br />the cost of a matrix inversion in the EP step. In the decou-<br />pled setting this becomes O(M?K<br />1<br />?N<br />n=1g[vPD<br />f(x),vCPD<br />f<br />(x|x(i)<br />? )] in (11). The<br />k=1N3<br />k) where Nkis the<br />number of evaluations for the objective and constraint k.<br />4. Related Work<br />In this section we describe other methods that have previ-<br />ously been proposed to address Bayesian optimization with<br />unknown constraints. Most of them, like EIC, are based on<br />extensions of the expected improvement heuristic (Mockus<br />et al., 1978; Jones et al., 1998). Because these acquisition<br />functions are based on improvement, they are susceptible<br />to pathologies similar to those affecting EIC described in<br />Section 2. These methods can be effective in certain con-<br />texts but do not necessarily apply more generally.</p>  <p>Page 5</p> <p>Predictive Entropy Search with Unknown Constraints<br />4.1. Augmented Lagrangian<br />Gramacy et al. (2014) propose a combination of the<br />expected improvement heuristic and the augmented La-<br />grangian (AL) optimization framework for constrained<br />blackbox optimization. AL methods are a class of algo-<br />rithms for constrained nonlinear optimization that work by<br />iteratively optimizing the unconstrained AL:<br />?<br />where p &gt; 0 is a penalty parameter and λ ≥ 0 is an ap-<br />proximate Lagrange multiplier.<br />tion at iteration n with parameters p(n)and λ(n). Then,<br />λ(n+1)<br />kk<br />and p(n+1)= p(n)if x(n)<br />?<br />is feasible and p(n+1)= p(n)/2<br />otherwise.<br />LA(x|λ,p) = f(x) −<br />K<br />?<br />k=1<br />λkck(x) +1<br />2pmin(0,ck(x))2<br />?<br />Let x(n)<br />?<br />be the solu-<br />= max(0,λ(n)<br />− ck(x(n)<br />? )/p(n)) for k = 1,...,K<br />The method proposed by Gramacy et al. (2014) assumes<br />that the evaluations of the constraints c1,...,cKare noise-<br />free.At the nth iteration, the next evaluation loca-<br />tion is the one that maximizes the EI of the compos-<br />ite objective given by LA(x|λ(n),p(n)), with λ(0)<br />k = 1,...,K and p(0)= 1/2. Because LA(x|λ(n),p(n))<br />is unconstrained, the AL approach does not have to find<br />a best solution that is feasible, unlike EIC. However, AL<br />is limited by requiring noiseless constraints so that p and<br />λ can be updated at each iteration. In section 5.3 we show<br />that PESC and EIC perform better than AL on the synthetic<br />benchmark problem considered in Gramacy et al. (2014),<br />even when the AL method has access to the true objective<br />function and PESC and EIC do not.<br />k<br />= 0 for<br />4.2. Integrated expected conditional improvement<br />Gramacy &amp; Lee (2010) propose an acquisition function<br />based on the integrated expected conditional improvement<br />(IECI), which is given by<br />?<br />where EI(x?) is the expected improvement at x?<br />and EI(x|x?) is the expected improvement at x?when the<br />objective has been evaluated at x, but without knowing the<br />value obtained. The IECI at x is the expected reduction in<br />improvement at x?under the density h(x?) caused by ob-<br />serving the objective at that location, where h(x?) is the<br />probability of all the constraints being satisfied at x?. IECI<br />measuresimprovementoverthebestsolutionη, whichGra-<br />macy &amp; Lee (2010) define as the highest posterior mean<br />of the objective over the whole optimization domain. The<br />motivation for IECI is that evaluating at an infeasible lo-<br />cation may also provide useful information, and therefore<br />one should consider improvement over the whole optimiza-<br />tion domain. Gelbart et al. (2014) compare IECI with EIC<br />IECI(x) =[EI(x?) − EI(x?|x)]h(x?)dx?,<br />(12)<br />for optimizing the hyper-parameters of a topic model with<br />constraints on the entropy of the per-topic word distribution<br />and show that EIC outperforms IECI for this problem.<br />4.3. Stepwise uncertainty reduction<br />Picheny (2014) proposes to sequentially evaluate the lo-<br />cation that most decreases, in expectation, an uncertainty<br />measure given by integrating the product of the probability<br />of improvement and the probability of feasibility. This is<br />the expected volume (EV) of the admissible excursion set<br />above the best feasible objective η found so far. That is,<br />?<br />where, as in IECI, h(x?) is the probability of the constraints<br />being satisfied at x?. This step-wise uncertainty reduction<br />approach (SURA) is similar to PESC in that both methods<br />work by reducing a specific type of uncertainty measure<br />(entropy for PESC and EV for SURA). However, SURA is<br />limited by having to compute the integral in (13) over the<br />entire domain, which is done numerically over a grid on x?<br />(Picheny, 2014). The resulting acquisition function must<br />then be globally optimized, which also requires a grid on x.<br />This nesting of grid operations limits the application of this<br />method to small d. IECI has the same limitation. PESC<br />also involves an integral over the posterior on x?; however,<br />this can be done efficiently using the sampling approach<br />described in Hern´ andez-Lobato et al. (2014). Finally, since<br />SURA is based on improvement (along with EIC, LA and<br />IECI), it does not apply to the decoupled constraints sce-<br />nario in which one can individually evaluate the objective<br />or the constraints. PESC does not have this limitation.<br />EV(x) =p[f(x?) ≥ max(η,f(x))]h(x?)dx?,<br />(13)<br />5. Experiments<br />We evaluate the performance of predictive entropy search<br />with constraints (PESC) through experiments with i) syn-<br />thetic functions sampled from the GP prior distribution, ii)<br />analytic benchmark problems previously used in the liter-<br />ature on Bayesian optimization with unknown constraints<br />and iii) real-world constrained optimization problems.<br />For case i) above, the synthetic functions sampled from the<br />GP prior are generated following the same experimental set<br />up as in Hennig &amp; Schuler (2012) and Hern´ andez-Lobato<br />et al. (2014). The search space is the unit hypercube of<br />dimension d, and the ground truth objective f is a sample<br />from a zero-mean GP with a squared exponential covari-<br />ance function of unit amplitude and length scale ? = 0.1 in<br />each dimension. We represent the function f by first sam-<br />pling from the GP prior on a grid of 1000 points generated<br />using a Halton sequence (see Leobacher &amp; Pillichsham-<br />mer, 2014) and then defining f as the resulting GP pos-<br />terior mean. We use a single constraint function c1whose</p>  <p>Page 6</p> <p>Predictive Entropy Search with Unknown Constraints<br />Acquisition Functions<br />Number of Function Evaluations<br />Log Median Utility Gap<br />Results for d=1<br />0.00.2 0.40.6 0.81.0<br />−3<br />−3<br />−2<br />−1<br />00<br />1<br />2<br />3<br />3<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />0.0 0.2 0.40.6 0.8<br />1.0<br />0.0<br />0.2<br />0.4<br />0.6<br />0.8<br />x<br />Acqusition Function<br />Objective<br />Constraint<br />Marginal Posterior Distributions<br />RS<br />PESC<br />x<br />●●●●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●●●<br />●●●<br />●●<br />●<br />●●●●●●●●●●●●●●●●●●●●●●●●●●●●●<br />●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●<br />●<br />●●●●●●●<br />●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●<br />●<br />●<br />●<br />●<br />●●<br />●●●●●●●<br />●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●<br />−3.5<br />−2.5<br />−1.5<br />−0.5<br />0255075 100<br />Methods<br />PESC<br />RS<br />RSDG<br />●<br />●<br />●<br />10<br />Figure 1. Left: marginal posterior predictive distributions for the objective and a single constraint function given some collected data<br />denoted by crosses. Middle: PESC and RS acquisition functions given these data. Right: median utility gap for PESC, RS and RSD in<br />the experiments with synthetic functions sampled from the GP prior with d = 1.<br />ground truth is sampled in the same way as f. The evalu-<br />ations for f and c1are contaminated with i.i.d. Gaussian<br />noise with variance σ2<br />f= σ2<br />1= 0.01.<br />5.1. Accuracy of the PESC approximation<br />We first analyze the accuracy of the approximation to (5)<br />generated by PESC. We compare the PESC approximation<br />with a ground truth for (5) obtained by rejection sampling<br />(RS). The RS method works by discretizing the search<br />space using a uniform grid.<br />spect to p(x?|Dn) in (5) is then approximated by Monte<br />Carlo. To achieve this, f and c1,...,cKare sampled on<br />the grid and the grid cell with positive c1,...,cK (fea-<br />sibility) and the highest value of f (optimality) is se-<br />lected. For each sample of x? generated by this proce-<br />dure, H[p(y|Dn,x,x?)] is approximated by rejection sam-<br />pling: we select those samples of f and c1,...,cKwhose<br />corresponding feasible optimal solution is the sampled x?<br />and reject the other samples. We then assume that the se-<br />lected samples for f and c1,...,cKare independent and<br />have Gaussian marginal distributions. Under this assump-<br />tion, H[p(y|Dn,x,x?)] can be approximated using the for-<br />mula for the entropy of independent Gaussian random vari-<br />ables, with the variance parameters in this formula being<br />equal to the empirical marginal variances of the selected<br />samples of f and c1,...,cKat x plus the corresponding<br />noise variances σ2<br />The expectation with re-<br />fand σ2<br />1,...,σ2<br />K.<br />The left plot in Figure 1 shows the posterior distribution<br />for f and c1given 5 evaluations sampled from the GP prior<br />with d = 1. The posterior is computed using the optimal<br />GP hyperparameters. The corresponding approximations<br />to (5) generated by PESC and RS are shown in the middle<br />plot of Figure 1. Both PESC and RS use a total of 50 sam-<br />ples from p(x?|Dn) when approximating the expectation<br />in (5). The PESC approximation is very accurate, and im-<br />portantly its maximum value is very close to the maximum<br />value of the RS approximation.<br />One disadvantage of the RS method is its high cost, which<br />scales with the size of the grid used. This grid has to be<br />large to guarantee good performance, especially when d is<br />large. An alternative is to use a small dynamic grid that<br />changes as data is collected. Such a grid can be obtained<br />by sampling from p(x?|Dn) using the same approach as in<br />PESC. The samples obtained would then form the dynamic<br />grid. The resulting method is called Rejection Sampling<br />with a Dynamic Grid (RSDG).<br />We compare the performance of PESC, RS and RSDG in<br />experiments with synthetic data corresponding to 500 pairs<br />of f and c1sampled from the GP prior with d = 1. At<br />each iteration, RSDG draws the same number of samples<br />of x?as PESC. We fix δ1= 0.05 and assume that the GP<br />hyperparameter values are known to each method. Recom-<br />mendations are made by finding the location with highest<br />posterior mean for f such that c1is non-negative with prob-<br />ability at least 1 − δ1. For reporting purposes, we set the<br />utility u(x) of a recommendation x to be f(x) if x satisfies<br />the constraint, and otherwise a penalty value of the worst<br />(largest) objective function value achievable in the search<br />space. For each recommendation at x, we compute the<br />utility gap |u(x) − u(x?)|, where x?is the true solution of<br />the optimization problem. Each method is initialized with<br />the same three random points drawn with Latin hypercube<br />sampling.<br />The right plot in Figure 1 shows the median of the utility<br />gap for each method across the 500 realizations of f and c1.<br />The x-axis in this plot is the number of joint function eval-<br />uations for f and c1. We report the median because the<br />empirical distribution of the utility gap is heavy-tailed and<br />in this case the median is more representative of the lo-<br />cation of the bulk of the data than the mean. The heavy<br />tails arise because we are measuring performance across<br />500 different optimization problems with very different de-<br />grees of difficulty. In this and all following experiments,<br />standard errors on the reported plot are computed using</p>  <p>Page 7</p> <p>Predictive Entropy Search with Unknown Constraints<br />●●●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />0.2<br />0.5<br />01020<br />Results for d = 8<br />Results for d = 2<br />Number of Function Evaluations<br />Number of Function Evaluations<br />Methods<br />EIC<br />PESC<br />RSDG<br />●<br />●<br />●<br />●●<br />●<br />●<br />●<br />●<br />●<br />●●●<br />●<br />●<br />●●<br />●●●●●●●●<br />●●<br />●●●●<br />●<br />●●●●●●<br />●●●<br />●<br />●<br />●<br />●<br />●●<br />●●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●●<br />●<br />●●●<br />●<br />●●●●●●●●●<br />●●●●●●●●●<br />●●●●●●●●<br />●●●●●●●●●●<br />●●●●●●●●●●●●●●●●●●●●●●●●●●●●●<br />●●<br />●<br />●<br />●●●<br />●<br />●<br />●<br />●●<br />●●●<br />●●●<br />●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●<br />●●<br />●●<br />●<br />●<br />●<br />●●●●<br />●●<br />●●●●<br />●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●<br />−2.6<br />−1.6<br />−0.6<br />0 25 5075 100<br />Log Median Utility Gap<br />10<br />Methods<br />EIC<br />PESC<br />RSDG<br />●<br />●<br />●<br />Log Median Utility Gap<br />10<br />Figure 2. Optimizing samples from the prior with d = 2 (top) and<br />d = 8 (bottom).<br />the bootstrap. The plot shows that PESC and RS are bet-<br />ter than RSDG. Furthermore, PESC is very similar to RS,<br />with PESC even performing slightly better at the end of the<br />data collection process since PESC is not limited by a finite<br />grid as RS is. These results show that PESC yields a very<br />accurate approximation of the information gain. Further-<br />more, although RSDG performs worse than PESC, RSDG<br />is faster because the rejection sampling operation (with a<br />small grid) is less expensive than the EP algorithm. Thus,<br />RSDG is an attractive alternative to PESC when the avail-<br />able computing time is very limited.<br />5.2. Synthetic functions in 2 and 8 input dimensions<br />We also compare the performance of PESC and RSDG<br />with that of EIC (Section 2) using the same experimen-<br />tal protocol as in the previous section, but with dimen-<br />sionalities d = 2 and d = 8. We do not compare with RS<br />here because its use of grids does not scale to higher di-<br />mensions. Figure 2 shows the utility gap for each method<br />across 500 different samples of f and c1from the GP prior<br />with d = 2 (top) and d = 8 (bottom). Overall, PESC is the<br />best method, followed by RSDG and EIC. RSDG performs<br />similarly to PESC when d = 2, but is significantly worse<br />when d = 8. This shows that, when d is high, grid based<br />approaches (e.g. RSDG) are at a disadvantage with respect<br />to methods that do not require a grid (e.g. PESC).<br />●●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />●<br />−2.3<br />−1.3<br />−0.3<br />0102030<br />Number of Function Evaluations<br />Methods<br />AL<br />EIC<br />PESC<br />●<br />●<br />●<br />Results on the Toy Problem<br />Log Mean Utility Gap<br />10<br />Figure 3. Mean utility gap for PESC and EIC in the toy problem.<br />5.3. A toy problem<br />We compare PESC with EIC and AL (Section 4.1) in the<br />toy problem described in Gramacy et al. (2014). We seek<br />to maximize the function f(x) = −x1− x2, subject to the<br />constraint functions c1(x) ≥ 0 and c2(x) ≥ 0, given by<br />c1(x) = 0.5sin(2π(x2<br />c2(x) = −x2<br />where x is confined to the unit square. The evaluations for<br />f, c1and c2are noise-free. We compare PESC and EIC<br />with δ1= δ2= 0.025 and a squared exponential GP ker-<br />nel. PESC uses 10 samples from p(x?|Dn) when approx-<br />imating the expectation in (5). We use the AL implemen-<br />tation provided by Gramacy et al. (2014) in the R package<br />laGP which is based on the squared exponential kernel and<br />assumes the objective f is known. Thus, in order for this<br />implementation to be used, AL has an advantage over other<br />methods in that it has access to the true objective function.<br />In all three methods, the GP hyperparameters are estimated<br />by maximum likelihood.<br />1− 2x2)) + x1+ 2x2− 1.5, (14)<br />2+ 1.5,<br />1− x2<br />(15)<br />Figure 3 shows the mean utility gap for each method across<br />500 independent realizations. Each realization corresponds<br />to a different initialization of the methods with three data<br />points selected with Latin hypercube sampling. Here, we<br />report the mean because we are now measuring perfor-<br />mance across realizations of the same optimization prob-<br />lem and the heavy-tailed effect described in Section 5.1 is<br />less severe. The results show that PESC is significantly<br />better than EIC and AL for this problem. EIC is superior<br />to AL, which performs slightly better at the beginning be-<br />cause it has access to the ground truth objective f.<br />5.4. Finding a fast neural network<br />In this experiment, we tune the hyperparamters of a three-<br />hidden-layer neural network subject to the constraint that<br />the prediction time must not exceed 2 ms on a GeForce<br />GTX 580 GPU (also used for training). The search space<br />consists of 12 parameters: 2 learning rate parameters (ini-</p>  <p>Page 8</p> <p>Predictive Entropy Search with Unknown Constraints<br />tial and decay rate), 2 momentum parameters (initial and<br />final), 2 dropout parameters (input layer and other layers),<br />2 other regularization parameters (weight decay and max<br />weight norm), the number of hidden units in each of the 3<br />hidden layers, the activation function (RELU or sigmoid).<br />The network is trained on a using the deepnet package1,<br />and the prediction time is computed as the average time of<br />1000 predictions, each for a batch of size 128. The net-<br />work is trained on the MNIST digit classification task with<br />momentum-based stochastic gradient descent for 5000 iter-<br />ations. The objective is reported as the classification error<br />rate on the validation set. As above, we treat constraint<br />violations as the worst possible value (in this case a classi-<br />fication error of 1.0).<br />Figure 4 shows the results of 50 iterations of Bayesian opti-<br />mization. In this experiment and the next, the y-axis repre-<br />sents observed function values, δ1= 0.05, a Mat´ ern 5/2 GP<br />covariance kernel is used, and GP hyperparameters are in-<br />tegrated out using slice sampling (Neal, 2000) as in Snoek<br />et al. (2012). Curves are the mean over 5 independent ex-<br />periments. We find that PESC performs significantly better<br />than EIC. However, when the noise level is high, report-<br />ing the best observation is an overly optimistic metric (due<br />to “lucky” evaluations); on the other hand, ground-truth is<br />not available. Therefore, to validate our results further, we<br />used the recommendations made at the final iteration of<br />Bayesian optimization for each method (EIC and PESC)<br />and evaluted the function with these recommended param-<br />eters. We repeated the evaluation 10 times for each of the 5<br />repeated experiments to compute a ground-truth score av-<br />eraged of 50 function evaluations. This procedure yields a<br />score of 0.45±0.06 for PESC and 0.79±0.03 for EIC (as in<br />the Figure, constraint violations are treated as a classifica-<br />tion error of 100%). This result is consistent with Figure 4<br />in that PESC performs significantly better than EIC, but<br />also demonstrates that, due to noise, Figure 4 is overly op-<br />timistic. While we may believe this optimism to affect both<br />methods equally, the ground-truth measurement provides a<br />more reliable result and a much clearer understanding of<br />the classification error attained by Bayesian optimization.<br />5.5. Tuning Markov chain Monte Carlo<br />Hybrid Monte Carlo, also known as Hamiltonian Monte<br />Carlo (HMC), is a popular Markov Chain Monte Carlo<br />(MCMC) technique that uses gradient information in a nu-<br />merical integration to select the next sample. However,<br />using numerical integration gives rise to new parameters<br />like the integration step size and the number of integration<br />steps. Following the experimental set up in Gelbart et al.<br />(2014), we optimize the number of effective samples pro-<br />duced by an HMC sampler limited to 5 minutes of com-<br />1https://github.com/nitishsrivastava/deepnet<br />0 1020 30 40 50<br />Number of function evaluations<br />1.6<br />1.4<br />1.2<br />1.0<br />0.8<br />0.6<br />0.4<br />0.2<br />0.0<br />0.2<br />log10 objective value<br />EIC<br />PESC<br />Figure 4. Classification error of a 3-hidden-layer neural network<br />constrained to make predictions in under 2 ms.<br />putation time, subject to passing of the Geweke (Geweke,<br />1992) and Gelman-Rubin (Gelman &amp; Rubin, 1992) conver-<br />gence diagnostics, as well as the constraint that the numer-<br />ical integration should not diverge. We tune 4 parameters<br />of an HMC sampler: the integration step size, number of<br />integration steps, fraction of the allotted 5 minutes spent in<br />burn-in, and an HMC mass parameter (see Neal, 2011). We<br />use the coda R package (Plummer et al., 2006) to compute<br />the effective sample size and the Geweke convergence di-<br />agnostic, and the PyMC python package (Patil et al., 2010)<br />to compute the Gelman-Rubin diagnostic over two inde-<br />pendent traces. Following Gelbart et al. (2014), we impose<br />the constraints that the absolute value of the Geweke test<br />scorebeatmost2.0andtheGelman-Rubinscorebeatmost<br />1.2, and sample from the posterior distribution of a logistic<br />regression problem using the UCI German credit data set<br />(Frank &amp; Asuncion, 2010).<br />Figure 5 evaluates EIC and PESC on this task, averaged<br />over 10 independent experiments. As above, we perform a<br />ground-truthassessmentofthefinalrecommendations. The<br />average effective sample size is 3300±1200 for PESC and<br />2300 ± 900 for EIC. From these results we draw a similar<br />conclusion to that of Figure 5; namely, that PESC outper-<br />forms EIC but only by a small margin, and furthermore that<br />the experiment is very noisy.<br />6. Discussion<br />In this paper, we addressed global optimization with un-<br />known constraints. We described existing methods and<br />discuss their weaknesses. We presented PESC, a method<br />based on the theoretically appealing expected information<br />gain heuristic. We showed in Figure 1 that the mathemat-<br />ical approximations involved in PESC are quite accurate,<br />and that PESC performs about equally well to a ground<br />truth method based on rejection sampling. In sections 5.2<br />to 5.5, we showed that PESC outperforms current methods</p>  <p>Page 9</p> <p>Predictive Entropy Search with Unknown Constraints<br />020406080100<br />Number of function evaluations<br />-5<br />-4<br />-3<br />-2<br />-1<br />0<br />−log10 effective sample size<br />EIC<br />PESC<br />Figure 5. Tuning Hamiltonian Monte Carlo to maximize the num-<br />ber of effective samples within 5 minutes of compute time.<br />such as EIC and AL over a variety of problems. In ad-<br />dition, PESC is easily applied to problems with decoupled<br />constraints, with noadditional computationalcostand none<br />of the pathologies discussed in Gelbart et al. (2014).<br />One disadvantage of PESC is that it is relatively difficult to<br />implement: in particular, the EP approximation often leads<br />to numerical instabilities. Therefore, we have integrated<br />our implementation, which carefully addresses these nu-<br />merical issues, into the open-source Bayesian optimization<br />package Spearmint at https://github.com/HIPS/<br />Spearmint/tree/PESC. We have demonstrated that<br />PESC is a flexible and powerful method and we hope the<br />existence of such a method will bring constrained Bayesian<br />optimization into the standard toolbox of Bayesian opti-<br />mization practitioners.<br />Acknowledgements<br />Jos´ e Miguel Hern´ andez-Lobato acknowledges support<br />from the Rafael del Pino Foundation.<br />mani acknowledges support from Google Focused Re-<br />search Award and EPSRC grant EP/I036575/1. Matthew<br />W. Hoffman acknowledges support from EPSRC grant<br />EP/J012300/1.<br />Zoubin Ghahra-<br />References<br />Brochu, Eric, Cora, Vlad M., and de Freitas, Nando. A tu-<br />torial on Bayesian optimization of expensive cost func-<br />tions, 2010. arXiv:1012.2599 [cs.LG].<br />Frank, Andrew and Asuncion, Arthur. UCI machine learn-<br />ing repository, 2010.<br />Gardner, Jacob R., Kusner, Matt J., Xu, Zhixiang (Ed-<br />die), Weinberger, Kilian Q., and Cunningham, John P.<br />Bayesian optimization with inequality constraints. In<br />ICML, 2014.<br />Gelbart, Michael A., Snoek, Jasper, and Adams, Ryan P.<br />Bayesian optimization with unknown constraints.<br />UAI, 2014.<br />In<br />Gelman, Andrew and Rubin, Donald R. A single series<br />from the Gibbs sampler provides a false sense of secu-<br />rity. In Bayesian Statistics, pp. 625–32. Oxford Univer-<br />sity Press, 1992.<br />Geweke, John. Evaluating the accuracy of sampling-based<br />approaches to the calculation of posterior moments. In<br />BayesianStatistics, pp.169–193.UniversityPress, 1992.<br />Gramacy, Robert B. and Lee, Herbert K. H. Optimiza-<br />tion under unknown constraints, 2010. arXiv:1004.4027<br />[stat.ME].<br />Gramacy, Robert B., Gray, Genetha A., Digabel, Se-<br />bastien Le, Lee, Herbert K. H., Ranjan, Pritam, Wells,<br />Garth, and Wild, Stefan M. Modeling an augmented La-<br />grangian for improved blackbox constrained optimiza-<br />tion, 2014. arXiv:1403.4890v2 [stat.CO].<br />Hennig, Philipp and Schuler, Christian J. Entropy search<br />for information-efficient global optimization. JMLR, 13,<br />2012.<br />Hern´ andez-Lobato, J. M, Hoffman, M. W., and Ghahra-<br />mani, Z. Predictive entropy search for efficient global<br />optimization of black-box functions.<br />Neural Information Processing Systems 25. Curran As-<br />sociates, Inc., 2014.<br />In Advances in<br />Houlsby, N., Hern´ andez-Lobato, J. M, Huszar, F., and<br />Ghahramani, Z. Collaborative Gaussian processes for<br />preference learning. In Advances in Neural Information<br />Processing Systems 25, pp. 2096–2104. Curran Asso-<br />ciates, Inc., 2012.<br />Jones,<br />William J. Efficient global optimization of expensive<br />black-box functions. Journal of Global optimization, 13<br />(4):455–492, 1998.<br />Donald R, Schonlau,Matthias,and Welch,<br />Leobacher, Gunther and Pillichshammer, Friedrich. Intro-<br />duction to quasi-Monte Carlo integration and applica-<br />tions. Springer, 2014.<br />Minka, Thomas P. A family of algorithms for approximate<br />Bayesian inference. PhD thesis, Massachusetts Institute<br />of Technology, 2001.<br />Mockus, Jonas, Tiesis, Vytautas, and Zilinskas, Antanas.<br />The application of Bayesian methods for seeking the ex-<br />tremum. Towards Global Optimization, 2, 1978.<br />Neal, Radford. Slice sampling. Annals of Statistics, 31:<br />705–767, 2000.</p>  <p>Page 10</p> <p>Predictive Entropy Search with Unknown Constraints<br />Neal, Radford. MCMC using Hamiltonian dynamics. In<br />Handbook of Markov Chain Monte Carlo. Chapman and<br />Hall/CRC, 2011.<br />Patil, Anand, Huard, David, and Fonnesbeck, Christopher.<br />PyMC: Bayesian stochastic modelling in Python. Jour-<br />nal of Statistical Software, 2010.<br />Picheny, Victor. A stepwise uncertainty reduction approach<br />to constrained global optimization. In Proceedings of the<br />Seventeenth International Conference on Artificial Intel-<br />ligence and Statistics, pp. 787–795, 2014.<br />Plummer, Martyn, Best, Nicky, Cowles, Kate, and Vines,<br />Karen. CODA: Convergence diagnosis and output anal-<br />ysis for MCMC. R News, 6(1):7–11, 2006.<br />Rasmussen, C. and Williams, C. Gaussian Processes for<br />Machine Learning. MIT Press, 2006.<br />Schonlau, Matthias, Welch, William J, and Jones, Don-<br />ald R.Global versus local search in constrained<br />optimization of computer models.<br />Monograph Series, pp. 11–25, 1998.<br />Lecture Notes-<br />Snoek, Jasper. Bayesian Optimization and Semiparametric<br />Models with Applications to Assistive Technology. PhD<br />thesis, University of Toronto, Toronto, Canada, 2013.<br />Snoek, Jasper, Larochelle, Hugo, and Adams, Ryan P.<br />Practical Bayesian optimization of machine learning al-<br />gorithms. In NIPS, 2012.</p>  <p>Page 11</p> <p>Supplementary Material for “Predictive Entropy Search for<br />Bayesian Optimization with Unknown Constraints”<br />José Miguel Hernández-Lobato∗, Michael A. Gelbart∗, Matthew W. Hoffman,<br />Ryan P. Adams and Zoubin Ghahramani<br />February 18, 2015<br />1Introduction<br />We are interested in finding the global maximum x⋆of an objective function f(x) over some bounded domain,<br />typically X ⊂ Rd, subject to a series of constraint functions c1,...,cKbeing positive, that is, ck(x) ≥ 0, for<br />k = 1,...,K. In particular, we want to solve problems of the form<br />maxf(x) s.t.<br />c1(x) ≥ 0,...,cK(x) ≥ 0.<br />The objective function f and the constraint functions c1,...,cK are unkown and can only be evaluated via<br />queries to black-boxes that provide noisy outputs of the form yf<br />for ck, where k = 1,...,K. In this document, we describe a sequential search algorithm that, after n<br />evaluations of the objective f and of the constraints c1,...,cK, proposes to evaluate these functions at<br />some location xn+1. To make this decision the search algorithm conditions on all previous observations<br />Df<br />N evaluations, the algorithm makes a final recommendation ? xN for the global maximizer of the objective<br />functions f and c1,...,cK to guide the search and to select ? xN. In this work we use a zero-mean Gaussian<br />where [Kf<br />described above, the vector of concatenated observations yf<br />zero mean. Therefore, at any location x, the objective function f(x) conditioned on past observations Df<br />then Gaussian with marginal mean µf<br />i∼ N(f(xi),σ2<br />f) for f and yk<br />i∼ N(ck(xi),σ2<br />k)<br />n= {(x1,yf<br />function f under the constraints given by c1,...,cK.<br />We take a Bayesian approach to the problem described above and use a probabilistic model for the latent<br />i),...,(xn,yf<br />n)}, D1<br />n,...,Dk<br />n, where Dk<br />n= {(x1,yk<br />i),...,(xn,yk<br />n)} for k = 1,...,K. After<br />process (GP) prior for all the latent functions [2]. Given any finite collection of points {x1,...,xn}, the<br />vectors with the values of f at these points are jointly zero-mean Gaussian with covariance matrix Kf<br />n]ij = kf(xi,xj) and kf is a positive-definite covariance function. For the Gaussian likelihood<br />n,<br />n= (yf<br />1,...,yf<br />n)Tis also jointly Gaussian with<br />nis<br />n(x) and variance vf<br />n(x) given by<br />µf<br />vf<br />n(x)<br />n(x)<br />=<br />=<br />kf<br />kf(x,x) − kf<br />n(x)T(Kf<br />n+ σ2<br />n(x)T(Kf<br />fI)−1yf<br />n,<br />(1)<br />(2)<br />n+ σ2<br />fI)−1kf<br />n(x),<br />where kf<br />the prior variance of f(x). Similarly, the vector with the evaluations of ck at {x1,...,xn} is also jointly<br />Gaussian with zero mean and covariance matrix Kk<br />covariance function. For the Gaussian likelihood described above, the vector of concatenated observations<br />yk<br />x, the constraint function ck(x) conditioned on past observations Dk<br />∗Authors contributed equally.<br />n(x) is a vector of prior cross-covariances between f(x) and {f(x1),...,f(xn)} and kf(x,x) is<br />n, where [Kk<br />n]ij= kk(xi,xj) and kkis a positive-definite<br />n= (yk<br />1,...,yk<br />n)Tfor the k-th constraint is also jointly Gaussian with zero mean. Therefore, at any location<br />nis Gaussian with marginal mean µk<br />n(x)<br />1</p>  <p>Page 12</p> <p>and variance vk<br />above for µf<br />n(x) for k = 1,...,K. The expressions for µk<br />n(x) and vf<br />n(x) and vk<br />n(x) are similar to the ones shown<br />n(x). In particular,<br />µk<br />vk<br />n(x)<br />n(x)<br />=<br />=<br />kk<br />kk(x,x) − kj<br />n(x)T(Kk<br />n+ σ2<br />n(x)T(Kj<br />kI)−1yk<br />n,<br />n+ σ2<br />kI)−1kk<br />n(x),<br />where kk<br />prior variance of ck(x).<br />n(x) is a vector of prior cross-covariances between ck(x) and {ck(x1),...,cK(xn)} and kk(x,x) is the<br />2Predictive entropy search with unknown constraints<br />To solve the above problem efficiently, we propose to follow the information-theoretic method for active<br />data collection described in [1]. We are interested in maximizing information about the location x⋆ of the<br />constrained global maximum, whose posterior distribution is p(x⋆|Df<br />about x⋆can be measured in terms of the negative differential entropy of p(x⋆|Df<br />our strategy is to select the xn+1that maximizes the expected reduction in this quantity. The corresponding<br />acquisition function is<br />H?p(x⋆|Df<br />n,...DK<br />where H[p(x)] = −´p(x)logp(x)dx denotes the differential entropy of its argument and the expectation<br />above is taken with respect to the posterior predictive distribution for yfand y1,...,yKgiven Df<br />and x. The exact evaluation of (3) is infeasible in practice. We simplify the problem by following the<br />approach described in [3]. Note that (3) can be equivalently written as the mutual information between x⋆<br />and yf,y1,...,yKgiven Df<br />rewritten as<br />H?p(yf,y1,...,yK|Df<br />n,...DK<br />where p(yf,y1,...,yK|Df<br />Df<br />conditioning on the location x⋆pushes the posterior predictions for f up in locations around x⋆and down<br />in regions away from x⋆. This only occurs in areas where the constraints c1,...,cKare likely to be positive.<br />However, conditioning on x⋆has no effect in other areas where c1,...,cKare likely to be negative. In addition<br />to this, conditioning on x⋆has a significant effect on c1,...,cKsince all these functions have to be positive<br />at x⋆. Therefore, we would expect that the posterior distribution of c1,...,cK is pushed up at x⋆. Note<br />that, unlike the previous formulation, the objective (4) is based on the entropies of predictive distributions,<br />which are analytic or can be easily approximated, rather than on the entropies of distributions on x⋆whose<br />approximation is more challenging.<br />The first term in (4) can be computed using the posterior marginals for f(x) and c1(x),...,cK(x):<br />?<br />n,D1<br />n,...DK<br />n). Our current information<br />n,D1<br />n,...DK<br />n). Therefore,<br />α(x)=<br />n,D1<br />n,...DK<br />n)?−<br />Ep(yf,y1,...,yK|Df<br />n,D1<br />n,x)<br />?H?p(x⋆|Df<br />n∪ {(x,yf)},D1<br />n∪ {(x,y1)},...DK<br />n∪ {(x,yK)})??, (3)<br />n,D1<br />n,...DK<br />n<br />n,D1<br />n,...DK<br />n. Since the mututal information is a symmetric function, α(x) can be<br />α(x)=<br />n,D1<br />n,...DK<br />n,x)?−<br />Ep(x⋆|Df<br />n,D1<br />n,D1<br />n,x,x⋆) is the posterior predictive distribution for yf,y1,...,yKgiven<br />nand the location x⋆ of the solution to the constrained optimization problem. Intuitively,<br />n)<br />?H?p(yf,y1,...,yK|Df<br />n,D1<br />n,...DK<br />n,x,x⋆)??,<br />(4)<br />n,...DK<br />n,D1<br />n,...DK<br />H?p(yf,y1,...,yK|Df<br />However, the second term in (4) must be approximated. For this, we first approximate the expectation in (4)<br />by averaging over samples x(i)<br />⋆<br />drawn approximately from p(x⋆|Df<br />we then approximate the corresponding entropy function H<br />the method expectation propagation [4].<br />n,D1<br />n,...DK<br />n,x)?<br />=0.5 log(vf<br />n(x) + σ2<br />f) +<br />K<br />?<br />k=1<br />log(vk<br />n(x) + σ2<br />k) + (K + 1)log(2πe)<br />?<br />.<br />n,D1<br />n,...DK<br />n). For each of these samples,<br />p(yf,y1,...,yK|Df<br />?<br />n,D1<br />n,...DK<br />n,x,x(i)<br />⋆ )<br />?<br />using<br />2</p>  <p>Page 13</p> <p>2.1<br />Sampling from p(x⋆|Df<br />2.2Approximating the predictive entropy<br />Sampling from the posterior over constrained global maxima<br />n,D1<br />n,...DK<br />n) is relatively straight forward using the method described in [5].<br />We describe p(yf,y1,...,yK|Df<br />p(yf,y1,...,yK|Df<br />n,D1<br />n,...DK<br />n,x,x(i)<br />⋆ ) informally as<br />n,D1<br />n,...DK<br />n,x,x(i)<br />⋆ )=<br />Z−1<br /><br />x′?=x(i)<br />?<br />j=1<br />?<br />k=1<br />df dc1 ... dcK,<br />ˆ<br />δ[¯f − f(x)]N(yf|¯f,σ2<br />??<br />k=1<br />?<br />f)p(f|Df<br />n)<br /><br />?<br />⋆<br />K<br />?<br />Θ[ck(x′)]<br />?<br />Θ[f(x(i)<br />⋆i) − f(x′)] +<br />?<br />1 −<br />K<br />?<br />k=1<br />Θ[ck(x′)]<br />??<br /><br />k?<br />K<br />?<br />Θ[cj(x(i)<br />⋆ )]<br />?δ[¯ ck− ck(x)]N(yk|¯ ck,σ2<br />k)p(ck|Dk<br />n)?<br />?<br />where f and c1,...,cKare here infinite dimensional vectors encoding the objective and the constraint func-<br />tions, p(f|Df<br />step function, the Dirac deltas project the infinite dimensional vectors to their corresponding values at x and Z<br />is a normalization constant. Note that yf,y1,...,yKare obtained from¯f = f(x),¯ c1= c1(x),...,¯ cK= cK(x)<br />by adding independent Gaussian noise. Therefore, we focus on the corresponding distribution on¯f,¯ c1,...,¯ cK,<br />that is,<br />n) and p(ck|Dk<br />n) are infinite dimensional multivariate Guassian distributions, Θ is the Heaviside<br />p(¯f, ¯ c1,..., ¯ cK|Df<br />n,D1<br />n,...DK<br />n,x,x(i)<br />⋆ )=<br />ˆ<br /><br />?<br />df dc1 ... dcK.<br />δ[¯f − f(x)]p(f|Df<br />??<br />n)<br /><br />?<br />K<br />?<br />x′?=x(i)<br />⋆<br />K<br />?<br />k=1<br />Θ[ck(x′)]<br />?<br />Θ[f(x(i)<br />⋆) − f(x′)] +<br />?<br />1 −<br />K<br />?<br />k=1<br />Θ[ck(x′)]<br />??<br /><br />k=1<br />?<br />δ[¯ ck− ck(x)]N(yk|¯ ck,σ2<br />k)p(ck|Dk<br />n)?<br />?<br />We approximate this latter distribution with a multivariate Gaussian. However, instead of marginalizing over<br />the infinite dimensional elements f,c1,...,cK we will perform an approximation and marginalize only over<br />a finite dimensional proyection of these elements at the evaluation locations x1,...,xn and x(i)<br />let f = (f1,...,fn+1) be the vector such that fj= f(xj) for j = 1,...,n and fn+1= f(x(i)<br />ck= (ck<br />We focus on the distribution<br />⋆ . For this,<br />⋆ ). Similarly, let<br />⋆ ) for k = 1,...,K.<br />1,...,ck<br />n+1) be the vector such that ck<br />j= ck(xj) for j = 1,...,n and ck<br />n+1= ck(x(i)<br />q(f,c1,...,cK)<br />∝N(f|mf<br /><br />j=1<br />?K<br />k=1<br />pred,Vf<br />pred)<br />?K<br />k=1<br />?<br />?<br />N(ck|mck<br />pred,Vck<br />pred)<br />?<br /><br />n<br />?<br />?<br />??K<br />?<br />k=1<br />Θ[ck<br />j]Θ[fn+1− fj] +<br />?<br />1 −<br />K<br />?<br />k=1<br />Θ[ck<br />j]<br />??<br /><br />Θ[ck<br />n+1]<br />?<br />,<br />(5)<br />3</p>  <p>Page 14</p> <p>where mf<br />in Dfand where mck<br />given the data in Dk. In particular, we have that<br />predand Vf<br />predare the mean and covariance matrix of the posterior distribution of f given the data<br />predand Vck<br />predare the mean and covariance matrix of the posterior distribution of ck<br />mf<br />Vf<br />pred<br />=<br />=<br />Kf<br />Kf<br />⋆(Kf<br />⋆,⋆− Kf<br />n+ σ2<br />fI)−1yf<br />⋆(Kf<br />n,<br />fI)−1[Kf<br />pred<br />n+ σ2<br />⋆]T,<br />where Kf<br />and Kf<br />have that<br />⋆is an (n +1) ×n matrix with the prior cros-covariances between f = (f1,...,fn+1) and f1,...,fn<br />⋆,⋆is an (n + 1) × (n + 1) matrix with the prior covariances between f = (f1,...,fn+1). Similarly, we<br />mck<br />Vck<br />pred<br />=<br />=<br />Kk<br />Kk<br />⋆(Kk<br />⋆,⋆− Kk<br />n+ σ2<br />kI)−1yk<br />⋆(Kk<br />n,<br />kI)−1[Kk<br />pred<br />n+ σ2<br />⋆]T,<br />where Kk<br />and ck(x1),...,ck(xn) and Kk<br />ck(x1),...,ck(xn),ck(x(i)<br />side of (5) can be written as<br />⋆is an (n + 1) × n matrix with the prior cros-covariances between ck(x1),...,ck(xn),ck(x(i)<br />⋆,⋆is an (n + 1) × (n + 1) matrix containing the prior covariances between<br />⋆ ). We now find a Gaussian approximation to the distribution (5). The right hand<br />⋆ )<br />q(f,c1,...,cK)<br />∝N(f|mf<br /><br />j=1<br />?K<br />k=1<br />pred,Vf<br />pred)<br />?K<br />k=1<br />?<br /><br />?<br />N(ck|mck<br />pred,Vck<br />pred)<br />?<br /><br />n<br />?<br />?<br />hj(f,c1,...,cK)<br /><br />gk(f,c1,...,cK)<br />,<br />(6)<br />where hj(f,c1,...,cK) =<br />We approximate these exact factors with approximate factors˜hj(f,c1,...,cK) and ˜ gk(f,c1,...,cK) that<br />have a Gaussian form, that is,<br />˜hj(f,c1,...,cK)=<br />sh,jexp{−0.5[fjfn+1]Ah,j<br />K<br />?<br />˜ gk(f,c1,...,cK)=<br />sg,kexp{−0.5ag,k<br />The right hand side of (6) is then approximated by<br />??K<br />k=1Θ[ck<br />j]<br />?<br />Θ[fn+1− fj] +<br />?<br />1 −?K<br />k=1Θ[ck<br />j]<br />?<br />and gk(f,c1,...,cK) = Θ[ck<br />n+1].<br />fj,fn+1[fjfn+1]T+ [fjfn+1]bh,j<br />?<br />n+1]2+ bg,k<br />ck<br />fj,fn+1}<br />k=1<br />?<br />exp{−0.5ah,j<br />ck<br />j[ck<br />j]2+ bh,j<br />ck<br />jck<br />j}<br />,<br />ck<br />n+1[ck<br />n+1ck<br />n+1},<br />˜ q(f,c1,...,cK)<br />∝N(f|mf<br /><br />j=1<br />?K<br />k=1<br />pred,Vf<br />pred)<br />?K<br />k=1<br />?<br /><br />?<br />N(ck|mck<br />pred,Vck<br />pred)<br />?<br /><br />n<br />?<br />?<br />N(f|mf,Vf)<br />˜hj(f,c1,...,cK)<br /><br />˜ gk(f,c1,...,cK)<br />=<br />?K<br />k=1<br />?<br />N(ck|mck,Vck)<br />?<br />.<br />4</p>  <p>Page 15</p> <p>where<br />Vf<br />mf<br />=<br />=<br />?[Vf<br />?<br />pred]−1+˜Vf?−1,<br />[Vck<br />Vck?<br />j,j= [Ah,j<br />fj,fn+1]2,2, ˜ mfis an (n+1)-dimensional vector such that ˜ mf<br />j=1[bh,j<br />n+1,n+1= ag,k<br />ck<br />Vf?[Vf<br />pred]−1mf<br />pred]−1+˜Vck?−1<br />[Vck<br />pred+ ˜ mf?,<br />,<br />pred+ ˜ mck?<br />fj,fn+1]1,1and ˜ vf<br />Vck<br />=<br />mck<br />=<br />pred]−1mck<br />and˜Vfis an (n + 1) × (n + 1) matrix such that ˜ vf<br />j = 1,...,n and ˜ vf<br />for j = 1,...,n and ˜ mf<br />for j = 1,...,n and ˜ vck<br />and ˜ mck<br />ck<br />We use EP to refine the approximate factors˜hjand ˜ gk. EP adjusts each˜hjby minimizing the Kullback-<br />Leibler (KL) divergence between˜hj(f,c1,...,cK)˜ q\j(f,c1,...,cK) and hj(f,c1,...,cK)˜ q\j(f,c1,...,cK),<br />where we define ˜ q\j(f,c1,...,cK) as ˜ q\j(f,c1,...,cK) = ˜ q(f,c1,...,cK)/˜hj(f,c1,...,cK). We also adjust<br />each ˜ gkby minimizing the KL divergence between ˜ gk(f,c1,...,cK)˜ q\k(f,c1,...,cK) and gk(f,c1,...,cK)˜ q\k(f,c1,...,cK),<br />where ˜ q\k(f,c1,...,cK) = ˜ q(f,c1,...,cK)/˜ gk(f,c1,...,cK). The first step to refine each˜hj is to compute<br />the cavity distribution ˜ q\j(f,c1,...,cK) for each of these factors. In particular, we obtain<br />?<br />mfj,fn+1<br />j,old<br />j,old<br />?<br />ck<br />j<br />j,old<br />ck<br />j<br />j,n+1= ˜ vf<br />n+1,j= [Ah,j<br />fj,fn+1]1,2for<br />j= [bh,j<br />j,j= ah,j<br />for j = 1,...,n<br />n+1,n+1=?n<br />j=1[Ah,j<br />fj,fn+1]1<br />n+1=?n<br />fj,fn+1]2, Vckis an (n+1)×(n+1) diagonal matrix such that ˜ vck<br />j, ˜ mckis an (n+1)-dimensional vector such that ˜ mck<br />ck<br />j<br />j = bh,j<br />ck<br />j<br />n+1= bg,k<br />n+1.<br />Vfj,fn+1<br />j,old<br />=[Vf<br />fj,fn+1]−1− Ah,j<br />Vfj,fn+1<br />fj,fn+1<br />?−1<br />fj,fn+1− bh,j<br />,<br />=<br />?<br />[Vf<br />fj,fn+1]−1mf<br />?−1<br />j,j]−1− bh,j<br />fj,fn+1<br />?<br />,<br />v<br />ck<br />j<br />j,old<br />=[vck<br />j,j]−1− ah,j<br />ck<br />j<br />,<br />m<br />=<br />?<br />mck<br />j[vck<br />?−1<br />,<br />where Vf<br />dimensional mean vector. Similarly, vck<br />that, we compute<br />fj,fn+1is the 2 × 2 covariance matrix for fj and fn+1 in ˜ q and mf<br />j,jis the variance for ck<br />fj,fn+1is the corresponding 2-<br />j is the corresponding mean. After<br />jin ˜ q and mck<br />Z<br />=<br />ˆ<br />??K<br />gk(f,c1,...,cK)˜ q\k(f,c1,...,cK)df dc1... dcK<br />?<br />=<br />?<br />k=1<br />Φ[αk<br />j] Φ(αj) +<br />?<br />1 −<br />K<br />?<br />k=1<br />Φ[αk<br />j]<br />??<br />,<br />where αk<br />we need to compute<br />j= m<br />ck<br />j<br />j,old/<br />?<br />v<br />ck<br />j<br />j,oldand αj= [−11]mfj,fn+1<br />j,old<br />/<br />?<br />[−11]Vfj,fn+1<br />j,old<br />[−11]T. Before updating ag,j<br />ck<br />j<br />and bh,j<br />ck<br />j<br />dlogZ<br />ck<br />j,old<br />dm<br />j<br />=<br />(Z − 1)φ(αk<br />ZΦ(αk<br />j)<br />j)<br />?<br />v<br />ck<br />j<br />j,old<br />,<br />d2logZ<br />d[m<br />ck<br />j<br />j,old]2<br />=<br />−(Z − 1)φ(αk<br />ZΦ(αk<br />j)<br />j)<br />·<br />?<br />αk<br />j+<br />(Z−1)φ(αk<br />ZΦ(αk<br />j)<br />j)<br />?<br />vcj<br />l,old<br />l<br />.<br />5</p>  <p>Page 16</p> <p>We then update ah,j<br />ck<br />j<br />and bh,j<br />ck<br />j<br />using<br />[ah,j<br />ck<br />j]new<br />=<br />−1<br />]−1+ v<br />[dlog Z<br />dm<br /><br /><br />ck<br />j<br />j,old<br />ck<br />j<br />j,old<br />,<br />[bh,j<br />ck<br />j]new<br />=<br /><br /><br />m<br />m<br />ck<br />j<br />j,old− [d2logZ<br />d[m<br />?<br />ck<br />j<br />j,old]2<br />]−1dlogZ<br />dm<br />ck<br />j<br />j,old<br /><br /><br />[ah,j<br />j)<br />ck<br />j]new<br />?−1<br />=<br />ck<br />j<br />j,old+<br />v<br />ck<br />j<br />j,old<br />?<br />αk<br />j+(Z − 1)φ(αk<br />ZΦ(αk<br />j)<br /><br />[ah,j<br />ck<br />j]new.<br />Before updating Ah,j<br />fj,fn+1and Bh,j<br />fj,fn+1we need to compute<br />??K<br />dlogZ<br />dmfj,fn+1<br />j,old<br />=<br />k=1Φ[αk<br />Z√s<br />j]<br />?<br />φ(αj)<br />[−11],<br />dlogZ<br />dVfj,fn+1<br />j,old<br />=<br />−1<br />2[−11]T[−11]<br />??K<br />k=1Φ[αk<br />j]<br />?<br />φ(αj)αj<br />Zs<br />,<br />where s = [−11]Vfj,fn+1<br />j,old<br />[−11]T. We then compute<br />[Vf<br />fj,fn+1]new<br />=<br />Vfj,fn+1<br />j,old<br />− Vfj,fn+1<br />j,old<br /><br /><br />∂mfj,fn+1<br />j,old<br />∂ logZ<br />∂[mfj,fn+1<br />j,old<br />∂ logZ<br />]<br />?<br />∂ logZ<br />∂mfj,fn+1<br />j,old<br />?T<br />− 2<br />∂ logZ<br />∂Vfj,fn+1<br />j,old<br /><br />Vfj,fn+1<br />j,old<br />,<br />[mf<br />fj,fn+1]new<br />=<br />mfj,fn+1<br />j,old<br />+ Vfj,fn+1<br />j,old<br />.<br />We finally update Ah,j<br />fj,fn+1and Bh,j<br />fj,fn+1using<br />[Ah,j<br />[bh,j<br />fj,fn+1]new<br />fj,fn+1]new<br />=[Vf<br />[mf<br />fj,fn+1]−1<br />fj,fn+1]new[Vf<br />new− [Vfj,fn+1<br />fj,fn+1]−1<br />j,old<br />]−1.<br />=<br />new− mfj,fn+1<br />j,old<br />[Vfj,fn+1<br />j,old<br />]−1.<br />We now show how to refine the ˜ gk. In this case, we compute first the parameters of the cavity<br />v<br />ck<br />j<br />k,old<br />=<br />?<br />?<br />[vck<br />j,j]−1− ag,k<br />ck<br />j<br />?−1<br />,<br />m<br />ck<br />j<br />k,old<br />=<br />mck<br />j[vck<br />j,j]−1− bg,k<br />ck<br />j<br />?−1<br />.<br />After that, we compute<br />α<br />=<br />m<br />?<br />Φ(α),<br />ck<br />j<br />k,old<br />v<br />ck<br />j<br />k,old<br />,<br />Z<br />=<br />∂ logZ<br />ck<br />k,old<br />∂m<br />j<br />=<br />φ[α]<br />?<br />Φ[α]<br />v<br />ck<br />j<br />k,old<br />,<br />6</p>  <p>Page 17</p> <p>∂2logZ<br />∂[m<br />ck<br />j<br />k,old]2<br />=<br />−<br />φ[α]<br />ck<br />j<br />k,oldΦ[α]<br />v<br />·<br />?<br />α +φ[α]<br />Φ[α]<br />?<br />,.<br />Finally, we update ag,k<br />ck<br />j<br />and bg,k<br />ck<br />j<br />as<br />[ag,k<br />ck<br />j]new<br />=<br />−1<br />?−1<br />?<br /><br />dlog Z<br />ck<br />k,old<br />dm<br />j<br />+ v<br />ck<br />j<br />k,old<br />,<br />[bg,k<br />ck<br />j]new<br />=<br /><br />m<br />ck<br />j<br />k,old− [d2logZ<br />d[m<br />ck<br />j<br />k,old]2]−1dlogZ<br />dm<br />ck<br />j<br />k,old<br /><br /><br />[ag,k<br />n,D1<br />ck<br />j]new.<br />Once EP has converged we can approximate p(f(x),c1(x),...,cK(x)|Df<br />n,...DK<br />n,x,x(i)<br />⋆ ) as<br />p(f(x),c1(x),...,cK(x)|Df<br />n,D1<br />n,...DK<br />n,x,x(i)<br />⋆ )<br />≈<br />ˆ<br />??K<br />˜ q(f,c1,...,cK)df dc1...dcK<br />?<br />p(f(x)|f)p(c1(x)|c1)···p(cK(x)|cK)<br />?<br />k=1<br />Θ[ck(x)]<br />?<br />Θ[fn+1− f(x)] +<br />?<br />1 −<br />K<br />?<br />k=1<br />Θ[ck(x)]<br />??<br />(7)<br />where the constraint factor<br />f(x) is smaller than fn+1= f(x(i)<br />k = 1,...,K. Unfortunately, the right-hand side of the above equation is not analytical. Nevertheless, we<br />approximate it with a product of Gaussians that have the same marginal means and variances. In particular,<br />???K<br />k=1Θ[ck(x)]<br />⋆ ) when all the constraints are satisfied at x, that is, when ck(x) ≥ 0 for<br />?<br />Θ[fn+1− f(x)] +1 −?K<br />k=1Θ[ck(x)]<br />??<br />above enforces that<br />p(f(x),c1(x),...,cK(x)|Df<br />n,D1<br />n,...DK<br />n,x,x(i)<br />⋆ )<br />≈N(f(x)|µf<br />K<br />?<br />n,const(x),vf<br />n,const(x))<br />k=1<br />N(ck(x)|µk<br />n,const(x),vk<br />n,const(x)),<br />where µf<br />f(x) and ck(x) according to the right-hand-side of (7). To obtain these values, we first compute the predictive<br />means and variances for f(x),fn+1,c1(x),...,cK(x) when the constraint factor in the right-hand-side of (7)<br />is ignored.<br />For the case of f(x) and fn+1, we have that the two-dimensional vector f′= (f(x),fn+1) follows a<br />bivariate Gaussian distribution with mean vector mpred<br />f′<br />n,const(x), vf<br />n,const(x) and µk<br />n,const(x) and vk<br />n,const(x) are the marginal means and marginal variances of<br />and covariance matrix Vpred<br />f′<br />, that is,<br />ˆ<br />p(f(x)|f)˜ q(f,c1,...,cK)df1... dfndc1...dcK<br />=<br />N(f′|mpred<br />f′<br />,Vpred<br />f′<br />),<br />where<br />[mpred<br />f′<br />[Vpred<br />f′<br />]1<br />=<br />=<br />kf<br />kf(x,x) − kf<br />final(x)T[Kf<br />⋆,⋆]−1mf,<br />final(x)T?[Kf<br />]1,1<br />⋆,⋆]−1+ [Kf<br />⋆,⋆]−1Vf[Kf<br />⋆,⋆]−1?kf<br />final(x)<br />and mfand Vfare the posterior mean and posterior covariance matrix of f given by ˜ q, kf<br />(n + 1)-dimensional vector with the prior cros-covariances between f(x) and f(x1),...,f(xn),f(x(i)<br />final(x) is the<br />⋆ ) and<br />7</p>  <p>Page 18</p> <p>Kf<br />have that<br />⋆,⋆is and (n + 1) × (n + 1) matrix with the prior covariances between f(x1),...,f(xn),f(x(i)<br />⋆ ). We also<br />[mpred<br />f′<br />[Vpred<br />f′<br />]2<br />=<br />=<br />[mf]n+1,<br />[Vf]n+1,n+1.<br />]2,2<br />Finally, we have that<br />[Vpred<br />f′<br />]1,2<br />=<br />kf(x,x(i)<br />⋆ ) − kf<br />final(x)T?[Kf<br />⋆,⋆]−1+ [Kf<br />⋆,⋆]−1Vf[Kf<br />⋆,⋆]−1?kf<br />final(x(i)<br />⋆ ),<br />where kf<br />f(x1),...,f(xn),f(x(i)<br />Next, we compute the predictive means and variances for c1(x),...,cK(x) when the constraint factor in<br />the right-hand-side of (7) is ignored. In particular, for the k-th of these variables we have that<br />final(x(i)<br />⋆ ) is the (n + 1)-dimensional vector with the prior cros-covariances between f(x(i)<br />⋆ ).<br />⋆ ) and<br />ˆ<br />p(ck(x)|ck)˜ q(f,c1,...,ck)df dc1...dcK<br />=<br />N(ck(x)|mpred<br />ck<br />,vpred<br />ck<br />),<br />where<br />mpred<br />ck<br />vpred<br />ck<br />=<br />=<br />kk<br />kk(x,x) − kk<br />final(x)T[Kk<br />⋆,⋆]−1mck,<br />final(x)T?[Kk<br />⋆,⋆]−1+ [Kk<br />⋆,⋆]−1Vck[Kk<br />⋆,⋆]−1?kk<br />final(x)<br />and kk<br />Kk<br />final(xk) is an (n+1) vector with the cross-covariancesbetween ck(x) and ck(x1),...,ck(xn),ck(x(i)<br />⋆,⋆is an (n+1)×(n+1) covariance matrix with the prior covariances between ck(x1),...,ck(xn),ck(x(i)<br />After this, we approximate p(f(x),c1(x),...,cK(x)|Df<br />⋆ ) and<br />⋆ ).<br />n,D1<br />ˆ??K<br />n,...DK<br />n,x,x(i)<br />⋆ ) as<br />p(f(x),c1(x),...,cK(x)|Df<br />n,D1<br />n,...DK<br />n,x,x(i)<br />⋆ )<br />≈<br />1<br />Z<br /><br /><br />?<br />k=1<br />Θ[ck(x)]<br />?<br />Θ[fn+1− f(x)] +<br /><br />?<br />1 −<br />K<br />?<br />k=1<br />Θ[ck(x)]<br />??<br /><br />K<br />?<br />jk=1<br />N(ck(x)|mpred<br />ck<br />,vpred<br />ck<br />)<br /><br />N(f′|mpred<br />f′<br />,Vpred<br />f′<br />),<br />(8)<br />where Z is a normalization constant. We then approximate the right-hand-side of (8) using<br />p(f(x),c1(x),...,cK(x)|Df<br />n,D1<br />n,...DK<br />n,x,x(i)<br />⋆ )<br />≈N(f(x)|µf<br />K<br />?<br />n,const(x),vf<br />n,const(x))<br />k=1<br />N(ck(x)|µk<br />n,const(x),vk<br />n,const(x)),<br />where µf<br />of f(x) and ck(x) according to the right-hand-side of (8). In particular, we fix<br />n,const(x), vf<br />n,const(x) and µk<br />n,const(x) and vk<br />n,const(x) are the marginal means and marginal variances<br />vf<br />n,const(x)=[Vpred<br />f′<br />]1,1−β<br />]1+<br />s(β + α)<br />[Vpred<br />f′<br />?<br />[Vpred<br />f′<br />]1,1− [Vpred<br />]1,1<br />√s,<br />/√s and<br />f′<br />]1,2<br />?2<br />,<br />µf<br />n,const(x)=[mpred<br />f′<br />?<br />]1,2− [Vpred<br />f′<br />?β<br />where s = [Vpred<br />f′<br />]1,1+ [Vpred<br />f′<br />]2,2− 2[Vpred<br />f′<br />]1,2, α = [−11]mpred<br />??K<br />f′<br />β<br />=<br />k=1Φ[αk]<br />?<br />φ(α)<br />Z<br />,<br />8</p>  <p>Page 19</p> <p>Z =<br />??K<br />k=1Φ[αk]<br />?<br />Φ[α] +<br />?<br />vk<br />µk<br />1 −?K<br />n,const(x)<br />n,const(x)<br />k=1Φ[αk]<br />?<br />?[vpred<br />vk<br />and αk= mpred<br />ck<br />/<br />?<br />vpred<br />ck<br />. Finally, we also fix<br />=<br />=<br />ck<br />]−1+ ˜ a?−1,<br />n,const(x)?[mpred<br />ck<br />]−1[vpred<br />ck<br />]−1+˜b?,<br />where<br />˜ a<br />=<br />−<br />1<br />?<br /><br />d2log Z<br />d[mpred<br />ck<br />]2+ vpred<br />?<br />αk+ βk<br />ck<br />? ,<br /><br />˜b<br />=˜ a<br /><br />φ(αj)<br />ZΦ(αj)(Z − 1),<br />−βk{αk+ βk}<br />vpred<br />ck<br />mpred<br />ck<br />+<br />vpred<br />ck<br /><br />,<br />βk<br />=<br />d2logZ<br />d[mpred<br />ck<br />]2<br />=<br />.<br />Finally, we approximate the entropy of p(yf,y1,...,yK|Df<br />n,D1<br />n,...DK<br />K<br />?<br />n,x,x(i)<br />⋆ ) as<br />H<br />?<br />p(yf,y1,...,yK|Df<br />n,D1<br />n,...DK<br />n,x,x(i)<br />⋆ )<br />?<br />≈<br />0.5<br />?<br />log(vf<br />n,const(x) + σ2<br />f) +<br />k=1<br />log(vk<br />n,const(x) + σ2<br />k) + (K + 1)log(2πe)<br />?<br />.<br />References<br />[1] D. J. MacKay. Information-based objective functions for active data selection. Neural Computation,<br />4(4):590–604, 1992.<br />[2] C. E. Rasmussen and C. K. Williams. Gaussian processes for machine learning. The MIT Press, 2006.<br />[3] N. Houlsby, J. M. Hernandez-lobato, F. Huszar, and Z. Ghahramani. Collaborative Gaussian processes<br />for preference learning. In NIPS, pages 2096–2104. 2012.<br />[4] T. P. Minka. A family of algorithms for approximate Bayesian inference. PhD thesis, Massachusetts<br />Institute of Technology, 2001.<br />[5] José Miguel Hernández-Lobato, Matthew W. Hoffman, Zoubin Ghahramani, Predictive Entropy Search<br />for Efficient Global Optimization of Black-box Functions, arXiv:1406.2541 [stat.ML]<br />9</p>   </div> <div id="rgw26_56aba2012c1a1" class="c-box pub-resource-container js-toggle" style=""> <h4 class="lf js-expand-list"><small><a href="javascript:" class="lf">View other sources <span class="ico-expand-list"></span></a></small></h4> <h4 class="lf js-collapse-list hidden"><small><a href="javascript:" class="lf">Hide other sources <span class="ico-collapse-list"></span></a></small></h4> <div class="clear"></div> <div class="scroll-wrapper hidden"> <ul class="files-list c-list" id="rgw27_56aba2012c1a1">  <li class="c-list-item pub-resource-item"  data-type="fulltext" id="rgw28_56aba2012c1a1"> <span class="ico-pub"></span> <div class="file-content"> <div class="download"> <a href="http://de.arxiv.org/pdf/1502.05312" target="_blank" rel="nofollow" class="publication-viewer" title="Predictive Entropy Search for Bayesian Optimization with Unknown Constraints">Predictive Entropy Search for Bayesian Optimizatio...</a> </div>  <div class="details">   Available from <a href="http://de.arxiv.org/pdf/1502.05312" target="_blank" rel="nofollow">de.arxiv.org</a>  </div>    </div> </li>  </ul> </div> </div> </noscript> <div class="clearfix"> <div class="action-container">  </div> <div class="pub-legal"> Data provided are for informational purposes only. Although carefully collected, accuracy cannot be guaranteed. The impact factor represents a rough estimation of the journal's impact factor and does not reflect the actual current impact factor. Publisher conditions are provided by RoMEO. Differing provisions from the publisher's actual policy or licence agreement may be applicable. </div>   </div> </div> <div class="clearfix">     <div id="rgw30_56aba2012c1a1" class="c-box pub-resource-container js-toggle" style="display: none;"> <h4 class="lf js-expand-list"><small><a href="javascript:" class="lf">View other sources <span class="ico-expand-list"></span></a></small></h4> <h4 class="lf js-collapse-list hidden"><small><a href="javascript:" class="lf">Hide other sources <span class="ico-collapse-list"></span></a></small></h4> <div class="clear"></div> <div class="scroll-wrapper hidden"> <ul class="files-list c-list" id="rgw31_56aba2012c1a1">  </ul> </div> </div>   <div id="rgw22_56aba2012c1a1" class="similar-publications"> <h2>Similar Publications</h2> <ul class="list-bordered">  <li class="c-list-item li-publication-teaser" id="rgw23_56aba2012c1a1"> <div> <h5> <a href="publication/284219670_Predictive_Entropy_Search_for_Multi-objective_Bayesian_Optimization" class="color-inherit ga-similar-publication-title"><span class="publication-title">Predictive Entropy Search for Multi-objective Bayesian Optimization</span></a>  </h5>  <div class="authors"> <a href="researcher/33804361_Daniel_Hernandez-Lobato" class="authors ga-similar-publication-author">Daniel Hernández-Lobato</a>, <a href="researcher/59382974_Jose_Miguel_Hernandez-Lobato" class="authors ga-similar-publication-author">José Miguel Hernández-Lobato</a>, <a href="researcher/2085263922_Amar_Shah" class="authors ga-similar-publication-author">Amar Shah</a>, <a href="researcher/71165702_Ryan_P_Adams" class="authors ga-similar-publication-author">Ryan P. Adams</a>  </div>  </div> <div class="clear"></div> </li>  <li class="c-list-item li-publication-teaser" id="rgw24_56aba2012c1a1"> <div> <h5> <a href="publication/261065571_Bayesian_Optimization_with_Unknown_Constraints" class="color-inherit ga-similar-publication-title"><span class="publication-title">Bayesian Optimization with Unknown Constraints</span></a>  </h5>  <div class="authors"> <a href="researcher/2043445261_Michael_A_Gelbart" class="authors ga-similar-publication-author">Michael A. Gelbart</a>, <a href="researcher/70743985_Jasper_Snoek" class="authors ga-similar-publication-author">Jasper Snoek</a>, <a href="researcher/71165702_Ryan_P_Adams" class="authors ga-similar-publication-author">Ryan P. Adams</a>  </div>  </div> <div class="clear"></div> </li>  <li class="c-list-item li-publication-teaser" id="rgw25_56aba2012c1a1"> <div> <h5> <a href="publication/263238045_An_Entropy_Search_Portfolio_for_Bayesian_Optimization" class="color-inherit ga-similar-publication-title"><span class="publication-title">An Entropy Search Portfolio for Bayesian Optimization</span></a>  </h5>  <div class="authors"> <a href="researcher/2012167186_Bobak_Shahriari" class="authors ga-similar-publication-author">Bobak Shahriari</a>, <a href="researcher/2050014493_Ziyu_Wang" class="authors ga-similar-publication-author">Ziyu Wang</a>, <a href="researcher/65281428_Matthew_W_Hoffman" class="authors ga-similar-publication-author">Matthew W. Hoffman</a>, <a href="researcher/70164187_Alexandre_Bouchard-Cote" class="authors ga-similar-publication-author">Alexandre Bouchard-Côté</a>, <a href="researcher/35020845_Nando_de_Freitas" class="authors ga-similar-publication-author">Nando de Freitas</a>  </div>  </div> <div class="clear"></div> </li>  </ul> </div> </div> </div> </div> </div></div></div>
<div class="clear"></div><div id="rgw36_56aba2012c1a1" class="default-footer"> <div id="footer" class="clearfix"> <span class="footer-left"> &copy; 2008&dash;2016 researchgate.net. All rights reserved. </span> <span class="footer-right"> <a href="https://www.researchgate.net/about">About us</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="https://www.researchgate.net/contact">Contact us</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="careers">Careers</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="developers">Developers</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="blog" target="_blank">News</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="application.PrivacyPolicy.html">Privacy</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="application.TermsAndConditions.html">Terms</a> <span class="footer-link-separator" style="padding: 0 5px;">&nbsp;|&nbsp;</span> <a href="advertising?_ref=ft">Advertising</a> <span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="recruiters?_ref=ft">Recruiting</a> </span> </div>  </div></div>
<div id="rgw37_56aba2012c1a1">  <div class="header-wrapper-logged-out"> <div id="header"> <div class="header-content"> <a href="" class="g-l-logo"> <svg width="149" height="19"> <image xlink:href="https://c5.rgstatic.net/m/235107188705592/images/template/brand-header-logo.svg" src="https://c5.rgstatic.net/m/238113351022438/images/template/brand-header-logo.png" width="149" height="19"/> </svg> </a> <a href="" class="g-l-logo-ico"> <svg width="127" height="17" viewbox="0 0 127 22"> <image xlink:href="https://c5.rgstatic.net/m/235107188705592/images/template/brand-header-logo.svg" src="https://c5.rgstatic.net/m/238113351022438/images/template/brand-header-logo.png" width="127" height="17"/> </svg> </a> <div id="rgw38_56aba2012c1a1" class="header-login-wrapper js-header-login"> <div class="dropdown-right-align"> <div class="login-signup-container lf"> <a href="https://www.researchgate.net/signup.SignUp.html?ev=su_chnl_index&amp;hdrsu=1&amp;_sg=hTUb9lJKOXy4Gld5o8kk0VyfHZpq3DIR_yfToL69q4k_BuQN4xvCaYVeuvWxpfJs" class="dropdown-toggle lf">Join for free</a> </div> <div class="dropdown lf" style="height: 20px;"> <a href="https://www.researchgate.net/application.Login.html" class="js-login-url dropdown-toggle lf">Log in <span class="caret"></span></a> <div class="dropdown-menu"> <div class="header-login-form-wrapper"> <!--[if IE 6]><p class="box-warning" style="margin-bottom: 0;">Sorry, ResearchGate no longer supports the version of Internet Explorer you are using. <a href="http://whatbrowser.org/" rel="nofollow" target="_blank">Update your web browser</a> and then log in. </p><![endif]--> <form method="post" action="https://www.researchgate.net/application.Login.html" class="form-big header-login-form js-login-form" name="loginForm" id="headerLoginForm"> <input type="hidden" name="request_token" value="AKdsK52Xcr3Sy2qPkkgIjuLQvNSRHyQ+doxU0Mh8ZdTKlAxI3ysf+Zx9WKwVbDSe/XzdvAW6WgCwfR5Ir9gdUelLq9dXXzYMXG+/sek8cLtrFwCwj+K51G5suEutyDDvCx9gprLiIFbKrfcn/jIYT2F2T28WP31gcIKCjfExZEoSg7bb+8VUjEDruhj6U4Pp8qY2XLW3l7eryd20LaVFBkYTh5+O0ymoiBI0HD+HJdlpzGnQb28ct9YsVPmjk3HPRcUlmwSSKtDaaU4BpThcfNrbNoODhlzWYhvtkYns/NY="/> <input type="hidden" name="urlAfterLogin" value="publication/272521912_Predictive_Entropy_Search_for_Bayesian_Optimization_with_Unknown_Constraints"/> <input type="hidden" name="invalidPasswordCount" value="0"/> <input type="hidden" name="headerLogin" value="yes"/> <label for="input-header-login">Email</label> <div class="login-input"> <div class="info-tip-wrapper"> <span class="ico-info js-info"></span> </div> <input type="email" value="" name="login" class="login js-login-input text" id="input-header-login" tabindex="1"/> </div> <div class="clear"></div> <label class="lf" for="input-header-password"> Password </label> <a class="rf forgot-password js-forgot-password" href="application.LostPassword.html">Forgot password?</a> <div class="clear"></div> <input type="password" value="" name="password" class="password js-password-input text" id="input-header-password" tabindex="2"/> <div class="clear"></div> <label class="remember-me" for="headerLoginCookie"> <input type="checkbox" checked="checked" value="yes" name="setLoginCookie" class="lf checkbox" id="headerLoginCookie" tabindex="3"/> Keep me logged in </label> <div class="clear"></div> <input value="Log in" name="loginSubmit" class="btn btn-promote btn-fullwidth btn-large allow-leave js-submit-button" type="submit" tabindex="4"/> </form> <div class="connectors"> <div class="text">or log in with</div> <div class="connector-actions"> <a href="connector/linkedin/" class="li-connect js-li-connect" data-redirect-url="cHVibGljYXRpb24vMjcyNTIxOTEyX1ByZWRpY3RpdmVfRW50cm9weV9TZWFyY2hfZm9yX0JheWVzaWFuX09wdGltaXphdGlvbl93aXRoX1Vua25vd25fQ29uc3RyYWludHM%3D"> <span class="icon ico-linkedin-round-grey"></span> <span class="icon ico-linkedin-round"></span> </a> <a href="connector/facebook/" class="fb-connect middle js-fb-connect" data-redirect-url="cHVibGljYXRpb24vMjcyNTIxOTEyX1ByZWRpY3RpdmVfRW50cm9weV9TZWFyY2hfZm9yX0JheWVzaWFuX09wdGltaXphdGlvbl93aXRoX1Vua25vd25fQ29uc3RyYWludHM%3D"> <span class="icon ico-facebook-round-grey"></span> <span class="icon ico-facebook-round"></span> </a> <a href="connector/google/" class="g-connect js-g-connect" data-redirect-url="cHVibGljYXRpb24vMjcyNTIxOTEyX1ByZWRpY3RpdmVfRW50cm9weV9TZWFyY2hfZm9yX0JheWVzaWFuX09wdGltaXphdGlvbl93aXRoX1Vua25vd25fQ29uc3RyYWludHM%3D"> <span class="icon ico-google-round-grey"></span> <span class="icon ico-google-round"></span> </a> </div> </div> </div> </div> </div> </div> </div> </div> </div> <script type="application/ld+json">
{ "@context" : "http://schema.org",
  "@type" : "Organization",
  "name" : "ResearchGate",
  "url" : "http://www.researchgate.net",
  "logo" : "http://www.researchgate.net/images/template/rg_logo_square_brand.png",
  "sameAs" : [ "https://www.facebook.com/ResearchGate",
    "https://twitter.com/ResearchGate",
    "https://plus.google.com/+researchgate",
    "https://www.linkedin.com/company/researchgate"] 
}
</script> </div> </div><div class="c-signup-bar" id="rgw39_56aba2012c1a1"> <div class="banner-contents">   <span class="message">ResearchGate is the professional network for scientists and researchers.</span> <a href="signup.SignUp.html?ev=su_banner" class="btn btn-large btn-promote">Join for free</a>  </div> </div></div>
<script>
rgConfig.backendTime = 499;
</script>
<script src="//c5.rgstatic.net/m/2277196935388619/javascript/lib/yui3/yui/yui-min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/21832295316281274/javascript/yuiLoaderConfig-min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/23178613132105398/javascript/vendor/babel-core/browser-polyfill.min.js" type="text/javascript"></script>
<script>
(function (){
if (typeof YRG === "undefined") {
var xmlHttpRequest = new XMLHttpRequest();
xmlHttpRequest.open("post", "go.Error.html");
xmlHttpRequest.setRequestHeader("Content-Type", "application/json");
xmlHttpRequest.setRequestHeader("Accept", "application/json"); var loadedScripts = "";
if (window.performance && window.performance.getEntriesByType) {
    var result = [];
    var resources = performance.getEntriesByType("resource");
    for (var i in resources) {
        if (resources.hasOwnProperty(i)) {
            result.push({
                name: resources[i].name,
                duration: resources[i].duration
            });
        }
    }
    loadedScripts += "&loadedScripts=" + encodeURIComponent(JSON.stringify(result));
}
if (typeof YUI === "undefined") {
    loadedScripts += "&yuiLoaded=false";
} else {
    loadedScripts += "&yuiLoaded=true";
}
xmlHttpRequest.send("Type=InformationException&message=" + encodeURIComponent("Error loading YUI") + loadedScripts);
}
})();
</script>
<script>if (typeof YRG !== 'undefined') { YRG.use('rg-base',function(Y){Y.applyConfig({ignore: ["css-rg","css-rg2","css-ie","css-modules-publicprofile"]});Y.use(["rg.core.pagespeed.Monitoring"],function(Y){(function(){Y.rg.createInitialWidget({"data":{"content":{"data":{"profileSmallHeader":{"data":{"profileBadge":{"data":{"profileUrl":"researcher\/59382974_Jose_Miguel_Hernandez-Lobato","fullname":"Jos\u00e9 Miguel Hern\u00e1ndez-Lobato","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2549355721578\/images\/template\/default\/profile\/profile_default_m.png","profileStats":[{"data":{"impactPoints":"12.99","widgetId":"rgw5_56aba2012c1a1"},"id":"rgw5_56aba2012c1a1","partials":[],"templateName":"publicliterature\/stubs\/PublicLiteratureAuthorImpactPoints.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicLiteratureAuthorImpactPoints.html?authorUid=59382974","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"publicationCount":30,"widgetId":"rgw6_56aba2012c1a1"},"id":"rgw6_56aba2012c1a1","partials":[],"templateName":"publicliterature\/stubs\/PublicLiteratureAuthorPublicationCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicLiteratureAuthorPublicationCount.html?authorUid=59382974","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"followerCount":1,"widgetId":"rgw7_56aba2012c1a1"},"id":"rgw7_56aba2012c1a1","partials":[],"templateName":"publicliterature\/stubs\/PublicLiteratureAuthorFollowerCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicLiteratureAuthorFollowerCount.html?authorUid=59382974","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"widgetId":"rgw4_56aba2012c1a1"},"id":"rgw4_56aba2012c1a1","partials":[],"templateName":"publicprofile\/stubs\/ProfileBadge.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicLiteratureAuthorBadge.html?authorUid=59382974","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw3_56aba2012c1a1"},"id":"rgw3_56aba2012c1a1","partials":[],"templateName":"publicprofile\/stubs\/ProfileSmallHeader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicprofile.ProfileSmallHeader.html?publicationUid=272521912","viewClass":null,"yuiModules":["css-modules-publicprofile"],"stylesheets":["modules\/publicprofile.css"],"_isYUI":true},"publication":{"data":{"publicationUid":272521912,"title":"Predictive Entropy Search for Bayesian Optimization with Unknown Constraints","journalTitle":false,"journalDetailsTooltip":false,"affiliation":false,"type":"Article","details":{"journalInfos":{"journal":"","publicationDate":"02\/2015;","publicationDateRobot":"2015-02","article":""}},"source":{"sourceUrl":"http:\/\/arxiv.org\/abs\/1502.05312","sourceName":"arXiv"},"publicationActions":null,"publicationCoins":{"data":{"tags":[{"key":"ctx_ver","value":"Z39.88-2004"},{"key":"rft_val_fmt","value":"info:ofi\/fmt:kev:mtx:journal"},{"key":"rfr_id","value":"info:sid\/researchgate.net:researchgate"},{"key":"rft.atitle","value":"Predictive Entropy Search for Bayesian Optimization with Unknown Constraints"},{"key":"rft.date","value":"2015"},{"key":"rft.au","value":"Jos\u00e9 Miguel Hern\u00e1ndez-Lobato,Michael A. Gelbart,Matthew W. Hoffman,Ryan P. Adams,Zoubin Ghahramani"},{"key":"rft.genre","value":"article"}],"widgetId":"rgw9_56aba2012c1a1"},"id":"rgw9_56aba2012c1a1","partials":[],"templateName":"publicliterature\/stubs\/PublicationCoins.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationCoins.html?publicationUid=272521912","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationAuthors":{"data":{"publicationUid":272521912,"peopleItems":[{"data":{"authorUrl":"researcher\/59382974_Jose_Miguel_Hernandez-Lobato","authorNameOnPublication":"Jos\u00e9 Miguel Hern\u00e1ndez-Lobato","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg","imageSize":"s","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Jos\u00e9 Miguel Hern\u00e1ndez-Lobato","profile":{"professionalInstitution":{"professionalInstitutionName":false,"professionalInstitutionUrl":null}},"professionalInstitutionName":false,"professionalInstitutionUrl":null,"url":"researcher\/59382974_Jose_Miguel_Hernandez-Lobato","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":true,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":false,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"widgetId":"rgw12_56aba2012c1a1"},"id":"rgw12_56aba2012c1a1","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAuthorItem.html?entityId=59382974&imageSize=l&enableAuthorInviteButton=0","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"largeTooltip":false,"useRebrandedImageStyle":null,"widgetId":"rgw11_56aba2012c1a1"},"id":"rgw11_56aba2012c1a1","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorItem.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorItem.html?authorUid=59382974&authorNameOnPublication=Jos%C3%A9%20Miguel%20Hern%C3%A1ndez-Lobato","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true},{"data":{"authorUrl":"researcher\/2043445261_Michael_A_Gelbart","authorNameOnPublication":"Michael A. Gelbart","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg","imageSize":"s","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Michael A. Gelbart","profile":{"professionalInstitution":{"professionalInstitutionName":false,"professionalInstitutionUrl":null}},"professionalInstitutionName":false,"professionalInstitutionUrl":null,"url":"researcher\/2043445261_Michael_A_Gelbart","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":true,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":false,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"widgetId":"rgw14_56aba2012c1a1"},"id":"rgw14_56aba2012c1a1","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAuthorItem.html?entityId=2043445261&imageSize=l&enableAuthorInviteButton=0","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"largeTooltip":false,"useRebrandedImageStyle":null,"widgetId":"rgw13_56aba2012c1a1"},"id":"rgw13_56aba2012c1a1","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorItem.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorItem.html?authorUid=2043445261&authorNameOnPublication=Michael%20A.%20Gelbart","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true},{"data":{"authorUrl":"researcher\/2049681119_Matthew_W_Hoffman","authorNameOnPublication":"Matthew W. Hoffman","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg","imageSize":"s","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Matthew W. Hoffman","profile":{"professionalInstitution":{"professionalInstitutionName":false,"professionalInstitutionUrl":null}},"professionalInstitutionName":false,"professionalInstitutionUrl":null,"url":"researcher\/2049681119_Matthew_W_Hoffman","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":true,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":false,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"widgetId":"rgw16_56aba2012c1a1"},"id":"rgw16_56aba2012c1a1","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAuthorItem.html?entityId=2049681119&imageSize=l&enableAuthorInviteButton=0","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"largeTooltip":false,"useRebrandedImageStyle":null,"widgetId":"rgw15_56aba2012c1a1"},"id":"rgw15_56aba2012c1a1","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorItem.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorItem.html?authorUid=2049681119&authorNameOnPublication=Matthew%20W.%20Hoffman","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true},{"data":{"authorUrl":"researcher\/71165702_Ryan_P_Adams","authorNameOnPublication":"Ryan P. Adams","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg","imageSize":"s","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Ryan P. Adams","profile":{"professionalInstitution":{"professionalInstitutionName":false,"professionalInstitutionUrl":null}},"professionalInstitutionName":false,"professionalInstitutionUrl":null,"url":"researcher\/71165702_Ryan_P_Adams","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":true,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":false,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"widgetId":"rgw18_56aba2012c1a1"},"id":"rgw18_56aba2012c1a1","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAuthorItem.html?entityId=71165702&imageSize=l&enableAuthorInviteButton=0","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"largeTooltip":false,"useRebrandedImageStyle":null,"widgetId":"rgw17_56aba2012c1a1"},"id":"rgw17_56aba2012c1a1","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorItem.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorItem.html?authorUid=71165702&authorNameOnPublication=Ryan%20P.%20Adams","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true},{"data":{"authorUrl":"researcher\/8159937_Zoubin_Ghahramani","authorNameOnPublication":"Zoubin Ghahramani","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg","imageSize":"s","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Zoubin Ghahramani","profile":{"professionalInstitution":{"professionalInstitutionName":false,"professionalInstitutionUrl":null}},"professionalInstitutionName":false,"professionalInstitutionUrl":null,"url":"researcher\/8159937_Zoubin_Ghahramani","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":true,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":false,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"widgetId":"rgw20_56aba2012c1a1"},"id":"rgw20_56aba2012c1a1","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAuthorItem.html?entityId=8159937&imageSize=l&enableAuthorInviteButton=0","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"largeTooltip":false,"useRebrandedImageStyle":null,"widgetId":"rgw19_56aba2012c1a1"},"id":"rgw19_56aba2012c1a1","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorItem.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorItem.html?authorUid=8159937&authorNameOnPublication=Zoubin%20Ghahramani","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true}],"hasMore":false,"nextOffset":6,"useRebrandedImageStyle":null,"widgetId":"rgw10_56aba2012c1a1"},"id":"rgw10_56aba2012c1a1","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorList.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorList.html?publicationUid=272521912&context=pubdetail_authors_xflw&showContactAuthorButton=1","viewClass":"views.publicliterature.PublicationDetailAuthorListView","yuiModules":["rg.views.publicliterature.PublicationDetailAuthorListView"],"stylesheets":[],"_isYUI":true},"publicationAbstract":{"data":{"publicationUid":272521912,"abstract":"<noscript><\/noscript><div>Unknown constraints arise in many types of expensive black-box optimization<br \/>\nproblems. Several methods have been proposed recently for performing Bayesian<br \/>\noptimization with constraints, based on the expected improvement (EI)<br \/>\nheuristic. However, EI can lead to pathologies when used with constraints. For<br \/>\nexample, in the case of decoupled constraints---i.e., when one can<br \/>\nindependently evaluate the objective or the constraints---EI can encounter a<br \/>\npathology that prevents exploration. Additionally, computing EI requires a<br \/>\ncurrent best solution, which may not exist if none the data collected so far<br \/>\nsatisfy the constraints. By contrast, information-based approaches do not<br \/>\nsuffer from these failure modes. In this paper, we present a new<br \/>\ninformation-based method called Predictive Entropy Search with unknown<br \/>\nConstraints (PESC). We analyze the performance of PESC and show that it<br \/>\ncompares favorably to EI-based approaches on synthetic and benchmark problems,<br \/>\nas well as several real-world examples. We demonstrate that PESC is an<br \/>\neffective algorithm that provides a promising direction towards a unified<br \/>\nsolution for constrained Bayesian optimization.<\/div>","canEdit":false,"isAdmin":false,"isArtifact":false,"showFullAbstract":false,"widgetId":"rgw21_56aba2012c1a1"},"id":"rgw21_56aba2012c1a1","partials":[],"templateName":"publicliterature\/stubs\/PublicationAbstract.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationAbstract.html?publicationUid=272521912","viewClass":"views.publicliterature.PublicationAbstractView","yuiModules":["rg.views.publicliterature.PublicationAbstractView"],"stylesheets":[],"_isYUI":true},"publicationKeywords":null,"publicationState":null,"isGuest":true,"isAdminEditingAllowed":false,"isArtifact":false,"figureListWidget":null,"previewImage":"https:\/\/i1.rgstatic.net\/publication\/272521912_Predictive_Entropy_Search_for_Bayesian_Optimization_with_Unknown_Constraints\/links\/54ed277b0cf28f3e65356839\/smallpreview.png","nativeAdDisclosure":null,"showFollowPublicationButton":false,"followPublicationPromo":"","widgetId":"rgw8_56aba2012c1a1"},"id":"rgw8_56aba2012c1a1","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailItem.html","templateExtensions":["generalHelpers"],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailItem.html?publicationUid=272521912&showActionBar=0&showContactAuthorButton=1&showRequestFulltextExperience=0&showNoRgAuthorsRequestFulltextExperience=0&showFollowPublicationPromo=0","viewClass":"views.publicliterature.PublicationDetailItemView","yuiModules":["rg.views.publicliterature.PublicationDetailItemView"],"stylesheets":[],"_isYUI":true},"similarPublications":{"data":{"publicationListItems":[{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":33804361,"url":"researcher\/33804361_Daniel_Hernandez-Lobato","fullname":"Daniel Hern\u00e1ndez-Lobato","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":59382974,"url":"researcher\/59382974_Jose_Miguel_Hernandez-Lobato","fullname":"Jos\u00e9 Miguel Hern\u00e1ndez-Lobato","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2085263922,"url":"researcher\/2085263922_Amar_Shah","fullname":"Amar Shah","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":71165702,"url":"researcher\/71165702_Ryan_P_Adams","fullname":"Ryan P. Adams","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Nov 2015","journal":null,"showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/284219670_Predictive_Entropy_Search_for_Multi-objective_Bayesian_Optimization","usePlainButton":true,"publicationUid":284219670,"feedStubs":null,"hasFeedStubs":false,"impactPoints":false,"url":"publication\/284219670_Predictive_Entropy_Search_for_Multi-objective_Bayesian_Optimization","title":"Predictive Entropy Search for Multi-objective Bayesian Optimization","displayTitleAsLink":true,"authors":[{"id":33804361,"url":"researcher\/33804361_Daniel_Hernandez-Lobato","fullname":"Daniel Hern\u00e1ndez-Lobato","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":59382974,"url":"researcher\/59382974_Jose_Miguel_Hernandez-Lobato","fullname":"Jos\u00e9 Miguel Hern\u00e1ndez-Lobato","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2085263922,"url":"researcher\/2085263922_Amar_Shah","fullname":"Amar Shah","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":71165702,"url":"researcher\/71165702_Ryan_P_Adams","fullname":"Ryan P. Adams","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":[],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/284219670_Predictive_Entropy_Search_for_Multi-objective_Bayesian_Optimization","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/284219670_Predictive_Entropy_Search_for_Multi-objective_Bayesian_Optimization\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw23_56aba2012c1a1"},"id":"rgw23_56aba2012c1a1","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=284219670","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":2043445261,"url":"researcher\/2043445261_Michael_A_Gelbart","fullname":"Michael A. Gelbart","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":70743985,"url":"researcher\/70743985_Jasper_Snoek","fullname":"Jasper Snoek","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":71165702,"url":"researcher\/71165702_Ryan_P_Adams","fullname":"Ryan P. Adams","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Mar 2014","journal":null,"showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/261065571_Bayesian_Optimization_with_Unknown_Constraints","usePlainButton":true,"publicationUid":261065571,"feedStubs":null,"hasFeedStubs":false,"impactPoints":false,"url":"publication\/261065571_Bayesian_Optimization_with_Unknown_Constraints","title":"Bayesian Optimization with Unknown Constraints","displayTitleAsLink":true,"authors":[{"id":2043445261,"url":"researcher\/2043445261_Michael_A_Gelbart","fullname":"Michael A. Gelbart","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":70743985,"url":"researcher\/70743985_Jasper_Snoek","fullname":"Jasper Snoek","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":71165702,"url":"researcher\/71165702_Ryan_P_Adams","fullname":"Ryan P. Adams","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":[],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/261065571_Bayesian_Optimization_with_Unknown_Constraints","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/261065571_Bayesian_Optimization_with_Unknown_Constraints\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw24_56aba2012c1a1"},"id":"rgw24_56aba2012c1a1","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=261065571","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":2012167186,"url":"researcher\/2012167186_Bobak_Shahriari","fullname":"Bobak Shahriari","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2050014493,"url":"researcher\/2050014493_Ziyu_Wang","fullname":"Ziyu Wang","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":65281428,"url":"researcher\/65281428_Matthew_W_Hoffman","fullname":"Matthew W. Hoffman","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":{"id":70164187,"url":"researcher\/70164187_Alexandre_Bouchard-Cote","fullname":"Alexandre Bouchard-C\u00f4t\u00e9","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},"surplusAuthors":1,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Jun 2014","journal":null,"showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/263238045_An_Entropy_Search_Portfolio_for_Bayesian_Optimization","usePlainButton":true,"publicationUid":263238045,"feedStubs":null,"hasFeedStubs":false,"impactPoints":false,"url":"publication\/263238045_An_Entropy_Search_Portfolio_for_Bayesian_Optimization","title":"An Entropy Search Portfolio for Bayesian Optimization","displayTitleAsLink":true,"authors":[{"id":2012167186,"url":"researcher\/2012167186_Bobak_Shahriari","fullname":"Bobak Shahriari","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2050014493,"url":"researcher\/2050014493_Ziyu_Wang","fullname":"Ziyu Wang","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":65281428,"url":"researcher\/65281428_Matthew_W_Hoffman","fullname":"Matthew W. Hoffman","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":70164187,"url":"researcher\/70164187_Alexandre_Bouchard-Cote","fullname":"Alexandre Bouchard-C\u00f4t\u00e9","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":35020845,"url":"researcher\/35020845_Nando_de_Freitas","fullname":"Nando de Freitas","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":[],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/263238045_An_Entropy_Search_Portfolio_for_Bayesian_Optimization","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/263238045_An_Entropy_Search_Portfolio_for_Bayesian_Optimization\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw25_56aba2012c1a1"},"id":"rgw25_56aba2012c1a1","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=263238045","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"viewClass":"sidebar","widgetId":"rgw22_56aba2012c1a1"},"id":"rgw22_56aba2012c1a1","partials":[],"templateName":"publicliterature\/stubs\/SimilarPublications.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.SimilarPublications.html?referencePublicationId=272521912&view=sidebar","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationFulltextPreview":null,"publicationResourcesFulltext":{"data":{"publicationUid":272521912,"publicationResourceList":{"data":{"publicationResourceItems":[{"data":{"publicationUid":272521912,"publicationType":"article","linkId":"54ed277b0cf28f3e65356839","fileName":"Predictive Entropy Search for Bayesian Optimization with Unknown Constraints","fileUrl":"http:\/\/de.arxiv.org\/pdf\/1502.05312","name":"de.arxiv.org","nameUrl":"http:\/\/de.arxiv.org\/pdf\/1502.05312","canRemove":false,"fileIcon":"ico-pub","canPreview":true,"hasPublisherLink":null,"hasMetaData":true,"hide":false,"fulltext":"ico-pub","origin":"publication_list","isLastLink":true,"isUserLink":false,"widgetId":"rgw28_56aba2012c1a1"},"id":"rgw28_56aba2012c1a1","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceItem.html","templateExtensions":["generalHelpers"],"attrs":{"fileRequiredPublicationTypes":["code","coverPage","experimentFindings","method","negativeResults","presentation","rawData","researchProposal","workingPaper","artifact","dataset"]},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceItem.html?publicationUid=272521912&linkId=54ed277b0cf28f3e65356839&hide=0&disableJavascript=disableJavascript&useAlternativeTemplate=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"widgetId":"rgw27_56aba2012c1a1"},"id":"rgw27_56aba2012c1a1","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceList.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceList.html?publicationUid=272521912&limit=3&disableJavascript=disableJavascript&type=fulltextFile","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"resourceCount":1,"hidden":false,"showMore":false,"fulltext":true,"publicationDownloadCount":{"data":{"value":0,"valueFormatted":"0","widgetId":"rgw29_56aba2012c1a1"},"id":"rgw29_56aba2012c1a1","partials":[],"templateName":"publicliterature\/stubs\/PublicationDownloadCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDownloadCount.html?publicationUid=272521912","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw26_56aba2012c1a1"},"id":"rgw26_56aba2012c1a1","partials":[],"templateName":"publicliterature\/stubs\/PublicationResources.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResources.html?publicationUid=272521912&type=fulltextFile&disableJavascript=1","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationResourcesAttachments":{"data":{"publicationUid":272521912,"publicationResourceList":{"data":{"publicationResourceItems":[],"widgetId":"rgw31_56aba2012c1a1"},"id":"rgw31_56aba2012c1a1","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceList.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceList.html?publicationUid=272521912&limit=3&disableJavascript=disableJavascript&type=attachmentFile","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"resourceCount":0,"hidden":true,"showMore":false,"fulltext":false,"publicationDownloadCount":{"data":{"value":0,"valueFormatted":"0","widgetId":"rgw32_56aba2012c1a1"},"id":"rgw32_56aba2012c1a1","partials":[],"templateName":"publicliterature\/stubs\/PublicationDownloadCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDownloadCount.html?publicationUid=272521912","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw30_56aba2012c1a1"},"id":"rgw30_56aba2012c1a1","partials":[],"templateName":"publicliterature\/stubs\/PublicationResources.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResources.html?publicationUid=272521912&type=attachmentFile","viewClass":"views.publicliterature.PublicationResourcesView","yuiModules":["rg.views.publicliterature.PublicationResourcesView"],"stylesheets":[],"_isYUI":true},"publicationText":{"data":{"hide":false,"pages":[{"page":1,"text":"Predictive Entropy Search for Bayesian\nOptimization with Unknown Constraints\nJos\u00b4 e Miguel Hern\u00b4 andez-Lobato1\nHarvard University, Cambridge, MA 02138 USA\nJMH@SEAS.HARVARD.EDU\nMichael A. Gelbart1\nHarvard University, Cambridge, MA 02138 USA\nMGELBART@SEAS.HARVARD.EDU\nMatthew W. Hoffman\nUniversity of Cambridge, Cambridge, CB2 1PZ, UK\nMWH30@CAM.AC.UK\nRyan P. Adams\nHarvard University, Cambridge, MA 02138 USA\nRPA@SEAS.HARVARD.EDU\nZoubin Ghahramani\nUniversity of Cambridge, Cambridge, CB2 1PZ, UK\nZOUBIN@ENG.CAM.AC.UK\nAbstract\nUnknown constraints arise in many types of ex-\npensive black-box optimization problems. Sev-\neral methods have been proposed recently for\nperforming Bayesian optimization with con-\nstraints, based on the expected improvement (EI)\nheuristic. However, EI can lead to pathologies\nwhen used with constraints. For example, in the\ncase of decoupled constraints\u2014i.e., when one\ncan independently evaluate the objective or the\nconstraints\u2014EI can encounter a pathology that\npreventsexploration. Additionally, computingEI\nrequires a current best solution, which may not\nexist if none the data collected so far satisfy the\nconstraints. By contrast, information-based ap-\nproaches do not suffer from these failure modes.\nIn this paper, we present a new information-\nbased method called Predictive Entropy Search\nwith unknown Constraints (PESC). We analyze\nthe performance of PESC and show that it com-\npares favorably to EI-based approaches on syn-\nthetic and benchmark problems, as well as sev-\neral real-world examples. We demonstrate that\nPESC is an effective algorithm that provides a\npromising direction towards a unified solution\nfor constrained Bayesian optimization.\n1Authors contributed equally.\n1. Introduction\nWe are interested in finding the global maximum x?of an\nobjective function f(x) over some bounded domain, typi-\ncally X \u2282 Rd, subject to the non-negativity of a series of\nconstraint functions c1,...,cK. This can be formalized as\nmax\nx\u2208Xf(x)\ns.t.\nc1(x) \u2265 0,...,cK(x) \u2265 0.\n(1)\nHowever, f and c1,...,cK are unknown and can only\nbe evaluated pointwise via expensive queries to black-\nboxes that provide noise-corrupted evaluations of f and\nc1,...,cK. Note that we are assuming f and each of the\nconstraints ckare defined over the entire space X. We seek\nto find a solution to (1) with as few queries as possible.\nBayesian optimization methods approach this type of prob-\nlem by building a Bayesian model of the unknown objec-\ntive function and\/or constraints, using this model to com-\nputeanacquisitionfunctionthatrepresentshowusefuleach\ninpuy x is thought to be as a next evaluation, and then max-\nimizing this acquisition function to select the next input for\nfunction evaluation (see Brochu et al., 2010).\nIn this we work we extend Predictive Entropy Search (PES)\n(Hern\u00b4 andez-Lobato et al., 2014) to solve (1), an approach\nthat we call Predictive Entropy Search with unknown Con-\nstraints (PESC). PESC is a sequential optimization method,\nwhich, after N evaluations of f and c1,...,cK, proposes\nto evaluate these functions at the location xN+1, such\nthat xN+1approximately maximizes the expected informa-\ntion gain about the value of the constrained maximizer x?.\nWe compute this information gain by conditioning on\narXiv:1502.05312v1  [stat.ML]  18 Feb 2015"},{"page":2,"text":"Predictive Entropy Search with Unknown Constraints\nthe data Dk\nnotes the objective data and k = 1,...,K denotes the con-\nstraints. We assume that f and c1,...,cKfollow indepen-\ndent Gaussian process (GP) priors (see, e.g., Rasmussen &\nWilliams, 2006) and that observation noise is i.i.d. Gaus-\nsian with mean zero and variance \u03c32\nused probabilistic models for Bayesian nonparametric re-\ngression which provide a flexible framework for working\nwith unknown response surfaces.\nN= {(x1,yk\n1),...,(xN,yk\nN)} where k = 0 de-\nk. GPs are widely-\nWhile previous approaches to the problem of Bayesian op-\ntimization with unknown constraints have been proposed,\nmost are variants of expected improvement (EI) (Mockus\net al., 1978; Jones et al., 1998).\nSchonlau et al. (1998), one method of extending EI to\nthe constrained setting considers the expected feasible im-\nprovement, where the constraints are given as above; such\napproaches have recently been independently developed in\nGelbart et al. (2014); Gardner et al. (2014); Snoek (2013).\nAlternatively Gramacy & Lee (2010) consider the inte-\ngrated change in expected improvement of all points in the\nsearchspacewithrespecttoadensitygivenbytheprobabil-\nity of feasibility. Picheny (2014) considers the probability\nof improvement under a similar measure. Finally, Gramacy\net al. (2014) propose to combine EI with the augmented La-\ngrangian approach for constrained numerical optimization.\nInitially proposed by\nThestrategiesusedbythesemethodstoselectthenexteval-\nuation point are all based on the expected level of improve-\nment. As discussed below, however, this expectation is not\nalways well defined in the presence of constraints. In con-\ntrast to this previous work, the main contribution of this\npaper is to develop an approach (PESC) that is always well\ndefined. PESC achieves this by building a Bayesian op-\ntimization acquisition function around information gain in\nthe constrained setting, as described in Section 3.\n2. Expected improvement with constraints\nThe Expected Improvement (EI) heuristic measures the ex-\npected amount by which observing at x leads to improve-\nment over the current best value or incumbent \u03b7:\n?\nBecause all constraints must be satisfied at a new query\npoint in order for improvement (of the solution) to oc-\ncur. Approaches that compute the feasible expected im-\nprovement are obtained by discounting the original EI with\nthe posterior probability of a constraint violation. The re-\nsulting acquisition function\u2014which we call Expected Im-\nprovement with unknown Constraints (EIC)\u2014is given by\nEI(x|\u03b7,D0) =max(0,f(x) \u2212 \u03b7)p(f(x)|D0)df(x).\n\u03b1(x) = EI(x|\u03b7,D0)\nK\n?\nk=1\np(ck(x) \u2265 0|Dk),\n(2)\nIn the unconstrained case, \u03b7 is usually the maximum of\nthe posterior mean of f (Brochu et al., 2010). In the con-\nstrained case, \u03b7 is the largest value of the posterior mean\nof f such that all the constraints are satisfied at the corre-\nsponding location. However, since information about the\nconstraints may only be available through noisy measure-\nments, we may never be certain that the constraints are sat-\nisfiedatanyparticularlocation. Toavoidthisproblem, Gel-\nbart et al. (2014) consider a location x to be feasible only\nif all the constraints are satisfied at x with high posterior\nprobability, that is, if\n\u2200k \u2208 {1,...,K}, p(ck(x) \u2265 0|Dk) \u2265 1 \u2212 \u03b4k,\nfor small positive confidence thresholds \u03b4k. This is called\na probabilistic constraint. Under this new formulation, \u03b7 is\nthe largest value of the posterior mean for f such that (3) is\nsatisfied at the corresponding location. However, when no\npoint in the search space is feasible under the above defini-\ntion, \u03b7 doesnotexistandtheEIcannotbecomputed. Inthis\ncase, Gelbart et al. (2014) ignore the factor EI(x|\u03b7,D0) in\n(2) and only consider the posterior probability of the con-\nstraints being satisfied. The resulting acquisition function\nfocuses only on searching for a feasible location and ig-\nnores learning about the objective f.\n(3)\nNote that when used with probabilistic constraints, EIC is\nnot the true expected improvement of the best feasible so-\nlution. This is clear because the EIC does not depend on \u03b4k.\nComputing the true EI is not sensible due to the following\npathology: asinglenoisyobservationofconstraintsatisfac-\ntion may be insufficient to push the overall posterior prob-\nability of satisfaction above 1 \u2212 \u03b4k; thus a myopic strategy\nlike EI may see zero potential improvement from a single\nevaluation and EI may be uniformly zero.\nFurthermore, Gelbartetal.(2014)identifyapathologywith\nEI when one is able to separately evaluate the objective\nor the constraints, i.e., the decoupled case. The best so-\nlution x?must satisfy a conjunction of high objective value\nand high (non-negative) constraint values. By only evalu-\nating the objective or a single constraint, this conjunction\ncannot be satisfied by a single observation under a myopic\nsearch policy. Thus, the new observed x cannot become\nthe new incumbent as a result of a decoupled observation\nand the expected improvement is zero. Therefore standard\nEIC fails in the decoupled setting. Gelbart et al. (2014) cir-\ncumvent this pathology by treating decoupling as a special\ncase and using a two-stage acquisition function: first, x is\nchosen with EIC, and then the task (whether to evaluate the\nobjective or one of the constraints) is chosen with Entropy\nSearch (Hennig & Schuler, 2012) given x. This approach\ndoes not take full advantage of the available information in\nthe way a joint selection of x and the task would.\nOur new method, PESC, does not suffer from these\npathologies. First, the PESC acquisition function does not"},{"page":3,"text":"Predictive Entropy Search with Unknown Constraints\ndepend on the current best feasible solution, so it can op-\nerate coherently even when there is not yet a feasible solu-\ntion. Second, PESC naturally separates the contribution of\neach task (objective or constraint) in its acquisition func-\ntion. As a result, no pathology arises in the decoupled case\nand, thus, no ad hoc modifications to the acquisition func-\ntion are required. Furthermore, in addition to its increased\ngenerality, our experiments show that PESC performs fa-\nvorably when compared to EIC even in the basic setting of\njoint evaluations to which EIC is most suited.\n3. Predictive entropy search with constraints\nWe seek to maximize information about the location x?,\nthe constrained global maximum, whose posterior distribu-\ntion is p(x?|D0\nlet DN= {(xn,yn)}n\u2264N denote all the observations up\nto step N, where ynis a vector collecting the objective and\nconstraint observations at step n. The next query xN+1\ncan then be defined as that which maximizes the expected\nreduction in the differential entropy H[\u00b7] of the posterior\non x?. We can write the PESC acquisition function as\nN,...,DK\nN). In the coupled setting we will\n\u03b1(x) = H[x?|DN] \u2212 Ey{H[x?|DN\u222a (x,y)]}\nwhere the expectation is taken with respect to the posterior\ndistribution on the noisy evaluations of f and c1,...,cK\nat x, that is, p(y|DN,x).\nThe exact computation of the above expression is infeasi-\nble in practice. Instead, we follow Houlsby et al. (2012);\nHern\u00b4 andez-Lobato et al. (2014) and take advantage of the\nsymmetry of mutual information, rewriting this acquisition\nfunction as the mutual information between y and x?given\nthe collected data DN. That is,\n\u03b1(x) = H[y|DN,x] \u2212 Ex?{H[y|DN,x,x?]}\nwhere the expectation is now with respect to the poste-\nrior p(x?|DN) and where p(y|DN,x,x?) is the posterior\npredictive distribution for objective and constraint values\ngiven past data and the location of the global solution to\nthe constrained optimization problem x?. We call this dis-\ntribution the conditioned predictive distribution (CPD).\n(4)\n(5)\nThe first term on the right-hand side of (5) is straightfor-\nward to compute: it is the entropy of the predictive dis-\ntribution of independent Gaussians. This is one half of the\nsumofthelogpredictivevariancesplus1\nHowever, the second term has to be approximated. For\nthis, wefirstapproximatetheexpectationbyaveragingover\nsamples of x?approximately drawn from p(x?|DN). To\nsample x?, we first approximately draw f and c1,...,cK\nfrom their GP posteriors using a finite parameterization of\nthese functions. Then we solve a constrained optimization\nproblem using the sampled functions. The solution to this\n2(K+1)log(2\u03c0e).\nproblem is the sample of x?. This optimization approach\nis an extension of the approach described in more detail\nby Hern\u00b4 andez-Lobato et al. (2014), extended to the con-\nstrained setting. For each value of x?generated by this\nprocedure, we approximate the CPD p(y|DN,x,x?) as de-\nscribed in the next section.\n3.1. Approximating the CPD\nLet z = [f(x),c1(x),...,cK(x)]Tdenote the concate-\nnated vector of the noise-free objective and constraint val-\nues at x. We can approximate the CPD by first approx-\nimating the posterior predictive distribution of z condi-\ntioned on DN, x, and x?, which we call the noise free CPD\n(NFCPD),andthenconvolvingthatapproximationwithad-\nditive Gaussian noise of variance \u03c32\ncan be informally written as\n0,...,\u03c32\nK. The NFCPD\np(z|DN,x,x?) \u221d\n?\n?\n\u03b4[z0\u2212 f(x)]\n??K\nk=1\u0398[ck(x?)]\n1 \u2212?K\nk=1\u03b4[zk\u2212 ck(x)]\n?\nx??=x?\n???K\n?\n\u0398[f(x?) \u2212 f(x?)] +\n????K\n?\nk=1\u0398[ck(x?)\nk=1\u0398[ck(x?)]\n?\np(f,c1,...,cK|DN)df dc1... dck\nwhere \u0398 denotes the Heaviside step function, and the inte-\ngral above marginalizes out the infinite dimensional quanti-\nties f, c1,...,cKwhich encode the objective and the con-\nstraint functions. These infinite dimensional vectors are\nsampled from p(f,c1,...,ck|DN), given as infinite, multi-\nvariate Gaussian distributions. The Dirac delta functions in\nthesecondlineof(6)projecttheseinfinitedimensionalvec-\ntors to their corresponding values at x. The infinite product\nin the middle lines of (6) guarantee that x?is the global\nsolution, by taking value one when f(x?) is smaller than\nf(x?) for all feasible x??= x?and zero otherwise.\n(6)\nWe find a Gaussian approximation to (6) in several steps.\nWe first approximate the infinite product with one that is\nfinite dimensional, only evaluated at those locations where\nthe objective has been observed. Let f denote the (N +1)-\ndimensional vector containing objective function evalua-\ntions at x?and x1,...,xN, and define constraint vectors\nc1,...,cKsimilarly. We can then obtain a finite dimen-\nsional approximation to the relevant factors of (6) as\nq1(f,c1,...,cK) =\n?n\nk=1\u0398[ck0]\ni=1\n???K\nk=1\u0398[cki]\n?\n?\n\u0398[f0\u2212 fi] +\n?\n1 \u2212?K\nk=1\u0398[cki]\n??\n(7)\n??K\nwhere p(f,c1,...,cK|DN) is the GP predictive distribu-\ntion for objective and constraint values. Because (7) is\nnot tractable, we approximate the normalized version of q1\np(f,c1,...,cK|DN)"},{"page":4,"text":"Predictive Entropy Search with Unknown Constraints\nwith a product of Gaussians using expectation propagation\n(EP) (Minka, 2001). In particular, we obtain\nZ\u22121\n1q1(f,c1,...,cK) \u2248 q2(f,c1,...,cK) =\nN(f|m0,V0)?K\nwhere Z1is the normalization constant of q1and (mk,Vk)\nfor k = 0,...,K are the mean and covariance terms deter-\nmined by EP. Details on the implementation of EP can be\nfound in the supplementary material, however roughly this\nalgorithm proceeds by iteratively refining individual fac-\ntors to fit the joint distribution where a single Gaussian has\nbeen replaced by its true (but intractable) factor. Given q2,\nwe can approximate (6) by\n?\n???K\nq2(f,c1,...,cK)df dc1 \u00b7\u00b7\u00b7 dcK,\nwhere p(z|f,c1,...,cK) is a K + 1 dimensional, Gaus-\nsian conditional distribution given by the GP priors\non f,c1,...,cKand Z2is a normalization constant. This\nconditional distribution approximates the deltas in the sec-\nond line of (6). Note that, in the third line of (9), we have\nintroduced one of the factors forming the infinite product in\n(6). This is the factor corresponding to the point x at which\nwe are making predictions and guarantees that z0= f(x)\nis smaller than f0= f(x?) when all the constraints are sat-\nisfied at x\u2014i.e., when zk= ck(x) \u2265 0 for all k. After\nmarginalizing out f and c1,...,cKwe move from (9) to\nour final approximation of the NFCPD:\nk=1N(ck|mk,Vk),\n(8)\np(z|DN,x,x?) \u2248 Z\u22121\n2\np(z|f,c1,...,cK)\n?\nk=1\u0398[zk]\n?\n\u0398[f0\u2212 z0] +1 \u2212?K\nk=1\u0398[zk]\n??\n(9)\np(z|DN,x,x?) \u2248\nZ\u22121\n2\n????K\nN([z0,f0]|m?\nDetails on how to compute the means m?\nvariances v?\nvector m?\nin the supplementary material.\nk=1\u0398[zk]\n?\n\u0398[f0\u2212 z0] +\n0,V?\n?\n1 \u2212?K\nk,v?\nk=1\u0398[zk]\n??\n(10)\n0)?K\nk=1N(zk|m?\nk)df0.\n1,...,mK and\n1,...,v?\n0and the 2\u00d72 covariance matrix V?\nK, as well as the 2-dimensional mean\n0can be found\n3.2. The PESC acquisition function\nThe normalization constant Z2in (9) and (10) can be com-\nputed analytically. This allows us to obtain the marginal\nvariances of the right-hand-side of (10) by computing the\ngradient of logZ2with respect to m?\nv?\nresponding expressions are included in the supplementary\nmaterial. If we assume independence in the NFCPD (6),\nwe can then approximate the entropy in the CPD by per-\nforming the following operations. First, we add the noise\nvariances \u03c32\n0, V?\n0, m?\n1,...,mK,\n1,...,v?\nKusing formula 5.13 in Minka (2001). The cor-\n0,\u03c32\n1,...,\u03c32\nKto the marginal variances of the\nright-hand-side of (10) and second, after assuming Gaus-\nsianity, we sum one half of the logarithm of the resulting\nvariances and finally add\n2\nquisition function, which approximates (4), is then\n(K+1)\nlog(2\u03c0e). The PESC ac-\n\u03b1(x) =\n?\n?K\n1\nM\n?M\nk=1\ni=1g[vPD\n?\nf(x),vCPD\n?N\nf\n(x|x(i)\n? )]\n?\n+\n1\nN\nn=1g[vPD\nk(x),vCPD\nk\n(x|x(i)\n? )]\n?\n,\n(11)\nwhere M is the number of samples drawn from p(x?|DN),\nx(i)\nvPD\nthe noisy evaluations of f and ck at x, respectively,\nand vCPD\nfk\nmarginal variances of the CPD for the noisy evaluations\nof f and ckat x given that x?= x(i)\n(11) over the GP hyper-parameters can be done efficiently\nas in Hern\u00b4 andez-Lobato et al. (2014).\n? is the i-th of these samples, g(a,b) =1\nf(x) and vPD\n2(loga \u2212 logb),\nk(x) are the predictive variances for\n(x|x(i)\n? ) and vCPD\n(x|x(i)\n? ) are the approximated\n? . Marginalization of\nThe PESC acquisition function is additive in the expected\namount of information that is obtained from the evalua-\ntion of each task (objective or constraint) at any partic-\nular location x. For example, the expected information\ngain obtained from the evalation of f at x is given by\nthe term\nN\nother K terms in (11) measure the corresponding contri-\nbution from evaluating each of the constraints. This allows\nPESC to easily address the decoupled scenario when one\ncan independently evaluate the different functions at dif-\nferent locations. In other words, Equation (11) is a sum\nof individual acquisition functions, one for each function\nthat we can evaluate. Existing methods for Bayesian opti-\nmization with unknown constraints (described in the next\nsection) do not possess this desirable property. Finally, the\ncomplexity of PESC is of order O(MKN3) in the coupled\nsetting. As with unconstrained PES, this is dominated by\nthe cost of a matrix inversion in the EP step. In the decou-\npled setting this becomes O(M?K\n1\n?N\nn=1g[vPD\nf(x),vCPD\nf\n(x|x(i)\n? )] in (11). The\nk=1N3\nk) where Nkis the\nnumber of evaluations for the objective and constraint k.\n4. Related Work\nIn this section we describe other methods that have previ-\nously been proposed to address Bayesian optimization with\nunknown constraints. Most of them, like EIC, are based on\nextensions of the expected improvement heuristic (Mockus\net al., 1978; Jones et al., 1998). Because these acquisition\nfunctions are based on improvement, they are susceptible\nto pathologies similar to those affecting EIC described in\nSection 2. These methods can be effective in certain con-\ntexts but do not necessarily apply more generally."},{"page":5,"text":"Predictive Entropy Search with Unknown Constraints\n4.1. Augmented Lagrangian\nGramacy et al. (2014) propose a combination of the\nexpected improvement heuristic and the augmented La-\ngrangian (AL) optimization framework for constrained\nblackbox optimization. AL methods are a class of algo-\nrithms for constrained nonlinear optimization that work by\niteratively optimizing the unconstrained AL:\n?\nwhere p > 0 is a penalty parameter and \u03bb \u2265 0 is an ap-\nproximate Lagrange multiplier.\ntion at iteration n with parameters p(n)and \u03bb(n). Then,\n\u03bb(n+1)\nkk\nand p(n+1)= p(n)if x(n)\n?\nis feasible and p(n+1)= p(n)\/2\notherwise.\nLA(x|\u03bb,p) = f(x) \u2212\nK\n?\nk=1\n\u03bbkck(x) +1\n2pmin(0,ck(x))2\n?\nLet x(n)\n?\nbe the solu-\n= max(0,\u03bb(n)\n\u2212 ck(x(n)\n? )\/p(n)) for k = 1,...,K\nThe method proposed by Gramacy et al. (2014) assumes\nthat the evaluations of the constraints c1,...,cKare noise-\nfree.At the nth iteration, the next evaluation loca-\ntion is the one that maximizes the EI of the compos-\nite objective given by LA(x|\u03bb(n),p(n)), with \u03bb(0)\nk = 1,...,K and p(0)= 1\/2. Because LA(x|\u03bb(n),p(n))\nis unconstrained, the AL approach does not have to find\na best solution that is feasible, unlike EIC. However, AL\nis limited by requiring noiseless constraints so that p and\n\u03bb can be updated at each iteration. In section 5.3 we show\nthat PESC and EIC perform better than AL on the synthetic\nbenchmark problem considered in Gramacy et al. (2014),\neven when the AL method has access to the true objective\nfunction and PESC and EIC do not.\nk\n= 0 for\n4.2. Integrated expected conditional improvement\nGramacy & Lee (2010) propose an acquisition function\nbased on the integrated expected conditional improvement\n(IECI), which is given by\n?\nwhere EI(x?) is the expected improvement at x?\nand EI(x|x?) is the expected improvement at x?when the\nobjective has been evaluated at x, but without knowing the\nvalue obtained. The IECI at x is the expected reduction in\nimprovement at x?under the density h(x?) caused by ob-\nserving the objective at that location, where h(x?) is the\nprobability of all the constraints being satisfied at x?. IECI\nmeasuresimprovementoverthebestsolution\u03b7, whichGra-\nmacy & Lee (2010) define as the highest posterior mean\nof the objective over the whole optimization domain. The\nmotivation for IECI is that evaluating at an infeasible lo-\ncation may also provide useful information, and therefore\none should consider improvement over the whole optimiza-\ntion domain. Gelbart et al. (2014) compare IECI with EIC\nIECI(x) =[EI(x?) \u2212 EI(x?|x)]h(x?)dx?,\n(12)\nfor optimizing the hyper-parameters of a topic model with\nconstraints on the entropy of the per-topic word distribution\nand show that EIC outperforms IECI for this problem.\n4.3. Stepwise uncertainty reduction\nPicheny (2014) proposes to sequentially evaluate the lo-\ncation that most decreases, in expectation, an uncertainty\nmeasure given by integrating the product of the probability\nof improvement and the probability of feasibility. This is\nthe expected volume (EV) of the admissible excursion set\nabove the best feasible objective \u03b7 found so far. That is,\n?\nwhere, as in IECI, h(x?) is the probability of the constraints\nbeing satisfied at x?. This step-wise uncertainty reduction\napproach (SURA) is similar to PESC in that both methods\nwork by reducing a specific type of uncertainty measure\n(entropy for PESC and EV for SURA). However, SURA is\nlimited by having to compute the integral in (13) over the\nentire domain, which is done numerically over a grid on x?\n(Picheny, 2014). The resulting acquisition function must\nthen be globally optimized, which also requires a grid on x.\nThis nesting of grid operations limits the application of this\nmethod to small d. IECI has the same limitation. PESC\nalso involves an integral over the posterior on x?; however,\nthis can be done efficiently using the sampling approach\ndescribed in Hern\u00b4 andez-Lobato et al. (2014). Finally, since\nSURA is based on improvement (along with EIC, LA and\nIECI), it does not apply to the decoupled constraints sce-\nnario in which one can individually evaluate the objective\nor the constraints. PESC does not have this limitation.\nEV(x) =p[f(x?) \u2265 max(\u03b7,f(x))]h(x?)dx?,\n(13)\n5. Experiments\nWe evaluate the performance of predictive entropy search\nwith constraints (PESC) through experiments with i) syn-\nthetic functions sampled from the GP prior distribution, ii)\nanalytic benchmark problems previously used in the liter-\nature on Bayesian optimization with unknown constraints\nand iii) real-world constrained optimization problems.\nFor case i) above, the synthetic functions sampled from the\nGP prior are generated following the same experimental set\nup as in Hennig & Schuler (2012) and Hern\u00b4 andez-Lobato\net al. (2014). The search space is the unit hypercube of\ndimension d, and the ground truth objective f is a sample\nfrom a zero-mean GP with a squared exponential covari-\nance function of unit amplitude and length scale ? = 0.1 in\neach dimension. We represent the function f by first sam-\npling from the GP prior on a grid of 1000 points generated\nusing a Halton sequence (see Leobacher & Pillichsham-\nmer, 2014) and then defining f as the resulting GP pos-\nterior mean. We use a single constraint function c1whose"},{"page":6,"text":"Predictive Entropy Search with Unknown Constraints\nAcquisition Functions\nNumber of Function Evaluations\nLog Median Utility Gap\nResults for d=1\n0.00.2 0.40.6 0.81.0\n\u22123\n\u22123\n\u22122\n\u22121\n00\n1\n2\n3\n3\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\n0.0 0.2 0.40.6 0.8\n1.0\n0.0\n0.2\n0.4\n0.6\n0.8\nx\nAcqusition Function\nObjective\nConstraint\nMarginal Posterior Distributions\nRS\nPESC\nx\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u22123.5\n\u22122.5\n\u22121.5\n\u22120.5\n0255075 100\nMethods\nPESC\nRS\nRSDG\n\u25cf\n\u25cf\n\u25cf\n10\nFigure 1. Left: marginal posterior predictive distributions for the objective and a single constraint function given some collected data\ndenoted by crosses. Middle: PESC and RS acquisition functions given these data. Right: median utility gap for PESC, RS and RSD in\nthe experiments with synthetic functions sampled from the GP prior with d = 1.\nground truth is sampled in the same way as f. The evalu-\nations for f and c1are contaminated with i.i.d. Gaussian\nnoise with variance \u03c32\nf= \u03c32\n1= 0.01.\n5.1. Accuracy of the PESC approximation\nWe first analyze the accuracy of the approximation to (5)\ngenerated by PESC. We compare the PESC approximation\nwith a ground truth for (5) obtained by rejection sampling\n(RS). The RS method works by discretizing the search\nspace using a uniform grid.\nspect to p(x?|Dn) in (5) is then approximated by Monte\nCarlo. To achieve this, f and c1,...,cKare sampled on\nthe grid and the grid cell with positive c1,...,cK (fea-\nsibility) and the highest value of f (optimality) is se-\nlected. For each sample of x? generated by this proce-\ndure, H[p(y|Dn,x,x?)] is approximated by rejection sam-\npling: we select those samples of f and c1,...,cKwhose\ncorresponding feasible optimal solution is the sampled x?\nand reject the other samples. We then assume that the se-\nlected samples for f and c1,...,cKare independent and\nhave Gaussian marginal distributions. Under this assump-\ntion, H[p(y|Dn,x,x?)] can be approximated using the for-\nmula for the entropy of independent Gaussian random vari-\nables, with the variance parameters in this formula being\nequal to the empirical marginal variances of the selected\nsamples of f and c1,...,cKat x plus the corresponding\nnoise variances \u03c32\nThe expectation with re-\nfand \u03c32\n1,...,\u03c32\nK.\nThe left plot in Figure 1 shows the posterior distribution\nfor f and c1given 5 evaluations sampled from the GP prior\nwith d = 1. The posterior is computed using the optimal\nGP hyperparameters. The corresponding approximations\nto (5) generated by PESC and RS are shown in the middle\nplot of Figure 1. Both PESC and RS use a total of 50 sam-\nples from p(x?|Dn) when approximating the expectation\nin (5). The PESC approximation is very accurate, and im-\nportantly its maximum value is very close to the maximum\nvalue of the RS approximation.\nOne disadvantage of the RS method is its high cost, which\nscales with the size of the grid used. This grid has to be\nlarge to guarantee good performance, especially when d is\nlarge. An alternative is to use a small dynamic grid that\nchanges as data is collected. Such a grid can be obtained\nby sampling from p(x?|Dn) using the same approach as in\nPESC. The samples obtained would then form the dynamic\ngrid. The resulting method is called Rejection Sampling\nwith a Dynamic Grid (RSDG).\nWe compare the performance of PESC, RS and RSDG in\nexperiments with synthetic data corresponding to 500 pairs\nof f and c1sampled from the GP prior with d = 1. At\neach iteration, RSDG draws the same number of samples\nof x?as PESC. We fix \u03b41= 0.05 and assume that the GP\nhyperparameter values are known to each method. Recom-\nmendations are made by finding the location with highest\nposterior mean for f such that c1is non-negative with prob-\nability at least 1 \u2212 \u03b41. For reporting purposes, we set the\nutility u(x) of a recommendation x to be f(x) if x satisfies\nthe constraint, and otherwise a penalty value of the worst\n(largest) objective function value achievable in the search\nspace. For each recommendation at x, we compute the\nutility gap |u(x) \u2212 u(x?)|, where x?is the true solution of\nthe optimization problem. Each method is initialized with\nthe same three random points drawn with Latin hypercube\nsampling.\nThe right plot in Figure 1 shows the median of the utility\ngap for each method across the 500 realizations of f and c1.\nThe x-axis in this plot is the number of joint function eval-\nuations for f and c1. We report the median because the\nempirical distribution of the utility gap is heavy-tailed and\nin this case the median is more representative of the lo-\ncation of the bulk of the data than the mean. The heavy\ntails arise because we are measuring performance across\n500 different optimization problems with very different de-\ngrees of difficulty. In this and all following experiments,\nstandard errors on the reported plot are computed using"},{"page":7,"text":"Predictive Entropy Search with Unknown Constraints\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n0.2\n0.5\n01020\nResults for d = 8\nResults for d = 2\nNumber of Function Evaluations\nNumber of Function Evaluations\nMethods\nEIC\nPESC\nRSDG\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u22122.6\n\u22121.6\n\u22120.6\n0 25 5075 100\nLog Median Utility Gap\n10\nMethods\nEIC\nPESC\nRSDG\n\u25cf\n\u25cf\n\u25cf\nLog Median Utility Gap\n10\nFigure 2. Optimizing samples from the prior with d = 2 (top) and\nd = 8 (bottom).\nthe bootstrap. The plot shows that PESC and RS are bet-\nter than RSDG. Furthermore, PESC is very similar to RS,\nwith PESC even performing slightly better at the end of the\ndata collection process since PESC is not limited by a finite\ngrid as RS is. These results show that PESC yields a very\naccurate approximation of the information gain. Further-\nmore, although RSDG performs worse than PESC, RSDG\nis faster because the rejection sampling operation (with a\nsmall grid) is less expensive than the EP algorithm. Thus,\nRSDG is an attractive alternative to PESC when the avail-\nable computing time is very limited.\n5.2. Synthetic functions in 2 and 8 input dimensions\nWe also compare the performance of PESC and RSDG\nwith that of EIC (Section 2) using the same experimen-\ntal protocol as in the previous section, but with dimen-\nsionalities d = 2 and d = 8. We do not compare with RS\nhere because its use of grids does not scale to higher di-\nmensions. Figure 2 shows the utility gap for each method\nacross 500 different samples of f and c1from the GP prior\nwith d = 2 (top) and d = 8 (bottom). Overall, PESC is the\nbest method, followed by RSDG and EIC. RSDG performs\nsimilarly to PESC when d = 2, but is significantly worse\nwhen d = 8. This shows that, when d is high, grid based\napproaches (e.g. RSDG) are at a disadvantage with respect\nto methods that do not require a grid (e.g. PESC).\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u22122.3\n\u22121.3\n\u22120.3\n0102030\nNumber of Function Evaluations\nMethods\nAL\nEIC\nPESC\n\u25cf\n\u25cf\n\u25cf\nResults on the Toy Problem\nLog Mean Utility Gap\n10\nFigure 3. Mean utility gap for PESC and EIC in the toy problem.\n5.3. A toy problem\nWe compare PESC with EIC and AL (Section 4.1) in the\ntoy problem described in Gramacy et al. (2014). We seek\nto maximize the function f(x) = \u2212x1\u2212 x2, subject to the\nconstraint functions c1(x) \u2265 0 and c2(x) \u2265 0, given by\nc1(x) = 0.5sin(2\u03c0(x2\nc2(x) = \u2212x2\nwhere x is confined to the unit square. The evaluations for\nf, c1and c2are noise-free. We compare PESC and EIC\nwith \u03b41= \u03b42= 0.025 and a squared exponential GP ker-\nnel. PESC uses 10 samples from p(x?|Dn) when approx-\nimating the expectation in (5). We use the AL implemen-\ntation provided by Gramacy et al. (2014) in the R package\nlaGP which is based on the squared exponential kernel and\nassumes the objective f is known. Thus, in order for this\nimplementation to be used, AL has an advantage over other\nmethods in that it has access to the true objective function.\nIn all three methods, the GP hyperparameters are estimated\nby maximum likelihood.\n1\u2212 2x2)) + x1+ 2x2\u2212 1.5, (14)\n2+ 1.5,\n1\u2212 x2\n(15)\nFigure 3 shows the mean utility gap for each method across\n500 independent realizations. Each realization corresponds\nto a different initialization of the methods with three data\npoints selected with Latin hypercube sampling. Here, we\nreport the mean because we are now measuring perfor-\nmance across realizations of the same optimization prob-\nlem and the heavy-tailed effect described in Section 5.1 is\nless severe. The results show that PESC is significantly\nbetter than EIC and AL for this problem. EIC is superior\nto AL, which performs slightly better at the beginning be-\ncause it has access to the ground truth objective f.\n5.4. Finding a fast neural network\nIn this experiment, we tune the hyperparamters of a three-\nhidden-layer neural network subject to the constraint that\nthe prediction time must not exceed 2 ms on a GeForce\nGTX 580 GPU (also used for training). The search space\nconsists of 12 parameters: 2 learning rate parameters (ini-"},{"page":8,"text":"Predictive Entropy Search with Unknown Constraints\ntial and decay rate), 2 momentum parameters (initial and\nfinal), 2 dropout parameters (input layer and other layers),\n2 other regularization parameters (weight decay and max\nweight norm), the number of hidden units in each of the 3\nhidden layers, the activation function (RELU or sigmoid).\nThe network is trained on a using the deepnet package1,\nand the prediction time is computed as the average time of\n1000 predictions, each for a batch of size 128. The net-\nwork is trained on the MNIST digit classification task with\nmomentum-based stochastic gradient descent for 5000 iter-\nations. The objective is reported as the classification error\nrate on the validation set. As above, we treat constraint\nviolations as the worst possible value (in this case a classi-\nfication error of 1.0).\nFigure 4 shows the results of 50 iterations of Bayesian opti-\nmization. In this experiment and the next, the y-axis repre-\nsents observed function values, \u03b41= 0.05, a Mat\u00b4 ern 5\/2 GP\ncovariance kernel is used, and GP hyperparameters are in-\ntegrated out using slice sampling (Neal, 2000) as in Snoek\net al. (2012). Curves are the mean over 5 independent ex-\nperiments. We find that PESC performs significantly better\nthan EIC. However, when the noise level is high, report-\ning the best observation is an overly optimistic metric (due\nto \u201clucky\u201d evaluations); on the other hand, ground-truth is\nnot available. Therefore, to validate our results further, we\nused the recommendations made at the final iteration of\nBayesian optimization for each method (EIC and PESC)\nand evaluted the function with these recommended param-\neters. We repeated the evaluation 10 times for each of the 5\nrepeated experiments to compute a ground-truth score av-\neraged of 50 function evaluations. This procedure yields a\nscore of 0.45\u00b10.06 for PESC and 0.79\u00b10.03 for EIC (as in\nthe Figure, constraint violations are treated as a classifica-\ntion error of 100%). This result is consistent with Figure 4\nin that PESC performs significantly better than EIC, but\nalso demonstrates that, due to noise, Figure 4 is overly op-\ntimistic. While we may believe this optimism to affect both\nmethods equally, the ground-truth measurement provides a\nmore reliable result and a much clearer understanding of\nthe classification error attained by Bayesian optimization.\n5.5. Tuning Markov chain Monte Carlo\nHybrid Monte Carlo, also known as Hamiltonian Monte\nCarlo (HMC), is a popular Markov Chain Monte Carlo\n(MCMC) technique that uses gradient information in a nu-\nmerical integration to select the next sample. However,\nusing numerical integration gives rise to new parameters\nlike the integration step size and the number of integration\nsteps. Following the experimental set up in Gelbart et al.\n(2014), we optimize the number of effective samples pro-\nduced by an HMC sampler limited to 5 minutes of com-\n1https:\/\/github.com\/nitishsrivastava\/deepnet\n0 1020 30 40 50\nNumber of function evaluations\n1.6\n1.4\n1.2\n1.0\n0.8\n0.6\n0.4\n0.2\n0.0\n0.2\nlog10 objective value\nEIC\nPESC\nFigure 4. Classification error of a 3-hidden-layer neural network\nconstrained to make predictions in under 2 ms.\nputation time, subject to passing of the Geweke (Geweke,\n1992) and Gelman-Rubin (Gelman & Rubin, 1992) conver-\ngence diagnostics, as well as the constraint that the numer-\nical integration should not diverge. We tune 4 parameters\nof an HMC sampler: the integration step size, number of\nintegration steps, fraction of the allotted 5 minutes spent in\nburn-in, and an HMC mass parameter (see Neal, 2011). We\nuse the coda R package (Plummer et al., 2006) to compute\nthe effective sample size and the Geweke convergence di-\nagnostic, and the PyMC python package (Patil et al., 2010)\nto compute the Gelman-Rubin diagnostic over two inde-\npendent traces. Following Gelbart et al. (2014), we impose\nthe constraints that the absolute value of the Geweke test\nscorebeatmost2.0andtheGelman-Rubinscorebeatmost\n1.2, and sample from the posterior distribution of a logistic\nregression problem using the UCI German credit data set\n(Frank & Asuncion, 2010).\nFigure 5 evaluates EIC and PESC on this task, averaged\nover 10 independent experiments. As above, we perform a\nground-truthassessmentofthefinalrecommendations. The\naverage effective sample size is 3300\u00b11200 for PESC and\n2300 \u00b1 900 for EIC. From these results we draw a similar\nconclusion to that of Figure 5; namely, that PESC outper-\nforms EIC but only by a small margin, and furthermore that\nthe experiment is very noisy.\n6. Discussion\nIn this paper, we addressed global optimization with un-\nknown constraints. We described existing methods and\ndiscuss their weaknesses. We presented PESC, a method\nbased on the theoretically appealing expected information\ngain heuristic. We showed in Figure 1 that the mathemat-\nical approximations involved in PESC are quite accurate,\nand that PESC performs about equally well to a ground\ntruth method based on rejection sampling. In sections 5.2\nto 5.5, we showed that PESC outperforms current methods"},{"page":9,"text":"Predictive Entropy Search with Unknown Constraints\n020406080100\nNumber of function evaluations\n-5\n-4\n-3\n-2\n-1\n0\n\u2212log10 effective sample size\nEIC\nPESC\nFigure 5. Tuning Hamiltonian Monte Carlo to maximize the num-\nber of effective samples within 5 minutes of compute time.\nsuch as EIC and AL over a variety of problems. In ad-\ndition, PESC is easily applied to problems with decoupled\nconstraints, with noadditional computationalcostand none\nof the pathologies discussed in Gelbart et al. (2014).\nOne disadvantage of PESC is that it is relatively difficult to\nimplement: in particular, the EP approximation often leads\nto numerical instabilities. Therefore, we have integrated\nour implementation, which carefully addresses these nu-\nmerical issues, into the open-source Bayesian optimization\npackage Spearmint at https:\/\/github.com\/HIPS\/\nSpearmint\/tree\/PESC. We have demonstrated that\nPESC is a flexible and powerful method and we hope the\nexistence of such a method will bring constrained Bayesian\noptimization into the standard toolbox of Bayesian opti-\nmization practitioners.\nAcknowledgements\nJos\u00b4 e Miguel Hern\u00b4 andez-Lobato acknowledges support\nfrom the Rafael del Pino Foundation.\nmani acknowledges support from Google Focused Re-\nsearch Award and EPSRC grant EP\/I036575\/1. Matthew\nW. Hoffman acknowledges support from EPSRC grant\nEP\/J012300\/1.\nZoubin Ghahra-\nReferences\nBrochu, Eric, Cora, Vlad M., and de Freitas, Nando. A tu-\ntorial on Bayesian optimization of expensive cost func-\ntions, 2010. arXiv:1012.2599 [cs.LG].\nFrank, Andrew and Asuncion, Arthur. UCI machine learn-\ning repository, 2010.\nGardner, Jacob R., Kusner, Matt J., Xu, Zhixiang (Ed-\ndie), Weinberger, Kilian Q., and Cunningham, John P.\nBayesian optimization with inequality constraints. In\nICML, 2014.\nGelbart, Michael A., Snoek, Jasper, and Adams, Ryan P.\nBayesian optimization with unknown constraints.\nUAI, 2014.\nIn\nGelman, Andrew and Rubin, Donald R. A single series\nfrom the Gibbs sampler provides a false sense of secu-\nrity. In Bayesian Statistics, pp. 625\u201332. Oxford Univer-\nsity Press, 1992.\nGeweke, John. Evaluating the accuracy of sampling-based\napproaches to the calculation of posterior moments. In\nBayesianStatistics, pp.169\u2013193.UniversityPress, 1992.\nGramacy, Robert B. and Lee, Herbert K. H. Optimiza-\ntion under unknown constraints, 2010. arXiv:1004.4027\n[stat.ME].\nGramacy, Robert B., Gray, Genetha A., Digabel, Se-\nbastien Le, Lee, Herbert K. H., Ranjan, Pritam, Wells,\nGarth, and Wild, Stefan M. Modeling an augmented La-\ngrangian for improved blackbox constrained optimiza-\ntion, 2014. arXiv:1403.4890v2 [stat.CO].\nHennig, Philipp and Schuler, Christian J. Entropy search\nfor information-efficient global optimization. JMLR, 13,\n2012.\nHern\u00b4 andez-Lobato, J. M, Hoffman, M. W., and Ghahra-\nmani, Z. Predictive entropy search for efficient global\noptimization of black-box functions.\nNeural Information Processing Systems 25. Curran As-\nsociates, Inc., 2014.\nIn Advances in\nHoulsby, N., Hern\u00b4 andez-Lobato, J. M, Huszar, F., and\nGhahramani, Z. Collaborative Gaussian processes for\npreference learning. In Advances in Neural Information\nProcessing Systems 25, pp. 2096\u20132104. Curran Asso-\nciates, Inc., 2012.\nJones,\nWilliam J. Efficient global optimization of expensive\nblack-box functions. Journal of Global optimization, 13\n(4):455\u2013492, 1998.\nDonald R, Schonlau,Matthias,and Welch,\nLeobacher, Gunther and Pillichshammer, Friedrich. Intro-\nduction to quasi-Monte Carlo integration and applica-\ntions. Springer, 2014.\nMinka, Thomas P. A family of algorithms for approximate\nBayesian inference. PhD thesis, Massachusetts Institute\nof Technology, 2001.\nMockus, Jonas, Tiesis, Vytautas, and Zilinskas, Antanas.\nThe application of Bayesian methods for seeking the ex-\ntremum. Towards Global Optimization, 2, 1978.\nNeal, Radford. Slice sampling. Annals of Statistics, 31:\n705\u2013767, 2000."},{"page":10,"text":"Predictive Entropy Search with Unknown Constraints\nNeal, Radford. MCMC using Hamiltonian dynamics. In\nHandbook of Markov Chain Monte Carlo. Chapman and\nHall\/CRC, 2011.\nPatil, Anand, Huard, David, and Fonnesbeck, Christopher.\nPyMC: Bayesian stochastic modelling in Python. Jour-\nnal of Statistical Software, 2010.\nPicheny, Victor. A stepwise uncertainty reduction approach\nto constrained global optimization. In Proceedings of the\nSeventeenth International Conference on Artificial Intel-\nligence and Statistics, pp. 787\u2013795, 2014.\nPlummer, Martyn, Best, Nicky, Cowles, Kate, and Vines,\nKaren. CODA: Convergence diagnosis and output anal-\nysis for MCMC. R News, 6(1):7\u201311, 2006.\nRasmussen, C. and Williams, C. Gaussian Processes for\nMachine Learning. MIT Press, 2006.\nSchonlau, Matthias, Welch, William J, and Jones, Don-\nald R.Global versus local search in constrained\noptimization of computer models.\nMonograph Series, pp. 11\u201325, 1998.\nLecture Notes-\nSnoek, Jasper. Bayesian Optimization and Semiparametric\nModels with Applications to Assistive Technology. PhD\nthesis, University of Toronto, Toronto, Canada, 2013.\nSnoek, Jasper, Larochelle, Hugo, and Adams, Ryan P.\nPractical Bayesian optimization of machine learning al-\ngorithms. In NIPS, 2012."},{"page":11,"text":"Supplementary Material for \u201cPredictive Entropy Search for\nBayesian Optimization with Unknown Constraints\u201d\nJos\u00e9 Miguel Hern\u00e1ndez-Lobato\u2217, Michael A. Gelbart\u2217, Matthew W. Hoffman,\nRyan P. Adams and Zoubin Ghahramani\nFebruary 18, 2015\n1Introduction\nWe are interested in finding the global maximum x\u22c6of an objective function f(x) over some bounded domain,\ntypically X \u2282 Rd, subject to a series of constraint functions c1,...,cKbeing positive, that is, ck(x) \u2265 0, for\nk = 1,...,K. In particular, we want to solve problems of the form\nmaxf(x) s.t.\nc1(x) \u2265 0,...,cK(x) \u2265 0.\nThe objective function f and the constraint functions c1,...,cK are unkown and can only be evaluated via\nqueries to black-boxes that provide noisy outputs of the form yf\nfor ck, where k = 1,...,K. In this document, we describe a sequential search algorithm that, after n\nevaluations of the objective f and of the constraints c1,...,cK, proposes to evaluate these functions at\nsome location xn+1. To make this decision the search algorithm conditions on all previous observations\nDf\nN evaluations, the algorithm makes a final recommendation ? xN for the global maximizer of the objective\nfunctions f and c1,...,cK to guide the search and to select ? xN. In this work we use a zero-mean Gaussian\nwhere [Kf\ndescribed above, the vector of concatenated observations yf\nzero mean. Therefore, at any location x, the objective function f(x) conditioned on past observations Df\nthen Gaussian with marginal mean \u00b5f\ni\u223c N(f(xi),\u03c32\nf) for f and yk\ni\u223c N(ck(xi),\u03c32\nk)\nn= {(x1,yf\nfunction f under the constraints given by c1,...,cK.\nWe take a Bayesian approach to the problem described above and use a probabilistic model for the latent\ni),...,(xn,yf\nn)}, D1\nn,...,Dk\nn, where Dk\nn= {(x1,yk\ni),...,(xn,yk\nn)} for k = 1,...,K. After\nprocess (GP) prior for all the latent functions [2]. Given any finite collection of points {x1,...,xn}, the\nvectors with the values of f at these points are jointly zero-mean Gaussian with covariance matrix Kf\nn]ij = kf(xi,xj) and kf is a positive-definite covariance function. For the Gaussian likelihood\nn,\nn= (yf\n1,...,yf\nn)Tis also jointly Gaussian with\nnis\nn(x) and variance vf\nn(x) given by\n\u00b5f\nvf\nn(x)\nn(x)\n=\n=\nkf\nkf(x,x) \u2212 kf\nn(x)T(Kf\nn+ \u03c32\nn(x)T(Kf\nfI)\u22121yf\nn,\n(1)\n(2)\nn+ \u03c32\nfI)\u22121kf\nn(x),\nwhere kf\nthe prior variance of f(x). Similarly, the vector with the evaluations of ck at {x1,...,xn} is also jointly\nGaussian with zero mean and covariance matrix Kk\ncovariance function. For the Gaussian likelihood described above, the vector of concatenated observations\nyk\nx, the constraint function ck(x) conditioned on past observations Dk\n\u2217Authors contributed equally.\nn(x) is a vector of prior cross-covariances between f(x) and {f(x1),...,f(xn)} and kf(x,x) is\nn, where [Kk\nn]ij= kk(xi,xj) and kkis a positive-definite\nn= (yk\n1,...,yk\nn)Tfor the k-th constraint is also jointly Gaussian with zero mean. Therefore, at any location\nnis Gaussian with marginal mean \u00b5k\nn(x)\n1"},{"page":12,"text":"and variance vk\nabove for \u00b5f\nn(x) for k = 1,...,K. The expressions for \u00b5k\nn(x) and vf\nn(x) and vk\nn(x) are similar to the ones shown\nn(x). In particular,\n\u00b5k\nvk\nn(x)\nn(x)\n=\n=\nkk\nkk(x,x) \u2212 kj\nn(x)T(Kk\nn+ \u03c32\nn(x)T(Kj\nkI)\u22121yk\nn,\nn+ \u03c32\nkI)\u22121kk\nn(x),\nwhere kk\nprior variance of ck(x).\nn(x) is a vector of prior cross-covariances between ck(x) and {ck(x1),...,cK(xn)} and kk(x,x) is the\n2Predictive entropy search with unknown constraints\nTo solve the above problem efficiently, we propose to follow the information-theoretic method for active\ndata collection described in [1]. We are interested in maximizing information about the location x\u22c6 of the\nconstrained global maximum, whose posterior distribution is p(x\u22c6|Df\nabout x\u22c6can be measured in terms of the negative differential entropy of p(x\u22c6|Df\nour strategy is to select the xn+1that maximizes the expected reduction in this quantity. The corresponding\nacquisition function is\nH?p(x\u22c6|Df\nn,...DK\nwhere H[p(x)] = \u2212\u00b4p(x)logp(x)dx denotes the differential entropy of its argument and the expectation\nabove is taken with respect to the posterior predictive distribution for yfand y1,...,yKgiven Df\nand x. The exact evaluation of (3) is infeasible in practice. We simplify the problem by following the\napproach described in [3]. Note that (3) can be equivalently written as the mutual information between x\u22c6\nand yf,y1,...,yKgiven Df\nrewritten as\nH?p(yf,y1,...,yK|Df\nn,...DK\nwhere p(yf,y1,...,yK|Df\nDf\nconditioning on the location x\u22c6pushes the posterior predictions for f up in locations around x\u22c6and down\nin regions away from x\u22c6. This only occurs in areas where the constraints c1,...,cKare likely to be positive.\nHowever, conditioning on x\u22c6has no effect in other areas where c1,...,cKare likely to be negative. In addition\nto this, conditioning on x\u22c6has a significant effect on c1,...,cKsince all these functions have to be positive\nat x\u22c6. Therefore, we would expect that the posterior distribution of c1,...,cK is pushed up at x\u22c6. Note\nthat, unlike the previous formulation, the objective (4) is based on the entropies of predictive distributions,\nwhich are analytic or can be easily approximated, rather than on the entropies of distributions on x\u22c6whose\napproximation is more challenging.\nThe first term in (4) can be computed using the posterior marginals for f(x) and c1(x),...,cK(x):\n?\nn,D1\nn,...DK\nn). Our current information\nn,D1\nn,...DK\nn). Therefore,\n\u03b1(x)=\nn,D1\nn,...DK\nn)?\u2212\nEp(yf,y1,...,yK|Df\nn,D1\nn,x)\n?H?p(x\u22c6|Df\nn\u222a {(x,yf)},D1\nn\u222a {(x,y1)},...DK\nn\u222a {(x,yK)})??, (3)\nn,D1\nn,...DK\nn\nn,D1\nn,...DK\nn. Since the mututal information is a symmetric function, \u03b1(x) can be\n\u03b1(x)=\nn,D1\nn,...DK\nn,x)?\u2212\nEp(x\u22c6|Df\nn,D1\nn,D1\nn,x,x\u22c6) is the posterior predictive distribution for yf,y1,...,yKgiven\nnand the location x\u22c6 of the solution to the constrained optimization problem. Intuitively,\nn)\n?H?p(yf,y1,...,yK|Df\nn,D1\nn,...DK\nn,x,x\u22c6)??,\n(4)\nn,...DK\nn,D1\nn,...DK\nH?p(yf,y1,...,yK|Df\nHowever, the second term in (4) must be approximated. For this, we first approximate the expectation in (4)\nby averaging over samples x(i)\n\u22c6\ndrawn approximately from p(x\u22c6|Df\nwe then approximate the corresponding entropy function H\nthe method expectation propagation [4].\nn,D1\nn,...DK\nn,x)?\n=0.5 log(vf\nn(x) + \u03c32\nf) +\nK\n?\nk=1\nlog(vk\nn(x) + \u03c32\nk) + (K + 1)log(2\u03c0e)\n?\n.\nn,D1\nn,...DK\nn). For each of these samples,\np(yf,y1,...,yK|Df\n?\nn,D1\nn,...DK\nn,x,x(i)\n\u22c6 )\n?\nusing\n2"},{"page":13,"text":"2.1\nSampling from p(x\u22c6|Df\n2.2Approximating the predictive entropy\nSampling from the posterior over constrained global maxima\nn,D1\nn,...DK\nn) is relatively straight forward using the method described in [5].\nWe describe p(yf,y1,...,yK|Df\np(yf,y1,...,yK|Df\nn,D1\nn,...DK\nn,x,x(i)\n\u22c6 ) informally as\nn,D1\nn,...DK\nn,x,x(i)\n\u22c6 )=\nZ\u22121\n\uf8ee\nx\u2032?=x(i)\n?\nj=1\n?\nk=1\ndf dc1 ... dcK,\n\u02c6\n\u03b4[\u00aff \u2212 f(x)]N(yf|\u00aff,\u03c32\n??\nk=1\n?\nf)p(f|Df\nn)\n\uf8f0\n?\n\u22c6\nK\n?\n\u0398[ck(x\u2032)]\n?\n\u0398[f(x(i)\n\u22c6i) \u2212 f(x\u2032)] +\n?\n1 \u2212\nK\n?\nk=1\n\u0398[ck(x\u2032)]\n??\uf8f9\n\uf8fb\nk?\nK\n?\n\u0398[cj(x(i)\n\u22c6 )]\n?\u03b4[\u00af ck\u2212 ck(x)]N(yk|\u00af ck,\u03c32\nk)p(ck|Dk\nn)?\n?\nwhere f and c1,...,cKare here infinite dimensional vectors encoding the objective and the constraint func-\ntions, p(f|Df\nstep function, the Dirac deltas project the infinite dimensional vectors to their corresponding values at x and Z\nis a normalization constant. Note that yf,y1,...,yKare obtained from\u00aff = f(x),\u00af c1= c1(x),...,\u00af cK= cK(x)\nby adding independent Gaussian noise. Therefore, we focus on the corresponding distribution on\u00aff,\u00af c1,...,\u00af cK,\nthat is,\nn) and p(ck|Dk\nn) are infinite dimensional multivariate Guassian distributions, \u0398 is the Heaviside\np(\u00aff, \u00af c1,..., \u00af cK|Df\nn,D1\nn,...DK\nn,x,x(i)\n\u22c6 )=\n\u02c6\n\uf8ee\n?\ndf dc1 ... dcK.\n\u03b4[\u00aff \u2212 f(x)]p(f|Df\n??\nn)\n\uf8f0\n?\nK\n?\nx\u2032?=x(i)\n\u22c6\nK\n?\nk=1\n\u0398[ck(x\u2032)]\n?\n\u0398[f(x(i)\n\u22c6) \u2212 f(x\u2032)] +\n?\n1 \u2212\nK\n?\nk=1\n\u0398[ck(x\u2032)]\n??\uf8f9\n\uf8fb\nk=1\n?\n\u03b4[\u00af ck\u2212 ck(x)]N(yk|\u00af ck,\u03c32\nk)p(ck|Dk\nn)?\n?\nWe approximate this latter distribution with a multivariate Gaussian. However, instead of marginalizing over\nthe infinite dimensional elements f,c1,...,cK we will perform an approximation and marginalize only over\na finite dimensional proyection of these elements at the evaluation locations x1,...,xn and x(i)\nlet f = (f1,...,fn+1) be the vector such that fj= f(xj) for j = 1,...,n and fn+1= f(x(i)\nck= (ck\nWe focus on the distribution\n\u22c6 . For this,\n\u22c6 ). Similarly, let\n\u22c6 ) for k = 1,...,K.\n1,...,ck\nn+1) be the vector such that ck\nj= ck(xj) for j = 1,...,n and ck\nn+1= ck(x(i)\nq(f,c1,...,cK)\n\u221dN(f|mf\n\uf8ee\nj=1\n?K\nk=1\npred,Vf\npred)\n?K\nk=1\n?\n?\nN(ck|mck\npred,Vck\npred)\n?\n\uf8f0\nn\n?\n?\n??K\n?\nk=1\n\u0398[ck\nj]\u0398[fn+1\u2212 fj] +\n?\n1 \u2212\nK\n?\nk=1\n\u0398[ck\nj]\n??\uf8f9\n\uf8fb\n\u0398[ck\nn+1]\n?\n,\n(5)\n3"},{"page":14,"text":"where mf\nin Dfand where mck\ngiven the data in Dk. In particular, we have that\npredand Vf\npredare the mean and covariance matrix of the posterior distribution of f given the data\npredand Vck\npredare the mean and covariance matrix of the posterior distribution of ck\nmf\nVf\npred\n=\n=\nKf\nKf\n\u22c6(Kf\n\u22c6,\u22c6\u2212 Kf\nn+ \u03c32\nfI)\u22121yf\n\u22c6(Kf\nn,\nfI)\u22121[Kf\npred\nn+ \u03c32\n\u22c6]T,\nwhere Kf\nand Kf\nhave that\n\u22c6is an (n +1) \u00d7n matrix with the prior cros-covariances between f = (f1,...,fn+1) and f1,...,fn\n\u22c6,\u22c6is an (n + 1) \u00d7 (n + 1) matrix with the prior covariances between f = (f1,...,fn+1). Similarly, we\nmck\nVck\npred\n=\n=\nKk\nKk\n\u22c6(Kk\n\u22c6,\u22c6\u2212 Kk\nn+ \u03c32\nkI)\u22121yk\n\u22c6(Kk\nn,\nkI)\u22121[Kk\npred\nn+ \u03c32\n\u22c6]T,\nwhere Kk\nand ck(x1),...,ck(xn) and Kk\nck(x1),...,ck(xn),ck(x(i)\nside of (5) can be written as\n\u22c6is an (n + 1) \u00d7 n matrix with the prior cros-covariances between ck(x1),...,ck(xn),ck(x(i)\n\u22c6,\u22c6is an (n + 1) \u00d7 (n + 1) matrix containing the prior covariances between\n\u22c6 ). We now find a Gaussian approximation to the distribution (5). The right hand\n\u22c6 )\nq(f,c1,...,cK)\n\u221dN(f|mf\n\uf8ee\nj=1\n?K\nk=1\npred,Vf\npred)\n?K\nk=1\n?\n\uf8f9\n?\nN(ck|mck\npred,Vck\npred)\n?\n\uf8f0\nn\n?\n?\nhj(f,c1,...,cK)\n\uf8fb\ngk(f,c1,...,cK)\n,\n(6)\nwhere hj(f,c1,...,cK) =\nWe approximate these exact factors with approximate factors\u02dchj(f,c1,...,cK) and \u02dc gk(f,c1,...,cK) that\nhave a Gaussian form, that is,\n\u02dchj(f,c1,...,cK)=\nsh,jexp{\u22120.5[fjfn+1]Ah,j\nK\n?\n\u02dc gk(f,c1,...,cK)=\nsg,kexp{\u22120.5ag,k\nThe right hand side of (6) is then approximated by\n??K\nk=1\u0398[ck\nj]\n?\n\u0398[fn+1\u2212 fj] +\n?\n1 \u2212?K\nk=1\u0398[ck\nj]\n?\nand gk(f,c1,...,cK) = \u0398[ck\nn+1].\nfj,fn+1[fjfn+1]T+ [fjfn+1]bh,j\n?\nn+1]2+ bg,k\nck\nfj,fn+1}\nk=1\n?\nexp{\u22120.5ah,j\nck\nj[ck\nj]2+ bh,j\nck\njck\nj}\n,\nck\nn+1[ck\nn+1ck\nn+1},\n\u02dc q(f,c1,...,cK)\n\u221dN(f|mf\n\uf8ee\nj=1\n?K\nk=1\npred,Vf\npred)\n?K\nk=1\n?\n\uf8f9\n?\nN(ck|mck\npred,Vck\npred)\n?\n\uf8f0\nn\n?\n?\nN(f|mf,Vf)\n\u02dchj(f,c1,...,cK)\n\uf8fb\n\u02dc gk(f,c1,...,cK)\n=\n?K\nk=1\n?\nN(ck|mck,Vck)\n?\n.\n4"},{"page":15,"text":"where\nVf\nmf\n=\n=\n?[Vf\n?\npred]\u22121+\u02dcVf?\u22121,\n[Vck\nVck?\nj,j= [Ah,j\nfj,fn+1]2,2, \u02dc mfis an (n+1)-dimensional vector such that \u02dc mf\nj=1[bh,j\nn+1,n+1= ag,k\nck\nVf?[Vf\npred]\u22121mf\npred]\u22121+\u02dcVck?\u22121\n[Vck\npred+ \u02dc mf?,\n,\npred+ \u02dc mck?\nfj,fn+1]1,1and \u02dc vf\nVck\n=\nmck\n=\npred]\u22121mck\nand\u02dcVfis an (n + 1) \u00d7 (n + 1) matrix such that \u02dc vf\nj = 1,...,n and \u02dc vf\nfor j = 1,...,n and \u02dc mf\nfor j = 1,...,n and \u02dc vck\nand \u02dc mck\nck\nWe use EP to refine the approximate factors\u02dchjand \u02dc gk. EP adjusts each\u02dchjby minimizing the Kullback-\nLeibler (KL) divergence between\u02dchj(f,c1,...,cK)\u02dc q\\j(f,c1,...,cK) and hj(f,c1,...,cK)\u02dc q\\j(f,c1,...,cK),\nwhere we define \u02dc q\\j(f,c1,...,cK) as \u02dc q\\j(f,c1,...,cK) = \u02dc q(f,c1,...,cK)\/\u02dchj(f,c1,...,cK). We also adjust\neach \u02dc gkby minimizing the KL divergence between \u02dc gk(f,c1,...,cK)\u02dc q\\k(f,c1,...,cK) and gk(f,c1,...,cK)\u02dc q\\k(f,c1,...,cK),\nwhere \u02dc q\\k(f,c1,...,cK) = \u02dc q(f,c1,...,cK)\/\u02dc gk(f,c1,...,cK). The first step to refine each\u02dchj is to compute\nthe cavity distribution \u02dc q\\j(f,c1,...,cK) for each of these factors. In particular, we obtain\n?\nmfj,fn+1\nj,old\nj,old\n?\nck\nj\nj,old\nck\nj\nj,n+1= \u02dc vf\nn+1,j= [Ah,j\nfj,fn+1]1,2for\nj= [bh,j\nj,j= ah,j\nfor j = 1,...,n\nn+1,n+1=?n\nj=1[Ah,j\nfj,fn+1]1\nn+1=?n\nfj,fn+1]2, Vckis an (n+1)\u00d7(n+1) diagonal matrix such that \u02dc vck\nj, \u02dc mckis an (n+1)-dimensional vector such that \u02dc mck\nck\nj\nj = bh,j\nck\nj\nn+1= bg,k\nn+1.\nVfj,fn+1\nj,old\n=[Vf\nfj,fn+1]\u22121\u2212 Ah,j\nVfj,fn+1\nfj,fn+1\n?\u22121\nfj,fn+1\u2212 bh,j\n,\n=\n?\n[Vf\nfj,fn+1]\u22121mf\n?\u22121\nj,j]\u22121\u2212 bh,j\nfj,fn+1\n?\n,\nv\nck\nj\nj,old\n=[vck\nj,j]\u22121\u2212 ah,j\nck\nj\n,\nm\n=\n?\nmck\nj[vck\n?\u22121\n,\nwhere Vf\ndimensional mean vector. Similarly, vck\nthat, we compute\nfj,fn+1is the 2 \u00d7 2 covariance matrix for fj and fn+1 in \u02dc q and mf\nj,jis the variance for ck\nfj,fn+1is the corresponding 2-\nj is the corresponding mean. After\njin \u02dc q and mck\nZ\n=\n\u02c6\n??K\ngk(f,c1,...,cK)\u02dc q\\k(f,c1,...,cK)df dc1... dcK\n?\n=\n?\nk=1\n\u03a6[\u03b1k\nj] \u03a6(\u03b1j) +\n?\n1 \u2212\nK\n?\nk=1\n\u03a6[\u03b1k\nj]\n??\n,\nwhere \u03b1k\nwe need to compute\nj= m\nck\nj\nj,old\/\n?\nv\nck\nj\nj,oldand \u03b1j= [\u221211]mfj,fn+1\nj,old\n\/\n?\n[\u221211]Vfj,fn+1\nj,old\n[\u221211]T. Before updating ag,j\nck\nj\nand bh,j\nck\nj\ndlogZ\nck\nj,old\ndm\nj\n=\n(Z \u2212 1)\u03c6(\u03b1k\nZ\u03a6(\u03b1k\nj)\nj)\n?\nv\nck\nj\nj,old\n,\nd2logZ\nd[m\nck\nj\nj,old]2\n=\n\u2212(Z \u2212 1)\u03c6(\u03b1k\nZ\u03a6(\u03b1k\nj)\nj)\n\u00b7\n?\n\u03b1k\nj+\n(Z\u22121)\u03c6(\u03b1k\nZ\u03a6(\u03b1k\nj)\nj)\n?\nvcj\nl,old\nl\n.\n5"},{"page":16,"text":"We then update ah,j\nck\nj\nand bh,j\nck\nj\nusing\n[ah,j\nck\nj]new\n=\n\u22121\n]\u22121+ v\n[dlog Z\ndm\n\uf8f1\n\uf8f1\nck\nj\nj,old\nck\nj\nj,old\n,\n[bh,j\nck\nj]new\n=\n\uf8f2\n\uf8f2\n\uf8f3m\n\uf8f3m\nck\nj\nj,old\u2212 [d2logZ\nd[m\n?\nck\nj\nj,old]2\n]\u22121dlogZ\ndm\nck\nj\nj,old\n\uf8fc\n\uf8fd\n\uf8fe[ah,j\nj)\nck\nj]new\n?\u22121\uf8fc\n=\nck\nj\nj,old+\nv\nck\nj\nj,old\n?\n\u03b1k\nj+(Z \u2212 1)\u03c6(\u03b1k\nZ\u03a6(\u03b1k\nj)\n\uf8fd\n\uf8fe[ah,j\nck\nj]new.\nBefore updating Ah,j\nfj,fn+1and Bh,j\nfj,fn+1we need to compute\n??K\ndlogZ\ndmfj,fn+1\nj,old\n=\nk=1\u03a6[\u03b1k\nZ\u221as\nj]\n?\n\u03c6(\u03b1j)\n[\u221211],\ndlogZ\ndVfj,fn+1\nj,old\n=\n\u22121\n2[\u221211]T[\u221211]\n??K\nk=1\u03a6[\u03b1k\nj]\n?\n\u03c6(\u03b1j)\u03b1j\nZs\n,\nwhere s = [\u221211]Vfj,fn+1\nj,old\n[\u221211]T. We then compute\n[Vf\nfj,fn+1]new\n=\nVfj,fn+1\nj,old\n\u2212 Vfj,fn+1\nj,old\n\uf8ee\n\uf8f0\n\u2202mfj,fn+1\nj,old\n\u2202 logZ\n\u2202[mfj,fn+1\nj,old\n\u2202 logZ\n]\n?\n\u2202 logZ\n\u2202mfj,fn+1\nj,old\n?T\n\u2212 2\n\u2202 logZ\n\u2202Vfj,fn+1\nj,old\n\uf8f9\n\uf8fbVfj,fn+1\nj,old\n,\n[mf\nfj,fn+1]new\n=\nmfj,fn+1\nj,old\n+ Vfj,fn+1\nj,old\n.\nWe finally update Ah,j\nfj,fn+1and Bh,j\nfj,fn+1using\n[Ah,j\n[bh,j\nfj,fn+1]new\nfj,fn+1]new\n=[Vf\n[mf\nfj,fn+1]\u22121\nfj,fn+1]new[Vf\nnew\u2212 [Vfj,fn+1\nfj,fn+1]\u22121\nj,old\n]\u22121.\n=\nnew\u2212 mfj,fn+1\nj,old\n[Vfj,fn+1\nj,old\n]\u22121.\nWe now show how to refine the \u02dc gk. In this case, we compute first the parameters of the cavity\nv\nck\nj\nk,old\n=\n?\n?\n[vck\nj,j]\u22121\u2212 ag,k\nck\nj\n?\u22121\n,\nm\nck\nj\nk,old\n=\nmck\nj[vck\nj,j]\u22121\u2212 bg,k\nck\nj\n?\u22121\n.\nAfter that, we compute\n\u03b1\n=\nm\n?\n\u03a6(\u03b1),\nck\nj\nk,old\nv\nck\nj\nk,old\n,\nZ\n=\n\u2202 logZ\nck\nk,old\n\u2202m\nj\n=\n\u03c6[\u03b1]\n?\n\u03a6[\u03b1]\nv\nck\nj\nk,old\n,\n6"},{"page":17,"text":"\u22022logZ\n\u2202[m\nck\nj\nk,old]2\n=\n\u2212\n\u03c6[\u03b1]\nck\nj\nk,old\u03a6[\u03b1]\nv\n\u00b7\n?\n\u03b1 +\u03c6[\u03b1]\n\u03a6[\u03b1]\n?\n,.\nFinally, we update ag,k\nck\nj\nand bg,k\nck\nj\nas\n[ag,k\nck\nj]new\n=\n\u22121\n?\u22121\n?\n\uf8f1\ndlog Z\nck\nk,old\ndm\nj\n+ v\nck\nj\nk,old\n,\n[bg,k\nck\nj]new\n=\n\uf8f2\n\uf8f3m\nck\nj\nk,old\u2212 [d2logZ\nd[m\nck\nj\nk,old]2]\u22121dlogZ\ndm\nck\nj\nk,old\n\uf8fc\n\uf8fd\n\uf8fe[ag,k\nn,D1\nck\nj]new.\nOnce EP has converged we can approximate p(f(x),c1(x),...,cK(x)|Df\nn,...DK\nn,x,x(i)\n\u22c6 ) as\np(f(x),c1(x),...,cK(x)|Df\nn,D1\nn,...DK\nn,x,x(i)\n\u22c6 )\n\u2248\n\u02c6\n??K\n\u02dc q(f,c1,...,cK)df dc1...dcK\n?\np(f(x)|f)p(c1(x)|c1)\u00b7\u00b7\u00b7p(cK(x)|cK)\n?\nk=1\n\u0398[ck(x)]\n?\n\u0398[fn+1\u2212 f(x)] +\n?\n1 \u2212\nK\n?\nk=1\n\u0398[ck(x)]\n??\n(7)\nwhere the constraint factor\nf(x) is smaller than fn+1= f(x(i)\nk = 1,...,K. Unfortunately, the right-hand side of the above equation is not analytical. Nevertheless, we\napproximate it with a product of Gaussians that have the same marginal means and variances. In particular,\n???K\nk=1\u0398[ck(x)]\n\u22c6 ) when all the constraints are satisfied at x, that is, when ck(x) \u2265 0 for\n?\n\u0398[fn+1\u2212 f(x)] +1 \u2212?K\nk=1\u0398[ck(x)]\n??\nabove enforces that\np(f(x),c1(x),...,cK(x)|Df\nn,D1\nn,...DK\nn,x,x(i)\n\u22c6 )\n\u2248N(f(x)|\u00b5f\nK\n?\nn,const(x),vf\nn,const(x))\nk=1\nN(ck(x)|\u00b5k\nn,const(x),vk\nn,const(x)),\nwhere \u00b5f\nf(x) and ck(x) according to the right-hand-side of (7). To obtain these values, we first compute the predictive\nmeans and variances for f(x),fn+1,c1(x),...,cK(x) when the constraint factor in the right-hand-side of (7)\nis ignored.\nFor the case of f(x) and fn+1, we have that the two-dimensional vector f\u2032= (f(x),fn+1) follows a\nbivariate Gaussian distribution with mean vector mpred\nf\u2032\nn,const(x), vf\nn,const(x) and \u00b5k\nn,const(x) and vk\nn,const(x) are the marginal means and marginal variances of\nand covariance matrix Vpred\nf\u2032\n, that is,\n\u02c6\np(f(x)|f)\u02dc q(f,c1,...,cK)df1... dfndc1...dcK\n=\nN(f\u2032|mpred\nf\u2032\n,Vpred\nf\u2032\n),\nwhere\n[mpred\nf\u2032\n[Vpred\nf\u2032\n]1\n=\n=\nkf\nkf(x,x) \u2212 kf\nfinal(x)T[Kf\n\u22c6,\u22c6]\u22121mf,\nfinal(x)T?[Kf\n]1,1\n\u22c6,\u22c6]\u22121+ [Kf\n\u22c6,\u22c6]\u22121Vf[Kf\n\u22c6,\u22c6]\u22121?kf\nfinal(x)\nand mfand Vfare the posterior mean and posterior covariance matrix of f given by \u02dc q, kf\n(n + 1)-dimensional vector with the prior cros-covariances between f(x) and f(x1),...,f(xn),f(x(i)\nfinal(x) is the\n\u22c6 ) and\n7"},{"page":18,"text":"Kf\nhave that\n\u22c6,\u22c6is and (n + 1) \u00d7 (n + 1) matrix with the prior covariances between f(x1),...,f(xn),f(x(i)\n\u22c6 ). We also\n[mpred\nf\u2032\n[Vpred\nf\u2032\n]2\n=\n=\n[mf]n+1,\n[Vf]n+1,n+1.\n]2,2\nFinally, we have that\n[Vpred\nf\u2032\n]1,2\n=\nkf(x,x(i)\n\u22c6 ) \u2212 kf\nfinal(x)T?[Kf\n\u22c6,\u22c6]\u22121+ [Kf\n\u22c6,\u22c6]\u22121Vf[Kf\n\u22c6,\u22c6]\u22121?kf\nfinal(x(i)\n\u22c6 ),\nwhere kf\nf(x1),...,f(xn),f(x(i)\nNext, we compute the predictive means and variances for c1(x),...,cK(x) when the constraint factor in\nthe right-hand-side of (7) is ignored. In particular, for the k-th of these variables we have that\nfinal(x(i)\n\u22c6 ) is the (n + 1)-dimensional vector with the prior cros-covariances between f(x(i)\n\u22c6 ).\n\u22c6 ) and\n\u02c6\np(ck(x)|ck)\u02dc q(f,c1,...,ck)df dc1...dcK\n=\nN(ck(x)|mpred\nck\n,vpred\nck\n),\nwhere\nmpred\nck\nvpred\nck\n=\n=\nkk\nkk(x,x) \u2212 kk\nfinal(x)T[Kk\n\u22c6,\u22c6]\u22121mck,\nfinal(x)T?[Kk\n\u22c6,\u22c6]\u22121+ [Kk\n\u22c6,\u22c6]\u22121Vck[Kk\n\u22c6,\u22c6]\u22121?kk\nfinal(x)\nand kk\nKk\nfinal(xk) is an (n+1) vector with the cross-covariancesbetween ck(x) and ck(x1),...,ck(xn),ck(x(i)\n\u22c6,\u22c6is an (n+1)\u00d7(n+1) covariance matrix with the prior covariances between ck(x1),...,ck(xn),ck(x(i)\nAfter this, we approximate p(f(x),c1(x),...,cK(x)|Df\n\u22c6 ) and\n\u22c6 ).\nn,D1\n\u02c6??K\nn,...DK\nn,x,x(i)\n\u22c6 ) as\np(f(x),c1(x),...,cK(x)|Df\nn,D1\nn,...DK\nn,x,x(i)\n\u22c6 )\n\u2248\n1\nZ\n\uf8f1\n\uf8f3\n?\nk=1\n\u0398[ck(x)]\n?\n\u0398[fn+1\u2212 f(x)] +\n\uf8fc\n?\n1 \u2212\nK\n?\nk=1\n\u0398[ck(x)]\n??\n\uf8f2\nK\n?\njk=1\nN(ck(x)|mpred\nck\n,vpred\nck\n)\n\uf8fd\n\uf8feN(f\u2032|mpred\nf\u2032\n,Vpred\nf\u2032\n),\n(8)\nwhere Z is a normalization constant. We then approximate the right-hand-side of (8) using\np(f(x),c1(x),...,cK(x)|Df\nn,D1\nn,...DK\nn,x,x(i)\n\u22c6 )\n\u2248N(f(x)|\u00b5f\nK\n?\nn,const(x),vf\nn,const(x))\nk=1\nN(ck(x)|\u00b5k\nn,const(x),vk\nn,const(x)),\nwhere \u00b5f\nof f(x) and ck(x) according to the right-hand-side of (8). In particular, we fix\nn,const(x), vf\nn,const(x) and \u00b5k\nn,const(x) and vk\nn,const(x) are the marginal means and marginal variances\nvf\nn,const(x)=[Vpred\nf\u2032\n]1,1\u2212\u03b2\n]1+\ns(\u03b2 + \u03b1)\n[Vpred\nf\u2032\n?\n[Vpred\nf\u2032\n]1,1\u2212 [Vpred\n]1,1\n\u221as,\n\/\u221as and\nf\u2032\n]1,2\n?2\n,\n\u00b5f\nn,const(x)=[mpred\nf\u2032\n?\n]1,2\u2212 [Vpred\nf\u2032\n?\u03b2\nwhere s = [Vpred\nf\u2032\n]1,1+ [Vpred\nf\u2032\n]2,2\u2212 2[Vpred\nf\u2032\n]1,2, \u03b1 = [\u221211]mpred\n??K\nf\u2032\n\u03b2\n=\nk=1\u03a6[\u03b1k]\n?\n\u03c6(\u03b1)\nZ\n,\n8"},{"page":19,"text":"Z =\n??K\nk=1\u03a6[\u03b1k]\n?\n\u03a6[\u03b1] +\n?\nvk\n\u00b5k\n1 \u2212?K\nn,const(x)\nn,const(x)\nk=1\u03a6[\u03b1k]\n?\n?[vpred\nvk\nand \u03b1k= mpred\nck\n\/\n?\nvpred\nck\n. Finally, we also fix\n=\n=\nck\n]\u22121+ \u02dc a?\u22121,\nn,const(x)?[mpred\nck\n]\u22121[vpred\nck\n]\u22121+\u02dcb?,\nwhere\n\u02dc a\n=\n\u2212\n1\n?\n\uf8f1\nd2log Z\nd[mpred\nck\n]2+ vpred\n?\n\u03b1k+ \u03b2k\nck\n? ,\n\uf8fc\n\u02dcb\n=\u02dc a\n\uf8f2\n\u03c6(\u03b1j)\nZ\u03a6(\u03b1j)(Z \u2212 1),\n\u2212\u03b2k{\u03b1k+ \u03b2k}\nvpred\nck\n\uf8f3mpred\nck\n+\nvpred\nck\n\uf8fd\n\uf8fe,\n\u03b2k\n=\nd2logZ\nd[mpred\nck\n]2\n=\n.\nFinally, we approximate the entropy of p(yf,y1,...,yK|Df\nn,D1\nn,...DK\nK\n?\nn,x,x(i)\n\u22c6 ) as\nH\n?\np(yf,y1,...,yK|Df\nn,D1\nn,...DK\nn,x,x(i)\n\u22c6 )\n?\n\u2248\n0.5\n?\nlog(vf\nn,const(x) + \u03c32\nf) +\nk=1\nlog(vk\nn,const(x) + \u03c32\nk) + (K + 1)log(2\u03c0e)\n?\n.\nReferences\n[1] D. J. MacKay. Information-based objective functions for active data selection. Neural Computation,\n4(4):590\u2013604, 1992.\n[2] C. E. Rasmussen and C. K. Williams. Gaussian processes for machine learning. The MIT Press, 2006.\n[3] N. Houlsby, J. M. Hernandez-lobato, F. Huszar, and Z. Ghahramani. Collaborative Gaussian processes\nfor preference learning. In NIPS, pages 2096\u20132104. 2012.\n[4] T. P. Minka. A family of algorithms for approximate Bayesian inference. PhD thesis, Massachusetts\nInstitute of Technology, 2001.\n[5] Jos\u00e9 Miguel Hern\u00e1ndez-Lobato, Matthew W. Hoffman, Zoubin Ghahramani, Predictive Entropy Search\nfor Efficient Global Optimization of Black-box Functions, arXiv:1406.2541 [stat.ML]\n9"}],"widgetId":"rgw33_56aba2012c1a1"},"id":"rgw33_56aba2012c1a1","partials":[],"templateName":"publicliterature\/stubs\/PublicationText.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationText.html?publicationUid=272521912&hide=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationDetailAd":{"data":{"googleDfpSlot":null,"widgetId":"rgw34_56aba2012c1a1"},"id":"rgw34_56aba2012c1a1","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAd.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAd.html?publicationUid=272521912&slotId=336x280_Publications_ATF_Right&collapseSlotMode=never&fallbackContainerEnabled=1","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationRelations":null,"publicationRelationsReverse":null,"publicationUid":272521912,"showSignUpDialog":false,"selectNewSignUpDialog":false,"publicationQuestions":null,"publicationCitations":null,"publicationReviewPromo":null,"publicationUsedInReviews":null,"publicationPdfJsReader":null,"useFulltextOptimizedLayout":false,"publicationActions":null,"requestFulltextPromo":null,"currentUrl":"publication\/272521912_Predictive_Entropy_Search_for_Bayesian_Optimization_with_Unknown_Constraints","isLeaderboardAd":false,"enableStickyBox":null,"googleDfpSlotMobileBottom":null,"fullTextExitPopup":null,"showExitPopupDialog":false,"widgetId":"rgw2_56aba2012c1a1"},"id":"rgw2_56aba2012c1a1","partials":{"romeo_legal_notice":"publicliterature\/stubs\/partials\/romeo_legal_notice.html"},"templateName":"publicliterature\/stubs\/PublicPublicationDetails_NewLayout.html","templateExtensions":["generalHelpers"],"attrs":{"publicationUid":272521912},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicPublicationDetailsOld.html?publicationUid=272521912&isTestOldDesign=0","viewClass":"views.publicliterature.PublicPublicationDetailsOldView","yuiModules":["rg.views.publicliterature.PublicPublicationDetailsOldView"],"stylesheets":[],"_isYUI":true},"widgetId":"rgw1_56aba2012c1a1"},"id":"rgw1_56aba2012c1a1","partials":[],"templateName":"publicliterature\/stubs\/PublicPublicationDetails.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicPublicationDetails.html","viewClass":"views.publicliterature.PublicPublicationDetailsView","yuiModules":["rg.views.publicliterature.PublicPublicationDetailsView"],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"uaClass":"","headPrefix":[],"rootUrl":"https:\/\/www.researchgate.net\/","requestToken":"07few6ZTQjghhwRlN9ANPp2wUqeW6KTC12vzcpAcKhCEQQWCJ4dazoQaos6dkxxyZFjW7qgN1r4jbSGyUrPxfiZ6SCQEOJv3sfWpB72vhGsqv3kiWpFuG5I7ZzFbtal3KLTaBPCo7D1xxhALFPTO\/CYpjAiwFTbWlmG0\/tIQ\/ttsA0vXkhVVbFgYq5iuU\/R861kKbPICdOcc5mvJK50zUj\/4jzuACQu8\/JWArjLmwpwgACQGQTA41L4U7ipzB9WA37QoXQy4aq4ggCPQqj+\/9uELDUqEOU5pkS98ouxK3SQ=","faviconCdnUrl":"https:\/\/c5.rgstatic.net\/m\/2390829798215018\/images\/favicon.ico","headerOutput":"<noscript><\/noscript><link rel=\"canonical\" href=\"https:\/\/www.researchgate.net\/publication\/272521912_Predictive_Entropy_Search_for_Bayesian_Optimization_with_Unknown_Constraints\" \/>\n<link rel=\"dns-prefetch\" href=\"\/\/c5.rgstatic.net\" \/>\n<link rel=\"dns-prefetch\" href=\"\/\/i1.rgstatic.net\" \/>\n<meta property=\"twitter:card\" content=\"summary\" \/>\n<meta property=\"twitter:site\" content=\"@ResearchGate\" \/>\n<meta property=\"og:title\" content=\"Predictive Entropy Search for Bayesian Optimization with Unknown Constraints\" \/>\n<meta property=\"og:description\" content=\"Unknown constraints arise in many types of expensive black-box optimization\nproblems. Several methods have been proposed recently for performing Bayesian\noptimization with constraints, based on...\" \/>\n<meta property=\"og:site_name\" content=\"ResearchGate\" \/>\n<meta property=\"og:image\" content=\"https:\/\/i1.rgstatic.net\/publication\/272521912_Predictive_Entropy_Search_for_Bayesian_Optimization_with_Unknown_Constraints\/links\/54ed277b0cf28f3e65356839\/smallpreview.png\" \/>\n<meta property=\"og:url\" content=\"https:\/\/www.researchgate.net\/publication\/272521912_Predictive_Entropy_Search_for_Bayesian_Optimization_with_Unknown_Constraints\" \/>\n<meta property=\"rg:id\" content=\"PB:272521912\" \/>\n<meta name=\"DC.identifier\" scheme=\"DCTERMS.URI\" content=\"http:\/\/dx.doi.org\/\" \/>\n<meta name=\"gs_meta_revision\" content=\"1.1\" \/>\n<meta name=\"citation_title\" content=\"Predictive Entropy Search for Bayesian Optimization with Unknown Constraints\" \/>\n<meta name=\"citation_author\" content=\"Jos\u00e9 Miguel Hern\u00e1ndez-Lobato\" \/>\n<meta name=\"citation_author\" content=\"Michael A. Gelbart\" \/>\n<meta name=\"citation_author\" content=\"Matthew W. Hoffman\" \/>\n<meta name=\"citation_author\" content=\"Ryan P. Adams\" \/>\n<meta name=\"citation_author\" content=\"Zoubin Ghahramani\" \/>\n<meta name=\"citation_publication_date\" content=\"2015\/02\/18\" \/>\n<meta name=\"citation_abstract_html_url\" content=\"https:\/\/www.researchgate.net\/publication\/272521912_Predictive_Entropy_Search_for_Bayesian_Optimization_with_Unknown_Constraints\" \/>\n<meta name=\"citation_fulltext_html_url\" content=\"https:\/\/www.researchgate.net\/publication\/272521912_Predictive_Entropy_Search_for_Bayesian_Optimization_with_Unknown_Constraints\" \/>\n<meta name=\"viewport\" content=\"width=device-width,initial-scale=1\" \/>\n<link href=\"\/\/c5.rgstatic.net\/m\/22664197317151888\/styles\/rg.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/21004998181197492\/styles\/rg2.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<!--[if lt IE 9]><link href=\"\/\/c5.rgstatic.net\/m\/238176252723686\/styles\/ie.css\" type=\"text\/css\" rel=\"stylesheet\"\/><![endif]-->\n<link href=\"\/\/c5.rgstatic.net\/m\/217752362214895\/styles\/modules\/publicprofile.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<script src=\"\/\/c5.rgstatic.net\/m\/2321000301012716\/javascript\/vendor\/webfontloader\/webfontloader.js\" type=\"text\/javascript\"><\/script>\n <script>(function(i,s,o,g,r,a,m){i[\"GoogleAnalyticsObject\"]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,\"script\",\"\/\/www.google-analytics.com\/analytics.js\",\"ga\");\n ga(\"create\",\"UA-58591210-1\");ga(\"set\",\"anonymizeIp\",true);ga('set', 'dimension1', 'publication slurped');ga('set', 'dimension2', 'Article');ga('set', 'dimension3', 'Logged out');ga('set', 'dimension4', 'https');ga(\"send\",\"pageview\");<\/script>\n","webfont":"<noscript><\/noscript><script> WebFontConfig = { custom: { families: ['source_sans_pro_italic', 'source_sans_pro_bold', 'source_sans_pro', 'martel'], urls : ['\/\/c5.rgstatic.net\/m\/231392577336386\/styles\/fonts.css'] } }; WebFont.load(WebFontConfig); <\/script>\n","correlationId":"rgreq-110399e0-6e67-4236-a9d9-d0de2fdb66bb","accountId":null,"module":"publicliterature","action":"publicliterature.PublicPublicationDetails","page":"publicationDetail","product":"publications","backendTime":481,"continent":"Asia","stylesHome":"\/\/c5.rgstatic.net\/m\/","staticHost":"c5.rgstatic.net","useEarlyFlush":false,"longRunningRequestIdentifier":"LongRunningRequest.publicliterature.PublicPublicationDetails","longRunningRequestFp":"e9e5bbe1366c7ee8c8e41d02f793c884ac9be19b","widgetId":"rgw35_56aba2012c1a1"},"id":"rgw35_56aba2012c1a1","partials":[],"templateName":"application\/stubs\/StaticHeader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.StaticHeader.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){
            Y.rg.core.pagespeed.Monitoring.monitorPage("\/\/glassmoni.researchgate.net", "publicliterature.PublicPublicationDetails.run.html.loggedOut.get", "59de9668d07aeb77ab4de5f24d382b5d199d2437", "rgreq-110399e0-6e67-4236-a9d9-d0de2fdb66bb", "1f0e7f6d4fa4ff83046ca9a935e6de4f85ca8a73");
        
            Y.rg.core.pagespeed.Monitoring.monitorPage("\/\/glassmoni.researchgate.net", "publicationDetail.loggedOut", "ed1993d9e20f6cefa83edacaa24401a18c071aea", "rgreq-110399e0-6e67-4236-a9d9-d0de2fdb66bb", "1f0e7f6d4fa4ff83046ca9a935e6de4f85ca8a73");
        })();
(function(){Y.rg.createInitialWidget({"data":{"year":"2016","inlinePromo":null,"isAdmin":false,"contactUrl":"https:\/\/www.researchgate.net\/contact","aboutUsUrl":"https:\/\/www.researchgate.net\/about","widgetId":"rgw36_56aba2012c1a1"},"id":"rgw36_56aba2012c1a1","partials":[],"templateName":"application\/stubs\/DefaultFooter.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.DefaultFooter.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"headerLogin":{"data":{"urlAfterLogin":"publication\/272521912_Predictive_Entropy_Search_for_Bayesian_Optimization_with_Unknown_Constraints","requestToken":"AKdsK52Xcr3Sy2qPkkgIjuLQvNSRHyQ+doxU0Mh8ZdTKlAxI3ysf+Zx9WKwVbDSe\/XzdvAW6WgCwfR5Ir9gdUelLq9dXXzYMXG+\/sek8cLtrFwCwj+K51G5suEutyDDvCx9gprLiIFbKrfcn\/jIYT2F2T28WP31gcIKCjfExZEoSg7bb+8VUjEDruhj6U4Pp8qY2XLW3l7eryd20LaVFBkYTh5+O0ymoiBI0HD+HJdlpzGnQb28ct9YsVPmjk3HPRcUlmwSSKtDaaU4BpThcfNrbNoODhlzWYhvtkYns\/NY=","loginUrl":"https:\/\/www.researchgate.net\/application.Login.html","signupUrl":"https:\/\/www.researchgate.net\/signup.SignUp.html?ev=su_chnl_index&hdrsu=1&_sg=hTUb9lJKOXy4Gld5o8kk0VyfHZpq3DIR_yfToL69q4k_BuQN4xvCaYVeuvWxpfJs","encodedUrlAfterLogin":"cHVibGljYXRpb24vMjcyNTIxOTEyX1ByZWRpY3RpdmVfRW50cm9weV9TZWFyY2hfZm9yX0JheWVzaWFuX09wdGltaXphdGlvbl93aXRoX1Vua25vd25fQ29uc3RyYWludHM%3D","signupCallToAction":"Join for free","widgetId":"rgw38_56aba2012c1a1"},"id":"rgw38_56aba2012c1a1","partials":{"partial":"application\/stubs\/partials\/headerLoginDefault.html"},"templateName":"application\/stubs\/HeaderLogin.html","templateExtensions":[],"attrs":{"goal":"milestoneHeaderLoginSeen"},"widgetUrl":"https:\/\/www.researchgate.net\/application.HeaderLogin.html","viewClass":"views.application.HeaderLoginView","yuiModules":["rg.views.application.HeaderLoginView"],"stylesheets":[],"_isYUI":true},"cookieConsent":null,"logoSvgSrc":"https:\/\/c5.rgstatic.net\/m\/235107188705592\/images\/template\/brand-header-logo.svg","logoFallbackSrc":"https:\/\/c5.rgstatic.net\/m\/238113351022438\/images\/template\/brand-header-logo.png","widgetId":"rgw37_56aba2012c1a1"},"id":"rgw37_56aba2012c1a1","partials":{"schemaSocialProfiles":"application\/stubs\/partials\/schemaSocialProfiles.html"},"templateName":"application\/stubs\/HeaderLoggedOut.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.HeaderLoggedOut.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"logEvent":"su_banner","specialCopy":false,"widgetId":"rgw39_56aba2012c1a1"},"id":"rgw39_56aba2012c1a1","partials":[],"templateName":"application\/stubs\/LoggedOutBanner.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.LoggedOutBanner.html","viewClass":"views.application.LoggedOutBannerView","yuiModules":["rg.views.application.LoggedOutBannerView"],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.core.util.ParameterFilter.filter(["ev","cp","ch","ref","dbw","pli","loginT","uid","claimChannel","enrichId","enrichSource","utm_source","utm_medium","utm_campaign","el","ci"]);})();
});}); } else { throw 'YRG was not loaded when attaching widgets'; }</script><script> dataLayer = [{"pageCategory":"publication slurped","publicationType":"Article","eventCategory":"Publication page"}]; </script> <noscript><iframe src="//www.googletagmanager.com/ns.html?id=GTM-MKVKH7" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-MKVKH7');</script><script>(function(e){function n(n,t,o,a){"use strict";var i=e.document.createElement("link"),r=t||e.document.getElementsByTagName("script")[0],d=e.document.styleSheets;return i.rel="stylesheet",i.href=n,i.media="only x",a&&(i.onload=a),r.parentNode.insertBefore(i,r),i.onloadcssdefined=function(e){for(var t,o=0;d.length>o;o++)d[o].href&&d[o].href.indexOf(n)>-1&&(t=!0);t?e():setTimeout(function(){i.onloadcssdefined(e)})},i.onloadcssdefined(function(){i.media=o||"all"}),i}function t(e,n){e.onload=function(){e.onload=null,n&&n.call(e)},"isApplicationInstalled"in navigator&&"onloadcssdefined"in e&&e.onloadcssdefined(n)}var o=function(a,i){"use strict";if(a&&3===a.length){var r=e.Image,d=!(!document.createElementNS||!document.createElementNS("http://www.w3.org/2000/svg","svg").createSVGRect||!document.implementation.hasFeature("http://www.w3.org/TR/SVG11/feature#Image","1.1")||e.opera&&-1===navigator.userAgent.indexOf("Chrome")||-1!==navigator.userAgent.indexOf("Series40")),c=new r;c.onerror=function(){o.method="png",o.href=a[2],n(a[2])},c.onload=function(){var e=1===c.width&&1===c.height,r=a[e&&d?0:e?1:2];o.method=e&&d?"svg":e?"datapng":"png",o.href=r,t(n(r),i)},c.src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///ywAAAAAAQABAAACAUwAOw==",document.documentElement.className+=" grunticon"}};o.loadCSS=n,o.onloadCSS=t,e.grunticon=o})(this);grunticon(["https://c5.rgstatic.net/c/o1q2er/styles/icons/_header-ico.svg.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_header-ico.png.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_header-ico.fallback.scss"]);grunticon(["https://c5.rgstatic.net/c/o1q2er/styles/icons/_admin-ico.svg.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_admin-ico.png.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_admin-ico.fallback.scss"]);grunticon(["https://c5.rgstatic.net/c/o1q2er/styles/icons/_ico.svg.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_ico.png.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_ico.fallback.scss"]);</script></body>
</html>
