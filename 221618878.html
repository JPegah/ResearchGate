<!DOCTYPE html> <html lang="en" class="" id="rgw44_56ab9f6060214"> <head > <meta charset="utf-8"/> <meta http-equiv="content-type" content="text/html; charset=UTF-8"/> <meta name="Rg-Request-Token" id="Rg-Request-Token" content="T1vG3ASoTpAp/mmFJSSSDa5rjwl7ftvGYJsIkk7HfnKsvMgDfKfYBmYW+oj+iBl0fID3CX4oc+PPPVlb4BZ017s/UnwgOIIIEHMRixPkut3mc1I8GEpXSHOvBDfCKWO8iOinMWU2x3DlcKuQJ0qDuBln9aYkIYyWI2nCGWAFfWO0Q9nvpw2gAaGW/YMHReOeFgQ4drie00WPtgb6PvZrGKwRkdYaK0Zj+Nb3HzFe8bQaTt7xsffwCHyiGtN3p179xH9Ae/YA0Y/KY2evyBUMlw5AOvXPkbP6IR3tWmu9iZA="/> <meta http-equiv="expires" content="0"/> <link rel="apple-touch-icon" sizes="57x57" href="https://www.researchgate.net/apple-touch-icon-57x57.png"> <link rel="apple-touch-icon" sizes="60x60" href="https://www.researchgate.net/apple-touch-icon-60x60.png"> <link rel="apple-touch-icon" sizes="72x72" href="https://www.researchgate.net/apple-touch-icon-72x72.png"> <link rel="apple-touch-icon" sizes="76x76" href="https://www.researchgate.net/apple-touch-icon-76x76.png"> <link rel="apple-touch-icon" sizes="114x114" href="https://www.researchgate.net/apple-touch-icon-114x114.png"> <link rel="apple-touch-icon" sizes="120x120" href="https://www.researchgate.net/apple-touch-icon-120x120.png"> <link rel="apple-touch-icon" sizes="144x144" href="https://www.researchgate.net/apple-touch-icon-144x144.png"> <link rel="apple-touch-icon" sizes="152x152" href="https://www.researchgate.net/apple-touch-icon-152x152.png"> <link rel="apple-touch-icon" sizes="180x180" href="https://www.researchgate.net/apple-touch-icon-180x180.png"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-32x32.png" sizes="32x32"> <link rel="icon" type="image/png" href="https://www.researchgate.net/android-chrome-192x192.png" sizes="192x192"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-96x96.png" sizes="96x96"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-16x16.png" sizes="16x16"> <link rel="shortcut icon" type="image/x-icon" href="https://c5.rgstatic.net/m/2390829798215018/images/favicon.ico"/> <link rel="manifest" href="https://www.researchgate.net/manifest.json"> <meta name="msapplication-TileColor" content="#da532c"> <meta name="msapplication-TileImage" content="https://www.researchgate.net/mstile-144x144.png"> <meta name="theme-color" content="#444444"> <link rel="search" type="application/opensearchdescription+xml" title="ResearchGate search" href="https://www.researchgate.net/application.DownloadOpenSearchPlugin.html"/> <link rel="meta" type="application/rdf+xml" title="ICRA labels" href="https://www.researchgate.net/application.DownloadLabels.html"/> <link rel="http://oexchange.org/spec/0.8/rel/related-target" type="application/xrd+xml" href="https://www.researchgate.net/application.DownloadOExchange.html"/> <base href="https://www.researchgate.net/"/> <script>
    var rgConfig = {
        correlationId: "rgreq-323eba07-67d5-4b66-888c-4a74f0d5e95e",
        accountId: "",
        module: "publicliterature",
        action: "publicliterature.PublicPublicationDetails",
        page: "publicationDetail",
        product: "publications",
        continent: "Asia",
        stylesHome: "//c5.rgstatic.net/m/",
        staticHost: "c5.rgstatic.net",
        longRunningRequestIdentifier: "LongRunningRequest.publicliterature.PublicPublicationDetails",
        longRunningRequestFp: "e9e5bbe1366c7ee8c8e41d02f793c884ac9be19b"
    };
    window.rootUrl = "https://www.researchgate.net/";
</script> <link rel="canonical" href="https://www.researchgate.net/publication/221618878_Non-Parametric_Bayesian_Dictionary_Learning_for_Sparse_Image_Representations" />
<link rel="dns-prefetch" href="//c5.rgstatic.net" />
<link rel="dns-prefetch" href="//i1.rgstatic.net" />
<meta property="twitter:card" content="summary" />
<meta property="twitter:site" content="@ResearchGate" />
<meta property="og:title" content="Non-Parametric Bayesian Dictionary Learning for Sparse Image Representations." />
<meta property="og:description" content="Non-parametric Bayesian techniques are considered for learning dictionaries for sparse image representations, with applications in denoising, inpainting and com- pressive sensing (CS). The beta..." />
<meta property="og:site_name" content="ResearchGate" />
<meta property="og:image" content="https://i1.rgstatic.net/publication/221618878_Non-Parametric_Bayesian_Dictionary_Learning_for_Sparse_Image_Representations/links/0deec528e576781722000000/smallpreview.png" />
<meta property="og:url" content="https://www.researchgate.net/publication/221618878_Non-Parametric_Bayesian_Dictionary_Learning_for_Sparse_Image_Representations" />
<meta property="rg:id" content="PB:221618878" />
<meta name="DC.identifier" scheme="DCTERMS.URI" content="http://dx.doi.org/" />
<meta name="gs_meta_revision" content="1.1" />
<meta name="citation_title" content="Non-Parametric Bayesian Dictionary Learning for Sparse Image Representations." />
<meta name="citation_author" content="Mingyuan Zhou" />
<meta name="citation_author" content="Haojun Chen" />
<meta name="citation_author" content="John William Paisley" />
<meta name="citation_author" content="Lu Ren" />
<meta name="citation_author" content="Guillermo Sapiro" />
<meta name="citation_author" content="Lawrence Carin" />
<meta name="citation_conference_title" content="Advances in Neural Information Processing Systems 22: 23rd Annual Conference on Neural Information Processing Systems 2009. Proceedings of a meeting held 7-10 December 2009, Vancouver, British Columbia, Canada." />
<meta name="citation_publication_date" content="2009/01/01" />
<meta name="citation_firstpage" content="2295" />
<meta name="citation_lastpage" content="2303" />
<meta name="citation_pdf_url" content="https://www.researchgate.net/profile/Mingyuan_Zhou/publication/221618878_Non-Parametric_Bayesian_Dictionary_Learning_for_Sparse_Image_Representations/links/0deec528e576781722000000.pdf" />
<meta name="citation_abstract_html_url" content="https://www.researchgate.net/publication/221618878_Non-Parametric_Bayesian_Dictionary_Learning_for_Sparse_Image_Representations" />
<meta name="citation_fulltext_html_url" content="https://www.researchgate.net/publication/221618878_Non-Parametric_Bayesian_Dictionary_Learning_for_Sparse_Image_Representations" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<link href="//c5.rgstatic.net/m/22664197317151888/styles/rg.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/21004998181197492/styles/rg2.css" type="text/css" rel="stylesheet"/>
<!--[if lt IE 9]><link href="//c5.rgstatic.net/m/238176252723686/styles/ie.css" type="text/css" rel="stylesheet"/><![endif]-->
<link href="//c5.rgstatic.net/m/217752362214895/styles/modules/publicprofile.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/21993347442549/styles/pow/publicliterature/FollowPublicationPromo.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/282514599719602/styles/pow/application/PdfJsReader.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/23819663151220/styles/pow/publicliterature/PublicationInlineReader.css" type="text/css" rel="stylesheet"/>
<script src="//c5.rgstatic.net/m/2321000301012716/javascript/vendor/webfontloader/webfontloader.js" type="text/javascript"></script>
 <script>(function(i,s,o,g,r,a,m){i["GoogleAnalyticsObject"]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,"script","//www.google-analytics.com/analytics.js","ga");
 ga("create","UA-58591210-1");ga("set","anonymizeIp",true);ga('set', 'dimension1', 'publication full-text');ga('set', 'dimension2', 'Conference Paper');ga('set', 'dimension3', 'Logged out');ga('set', 'dimension4', 'https');ga("send","pageview");</script>
  <script> WebFontConfig = { custom: { families: ['source_sans_pro_italic', 'source_sans_pro_bold', 'source_sans_pro', 'martel'], urls : ['//c5.rgstatic.net/m/231392577336386/styles/fonts.css'] } }; WebFont.load(WebFontConfig); </script><noscript></noscript>

<title>Non-Parametric Bayesian Dictionary Learning for Sparse Image Representations. (PDF Download Available)</title>
<meta name="description" content="Official Full-Text Publication: Non-Parametric Bayesian Dictionary Learning for Sparse Image Representations. on ResearchGate, the professional network for scientists."/>
<meta name="keywords" content="scientific network, scientific platform, scientific community, research partner, research collaboration, journal articles, international collaboration, find researcher, lifescience researcher, interdisciplinary research, research collaboration"/>
</head>
<body class="use-svg-icons logged-out">
<div id="page-container">
<script type="text/javascript">var googletag = googletag || {}; googletag.cmd = googletag.cmd || [];
(function() { var gads = document.createElement("script"); gads.async = true; gads.type = "text/javascript"; var useSSL = "https:" == document.location.protocol; gads.src = (useSSL ? "https:" : "http:") + "//www.googletagservices.com/tag/js/gpt.js"; var node =document.getElementsByTagName("script")[0]; node.parentNode.insertBefore(gads, node); })();</script><div id="main" class="logged-out-header-support">
<div id="content" class="">

<noscript>
<div class="c-box-warning full-width-element" style="text-align: center; ">
    <div style="margin: auto; padding:10px;" class="container">
        <b>For full functionality of ResearchGate it is necessary to enable JavaScript.
            Here are the <a href="http://www.enable-javascript.com/" rel="nofollow" target="_blank">
                instructions how to enable JavaScript in your web browser</a>.</b>
    </div>
</div>
</noscript>

<div id="rgw1_56ab9f6060214" itemscope itemtype="http://schema.org/ScholarlyArticle"><div class="publication-wrapper publication-wrapper-onecol" id="rgw2_56ab9f6060214" itemscope itemtype="http://schema.org/ScholarlyArticle"> <div class="c-col-content"> <div class="c-content"> <div class="clearfix">  <div class="publication-header"> <div id="rgw5_56ab9f6060214">  <div class="type-label"> Conference Paper   </div> <span class="Z3988" title="ctx_ver=Z39.88-2004&rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&rfr_id=info%3Asid%2Fresearchgate.net%3Aresearchgate&rft.atitle=Non-Parametric%20Bayesian%20Dictionary%20Learning%20for%20Sparse%20Image%20Representations.&rft.date=2009&rft.pages=2295-2303&rft.au=Mingyuan%20Zhou%2CHaojun%20Chen%2CJohn%20William%20Paisley%2CLu%20Ren%2CGuillermo%20Sapiro%2CLawrence%20Carin&rft.genre=inProceedings"></span> <h1 class="pub-title" itemprop="name">Non-Parametric Bayesian Dictionary Learning for Sparse Image Representations.</h1> <meta itemprop="headline" content="Non-Parametric Bayesian Dictionary Learning for Sparse Image Representations.">  <meta itemprop="image" content="https://i1.rgstatic.net/publication/221618878_Non-Parametric_Bayesian_Dictionary_Learning_for_Sparse_Image_Representations/links/0deec528e576781722000000/smallpreview.png">  <div id="rgw7_56ab9f6060214" class="publication-detail-author-list"> <div> <ul class="clearfix js-people-list">  <li id="rgw8_56ab9f6060214" itemprop="author" itemscope itemtype="http://schema.org/Person"> <a itemprop="sameAs" href="profile/Mingyuan_Zhou" class="pub-detail-item account-item"> <div class="indent-left"> <div class="people-img"> <img  src="https://c5.rgstatic.net/m/2671872220764/images/template/default/profile/profile_default_m.jpg" title="Mingyuan Zhou" alt="Mingyuan Zhou" height="20px" width="20px" style="height: 20px;"/> </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Mingyuan Zhou</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item  remove-action-indent   " id="rgw9_56ab9f6060214" data-account-key="Mingyuan_Zhou">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="profile/Mingyuan_Zhou"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="Mingyuan Zhou" alt="Mingyuan Zhou" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">     </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="profile/Mingyuan_Zhou" class="display-name">Mingyuan Zhou</a>    </h5> <div class="truncate-single-line meta">   <a class="meta ga-top-coauthor-institution" href="institution/Duke_University" title="Duke University">Duke University</a>     </div>  <a href="javascript:" class="btn btn-promote btn-large people-item-contact-author js-contact-author">Message author</a>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>  <li id="rgw10_56ab9f6060214"> <a href="researcher/63063915_Haojun_Chen" class="pub-detail-item author-item" itemprop="author" itemscope itemtype="http://schema.org/Person"> <div class="indent-left"> <div class="people-img">  <img src="https://c5.rgstatic.net/m/2951093203564/images/template/default/profile/profile_default_s.jpg" title="Haojun Chen" alt="Haojun Chen" height="20px" width="20px" style="height: 20px;"/>  </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Haojun Chen</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item   not-claimed " id="rgw11_56ab9f6060214">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="researcher/63063915_Haojun_Chen"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="Haojun Chen" alt="Haojun Chen" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">       </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="researcher/63063915_Haojun_Chen" class="display-name">Haojun Chen</a>    </h5> <div class="truncate-single-line meta">   </div>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>  <li id="rgw12_56ab9f6060214"> <a href="researcher/70672430_John_William_Paisley" class="pub-detail-item author-item" itemprop="author" itemscope itemtype="http://schema.org/Person"> <div class="indent-left"> <div class="people-img">  <img src="https://c5.rgstatic.net/m/2951093203564/images/template/default/profile/profile_default_s.jpg" title="John William Paisley" alt="John William Paisley" height="20px" width="20px" style="height: 20px;"/>  </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">John William Paisley</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item   not-claimed " id="rgw13_56ab9f6060214">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="researcher/70672430_John_William_Paisley"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="John William Paisley" alt="John William Paisley" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">       </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="researcher/70672430_John_William_Paisley" class="display-name">John William Paisley</a>    </h5> <div class="truncate-single-line meta">   </div>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>  <li id="rgw14_56ab9f6060214" itemprop="author" itemscope itemtype="http://schema.org/Person"> <a itemprop="sameAs" href="profile/Lu_Ren4" class="pub-detail-item account-item"> <div class="indent-left"> <div class="people-img"> <img  src="https://i1.rgstatic.net/ii/profile.image/AS%3A289644269850626%401446067983946_m/Lu_Ren4.png" title="Lu Ren" alt="Lu Ren" height="20px" width="20px" style="height: 20px;"/> </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Lu Ren</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item  remove-action-indent   " id="rgw15_56ab9f6060214" data-account-key="Lu_Ren4">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="profile/Lu_Ren4"> <img class="lazyload" data-src="https://i1.rgstatic.net/ii/profile.image/AS%3A289644269850626%401446067983946_l/Lu_Ren4.png" title="Lu Ren" alt="Lu Ren" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">     </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="profile/Lu_Ren4" class="display-name">Lu Ren</a>    </h5> <div class="truncate-single-line meta">   <a class="meta ga-top-coauthor-institution" href="institution/Apple_Inc" title="Apple Inc.">Apple Inc.</a>     </div>  <a href="javascript:" class="btn btn-promote btn-large people-item-contact-author js-contact-author">Message author</a>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>  <li id="rgw16_56ab9f6060214"> <a href="researcher/7868797_Guillermo_Sapiro" class="pub-detail-item author-item" itemprop="author" itemscope itemtype="http://schema.org/Person"> <div class="indent-left"> <div class="people-img">  <img src="https://c5.rgstatic.net/m/2951093203564/images/template/default/profile/profile_default_s.jpg" title="Guillermo Sapiro" alt="Guillermo Sapiro" height="20px" width="20px" style="height: 20px;"/>  </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Guillermo Sapiro</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item   not-claimed " id="rgw17_56ab9f6060214">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="researcher/7868797_Guillermo_Sapiro"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="Guillermo Sapiro" alt="Guillermo Sapiro" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">       </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="researcher/7868797_Guillermo_Sapiro" class="display-name">Guillermo Sapiro</a>    </h5> <div class="truncate-single-line meta">   </div>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>  <li id="rgw18_56ab9f6060214"> <a href="researcher/10135830_Lawrence_Carin" class="pub-detail-item author-item" itemprop="author" itemscope itemtype="http://schema.org/Person"> <div class="indent-left"> <div class="people-img">  <img src="https://c5.rgstatic.net/m/2951093203564/images/template/default/profile/profile_default_s.jpg" title="Lawrence Carin" alt="Lawrence Carin" height="20px" width="20px" style="height: 20px;"/>  </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Lawrence Carin</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item   not-claimed " id="rgw19_56ab9f6060214">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="researcher/10135830_Lawrence_Carin"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="Lawrence Carin" alt="Lawrence Carin" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">       </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="researcher/10135830_Lawrence_Carin" class="display-name">Lawrence Carin</a>    </h5> <div class="truncate-single-line meta">   </div>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>   </ul> <div class="js-loading"></div>  </div> </div> <div class="pub-details js-pub-details">         Conference: Advances in Neural Information Processing Systems 22: 23rd Annual Conference on Neural Information Processing Systems 2009. Proceedings of a meeting held 7-10 December 2009, Vancouver, British Columbia, Canada.      <div class="pub-source"> Source: <a href="http://dblp.uni-trier.de/db/conf/nips/nips2009.html#ZhouCPRSC09" rel="nofollow">DBLP</a> </div>  </div> <div id="rgw20_56ab9f6060214" class="pub-abstract">  <div class="clearfix">   <div style="max-height: 54px;" class="js-expander-container js-expander-collapsed">  <p itemprop="description"> <strong>ABSTRACT</strong> <div>Non-parametric Bayesian techniques are considered for learning dictionaries for sparse image representations, with applications in denoising, inpainting and com- pressive sensing (CS). The beta process is employed as a prior for learning the dictionary, and this non-parametric method naturally infers an appropriate dic- tionary size. The Dirichlet process and a probit stick-breaking process are also considered to exploit structure within an image. The proposed method can learn a sparse dictionary in situ; training images may be exploited if available, but they are not required. Further, the noise variance need not be known, and can be non- stationary. Another virtue of the proposed method is that sequential inference can be readily employed, thereby allowing scaling to large images. Several example results are presented, using both Gibbs and variational Bayesian inference, with comparisons to other state-of-the-art approaches.</div> </p>  </div>  </div>   </div>      <div class="action-container"> <div id="rgw21_56ab9f6060214" class="follow-publication-promo"> <table> <tr> <td class="follow-publication-promo-text-cell"> <p>Get notified about updates to this publication</p> <a class="btn btn-large btn-promote js-follow-publication ga-follow-publication-new-promo">Follow publication</a> </td> <td> <div class="follow-publication-publication-image"></div> </td> </tr> </table> </div>  <div class="clear"></div> <div class="share-dialog-container" style="display: none;">  </div> </div> </div> <div style="margin-left: -20px; margin-right: -20px;">  </div> </div>  <div class="publication-detail-dfp-container rf"> <div id="rgw35_56ab9f6060214">  </div> </div>  </div>  <div class="clearfix"> <div class="pdf-js-container clearfix " id="rgw36_56ab9f6060214">  <div class="pdf-js-header js-sticky-header clear">  <a class="blue-link js-download rf btn btn-promote" href="https://www.researchgate.net/profile/Mingyuan_Zhou/publication/221618878_Non-Parametric_Bayesian_Dictionary_Learning_for_Sparse_Image_Representations/links/0deec528e576781722000000.pdf?inViewer=0&amp;pdfJsDownload=0&amp;origin=publication_detail">Download full-text</a>  <h3>Full-text</h3> <span class="publication-info">  <span class="js-doi-container" style="display: none;"> DOI: <span class="js-doi"></span> &middot; </span> Available from: <a class="js-name" href="profile/Mingyuan_Zhou">Mingyuan Zhou</a>   </span>  </div>  <div class="social-share-container"><div id="rgw38_56ab9f6060214" class="social-share js-social-share"> <div class="social-share-heading">Share</div>  <a id="rgw39_56ab9f6060214" href="javascript:" title="Share on Facebook" class="link-nostyle js-share-item share-icon "  data-url="http://www.facebook.com/share.php?u={{url}}{{#title}}&amp;t={{title}}{{/title}}" data-width="600" data-height="350" data-name="Facebook"> <span class="share-icon ico-share-facebook-round reset-background ga-share-blog-facebook"></span> </a>  <a id="rgw40_56ab9f6060214" href="javascript:" title="Share on Twitter" class="link-nostyle js-share-item share-icon "  data-url="http://twitter.com/intent/tweet?text={{#title}}{{title}}: {{/title}}{{url}}&amp;via=researchgate" data-width="600" data-height="350" data-name="Twitter"> <span class="share-icon ico-share-twitter-round reset-background ga-share-blog-twitter"></span> </a>  <a id="rgw41_56ab9f6060214" href="javascript:" title="Share on Google+" class="link-nostyle js-share-item share-icon "  data-url="https://plus.google.com/share?url={{url}}" data-width="600" data-height="600" data-name="Google+"> <span class="share-icon ico-share-gplus-round reset-background ga-share-blog-gplus"></span> </a>  <a id="rgw42_56ab9f6060214" href="javascript:" title="Share on LinkedIn" class="link-nostyle js-share-item share-icon "  data-url="http://www.linkedin.com/shareArticle?mini=true&amp;url={{url}}{{#title}}&amp;title={{title}}{{/title}}&amp;source=ResearchGate" data-width="520" data-height="570" data-name="LinkedIn"> <span class="share-icon ico-share-linkedin-round reset-background ga-share-blog-linkedin"></span> </a>  <a id="rgw43_56ab9f6060214" href="javascript:" title="Share on Reddit" class="link-nostyle js-share-item share-icon "  data-url="https://www.reddit.com/submit?url={{url}}{{#title}}&amp;title={{title}}{{/title}}" data-width="600" data-height="600" data-name="Reddit"> <span class="share-icon ico-share-reddit reset-background ga-share-blog-reddit"></span> </a>  </div></div>    <iframe id="rgw37_56ab9f6060214" src="https://www.researchgate.net/c/o1q2er/javascript/lib/pdfjs/web/viewer.html?file=https%3A%2F%2Fwww.researchgate.net%2Fprofile%2FMingyuan_Zhou%2Fpublication%2F221618878_Non-Parametric_Bayesian_Dictionary_Learning_for_Sparse_Image_Representations%2Flinks%2F0deec528e576781722000000.pdf%3FinViewer%3D1%26pdfJsDownload%3D1%26origin%3Dpublication_detail" allowfullscreen frameborder="0" style="width: 100%; height: 100%; box-sizing: border-box;"></iframe>    </div> <noscript> <div id="rgw34_56ab9f6060214"  itemprop="articleBody">  <p>Page 1</p> <p>Non-Parametric Bayesian Dictionary Learning for<br />Sparse Image Representations<br />1Mingyuan Zhou1Haojun Chen1John Paisley1Lu Ren2Guillermo Sapiro1Lawrence Carin<br />1Department of Electrical and Computer Engineering, Duke University, Durham, NC 27708<br />2Department of Electrical and Computer Engineering, University of Minnesota, Minneapolis, MN 55455<br />{mz1,hc44,jwp4,lr,lcarin}@ee.duke.edu, {guille}@ece.umn.edu<br />Abstract<br />Non-parametric Bayesian techniques are considered for learning dictionaries for<br />sparse image representations, with applications in denoising, inpainting and com-<br />pressive sensing (CS). The beta process is employed as a prior for learning the<br />dictionary, and this non-parametric method naturally infers an appropriate dic-<br />tionary size. The Dirichlet process and a probit stick-breaking process are also<br />considered to exploit structure within an image. The proposed method can learn<br />a sparse dictionary in situ; training images may be exploited if available, but they<br />are not required. Further, the noise variance need not be known, and can be non-<br />stationary. Another virtue of the proposed method is that sequential inference can<br />be readily employed, thereby allowing scaling to large images. Several example<br />results are presented, using both Gibbs and variational Bayesian inference, with<br />comparisons to other state-of-the-art approaches.<br />1 Introduction<br />There has been significant recent interest in sparse signal expansions in several settings. For ex-<br />ample, such algorithms as the support vector machine (SVM) [1], the relevance vector machine<br />(RVM) [2], Lasso [3] and many others have been developed for sparse regression (and classifica-<br />tion). A sparse representation has several advantages, including the fact that it encourages a simple<br />model, and therefore over-training is often avoided. The inferred sparse coefficients also often have<br />biological/physical meaning, of interest for model interpretation [4].<br />Of relevance for the current paper, there has recently been significant interest in sparse representa-<br />tions in the context of denoising, inpainting [5–10], compressive sensing (CS) [11,12], and classifi-<br />cation [13]. All of these applications exploit the fact that most images may be sparsely represented<br />in an appropriate dictionary. Most of the CS literature assumes “off-the-shelf” wavelet and DCT<br />bases/dictionaries [14], but recent denoising and inpainting research has demonstrated the signif-<br />icant advantages of learning an often over-complete dictionary matched to the signals of interest<br />(e.g., images) [5–10, 12, 15]. The purpose of this paper is to perform dictionary learning using<br />new non-parametric Bayesian technology [16,17], that offers several advantages not found in earlier<br />approaches, which have generally sought point estimates.<br />This paper makes four main contributions:<br />• The dictionary is learned using a beta process construction [16,17], and therefore the number of<br />dictionary elements and their relative importance may be inferred non-parametrically.<br />• For the denoising and inpainting applications, we do not have to assume a priori knowledge of the<br />noise variance (it is inferred within the inversion). The noise variance can also be non-stationary.<br />• The spatial inter-relationships between different components in images are exploited by use of the<br />Dirichlet process [18] and a probit stick-breaking process [19].<br />• Using learned dictionaries, inferred off-line or in situ, the proposed approach yields CS perfor-<br />1</p>  <p>Page 2</p> <p>mance that is markedly better than existing standard CS methods as applied to imagery.<br />2<br />In traditional sparse coding tasks, one considers a signal x ∈ ?nand a fixed dictionary D =<br />(d1,d2,...,dM) where each dm∈ ?n. We wish to impose that any x ∈ ?nmay be represented<br />approximately as ˆ x = Dα, where α ∈ ?Mis sparse, and our objective is to also minimize the ?2<br />error ?ˆ x−x?2. With a proper dictionary, a sparse α often manifests robustness to noise (the model<br />doesn’t fit noise well), and the model also yields effective inference of α even when x is partially<br />or indirectly observed via a small number of measurements (of interest for inpainting, interpolation<br />and compressive sensing [5,7]). To the authors’ knowledge, all previous work in this direction has<br />been performed in the following manner: (i) if D is given, the sparse vector α is estimated via a<br />point estimate (without a posterior distribution), typically based on orthogonal matching pursuits<br />(OMP), basis pursuits or related methods, for which the stopping criteria is defined by assuming<br />knowledge (or off-line estimation) of the noise variance or the sparsity level of α; and (ii) when<br />the dictionary D is to be learned, the dictionary size M must be set a priori, and a point estimate<br />is achieved for D (in practice one may infer M via cross-validation, with this step avoided in the<br />proposed method). In many applications one may not know the noise variance or an appropriate<br />sparsity level of α; further, one may be interested in the confidence of the estimate (e.g., “error<br />bars” on the estimate of α). To address these goals, we propose development of a non-parametric<br />Bayesian formulation to this problem, in terms of the beta process, this allowing one to infer the<br />appropriate values of M and ?α?0(sparsity level) jointly, also manifesting a full posterior density<br />function on the learned D and the inferred α (for a particular x), yielding a measure of confidence<br />in the inversion. As discussed further below, the non-parametric Bayesian formulation also allows<br />one to relax other assumptions that have been made in the field of learning D and α for denoising,<br />inpainting and compressive sensing. Further, the addition of other goals are readily addressed within<br />the non-parametric Bayesian paradigm, e.g. designing D for joint compression and classification.<br />Dictionary Learning with a Beta Process<br />2.1Beta process formulation<br />We desire the model x = Dα+?, where x ∈ ?nand D ∈ ?n×M, and we wish to learn D and in so<br />doing infer M. Toward this end, we consider a dictionary D ∈ ?n×K, with K → ∞; by inferring<br />the number of columns of D that are required for accurate representation of x, the appropriate<br />value of M is implicitly inferred (work has been considered in [20,21] for the related but distinct<br />application of factor analysis). We wish to also impose that α ∈ ?Kis sparse, and therefore only<br />a small fraction of the columns of D are used for representation of a given x. Specifically, assume<br />that we have a training set D = {xi,yi}i=1,N, where xi ∈ ?nand yi ∈ {1,2,...,Nc}, where<br />Nc≥ 2 represents the number of classes from which the data arise; when learning the dictionary we<br />ignore the class labels yi, and later discuss how they may be considered in the learning process.<br />The two-parameter beta process (BP) was developed in [17], to which the reader is referred for<br />further details; we here only provide those details of relevance for the current application. The BP<br />with parameters a &gt; 0 and b &gt; 0, and base measure H0, is represented as BP(a,b,H0), and a draw<br />H ∼ BP(a,b,H0) may be represented as<br />K<br />?<br />with this a valid measure as K → ∞. The expression δψk(ψ) equals one if ψ = ψkand is zero<br />otherwise. Therefore, H(ψ) represents a vector of K probabilities, with each associated with a<br />respective atom ψk. In the limit K → ∞, H(ψ) corresponds to an infinite-dimensional vector of<br />probabilities, and each probability has an associated atom ψkdrawn i.i.d. from H0.<br />Using H(ψ), we may now draw N binary vectors, the ith of which is denoted zi ∈ {0,1}K,<br />and the kth component of ziis drawn zik ∼ Bernoulli(πk). These N binary column vectors are<br />used to constitute a matrix Z ∈ {0,1}K×N, with ith column corresponding to zi; the kth row of<br />Z is associated with atom ψk, drawn as discussed above. For our problem the atoms ψk∈ ?n<br />will correspond to candidate members of our dictionary D, and the binary vector zidefines which<br />members of the dictionary are used to represent sample xi∈ D.<br />Let Ψ = (ψ1,ψ2,...,ψK), and we may consider the limit K → ∞. A naive form of our model,<br />for representation of sample xi∈ D, is xi= Ψzi+ ?i. However, this is highly restrictive, as it<br />H(ψ) =<br />k=1<br />πkδψk(ψ)<br />πk∼ Beta(a/K,b(K − 1)/K)<br />ψk∼ H0<br />(1)<br />2</p>  <p>Page 3</p> <p>imposes that the coefficients of the dictionary expansion must be binary. To address this, we draw<br />weights wi∼ N(0,γ−1<br />are now αi = zi◦ wi, and xi = Ψαi+ ?i, where ◦ represents the Hadamard (element-wise)<br />multiplication of two vectors. Note that, by construction, α is sparse; this imposition of sparseness<br />is distinct from the widely used Laplace shrinkage prior [3], which imposes that many coefficients<br />are small but not necessarily exactly zero.<br />For simplicity we assume that the dictionary elements, defined by the atoms ψk, are drawn from a<br />multivariate Gaussian base H0, and the components of the error vectors ?iare drawn i.i.d. from a<br />zero-mean Gaussian. The hierarchical form of the model may now be expressed as<br />wIK), where γwis the precision or inverse variance; the dictionary weights<br />xi<br />Ψ<br />=<br />=<br />∼<br />Ψαi+ ?i,<br />(ψ1,ψ2,...,ψK) ,<br />N(0,γ−1<br />K<br />?<br />αi= zi◦ wi<br />ψk∼ N(0,n−1In)<br />?i∼ N(0,γ−1<br />wi<br />wIK) ,<br />? In)<br />zi<br />∼<br />k=1<br />Bernoulli(πk) ,πk∼ Beta(a/K,b(K − 1)/K)<br />(2)<br />Non-informative gamma hyper-priors are typically placed on γwand γ?. Consecutive elements in<br />the above hierarchical model are in the conjugate exponential family, and therefore inference may<br />be implemented via a variational Bayesian [22] or Gibbs-sampling analysis, with analytic update<br />equations (all inference update equations, and the software, will be referenced in a technical report,<br />if the paper is accepted). After performing such inference, we retain those columns of Ψ that are<br />used in the representation of the data in D, thereby inferring D and hence M.<br />To impose our desire that the vector of dictionary weights α is sparse, one may adjust the parameters<br />a and b. Particularly, as discussed in [17], in the limit K → ∞, the number of elements of zithat<br />are non-zero is a random variable drawn from Poisson(a/b). In Section 3.1 we discuss the fact that<br />these parameters are in general non-informative and the sparsity is intrinsic to the data.<br />2.2Accounting for a classification task<br />There are problems for which it is desired that x is sparsely rendered in D, and the associated<br />weight vector α may be employed for other purposes beyond representation. For example, one may<br />perform a classification task based on α. If one is interested in joint compression and classification,<br />both goals should be accounted for when designing D. For simplicity, we assume that the number<br />of classes is NC= 2 (binary classification), with this readily extended [23] to NC&gt; 2.<br />Following [9], we may define a linear or bilinear classifier based on the sparse weights α and the<br />associated data x (in the bilinear case), with this here implemented in the form of a probit classifier.<br />We focus on the linear model, as it is simpler (has fewer parameters), and the results in [9] demon-<br />strated that it was often as good or better than the bilinear classifier. To account for classification,<br />the model in (2) remains unchanged, and the following may be added to the top of the hierarchy:<br />yi= 1 if θTˆ α + ν &gt; 0, yi= 2 if θTˆ α + ν &lt; 0, θ ∼ N(0,γ−1<br />ˆ α ∈ ?K+1is the same as α ∈ ?Kwith an appended one, to account for the classifier bias. Again,<br />one typically places (non-informative) gamma hyper-priors on γθand γ0. With the added layers for<br />the classifier, the conjugate-exponential character of the model is retained, sustaining the ability to<br />perform VB or MCMC inference with analytic update equations. Note that the model in (2) may<br />be employed for unlabeled data, and the extension above may be employed for the available labeled<br />data; consequently, all data (labeled and unlabeled) may be processed jointly to infer D.<br />θIK+1), and ν ∼ N(0,γ−1<br />0), where<br />2.3Sequential dictionary learning for large training sets<br />In the above discussion, we implicitly assumed all data D = {xi,yi}i=1,N are used together to<br />infer the dictionary D. However, in some applications N may be large, and therefore such a “batch”<br />approach is undesirable. To address this issue one may partition the data as D = D1∪ D2∪<br />...DJ−1∪ DJ, with the data processed sequentially. This issue has been considered for point<br />estimates of D [8], in which considerations are required to assure algorithm convergence. It is<br />of interest to briefly note that sequential inference is handled naturally via the proposed Bayesian<br />analysis.<br />3</p>  <p>Page 4</p> <p>Specifically, let p(D|D,Θ) represent the posterior on the desired dictionary, with all other model<br />parameters marginalized out (e.g., the sample-dependent coefficients α); the vector Θ represents<br />the model hyper-parameters. In a Bayesian analysis, rather than evaluating p(D|D,Θ) directly, one<br />may employ the same model (prior) to infer p(D|D1,Θ). This posterior may then serve as a prior<br />for D when considering next D2, inferring p(D|D1∪ D2,Θ). When doing variational Bayesian<br />(VB) inference we have an analytic approximate representation for posteriors such as p(D|D1,Θ),<br />while for Gibbs sampling we may use the inferred samples. When presenting results in Section 5,<br />we discuss additional means of sequentially accelerating a Gibbs sampler.<br />3 Denoising, Inpainting and Compressive Sensing<br />3.1<br />Assume we are given an image I ∈ ?Ny×Nxwith additive noise and missing pixels; we here assume<br />a monochrome image for simplicity, but color images are also readily handled, as demonstrated<br />when presenting results. As is done typically [6, 7], we partition the image into NB = (Ny−<br />B + 1) × (Nx− B + 1) overlapping blocks {xi}i=1,NB, for each of which xi∈ ?B2(B = 8 is<br />typically used). If there is only additive noise but no missing pixels, then the model in (2) can be<br />readily applied for simultaneous dictionary learning and image denoising. If there are both noise<br />and missing pixels, instead of directly observing xi, we observe a subset of the pixels in each xi.<br />Note that here Ψ and {αi}i=1,NB, which are used to recover the original noise-free and complete<br />image, are directly inferred from the data under test; one may also employ an appropriate training<br />set D with which to learn a dictionary D offline, or for initialization of in situ learning.<br />In denoising and inpainting studies of this type (see for example [6,7] and references therein), it<br />is often assumed that either the variance is known and used as a “stopping” criteria, or that the<br />sparsity level is pre-determined and fixed for all i ∈ {1,NB}. While these may be practical in<br />some applications, we feel it is more desirable to not make these assumptions. In (2) the noise<br />precision (inverse variance), γ?, is assumed drawn from a non-informative gamma distribution, and<br />a full posterior density function is inferred for γ?(and all other model parameters). In addition,<br />the problems of addressing spatially nonuniform noise as well as nonuniform noise across color<br />channels are of interest [7]; they are readily handled in the proposed model by drawing a separate<br />precision γ?for each color channel in each B × B block, each of which is drawn from a shared<br />gamma prior.<br />The sparsity level of the representation in our model, i.e., {?αi?0}i=1,N, is influenced by the<br />parameters a and b in the beta prior in (2). Examining the posterior p(πk|−) ∼ Beta(a/K +<br />?N<br />cussed further in Section 5). Therefore, the average sparsity level of the representation is inferred by<br />the data itself and each sample xihas its own unique sparse representation based on the posterior,<br />which renders much more flexibility than enforcing the same sparsity level for each sample.<br />Image Denoising and Inpainting<br />i=1zik,b(K − 1)/K + N −?N<br />i=1zik), conditioned on all other parameters, we find that most<br />settings of a and b tend to be non-informative, especially in the case of sequential learning (dis-<br />3.2Compressive sensing<br />We consider CS in the manner employed in [12]. Assume our objective is to measure an image<br />I ∈ ?Ny×Nx, with this image constituting the 8 × 8 blocks {xi}i=1,NB. Rather than measuring<br />the xidirectly, pixel-by-pixel, in CS we perform the projection measurement vi = Φxi, where<br />vi∈ ?Np, with Nprepresenting the number of projections, and Φ ∈ ?Np×64(assuming that xi<br />is represented by a 64-dimensional vector). There are many (typically random) ways in which Φ<br />may be constructed, with the reader referred to [24]. Our goal is to have Np? 64, thereby yielding<br />compressive measurements. Based on the CS measurements {vi}i=1,NB, our objective is to recover<br />{xi}i=1,NB.<br />Consider a potential dictionary Ψ, as discussed in Section 2. It is assumed that for each of the<br />{xi}i=1,NBfrom the image under test xi = Ψαi+ ?i, for sparse αiand relatively small error<br />??i?2. The number of required projections Npneeded for accurate estimation of αiis proportional<br />to ?αi?0[11], with this underscoring the desirability of learning a dictionary in which very sparse<br />representations are manifested (as compared to using an “off-the-shelf” wavelets or DCT basis).<br />For CS inversion, the model in (2) is employed, and therefore the appropriate dictionary D is learned<br />jointly while performing CS inversion, in situ on the image under test. When performing CS analy-<br />4</p>  <p>Page 5</p> <p>sis, in (2), rather than observing xi, we observe vi= ΦDαi+?i, for i = 1,...,NB(the likelihood<br />function is therefore modified slightly).<br />As discussed when presenting results, one may also learn the CS dictionary in advance, off-line,<br />with appropriate training images (using the model in (2)). However, the unique opportunity for joint<br />CS inversion and learning of an appropriate parsimonious dictionary is deemed to be a significant<br />advantage, as it does not presuppose that one would know an appropriate training set in advance.<br />The inpainting problem may be viewed as a special case of CS, in which each row of Φ corresponds<br />to a delta function, locating a unique pixel on the image at which useful (unobscured) data are<br />observed. Those pixels that are unobserved, or that are contaminated (e.g., by superposed text [7])<br />are not considered when inferring the αiand D. A CS camera designed around an inpainting<br />construction has several advantages, from the standpoint of simplicity. As observed from the results<br />in Section 5, an inpainting-based CS camera would simply observe a subset of the usual pixels,<br />selected at random.<br />4 Exploiting Spatial Structure<br />For the applications discussed above, the {xi}i=1,NBcome from the single image under test, and<br />consequently there is underlying (spatial) structure that should ideally be exploited. Rather than<br />re-writing the entire model in (2), we focus on the following equations in the hierarchy: zi ∼<br />?K<br />vectors, corresponding to different segments in the image. Since the number of mixture components<br />is not known a priori, this mixture model is modeled via a Dirichlet process [18]. We may therefore<br />employ, for i = 1,...,NB,<br />k=1Bernoulli(πk), and π ∼?K<br />k=1Beta(a/K,b(K − 1)/K). Instead of having a single vector<br />π = {π1,...,πK} that is shared for all {xi}i=1,NB, it is expected that there may be a mixture of π<br />zi∼<br />K<br />?<br />k=1<br />Bernoulli(πik)<br />πi∼ GG ∼ DP(β,<br />K<br />?<br />k=1<br />Beta(a/K,b(K − 1)/K))<br />(3)<br />Alternatively, we may cluster the zidirectly, yielding zi∼ G, G ∼ DP(β,?K<br />ment such DP constructions via a truncated stick-breaking representation [25], again retaining the<br />conjugate-exponential structure of interest for analytic VB or Gibbs inference. In such an analysis<br />we place a non-informative gamma prior on the precision β.<br />The construction in (3) clusters the blocks, and therefore it imposes structure not constituted in the<br />simpler model in (2). However, the DP still assumes that the members of {xi}i=1,NBare exchange-<br />able. Space limitations preclude discussing this matter in detail here, but we have also considered<br />replacement of the DP framework above with a probit stick-breaking process (PSBP) [19], which<br />explicitly imposes that it is more likely for proximate blocks to be in the same cluster, relative to<br />distant blocks. When presenting results, we show examples in which PSBP has been used, with<br />its relative effectiveness compared to the simpler DP construction. The PSBP again retains full<br />conjugate-exponential character within the hierarchy, of interest for efficient inference, as discussed<br />above.<br />k=1Bernoulli(πk)),<br />π ∼?K<br />k=1Beta(a/K,b(K − 1)/K), where the ziare drawn i.i.d. from G. In practice we imple-<br />5Example Results<br />For the denoising and inpainting results, we observed that the Gibbs sampler provided better perfor-<br />mance than associated variational Bayesian inference. For denoising and inpainting we may exploit<br />shifted versions of the data, which accelerates convergence substantially (discussed in detail be-<br />low). Therefore, all denoising and inpainting results are based on efficient Gibbs sampling. For CS<br />we cannot exploit shifted images, and therefore to achieve fast inversion variational Bayesian (VB)<br />inference [22] is employed; for this application VB has proven to be quite effective, as discussed<br />below. The same set of model hyper-parameters are used across all our denoising, inpainting and<br />CS examples (no tuning was performed): all gamma priors are set as Gamma(10−6,10−6), along<br />the lines suggested in [2], and the beta distribution parameters are set with a = K and b = N/8<br />(many other settings of a and b yield similar results).<br />5</p>  <p>Page 6</p> <p>5.1<br />We consider denoising a 256×256 image, with comparison of the proposed approach to K-SVD [6]<br />(for which the noise variance is assumed known and fixed); the true noise standard deviation is<br />set at 15, 25 and 50 in the examples below. We show results for three algorithms: (i) mismatched<br />K-SVD (with noise standard deviation of 30), (ii) K-SVD when the standard deviation is properly<br />matched, and (iii) the proposed BP approach. For (iii) a non-informative prior is placed on the<br />noise precision, and the same BP model is run for all three noise levels (with the underlying noise<br />levels inferred). The BP and K-SVD employed no a priori training data. In Figure 1 are shown<br />the noisy images at the three different noise levels, as well as the reconstructions via BP and K-<br />SVD. A preset large dictionary size K = 256 is used for both algorithms, and for the BP results<br />we inferred that approximately M = 219, 143, and 28 dictionary elements were important for noise<br />standard deviations 15, 25, and 50, respectively; the remaining elements of the dictionary were used<br />less than 0.1% of the time. As seen within the bottom portion of the right part of Figure 1, the<br />unused dictionary elements appear as random draws from the prior, since they are not used and<br />hence influenced by the data.<br />Note that K-SVD works well when the set noise variance is at or near truth, but the method is un-<br />dermined by mismatch. The proposed BP approach is robust to changing noise levels. Quantitative<br />performance is summarized in Table 1. The BP denoiser estimates a full posterior density func-<br />tion on the noise standard deviation; for the examples considered here, the modes of the inferred<br />standard-deviation posteriors were 15.52, 25.33, and 48.13, for true standard deviations 15, 25, and<br />50, respectively.<br />To achieve these BP results, we employ a sequential implementation of the Gibbs sampler (a batch<br />implementation converges to the same results but with higher computational cost); this is discussed<br />in further detail below, when presenting inpainting results.<br />Denoising<br />Figure 1: Left: Representative denoising results, with the top through bottom rows corresponding to noise<br />standard deviations of 15, 25 and 50, respectively. The second and third columns represent K-SVD [6] results<br />with assumed standard deviation equal to 30 and the ground truth, respectively. The fourth column represents<br />the proposed BP reconstructions. The noisy images are in the first column. Right: Inferred BP dictionary<br />elements for noise standard deviation 25, in order of importance (probability to be used) from the top-left.<br />Table 1: Peak signal-to-reconstructed image measure (PSNR) for the data in Figure 1, for K-SVD [6] and the<br />proposed BP method. The true standard deviation was 15, 25 and 50, respectively, from the top to the bottom<br />row. For the mismatched K-SVD results, the noise stand deviation was fixed at 30.<br />Original NoisyK-SVD Denoising<br />Image (dB)mismatched variance (dB)<br />24.58 30.67<br />20.19 31.52<br />14.56 19.60<br />K-SVD Denoising<br />matched variance (dB)<br />34.22<br />32.08<br />27.07<br />Beta Process<br />Denoising (dB)<br />34.19<br />31.89<br />27.85<br />5.2<br />Our inpainting and denoising results were achieved by using the following sequential procedure.<br />Consider any pixel [p,j], where p,j ∈ [1,B], and let this pixel constitute the left-bottom pixel in<br />Inpainting<br />6</p>  <p>Page 7</p> <p>08 162432404856 64<br />5<br />10<br />15<br />20<br />25<br />30<br />Learning round<br />PSNR<br />Figure 2: Inpainting results. The curve shows the PSNR as a function of the B2= 64 Gibbs learning rounds.<br />The left figure is the test image, with 80% of the RGB pixels missing, the middle figure is the result after 64<br />after Gibbs rounds (final result), and the right figure is the original uncontaminated image.<br />a new B × B block. Further, consider all B × B blocks with left-bottom pixels at {p + ?B,j +<br />mB} ∪ δ(p − 1){Ny− B + 1,j + mB} ∪ δ(j − 1){p + ?B,Nx− B + 1} for ? and m that satisfy<br />p + ?B ≤ Ny− B + 1 and j + mB ≤ Nx− B + 1. This set of blocks is denoted data set Dpj,<br />and considering 1 ≤ p ≤ B and 1 ≤ j ≤ B, there are a total of B2such shifted data sets. In the<br />first iteration of learning Ψ, we employ the blocks in D11, and for this first round we initialize Ψ<br />and αibased on a singular value decomposition (SVD) of the blocks in D11(we achieved similar<br />results when Ψ was initialized randomly). We do several Gibbs iterations with D11and then stop<br />the Gibbs algorithm, retaining the last sample of Ψ and αifrom the previous step. These Ψ and αi<br />are then used to initialize the Gibbs sampler in the second round, now applied to the B × B blocks<br />in D11∪ D21(for D21the neighboring αiis used for initialization). The Gibbs sampler is now run<br />on this expanded data for several iterations, the last sample is retained, and the data set is augmented<br />again. This is done B2= 64 times until at the end all shifted blocks are processed simultaneously.<br />This sequential process may be viewed as a sequential Gibbs burn in, after which all of the shifted<br />blocks are processed.<br />Theoretically, one would expect to need thousands of Gibbs iterations to achieve convergence. How-<br />ever, our experience is that even a single iteration in each of the above B2rounds yields good results.<br />In Figure 2 we show the PSNR as a function of each of the B2= 64 rounds discussed above. For<br />Gibbs rounds 16, 32 and 64 the corresponding PSNR values were 27.66 dB, 28.22 dB and 28.76<br />dB. For this example we used K = 256. This example was considered in [7] (we obtained similar<br />results for the “New Orleans” image, also considered in [7]); the best results reported there were a<br />PSNR of 29.65 dB. However, to achieve those results a training data set was employed for initializa-<br />tion [7]; the BP results are achieved with no a priori training data. Concerning computational costs,<br />the inpainting and denoising algorithms scale linearly as a function of the block size, the dictionary<br />size, and the number of training samples; all results reported here were run efficiently in Matlab on<br />PCs, with comparable costs as K-SVD.<br />5.3Compressive sensing<br />We consider a CS example, in which the image is divided into 8×8 patches, with these constituting<br />the underlying data {xi}i=1,NBto be inferred. For each of the NBblocks, a vector of CS measure-<br />ments vi= Φxiis measured, where the number of projections per patch is Np, and the total number<br />of CS projections is NpNB. In this example the elements of Φ were constructed randomly as draws<br />from N(0,1), but many other projection classes may be considered [11,24]. Each xiis assumed<br />represented in terms of a dictionary xi= Dαi+?i, and three constructions for D were considered:<br />(i) a DCT expansion; (ii) learning of D using the beta process construction, using training images;<br />(iii) using the beta process to perform joint CS inversion and learning of D. For (ii), the training<br />data consisted of 4000 8×8 patches chosen at random from 100 images selected from the Microsoft<br />database (http : //research.microsoft.com/en − us/projects/objectclassrecognition). The<br />dictionary was set to K = 256, and the offline beta process inferred a dictionary of size M = 237.<br />Representative CS reconstruction results are shown in Figure 3, for a gray-scale version of the<br />“castle” image. The inversion results at left are based on a learned dictionary; except for the “online<br />7</p>  <p>Page 8</p> <p>BP” results, all of these results employ the same dictionary D learned off-line as above, and the<br />algorithms are distinguished by different ways of estimating {αi}i=1,NB. A range of CS-inversion<br />algorithms are considered from the literature, and several BP-based constructions are considered as<br />well for CS inversion. The online BP results are quite competitive with those inferred off-line.<br />One also notes that the results based on a learned dictionary (left in Figure 3) are markedly better<br />than those based on the DCT (right in Figure 3); similar results were achieved when the DCT was<br />replaced by a wavelet representation. For the DCT-based results, note that the DP- and PSBP-based<br />BP CS inversion results are significantly better than those of all other CS inversion algorithms.<br />The results reported here are consistent with tests we performed using over 100 images from the<br />aforementioned Microsoft database, not reported here in detail for brevity.<br />Note that CS inversion using the DP-based BP algorithm (as discussed in Section 4) yield the best<br />results, significantly better than BP results not based on the DP, and better than all competing CS<br />inversion algorithms (for both learned dictionaries and the DCT). The DP-based results are very<br />similar to those generated by the probit stick-breaking process (PSBP) [19], which enforces spatial<br />information more explicitly; this suggests that the simpler DP-based results are adequate, at least<br />for the wide class of examples considered. Note that we also considered the DP and PSBP for<br />the denoising and inpaiting examples above (those results were omitted, for brevity). The DP and<br />PSBP denoising and inpainting results were similar to BP results without DP/PSBP (those presented<br />above); this is attributed to the fact that when performing denoising/inpainting we may consider<br />many shifted versions of the same image (as discussed when presenting the inpainting results).<br />Concerning computational costs, all CS inversions were run efficiently on PCs, with the specifics<br />computational times dictated by the detailed Matlab implementation and the machine run on. A<br />rough ranking of the computational speeds, from fastest to slowest, is as follows: StOMP-CFAR,<br />Fast BCS, OMP, BP, LARS/Lasso, Online BP, DP BP, PSBP BP, VB BCS, Basis Pursuit; in this<br />list, algorithms BP through Basis Pursuits have approximately the same computational costs. The<br />DP-based BP CS inversion algorithm scales as O(NB· Np· B2).<br />3 3.54 4.5<br />Number of Measurements<br />Number of CS Measurements (x 104)<br />5 5.56 6.57 7.5<br />x 10<br />4<br />0<br />0.05<br />0.1<br />0.15<br />0.2<br />0.25<br />0.3<br />Relative Reconstruction Error<br />PSBP BP<br />DP BP<br />Online BP<br />BP<br />BCS<br />Fast BCS<br />Basis Pursuit<br />LARS/Lasso<br />OMP<br />STOMP-CFAR<br />Relative Reconstruction Error<br />33.5 4 4.5<br />Number of Measurements<br />Number of CS Measurements (x 104)<br />5 5.566.5 7 7.5<br />x 10<br />4<br />0.2<br />0.25<br />0.3<br />0.35<br />0.4<br />0.45<br />0.5<br />Relative Reconstruction Error<br />PSBP BP<br />DP BP<br />BP<br />BCS<br />Fast BCS<br />Basis Pursuit<br />LARS/Lasso<br />OMP<br />STOMP-CFAR<br />Relative Reconstruction Error<br />Figure 3: CS performance (fraction of ?2 error) based on learned dictionaries (left) and based on the DCT<br />(right). For the left results, the “Online BP” results simultaneously learned the dictionary and did CS inversion;<br />the remainder of the left results are based on a dictionary learned offline on a training set. A DCT dictionary<br />is used for the results on the right. The underlying image under test is shown at right. Matlab code for Basis<br />Pursuit, LARS/Lasso, OMP, STOMP are available at http : //sparselab.stanford.edu/, and code for BCS<br />and Fast BCS are available at http : //people.ee.duke.edu/ lihan/cs/. The horizontal axis represents the<br />total number of CS projections, NpNB. The total number of pixels in the image is 480 × 320 = 153,600.<br />99.9% of the signal energy is contained in 33,500 DCT coefficients.<br />6 Conclusions<br />The non-parametric beta process has been presented for dictionary learning with the goal of image<br />denoising, inpainting and compressive sensing, with very encouraging results relative to the state<br />of the art. The framework may also be applied to joint compression-classification tasks, which we<br />have implemented successfully but do not present in detail here because of the paper length. In the<br />context of noisy underlying data, the noise variance need not be known in advance, and it need not<br />be spatially uniform. The proposed formulation also allows unique opportunities to leverage known<br />structure in the data, such as relative spatial locations within an image; this framework was used to<br />achieve marked improvements in CS-inversion quality.<br />8</p>  <p>Page 9</p> <p>References<br />[1] N. Cristianini and J. Shawe-Taylor. An Introduction to Support Vector Machines. Cambridge<br />University Press, 2000.<br />[2] M. Tipping. Sparse Bayesian learning and the relevance vector machine. Journal of Machine<br />Learning Research, 1, 2001.<br />[3] R. Tibshirani. Regression shrinkage and selection via the lasso. Journal of the Royal Statistical<br />Society, Series B, 58, 1994.<br />[4] B.A. Olshausen and D. J. Field. Sparse coding with an overcomplete basis set: A strategy<br />employed by V1? Vision Research, 37, 1998.<br />[5] M. Aharon, M. Elad, and A. M. Bruckstein. K-SVD: An algorithm for designing overcomplete<br />dictionaries for sparse representation. IEEE Trans. Signal Processing, 54, 2006.<br />[6] M. Elad and M. Aharon. Image denoising via sparse and redundant representations over<br />learned dictionaries. IEEE Trans. Image Processing, 15, 2006.<br />[7] J. Mairal, M. Elad, and G. Sapiro. Sparse representation for color image restoration. IEEE<br />Trans. Image Processing, 17, 2008.<br />[8] J. Mairal, F. Bach, J. Ponce, and G. Sapiro. Online dictionary learning for sparse coding. In<br />Proc. International Conference on Machine Learning, 2009.<br />[9] J. Mairal, F. Bach, J. Ponce, G. Sapiro, and A. Zisserman. Supervised dictionary learning. In<br />Proc. Neural Information Processing Systems, 2008.<br />[10] M. Ranzato, C. Poultney, S. Chopra, and Y. Lecun. Efficient learning of sparse representations<br />with an energy-based model. In Proc. Neural Information Processing Systems, 2006.<br />[11] E. Cand` es and T. Tao. Near-optimal signal recovery from random projections: universal en-<br />coding strategies? IEEE Trans. Information Theory, 52, 2006.<br />[12] J.M.Duarte-CarvajalinoandG.Sapiro. Learningtosensesparsesignals: Simultaneoussensing<br />matrix and sparsifying dictionary optimization. IMA Preprint Series 2211, 2008.<br />[13] J. Wright, A.Y. Yang, A. Ganesh, S.S. Sastry, and Y. Ma. Robust face recognition via sparse<br />representation. IEEE Trans. Pattern Analysis Machine Intelligence, 31, 2009.<br />[14] S. Ji, Y. Xue, and L. Carin. Bayesian compressive sensing. IEEE Trans. Signal Processing,<br />56, 2008.<br />[15] R. Raina, A. Battle, H. Lee, B. Packer, and A.Y. Ng. Self-taught learning: transfer learning<br />from unlabeled data. In Proc. International Conference on Machine Learning, 2007.<br />[16] R. Thibaux and M.I. Jordan. Hierarchical beta processes and the indian buffet process. In Proc.<br />International Conference on Artificial Intelligence and Statistics, 2007.<br />[17] J. Paisley and L. Carin. Nonparametric factor analysis with beta process priors. In Proc.<br />International Conference on Machine Learning, 2009.<br />[18] T. Ferguson. A Bayesian analysis of some nonparametric problems. Annals of Statistics, 1,<br />1973.<br />[19] A. Rodriguez and D.B. Dunson. Nonparametric bayesian models through probit stickbreaking<br />processes. Univ. California Santa Cruz Technical Report, 2009.<br />[20] D. Knowles and Z. Ghahramani. Infinite sparse factor analysis and infinite independent com-<br />ponents analysis. In Proc. International Conference on Independent Component Analysis and<br />Signal Separation, 2007.<br />[21] P. Rai and H. Daum´ e III. The infinite hierarchical factor regression model. In Proc. Neural<br />Information Processing Systems, 2008.<br />[22] M.J. Beal. Variational Algorithms for Approximate Bayesian Inference. PhD thesis, Gatsby<br />Computational Neuroscience Unit, University College London, 2003.<br />[23] M. Girolami and S. Rogers. Variational Bayesian multinomial probit regression with Gaussian<br />process priors. Neural Computation, 18, 2006.<br />[24] R.G. Baraniuk. Compressive sensing. IEEE Signal Processing Magazine, 24, 2007.<br />[25] J. Sethuraman. A constructive definition of Dirichlet priors. Statistica Sinica, 4, 1994.<br />9</p>  <a href="https://www.researchgate.net/profile/Mingyuan_Zhou/publication/221618878_Non-Parametric_Bayesian_Dictionary_Learning_for_Sparse_Image_Representations/links/0deec528e576781722000000.pdf">Download full-text</a> </div> <div id="rgw26_56ab9f6060214" class="c-box pub-resource-container js-toggle" style=""> <h4 class="lf js-expand-list"><small><a href="javascript:" class="lf">View other sources <span class="ico-expand-list"></span></a></small></h4> <h4 class="lf js-collapse-list hidden"><small><a href="javascript:" class="lf">Hide other sources <span class="ico-collapse-list"></span></a></small></h4> <div class="clear"></div> <div class="scroll-wrapper hidden"> <ul class="files-list c-list" id="rgw27_56ab9f6060214">  <li class="c-list-item pub-resource-item"  data-type="fulltext" id="rgw28_56ab9f6060214"> <span class="ico-pub"></span> <div class="file-content"> <div class="download"> <a href="profile/Mingyuan_Zhou/publication/221618878_Non-Parametric_Bayesian_Dictionary_Learning_for_Sparse_Image_Representations/links/0deec528e576781722000000.pdf" class="publication-viewer" title="0deec528e576781722000000.pdf">0deec528e576781722000000.pdf</a> </div>  <div class="details">  <span> Available from <a href="profile/Mingyuan_Zhou">Mingyuan Zhou</a> &middot; May 21, 2014 </span>   </div>    </div> </li>  <li class="c-list-item pub-resource-item"  data-type="fulltext" id="rgw29_56ab9f6060214"> <span class="ico-pub"></span> <div class="file-content"> <div class="download"> <a href="http://people.ee.duke.edu/~lcarin/Mingyuan_nips2009_FINAL.pdf" target="_blank" rel="nofollow" class="publication-viewer" title="Non-Parametric Bayesian Dictionary Learning for Sparse Image Representations.">Non-Parametric Bayesian Dictionary Learning for Sp...</a> </div>  <div class="details">   Available from <a href="http://people.ee.duke.edu/~lcarin/Mingyuan_nips2009_FINAL.pdf" target="_blank" rel="nofollow">people.ee.duke.edu</a>  </div>    </div> </li>  </ul> </div> </div> </noscript> <div class="clearfix"> <div class="action-container">  </div> <div class="pub-legal"> Data provided are for informational purposes only. Although carefully collected, accuracy cannot be guaranteed. The impact factor represents a rough estimation of the journal's impact factor and does not reflect the actual current impact factor. Publisher conditions are provided by RoMEO. Differing provisions from the publisher's actual policy or licence agreement may be applicable. </div>   </div> </div> <div class="clearfix">     <div id="rgw31_56ab9f6060214" class="c-box pub-resource-container js-toggle" style="display: none;"> <h4 class="lf js-expand-list"><small><a href="javascript:" class="lf">View other sources <span class="ico-expand-list"></span></a></small></h4> <h4 class="lf js-collapse-list hidden"><small><a href="javascript:" class="lf">Hide other sources <span class="ico-collapse-list"></span></a></small></h4> <div class="clear"></div> <div class="scroll-wrapper hidden"> <ul class="files-list c-list" id="rgw32_56ab9f6060214">  </ul> </div> </div>   <div id="rgw22_56ab9f6060214" class="similar-publications"> <h2>Similar Publications</h2> <ul class="list-bordered">  <li class="c-list-item li-publication-teaser" id="rgw23_56ab9f6060214"> <div> <h5> <a href="publication/290533653_Ship_Detection_in_SAR_Imagery_via_Variational_Bayesian_Inference" class="color-inherit ga-similar-publication-title"><span class="publication-title">Ship Detection in SAR Imagery via Variational Bayesian Inference</span></a>  </h5>  <div class="authors"> <a href="researcher/2094145672_Shengli_Song" class="authors ga-similar-publication-author">Shengli Song</a>, <a href="researcher/2045737986_Bin_Xu" class="authors ga-similar-publication-author">Bin Xu</a>, <a href="researcher/2064607746_Zenghui_Li" class="authors ga-similar-publication-author">Zenghui Li</a>, <a href="researcher/2094179389_Jian_Yang" class="authors ga-similar-publication-author">Jian Yang</a>  </div>  </div> <div class="clear"></div> </li>  <li class="c-list-item li-publication-teaser" id="rgw24_56ab9f6060214"> <div> <h5> <a href="publication/284136871_Markov_chain_Monte_Carlo_simulation_using_the_DREAM_software_package_Theory_concepts_and_MATLAB_implementation" class="color-inherit ga-similar-publication-title"><span class="publication-title">Markov chain Monte Carlo simulation using the DREAM software package: Theory, concepts, and MATLAB implementation</span></a>  </h5>  <div class="authors"> <a href="researcher/10295979_Jasper_A_Vrugt" class="authors ga-similar-publication-author">Jasper A. Vrugt</a>  </div>  </div> <div class="clear"></div> </li>  <li class="c-list-item li-publication-teaser" id="rgw25_56ab9f6060214"> <div> <h5> <a href="publication/284811060_Molecular_phylogeny_of_the_subfamily_Schizothoracinae_Teleostei_Cypriniformes_Cyprinidae_inferred_from_complete_mitochondrial_genomes" class="color-inherit ga-similar-publication-title"><span class="publication-title">Molecular phylogeny of the subfamily Schizothoracinae (Teleostei: Cypriniformes: Cyprinidae) inferred from complete mitochondrial genomes</span></a>  </h5>  <div class="authors"> <a href="researcher/2054762076_Jie_Zhang" class="authors ga-similar-publication-author">Jie Zhang</a>, <a href="researcher/2085966150_Zhuo_Chen" class="authors ga-similar-publication-author">Zhuo Chen</a>, <a href="researcher/54051363_Chuanjiang_Zhou" class="authors ga-similar-publication-author">Chuanjiang Zhou</a>, <a href="researcher/33113094_Xianghui_Kong" class="authors ga-similar-publication-author">Xianghui Kong</a>  </div>  </div> <div class="clear"></div> </li>  </ul> </div> </div> </div> </div> </div></div></div>
<div class="clear"></div><div id="rgw45_56ab9f6060214" class="default-footer"> <div id="footer" class="clearfix"> <span class="footer-left"> &copy; 2008&dash;2016 researchgate.net. All rights reserved. </span> <span class="footer-right"> <a href="https://www.researchgate.net/about">About us</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="https://www.researchgate.net/contact">Contact us</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="careers">Careers</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="developers">Developers</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="blog" target="_blank">News</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="application.PrivacyPolicy.html">Privacy</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="application.TermsAndConditions.html">Terms</a> <span class="footer-link-separator" style="padding: 0 5px;">&nbsp;|&nbsp;</span> <a href="advertising?_ref=ft">Advertising</a> <span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="recruiters?_ref=ft">Recruiting</a> </span> </div>  </div></div>
<div id="rgw46_56ab9f6060214">  <div class="header-wrapper-logged-out"> <div id="header"> <div class="header-content"> <a href="" class="g-l-logo"> <svg width="149" height="19"> <image xlink:href="https://c5.rgstatic.net/m/235107188705592/images/template/brand-header-logo.svg" src="https://c5.rgstatic.net/m/238113351022438/images/template/brand-header-logo.png" width="149" height="19"/> </svg> </a> <a href="" class="g-l-logo-ico"> <svg width="127" height="17" viewbox="0 0 127 22"> <image xlink:href="https://c5.rgstatic.net/m/235107188705592/images/template/brand-header-logo.svg" src="https://c5.rgstatic.net/m/238113351022438/images/template/brand-header-logo.png" width="127" height="17"/> </svg> </a> <div id="rgw47_56ab9f6060214" class="header-login-wrapper js-header-login"> <div class="dropdown-right-align"> <div class="login-signup-container lf"> <a href="https://www.researchgate.net/signup.SignUp.html?ev=su_chnl_index&amp;hdrsu=1&amp;_sg=0k4-3N_nDASf6ZTm0qCtlly36ZmlqjUBM6qAz5Il62hhrytU8pj_DsyY-6erZNnb" class="dropdown-toggle lf">Join for free</a> </div> <div class="dropdown lf" style="height: 20px;"> <a href="https://www.researchgate.net/application.Login.html" class="js-login-url dropdown-toggle lf">Log in <span class="caret"></span></a> <div class="dropdown-menu"> <div class="header-login-form-wrapper"> <!--[if IE 6]><p class="box-warning" style="margin-bottom: 0;">Sorry, ResearchGate no longer supports the version of Internet Explorer you are using. <a href="http://whatbrowser.org/" rel="nofollow" target="_blank">Update your web browser</a> and then log in. </p><![endif]--> <form method="post" action="https://www.researchgate.net/application.Login.html" class="form-big header-login-form js-login-form" name="loginForm" id="headerLoginForm"> <input type="hidden" name="request_token" value="dNT2UI6m9MfJ7x56X/R79G5V0NpIIW+3F/I5OyzXniMLOaDHt+EM2ogv5nM6gRsPIlqM/gXioxHs7E+N/G/NhKT6cZVy7T+QaJm3Hm1Yq3UmjFKjnedRaSFxuG2DjdZ/iB3VJYd1Lm6/xpI9cReDAhb5VCgi8xGJ2F0qYDzmZ0/sTJB9Pp5RkaFVJPiJYjGckaJLgQQaS2FCEaTGNfvTzAl1sAZpqSNbusuJAzE6Mnkr5RV4zG+Gw/5BOJh1JuIj68IgPfYoisnWSaXQkpaYfqbz1jwE39l/+3KoeNN02BE="/> <input type="hidden" name="urlAfterLogin" value="publication/221618878_Non-Parametric_Bayesian_Dictionary_Learning_for_Sparse_Image_Representations"/> <input type="hidden" name="invalidPasswordCount" value="0"/> <input type="hidden" name="headerLogin" value="yes"/> <label for="input-header-login">Email</label> <div class="login-input"> <div class="info-tip-wrapper"> <span class="ico-info js-info"></span> </div> <input type="email" value="" name="login" class="login js-login-input text" id="input-header-login" tabindex="1"/> </div> <div class="clear"></div> <label class="lf" for="input-header-password"> Password </label> <a class="rf forgot-password js-forgot-password" href="application.LostPassword.html">Forgot password?</a> <div class="clear"></div> <input type="password" value="" name="password" class="password js-password-input text" id="input-header-password" tabindex="2"/> <div class="clear"></div> <label class="remember-me" for="headerLoginCookie"> <input type="checkbox" checked="checked" value="yes" name="setLoginCookie" class="lf checkbox" id="headerLoginCookie" tabindex="3"/> Keep me logged in </label> <div class="clear"></div> <input value="Log in" name="loginSubmit" class="btn btn-promote btn-fullwidth btn-large allow-leave js-submit-button" type="submit" tabindex="4"/> </form> <div class="connectors"> <div class="text">or log in with</div> <div class="connector-actions"> <a href="connector/linkedin/" class="li-connect js-li-connect" data-redirect-url="cHVibGljYXRpb24vMjIxNjE4ODc4X05vbi1QYXJhbWV0cmljX0JheWVzaWFuX0RpY3Rpb25hcnlfTGVhcm5pbmdfZm9yX1NwYXJzZV9JbWFnZV9SZXByZXNlbnRhdGlvbnM%3D"> <span class="icon ico-linkedin-round-grey"></span> <span class="icon ico-linkedin-round"></span> </a> <a href="connector/facebook/" class="fb-connect middle js-fb-connect" data-redirect-url="cHVibGljYXRpb24vMjIxNjE4ODc4X05vbi1QYXJhbWV0cmljX0JheWVzaWFuX0RpY3Rpb25hcnlfTGVhcm5pbmdfZm9yX1NwYXJzZV9JbWFnZV9SZXByZXNlbnRhdGlvbnM%3D"> <span class="icon ico-facebook-round-grey"></span> <span class="icon ico-facebook-round"></span> </a> <a href="connector/google/" class="g-connect js-g-connect" data-redirect-url="cHVibGljYXRpb24vMjIxNjE4ODc4X05vbi1QYXJhbWV0cmljX0JheWVzaWFuX0RpY3Rpb25hcnlfTGVhcm5pbmdfZm9yX1NwYXJzZV9JbWFnZV9SZXByZXNlbnRhdGlvbnM%3D"> <span class="icon ico-google-round-grey"></span> <span class="icon ico-google-round"></span> </a> </div> </div> </div> </div> </div> </div> </div> </div> </div> <script type="application/ld+json">
{ "@context" : "http://schema.org",
  "@type" : "Organization",
  "name" : "ResearchGate",
  "url" : "http://www.researchgate.net",
  "logo" : "http://www.researchgate.net/images/template/rg_logo_square_brand.png",
  "sameAs" : [ "https://www.facebook.com/ResearchGate",
    "https://twitter.com/ResearchGate",
    "https://plus.google.com/+researchgate",
    "https://www.linkedin.com/company/researchgate"] 
}
</script> </div> </div><div class="c-signup-bar" id="rgw48_56ab9f6060214"> <div class="banner-contents">   <span class="message">ResearchGate is the professional network for scientists and researchers.</span> <a href="signup.SignUp.html?ev=su_banner" class="btn btn-large btn-promote">Join for free</a>  </div> </div></div>
<script>
rgConfig.backendTime = 602;
</script>
<script src="//c5.rgstatic.net/m/2277196935388619/javascript/lib/yui3/yui/yui-min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/21832295316281274/javascript/yuiLoaderConfig-min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/23178613132105398/javascript/vendor/babel-core/browser-polyfill.min.js" type="text/javascript"></script>
<script>
(function (){
if (typeof YRG === "undefined") {
var xmlHttpRequest = new XMLHttpRequest();
xmlHttpRequest.open("post", "go.Error.html");
xmlHttpRequest.setRequestHeader("Content-Type", "application/json");
xmlHttpRequest.setRequestHeader("Accept", "application/json"); var loadedScripts = "";
if (window.performance && window.performance.getEntriesByType) {
    var result = [];
    var resources = performance.getEntriesByType("resource");
    for (var i in resources) {
        if (resources.hasOwnProperty(i)) {
            result.push({
                name: resources[i].name,
                duration: resources[i].duration
            });
        }
    }
    loadedScripts += "&loadedScripts=" + encodeURIComponent(JSON.stringify(result));
}
if (typeof YUI === "undefined") {
    loadedScripts += "&yuiLoaded=false";
} else {
    loadedScripts += "&yuiLoaded=true";
}
xmlHttpRequest.send("Type=InformationException&message=" + encodeURIComponent("Error loading YUI") + loadedScripts);
}
})();
</script>
<script>if (typeof YRG !== 'undefined') { YRG.use('rg-base',function(Y){Y.applyConfig({ignore: ["css-rg","css-rg2","css-ie","css-modules-publicprofile","css-pow-publicliterature-FollowPublicationPromo","css-pow-application-PdfJsReader","css-pow-publicliterature-PublicationInlineReader"]});Y.use(["rg.core.pagespeed.Monitoring"],function(Y){(function(){Y.rg.createInitialWidget({"data":{"content":{"data":{"profileSmallHeader":{"data":{"profileBadge":{"data":{"fullname":"Mingyuan Zhou","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2671872220764\/images\/template\/default\/profile\/profile_default_m.jpg","profileStats":[],"profileFollowButton":null,"profileReputationScoreNumber":null,"profileUrl":"profile\/Mingyuan_Zhou","institution":"Duke University","institutionUrl":false,"widgetId":"rgw4_56ab9f6060214"},"id":"rgw4_56ab9f6060214","partials":[],"templateName":"publicprofile\/stubs\/ProfileBadge.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicprofile.ProfileBadge.html?accountId=1820977","viewClass":null,"yuiModules":["css-modules-publicprofile"],"stylesheets":["modules\/publicprofile.css"],"_isYUI":true},"widgetId":"rgw3_56ab9f6060214"},"id":"rgw3_56ab9f6060214","partials":[],"templateName":"publicprofile\/stubs\/ProfileSmallHeader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicprofile.ProfileSmallHeader.html?publicationUid=221618878","viewClass":null,"yuiModules":["css-modules-publicprofile"],"stylesheets":["modules\/publicprofile.css"],"_isYUI":true},"publication":{"data":{"publicationUid":221618878,"title":"Non-Parametric Bayesian Dictionary Learning for Sparse Image Representations.","journalTitle":false,"journalDetailsTooltip":false,"affiliation":false,"type":"Conference Paper","details":{"conferenceInfos":"Conference: Advances in Neural Information Processing Systems 22: 23rd Annual Conference on Neural Information Processing Systems 2009. Proceedings of a meeting held 7-10 December 2009, Vancouver, British Columbia, Canada."},"source":{"sourceUrl":"http:\/\/dblp.uni-trier.de\/db\/conf\/nips\/nips2009.html#ZhouCPRSC09","sourceName":"DBLP"},"publicationActions":null,"publicationCoins":{"data":{"tags":[{"key":"ctx_ver","value":"Z39.88-2004"},{"key":"rft_val_fmt","value":"info:ofi\/fmt:kev:mtx:journal"},{"key":"rfr_id","value":"info:sid\/researchgate.net:researchgate"},{"key":"rft.atitle","value":"Non-Parametric Bayesian Dictionary Learning for Sparse Image Representations."},{"key":"rft.date","value":"2009"},{"key":"rft.pages","value":"2295-2303"},{"key":"rft.au","value":"Mingyuan Zhou,Haojun Chen,John William Paisley,Lu Ren,Guillermo Sapiro,Lawrence Carin"},{"key":"rft.genre","value":"inProceedings"}],"widgetId":"rgw6_56ab9f6060214"},"id":"rgw6_56ab9f6060214","partials":[],"templateName":"publicliterature\/stubs\/PublicationCoins.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationCoins.html?publicationUid=221618878","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationAuthors":{"data":{"publicationUid":221618878,"peopleItems":[{"data":{"authorNameOnPublication":"Mingyuan Zhou","accountUrl":"profile\/Mingyuan_Zhou","accountKey":"Mingyuan_Zhou","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2671872220764\/images\/template\/default\/profile\/profile_default_m.jpg","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Mingyuan Zhou","profile":{"professionalInstitution":{"professionalInstitutionName":"Duke University","professionalInstitutionUrl":"institution\/Duke_University"}},"professionalInstitutionName":"Duke University","professionalInstitutionUrl":"institution\/Duke_University","url":"profile\/Mingyuan_Zhou","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":false,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":true,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"accountKey":"Mingyuan_Zhou","hasInfoPopup":false,"hasTeaserPopup":true,"showContactAuthorButton":true,"widgetId":"rgw9_56ab9f6060214"},"id":"rgw9_56ab9f6060214","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAccountItem.html?entityId=1820977&enableUnfollow=0&imageSize=l&enableFollowButton=0&showContactAuthorButton=1","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"accountInstitution":"Duke University","score":null,"largeTooltip":false,"useRebrandedImageStyle":null,"authorCount":6,"accountCount":2,"publicationUid":221618878,"widgetId":"rgw8_56ab9f6060214"},"id":"rgw8_56ab9f6060214","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAccountItem.html","templateExtensions":[],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAccountItem.html?accountId=1820977&context=pubdetail_authors_xflw&showContactAuthorButton=1&authorCount=6&accountCount=2&publicationUid=221618878","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true},{"data":{"authorUrl":"researcher\/63063915_Haojun_Chen","authorNameOnPublication":"Haojun Chen","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg","imageSize":"s","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Haojun Chen","profile":{"professionalInstitution":{"professionalInstitutionName":false,"professionalInstitutionUrl":null}},"professionalInstitutionName":false,"professionalInstitutionUrl":null,"url":"researcher\/63063915_Haojun_Chen","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":true,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":false,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"widgetId":"rgw11_56ab9f6060214"},"id":"rgw11_56ab9f6060214","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAuthorItem.html?entityId=63063915&imageSize=l&enableAuthorInviteButton=0","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"largeTooltip":false,"useRebrandedImageStyle":null,"widgetId":"rgw10_56ab9f6060214"},"id":"rgw10_56ab9f6060214","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorItem.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorItem.html?authorUid=63063915&authorNameOnPublication=Haojun%20Chen","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true},{"data":{"authorUrl":"researcher\/70672430_John_William_Paisley","authorNameOnPublication":"John William Paisley","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg","imageSize":"s","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"John William Paisley","profile":{"professionalInstitution":{"professionalInstitutionName":false,"professionalInstitutionUrl":null}},"professionalInstitutionName":false,"professionalInstitutionUrl":null,"url":"researcher\/70672430_John_William_Paisley","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":true,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":false,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"widgetId":"rgw13_56ab9f6060214"},"id":"rgw13_56ab9f6060214","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAuthorItem.html?entityId=70672430&imageSize=l&enableAuthorInviteButton=0","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"largeTooltip":false,"useRebrandedImageStyle":null,"widgetId":"rgw12_56ab9f6060214"},"id":"rgw12_56ab9f6060214","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorItem.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorItem.html?authorUid=70672430&authorNameOnPublication=John%20William%20Paisley","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true},{"data":{"authorNameOnPublication":"Lu Ren","accountUrl":"profile\/Lu_Ren4","accountKey":"Lu_Ren4","imageUrl":"https:\/\/i1.rgstatic.net\/ii\/profile.image\/AS%3A289644269850626%401446067983946_m\/Lu_Ren4.png","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Lu Ren","profile":{"professionalInstitution":{"professionalInstitutionName":"Apple Inc.","professionalInstitutionUrl":"institution\/Apple_Inc"}},"professionalInstitutionName":"Apple Inc.","professionalInstitutionUrl":"institution\/Apple_Inc","url":"profile\/Lu_Ren4","imageUrl":"https:\/\/i1.rgstatic.net\/ii\/profile.image\/AS%3A289644269850626%401446067983946_l\/Lu_Ren4.png","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":false,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":true,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"accountKey":"Lu_Ren4","hasInfoPopup":false,"hasTeaserPopup":true,"showContactAuthorButton":true,"widgetId":"rgw15_56ab9f6060214"},"id":"rgw15_56ab9f6060214","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAccountItem.html?entityId=9053989&enableUnfollow=0&imageSize=l&enableFollowButton=0&showContactAuthorButton=1","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"accountInstitution":"Apple Inc.","score":null,"largeTooltip":false,"useRebrandedImageStyle":null,"authorCount":6,"accountCount":2,"publicationUid":221618878,"widgetId":"rgw14_56ab9f6060214"},"id":"rgw14_56ab9f6060214","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAccountItem.html","templateExtensions":[],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAccountItem.html?accountId=9053989&context=pubdetail_authors_xflw&showContactAuthorButton=1&authorCount=6&accountCount=2&publicationUid=221618878","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true},{"data":{"authorUrl":"researcher\/7868797_Guillermo_Sapiro","authorNameOnPublication":"Guillermo Sapiro","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg","imageSize":"s","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Guillermo Sapiro","profile":{"professionalInstitution":{"professionalInstitutionName":false,"professionalInstitutionUrl":null}},"professionalInstitutionName":false,"professionalInstitutionUrl":null,"url":"researcher\/7868797_Guillermo_Sapiro","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":true,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":false,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"widgetId":"rgw17_56ab9f6060214"},"id":"rgw17_56ab9f6060214","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAuthorItem.html?entityId=7868797&imageSize=l&enableAuthorInviteButton=0","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"largeTooltip":false,"useRebrandedImageStyle":null,"widgetId":"rgw16_56ab9f6060214"},"id":"rgw16_56ab9f6060214","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorItem.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorItem.html?authorUid=7868797&authorNameOnPublication=Guillermo%20Sapiro","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true},{"data":{"authorUrl":"researcher\/10135830_Lawrence_Carin","authorNameOnPublication":"Lawrence Carin","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg","imageSize":"s","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Lawrence Carin","profile":{"professionalInstitution":{"professionalInstitutionName":false,"professionalInstitutionUrl":null}},"professionalInstitutionName":false,"professionalInstitutionUrl":null,"url":"researcher\/10135830_Lawrence_Carin","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":true,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":false,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"widgetId":"rgw19_56ab9f6060214"},"id":"rgw19_56ab9f6060214","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAuthorItem.html?entityId=10135830&imageSize=l&enableAuthorInviteButton=0","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"largeTooltip":false,"useRebrandedImageStyle":null,"widgetId":"rgw18_56ab9f6060214"},"id":"rgw18_56ab9f6060214","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorItem.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorItem.html?authorUid=10135830&authorNameOnPublication=Lawrence%20Carin","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true}],"hasMore":false,"nextOffset":6,"useRebrandedImageStyle":null,"widgetId":"rgw7_56ab9f6060214"},"id":"rgw7_56ab9f6060214","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorList.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorList.html?publicationUid=221618878&context=pubdetail_authors_xflw&showContactAuthorButton=1","viewClass":"views.publicliterature.PublicationDetailAuthorListView","yuiModules":["rg.views.publicliterature.PublicationDetailAuthorListView"],"stylesheets":[],"_isYUI":true},"publicationAbstract":{"data":{"publicationUid":221618878,"abstract":"<noscript><\/noscript><div>Non-parametric Bayesian techniques are considered for learning dictionaries for sparse image representations, with applications in denoising, inpainting and com- pressive sensing (CS). The beta process is employed as a prior for learning the dictionary, and this non-parametric method naturally infers an appropriate dic- tionary size. The Dirichlet process and a probit stick-breaking process are also considered to exploit structure within an image. The proposed method can learn a sparse dictionary in situ; training images may be exploited if available, but they are not required. Further, the noise variance need not be known, and can be non- stationary. Another virtue of the proposed method is that sequential inference can be readily employed, thereby allowing scaling to large images. Several example results are presented, using both Gibbs and variational Bayesian inference, with comparisons to other state-of-the-art approaches.<\/div>","canEdit":false,"isAdmin":false,"isArtifact":false,"showFullAbstract":false,"widgetId":"rgw20_56ab9f6060214"},"id":"rgw20_56ab9f6060214","partials":[],"templateName":"publicliterature\/stubs\/PublicationAbstract.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationAbstract.html?publicationUid=221618878","viewClass":"views.publicliterature.PublicationAbstractView","yuiModules":["rg.views.publicliterature.PublicationAbstractView"],"stylesheets":[],"_isYUI":true},"publicationKeywords":null,"publicationState":null,"isGuest":true,"isAdminEditingAllowed":false,"isArtifact":false,"figureListWidget":null,"previewImage":"https:\/\/i1.rgstatic.net\/publication\/221618878_Non-Parametric_Bayesian_Dictionary_Learning_for_Sparse_Image_Representations\/links\/0deec528e576781722000000\/smallpreview.png","nativeAdDisclosure":null,"showFollowPublicationButton":false,"followPublicationPromo":{"data":{"widgetId":"rgw21_56ab9f6060214"},"id":"rgw21_56ab9f6060214","partials":[],"templateName":"publicliterature\/stubs\/FollowPublicationPromo.html","templateExtensions":[],"attrs":{"context":null,"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.FollowPublicationPromo.html","viewClass":null,"yuiModules":["css-pow-publicliterature-FollowPublicationPromo"],"stylesheets":["pow\/publicliterature\/FollowPublicationPromo.css"],"_isYUI":true},"widgetId":"rgw5_56ab9f6060214"},"id":"rgw5_56ab9f6060214","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailItem.html","templateExtensions":["generalHelpers"],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailItem.html?publicationUid=221618878&showActionBar=0&showContactAuthorButton=1&showRequestFulltextExperience=0&showNoRgAuthorsRequestFulltextExperience=0&showFollowPublicationPromo=1","viewClass":"views.publicliterature.PublicationDetailItemView","yuiModules":["rg.views.publicliterature.PublicationDetailItemView"],"stylesheets":[],"_isYUI":true},"similarPublications":{"data":{"publicationListItems":[{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":2094145672,"url":"researcher\/2094145672_Shengli_Song","fullname":"Shengli Song","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2045737986,"url":"researcher\/2045737986_Bin_Xu","fullname":"Bin Xu","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2064607746,"url":"researcher\/2064607746_Zenghui_Li","fullname":"Zenghui Li","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2094179389,"url":"researcher\/2094179389_Jian_Yang","fullname":"Jian Yang","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Jan 2016","journal":"IEEE Geoscience and Remote Sensing Letters","showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/290533653_Ship_Detection_in_SAR_Imagery_via_Variational_Bayesian_Inference","usePlainButton":true,"publicationUid":290533653,"feedStubs":null,"hasFeedStubs":false,"impactPoints":"2.10","url":"publication\/290533653_Ship_Detection_in_SAR_Imagery_via_Variational_Bayesian_Inference","title":"Ship Detection in SAR Imagery via Variational Bayesian Inference","displayTitleAsLink":true,"authors":[{"id":2094145672,"url":"researcher\/2094145672_Shengli_Song","fullname":"Shengli Song","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2045737986,"url":"researcher\/2045737986_Bin_Xu","fullname":"Bin Xu","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2064607746,"url":"researcher\/2064607746_Zenghui_Li","fullname":"Zenghui Li","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2094179389,"url":"researcher\/2094179389_Jian_Yang","fullname":"Jian Yang","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["IEEE Geoscience and Remote Sensing Letters 01\/2016;  DOI:10.1109\/LGRS.2015.2510378"],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/290533653_Ship_Detection_in_SAR_Imagery_via_Variational_Bayesian_Inference","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/290533653_Ship_Detection_in_SAR_Imagery_via_Variational_Bayesian_Inference\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw23_56ab9f6060214"},"id":"rgw23_56ab9f6060214","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=290533653","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":10295979,"url":"researcher\/10295979_Jasper_A_Vrugt","fullname":"Jasper A. Vrugt","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Jan 2016","journal":"Environmental Modelling and Software","showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/284136871_Markov_chain_Monte_Carlo_simulation_using_the_DREAM_software_package_Theory_concepts_and_MATLAB_implementation","usePlainButton":true,"publicationUid":284136871,"feedStubs":null,"hasFeedStubs":false,"impactPoints":"4.42","url":"publication\/284136871_Markov_chain_Monte_Carlo_simulation_using_the_DREAM_software_package_Theory_concepts_and_MATLAB_implementation","title":"Markov chain Monte Carlo simulation using the DREAM software package: Theory, concepts, and MATLAB implementation","displayTitleAsLink":true,"authors":[{"id":10295979,"url":"researcher\/10295979_Jasper_A_Vrugt","fullname":"Jasper A. Vrugt","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["Environmental Modelling and Software 01\/2016; 75:273-316. DOI:10.1016\/j.envsoft.2015.08.013"],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/284136871_Markov_chain_Monte_Carlo_simulation_using_the_DREAM_software_package_Theory_concepts_and_MATLAB_implementation","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/284136871_Markov_chain_Monte_Carlo_simulation_using_the_DREAM_software_package_Theory_concepts_and_MATLAB_implementation\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw24_56ab9f6060214"},"id":"rgw24_56ab9f6060214","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=284136871","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":2054762076,"url":"researcher\/2054762076_Jie_Zhang","fullname":"Jie Zhang","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2085966150,"url":"researcher\/2085966150_Zhuo_Chen","fullname":"Zhuo Chen","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":54051363,"url":"researcher\/54051363_Chuanjiang_Zhou","fullname":"Chuanjiang Zhou","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":33113094,"url":"researcher\/33113094_Xianghui_Kong","fullname":"Xianghui Kong","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Feb 2016","journal":"Biochemical Systematics and Ecology","showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/284811060_Molecular_phylogeny_of_the_subfamily_Schizothoracinae_Teleostei_Cypriniformes_Cyprinidae_inferred_from_complete_mitochondrial_genomes","usePlainButton":true,"publicationUid":284811060,"feedStubs":null,"hasFeedStubs":false,"impactPoints":"0.97","url":"publication\/284811060_Molecular_phylogeny_of_the_subfamily_Schizothoracinae_Teleostei_Cypriniformes_Cyprinidae_inferred_from_complete_mitochondrial_genomes","title":"Molecular phylogeny of the subfamily Schizothoracinae (Teleostei: Cypriniformes: Cyprinidae) inferred from complete mitochondrial genomes","displayTitleAsLink":true,"authors":[{"id":2054762076,"url":"researcher\/2054762076_Jie_Zhang","fullname":"Jie Zhang","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2085966150,"url":"researcher\/2085966150_Zhuo_Chen","fullname":"Zhuo Chen","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":54051363,"url":"researcher\/54051363_Chuanjiang_Zhou","fullname":"Chuanjiang Zhou","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":33113094,"url":"researcher\/33113094_Xianghui_Kong","fullname":"Xianghui Kong","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["Biochemical Systematics and Ecology 02\/2016; 64:6-13. DOI:10.1016\/j.bse.2015.11.004"],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/284811060_Molecular_phylogeny_of_the_subfamily_Schizothoracinae_Teleostei_Cypriniformes_Cyprinidae_inferred_from_complete_mitochondrial_genomes","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/284811060_Molecular_phylogeny_of_the_subfamily_Schizothoracinae_Teleostei_Cypriniformes_Cyprinidae_inferred_from_complete_mitochondrial_genomes\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw25_56ab9f6060214"},"id":"rgw25_56ab9f6060214","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=284811060","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"viewClass":"sidebar","widgetId":"rgw22_56ab9f6060214"},"id":"rgw22_56ab9f6060214","partials":[],"templateName":"publicliterature\/stubs\/SimilarPublications.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.SimilarPublications.html?referencePublicationId=221618878&view=sidebar","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationFulltextPreview":null,"publicationResourcesFulltext":{"data":{"publicationUid":221618878,"publicationResourceList":{"data":{"publicationResourceItems":[{"data":{"publicationUid":221618878,"publicationType":"inProceedings","linkId":"0deec528e576781722000000","fileName":"0deec528e576781722000000.pdf","fileUrl":"profile\/Mingyuan_Zhou\/publication\/221618878_Non-Parametric_Bayesian_Dictionary_Learning_for_Sparse_Image_Representations\/links\/0deec528e576781722000000.pdf","name":"Mingyuan Zhou","nameUrl":"profile\/Mingyuan_Zhou","canRemove":false,"fileIcon":"ico-pub","canPreview":true,"hasPublisherLink":null,"hasMetaData":true,"hide":false,"fulltext":"ico-pub","origin":"publication_list","isLastLink":false,"isUserLink":true,"uploadDate":"May 21, 2014","fileSize":"1.26 MB","widgetId":"rgw28_56ab9f6060214"},"id":"rgw28_56ab9f6060214","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceItem.html","templateExtensions":["generalHelpers"],"attrs":{"fileRequiredPublicationTypes":["code","coverPage","experimentFindings","method","negativeResults","presentation","rawData","researchProposal","workingPaper","artifact","dataset"]},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceItem.html?publicationUid=221618878&linkId=0deec528e576781722000000&hide=0&disableJavascript=disableJavascript&useAlternativeTemplate=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"publicationUid":221618878,"publicationType":"inProceedings","linkId":"024d433a0cf2afadce4c78c9","fileName":"Non-Parametric Bayesian Dictionary Learning for Sparse Image Representations.","fileUrl":"http:\/\/people.ee.duke.edu\/~lcarin\/Mingyuan_nips2009_FINAL.pdf","name":"people.ee.duke.edu","nameUrl":"http:\/\/people.ee.duke.edu\/~lcarin\/Mingyuan_nips2009_FINAL.pdf","canRemove":false,"fileIcon":"ico-pub","canPreview":true,"hasPublisherLink":null,"hasMetaData":true,"hide":false,"fulltext":"ico-pub","origin":"publication_list","isLastLink":false,"isUserLink":false,"widgetId":"rgw29_56ab9f6060214"},"id":"rgw29_56ab9f6060214","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceItem.html","templateExtensions":["generalHelpers"],"attrs":{"fileRequiredPublicationTypes":["code","coverPage","experimentFindings","method","negativeResults","presentation","rawData","researchProposal","workingPaper","artifact","dataset"]},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceItem.html?publicationUid=221618878&linkId=024d433a0cf2afadce4c78c9&hide=0&disableJavascript=disableJavascript&useAlternativeTemplate=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"widgetId":"rgw27_56ab9f6060214"},"id":"rgw27_56ab9f6060214","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceList.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceList.html?publicationUid=221618878&limit=3&disableJavascript=disableJavascript&type=fulltextFile","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"resourceCount":2,"hidden":false,"showMore":false,"fulltext":true,"publicationDownloadCount":{"data":{"value":74,"valueFormatted":"74","widgetId":"rgw30_56ab9f6060214"},"id":"rgw30_56ab9f6060214","partials":[],"templateName":"publicliterature\/stubs\/PublicationDownloadCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDownloadCount.html?publicationUid=221618878","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw26_56ab9f6060214"},"id":"rgw26_56ab9f6060214","partials":[],"templateName":"publicliterature\/stubs\/PublicationResources.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResources.html?publicationUid=221618878&type=fulltextFile&disableJavascript=1","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationResourcesAttachments":{"data":{"publicationUid":221618878,"publicationResourceList":{"data":{"publicationResourceItems":[],"widgetId":"rgw32_56ab9f6060214"},"id":"rgw32_56ab9f6060214","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceList.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceList.html?publicationUid=221618878&limit=3&disableJavascript=disableJavascript&type=attachmentFile","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"resourceCount":0,"hidden":true,"showMore":false,"fulltext":false,"publicationDownloadCount":{"data":{"value":74,"valueFormatted":"74","widgetId":"rgw33_56ab9f6060214"},"id":"rgw33_56ab9f6060214","partials":[],"templateName":"publicliterature\/stubs\/PublicationDownloadCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDownloadCount.html?publicationUid=221618878","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw31_56ab9f6060214"},"id":"rgw31_56ab9f6060214","partials":[],"templateName":"publicliterature\/stubs\/PublicationResources.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResources.html?publicationUid=221618878&type=attachmentFile","viewClass":"views.publicliterature.PublicationResourcesView","yuiModules":["rg.views.publicliterature.PublicationResourcesView"],"stylesheets":[],"_isYUI":true},"publicationText":{"data":{"hide":false,"pages":[{"page":1,"text":"Non-Parametric Bayesian Dictionary Learning for\nSparse Image Representations\n1Mingyuan Zhou1Haojun Chen1John Paisley1Lu Ren2Guillermo Sapiro1Lawrence Carin\n1Department of Electrical and Computer Engineering, Duke University, Durham, NC 27708\n2Department of Electrical and Computer Engineering, University of Minnesota, Minneapolis, MN 55455\n{mz1,hc44,jwp4,lr,lcarin}@ee.duke.edu, {guille}@ece.umn.edu\nAbstract\nNon-parametric Bayesian techniques are considered for learning dictionaries for\nsparse image representations, with applications in denoising, inpainting and com-\npressive sensing (CS). The beta process is employed as a prior for learning the\ndictionary, and this non-parametric method naturally infers an appropriate dic-\ntionary size. The Dirichlet process and a probit stick-breaking process are also\nconsidered to exploit structure within an image. The proposed method can learn\na sparse dictionary in situ; training images may be exploited if available, but they\nare not required. Further, the noise variance need not be known, and can be non-\nstationary. Another virtue of the proposed method is that sequential inference can\nbe readily employed, thereby allowing scaling to large images. Several example\nresults are presented, using both Gibbs and variational Bayesian inference, with\ncomparisons to other state-of-the-art approaches.\n1 Introduction\nThere has been significant recent interest in sparse signal expansions in several settings. For ex-\nample, such algorithms as the support vector machine (SVM) [1], the relevance vector machine\n(RVM) [2], Lasso [3] and many others have been developed for sparse regression (and classifica-\ntion). A sparse representation has several advantages, including the fact that it encourages a simple\nmodel, and therefore over-training is often avoided. The inferred sparse coefficients also often have\nbiological\/physical meaning, of interest for model interpretation [4].\nOf relevance for the current paper, there has recently been significant interest in sparse representa-\ntions in the context of denoising, inpainting [5\u201310], compressive sensing (CS) [11,12], and classifi-\ncation [13]. All of these applications exploit the fact that most images may be sparsely represented\nin an appropriate dictionary. Most of the CS literature assumes \u201coff-the-shelf\u201d wavelet and DCT\nbases\/dictionaries [14], but recent denoising and inpainting research has demonstrated the signif-\nicant advantages of learning an often over-complete dictionary matched to the signals of interest\n(e.g., images) [5\u201310, 12, 15]. The purpose of this paper is to perform dictionary learning using\nnew non-parametric Bayesian technology [16,17], that offers several advantages not found in earlier\napproaches, which have generally sought point estimates.\nThis paper makes four main contributions:\n\u2022 The dictionary is learned using a beta process construction [16,17], and therefore the number of\ndictionary elements and their relative importance may be inferred non-parametrically.\n\u2022 For the denoising and inpainting applications, we do not have to assume a priori knowledge of the\nnoise variance (it is inferred within the inversion). The noise variance can also be non-stationary.\n\u2022 The spatial inter-relationships between different components in images are exploited by use of the\nDirichlet process [18] and a probit stick-breaking process [19].\n\u2022 Using learned dictionaries, inferred off-line or in situ, the proposed approach yields CS perfor-\n1"},{"page":2,"text":"mance that is markedly better than existing standard CS methods as applied to imagery.\n2\nIn traditional sparse coding tasks, one considers a signal x \u2208 ?nand a fixed dictionary D =\n(d1,d2,...,dM) where each dm\u2208 ?n. We wish to impose that any x \u2208 ?nmay be represented\napproximately as \u02c6 x = D\u03b1, where \u03b1 \u2208 ?Mis sparse, and our objective is to also minimize the ?2\nerror ?\u02c6 x\u2212x?2. With a proper dictionary, a sparse \u03b1 often manifests robustness to noise (the model\ndoesn\u2019t fit noise well), and the model also yields effective inference of \u03b1 even when x is partially\nor indirectly observed via a small number of measurements (of interest for inpainting, interpolation\nand compressive sensing [5,7]). To the authors\u2019 knowledge, all previous work in this direction has\nbeen performed in the following manner: (i) if D is given, the sparse vector \u03b1 is estimated via a\npoint estimate (without a posterior distribution), typically based on orthogonal matching pursuits\n(OMP), basis pursuits or related methods, for which the stopping criteria is defined by assuming\nknowledge (or off-line estimation) of the noise variance or the sparsity level of \u03b1; and (ii) when\nthe dictionary D is to be learned, the dictionary size M must be set a priori, and a point estimate\nis achieved for D (in practice one may infer M via cross-validation, with this step avoided in the\nproposed method). In many applications one may not know the noise variance or an appropriate\nsparsity level of \u03b1; further, one may be interested in the confidence of the estimate (e.g., \u201cerror\nbars\u201d on the estimate of \u03b1). To address these goals, we propose development of a non-parametric\nBayesian formulation to this problem, in terms of the beta process, this allowing one to infer the\nappropriate values of M and ?\u03b1?0(sparsity level) jointly, also manifesting a full posterior density\nfunction on the learned D and the inferred \u03b1 (for a particular x), yielding a measure of confidence\nin the inversion. As discussed further below, the non-parametric Bayesian formulation also allows\none to relax other assumptions that have been made in the field of learning D and \u03b1 for denoising,\ninpainting and compressive sensing. Further, the addition of other goals are readily addressed within\nthe non-parametric Bayesian paradigm, e.g. designing D for joint compression and classification.\nDictionary Learning with a Beta Process\n2.1Beta process formulation\nWe desire the model x = D\u03b1+?, where x \u2208 ?nand D \u2208 ?n\u00d7M, and we wish to learn D and in so\ndoing infer M. Toward this end, we consider a dictionary D \u2208 ?n\u00d7K, with K \u2192 \u221e; by inferring\nthe number of columns of D that are required for accurate representation of x, the appropriate\nvalue of M is implicitly inferred (work has been considered in [20,21] for the related but distinct\napplication of factor analysis). We wish to also impose that \u03b1 \u2208 ?Kis sparse, and therefore only\na small fraction of the columns of D are used for representation of a given x. Specifically, assume\nthat we have a training set D = {xi,yi}i=1,N, where xi \u2208 ?nand yi \u2208 {1,2,...,Nc}, where\nNc\u2265 2 represents the number of classes from which the data arise; when learning the dictionary we\nignore the class labels yi, and later discuss how they may be considered in the learning process.\nThe two-parameter beta process (BP) was developed in [17], to which the reader is referred for\nfurther details; we here only provide those details of relevance for the current application. The BP\nwith parameters a > 0 and b > 0, and base measure H0, is represented as BP(a,b,H0), and a draw\nH \u223c BP(a,b,H0) may be represented as\nK\n?\nwith this a valid measure as K \u2192 \u221e. The expression \u03b4\u03c8k(\u03c8) equals one if \u03c8 = \u03c8kand is zero\notherwise. Therefore, H(\u03c8) represents a vector of K probabilities, with each associated with a\nrespective atom \u03c8k. In the limit K \u2192 \u221e, H(\u03c8) corresponds to an infinite-dimensional vector of\nprobabilities, and each probability has an associated atom \u03c8kdrawn i.i.d. from H0.\nUsing H(\u03c8), we may now draw N binary vectors, the ith of which is denoted zi \u2208 {0,1}K,\nand the kth component of ziis drawn zik \u223c Bernoulli(\u03c0k). These N binary column vectors are\nused to constitute a matrix Z \u2208 {0,1}K\u00d7N, with ith column corresponding to zi; the kth row of\nZ is associated with atom \u03c8k, drawn as discussed above. For our problem the atoms \u03c8k\u2208 ?n\nwill correspond to candidate members of our dictionary D, and the binary vector zidefines which\nmembers of the dictionary are used to represent sample xi\u2208 D.\nLet \u03a8 = (\u03c81,\u03c82,...,\u03c8K), and we may consider the limit K \u2192 \u221e. A naive form of our model,\nfor representation of sample xi\u2208 D, is xi= \u03a8zi+ ?i. However, this is highly restrictive, as it\nH(\u03c8) =\nk=1\n\u03c0k\u03b4\u03c8k(\u03c8)\n\u03c0k\u223c Beta(a\/K,b(K \u2212 1)\/K)\n\u03c8k\u223c H0\n(1)\n2"},{"page":3,"text":"imposes that the coefficients of the dictionary expansion must be binary. To address this, we draw\nweights wi\u223c N(0,\u03b3\u22121\nare now \u03b1i = zi\u25e6 wi, and xi = \u03a8\u03b1i+ ?i, where \u25e6 represents the Hadamard (element-wise)\nmultiplication of two vectors. Note that, by construction, \u03b1 is sparse; this imposition of sparseness\nis distinct from the widely used Laplace shrinkage prior [3], which imposes that many coefficients\nare small but not necessarily exactly zero.\nFor simplicity we assume that the dictionary elements, defined by the atoms \u03c8k, are drawn from a\nmultivariate Gaussian base H0, and the components of the error vectors ?iare drawn i.i.d. from a\nzero-mean Gaussian. The hierarchical form of the model may now be expressed as\nwIK), where \u03b3wis the precision or inverse variance; the dictionary weights\nxi\n\u03a8\n=\n=\n\u223c\n\u03a8\u03b1i+ ?i,\n(\u03c81,\u03c82,...,\u03c8K) ,\nN(0,\u03b3\u22121\nK\n?\n\u03b1i= zi\u25e6 wi\n\u03c8k\u223c N(0,n\u22121In)\n?i\u223c N(0,\u03b3\u22121\nwi\nwIK) ,\n? In)\nzi\n\u223c\nk=1\nBernoulli(\u03c0k) ,\u03c0k\u223c Beta(a\/K,b(K \u2212 1)\/K)\n(2)\nNon-informative gamma hyper-priors are typically placed on \u03b3wand \u03b3?. Consecutive elements in\nthe above hierarchical model are in the conjugate exponential family, and therefore inference may\nbe implemented via a variational Bayesian [22] or Gibbs-sampling analysis, with analytic update\nequations (all inference update equations, and the software, will be referenced in a technical report,\nif the paper is accepted). After performing such inference, we retain those columns of \u03a8 that are\nused in the representation of the data in D, thereby inferring D and hence M.\nTo impose our desire that the vector of dictionary weights \u03b1 is sparse, one may adjust the parameters\na and b. Particularly, as discussed in [17], in the limit K \u2192 \u221e, the number of elements of zithat\nare non-zero is a random variable drawn from Poisson(a\/b). In Section 3.1 we discuss the fact that\nthese parameters are in general non-informative and the sparsity is intrinsic to the data.\n2.2Accounting for a classification task\nThere are problems for which it is desired that x is sparsely rendered in D, and the associated\nweight vector \u03b1 may be employed for other purposes beyond representation. For example, one may\nperform a classification task based on \u03b1. If one is interested in joint compression and classification,\nboth goals should be accounted for when designing D. For simplicity, we assume that the number\nof classes is NC= 2 (binary classification), with this readily extended [23] to NC> 2.\nFollowing [9], we may define a linear or bilinear classifier based on the sparse weights \u03b1 and the\nassociated data x (in the bilinear case), with this here implemented in the form of a probit classifier.\nWe focus on the linear model, as it is simpler (has fewer parameters), and the results in [9] demon-\nstrated that it was often as good or better than the bilinear classifier. To account for classification,\nthe model in (2) remains unchanged, and the following may be added to the top of the hierarchy:\nyi= 1 if \u03b8T\u02c6 \u03b1 + \u03bd > 0, yi= 2 if \u03b8T\u02c6 \u03b1 + \u03bd < 0, \u03b8 \u223c N(0,\u03b3\u22121\n\u02c6 \u03b1 \u2208 ?K+1is the same as \u03b1 \u2208 ?Kwith an appended one, to account for the classifier bias. Again,\none typically places (non-informative) gamma hyper-priors on \u03b3\u03b8and \u03b30. With the added layers for\nthe classifier, the conjugate-exponential character of the model is retained, sustaining the ability to\nperform VB or MCMC inference with analytic update equations. Note that the model in (2) may\nbe employed for unlabeled data, and the extension above may be employed for the available labeled\ndata; consequently, all data (labeled and unlabeled) may be processed jointly to infer D.\n\u03b8IK+1), and \u03bd \u223c N(0,\u03b3\u22121\n0), where\n2.3Sequential dictionary learning for large training sets\nIn the above discussion, we implicitly assumed all data D = {xi,yi}i=1,N are used together to\ninfer the dictionary D. However, in some applications N may be large, and therefore such a \u201cbatch\u201d\napproach is undesirable. To address this issue one may partition the data as D = D1\u222a D2\u222a\n...DJ\u22121\u222a DJ, with the data processed sequentially. This issue has been considered for point\nestimates of D [8], in which considerations are required to assure algorithm convergence. It is\nof interest to briefly note that sequential inference is handled naturally via the proposed Bayesian\nanalysis.\n3"},{"page":4,"text":"Specifically, let p(D|D,\u0398) represent the posterior on the desired dictionary, with all other model\nparameters marginalized out (e.g., the sample-dependent coefficients \u03b1); the vector \u0398 represents\nthe model hyper-parameters. In a Bayesian analysis, rather than evaluating p(D|D,\u0398) directly, one\nmay employ the same model (prior) to infer p(D|D1,\u0398). This posterior may then serve as a prior\nfor D when considering next D2, inferring p(D|D1\u222a D2,\u0398). When doing variational Bayesian\n(VB) inference we have an analytic approximate representation for posteriors such as p(D|D1,\u0398),\nwhile for Gibbs sampling we may use the inferred samples. When presenting results in Section 5,\nwe discuss additional means of sequentially accelerating a Gibbs sampler.\n3 Denoising, Inpainting and Compressive Sensing\n3.1\nAssume we are given an image I \u2208 ?Ny\u00d7Nxwith additive noise and missing pixels; we here assume\na monochrome image for simplicity, but color images are also readily handled, as demonstrated\nwhen presenting results. As is done typically [6, 7], we partition the image into NB = (Ny\u2212\nB + 1) \u00d7 (Nx\u2212 B + 1) overlapping blocks {xi}i=1,NB, for each of which xi\u2208 ?B2(B = 8 is\ntypically used). If there is only additive noise but no missing pixels, then the model in (2) can be\nreadily applied for simultaneous dictionary learning and image denoising. If there are both noise\nand missing pixels, instead of directly observing xi, we observe a subset of the pixels in each xi.\nNote that here \u03a8 and {\u03b1i}i=1,NB, which are used to recover the original noise-free and complete\nimage, are directly inferred from the data under test; one may also employ an appropriate training\nset D with which to learn a dictionary D offline, or for initialization of in situ learning.\nIn denoising and inpainting studies of this type (see for example [6,7] and references therein), it\nis often assumed that either the variance is known and used as a \u201cstopping\u201d criteria, or that the\nsparsity level is pre-determined and fixed for all i \u2208 {1,NB}. While these may be practical in\nsome applications, we feel it is more desirable to not make these assumptions. In (2) the noise\nprecision (inverse variance), \u03b3?, is assumed drawn from a non-informative gamma distribution, and\na full posterior density function is inferred for \u03b3?(and all other model parameters). In addition,\nthe problems of addressing spatially nonuniform noise as well as nonuniform noise across color\nchannels are of interest [7]; they are readily handled in the proposed model by drawing a separate\nprecision \u03b3?for each color channel in each B \u00d7 B block, each of which is drawn from a shared\ngamma prior.\nThe sparsity level of the representation in our model, i.e., {?\u03b1i?0}i=1,N, is influenced by the\nparameters a and b in the beta prior in (2). Examining the posterior p(\u03c0k|\u2212) \u223c Beta(a\/K +\n?N\ncussed further in Section 5). Therefore, the average sparsity level of the representation is inferred by\nthe data itself and each sample xihas its own unique sparse representation based on the posterior,\nwhich renders much more flexibility than enforcing the same sparsity level for each sample.\nImage Denoising and Inpainting\ni=1zik,b(K \u2212 1)\/K + N \u2212?N\ni=1zik), conditioned on all other parameters, we find that most\nsettings of a and b tend to be non-informative, especially in the case of sequential learning (dis-\n3.2Compressive sensing\nWe consider CS in the manner employed in [12]. Assume our objective is to measure an image\nI \u2208 ?Ny\u00d7Nx, with this image constituting the 8 \u00d7 8 blocks {xi}i=1,NB. Rather than measuring\nthe xidirectly, pixel-by-pixel, in CS we perform the projection measurement vi = \u03a6xi, where\nvi\u2208 ?Np, with Nprepresenting the number of projections, and \u03a6 \u2208 ?Np\u00d764(assuming that xi\nis represented by a 64-dimensional vector). There are many (typically random) ways in which \u03a6\nmay be constructed, with the reader referred to [24]. Our goal is to have Np? 64, thereby yielding\ncompressive measurements. Based on the CS measurements {vi}i=1,NB, our objective is to recover\n{xi}i=1,NB.\nConsider a potential dictionary \u03a8, as discussed in Section 2. It is assumed that for each of the\n{xi}i=1,NBfrom the image under test xi = \u03a8\u03b1i+ ?i, for sparse \u03b1iand relatively small error\n??i?2. The number of required projections Npneeded for accurate estimation of \u03b1iis proportional\nto ?\u03b1i?0[11], with this underscoring the desirability of learning a dictionary in which very sparse\nrepresentations are manifested (as compared to using an \u201coff-the-shelf\u201d wavelets or DCT basis).\nFor CS inversion, the model in (2) is employed, and therefore the appropriate dictionary D is learned\njointly while performing CS inversion, in situ on the image under test. When performing CS analy-\n4"},{"page":5,"text":"sis, in (2), rather than observing xi, we observe vi= \u03a6D\u03b1i+?i, for i = 1,...,NB(the likelihood\nfunction is therefore modified slightly).\nAs discussed when presenting results, one may also learn the CS dictionary in advance, off-line,\nwith appropriate training images (using the model in (2)). However, the unique opportunity for joint\nCS inversion and learning of an appropriate parsimonious dictionary is deemed to be a significant\nadvantage, as it does not presuppose that one would know an appropriate training set in advance.\nThe inpainting problem may be viewed as a special case of CS, in which each row of \u03a6 corresponds\nto a delta function, locating a unique pixel on the image at which useful (unobscured) data are\nobserved. Those pixels that are unobserved, or that are contaminated (e.g., by superposed text [7])\nare not considered when inferring the \u03b1iand D. A CS camera designed around an inpainting\nconstruction has several advantages, from the standpoint of simplicity. As observed from the results\nin Section 5, an inpainting-based CS camera would simply observe a subset of the usual pixels,\nselected at random.\n4 Exploiting Spatial Structure\nFor the applications discussed above, the {xi}i=1,NBcome from the single image under test, and\nconsequently there is underlying (spatial) structure that should ideally be exploited. Rather than\nre-writing the entire model in (2), we focus on the following equations in the hierarchy: zi \u223c\n?K\nvectors, corresponding to different segments in the image. Since the number of mixture components\nis not known a priori, this mixture model is modeled via a Dirichlet process [18]. We may therefore\nemploy, for i = 1,...,NB,\nk=1Bernoulli(\u03c0k), and \u03c0 \u223c?K\nk=1Beta(a\/K,b(K \u2212 1)\/K). Instead of having a single vector\n\u03c0 = {\u03c01,...,\u03c0K} that is shared for all {xi}i=1,NB, it is expected that there may be a mixture of \u03c0\nzi\u223c\nK\n?\nk=1\nBernoulli(\u03c0ik)\n\u03c0i\u223c GG \u223c DP(\u03b2,\nK\n?\nk=1\nBeta(a\/K,b(K \u2212 1)\/K))\n(3)\nAlternatively, we may cluster the zidirectly, yielding zi\u223c G, G \u223c DP(\u03b2,?K\nment such DP constructions via a truncated stick-breaking representation [25], again retaining the\nconjugate-exponential structure of interest for analytic VB or Gibbs inference. In such an analysis\nwe place a non-informative gamma prior on the precision \u03b2.\nThe construction in (3) clusters the blocks, and therefore it imposes structure not constituted in the\nsimpler model in (2). However, the DP still assumes that the members of {xi}i=1,NBare exchange-\nable. Space limitations preclude discussing this matter in detail here, but we have also considered\nreplacement of the DP framework above with a probit stick-breaking process (PSBP) [19], which\nexplicitly imposes that it is more likely for proximate blocks to be in the same cluster, relative to\ndistant blocks. When presenting results, we show examples in which PSBP has been used, with\nits relative effectiveness compared to the simpler DP construction. The PSBP again retains full\nconjugate-exponential character within the hierarchy, of interest for efficient inference, as discussed\nabove.\nk=1Bernoulli(\u03c0k)),\n\u03c0 \u223c?K\nk=1Beta(a\/K,b(K \u2212 1)\/K), where the ziare drawn i.i.d. from G. In practice we imple-\n5Example Results\nFor the denoising and inpainting results, we observed that the Gibbs sampler provided better perfor-\nmance than associated variational Bayesian inference. For denoising and inpainting we may exploit\nshifted versions of the data, which accelerates convergence substantially (discussed in detail be-\nlow). Therefore, all denoising and inpainting results are based on efficient Gibbs sampling. For CS\nwe cannot exploit shifted images, and therefore to achieve fast inversion variational Bayesian (VB)\ninference [22] is employed; for this application VB has proven to be quite effective, as discussed\nbelow. The same set of model hyper-parameters are used across all our denoising, inpainting and\nCS examples (no tuning was performed): all gamma priors are set as Gamma(10\u22126,10\u22126), along\nthe lines suggested in [2], and the beta distribution parameters are set with a = K and b = N\/8\n(many other settings of a and b yield similar results).\n5"},{"page":6,"text":"5.1\nWe consider denoising a 256\u00d7256 image, with comparison of the proposed approach to K-SVD [6]\n(for which the noise variance is assumed known and fixed); the true noise standard deviation is\nset at 15, 25 and 50 in the examples below. We show results for three algorithms: (i) mismatched\nK-SVD (with noise standard deviation of 30), (ii) K-SVD when the standard deviation is properly\nmatched, and (iii) the proposed BP approach. For (iii) a non-informative prior is placed on the\nnoise precision, and the same BP model is run for all three noise levels (with the underlying noise\nlevels inferred). The BP and K-SVD employed no a priori training data. In Figure 1 are shown\nthe noisy images at the three different noise levels, as well as the reconstructions via BP and K-\nSVD. A preset large dictionary size K = 256 is used for both algorithms, and for the BP results\nwe inferred that approximately M = 219, 143, and 28 dictionary elements were important for noise\nstandard deviations 15, 25, and 50, respectively; the remaining elements of the dictionary were used\nless than 0.1% of the time. As seen within the bottom portion of the right part of Figure 1, the\nunused dictionary elements appear as random draws from the prior, since they are not used and\nhence influenced by the data.\nNote that K-SVD works well when the set noise variance is at or near truth, but the method is un-\ndermined by mismatch. The proposed BP approach is robust to changing noise levels. Quantitative\nperformance is summarized in Table 1. The BP denoiser estimates a full posterior density func-\ntion on the noise standard deviation; for the examples considered here, the modes of the inferred\nstandard-deviation posteriors were 15.52, 25.33, and 48.13, for true standard deviations 15, 25, and\n50, respectively.\nTo achieve these BP results, we employ a sequential implementation of the Gibbs sampler (a batch\nimplementation converges to the same results but with higher computational cost); this is discussed\nin further detail below, when presenting inpainting results.\nDenoising\nFigure 1: Left: Representative denoising results, with the top through bottom rows corresponding to noise\nstandard deviations of 15, 25 and 50, respectively. The second and third columns represent K-SVD [6] results\nwith assumed standard deviation equal to 30 and the ground truth, respectively. The fourth column represents\nthe proposed BP reconstructions. The noisy images are in the first column. Right: Inferred BP dictionary\nelements for noise standard deviation 25, in order of importance (probability to be used) from the top-left.\nTable 1: Peak signal-to-reconstructed image measure (PSNR) for the data in Figure 1, for K-SVD [6] and the\nproposed BP method. The true standard deviation was 15, 25 and 50, respectively, from the top to the bottom\nrow. For the mismatched K-SVD results, the noise stand deviation was fixed at 30.\nOriginal NoisyK-SVD Denoising\nImage (dB)mismatched variance (dB)\n24.58 30.67\n20.19 31.52\n14.56 19.60\nK-SVD Denoising\nmatched variance (dB)\n34.22\n32.08\n27.07\nBeta Process\nDenoising (dB)\n34.19\n31.89\n27.85\n5.2\nOur inpainting and denoising results were achieved by using the following sequential procedure.\nConsider any pixel [p,j], where p,j \u2208 [1,B], and let this pixel constitute the left-bottom pixel in\nInpainting\n6"},{"page":7,"text":"08 162432404856 64\n5\n10\n15\n20\n25\n30\nLearning round\nPSNR\nFigure 2: Inpainting results. The curve shows the PSNR as a function of the B2= 64 Gibbs learning rounds.\nThe left figure is the test image, with 80% of the RGB pixels missing, the middle figure is the result after 64\nafter Gibbs rounds (final result), and the right figure is the original uncontaminated image.\na new B \u00d7 B block. Further, consider all B \u00d7 B blocks with left-bottom pixels at {p + ?B,j +\nmB} \u222a \u03b4(p \u2212 1){Ny\u2212 B + 1,j + mB} \u222a \u03b4(j \u2212 1){p + ?B,Nx\u2212 B + 1} for ? and m that satisfy\np + ?B \u2264 Ny\u2212 B + 1 and j + mB \u2264 Nx\u2212 B + 1. This set of blocks is denoted data set Dpj,\nand considering 1 \u2264 p \u2264 B and 1 \u2264 j \u2264 B, there are a total of B2such shifted data sets. In the\nfirst iteration of learning \u03a8, we employ the blocks in D11, and for this first round we initialize \u03a8\nand \u03b1ibased on a singular value decomposition (SVD) of the blocks in D11(we achieved similar\nresults when \u03a8 was initialized randomly). We do several Gibbs iterations with D11and then stop\nthe Gibbs algorithm, retaining the last sample of \u03a8 and \u03b1ifrom the previous step. These \u03a8 and \u03b1i\nare then used to initialize the Gibbs sampler in the second round, now applied to the B \u00d7 B blocks\nin D11\u222a D21(for D21the neighboring \u03b1iis used for initialization). The Gibbs sampler is now run\non this expanded data for several iterations, the last sample is retained, and the data set is augmented\nagain. This is done B2= 64 times until at the end all shifted blocks are processed simultaneously.\nThis sequential process may be viewed as a sequential Gibbs burn in, after which all of the shifted\nblocks are processed.\nTheoretically, one would expect to need thousands of Gibbs iterations to achieve convergence. How-\never, our experience is that even a single iteration in each of the above B2rounds yields good results.\nIn Figure 2 we show the PSNR as a function of each of the B2= 64 rounds discussed above. For\nGibbs rounds 16, 32 and 64 the corresponding PSNR values were 27.66 dB, 28.22 dB and 28.76\ndB. For this example we used K = 256. This example was considered in [7] (we obtained similar\nresults for the \u201cNew Orleans\u201d image, also considered in [7]); the best results reported there were a\nPSNR of 29.65 dB. However, to achieve those results a training data set was employed for initializa-\ntion [7]; the BP results are achieved with no a priori training data. Concerning computational costs,\nthe inpainting and denoising algorithms scale linearly as a function of the block size, the dictionary\nsize, and the number of training samples; all results reported here were run efficiently in Matlab on\nPCs, with comparable costs as K-SVD.\n5.3Compressive sensing\nWe consider a CS example, in which the image is divided into 8\u00d78 patches, with these constituting\nthe underlying data {xi}i=1,NBto be inferred. For each of the NBblocks, a vector of CS measure-\nments vi= \u03a6xiis measured, where the number of projections per patch is Np, and the total number\nof CS projections is NpNB. In this example the elements of \u03a6 were constructed randomly as draws\nfrom N(0,1), but many other projection classes may be considered [11,24]. Each xiis assumed\nrepresented in terms of a dictionary xi= D\u03b1i+?i, and three constructions for D were considered:\n(i) a DCT expansion; (ii) learning of D using the beta process construction, using training images;\n(iii) using the beta process to perform joint CS inversion and learning of D. For (ii), the training\ndata consisted of 4000 8\u00d78 patches chosen at random from 100 images selected from the Microsoft\ndatabase (http : \/\/research.microsoft.com\/en \u2212 us\/projects\/objectclassrecognition). The\ndictionary was set to K = 256, and the offline beta process inferred a dictionary of size M = 237.\nRepresentative CS reconstruction results are shown in Figure 3, for a gray-scale version of the\n\u201ccastle\u201d image. The inversion results at left are based on a learned dictionary; except for the \u201conline\n7"},{"page":8,"text":"BP\u201d results, all of these results employ the same dictionary D learned off-line as above, and the\nalgorithms are distinguished by different ways of estimating {\u03b1i}i=1,NB. A range of CS-inversion\nalgorithms are considered from the literature, and several BP-based constructions are considered as\nwell for CS inversion. The online BP results are quite competitive with those inferred off-line.\nOne also notes that the results based on a learned dictionary (left in Figure 3) are markedly better\nthan those based on the DCT (right in Figure 3); similar results were achieved when the DCT was\nreplaced by a wavelet representation. For the DCT-based results, note that the DP- and PSBP-based\nBP CS inversion results are significantly better than those of all other CS inversion algorithms.\nThe results reported here are consistent with tests we performed using over 100 images from the\naforementioned Microsoft database, not reported here in detail for brevity.\nNote that CS inversion using the DP-based BP algorithm (as discussed in Section 4) yield the best\nresults, significantly better than BP results not based on the DP, and better than all competing CS\ninversion algorithms (for both learned dictionaries and the DCT). The DP-based results are very\nsimilar to those generated by the probit stick-breaking process (PSBP) [19], which enforces spatial\ninformation more explicitly; this suggests that the simpler DP-based results are adequate, at least\nfor the wide class of examples considered. Note that we also considered the DP and PSBP for\nthe denoising and inpaiting examples above (those results were omitted, for brevity). The DP and\nPSBP denoising and inpainting results were similar to BP results without DP\/PSBP (those presented\nabove); this is attributed to the fact that when performing denoising\/inpainting we may consider\nmany shifted versions of the same image (as discussed when presenting the inpainting results).\nConcerning computational costs, all CS inversions were run efficiently on PCs, with the specifics\ncomputational times dictated by the detailed Matlab implementation and the machine run on. A\nrough ranking of the computational speeds, from fastest to slowest, is as follows: StOMP-CFAR,\nFast BCS, OMP, BP, LARS\/Lasso, Online BP, DP BP, PSBP BP, VB BCS, Basis Pursuit; in this\nlist, algorithms BP through Basis Pursuits have approximately the same computational costs. The\nDP-based BP CS inversion algorithm scales as O(NB\u00b7 Np\u00b7 B2).\n3 3.54 4.5\nNumber of Measurements\nNumber of CS Measurements (x 104)\n5 5.56 6.57 7.5\nx 10\n4\n0\n0.05\n0.1\n0.15\n0.2\n0.25\n0.3\nRelative Reconstruction Error\nPSBP BP\nDP BP\nOnline BP\nBP\nBCS\nFast BCS\nBasis Pursuit\nLARS\/Lasso\nOMP\nSTOMP-CFAR\nRelative Reconstruction Error\n33.5 4 4.5\nNumber of Measurements\nNumber of CS Measurements (x 104)\n5 5.566.5 7 7.5\nx 10\n4\n0.2\n0.25\n0.3\n0.35\n0.4\n0.45\n0.5\nRelative Reconstruction Error\nPSBP BP\nDP BP\nBP\nBCS\nFast BCS\nBasis Pursuit\nLARS\/Lasso\nOMP\nSTOMP-CFAR\nRelative Reconstruction Error\nFigure 3: CS performance (fraction of ?2 error) based on learned dictionaries (left) and based on the DCT\n(right). For the left results, the \u201cOnline BP\u201d results simultaneously learned the dictionary and did CS inversion;\nthe remainder of the left results are based on a dictionary learned offline on a training set. A DCT dictionary\nis used for the results on the right. The underlying image under test is shown at right. Matlab code for Basis\nPursuit, LARS\/Lasso, OMP, STOMP are available at http : \/\/sparselab.stanford.edu\/, and code for BCS\nand Fast BCS are available at http : \/\/people.ee.duke.edu\/ lihan\/cs\/. The horizontal axis represents the\ntotal number of CS projections, NpNB. The total number of pixels in the image is 480 \u00d7 320 = 153,600.\n99.9% of the signal energy is contained in 33,500 DCT coefficients.\n6 Conclusions\nThe non-parametric beta process has been presented for dictionary learning with the goal of image\ndenoising, inpainting and compressive sensing, with very encouraging results relative to the state\nof the art. The framework may also be applied to joint compression-classification tasks, which we\nhave implemented successfully but do not present in detail here because of the paper length. In the\ncontext of noisy underlying data, the noise variance need not be known in advance, and it need not\nbe spatially uniform. The proposed formulation also allows unique opportunities to leverage known\nstructure in the data, such as relative spatial locations within an image; this framework was used to\nachieve marked improvements in CS-inversion quality.\n8"},{"page":9,"text":"References\n[1] N. Cristianini and J. Shawe-Taylor. An Introduction to Support Vector Machines. Cambridge\nUniversity Press, 2000.\n[2] M. Tipping. Sparse Bayesian learning and the relevance vector machine. Journal of Machine\nLearning Research, 1, 2001.\n[3] R. Tibshirani. Regression shrinkage and selection via the lasso. Journal of the Royal Statistical\nSociety, Series B, 58, 1994.\n[4] B.A. Olshausen and D. J. Field. Sparse coding with an overcomplete basis set: A strategy\nemployed by V1? Vision Research, 37, 1998.\n[5] M. Aharon, M. Elad, and A. M. Bruckstein. K-SVD: An algorithm for designing overcomplete\ndictionaries for sparse representation. IEEE Trans. Signal Processing, 54, 2006.\n[6] M. Elad and M. Aharon. Image denoising via sparse and redundant representations over\nlearned dictionaries. IEEE Trans. Image Processing, 15, 2006.\n[7] J. Mairal, M. Elad, and G. Sapiro. Sparse representation for color image restoration. IEEE\nTrans. Image Processing, 17, 2008.\n[8] J. Mairal, F. Bach, J. Ponce, and G. Sapiro. Online dictionary learning for sparse coding. In\nProc. International Conference on Machine Learning, 2009.\n[9] J. Mairal, F. Bach, J. Ponce, G. Sapiro, and A. Zisserman. Supervised dictionary learning. In\nProc. Neural Information Processing Systems, 2008.\n[10] M. Ranzato, C. Poultney, S. Chopra, and Y. Lecun. Efficient learning of sparse representations\nwith an energy-based model. In Proc. Neural Information Processing Systems, 2006.\n[11] E. Cand` es and T. Tao. Near-optimal signal recovery from random projections: universal en-\ncoding strategies? IEEE Trans. Information Theory, 52, 2006.\n[12] J.M.Duarte-CarvajalinoandG.Sapiro. Learningtosensesparsesignals: Simultaneoussensing\nmatrix and sparsifying dictionary optimization. IMA Preprint Series 2211, 2008.\n[13] J. Wright, A.Y. Yang, A. Ganesh, S.S. Sastry, and Y. Ma. Robust face recognition via sparse\nrepresentation. IEEE Trans. Pattern Analysis Machine Intelligence, 31, 2009.\n[14] S. Ji, Y. Xue, and L. Carin. Bayesian compressive sensing. IEEE Trans. Signal Processing,\n56, 2008.\n[15] R. Raina, A. Battle, H. Lee, B. Packer, and A.Y. Ng. Self-taught learning: transfer learning\nfrom unlabeled data. In Proc. International Conference on Machine Learning, 2007.\n[16] R. Thibaux and M.I. Jordan. Hierarchical beta processes and the indian buffet process. In Proc.\nInternational Conference on Artificial Intelligence and Statistics, 2007.\n[17] J. Paisley and L. Carin. Nonparametric factor analysis with beta process priors. In Proc.\nInternational Conference on Machine Learning, 2009.\n[18] T. Ferguson. A Bayesian analysis of some nonparametric problems. Annals of Statistics, 1,\n1973.\n[19] A. Rodriguez and D.B. Dunson. Nonparametric bayesian models through probit stickbreaking\nprocesses. Univ. California Santa Cruz Technical Report, 2009.\n[20] D. Knowles and Z. Ghahramani. Infinite sparse factor analysis and infinite independent com-\nponents analysis. In Proc. International Conference on Independent Component Analysis and\nSignal Separation, 2007.\n[21] P. Rai and H. Daum\u00b4 e III. The infinite hierarchical factor regression model. In Proc. Neural\nInformation Processing Systems, 2008.\n[22] M.J. Beal. Variational Algorithms for Approximate Bayesian Inference. PhD thesis, Gatsby\nComputational Neuroscience Unit, University College London, 2003.\n[23] M. Girolami and S. Rogers. Variational Bayesian multinomial probit regression with Gaussian\nprocess priors. Neural Computation, 18, 2006.\n[24] R.G. Baraniuk. Compressive sensing. IEEE Signal Processing Magazine, 24, 2007.\n[25] J. Sethuraman. A constructive definition of Dirichlet priors. Statistica Sinica, 4, 1994.\n9"}],"fullTextUrl":"https:\/\/www.researchgate.net\/profile\/Mingyuan_Zhou\/publication\/221618878_Non-Parametric_Bayesian_Dictionary_Learning_for_Sparse_Image_Representations\/links\/0deec528e576781722000000.pdf","widgetId":"rgw34_56ab9f6060214"},"id":"rgw34_56ab9f6060214","partials":[],"templateName":"publicliterature\/stubs\/PublicationText.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationText.html?publicationUid=221618878&hide=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationDetailAd":{"data":{"googleDfpSlot":null,"widgetId":"rgw35_56ab9f6060214"},"id":"rgw35_56ab9f6060214","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAd.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAd.html?publicationUid=221618878&slotId=336x280_Publications_ATF_Right&collapseSlotMode=never&fallbackContainerEnabled=1","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationRelations":null,"publicationRelationsReverse":null,"publicationUid":221618878,"showSignUpDialog":false,"selectNewSignUpDialog":false,"publicationQuestions":null,"publicationCitations":null,"publicationReviewPromo":null,"publicationUsedInReviews":null,"publicationPdfJsReader":{"data":{"isPreview":false,"licenseUrl":null,"licenseInfo":null,"defaultLinkData":{"linkId":"0deec528e576781722000000","name":"Mingyuan Zhou","date":null,"nameLink":"profile\/Mingyuan_Zhou","filename":"","downloadLink":"https:\/\/www.researchgate.net\/profile\/Mingyuan_Zhou\/publication\/221618878_Non-Parametric_Bayesian_Dictionary_Learning_for_Sparse_Image_Representations\/links\/0deec528e576781722000000.pdf?inViewer=0&pdfJsDownload=0&origin=publication_detail","viewerUrl":"https:\/\/www.researchgate.net\/profile\/Mingyuan_Zhou\/publication\/221618878_Non-Parametric_Bayesian_Dictionary_Learning_for_Sparse_Image_Representations\/links\/0deec528e576781722000000.pdf?inViewer=1&pdfJsDownload=1&origin=publication_detail","downloadHash":"590a920fa29be79737378e2b966f2be3","showFileSizeNote":false,"fileSize":"1.26 MB","noFollow":false,"isDefault":true,"doi":null},"displayableLinks":[{"linkId":"0deec528e576781722000000","name":"Mingyuan Zhou","date":null,"nameLink":"profile\/Mingyuan_Zhou","filename":"","downloadLink":"https:\/\/www.researchgate.net\/profile\/Mingyuan_Zhou\/publication\/221618878_Non-Parametric_Bayesian_Dictionary_Learning_for_Sparse_Image_Representations\/links\/0deec528e576781722000000.pdf?inViewer=0&pdfJsDownload=0&origin=publication_detail","viewerUrl":"https:\/\/www.researchgate.net\/profile\/Mingyuan_Zhou\/publication\/221618878_Non-Parametric_Bayesian_Dictionary_Learning_for_Sparse_Image_Representations\/links\/0deec528e576781722000000.pdf?inViewer=1&pdfJsDownload=1&origin=publication_detail","downloadHash":"590a920fa29be79737378e2b966f2be3","showFileSizeNote":false,"fileSize":"1.26 MB","noFollow":false,"isDefault":true,"doi":null}],"hasDisplayableLinks":false,"reader":{"data":{"pdfCommentsActive":false,"publicationType":"Conference Paper","onlyRenderFirstPage":false,"readMoreExperimentGoal":"goalPublicationPdfClicksReadMore","readMoreExperimentViewId":null,"comments":null,"figures":[],"figureAssetIds":[],"figureOverlayUrls":{"clickOnOverlay":"publication.PublicationFigures.html?_sg=-3mTgK0JeUDtUPcB3SqVEqTMR8ceGIvKT_2_uo_EoB6CzXg8rIL6PkN7cJ80NqVkYRq8taV1pNc46DPp3UMiDA.x2ortBLkJf2SL1j9dohCpNBG1wZM1uS_8wWLbHk8sVhOT608OijWM7E5YeCqr6tJYK3goJrooZNea5GqI6GrbQ","clickOnPill":"publication.PublicationFigures.html?_sg=yooHbRooSOxyzGrK0VCDRZRZZzl0TtpSHfTgJNleBOh8vbPgfomfjWjo442GmD4R0HmxoTPuda1VligkdBbA9g.WEWOE1L1pJO3z7vRi8cQev3sqwyQEu2KFNupm_hAY09gr4eWOnUTdGpARJiFH67HLDc6KaD1_VG_sS92tyA5Tw"},"canSelect":false,"javascriptPath":"https:\/\/www.researchgate.net\/c\/o1q2er\/","downloadUrl":"https%3A%2F%2Fwww.researchgate.net%2Fprofile%2FMingyuan_Zhou%2Fpublication%2F221618878_Non-Parametric_Bayesian_Dictionary_Learning_for_Sparse_Image_Representations%2Flinks%2F0deec528e576781722000000.pdf%3FinViewer%3D1%26pdfJsDownload%3D1%26origin%3Dpublication_detail","viewerUrl":"https:\/\/www.researchgate.net\/c\/o1q2er\/javascript\/lib\/pdfjs\/web\/viewer.html","commentEndpoint":"https:\/\/www.researchgate.net\/rgformat\/api\/comment","experimentEndpoint":"https:\/\/www.researchgate.net\/rgformat\/api\/experiment?key=8-32TvF9unDOsfaNwqWVwZA6Hit2-4hb3vBsYi3NTW7vojEXXrkFf9ydXdY5emXOh0WWWxP3o1uNx3CkbCa43w","urlHash":"86a7a6df9432963e7b68ace0586ab9a2","downloadTrackUrl":"application.PdfJsReader.ajaxTrackDownload.html?msrp=nT5M23Xgr8DOyprPOGt2OYZdCz2kpw2mpM14HulX-0KisUZAgd8KlEHs_AYPPzi6IKYfYxL0qT5VCvTu-DOr2aQC85rwo9r1xhTRSMJkt1c.7hEttB0_vc1MQBPbcGHj4hd_FRhN-pvfZFT5N3b-VrHF9E_LacmP1GtObJwqD5PNK0mG5QYSOCaHy1W-1TOwPA.Vh2Nc39PJqLYRPEYdSd8pGqjpip-7YL3lIPz0I-aAaKXf0mAvGJ0wM1-QRhalHdGwoOvk-2KGxh1RT7CwWPkbA","viewportMilestoneTrackUrl":"application.PdfJsReader.ajaxTrackViewportMilestone.html","linkId":"0deec528e576781722000000","trackedDownloads":{"0deec528e576781722000000":{"v":false,"d":false}},"assetId":"AS:99311618625536@1400689143064","readerDocId":null,"assetType":"fulltext","interactionType":{"comment":"comment","highlight":"highlight"},"publicationUid":221618878,"commentCursorPromo":null,"widgetId":"rgw37_56ab9f6060214"},"id":"rgw37_56ab9f6060214","partials":[],"templateName":"application\/stubs\/PdfJsReader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PdfJsReader.html?fileHref=https%3A%2F%2Fwww.researchgate.net%2Fprofile%2FMingyuan_Zhou%2Fpublication%2F221618878_Non-Parametric_Bayesian_Dictionary_Learning_for_Sparse_Image_Representations%2Flinks%2F0deec528e576781722000000.pdf%3FinViewer%3D1%26pdfJsDownload%3D1%26origin%3Dpublication_detail&assetId=AS%3A99311618625536%401400689143064&publicationUid=221618878&linkId=0deec528e576781722000000&onlyShowFirstPage=0","viewClass":null,"yuiModules":["css-pow-application-PdfJsReader"],"stylesheets":["pow\/application\/PdfJsReader.css"],"_isYUI":true},"showHeader":true,"title":"Non-Parametric Bayesian Dictionary Learning for Sparse Image Representations.","publicationType":"Conference Paper","downloadTrackUrl":"publicliterature.PublicationInlineReader.ajaxTrackDownload.html?msrp=WpjlV5DkJDL1O52eFJM4Q2W__v4brjJrQvOkWSJCxwUAvyP0oIupc9hVBnlP4IpU_W952oHyqhAq4Ltt2n_2hMuPkPl6xYb7T_GszGbtvWw.cN4kLbV6gab6GUeMXerWM4pCyyJWSxRLSlfNlm9AJ82MPAYskpiyHXMWToG38bwmbUGeyyZfnhaADf5So0Y7Gg.8ZhtvT3U1-VE8sAR_IVyXYZVxF544F9XPEO4xV0-lilOc5mmj2YFvbyeEl5I7a4Gy2YQ51aaS3EvphcKMjKZ0Q","publicationUid":221618878,"trackedDownloads":{"0deec528e576781722000000":{"v":false,"d":false}},"inlinePdf":false,"publicationComments":null,"showDownloadButton":true,"socialShare":{"data":{"shareItems":[{"data":{"name":"Facebook","url":"http:\/\/www.facebook.com\/share.php?u={{url}}{{#title}}&t={{title}}{{\/title}}","width":600,"height":350,"useUtmTags":true,"utmSource":"facebook","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareFacebook.ajaxTrackSocialShare.html","widgetId":"rgw39_56ab9f6060214"},"id":"rgw39_56ab9f6060214","partials":{"shareIcon":"application\/stubs\/partials\/shareFacebookBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareFacebook.html?provider=Facebook&shareIcon=shareIconBlog&utmSource=facebook&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"Twitter","url":"http:\/\/twitter.com\/intent\/tweet?text={{#title}}{{title}}: {{\/title}}{{url}}&via=researchgate","width":600,"height":350,"useUtmTags":true,"utmSource":"twitter","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareTwitter.ajaxTrackSocialShare.html","widgetId":"rgw40_56ab9f6060214"},"id":"rgw40_56ab9f6060214","partials":{"shareIcon":"application\/stubs\/partials\/shareTwitterBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareTwitter.html?provider=Twitter&shareIcon=shareIconBlog&utmSource=twitter&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"Google+","url":"https:\/\/plus.google.com\/share?url={{url}}","width":600,"height":600,"useUtmTags":true,"utmSource":"googleplus","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareGooglePlus.ajaxTrackSocialShare.html","widgetId":"rgw41_56ab9f6060214"},"id":"rgw41_56ab9f6060214","partials":{"shareIcon":"application\/stubs\/partials\/shareGooglePlusBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareGooglePlus.html?provider=Google%2B&shareIcon=shareIconBlog&utmSource=googleplus&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"LinkedIn","url":"http:\/\/www.linkedin.com\/shareArticle?mini=true&url={{url}}{{#title}}&title={{title}}{{\/title}}&source=ResearchGate","width":520,"height":570,"useUtmTags":true,"utmSource":"linkedin","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareLinkedIn.ajaxTrackSocialShare.html","widgetId":"rgw42_56ab9f6060214"},"id":"rgw42_56ab9f6060214","partials":{"shareIcon":"application\/stubs\/partials\/shareLinkedInBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareLinkedIn.html?provider=LinkedIn&shareIcon=shareIconBlog&utmSource=linkedin&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"Reddit","url":"https:\/\/www.reddit.com\/submit?url={{url}}{{#title}}&title={{title}}{{\/title}}","width":600,"height":600,"useUtmTags":true,"utmSource":"reddit","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareReddit.ajaxTrackSocialShare.html","widgetId":"rgw43_56ab9f6060214"},"id":"rgw43_56ab9f6060214","partials":{"shareIcon":"application\/stubs\/partials\/shareRedditBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareReddit.html?provider=Reddit&shareIcon=shareIconBlog&utmSource=reddit&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true}],"widgetId":"rgw38_56ab9f6060214"},"id":"rgw38_56ab9f6060214","partials":[],"templateName":"application\/stubs\/SocialShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.SocialShare.html?campaign=shareFullTextPublication&trackClick=1&shareIcon=shareIconBlog","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw36_56ab9f6060214"},"id":"rgw36_56ab9f6060214","partials":[],"templateName":"publicliterature\/stubs\/PublicationInlineReader.html","templateExtensions":["generalHelpers"],"attrs":{"showFulltextDownloadedSignupDialog":true,"preSignUpDialogContext":null,"requestFulltext":false},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationInlineReader.html","viewClass":"views.publicliterature.PublicationInlineReaderView","yuiModules":["rg.views.publicliterature.PublicationInlineReaderView","css-pow-publicliterature-PublicationInlineReader"],"stylesheets":["pow\/publicliterature\/PublicationInlineReader.css"],"_isYUI":true},"useFulltextOptimizedLayout":false,"publicationActions":null,"requestFulltextPromo":null,"currentUrl":"publication\/221618878_Non-Parametric_Bayesian_Dictionary_Learning_for_Sparse_Image_Representations","isLeaderboardAd":false,"enableStickyBox":null,"googleDfpSlotMobileBottom":null,"fullTextExitPopup":null,"showExitPopupDialog":false,"widgetId":"rgw2_56ab9f6060214"},"id":"rgw2_56ab9f6060214","partials":{"romeo_legal_notice":"publicliterature\/stubs\/partials\/romeo_legal_notice.html"},"templateName":"publicliterature\/stubs\/PublicPublicationDetails_NewLayout.html","templateExtensions":["generalHelpers"],"attrs":{"publicationUid":221618878},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicPublicationDetailsOld.html?publicationUid=221618878&isTestOldDesign=0","viewClass":"views.publicliterature.PublicPublicationDetailsOldView","yuiModules":["rg.views.publicliterature.PublicPublicationDetailsOldView"],"stylesheets":[],"_isYUI":true},"widgetId":"rgw1_56ab9f6060214"},"id":"rgw1_56ab9f6060214","partials":[],"templateName":"publicliterature\/stubs\/PublicPublicationDetails.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicPublicationDetails.html","viewClass":"views.publicliterature.PublicPublicationDetailsView","yuiModules":["rg.views.publicliterature.PublicPublicationDetailsView"],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"uaClass":"","headPrefix":[],"rootUrl":"https:\/\/www.researchgate.net\/","requestToken":"T1vG3ASoTpAp\/mmFJSSSDa5rjwl7ftvGYJsIkk7HfnKsvMgDfKfYBmYW+oj+iBl0fID3CX4oc+PPPVlb4BZ017s\/UnwgOIIIEHMRixPkut3mc1I8GEpXSHOvBDfCKWO8iOinMWU2x3DlcKuQJ0qDuBln9aYkIYyWI2nCGWAFfWO0Q9nvpw2gAaGW\/YMHReOeFgQ4drie00WPtgb6PvZrGKwRkdYaK0Zj+Nb3HzFe8bQaTt7xsffwCHyiGtN3p179xH9Ae\/YA0Y\/KY2evyBUMlw5AOvXPkbP6IR3tWmu9iZA=","faviconCdnUrl":"https:\/\/c5.rgstatic.net\/m\/2390829798215018\/images\/favicon.ico","headerOutput":"<noscript><\/noscript><link rel=\"canonical\" href=\"https:\/\/www.researchgate.net\/publication\/221618878_Non-Parametric_Bayesian_Dictionary_Learning_for_Sparse_Image_Representations\" \/>\n<link rel=\"dns-prefetch\" href=\"\/\/c5.rgstatic.net\" \/>\n<link rel=\"dns-prefetch\" href=\"\/\/i1.rgstatic.net\" \/>\n<meta property=\"twitter:card\" content=\"summary\" \/>\n<meta property=\"twitter:site\" content=\"@ResearchGate\" \/>\n<meta property=\"og:title\" content=\"Non-Parametric Bayesian Dictionary Learning for Sparse Image Representations.\" \/>\n<meta property=\"og:description\" content=\"Non-parametric Bayesian techniques are considered for learning dictionaries for sparse image representations, with applications in denoising, inpainting and com- pressive sensing (CS). The beta...\" \/>\n<meta property=\"og:site_name\" content=\"ResearchGate\" \/>\n<meta property=\"og:image\" content=\"https:\/\/i1.rgstatic.net\/publication\/221618878_Non-Parametric_Bayesian_Dictionary_Learning_for_Sparse_Image_Representations\/links\/0deec528e576781722000000\/smallpreview.png\" \/>\n<meta property=\"og:url\" content=\"https:\/\/www.researchgate.net\/publication\/221618878_Non-Parametric_Bayesian_Dictionary_Learning_for_Sparse_Image_Representations\" \/>\n<meta property=\"rg:id\" content=\"PB:221618878\" \/>\n<meta name=\"DC.identifier\" scheme=\"DCTERMS.URI\" content=\"http:\/\/dx.doi.org\/\" \/>\n<meta name=\"gs_meta_revision\" content=\"1.1\" \/>\n<meta name=\"citation_title\" content=\"Non-Parametric Bayesian Dictionary Learning for Sparse Image Representations.\" \/>\n<meta name=\"citation_author\" content=\"Mingyuan Zhou\" \/>\n<meta name=\"citation_author\" content=\"Haojun Chen\" \/>\n<meta name=\"citation_author\" content=\"John William Paisley\" \/>\n<meta name=\"citation_author\" content=\"Lu Ren\" \/>\n<meta name=\"citation_author\" content=\"Guillermo Sapiro\" \/>\n<meta name=\"citation_author\" content=\"Lawrence Carin\" \/>\n<meta name=\"citation_conference_title\" content=\"Advances in Neural Information Processing Systems 22: 23rd Annual Conference on Neural Information Processing Systems 2009. Proceedings of a meeting held 7-10 December 2009, Vancouver, British Columbia, Canada.\" \/>\n<meta name=\"citation_publication_date\" content=\"2009\/01\/01\" \/>\n<meta name=\"citation_firstpage\" content=\"2295\" \/>\n<meta name=\"citation_lastpage\" content=\"2303\" \/>\n<meta name=\"citation_pdf_url\" content=\"https:\/\/www.researchgate.net\/profile\/Mingyuan_Zhou\/publication\/221618878_Non-Parametric_Bayesian_Dictionary_Learning_for_Sparse_Image_Representations\/links\/0deec528e576781722000000.pdf\" \/>\n<meta name=\"citation_abstract_html_url\" content=\"https:\/\/www.researchgate.net\/publication\/221618878_Non-Parametric_Bayesian_Dictionary_Learning_for_Sparse_Image_Representations\" \/>\n<meta name=\"citation_fulltext_html_url\" content=\"https:\/\/www.researchgate.net\/publication\/221618878_Non-Parametric_Bayesian_Dictionary_Learning_for_Sparse_Image_Representations\" \/>\n<meta name=\"viewport\" content=\"width=device-width,initial-scale=1\" \/>\n<link href=\"\/\/c5.rgstatic.net\/m\/22664197317151888\/styles\/rg.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/21004998181197492\/styles\/rg2.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<!--[if lt IE 9]><link href=\"\/\/c5.rgstatic.net\/m\/238176252723686\/styles\/ie.css\" type=\"text\/css\" rel=\"stylesheet\"\/><![endif]-->\n<link href=\"\/\/c5.rgstatic.net\/m\/217752362214895\/styles\/modules\/publicprofile.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/21993347442549\/styles\/pow\/publicliterature\/FollowPublicationPromo.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/282514599719602\/styles\/pow\/application\/PdfJsReader.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/23819663151220\/styles\/pow\/publicliterature\/PublicationInlineReader.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<script src=\"\/\/c5.rgstatic.net\/m\/2321000301012716\/javascript\/vendor\/webfontloader\/webfontloader.js\" type=\"text\/javascript\"><\/script>\n <script>(function(i,s,o,g,r,a,m){i[\"GoogleAnalyticsObject\"]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,\"script\",\"\/\/www.google-analytics.com\/analytics.js\",\"ga\");\n ga(\"create\",\"UA-58591210-1\");ga(\"set\",\"anonymizeIp\",true);ga('set', 'dimension1', 'publication full-text');ga('set', 'dimension2', 'Conference Paper');ga('set', 'dimension3', 'Logged out');ga('set', 'dimension4', 'https');ga(\"send\",\"pageview\");<\/script>\n","webfont":"<noscript><\/noscript><script> WebFontConfig = { custom: { families: ['source_sans_pro_italic', 'source_sans_pro_bold', 'source_sans_pro', 'martel'], urls : ['\/\/c5.rgstatic.net\/m\/231392577336386\/styles\/fonts.css'] } }; WebFont.load(WebFontConfig); <\/script>\n","correlationId":"rgreq-323eba07-67d5-4b66-888c-4a74f0d5e95e","accountId":null,"module":"publicliterature","action":"publicliterature.PublicPublicationDetails","page":"publicationDetail","product":"publications","backendTime":583,"continent":"Asia","stylesHome":"\/\/c5.rgstatic.net\/m\/","staticHost":"c5.rgstatic.net","useEarlyFlush":false,"longRunningRequestIdentifier":"LongRunningRequest.publicliterature.PublicPublicationDetails","longRunningRequestFp":"e9e5bbe1366c7ee8c8e41d02f793c884ac9be19b","widgetId":"rgw44_56ab9f6060214"},"id":"rgw44_56ab9f6060214","partials":[],"templateName":"application\/stubs\/StaticHeader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.StaticHeader.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){
            Y.rg.core.pagespeed.Monitoring.monitorPage("\/\/glassmoni.researchgate.net", "publicliterature.PublicPublicationDetails.run.html.loggedOut.get", "59de9668d07aeb77ab4de5f24d382b5d199d2437", "rgreq-323eba07-67d5-4b66-888c-4a74f0d5e95e", "64aa04ee8d27d7b7fdeca4b11ab2f98d8de53b50");
        
            Y.rg.core.pagespeed.Monitoring.monitorPage("\/\/glassmoni.researchgate.net", "publicationDetail.loggedOut", "ed1993d9e20f6cefa83edacaa24401a18c071aea", "rgreq-323eba07-67d5-4b66-888c-4a74f0d5e95e", "64aa04ee8d27d7b7fdeca4b11ab2f98d8de53b50");
        })();
(function(){Y.rg.createInitialWidget({"data":{"year":"2016","inlinePromo":null,"isAdmin":false,"contactUrl":"https:\/\/www.researchgate.net\/contact","aboutUsUrl":"https:\/\/www.researchgate.net\/about","widgetId":"rgw45_56ab9f6060214"},"id":"rgw45_56ab9f6060214","partials":[],"templateName":"application\/stubs\/DefaultFooter.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.DefaultFooter.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"headerLogin":{"data":{"urlAfterLogin":"publication\/221618878_Non-Parametric_Bayesian_Dictionary_Learning_for_Sparse_Image_Representations","requestToken":"dNT2UI6m9MfJ7x56X\/R79G5V0NpIIW+3F\/I5OyzXniMLOaDHt+EM2ogv5nM6gRsPIlqM\/gXioxHs7E+N\/G\/NhKT6cZVy7T+QaJm3Hm1Yq3UmjFKjnedRaSFxuG2DjdZ\/iB3VJYd1Lm6\/xpI9cReDAhb5VCgi8xGJ2F0qYDzmZ0\/sTJB9Pp5RkaFVJPiJYjGckaJLgQQaS2FCEaTGNfvTzAl1sAZpqSNbusuJAzE6Mnkr5RV4zG+Gw\/5BOJh1JuIj68IgPfYoisnWSaXQkpaYfqbz1jwE39l\/+3KoeNN02BE=","loginUrl":"https:\/\/www.researchgate.net\/application.Login.html","signupUrl":"https:\/\/www.researchgate.net\/signup.SignUp.html?ev=su_chnl_index&hdrsu=1&_sg=0k4-3N_nDASf6ZTm0qCtlly36ZmlqjUBM6qAz5Il62hhrytU8pj_DsyY-6erZNnb","encodedUrlAfterLogin":"cHVibGljYXRpb24vMjIxNjE4ODc4X05vbi1QYXJhbWV0cmljX0JheWVzaWFuX0RpY3Rpb25hcnlfTGVhcm5pbmdfZm9yX1NwYXJzZV9JbWFnZV9SZXByZXNlbnRhdGlvbnM%3D","signupCallToAction":"Join for free","widgetId":"rgw47_56ab9f6060214"},"id":"rgw47_56ab9f6060214","partials":{"partial":"application\/stubs\/partials\/headerLoginDefault.html"},"templateName":"application\/stubs\/HeaderLogin.html","templateExtensions":[],"attrs":{"goal":"milestoneHeaderLoginSeen"},"widgetUrl":"https:\/\/www.researchgate.net\/application.HeaderLogin.html","viewClass":"views.application.HeaderLoginView","yuiModules":["rg.views.application.HeaderLoginView"],"stylesheets":[],"_isYUI":true},"cookieConsent":null,"logoSvgSrc":"https:\/\/c5.rgstatic.net\/m\/235107188705592\/images\/template\/brand-header-logo.svg","logoFallbackSrc":"https:\/\/c5.rgstatic.net\/m\/238113351022438\/images\/template\/brand-header-logo.png","widgetId":"rgw46_56ab9f6060214"},"id":"rgw46_56ab9f6060214","partials":{"schemaSocialProfiles":"application\/stubs\/partials\/schemaSocialProfiles.html"},"templateName":"application\/stubs\/HeaderLoggedOut.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.HeaderLoggedOut.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"logEvent":"su_banner","specialCopy":false,"widgetId":"rgw48_56ab9f6060214"},"id":"rgw48_56ab9f6060214","partials":[],"templateName":"application\/stubs\/LoggedOutBanner.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.LoggedOutBanner.html","viewClass":"views.application.LoggedOutBannerView","yuiModules":["rg.views.application.LoggedOutBannerView"],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.core.util.ParameterFilter.filter(["ev","cp","ch","ref","dbw","pli","loginT","uid","claimChannel","enrichId","enrichSource","utm_source","utm_medium","utm_campaign","el","ci"]);})();
});}); } else { throw 'YRG was not loaded when attaching widgets'; }</script><script> dataLayer = [{"pageCategory":"publication full-text","publicationType":"Conference Paper","eventCategory":"Publication page"}]; </script> <noscript><iframe src="//www.googletagmanager.com/ns.html?id=GTM-MKVKH7" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-MKVKH7');</script><script>(function(e){function n(n,t,o,a){"use strict";var i=e.document.createElement("link"),r=t||e.document.getElementsByTagName("script")[0],d=e.document.styleSheets;return i.rel="stylesheet",i.href=n,i.media="only x",a&&(i.onload=a),r.parentNode.insertBefore(i,r),i.onloadcssdefined=function(e){for(var t,o=0;d.length>o;o++)d[o].href&&d[o].href.indexOf(n)>-1&&(t=!0);t?e():setTimeout(function(){i.onloadcssdefined(e)})},i.onloadcssdefined(function(){i.media=o||"all"}),i}function t(e,n){e.onload=function(){e.onload=null,n&&n.call(e)},"isApplicationInstalled"in navigator&&"onloadcssdefined"in e&&e.onloadcssdefined(n)}var o=function(a,i){"use strict";if(a&&3===a.length){var r=e.Image,d=!(!document.createElementNS||!document.createElementNS("http://www.w3.org/2000/svg","svg").createSVGRect||!document.implementation.hasFeature("http://www.w3.org/TR/SVG11/feature#Image","1.1")||e.opera&&-1===navigator.userAgent.indexOf("Chrome")||-1!==navigator.userAgent.indexOf("Series40")),c=new r;c.onerror=function(){o.method="png",o.href=a[2],n(a[2])},c.onload=function(){var e=1===c.width&&1===c.height,r=a[e&&d?0:e?1:2];o.method=e&&d?"svg":e?"datapng":"png",o.href=r,t(n(r),i)},c.src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///ywAAAAAAQABAAACAUwAOw==",document.documentElement.className+=" grunticon"}};o.loadCSS=n,o.onloadCSS=t,e.grunticon=o})(this);grunticon(["https://c5.rgstatic.net/c/o1q2er/styles/icons/_header-ico.svg.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_header-ico.png.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_header-ico.fallback.scss"]);grunticon(["https://c5.rgstatic.net/c/o1q2er/styles/icons/_admin-ico.svg.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_admin-ico.png.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_admin-ico.fallback.scss"]);grunticon(["https://c5.rgstatic.net/c/o1q2er/styles/icons/_ico.svg.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_ico.png.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_ico.fallback.scss"]);</script></body>
</html>
