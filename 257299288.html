<!DOCTYPE html> <html lang="en" class="" id="rgw28_56aba263ae6b7"> <head > <meta charset="utf-8"/> <meta http-equiv="content-type" content="text/html; charset=UTF-8"/> <meta name="Rg-Request-Token" id="Rg-Request-Token" content="HsyHixcmd/IkWe1f7uBqNMG0qPyarIwAHyEX4eVuHJELLH8BqzzsfrPaoqkZjeHOo7vb2wZz+QJ+EwDT4q4qLIcSAZyc3nUua5ysGzVFWVLCatXL2IQrY5LFiq3/gnbFoyozLcqPDwFdEkyn9WeJn+VxtyhlgHgqLtjV+sCxm2j4/Dw05sQBmoY87uRgwmSKc/p4t9N7l8xEihrXZmPC51Sih/FH+lsoP3PmMfianCvGE/jnJA5IgWRk8/owjO1wJ1/L4e2WYWxuH2uiXi8guI6sTzDyi11upmx61k5476c="/> <meta http-equiv="expires" content="0"/> <link rel="apple-touch-icon" sizes="57x57" href="https://www.researchgate.net/apple-touch-icon-57x57.png"> <link rel="apple-touch-icon" sizes="60x60" href="https://www.researchgate.net/apple-touch-icon-60x60.png"> <link rel="apple-touch-icon" sizes="72x72" href="https://www.researchgate.net/apple-touch-icon-72x72.png"> <link rel="apple-touch-icon" sizes="76x76" href="https://www.researchgate.net/apple-touch-icon-76x76.png"> <link rel="apple-touch-icon" sizes="114x114" href="https://www.researchgate.net/apple-touch-icon-114x114.png"> <link rel="apple-touch-icon" sizes="120x120" href="https://www.researchgate.net/apple-touch-icon-120x120.png"> <link rel="apple-touch-icon" sizes="144x144" href="https://www.researchgate.net/apple-touch-icon-144x144.png"> <link rel="apple-touch-icon" sizes="152x152" href="https://www.researchgate.net/apple-touch-icon-152x152.png"> <link rel="apple-touch-icon" sizes="180x180" href="https://www.researchgate.net/apple-touch-icon-180x180.png"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-32x32.png" sizes="32x32"> <link rel="icon" type="image/png" href="https://www.researchgate.net/android-chrome-192x192.png" sizes="192x192"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-96x96.png" sizes="96x96"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-16x16.png" sizes="16x16"> <link rel="shortcut icon" type="image/x-icon" href="https://c5.rgstatic.net/m/2390829798215018/images/favicon.ico"/> <link rel="manifest" href="https://www.researchgate.net/manifest.json"> <meta name="msapplication-TileColor" content="#da532c"> <meta name="msapplication-TileImage" content="https://www.researchgate.net/mstile-144x144.png"> <meta name="theme-color" content="#444444"> <link rel="search" type="application/opensearchdescription+xml" title="ResearchGate search" href="https://www.researchgate.net/application.DownloadOpenSearchPlugin.html"/> <link rel="meta" type="application/rdf+xml" title="ICRA labels" href="https://www.researchgate.net/application.DownloadLabels.html"/> <link rel="http://oexchange.org/spec/0.8/rel/related-target" type="application/xrd+xml" href="https://www.researchgate.net/application.DownloadOExchange.html"/> <base href="https://www.researchgate.net/"/> <script>
    var rgConfig = {
        correlationId: "rgreq-005a772b-b15a-4347-9ffd-418fa1169797",
        accountId: "",
        module: "publicliterature",
        action: "publicliterature.PublicPublicationDetails",
        page: "publicationDetail",
        product: "publications",
        continent: "Asia",
        stylesHome: "//c5.rgstatic.net/m/",
        staticHost: "c5.rgstatic.net",
        longRunningRequestIdentifier: "LongRunningRequest.publicliterature.PublicPublicationDetails",
        longRunningRequestFp: "e9e5bbe1366c7ee8c8e41d02f793c884ac9be19b"
    };
    window.rootUrl = "https://www.researchgate.net/";
</script> <link rel="canonical" href="https://www.researchgate.net/publication/257299288_Multiobjective_optimization_using_Gaussian_process_emulators_via_stepwise_uncertainty_reduction" />
<link rel="dns-prefetch" href="//c5.rgstatic.net" />
<link rel="dns-prefetch" href="//i1.rgstatic.net" />
<meta property="twitter:card" content="summary" />
<meta property="twitter:site" content="@ResearchGate" />
<meta property="og:title" content="Multiobjective optimization using Gaussian process emulators via stepwise uncertainty reduction" />
<meta property="og:description" content="Optimization of expensive computer models with the help of Gaussian process
emulators in now commonplace. However, when several (competing) objectives are
considered, choosing an appropriate..." />
<meta property="og:site_name" content="ResearchGate" />
<meta property="og:image" content="https://i1.rgstatic.net/publication/257299288_Multiobjective_optimization_using_Gaussian_process_emulators_via_stepwise_uncertainty_reduction/links/02f48f2c0cf21189773bf244/smallpreview.png" />
<meta property="og:url" content="https://www.researchgate.net/publication/257299288_Multiobjective_optimization_using_Gaussian_process_emulators_via_stepwise_uncertainty_reduction" />
<meta property="rg:id" content="PB:257299288" />
<meta name="DC.identifier" scheme="DCTERMS.URI" content="http://dx.doi.org/10.1007/s11222-014-9477-x" />
<meta name="gs_meta_revision" content="1.1" />
<meta name="citation_title" content="Multiobjective optimization using Gaussian process emulators via stepwise uncertainty reduction" />
<meta name="citation_author" content="Victor Picheny" />
<meta name="citation_publication_date" content="2013/10/02" />
<meta name="citation_journal_title" content="Statistics and Computing" />
<meta name="citation_issn" content="0960-3174" />
<meta name="citation_volume" content="25" />
<meta name="citation_issue" content="6" />
<meta name="citation_doi" content="10.1007/s11222-014-9477-x" />
<meta name="citation_abstract_html_url" content="https://www.researchgate.net/publication/257299288_Multiobjective_optimization_using_Gaussian_process_emulators_via_stepwise_uncertainty_reduction" />
<meta name="citation_fulltext_html_url" content="https://www.researchgate.net/publication/257299288_Multiobjective_optimization_using_Gaussian_process_emulators_via_stepwise_uncertainty_reduction" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<link href="//c5.rgstatic.net/m/22664197317151888/styles/rg.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/21004998181197492/styles/rg2.css" type="text/css" rel="stylesheet"/>
<!--[if lt IE 9]><link href="//c5.rgstatic.net/m/238176252723686/styles/ie.css" type="text/css" rel="stylesheet"/><![endif]-->
<link href="//c5.rgstatic.net/m/217752362214895/styles/modules/publicprofile.css" type="text/css" rel="stylesheet"/>
<script src="//c5.rgstatic.net/m/2321000301012716/javascript/vendor/webfontloader/webfontloader.js" type="text/javascript"></script>
 <script>(function(i,s,o,g,r,a,m){i["GoogleAnalyticsObject"]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,"script","//www.google-analytics.com/analytics.js","ga");
 ga("create","UA-58591210-1");ga("set","anonymizeIp",true);ga('set', 'dimension1', 'publication slurped');ga('set', 'dimension2', 'Article');ga('set', 'dimension3', 'Logged out');ga('set', 'dimension4', 'https');ga("send","pageview");</script>
  <script> WebFontConfig = { custom: { families: ['source_sans_pro_italic', 'source_sans_pro_bold', 'source_sans_pro', 'martel'], urls : ['//c5.rgstatic.net/m/231392577336386/styles/fonts.css'] } }; WebFont.load(WebFontConfig); </script><noscript></noscript>

<title>Multiobjective optimization using Gaussian process emulators via stepwise uncertainty reduction</title>
<meta name="description" content="Multiobjective optimization using Gaussian process emulators via stepwise uncertainty reduction on ResearchGate, the professional network for scientists."/>
<meta name="keywords" content="scientific network, scientific platform, scientific community, research partner, research collaboration, journal articles, international collaboration, find researcher, lifescience researcher, interdisciplinary research, research collaboration"/>
</head>
<body class="use-svg-icons logged-out">
<div id="page-container">
<script type="text/javascript">var googletag = googletag || {}; googletag.cmd = googletag.cmd || [];
(function() { var gads = document.createElement("script"); gads.async = true; gads.type = "text/javascript"; var useSSL = "https:" == document.location.protocol; gads.src = (useSSL ? "https:" : "http:") + "//www.googletagservices.com/tag/js/gpt.js"; var node =document.getElementsByTagName("script")[0]; node.parentNode.insertBefore(gads, node); })();</script><div id="main" class="logged-out-header-support">
<div id="content" class="">

<noscript>
<div class="c-box-warning full-width-element" style="text-align: center; ">
    <div style="margin: auto; padding:10px;" class="container">
        <b>For full functionality of ResearchGate it is necessary to enable JavaScript.
            Here are the <a href="http://www.enable-javascript.com/" rel="nofollow" target="_blank">
                instructions how to enable JavaScript in your web browser</a>.</b>
    </div>
</div>
</noscript>

<div id="rgw1_56aba263ae6b7" itemscope itemtype="http://schema.org/ScholarlyArticle"><div class="publication-wrapper publication-wrapper-onecol" id="rgw2_56aba263ae6b7" itemscope itemtype="http://schema.org/ScholarlyArticle"> <div class="c-col-content"> <div class="c-content"> <div class="clearfix">  <div class="publication-header"> <div id="rgw8_56aba263ae6b7">  <div class="type-label"> Article   </div> <span class="Z3988" title="ctx_ver=Z39.88-2004&rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&rfr_id=info%3Asid%2Fresearchgate.net%3Aresearchgate&rft_id=info%3Adoi%2F10.1007%2Fs11222-014-9477-x&rft.atitle=Multiobjective%20optimization%20using%20Gaussian%20process%20emulators%20via%20stepwise%20uncertainty%20reduction&rft.title=Statistics%20and%20Computing&rft.jtitle=Statistics%20and%20Computing&rft.volume=25&rft.issue=6&rft.date=2013&rft.issn=0960-3174&rft.au=Victor%20Picheny&rft.genre=article"></span> <h1 class="pub-title" itemprop="name">Multiobjective optimization using Gaussian process emulators via stepwise uncertainty reduction</h1> <meta itemprop="headline" content="Multiobjective optimization using Gaussian process emulators via stepwise uncertainty reduction">  <meta itemprop="image" content="https://i1.rgstatic.net/publication/257299288_Multiobjective_optimization_using_Gaussian_process_emulators_via_stepwise_uncertainty_reduction/links/02f48f2c0cf21189773bf244/smallpreview.png">  <div id="rgw11_56aba263ae6b7" class="publication-detail-author-list"> <div> <ul class="clearfix js-people-list">  <li id="rgw12_56aba263ae6b7"> <a href="researcher/19512962_Victor_Picheny" class="pub-detail-item author-item" itemprop="author" itemscope itemtype="http://schema.org/Person"> <div class="indent-left"> <div class="people-img">  <img src="https://c5.rgstatic.net/m/2951093203564/images/template/default/profile/profile_default_s.jpg" title="Victor Picheny" alt="Victor Picheny" height="20px" width="20px" style="height: 20px;"/>  </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Victor Picheny</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item   not-claimed " id="rgw13_56aba263ae6b7">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="researcher/19512962_Victor_Picheny"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="Victor Picheny" alt="Victor Picheny" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">       </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="researcher/19512962_Victor_Picheny" class="display-name">Victor Picheny</a>    </h5> <div class="truncate-single-line meta">   </div>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>   </ul> <div class="js-loading"></div>  </div> </div> <div class="pub-details js-pub-details">      <span itemprop="isPartOf" itemscope itemtype="http://schema.org/Periodical"> <a itemprop="sameAs" href="journal/0960-3174_Statistics_and_Computing"><span itemprop="name">Statistics and Computing</span></a> </span>    (Impact Factor: 1.62).     <meta itemprop="datePublished" content="2013-10">  10/2013;  25(6).    DOI:&nbsp;10.1007/s11222-014-9477-x           <div class="pub-source"> Source: <a href="http://arxiv.org/abs/1310.0732" rel="nofollow">arXiv</a> </div>  </div> <div id="rgw14_56aba263ae6b7" class="pub-abstract">  <div class="clearfix">   <div style="max-height: 54px;" class="js-expander-container js-expander-collapsed">  <p itemprop="description"> <strong>ABSTRACT</strong> <div>Optimization of expensive computer models with the help of Gaussian process<br />
emulators in now commonplace. However, when several (competing) objectives are<br />
considered, choosing an appropriate sampling strategy remains an open question.<br />
We present here a new algorithm based on stepwise uncertainty reduction<br />
principles to address this issue. Optimization is seen as a sequential<br />
reduction of the volume of the excursion sets below the current best solutions,<br />
and our sampling strategy chooses the points that give the highest expected<br />
reduction. Closed-form formulae are provided to compute the sampling criterion,<br />
avoiding the use of cumbersome simulations. We test our method on numerical<br />
examples, showing that it provides an efficient trade-off between exploration<br />
and intensification.</div> </p>  </div>  </div>   </div>      <div class="action-container">   <div class="clear"></div> <div class="share-dialog-container" style="display: none;">  </div> </div> </div> <div style="margin-left: -20px; margin-right: -20px;">  </div> </div>  <div class="publication-detail-dfp-container rf"> <div id="rgw27_56aba263ae6b7">  </div> </div>  </div>  <div class="clearfix">  <noscript> <div id="rgw26_56aba263ae6b7"  itemprop="articleBody">  <p>Page 1</p> <p>arXiv:1310.0732v1  [math.OC]  2 Oct 2013<br />Multiobjective optimization using Gaussian process emulators via<br />stepwise uncertainty reduction<br />Victor Picheny<br />INRA, 31326 Castanet Tolosan, France<br />Tel.: +33-5-61 28 54 39<br />victor.picheny@toulouse.inra.fr<br />December 16, 2013<br />Abstract<br />Optimization of expensive computer models with the help<br />of Gaussian process emulators in now commonplace. How-<br />ever, when several (competing) objectives are considered,<br />choosing an appropriate sampling strategy remains an<br />open question. We present here a new algorithm based on<br />stepwise uncertainty reduction principles to address this<br />issue. Optimization is seen as a sequential reduction of the<br />volume of the excursion sets below the current best solu-<br />tions, and our sampling strategy chooses the points that<br />give the highest expected reduction. Closed-form formulae<br />are provided to compute the sampling criterion, avoiding<br />the use of cumbersome simulations. We test our method<br />on numerical examples, showing that it provides an effi-<br />cient trade-off between exploration and intensification.<br />keywords Kriging; EGO; Pareto front; Excursion sets<br />1 Introduction<br />We consider the problem of simultaneous optimization of<br />several objective functions over a design region X ⊂ Rd:<br />y(1)(x),...,y(q)(x), min<br />where y(i): X → R are outputs of a complex com-<br />puter code. The objectives being typically conflicting,<br />there exists no unique minimizer, and the goal is to<br />identify the set of optimal solutions, called Pareto front<br />(Collette and Siarry, 2003). Defining that a point domi-<br />nates another if all his objectives are better, the Pareto<br />front X∗is the subset of the non-dominated points in X:<br />∀x∗∈ X∗,∀x ∈ X,∃k ∈ {1,...,q} such that<br />y(k)(x∗) ≤ y(k)(x).<br />When the computational cost of a single model evaluation<br />is high, a well-established practice consists of using Gaus-<br />sian process (GP) emulators to approximate the model<br />outputs and guide the optimization process. Following<br />the seminal article of Jones et al. (1998) and its Efficient<br />Global Optimization (EGO) algorithm for single objec-<br />tive optimization, several strategies have been proposed<br />in the past few years to address the multi-objective prob-<br />lem (Knowles, 2006; Keane, 2006; Ponweiser et al., 2008;<br />Wagner et al., 2010). They consist in evaluating sequen-<br />tially the computer model at the set of inputs that maxi-<br />mizes a so-called infill criterion, derived from the GP em-<br />ulator, that expresses a trade-off between exploration of<br />unsampled areas and sampling intensification in promis-<br />ing regions. While the single objective case has been ex-<br />tensively discussed (Jones, 2001; Wang and Shan, 2007),<br />finding efficient and statistically consistent infill criteria<br />for the multi-objective case remains an open question.<br />Alternatively to the EGO paradigm, stepwise uncer-<br />tainty reduction (SUR) strategies aim at reducing, by se-<br />quential sampling, an uncertainty measure about a quan-<br />tity of interest. In a single objective optimization context,<br />Villemonteix et al. (2009) defined the Shannon entropy of<br />the maximizer (computed using the GP model) as an un-<br />certainty measure: a smaller entropy implies that the max-<br />imizer is well-identified. They show that their approach<br />outperforms the EGO strategy on a series of problems.<br />Another example in a reliability assessment context can be<br />found in Bect et al. (2012). In general, SUR approaches<br />allow to define policies rigorously with respect to a given<br />objective, resulting in very good performances. However,<br />they are often challenging to use in practice, as they rely<br />on very expensive GP simulations.<br />We propose here a novel SUR strategy to address the<br />multi-objective problem. It is based on a measure of un-<br />certainty of the current identification of the Pareto front<br />X∗, hence avoiding some of the drawbacks of the existing<br />criteria (hierarchy between objectives, difficult-to-tune pa-<br />rameters, etc.). Following Chevalier et al. (2012), explicit<br />formulae for the expected uncertainty reduction are pro-<br />vided, avoiding the need to rely on simulations.<br />The paper is organized as follows: section 2 presents the<br />GP model and the basics of GP-based optimization. Then,<br />we describe our SUR strategy for a single objective in sec-<br />tion 3 and for several objectives in section 4. We provide<br />some numerical experiments in section 5 and compare our<br />method to the state-of-the-art. Finally, advantages and<br />drawbacks of the method are discussed in section 6.<br />1</p>  <p>Page 2</p> <p>2 Some<br />process-based optimization<br />conceptsof Gaussian-<br />2.1 Gaussian process emulation<br />We consider first the emulation of a single computer re-<br />sponse y. The response is modelled as<br />Y (.) = f(.)Tβ + Z(.), (1)<br />where f(.)T= (f1(.),...,fp(.)) is a vector of trend func-<br />tions, β a vector of (unknown) coefficients and Z(.) is a<br />Gaussian process (GP) Z with zero mean and known co-<br />variance kernel k (Cressie, 1993; Rasmussen and Williams,<br />2006). Let us call Anthe event:<br />{Y (x1) = y1,...,Y (xn) = yn};<br />conditionally on An, the mean and covariance of Y are<br />given by:<br />E?Y (x)??An<br />cn(x,x′)=<br />k(x,x′) − kn(x)TK−1<br />+<br />?f(x′)T− kn(x′)TK−1<br />where<br />mn(x)=<br />?=<br />=<br />f(x)Tˆβ + kn(x)TK−1<br />cov?Y (x),Y (x′)??An<br />?f(x)T− kn(x)TK−1<br />n(yn− Fnˆβ),<br />?<br />?T?FT<br />=<br />nkn(x′)<br />nFn<br />nK−1<br />nFn<br />?−1<br />nFn<br />?,<br />• yn= (y1,...,yn)Tare the observations,<br />• Kn= (k(xi,xj))1≤i,j≤nis the observation covariance<br />matrix,<br />• kn(x)T= (k(x,x1),...,k(x,xn)),<br />• Fn=?f(x1)T,...,f(xn)T?T, and<br />•ˆβ =?FT<br />In addition, the prediction variance is defined as<br />nK−1<br />nFn<br />?−1FT<br />nK−1<br />nynis the best linear un-<br />biased estimate of β.<br />s2<br />n(x) = cn(x,x).<br />The covariance kernel depends on parameters that are<br />usually unknown and must be estimated from an initial set<br />of responses. Typically, maximum likelihood estimates are<br />obtained by numerical optimization and used as face value,<br />the estimates being updated when new observations are<br />added to the model. The reader can refer to Stein (1999)<br />(chapter 6), Rasmussen and Williams (2006) (chapter 5)<br />or Roustant et al. (2012) for detailed calculations and im-<br />plementation issues.<br />When several functions y(1),...,y(q)are predicted si-<br />multaneously, it is possible to take their dependency into<br />account (Kennedy and O’Hagan, 2001; Craig et al., 2001).<br />However, in this work we consider all the processes Y(i)<br />independent, hence modelled as above, which is in line<br />with current practice.<br />2.2 Gaussian-process-based optimization<br />with a single objective<br />The EGO strategy, as well as most of its modifications,<br />is based on the following scheme. An initial set of ob-<br />servations is generated, from which the GP model is con-<br />structed and validated. Then, new observations are ob-<br />tained sequentially, at the point in the design space that<br />maximizes the infill criterion, and the model is updated<br />every time a new observation is added to the training set.<br />The two later steps are repeated until a stopping criterion<br />is met.<br />The expected improvement criterion (EI) used in EGO<br />relies on the idea that progress is achieved by perform-<br />ing an evaluation at step n if the (n + 1)thdesign has a<br />lower objective function value than any of the n previous<br />designs. Hence, the improvement is defined as the differ-<br />ence between the current observed minimum and the new<br />function value if it is positive, or zero otherwise, and EI<br />is its conditional expectation under the GP model:<br />EI(x) = E?max?0,ymin<br />where ymin<br />n<br />denotes the current minimum of y found at<br />step n: ymin<br />n<br />= min(y1,...,yn).<br />EGO is the one-step optimal strategy (in expectation)<br />regarding improvement: at step n, the new measurement<br />is chosen as<br />xn+1= argmax<br />n<br />− Y (x)?|An<br />?,<br />x∈XEI(x),<br />which is in practice done by running an optimization al-<br />gorithm. It has been shown in Jones (2001) that EGO<br />provides, among numerous alternatives, an efficient solu-<br />tion for global optimization.<br />2.3Gaussian-process-based optimization<br />with several objectives<br />Several adaptations of EGO to the multi-objective frame-<br />work have been proposed; a review can be found in<br />Ponweiser et al. (2008). The main difficulty is that the<br />concept of improvement cannot be transferred directly, as<br />the current best point is here a set, and the gain is mea-<br />sured on several objectives simultaneously. In Knowles<br />(2006), the objectives are aggregated in a single func-<br />tion using random weights, which allows using the stan-<br />dard EGO. Keane (2006) derived an EI with respect to<br />multiple objectives. Ponweiser et al. (2008) proposed an<br />hypervolume-based infill criterion, where the improvement<br />is measured in terms of hypervolume increase.<br />3Single objective optimization by<br />stepwise uncertainty reduction<br />We consider first the case of a problem with a single ob-<br />jective y to minimize. In this section, we propose a new<br />strategy in a form similar to EGO that uses an alterna-<br />tive infill criterion based on stepwise uncertainty reduction<br />principles. The adaptation of this criterion to the multi-<br />objective case is presented in Section 4.<br />2</p>  <p>Page 3</p> <p>3.1 Definition of an uncertainty measure<br />for optimization<br />The EGO strategy focuses on progress in terms of objec-<br />tive function value. It does not account (or only indirectly)<br />for the knowledge improvement that a new measurement<br />would provide to the GP model, nor for the discrepancy<br />between the location of the current best design found and<br />the actual minimizer (which is actually most users’ objec-<br />tive).<br />Alternative sampling criteria have been proposed to ac-<br />count for these two aspects. In Villemonteix et al. (2009),<br />the IAGO stategy chooses the point that minimizes the<br />posterior Shannon entropy of the minimizer: the inter-<br />est of performing a new observation is measured in gain of<br />information about the location of the minimizer. Unfortu-<br />nately, it relies on expensive GP simulations, which makes<br />its use challenging in practice. Gramacy and Lee (2011)<br />proposed an integrated expected conditional improvement<br />to measure a global informational gain of an observation.<br />In the noisy case, Scott et al. (2011) proposed a some-<br />how similar knowledge gradient policy that also measures<br />global information gain. However, as both criteria rely on<br />notions of improvement, it makes them difficult to adapt<br />to the multiobjective case. The criterion we propose below<br />address this issue.<br />Consider that n measurements have been performed.<br />As a measure of performance regarding the optimization<br />problem, we consider the expected volume of excursion set<br />below the current minimum ymin<br />?P?Y (x) ≤ ymin<br />Similarly to the Shannon entropy measure in IAGO, a<br />large volume indicates that the optimum is not yet pre-<br />cisely located (see Figure 1); on the contrary, a small vol-<br />ume indicates that very little can be gained by pursuing<br />the optimization process. Following the stepwise uncer-<br />tainty reduction paradigm, this volume is an uncertainty<br />measure related to our objective (finding the minimizer<br />of y); minimizing the uncertainty amounts to solving the<br />optimization problem.<br />The probability pn(x,ymin<br />n<br />which is often referred to as probability of improvement<br />(Jones, 2001), can be expressed in closed form, and Eq. (2)<br />writes:<br />?<br />where Φ(.) is the cumulative distribution function (CDF)<br />of the standard Gaussian distribution. Hypothesizing that<br />a measurement yn+1 is performed at a point xn+1, its<br />benefit can be measured by the reduction of the expected<br />volume of excursion set ∆ = evn− evn+1, with:<br />?<br />?<br />Of course, evn+1 cannot be known exactly without eval-<br />uating yn+1. However, we show in the following that its<br />n<br />:<br />evn= EX<br />n<br />|An<br />??. (2)<br />) := P?Y (x) ≤ ymin<br />n<br />|An<br />?,<br />evn=<br />X<br />pn(x,ymin<br />n<br />)dx =<br />?<br />X<br />Φ<br />?ymin<br />n<br />− mn(x)<br />sn(x)<br />?<br />dx, (3)<br />evn+1<br />=<br />X<br />pn+1(x,min?ymin<br />Φ<br />n<br />,yn+1<br />?− mn+1(x)<br />sn+1(x)<br />?)dx<br />=<br />X<br />?<br />min?ymin<br />n<br />,yn+1<br />?<br />dx.<br />expectation can be calculated in closed form, leading to<br />a suitable infill criterion. To do so, we first formulate a<br />series of propositions in the next subsection.<br />3.2 Probabilities updates<br />An interesting property of the GP model is that, when a<br />new observation yn+1= y(xn+1) is added to the training<br />set, its new predictive distribution can be expressed simply<br />as a function of the old one (Emery, 2009):<br />mn+1(x)=mn(x) +<br />cn(x,xn+1)<br />cn(xn+1,xn+1)(yn+1− mn(xn+1));<br />n(x) −cn(x,xn+1)2<br />s2<br />n(xn+1)<br />s2<br />n+1(x)=s2<br />.(4)<br />Note that only mn+1(x) depends on the value of the new<br />observation yn+1. Now, conditionally on the n first obser-<br />vations, Yn+1is a random variable (as the new observation<br />has not yet been performed) with its moments given by<br />the GP model:<br />Yn+1∼ N?mn(xn+1),s2<br />We can then define the future expectation Mn+1(x) (or<br />any quantity depending on it) as a random variable con-<br />ditionally on Anand on the fact that the next observation<br />will be at xn+1. This applies to any quantity depending<br />on Yn+1or Mn+1(x), for instance, the probability of being<br />below a threshold a ∈ R:<br />?a − Mn+1(x)<br />Proposition 3.1. Without any restriction on the value<br />of Yn+1, the expectation of the future probability of being<br />below the threshold is equal to the current probability:<br />n(xn+1)?.<br />Pn+1(x,a) = Φ<br />sn+1(x)<br />?<br />.<br />P(Y (x) ≤ a|An,Y (xn+1) = Yn+1)=<br />=<br />E?Pn+1(x,a)??An<br />?<br />pn(x,a).<br />Proposition 3.2. Conditioning further by Yn+1 ≤ b,<br />the probability expectation writes in simple form using the<br />Gaussian bivariate CDF:<br />P?Y (x) ≤ a??An,Y (xn+1) = Yn+1,Yn+1≤ b?<br />=<br />?¯b,˜ a?,<br />where Φρ is the Gaussian bivariate CDF with zero mean<br />?1<br />ρ =<br />sn(xn+1)sn(x).<br />q(x,b,a) :=<br />×<br />P?Yn+1≤ b??An<br />Φρ<br />?<br />E?Pn+1(x,a) ×<br />?Yn+1≤b<br />??An<br />?<br />=<br />(5)<br />and covariance<br />ρ<br />1ρ<br />?<br />,¯b =<br />b−mn(xn+1)<br />sn(xn+1), ˜ a =a−mn(x)<br />sn(x)<br />and<br />cn(x,xn+1)<br />Corollary 3.3. Similarly, conditioning by Yn+1≥ b leads<br />to:<br />P?Y (x) ≤ a??An,Y (xn+1) = Yn+1,Yn+1≥ b?<br />=<br />Φ−ρ<br />r(x,b,a):=<br />×<br />P?Yn+1≥ b??An<br />?<br />?−¯b,˜ a?. (6)<br />3</p>  <p>Page 4</p> <p>The final proposition resembles Proposition 3.2, but the<br />fixed threshold a is here replaced by Yn+1:<br />Proposition 3.4. The expectation of the probability that<br />Y (x) is smaller than Yn+1, conditionally on Yn+1≤ b, is<br />given by:<br />P?Y (x) ≤ Yn+1|An,Y (xn+1)<br />=<br />=<br />?¯b,η?,<br />with:<br />h(x,b) :=<br />Yn+1,Yn+1≤ b?P?Yn+1≤ b??An<br />Φν<br />?<br />E?Pn+1(x,Yn+1) ×<br />?Yn+1≤b<br />??An<br />?<br />=(7)<br />η=<br />mn(xn+1) − mn(x)<br />n(x) + s2<br />cn(x,xn+1) − s2<br />sn(xn+1)?s2<br />All the proofs are reported in Appendix A.<br />?s2<br />n(xn+1) − 2cn(x,xn+1)<br />and<br />ν=<br />n(xn+1)<br />n(x) + s2<br />n(xn+1) − 2cn(x,xn+1).<br />3.3A Stepwise uncertainty reduction cri-<br />terion<br />Coming back to the SUR criterion, at step n the future<br />volume of excursion set EVn+1is a random variable, and<br />its expectation is:<br />E?EVn+1<br />=<br />X<br />??An,Y (xn+1) = Yn+1<br />Let ϕ(yn+1) be the probability density function (PDF) of<br />Yn+1conditionally on An. We have:<br />EEV (xn+1) :=<br />??An,Y (xn+1) = Yn+1<br />sn+1(x)<br />?<br />?<br />E<br />?<br />Φ<br />?<br />min?ymin<br />n<br />,Yn+1<br />?− Mn+1(x)<br />?<br />?<br />dx.<br />EEV (xn+1)<br />?<br />?<br />?+∞<br />?<br />=<br />X<br />?<br />??ymin<br />Φ<br />R<br />Φ<br />?<br />min?ymin<br />?yn+1− mn+1(x)<br />?ymin<br />?h(x,ymin<br />The first term of the integrand is given by Eq. (7) in Propo-<br />sition 3.4, with b = ymin<br />n<br />, and the second term is given by<br />Eq. (6) in Corrolary 3.3, with a = b = ymin<br />?<br />n<br />,yn+1<br />sn+1(x)<br />?− mn+1(x)<br />?<br />?<br />,ymin<br />n<br />?<br />dϕ(yn+1)dx<br />=<br />X<br />n<br />−∞<br />Φ<br />sn+1(x)<br />+<br />ymin<br />n<br />n<br />− mn+1(x)<br />sn+1(x)<br />dϕ(yn+1)?dx<br />)?dx.=<br />X<br />n<br />) + r(x,ymin<br />n<br />n<br />, hence:<br />EEV (xn+1) =<br />X<br />?Φν<br />?ymin<br />n<br />,η?+ Φρ<br />?−ymin<br />n<br />, ? ymin<br />n<br />??dx,<br />(8)<br />with:<br />ymin<br />n<br />= (ymin<br />n<br />− mn(xn+1))/sn(xn+1)<br />and<br />? ymin<br />n<br />= (ymin<br />n<br />− mn(x))/sn(x).<br />The SUR optimization strategy consists in adding the<br />experiment that minimizes the expected volume of excur-<br />sion set (or maximizes the difference), that is, the one-step<br />optimal policy in terms of reduction of the uncertainty on<br />the objective function minimizer:<br />xn+1= arg min<br />x+∈XEEV (x+) (9)<br />Remark In general, the probability of improvement<br />pn(x,ymin<br />n<br />) is high where the prediction mean mn(.) is<br />low and/or the prediction variance s2<br />ply choosing points that maximize pn(x,ymin<br />to be inefficient (Jones, 2001), as it does not consider the<br />amplitude of the gain in the objective function.<br />EEV (x+) strongly depends on the potential gain am-<br />plitude. Indeed, minimizing the expected volume relies<br />on two mecanisms: reducing the local uncertainty and<br />lowering the current minimum value (ymin<br />achieved by adding measurements in unsampled regions<br />(high s2<br />n(.)), the second in regions where this potential re-<br />duction is high. Hence, the EEV criterion can be seen as<br />a mixed measure of uncertainty on the current minimum<br />location and of potential gain in the objective function.<br />n(.) is high. Sim-<br />n<br />) is known<br />Here,<br />n<br />). The first is<br />3.4 Illustration<br />Figure 1 illustrates the concept of reduction of volume of<br />excursion on a toy example. A GP model is built on a six-<br />point training set, from which the probability of improve-<br />ment p6(x,ymin<br />6<br />) is computed for every point in X = [0,1].<br />We see that it can be intepreted as an indicator of the<br />uncertainty we have about the location of the actual min-<br />imizer x∗= 0.47, as the model can only predict that x∗<br />is likely to be between 0.4 and 0.6. Then, we consider<br />two candidate points (x+= 0.2 and x+= 0.5) and com-<br />pute, for each, the expected new probability (integrand<br />in Eq. (8)). We see that the probability is likely to re-<br />main mostly unchanged by adding the measurement at<br />x+= 0.2 (which is, indeed, a region with high response<br />value), while it would be considerably reduced by adding<br />a measurement at x+= 0.5. In terms of volume of excur-<br />sion set, we have EEV (0.2) ≈ ev6 (no reduction), while<br />EEV (0.5) ≈ ev6/3 (large reduction): the EEV criterion<br />clearly indicates x+= 0.5 as a better sampling location.<br />4Multi-objective optimization by<br />stepwise uncertainty reduction<br />4.1 Volume<br />Pareto front<br />?y(1)(x),...,y(q)(x)?<br />other point x′if y(k)(x) ≤ y(k)(x′) for all k in {1,...,q},<br />which we denote by x′≺ x in the following. At step n,<br />Xn = {x1,...,xn} is the current experimental set and<br />Yn = {y(x1),...,y(xn)} the corresponding set of mea-<br />sures. The non-dominated subset X∗<br />the current Pareto front (of size m ≤ n). In the objective<br />ofexcursion behind the<br />Let y(x) =<br />jective functions to minimize. A point x dominates an-<br />be the vector of ob-<br />nof Xn constitutes<br />4</p>  <p>Page 5</p> <p>0.0 0.20.4 0.60.81.0<br />0.0<br />0.5<br />1.0<br />GP model<br />0.00.2 0.4 0.60.8 1.0<br />0.0<br />0.2<br />0.4<br />0.6<br />0.8<br />1.0<br />Proba of improvement<br />Figure 1: Illustration of the effect of a new observation on the EV criterion. Left: actual objective function (dotted<br />line), GP model (depicted by its mean in black plain line and 95% confidence interval in grey) based on six observations<br />(black circles). The horizontal line shows the current minimum; the vertical bars are placed at two candidate locations.<br />Right: probability of improvement given by the current model and expected updated probability for each candidate.<br />Adding a point at x+= 0.5 (mixed line) is likely to reduce substantially the probability, while adding a point at<br />x+= 0.05 (dotted line) has little expected effect.<br />space, the corresponding subset Y∗<br />dominated and not dominated by the experimental set.<br />Then, we decompose the objective space plane using a<br />tesselation {Ωi}i∈{1,...,I}of size I = (m+1)q(∪i∈IΩi= Rq<br />and ∩i∈IΩi= ∅), each cell being a hyperrectangle defined<br />as:<br />nseparates the regions<br />Ωi= {y ∈ Rq|y(k)<br />Each couple (y(k)<br />of the vector?−∞,y(k)(x∗<br />A cell Ωi dominates another cell Ωj (Ωj ≺ Ωi) if any<br />point in Ωi dominates any point in Ωj, and it partially<br />dominates Ωj if there exists a point in Ωj that is domi-<br />nated by any point in Ωi. Otherwise, we say that Ωj is<br />not dominated by Ωi(Ωj?≺ Ωi).<br />We denote by I∗the indices of all the non-dominated<br />cells at step n, that is, the cells that are not dominated by<br />any point of X∗<br />n. In two dimensions, the non-dominated<br />cells are located in the bottom left half of the plane (Figure<br />2).<br />Now, let us assume that GP models are fitted to each<br />objective y(k). At step n, the probability that Y(x) be-<br />longs to the cell Ωiis:<br />P?Y(x) ∈ Ωi<br />=<br />Φ<br />s(k)<br />n (x)<br />i−≤ y(k)&lt; y(k)<br />i−,y(k)<br />1),...,y(k)(x∗<br />i+,k ∈ {1,...,q}}.<br />i+) consists of two consecutive values<br />m),+∞?. An illus-<br />tration is given in Figure 2.<br />pi<br />n(x)=<br />??An<br />?<br />q?<br />q?<br />k=1<br />?<br />y(k)<br />i+− m(k)<br />n (x)<br />?<br />− Φ<br />?<br />y(k)<br />i−− m(k)<br />s(k)<br />n (x)<br />n (x)<br />?<br />:=<br />k=1<br />pi(k)<br />n<br />by pairwise independence of Y(1),...,Y(q). The probabil-<br />ity that x is not dominated by any point of Xnis then the<br />probability that Y(x) belongs to one of the non-dominated<br />parts of the objective space. As the Ωi’s are disjoint, it is<br />equal to:<br />P(x ?≺ Xn<br />??An) =<br />?<br />i∈I∗<br />pi<br />n(x). (10)<br />Figure 2: Example of Pareto front generated by four points<br />(circles), and associated tesselation. The grey area corre-<br />sponds to the dominated cells.<br />Figure 3: Example of Pareto front modification due to<br />a new measurement. Two points are removed from the<br />Pareto front while the new point is added. The hatched<br />area represents the additional dominated region.<br />5</p>  <p>Page 6</p> <p>Finally, the volume of the excursion sets behind the<br />Pareto front is equal to the integral of this probability<br />over X:<br />?<br />=<br />X<br />i∈I∗<br />evn<br />=<br />X<br />P(x ?≺ Xn<br />?<br />??An)dx<br />?<br />pi<br />n(x)dx =<br />?<br />i∈I∗<br />?<br />X<br />pi<br />n(x)dx. (11)<br />When evnis high, a large proportion of the design space is<br />likely to be better than the current Pareto set; inversely,<br />when X∗<br />tends to zero. Hence, it defines naturally an uncertainty<br />indicator for a SUR strategy.<br />napproaches the actual Pareto set X∗, the volume<br />4.2SUR criterion derivation<br />Now, let us consider that a measurement yn+1 is per-<br />formed at a point xn+1. Compared to step n, the vol-<br />ume ev is modified by two means. First, the new mea-<br />surement will modify the quantities m(k)<br />{1,...,q}), hence, the probabilities pi<br />new measurement is not dominated by the current Pareto<br />set, it modifies the Pareto optimal front, as the new value<br />y(xn+1) is added to Y∗and the values of Y∗dominated<br />by y(xn+1) (if they exist) are removed. An example of<br />such update is given in Figure 3.<br />Focusing on the probability that a point remains non-<br />dominated (Eq. (10)), accounting for the modifications<br />of the models is relatively easy (that is, computing the<br />quantity pi<br />n+1(.)), but accounting for modifications in the<br />Pareto front is complex, as both the number of elements<br />and their values might change. To address this issue, we<br />consider that the updated probability P(x ?≺ Xn+1<br />can be computed using the same sum as for P(x ?≺ Xn<br />(Eq. (10)) by modifying its elements pi<br />n (x), s(k)<br />n(x). Second, if the<br />n (x) (k ∈<br />??An+1)<br />??An)<br />n(x):<br />P(x ?≺ Xn+1<br />??An+1) =<br />?<br />i∈I∗<br />˜ pi<br />n+1(x),<br />with<br />˜ pi<br />n+1(x) = P<br />?<br />x ?≺ Xn+1∩Y(x) ∈ Ωi<br />???An,y(xn+1) = yn+1<br />n+1(x) are random, as<br />?<br />and the Ωi’s defined using Y∗<br />Seing from step n, the˜Pj<br />n(not Y∗<br />n+1).<br />Y (xn+1)(k)∼ N<br />?<br />m(k)<br />n(xn+1),s(k)2<br />n<br />(xn+1)<br />?<br />,<br />∀k ∈ {1,...,q}.<br />The expectation of the new volume is then:<br />EEV (xn+1)=<br />E<br /><br /><br />?<br />X<br />?<br />?<br />j∈I∗<br />˜Pj<br />n+1(x)dx<br /><br /><br />=<br />?<br />j∈I∗<br />X<br />E<br />?˜Pj<br />n+1(x)<br />?<br />dx.<br />This expression can be decomposed by conditioning on<br />the range values of the new observation (using the fact<br />that the Ωi’s are disjoint):<br />?˜Pj<br />=<br />Pn+1<br />E<br />n+1(x)<br />?<br />?<br />i∈I<br />?<br />x<br />?≺ Xn+1∩ Y(x) ∈ Ωj<br />?<br />???Yn+1∈ Ωi<br />?<br />×<br />Pn+1<br />Yn+1∈ Ωi<br />?<br />:=<br />?<br />i∈I<br />pij(x),<br />where Pn+1is the probability conditional on<br />?<br />We first note from Proposition 3.1 that<br />An,Y(xn+1) = Yn+1<br />?<br />.<br />Pn+1[Yn+1∈ Ωi] = pi<br />n(xn+1).<br />Then, leaving aside non-domination, the probability that<br />Y(x) belongs to Ωj knowing that Yn+1belongs to Ωiis<br />given by:<br />Pn+1<br />?<br />Y(x) ∈ Ωj<br />???Yn+1∈ Ωi<br />?<br />(xn+1),<br />?<br />× pi<br />n(xn+1) =<br />q?<br />k=1<br />b(k)<br />ij(x),<br />with:<br />b(k)<br />ij(x)=<br />Pn+1<br />y(k)<br />j−≤ Y(k)(x) &lt; y(k)<br />j+<br />???y(k)<br />i−≤ Y(k)<br />n+1&lt; y(k)<br />i+<br />?<br />×<br />pi(k)<br />n<br />pi(k)<br />n<br />(xn+1) = Pn<br />?<br />y(k)<br />i−≤ Y(k)<br />n+1&lt; y(k)<br />i+<br />?<br />,<br />by pairwise independence of Y(1),...,Y(q). We show in<br />Appendix B that b(k)<br />ij(x) can be expressed in closed form<br />as:<br />?<br />−<br />b(k)<br />ij(x)=<br />Φ(k)<br />ρ<br />y(k)<br />i+,?<br />y(k)<br />y(k)<br />j+<br />?<br />?<br />− Φ(k)<br />ρ<br />?<br />?<br />y(k)<br />i+,?<br />y(k)<br />y(k)<br />j−<br />?<br />?<br />Φ(k)<br />ρ<br />?<br />i−,?<br />y(k)<br />j+<br />+ Φ(k)<br />ρ<br />i−,?<br />y(k)<br />j−<br />with the notations introduced in Section 3.2.<br />Now, we define:<br />?<br />y(k)<br />d(k)<br />ij(x)=<br />???<br />Pn+1<br />y(k)<br />j−≤ Y(k)(x) &lt; y(k)<br />i−≤ Y(k)<br />j+∩ Y(k)<br />× pi(k)<br />n+1≤ Y(k)(x)<br />(xn+1),<br />n+1&lt; y(k)<br />i+<br />?<br />n<br />which is identical to b(k)<br />Y(k)<br />ponent of the new observation dominates the k-th compo-<br />nent of Y(x). We have x ≺ xn+1 only if the condition<br />Y(k)<br />probability of occurence?p<br />• y(k)<br />which implies d(k)<br />ij(x) = 0;<br />ij(x) with the additional condition<br />n+1≤ Y(k)(x). This condition is met when the k-th com-<br />n+1≤ Y(k)(x) is met for all components, hence, with<br />k=1d(k)<br />ij(x). Three cases arise:<br />i−≥ y(k)<br />j+: the component cannot be dominated,<br />• y(k)<br />which implies d(k)<br />i+<br />≤ y(k)<br />j−: the component is always dominated,<br />ij(x) = b(k)<br />ij(x);<br />6</p>  <p>Page 7</p> <p>• y(k)<br />the same interval of variation, and:<br />i+= y(k)<br />j+(and y(k)<br />i−= y(k)<br />j−): Y(k)(x) and Y(k)<br />n+1share<br />d(k)<br />ij(x)=<br />Pn+1<br />?<br />F(k)<br />n+1≤ Y(k)(x) &lt; y(k)<br />(xn+1),<br />i+<br />???y(k)<br />i−≤ Y(k)<br />n+1&lt; y(k)<br />i+<br />?<br />×<br />pi(k)<br />n<br />which is equal (as shown in Appendix B) to:<br />?<br />Φ(k)<br />ν<br />d(k)<br />ij(x)=<br />Φ(k)<br />ρ<br />y(k)<br />i+,?<br />y(k)<br />y(k)<br />j+<br />?<br />− Φ(k)<br />ν<br />?<br />?<br />y(k)<br />i+,η(k)?<br />y(k)<br />y(k)<br />+<br />?<br />i−,η(k)?<br />− Φ(k)<br />ρ<br />i−,?<br />j+<br />?<br />.<br />The probability of Y(x) being non-dominated while in<br />Ωj(and Yn+1being in Ωi) is then:<br />pij(x) =<br />q?<br />k=1<br />b(k)<br />ij(x) −<br />q?<br />k=1<br />d(k)<br />ij(x).<br />If Ωj ≺ Ωi, the new observation dominates any point<br />in Ωj, hence d(k)<br />ij(x) for all k, which gives<br />pij(x) = 0. Inversely, if Ωj?≺ Ωi, the new observation can-<br />not dominate any point in the cell Ωj. We have d(k)<br />for at least one value of k, and pij(x) is the probability<br />that Y(x) belongs to Ωj: pij(x) =?q<br />ability that it is non-dominated at step n + 1 using:<br />ij(x) = b(k)<br />ij(x) = 0<br />k=1b(k)<br />ij(x).<br />Finally, for a given point x ∈ X, we compute the prob-<br />Pn+1(x ?≺ Xn+1) =<br />?<br />i∈I<br />?<br />j∈I∗<br />pij(x),<br />and the SUR criterion is:<br />EEV (xn+1) =<br />?<br />i∈I<br />?<br />j∈I∗<br />?<br />X<br />pij(x)dx, (12)<br />with:<br />pij(x) =<br /><br /><br /><br /><br /><br />0<br />?q<br />if Ωj≺ Ωi<br />if Ωj?≺ Ωi<br />otherwise<br />k=1b(k)<br />?q<br />ij(x)<br />ij(x) −?q<br />k=1b(k)<br />k=1d(k)<br />ij(x)<br />(13)<br />The first sum in Eq. (12) accounts for Yn+1 potentially<br />being in any cell Ωi; the second sum accounts for Y(x)<br />potentially being in a non-dominated cell Ωj.<br />4.3 Computation<br />Evaluating the criterion as in Eq. (12) is a non-trivial task;<br />besides, a relatively fast computation is needed, as it may<br />be embedded in an optimization loop to search for the<br />best new observation (Eq. (9)). We provide here some<br />technical solutions to ease its computation. Some of these<br />issues have also been experienced with SUR criteria for<br />inversion, as reported in Chevalier et al. (2012, 2013).<br />Firstly, as no closed form exists for the integration over<br />the design domain X in Eq. (12), one may rely on Monte-<br />Carlo integration, with approximations of the form:<br />?<br />X<br />pij(x)dx ≈1<br />L<br />L<br />?<br />l=1<br />wlpij(xl),<br />where the xl’s and wl’s are integration points and weights,<br />respectively. One solution to alleviate the computational<br />cost is to use a fixed set of integration points while search-<br />ing for the best new observation. Then, many quantities<br />that do not depend on xn+1can be precalculated only once<br />beforehand outside the optimization loop, as suggested in<br />Chevalier et al. (2012).<br />Secondly, the criterion relies on the bivariate normal<br />distribution, which also must be computed numerically.<br />Very efficient programs can be found, such as the R pack-<br />age pbivnorm (Kenkel, 2012), which makes this task rela-<br />tively inexpensive.<br />Thirdly, the tesselation used in the previous section has<br />I = (m + 1)qelements, with I∗= I/2 non-dominated<br />elements, making the computation of the double sum in<br />Eq. (12) intensive. As detailed in Section 4.4 for the two<br />dimensional case, the number of elements can be very sub-<br />stantially reduced by grouping cells together. Note how-<br />ever that such decomposition may not be straightforward<br />in high dimension.<br />Finally, as the optimization progresses, it is likely that<br />the Pareto set grows, making the criterion more expen-<br />sive to compute as more cells are to be considered. This<br />problem is shared by all GP-based strategies, and some so-<br />lutions have been proposed to filter the Pareto set and re-<br />tain a small representative set (Wagner et al., 2010). Such<br />types of strategies may be applicable to our criterion, as<br />some small cells would contribute to a very small part of<br />the volume of excursion sets and could be neglected with-<br />out introducing a critical error, and would reduce substan-<br />tially the computational cost, especially when the number<br />of observations is high.<br />4.4Efficient formulas in the two-objective<br />case<br />We consider here the two-objective case, for which the<br />EEV criterion can be expressed in a compact and compu-<br />tationally efficent way. With two objectives, the Pareto set<br />can be ordered as follows (the first and second objective<br />functions in ascending and descending order, respectively):<br />y(1)∗<br />1<br />≤ ... ≤ y(1)∗<br />The non-dominated part of the objective space can be<br />divided in m + 1 cells. Then, given a non-dominated cell<br />Ωj, only four cases arise for Ωi (the cell of the new ob-<br />servation), as shown in Figure 4, for which the quantities<br />pij(x) need to be computed.<br />m<br />and y(2)∗<br />1<br />≥ ... ≥ y(2)∗<br />m .<br />Hence, the criterion can be expressed as a sum of at<br />most (m+1)×4 terms. As many terms can be factorized,<br />we finally obtain:<br />EEV (xn+1) =<br />m<br />?<br />j=0<br />?<br />X<br />αj(x),<br />7</p>  <p>Page 8</p> <p>Figure 4: Left: the m+1 non-dominated cells (in white). Right: the four cases for Ωigiven Ωj: three are represented<br />by the different hatched regions, the fourth corresponds to Ωj= Ωi.<br />with:<br />α0(x)=<br />?<br />Φ(1)<br />ρ<br />?<br />?Φ(1)<br />Φ(1)<br />ν<br />?<br />Φ<br />?<br />¯ y(1)∗<br />1<br />η(2)?<br />¯ y(1)∗<br />?<br />Φ(2)<br />ν<br />?<br />{1,...,m − 1},<br />, ˜ y(1)∗<br />1<br />?<br />j+1<br />,η(1)?<br />?<br />− Φ(1)<br />?<br />− Φ(1)<br />− Φ(1)<br />− Φ(2)<br />˜ y(1)∗<br />j<br />ν<br />?<br />¯ y(1)∗<br />1<br />,η(1)??<br />×<br />=<br />Φ<br />?<br />ρ<br />− 1+ Φ˜ y(1)∗<br />1<br />?<br />,<br />αj(x)<br />?<br />¯ y(1)∗<br />j<br />?<br />˜ y(1)∗<br />j+1<br />j+1, ˜ y(1)∗<br />?<br />ν<br />?<br />j<br />¯ y(1)∗<br />j+1,η(1)?<br />¯ y(1)∗<br />, ˜ y(1)∗<br />?<br />Φ˜ y(2)∗<br />j<br />+<br />ρ<br />?<br />j<br />??<br />×<br />+<br />¯ y(2)∗<br />j<br />?<br />,η(2)?<br />− Φ<br />ρ<br />¯ y(2)∗<br />j<br />?<br />,y(2)∗<br />j<br />?<br />??<br />?<br />?<br />??<br />,<br />∀j<br />∈<br />and:<br />αm(x)=<br />?1 − Φ<br />Φ(1)<br />ρ<br />?<br />1 − Φ<br />?<br />m , ˜ y(1)∗<br />?<br />¯ y(1)∗<br />m<br />η(1)?<br />+ Φ(1)<br />??<br />??<br />ν<br />?<br />¯ y(1)∗<br />m ,η(1)?<br />−<br />×<br />+<br />?<br />¯ y(1)∗<br />m<br />Φ(2)<br />ν<br />?<br />¯ y(2)∗<br />?<br />m ,η(2)?<br />− Φ(2)<br />?<br />ρ<br />?<br />.<br />¯ y(2)∗<br />m , ˜ y(2)∗<br />m<br />??<br />Φ¯ y(2)∗<br />m<br />?<br />Calculations are not detailed, as they are straightforward<br />developments of Eq. (13). The two extremal terms (j = 0<br />and j = m+1) correspond to special cases of Ωj(first and<br />last cells in Figure 4, right).<br />5 Numerical experiments<br />5.1 One-dimensional, bi-objective prob-<br />lem<br />In this section, we apply the method to the follow-<br />ing bi-objective problem:F(1)and F(2)are indepen-<br />dent realizations of one-dimensional GPs, indexed by<br />a 300-point regular grid on [0,1], with a stationary<br />Matern covariance with regularity parameter ν = 3/2<br />(Rasmussen and Williams, 2006, chapter 4). The variance<br />and range parameters are taken as one and 1/5, respec-<br />tively.<br />Now, two GP models are built based on four randomly<br />chosen observations. The covariance function is considered<br />as known. Figure 5 shows the initial models and Pareto<br />front. Here, a single point dominates the three others. Af-<br />ter building the tesselation as described in Section 4.1, we<br />compute the volume of the excursion sets corresponding to<br />each cell (Eq. (11)). As there are only four observations,<br />the probability to belong to a non-dominated cell is rela-<br />tively high (Figure 5, bottom right). Then, the criterion<br />is computed for each point in the grid (Figure 5, bottom<br />right). Its maximum is obtained in a region with high un-<br />certainty and low expected values for the two functions.<br />After 10 iterations (Figure 6), the Pareto front is well-<br />approximated. The models are accurate in the optimal<br />regions and have high prediction variances in the other<br />regions, which indicates a good allocation of the compu-<br />tational resources.<br />Next, we compare these results to a state-of-the-art<br />method, called SMS-EGO (Ponweiser et al., 2008), which<br />has been shown to outperform significantly non-GP based<br />methods (such as NSGA-II), in particular when only<br />a limited budget of evaluation is available.<br />suring performances is non-trivial in multi-criteria op-<br />timization, we use a series of three indicators: hyper-<br />volume, epsilon and R2 indicators (Zitzler et al., 2003;<br />Hansen and Jaszkiewicz, 1998), all available in the R<br />package EMOA (Mersmann, 2012). They provide different<br />measures of distance to the actual Pareto set and coverage<br />of the objective space. Results are reported in Figure 7.<br />The Pareto front obtained with SMS-EGO shows that the<br />algorithm only detected one of the two Pareto optimal re-<br />gions. As a consequence, the Pareto front is locally more<br />accurate than the one obtained with the SUR strategy,<br />but the indicators are much poorer.<br />As mea-<br />5.2 Six-dimensional, bi-objective problem<br />Here, the objectives functions are realizations of six-<br />dimensional GPs indexed by a 2000-point Sobol sequence<br />on [0,1]6, with a stationary Matern covariance with regu-<br />larity parameter ν = 5/2. The variance and range param-<br />eters are taken as one and√6/6, respectively. The initial<br />experimental set consists of 10 points randomly chosen,<br />and 40 points are added iteratively using the SUR and<br />SMS-EGO strategies. The results are given in Figure 8.<br />Again, the SUR strategy shows better performances com-<br />8</p>  <p>Page 9</p> <p>0.00.2 0.4<br />Criterion<br />0.6 0.81.0<br />−2<br />−1<br />0<br />1<br />2<br />F(1)<br />0.0 0.2 0.4 0.60.81.0<br />−2<br />−1<br />0<br />1<br />2<br />F(2)<br />0.00.2 0.40.6 0.81.0<br />0.00<br />0.04<br />0.08<br />−1.5−1.0−0.5 0.00.5<br />−1.5<br />−0.5<br />Pareto front<br />0.170<br />0.0690.062<br />Figure 5: Top graphs: initial models (same representation as Figure 1); the actual Pareto-optimal points are repre-<br />sented by red crosses. Bottom right: observations (black circles) represented in the objective space, actual Pareto<br />front (red) and current front (blue). Bottom left: criterion value as a function of x. The vertical bars show the new<br />observation location; the green circle is the new observation.<br />0.00.20.4 0.60.81.0<br />−1.5 −1.0 −0.5<br />0.0<br />0.5<br />F(1)<br />0.00.2 0.40.6 0.81.0<br />−2.0<br />−1.0<br />0.0<br />0.5<br />F(2)<br />−1.5 −1.0 −0.5 0.0 0.5<br />−1.5<br />−1.0<br />−0.5<br />0.0<br />Pareto front<br />Figure 6: Models and Pareto front after 10 iterations.<br />−1.5 −0.5<br />Y(1)<br />0.5<br />−1.5<br />−0.5<br />SMSEGO<br />Y(2)<br />2468 10<br />1.5<br />2.0<br />2.5<br />3.0<br />Hypervolume indicator<br />Iteration<br />2468 10<br />0.2<br />0.6<br />1.0<br />Epsilon indicator<br />Iteration<br />2468 10<br />0.0<br />0.1<br />0.2<br />0.3<br />0.4<br />R2 indicator<br />Iteration<br />Figure 7: SMS-EGO Pareto front after 10 iterations (left) and performance comparison between SUR (plain line)<br />and SMS-EGO (dotted line) on a one-dimensional problem. Hypervolume indicator: higher is better; other indicators<br />should tend to zero.<br />pared to SMS-EGO.<br />6 Discussion<br />We have proposed a new sequential sampling strategy,<br />based on stepwise uncertainty reduction principles, for<br />multi-objective optimization.Closed-form expressions<br />9</p>  <p>Page 10</p> <p>−2 −10<br />Y(1)<br />123<br />−3<br />−1<br />0<br />1<br />2<br />3<br />Pareto front<br />Y(2)<br />−2−10<br />Y(1)<br />123<br />−3<br />−1<br />0<br />1<br />2<br />3<br />SUR<br />Y(2)<br />−2 −10<br />Y(1)<br />123<br />−3<br />−1<br />0<br />1<br />2<br />3<br />SMSEGO<br />Y(2)<br />0 102030 40<br />22<br />24<br />26<br />28<br />30<br />Hypervolume indicator<br />Iteration<br />010 2030 40<br />0.8<br />1.2<br />1.6<br />Epsilon indicator<br />Iteration<br />010 20 3040<br />0.10<br />0.15<br />0.20<br />R2 indicator<br />Iteration<br />Figure 8: Performance comparison between SUR (plain line) and SMS-EGO (dotted line) on a six-dimensional problem.<br />Top left: all 2000 points in the objective space; Pareto-optimal points are the red crosses. Top middle and right: Pareto<br />fronts after 40 iterations.<br />were provided for the infill criterion. Numerical exper-<br />iments showed promising performances of our strategy<br />compared to a state-of-the-art method.<br />some strengths and weaknesses of our approach.<br />We point here<br />First of all, as it is based on Gaussian process modeling,<br />it shares the limits inherents to the model. In particu-<br />lar, it is well-known that classical GP models cannot cope<br />with large datasets (&gt; 1000) or high-dimensional spaces<br />(&gt; 100). Most models also have restrictive conditions on<br />the approximated function (typically, stationarity), and<br />the strategy efficiency may be greatly penalized by impor-<br />tant inadequations between the model hypothesis and the<br />actual function characteristics. Using the proposed strat-<br />egy on more complex GP models (Gramacy and Lee, 2008;<br />Banerjee et al., 2013) may help mitigate these issues.<br />Secondly, we wish to emphasize here that the proposed<br />method has a non-negligible computational cost, as (a) the<br />criterion is evaluated by numerical integration and (b) it<br />is embedded in an optimization loop. Hence, its use may<br />be limited to simulators for which the time to compute<br />an evaluation is much higher than the time to choose the<br />next point to evaluate. However, one may note that the<br />use of closed-form expressions, although relying on the<br />bivariate normal CDF, avoid the need to use conditional<br />simulations (as in Villemonteix et al. (2009)) that would<br />have made the method overly expensive.<br />On the other hand, moving away from the expected im-<br />provement paradigm allowed us to provide a method that<br />does not necessitate any artificial ranking or trade-off be-<br />tween objective functions. It is also scale-invariant, which<br />can be of great advantage when dealing with objectives of<br />different nature. Finally, one advantage of the proposed<br />strategy is that it considers progress in the design space<br />rather than in the objective space, which corresponds to<br />what practitioners are eventually interested in.<br />Possible extensions of this work are various. Account-<br />ing for the uncertainty due to the estimation of the model<br />hyperparameters were left appart here; Bayesian ap-<br />proaches, in the fashion of Kennedy and O’Hagan (2001)<br />or Gramacy and Lee (2008) for instance, may help address<br />this issue. Objective functions were considered as not cor-<br />related to ease calculations and allow the use of simple<br />models. As objectives are likely to be negatively corre-<br />lated in practice, accounting for it while keeping tractable<br />criteria is an important question. Finally, the stepwise<br />uncertainty reduction strategy may be easily adapted to<br />other frameworks, such as constrained or noisy optimiza-<br />tion.<br />AProbabilities update<br />A.1Proof of Proposition 3.2<br />Using the model update equations (4), we note first that:<br />pn+1(x,a) = Φ<br /><br />a − mn(x) +cn(x,xn+1)<br />s2<br />n(xn+1)[mn(xn+1) − yn+1]<br />sn+1(x)<br /><br /><br />10</p>  <p>Page 11</p> <p>Now, let ϕ(yn+1) be the PDF of Yn+1(conditional on An).<br />We have:<br />q(x,b,a)<br />?b<br />?b<br />dϕ(yn+1)<br />As Yn+1∼ N?mn(xn+1),s2<br />Yn+1= mn(xn+1) + sn(xn+1)U<br />=<br />−∞<br />pn+1(x,a)dϕ(yn+1)<br /><br />=<br />−∞<br />Φ<br />a − mn(x) +cn(x,xn+1)<br />s2<br />n(xn+1)[mn(xn+1) − yn+1]<br />sn+1(x)<br /><br /><br />n(xn+1)?, we can write (fol-<br />lowing Chevalier et al. (2012)):<br />with<br />U ∼ N (0,1),<br />which allows to simplify the previous equations to:<br />q(x,b,a)<br />? ¯b<br />? ¯b<br />=<br />−∞<br />Φ<br />?a − mn(x)<br />sn+1(x)<br />−<br />?<br />cn(x,xn+1)<br />sn(xn+1)sn+1(x)<br />?<br />u<br />?<br />dϕ(u)<br />=<br />−∞<br />Φ[ˆ a − βu]dϕ(u),<br />(14)<br />with<br />β=(cn(x,xn+1))/(sn(xn+1)sn+1(x)),<br />(a − mn(x))/sn+1(x) and<br />(b − mn(xn+1))/sn(xn+1).<br />This quantity can be written as a bivariate Gaussian CDF.<br />Indeed:<br />? ¯b<br />1<br />√2π<br />−∞<br />? ¯b<br />1<br />2π<br />−∞ −∞<br />2<br />? ¯b<br />?1<br />is the standard form of the bivariate Gaussian CDF with<br />zero mean and covariance matrix Σβ, hence:<br />ˆ a<br />¯b<br />=<br />=<br />−∞<br />Φ[ˆ a − βu]dϕ(u)<br />? ¯b<br />?ˆ a−βu<br />? ¯b<br />1<br />2π|Σβ|<br />=<br />Φ[ˆ a − βu]exp<br />?−u2<br />?u2+ t2??<br />u2+ [t − βu]2??<br />−1<br />2<br />2<br />?<br />du<br />=<br />1<br />2π<br />−∞−∞<br />?ˆ a<br />exp<br />?<br />−1<br />?<br />?<br />2<br />dtdu<br />=<br />exp<br />?<br />−1<br />dtdu<br />=<br />−∞<br />?ˆ a<br />β<br />1 + β2<br />−∞<br />exp<br />?ut?Σ−1<br />β<br />?u<br />t<br />??<br />dtdu,<br />with Σβ =<br />β<br />?<br />(noting that |Σβ| = 1), which<br />q(x,b,a) = ΦΣβ<br />?¯b,ˆ a?.<br />Finally, applying the normalization ˜ a = ˆ a/?1 + β2, we<br />β<br />?1 + β2=<br />have: q(x,b,a) = Φρ<br />?¯b,˜ a?, with:<br />ρ =<br />cn(x,xn+1)<br />sn(xn+1)sn(x).<br />A.2 Proof of Proposition 3.1<br />The result can be obtained directly from Proposition 3.2<br />with b → +∞.<br />pn(x,a).<br />We have then: q(x,b,a) → Φ(˜ a) =<br />A.3Proof of Corollary 3.3<br />From Eq. (14), we have directly:<br />r(x,b,a)=<br />?+∞<br />?−¯b<br />ΦΣ−β<br />¯b<br />Φ[ˆ a − βu]dϕ(u)<br />=<br />−∞<br />Φ[ˆ a + βu]dϕ(u)<br />?−¯b,ˆ a?= Φ−ρ<br />=<br />?−¯b,˜ a?.<br />A.4Proof of Proposition 3.4<br />The steps of the proof are similar to those of Proposition<br />3. Using the update equations (4), we have first:<br />P(Y (x) ≤ yn+1|An,yn+1= y(xn+1))<br />?yn+1− mn+1(x)<br /><br />?mn(xn+1) − mn(x)<br />= Φ<br />sn+1(x)<br />?<br />= Φ<br />−mn(x) +cn(x,xn+1)mn(xn+1)<br />s2<br />n(xn+1)<br />+<br />?<br />1 −cn(x,xn+1)<br />s2<br />n(xn+1)<br />?<br />yn+1<br />sn+1(x)<br />?cn(x,xn+1) − s2<br /><br /><br />= Φ<br />sn+1(x)<br />−<br />n(xn+1)<br />sn(xn+1)sn+1(x)<br />?<br />u<br />?<br />.<br />Now:<br />h(x,b)<br />?b<br />? ¯b<br />?cn(x,xn+1) − s2<br />? ¯b<br />= ΦΣτ<br />=<br />−∞<br />P(Y (x) ≤ Yn+1|An,Yn+1= yn+1)dϕ(yn+1)<br />?mn(xn+1) − mn(x)<br />n(xn+1)<br />sn(xn+1)sn+1(x)<br />=<br />−∞<br />Φ<br />sn+1(x)<br />−<br />?<br />u<br />?<br />dϕ(u)<br />=<br />−∞<br />Φ[µ − τu]dϕ(u)<br />?¯b,µ?,<br />as we get a form similar to Equation 14, with ΦΣτthe<br />CDF of the centered bigaussian with covariance Στ =<br />?1τ<br />τ1 + τ2<br />?<br />,<br />µ<br />τ<br />=<br />=<br />(mn(xn+1) − mn(x))/sn+1(x)<br />(cn(x,xn+1) − s2<br />Normalizing η = µ/√1 + τ2delivers the final result.<br />n(xn+1))/(sn(xn+1)sn+1(x)).<br />B<br />b(k)<br />ij(x) and d(k)<br />ij(x) computation<br />Let X and Y be two dependent random variables, and<br />a, b, c and d four real numbers. By direct application of<br />11</p>  <p>Page 12</p> <p>Bayes formula, we have:<br />P(a ≤ X &lt; b|c ≤ Y &lt; d)P(c ≤ Y &lt; d)<br />= P(Y &lt; d) × [P(X &lt; b|Y &lt; d) − P(X ≤ a|Y &lt; d)]<br />− P(Y ≤ c) × [P(X &lt; b|Y ≤ c) − P(X ≤ a|Y ≤ c)]<br />P(Y ≤ X &lt; b|a ≤ Y &lt; b)P(a ≤ Y &lt; b)<br />= P(Y &lt; b) × [P(X &lt; b|Y &lt; b) − P(X ≤ Y |Y &lt; b)]<br />− P(Y ≤ a) × [P(X &lt; b|Y ≤ a) − P(X ≤ Y |Y ≤ a)]<br />Now, by definition, b(k)<br />ij<br />is of the form of the fist equa-<br />tion:<br />b(k)<br />ij(x):=<br />Pn+1<br />y(k)<br />?<br />hence write as the sum of four terms:<br />b(k)<br />ij(x)=p(k)<br />?Y(k)(x) ≤ y(k)<br />−<br />−<br />=<br />x,y(k)<br />j+<br />q(k)?<br />with q(k)(x,b,a) given by Eq. (5), thus:<br />?<br />−Φ(k)<br />?<br />i−≤ Y(k)<br />j−≤ Y(k)(x) &lt; y(k)<br />n+1&lt; y(k)<br />j+|y(k)<br />i−≤ Y(k)<br />n+1&lt; y(k)<br />i+<br />?<br />×<br />Pn<br />y(k)<br />i+<br />?<br />,<br />n(xn+1,y(k)<br />i+)<br />?<br />Pn+1<br />?Y(k)(x) ≤ y(k)<br />n+1≤ y(k)<br />?Y(k)(x) &lt; y(k)<br />n+1≤ y(k)<br />− q(k)?<br />x,y(k)<br />j+<br />??Y(k)<br />??Y(k)<br />?<br />,<br />n+1≤ y(k)<br />i+<br />?<br />−<br />Pn+1<br />j−<br />??Y(k)<br />??Y(k)<br />+ q(k)?<br />?<br />y(k)<br />j+<br />i+<br />??<br />??<br />p(k)<br />n(xn+1,y(k)<br />?Y(k)(x) ≤ y(k)<br />i+,y(k)<br />i−)<br />?<br />Pn+1<br />j+<br />n+1≤ y(k)<br />i−<br />?<br />Bayesian forecasting for complex systems using com-<br />puter simulators. Journal of the American Statistical<br />Association 96(454), 717–729 (2001)<br />Pn+1<br />q(k)?<br />j−<br />i−<br />?<br />x,y(k)<br />i+,y(k)<br />j−<br />−<br />x,y(k)<br />i−,y(k)<br />j+<br />?<br />i−,y(k)<br />j−<br />?<br />?<br />b(k)<br />ij(x)=<br />Φ(k)<br />ρ<br />y(k)<br />?<br />i+,?<br />y(k)<br />y(k)<br />j+<br />− Φ(k)<br />?<br />ρ<br />?<br />y(k)<br />?<br />i+,?<br />y(k)<br />y(k)<br />j−<br />ρ<br />i−,?<br />+ Φ(k)<br />ρ<br />i−,?<br />y(k)<br />j−<br />?<br />.<br />Similary, d(k)<br />Starting with the definition:<br />ij<br />is of the form of the second equation:<br />d(k)<br />ij(x) :=<br />Pn+1<br />?<br />i−≤ Y(k)<br />Y(k)<br />n+1≤ Y(k)(x) &lt; y(k)<br />n+1&lt; y(k)<br />j+<br />??y(k)<br />i−≤ Y(k)<br />n+1&lt; y(k)<br />i+<br />?<br />103(483) (2008)<br />×<br />Pn<br />?<br />y(k)<br />i+<br />?<br />,<br />hence writes:<br />d(k)<br />ij(x)=p(k)<br />n(xn+1,y(k)<br />?Y(k)(x) ≤ Y(k)<br />p(k)<br />?Y(k)(x) ≤ Y(k)<br />x,y(k)<br />h(k)?<br />i+)<br />?<br />Pn+1<br />?Y(k)(x) ≤ y(k)<br />n+1≤ y(k)<br />?Y(k)(x) &lt; y(k)<br />n+1≤ y(k)<br />− h(k)?<br />x,y(k)<br />j+<br />??<br />j+<br />??<br />??Y(k)<br />??Y(k)<br />n+1≤ y(k)<br />i+<br />?<br />−<br />−<br />−<br />=<br />Pn+1<br />n+1<br />??Y(k)<br />??Y(k)<br />i+<br />n(xn+1,y(k)<br />i−)<br />?<br />Pn+1<br />n+1≤ y(k)<br />i−<br />?<br />Pn+1<br />q(k)?<br />n+1<br />i−<br />i+,y(k)<br />?<br />j+<br />+ q(k)?<br />?<br />x,y(k)<br />i+<br />?<br />−<br />x,y(k)<br />i−<br />i−,y(k)<br />j−<br />?<br />,<br />with q(k)(x,b,a) given by Eq. (5) and h(k)(x,b) given by<br />Eq. (7), thus:<br />?<br />+<br />Φ(k)<br />ν<br />y(k)<br />d(k)<br />ij(x)=<br />Φ(k)<br />ρ<br />y(k)<br />i+,?<br />y(k)<br />j+<br />?<br />− Φ(k)<br />ν<br />?<br />?<br />y(k)<br />i+,η(k)?<br />y(k)<br />y(k)<br />?<br />i−,η(k)?<br />− Φ(k)<br />ρ<br />i−,?<br />j+<br />?<br />.<br />References<br />Banerjee, A., Dunson, D.B., Tokdar, S.T.: Efficient gaus-<br />sian process regression for large datasets. Biometrika<br />100(1), 75–89 (2013)<br />Bect, J., Ginsbourger, D., Li, L., Picheny, V., Vazquez, E.:<br />Sequential design of computer experiments for the esti-<br />mation of a probability of failure. Statistics and Com-<br />puting 22(3), 773–793 (2012)<br />Chevalier, C., Bect, J., Ginsbourger, D., Vazquez,<br />E., Picheny, V., Richet, Y.:<br />based stepwiseuncertainty reduction<br />cation to the identification of an excursion set.<br />http://hal.inria.fr/hal-00641108/en (2012)<br />Fast parallel kriging-<br />withappli-<br />Chevalier, C., Picheny, V., Ginsbourger, D.:<br />An efficient and user-friendly implementation of batch-<br />sequential inversion strategies based on kriging. Com-<br />putational Statistics &amp; Data Analysis (2013)<br />Kriginv:<br />Collette, Y., Siarry, P.: Multiobjective optimization: prin-<br />ciples and case studies. Springer (2003)<br />Craig, P.S., Goldstein, M., Rougier, J.C., Seheult, A.H.:<br />Cressie, N.: Statistics for Spatial Data, revised edition,<br />vol. 928. Wiley, New York (1993)<br />Emery, X.: The kriging update equations and their appli-<br />cation to the selection of neighboring data. Computa-<br />tional Geosciences 13(3), 269–280 (2009)<br />Gramacy, L., Lee, H.: Optimization under unknown con-<br />straints. Bayesian Statistics 9, 229 (2011)<br />Gramacy, R.B., Lee, H.K.: Bayesian treed gaussian pro-<br />cess models with an application to computer model-<br />ing.Journal of the American Statistical Association<br />Hansen, M.P., Jaszkiewicz, A.: Evaluating the quality of<br />approximations to the non-dominated set. IMM, De-<br />partment of Mathematical Modelling, Technical Univer-<br />sity of Denmark (1998)<br />Jones, D.R.: A taxonomy of global optimization methods<br />based on response surfaces. Journal of global optimiza-<br />tion 21(4), 345–383 (2001)<br />Jones, D.R., Schonlau, M., Welch, W.J.: Efficient global<br />optimization of expensive black-box functions. Journal<br />of Global optimization 13(4), 455–492 (1998)<br />Keane, A.J.:<br />in multiobjective design optimization.<br />44(4), 879–891 (2006)<br />Statistical improvement criteria for use<br />AIAA journal<br />Kenkel,<br />variate<br />http://CRAN.R-project.org/package=pbivnorm.<br />R package version 0.5-1<br />B.:<br />Normal<br />pbivnorm:<br />CDF<br />VectorizedBi-<br />(2012).URL<br />12</p>  <p>Page 13</p> <p>Kennedy, M.C., O’Hagan, A.: Bayesian calibration of<br />computer models. Journal of the Royal Statistical Soci-<br />ety: Series B (Statistical Methodology) 63(3), 425–464<br />(2001)<br />Knowles, J.: Parego: A hybrid algorithm with on-line<br />landscape approximation for expensive multiobjective<br />optimization problems.<br />IEEE Transactions on 10(1), 50–66 (2006)<br />Evolutionary Computation,<br />Mersmann,<br />tive<br />http://CRAN.R-project.org/package=emoa.<br />package version 0.5-0<br />O.: emoa:Evolutionary<br />Algorithms<br />Multiobjec-<br />Optimization(2012).URL<br />R<br />Ponweiser, W., Wagner, T., Biermann, D., Vincze, M.:<br />Multiobjective optimization on a limited budget of eval-<br />uations using model-assisted s-metric selection.<br />Parallel Problem Solving from Nature, pp. 784–794.<br />Springer (2008)<br />In:<br />Rasmussen, C., Williams, C.: Gaussian processes for ma-<br />chine learning. MIT Press (2006)<br />Roustant, O., Ginsbourger, D., Deville, Y.: Dicekriging,<br />diceoptim: Two r packages for the analysis of computer<br />experiments by kriging-based metamodeling and opti-<br />mization. Journal of Statistical Software 51(1), 1–55<br />(2012)<br />Scott, W., Frazier, P., Powell, W.: The correlated knowl-<br />edge gradient for simulation optimization of continuous<br />parameters using gaussian process regression.<br />Journal on Optimization 21(3), 996–1026 (2011)<br />SIAM<br />Stein, M.: Interpolation of spatial data: some theory for<br />kriging. Springer Verlag (1999)<br />Villemonteix, J., Vazquez, E., Walter, E.: An informa-<br />tional approach to the global optimization of expensive-<br />to-evaluate functions. Journal of Global Optimization<br />44(4), 509–534 (2009)<br />Wagner, T., Emmerich, M., Deutz, A., Ponweiser, W.: On<br />expected-improvement criteria for model-based multi-<br />objective optimization. In: Parallel Problem Solving<br />from Nature, PPSN XI, pp. 718–727. Springer (2010)<br />Wang, G.G., Shan, S.: Review of metamodeling tech-<br />niques in support of engineering design optimization.<br />Journal of Mechanical Design 129, 370 (2007)<br />Zitzler, E., Thiele, L., Laumanns, M., Fonseca, C.M.,<br />Da Fonseca, V.G.: Performance assessment of multiob-<br />jective optimizers: An analysis and review. Evolution-<br />ary Computation, IEEE Transactions on 7(2), 117–132<br />(2003)<br />13</p>   </div> <div id="rgw19_56aba263ae6b7" class="c-box pub-resource-container js-toggle" style=""> <h4 class="lf js-expand-list"><small><a href="javascript:" class="lf">View other sources <span class="ico-expand-list"></span></a></small></h4> <h4 class="lf js-collapse-list hidden"><small><a href="javascript:" class="lf">Hide other sources <span class="ico-collapse-list"></span></a></small></h4> <div class="clear"></div> <div class="scroll-wrapper hidden"> <ul class="files-list c-list" id="rgw20_56aba263ae6b7">  <li class="c-list-item pub-resource-item"  data-type="fulltext" id="rgw21_56aba263ae6b7"> <span class="ico-pub"></span> <div class="file-content"> <div class="download"> <a href="http://export.arxiv.org/pdf/1310.0732" target="_blank" rel="nofollow" class="publication-viewer" title="Multiobjective optimization using Gaussian process emulators via stepwise uncertainty reduction">Multiobjective optimization using Gaussian process...</a> </div>  <div class="details">   Available from <a href="http://export.arxiv.org/pdf/1310.0732" target="_blank" rel="nofollow">export.arxiv.org</a>  </div>    </div> </li>  </ul> </div> </div> </noscript> <div class="clearfix"> <div class="action-container">  </div> <div class="pub-legal"> Data provided are for informational purposes only. Although carefully collected, accuracy cannot be guaranteed. The impact factor represents a rough estimation of the journal's impact factor and does not reflect the actual current impact factor. Publisher conditions are provided by RoMEO. Differing provisions from the publisher's actual policy or licence agreement may be applicable. </div>   </div> </div> <div class="clearfix">     <div id="rgw23_56aba263ae6b7" class="c-box pub-resource-container js-toggle" style="display: none;"> <h4 class="lf js-expand-list"><small><a href="javascript:" class="lf">View other sources <span class="ico-expand-list"></span></a></small></h4> <h4 class="lf js-collapse-list hidden"><small><a href="javascript:" class="lf">Hide other sources <span class="ico-collapse-list"></span></a></small></h4> <div class="clear"></div> <div class="scroll-wrapper hidden"> <ul class="files-list c-list" id="rgw24_56aba263ae6b7">  </ul> </div> </div>   <div id="rgw15_56aba263ae6b7" class="similar-publications"> <h2>Similar Publications</h2> <ul class="list-bordered">  <li class="c-list-item li-publication-teaser" id="rgw16_56aba263ae6b7"> <div> <h5> <a href="publication/254061323_Improved_Estimation_of_Water_Chlorophyll_Concentration_With_Semisupervised_Gaussian_Process_Regression" class="color-inherit ga-similar-publication-title"><span class="publication-title">Improved Estimation of Water Chlorophyll Concentration With Semisupervised Gaussian Process Regression</span></a>  </h5>  <div class="authors"> <a href="researcher/11994525_Yakoub_Bazi" class="authors ga-similar-publication-author">Yakoub Bazi</a>, <a href="researcher/71323522_Naif_Alajlan" class="authors ga-similar-publication-author">Naif Alajlan</a>, <a href="researcher/10761555_Farid_Melgani" class="authors ga-similar-publication-author">Farid Melgani</a>  </div>  </div> <div class="clear"></div> </li>  <li class="c-list-item li-publication-teaser" id="rgw17_56aba263ae6b7"> <div> <h5> <a href="publication/3418871_ParEGO_A_Hybrid_Algorithm_With_On-Line_Landscape_Approximation_for_Expension_Multiobjective_Optimization_Problems" class="color-inherit ga-similar-publication-title"><span class="publication-title">ParEGO: A Hybrid Algorithm With On-Line Landscape Approximation for Expension Multiobjective Optimization Problems</span></a>  </h5>  <div class="authors"> <a href="researcher/8111149_Joshua_Knowles" class="authors ga-similar-publication-author">Joshua Knowles</a>  </div>  </div> <div class="clear"></div> </li>  <li class="c-list-item li-publication-teaser" id="rgw18_56aba263ae6b7"> <div> <h5> <a href="publication/221228406_Multiobjective_Optimization_on_a_Budget_of_250_Evaluations" class="color-inherit ga-similar-publication-title"><span class="publication-title">Multiobjective Optimization on a Budget of 250 Evaluations</span></a>  </h5>  <div class="authors"> <a href="researcher/8111149_Joshua_D_Knowles" class="authors ga-similar-publication-author">Joshua D. Knowles</a>, <a href="researcher/33937555_Evan_J_Hughes" class="authors ga-similar-publication-author">Evan J. Hughes</a>  </div>  </div> <div class="clear"></div> </li>  </ul> </div> </div> </div> </div> </div></div></div>
<div class="clear"></div><div id="rgw29_56aba263ae6b7" class="default-footer"> <div id="footer" class="clearfix"> <span class="footer-left"> &copy; 2008&dash;2016 researchgate.net. All rights reserved. </span> <span class="footer-right"> <a href="https://www.researchgate.net/about">About us</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="https://www.researchgate.net/contact">Contact us</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="careers">Careers</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="developers">Developers</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="blog" target="_blank">News</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="application.PrivacyPolicy.html">Privacy</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="application.TermsAndConditions.html">Terms</a> <span class="footer-link-separator" style="padding: 0 5px;">&nbsp;|&nbsp;</span> <a href="advertising?_ref=ft">Advertising</a> <span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="recruiters?_ref=ft">Recruiting</a> </span> </div>  </div></div>
<div id="rgw30_56aba263ae6b7">  <div class="header-wrapper-logged-out"> <div id="header"> <div class="header-content"> <a href="" class="g-l-logo"> <svg width="149" height="19"> <image xlink:href="https://c5.rgstatic.net/m/235107188705592/images/template/brand-header-logo.svg" src="https://c5.rgstatic.net/m/238113351022438/images/template/brand-header-logo.png" width="149" height="19"/> </svg> </a> <a href="" class="g-l-logo-ico"> <svg width="127" height="17" viewbox="0 0 127 22"> <image xlink:href="https://c5.rgstatic.net/m/235107188705592/images/template/brand-header-logo.svg" src="https://c5.rgstatic.net/m/238113351022438/images/template/brand-header-logo.png" width="127" height="17"/> </svg> </a> <div id="rgw31_56aba263ae6b7" class="header-login-wrapper js-header-login"> <div class="dropdown-right-align"> <div class="login-signup-container lf"> <a href="https://www.researchgate.net/signup.SignUp.html?ev=su_chnl_index&amp;hdrsu=1&amp;_sg=-KKZpJNoMO5qfgAWyatvopEa2E1Eve9wm3hJ-7aHNZ-6ugGyFbGdINmsPXedR4_0" class="dropdown-toggle lf">Join for free</a> </div> <div class="dropdown lf" style="height: 20px;"> <a href="https://www.researchgate.net/application.Login.html" class="js-login-url dropdown-toggle lf">Log in <span class="caret"></span></a> <div class="dropdown-menu"> <div class="header-login-form-wrapper"> <!--[if IE 6]><p class="box-warning" style="margin-bottom: 0;">Sorry, ResearchGate no longer supports the version of Internet Explorer you are using. <a href="http://whatbrowser.org/" rel="nofollow" target="_blank">Update your web browser</a> and then log in. </p><![endif]--> <form method="post" action="https://www.researchgate.net/application.Login.html" class="form-big header-login-form js-login-form" name="loginForm" id="headerLoginForm"> <input type="hidden" name="request_token" value="V+edG0N+TrvyNpR7Q28hVA8xc6P8se5Ts1OmJ1OGBTuMby9U87GyAZAeog+SWDru9QRKL65DBJ6XRhqnjYGNnGM90Ft9v6incLBCyBK664yHBNYg4cBMs3Nrhd9a3vmcNO3o4ilNBBt8EsxrDMW+p3BlPioezudSVbmLUrwTMWlIJ2i0X8XOUZxjKQ9HU5XM6IP7yQEFVeVCNkdDsi+QoZdvxUA/GXw+tGyBSOzTG0r4nhyewjViu3/8b0SYF/glCjZS26nK84fv7BY6/upkWxGzYqvRPgdxIspSriY85t0="/> <input type="hidden" name="urlAfterLogin" value="publication/257299288_Multiobjective_optimization_using_Gaussian_process_emulators_via_stepwise_uncertainty_reduction"/> <input type="hidden" name="invalidPasswordCount" value="0"/> <input type="hidden" name="headerLogin" value="yes"/> <label for="input-header-login">Email</label> <div class="login-input"> <div class="info-tip-wrapper"> <span class="ico-info js-info"></span> </div> <input type="email" value="" name="login" class="login js-login-input text" id="input-header-login" tabindex="1"/> </div> <div class="clear"></div> <label class="lf" for="input-header-password"> Password </label> <a class="rf forgot-password js-forgot-password" href="application.LostPassword.html">Forgot password?</a> <div class="clear"></div> <input type="password" value="" name="password" class="password js-password-input text" id="input-header-password" tabindex="2"/> <div class="clear"></div> <label class="remember-me" for="headerLoginCookie"> <input type="checkbox" checked="checked" value="yes" name="setLoginCookie" class="lf checkbox" id="headerLoginCookie" tabindex="3"/> Keep me logged in </label> <div class="clear"></div> <input value="Log in" name="loginSubmit" class="btn btn-promote btn-fullwidth btn-large allow-leave js-submit-button" type="submit" tabindex="4"/> </form> <div class="connectors"> <div class="text">or log in with</div> <div class="connector-actions"> <a href="connector/linkedin/" class="li-connect js-li-connect" data-redirect-url="cHVibGljYXRpb24vMjU3Mjk5Mjg4X011bHRpb2JqZWN0aXZlX29wdGltaXphdGlvbl91c2luZ19HYXVzc2lhbl9wcm9jZXNzX2VtdWxhdG9yc192aWFfc3RlcHdpc2VfdW5jZXJ0YWludHlfcmVkdWN0aW9u"> <span class="icon ico-linkedin-round-grey"></span> <span class="icon ico-linkedin-round"></span> </a> <a href="connector/facebook/" class="fb-connect middle js-fb-connect" data-redirect-url="cHVibGljYXRpb24vMjU3Mjk5Mjg4X011bHRpb2JqZWN0aXZlX29wdGltaXphdGlvbl91c2luZ19HYXVzc2lhbl9wcm9jZXNzX2VtdWxhdG9yc192aWFfc3RlcHdpc2VfdW5jZXJ0YWludHlfcmVkdWN0aW9u"> <span class="icon ico-facebook-round-grey"></span> <span class="icon ico-facebook-round"></span> </a> <a href="connector/google/" class="g-connect js-g-connect" data-redirect-url="cHVibGljYXRpb24vMjU3Mjk5Mjg4X011bHRpb2JqZWN0aXZlX29wdGltaXphdGlvbl91c2luZ19HYXVzc2lhbl9wcm9jZXNzX2VtdWxhdG9yc192aWFfc3RlcHdpc2VfdW5jZXJ0YWludHlfcmVkdWN0aW9u"> <span class="icon ico-google-round-grey"></span> <span class="icon ico-google-round"></span> </a> </div> </div> </div> </div> </div> </div> </div> </div> </div> <script type="application/ld+json">
{ "@context" : "http://schema.org",
  "@type" : "Organization",
  "name" : "ResearchGate",
  "url" : "http://www.researchgate.net",
  "logo" : "http://www.researchgate.net/images/template/rg_logo_square_brand.png",
  "sameAs" : [ "https://www.facebook.com/ResearchGate",
    "https://twitter.com/ResearchGate",
    "https://plus.google.com/+researchgate",
    "https://www.linkedin.com/company/researchgate"] 
}
</script> </div> </div><div class="c-signup-bar" id="rgw32_56aba263ae6b7"> <div class="banner-contents">   <span class="message">ResearchGate is the professional network for scientists and researchers.</span> <a href="signup.SignUp.html?ev=su_banner" class="btn btn-large btn-promote">Join for free</a>  </div> </div></div>
<script>
rgConfig.backendTime = 356;
</script>
<script src="//c5.rgstatic.net/m/2277196935388619/javascript/lib/yui3/yui/yui-min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/21832295316281274/javascript/yuiLoaderConfig-min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/23178613132105398/javascript/vendor/babel-core/browser-polyfill.min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/2198378204065/javascript/min/lib/error_logging.js" type="text/javascript"></script>
<script>
(function (){
if (typeof YRG === "undefined") {
var xmlHttpRequest = new XMLHttpRequest();
xmlHttpRequest.open("post", "go.Error.html");
xmlHttpRequest.setRequestHeader("Content-Type", "application/json");
xmlHttpRequest.setRequestHeader("Accept", "application/json"); var loadedScripts = "";
if (window.performance && window.performance.getEntriesByType) {
    var result = [];
    var resources = performance.getEntriesByType("resource");
    for (var i in resources) {
        if (resources.hasOwnProperty(i)) {
            result.push({
                name: resources[i].name,
                duration: resources[i].duration
            });
        }
    }
    loadedScripts += "&loadedScripts=" + encodeURIComponent(JSON.stringify(result));
}
if (typeof YUI === "undefined") {
    loadedScripts += "&yuiLoaded=false";
} else {
    loadedScripts += "&yuiLoaded=true";
}
xmlHttpRequest.send("Type=InformationException&message=" + encodeURIComponent("Error loading YUI") + loadedScripts);
}
})();
</script>
<script>if (typeof YRG !== 'undefined') { YRG.use('rg-base',function(Y){Y.applyConfig({ignore: ["css-rg","css-rg2","css-ie","css-modules-publicprofile"]});Y.use(["rg.core.pagespeed.Monitoring"],function(Y){(function(){Y.rg.createInitialWidget({"data":{"content":{"data":{"profileSmallHeader":{"data":{"profileBadge":{"data":{"profileUrl":"researcher\/19512962_Victor_Picheny","fullname":"Victor Picheny","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2549355721578\/images\/template\/default\/profile\/profile_default_m.png","profileStats":[{"data":{"impactPoints":"18.58","widgetId":"rgw5_56aba263ae6b7"},"id":"rgw5_56aba263ae6b7","partials":[],"templateName":"publicliterature\/stubs\/PublicLiteratureAuthorImpactPoints.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicLiteratureAuthorImpactPoints.html?authorUid=19512962","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"publicationCount":34,"widgetId":"rgw6_56aba263ae6b7"},"id":"rgw6_56aba263ae6b7","partials":[],"templateName":"publicliterature\/stubs\/PublicLiteratureAuthorPublicationCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicLiteratureAuthorPublicationCount.html?authorUid=19512962","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"followerCount":5,"widgetId":"rgw7_56aba263ae6b7"},"id":"rgw7_56aba263ae6b7","partials":[],"templateName":"publicliterature\/stubs\/PublicLiteratureAuthorFollowerCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicLiteratureAuthorFollowerCount.html?authorUid=19512962","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"widgetId":"rgw4_56aba263ae6b7"},"id":"rgw4_56aba263ae6b7","partials":[],"templateName":"publicprofile\/stubs\/ProfileBadge.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicLiteratureAuthorBadge.html?authorUid=19512962","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw3_56aba263ae6b7"},"id":"rgw3_56aba263ae6b7","partials":[],"templateName":"publicprofile\/stubs\/ProfileSmallHeader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicprofile.ProfileSmallHeader.html?publicationUid=257299288","viewClass":null,"yuiModules":["css-modules-publicprofile"],"stylesheets":["modules\/publicprofile.css"],"_isYUI":true},"publication":{"data":{"publicationUid":257299288,"title":"Multiobjective optimization using Gaussian process emulators via stepwise uncertainty reduction","journalTitle":"Statistics and Computing","journalDetailsTooltip":{"data":{"journalTitle":"Statistics and Computing","journalAbbrev":"STAT COMPUT","publisher":"Springer Verlag","issn":"0960-3174","impactFactor":"1.62","fiveYearImpactFactor":"1.92","citedHalfLife":">10.0","immediacyIndex":"0.27","eigenFactor":"0.01","articleInfluence":"1.66","widgetId":"rgw9_56aba263ae6b7"},"id":"rgw9_56aba263ae6b7","partials":[],"templateName":"publicliterature\/stubs\/JournalInfo.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.JournalInfo.html?issn=0960-3174","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"affiliation":false,"type":"Article","details":{"doi":"10.1007\/s11222-014-9477-x","journalInfos":{"journal":"","publicationDate":"10\/2013;","publicationDateRobot":"2013-10","article":"25(6).","journalTitle":"Statistics and Computing","journalUrl":"journal\/0960-3174_Statistics_and_Computing","impactFactor":1.62}},"source":{"sourceUrl":"http:\/\/arxiv.org\/abs\/1310.0732","sourceName":"arXiv"},"publicationActions":null,"publicationCoins":{"data":{"tags":[{"key":"ctx_ver","value":"Z39.88-2004"},{"key":"rft_val_fmt","value":"info:ofi\/fmt:kev:mtx:journal"},{"key":"rfr_id","value":"info:sid\/researchgate.net:researchgate"},{"key":"rft_id","value":"info:doi\/10.1007\/s11222-014-9477-x"},{"key":"rft.atitle","value":"Multiobjective optimization using Gaussian process emulators via stepwise uncertainty reduction"},{"key":"rft.title","value":"Statistics and Computing"},{"key":"rft.jtitle","value":"Statistics and Computing"},{"key":"rft.volume","value":"25"},{"key":"rft.issue","value":"6"},{"key":"rft.date","value":"2013"},{"key":"rft.issn","value":"0960-3174"},{"key":"rft.au","value":"Victor Picheny"},{"key":"rft.genre","value":"article"}],"widgetId":"rgw10_56aba263ae6b7"},"id":"rgw10_56aba263ae6b7","partials":[],"templateName":"publicliterature\/stubs\/PublicationCoins.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationCoins.html?publicationUid=257299288","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationAuthors":{"data":{"publicationUid":257299288,"peopleItems":[{"data":{"authorUrl":"researcher\/19512962_Victor_Picheny","authorNameOnPublication":"Victor Picheny","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg","imageSize":"s","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Victor Picheny","profile":{"professionalInstitution":{"professionalInstitutionName":false,"professionalInstitutionUrl":null}},"professionalInstitutionName":false,"professionalInstitutionUrl":null,"url":"researcher\/19512962_Victor_Picheny","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":true,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":false,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"widgetId":"rgw13_56aba263ae6b7"},"id":"rgw13_56aba263ae6b7","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAuthorItem.html?entityId=19512962&imageSize=l&enableAuthorInviteButton=0","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"largeTooltip":false,"useRebrandedImageStyle":null,"widgetId":"rgw12_56aba263ae6b7"},"id":"rgw12_56aba263ae6b7","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorItem.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorItem.html?authorUid=19512962&authorNameOnPublication=Victor%20Picheny","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true}],"hasMore":false,"nextOffset":6,"useRebrandedImageStyle":null,"widgetId":"rgw11_56aba263ae6b7"},"id":"rgw11_56aba263ae6b7","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorList.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorList.html?publicationUid=257299288&context=pubdetail_authors_xflw&showContactAuthorButton=1","viewClass":"views.publicliterature.PublicationDetailAuthorListView","yuiModules":["rg.views.publicliterature.PublicationDetailAuthorListView"],"stylesheets":[],"_isYUI":true},"publicationAbstract":{"data":{"publicationUid":257299288,"abstract":"<noscript><\/noscript><div>Optimization of expensive computer models with the help of Gaussian process<br \/>\nemulators in now commonplace. However, when several (competing) objectives are<br \/>\nconsidered, choosing an appropriate sampling strategy remains an open question.<br \/>\nWe present here a new algorithm based on stepwise uncertainty reduction<br \/>\nprinciples to address this issue. Optimization is seen as a sequential<br \/>\nreduction of the volume of the excursion sets below the current best solutions,<br \/>\nand our sampling strategy chooses the points that give the highest expected<br \/>\nreduction. Closed-form formulae are provided to compute the sampling criterion,<br \/>\navoiding the use of cumbersome simulations. We test our method on numerical<br \/>\nexamples, showing that it provides an efficient trade-off between exploration<br \/>\nand intensification.<\/div>","canEdit":false,"isAdmin":false,"isArtifact":false,"showFullAbstract":false,"widgetId":"rgw14_56aba263ae6b7"},"id":"rgw14_56aba263ae6b7","partials":[],"templateName":"publicliterature\/stubs\/PublicationAbstract.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationAbstract.html?publicationUid=257299288","viewClass":"views.publicliterature.PublicationAbstractView","yuiModules":["rg.views.publicliterature.PublicationAbstractView"],"stylesheets":[],"_isYUI":true},"publicationKeywords":null,"publicationState":null,"isGuest":true,"isAdminEditingAllowed":false,"isArtifact":false,"figureListWidget":null,"previewImage":"https:\/\/i1.rgstatic.net\/publication\/257299288_Multiobjective_optimization_using_Gaussian_process_emulators_via_stepwise_uncertainty_reduction\/links\/02f48f2c0cf21189773bf244\/smallpreview.png","nativeAdDisclosure":null,"showFollowPublicationButton":false,"followPublicationPromo":"","widgetId":"rgw8_56aba263ae6b7"},"id":"rgw8_56aba263ae6b7","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailItem.html","templateExtensions":["generalHelpers"],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailItem.html?publicationUid=257299288&showActionBar=0&showContactAuthorButton=1&showRequestFulltextExperience=0&showNoRgAuthorsRequestFulltextExperience=0&showFollowPublicationPromo=0","viewClass":"views.publicliterature.PublicationDetailItemView","yuiModules":["rg.views.publicliterature.PublicationDetailItemView"],"stylesheets":[],"_isYUI":true},"similarPublications":{"data":{"publicationListItems":[{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":11994525,"url":"researcher\/11994525_Yakoub_Bazi","fullname":"Yakoub Bazi","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":71323522,"url":"researcher\/71323522_Naif_Alajlan","fullname":"Naif Alajlan","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":10761555,"url":"researcher\/10761555_Farid_Melgani","fullname":"Farid Melgani","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Jul 2012","journal":"IEEE Transactions on Geoscience and Remote Sensing","showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/254061323_Improved_Estimation_of_Water_Chlorophyll_Concentration_With_Semisupervised_Gaussian_Process_Regression","usePlainButton":true,"publicationUid":254061323,"feedStubs":null,"hasFeedStubs":false,"impactPoints":"3.51","url":"publication\/254061323_Improved_Estimation_of_Water_Chlorophyll_Concentration_With_Semisupervised_Gaussian_Process_Regression","title":"Improved Estimation of Water Chlorophyll Concentration With Semisupervised Gaussian Process Regression","displayTitleAsLink":true,"authors":[{"id":11994525,"url":"researcher\/11994525_Yakoub_Bazi","fullname":"Yakoub Bazi","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":71323522,"url":"researcher\/71323522_Naif_Alajlan","fullname":"Naif Alajlan","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":10761555,"url":"researcher\/10761555_Farid_Melgani","fullname":"Farid Melgani","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["IEEE Transactions on Geoscience and Remote Sensing 07\/2012; 50(7):2733-2743. DOI:10.1109\/TGRS.2011.2174246"],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/254061323_Improved_Estimation_of_Water_Chlorophyll_Concentration_With_Semisupervised_Gaussian_Process_Regression","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/254061323_Improved_Estimation_of_Water_Chlorophyll_Concentration_With_Semisupervised_Gaussian_Process_Regression\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw16_56aba263ae6b7"},"id":"rgw16_56aba263ae6b7","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=254061323","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":8111149,"url":"researcher\/8111149_Joshua_Knowles","fullname":"Joshua Knowles","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Mar 2006","journal":"IEEE Transactions on Evolutionary Computation","showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/3418871_ParEGO_A_Hybrid_Algorithm_With_On-Line_Landscape_Approximation_for_Expension_Multiobjective_Optimization_Problems","usePlainButton":true,"publicationUid":3418871,"feedStubs":null,"hasFeedStubs":false,"impactPoints":"3.65","url":"publication\/3418871_ParEGO_A_Hybrid_Algorithm_With_On-Line_Landscape_Approximation_for_Expension_Multiobjective_Optimization_Problems","title":"ParEGO: A Hybrid Algorithm With On-Line Landscape Approximation for Expension Multiobjective Optimization Problems","displayTitleAsLink":true,"authors":[{"id":8111149,"url":"researcher\/8111149_Joshua_Knowles","fullname":"Joshua Knowles","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["IEEE Transactions on Evolutionary Computation 03\/2006; 10(1-10):50 - 66. DOI:10.1109\/TEVC.2005.851274"],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/3418871_ParEGO_A_Hybrid_Algorithm_With_On-Line_Landscape_Approximation_for_Expension_Multiobjective_Optimization_Problems","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/3418871_ParEGO_A_Hybrid_Algorithm_With_On-Line_Landscape_Approximation_for_Expension_Multiobjective_Optimization_Problems\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw17_56aba263ae6b7"},"id":"rgw17_56aba263ae6b7","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=3418871","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":8111149,"url":"researcher\/8111149_Joshua_D_Knowles","fullname":"Joshua D. Knowles","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":33937555,"url":"researcher\/33937555_Evan_J_Hughes","fullname":"Evan J. Hughes","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Conference Paper","publicationDate":"Jan 2005","journal":"Lecture Notes in Computer Science","showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/221228406_Multiobjective_Optimization_on_a_Budget_of_250_Evaluations","usePlainButton":true,"publicationUid":221228406,"feedStubs":null,"hasFeedStubs":false,"impactPoints":"0.51","url":"publication\/221228406_Multiobjective_Optimization_on_a_Budget_of_250_Evaluations","title":"Multiobjective Optimization on a Budget of 250 Evaluations","displayTitleAsLink":true,"authors":[{"id":8111149,"url":"researcher\/8111149_Joshua_D_Knowles","fullname":"Joshua D. Knowles","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":33937555,"url":"researcher\/33937555_Evan_J_Hughes","fullname":"Evan J. Hughes","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["Evolutionary Multi-Criterion Optimization, Third International Conference, EMO 2005, Guanajuato, Mexico, March 9-11, 2005, Proceedings; 01\/2005"],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Conference Paper","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/221228406_Multiobjective_Optimization_on_a_Budget_of_250_Evaluations","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/221228406_Multiobjective_Optimization_on_a_Budget_of_250_Evaluations\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw18_56aba263ae6b7"},"id":"rgw18_56aba263ae6b7","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=221228406","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"viewClass":"sidebar","widgetId":"rgw15_56aba263ae6b7"},"id":"rgw15_56aba263ae6b7","partials":[],"templateName":"publicliterature\/stubs\/SimilarPublications.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.SimilarPublications.html?referencePublicationId=257299288&view=sidebar","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationFulltextPreview":null,"publicationResourcesFulltext":{"data":{"publicationUid":257299288,"publicationResourceList":{"data":{"publicationResourceItems":[{"data":{"publicationUid":257299288,"publicationType":"article","linkId":"02f48f2c0cf21189773bf244","fileName":"Multiobjective optimization using Gaussian process emulators via stepwise uncertainty reduction","fileUrl":"http:\/\/export.arxiv.org\/pdf\/1310.0732","name":"export.arxiv.org","nameUrl":"http:\/\/export.arxiv.org\/pdf\/1310.0732","canRemove":false,"fileIcon":"ico-pub","canPreview":true,"hasPublisherLink":null,"hasMetaData":true,"hide":false,"fulltext":"ico-pub","origin":"publication_list","isLastLink":true,"isUserLink":false,"widgetId":"rgw21_56aba263ae6b7"},"id":"rgw21_56aba263ae6b7","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceItem.html","templateExtensions":["generalHelpers"],"attrs":{"fileRequiredPublicationTypes":["code","coverPage","experimentFindings","method","negativeResults","presentation","rawData","researchProposal","workingPaper","artifact","dataset"]},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceItem.html?publicationUid=257299288&linkId=02f48f2c0cf21189773bf244&hide=0&disableJavascript=disableJavascript&useAlternativeTemplate=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"widgetId":"rgw20_56aba263ae6b7"},"id":"rgw20_56aba263ae6b7","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceList.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceList.html?publicationUid=257299288&limit=3&disableJavascript=disableJavascript&type=fulltextFile","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"resourceCount":1,"hidden":false,"showMore":false,"fulltext":true,"publicationDownloadCount":{"data":{"value":0,"valueFormatted":"0","widgetId":"rgw22_56aba263ae6b7"},"id":"rgw22_56aba263ae6b7","partials":[],"templateName":"publicliterature\/stubs\/PublicationDownloadCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDownloadCount.html?publicationUid=257299288","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw19_56aba263ae6b7"},"id":"rgw19_56aba263ae6b7","partials":[],"templateName":"publicliterature\/stubs\/PublicationResources.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResources.html?publicationUid=257299288&type=fulltextFile&disableJavascript=1","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationResourcesAttachments":{"data":{"publicationUid":257299288,"publicationResourceList":{"data":{"publicationResourceItems":[],"widgetId":"rgw24_56aba263ae6b7"},"id":"rgw24_56aba263ae6b7","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceList.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceList.html?publicationUid=257299288&limit=3&disableJavascript=disableJavascript&type=attachmentFile","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"resourceCount":0,"hidden":true,"showMore":false,"fulltext":false,"publicationDownloadCount":{"data":{"value":0,"valueFormatted":"0","widgetId":"rgw25_56aba263ae6b7"},"id":"rgw25_56aba263ae6b7","partials":[],"templateName":"publicliterature\/stubs\/PublicationDownloadCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDownloadCount.html?publicationUid=257299288","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw23_56aba263ae6b7"},"id":"rgw23_56aba263ae6b7","partials":[],"templateName":"publicliterature\/stubs\/PublicationResources.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResources.html?publicationUid=257299288&type=attachmentFile","viewClass":"views.publicliterature.PublicationResourcesView","yuiModules":["rg.views.publicliterature.PublicationResourcesView"],"stylesheets":[],"_isYUI":true},"publicationText":{"data":{"hide":false,"pages":[{"page":1,"text":"arXiv:1310.0732v1  [math.OC]  2 Oct 2013\nMultiobjective optimization using Gaussian process emulators via\nstepwise uncertainty reduction\nVictor Picheny\nINRA, 31326 Castanet Tolosan, France\nTel.: +33-5-61 28 54 39\nvictor.picheny@toulouse.inra.fr\nDecember 16, 2013\nAbstract\nOptimization of expensive computer models with the help\nof Gaussian process emulators in now commonplace. How-\never, when several (competing) objectives are considered,\nchoosing an appropriate sampling strategy remains an\nopen question. We present here a new algorithm based on\nstepwise uncertainty reduction principles to address this\nissue. Optimization is seen as a sequential reduction of the\nvolume of the excursion sets below the current best solu-\ntions, and our sampling strategy chooses the points that\ngive the highest expected reduction. Closed-form formulae\nare provided to compute the sampling criterion, avoiding\nthe use of cumbersome simulations. We test our method\non numerical examples, showing that it provides an effi-\ncient trade-off between exploration and intensification.\nkeywords Kriging; EGO; Pareto front; Excursion sets\n1 Introduction\nWe consider the problem of simultaneous optimization of\nseveral objective functions over a design region X \u2282 Rd:\ny(1)(x),...,y(q)(x), min\nwhere y(i): X \u2192 R are outputs of a complex com-\nputer code. The objectives being typically conflicting,\nthere exists no unique minimizer, and the goal is to\nidentify the set of optimal solutions, called Pareto front\n(Collette and Siarry, 2003). Defining that a point domi-\nnates another if all his objectives are better, the Pareto\nfront X\u2217is the subset of the non-dominated points in X:\n\u2200x\u2217\u2208 X\u2217,\u2200x \u2208 X,\u2203k \u2208 {1,...,q} such that\ny(k)(x\u2217) \u2264 y(k)(x).\nWhen the computational cost of a single model evaluation\nis high, a well-established practice consists of using Gaus-\nsian process (GP) emulators to approximate the model\noutputs and guide the optimization process. Following\nthe seminal article of Jones et al. (1998) and its Efficient\nGlobal Optimization (EGO) algorithm for single objec-\ntive optimization, several strategies have been proposed\nin the past few years to address the multi-objective prob-\nlem (Knowles, 2006; Keane, 2006; Ponweiser et al., 2008;\nWagner et al., 2010). They consist in evaluating sequen-\ntially the computer model at the set of inputs that maxi-\nmizes a so-called infill criterion, derived from the GP em-\nulator, that expresses a trade-off between exploration of\nunsampled areas and sampling intensification in promis-\ning regions. While the single objective case has been ex-\ntensively discussed (Jones, 2001; Wang and Shan, 2007),\nfinding efficient and statistically consistent infill criteria\nfor the multi-objective case remains an open question.\nAlternatively to the EGO paradigm, stepwise uncer-\ntainty reduction (SUR) strategies aim at reducing, by se-\nquential sampling, an uncertainty measure about a quan-\ntity of interest. In a single objective optimization context,\nVillemonteix et al. (2009) defined the Shannon entropy of\nthe maximizer (computed using the GP model) as an un-\ncertainty measure: a smaller entropy implies that the max-\nimizer is well-identified. They show that their approach\noutperforms the EGO strategy on a series of problems.\nAnother example in a reliability assessment context can be\nfound in Bect et al. (2012). In general, SUR approaches\nallow to define policies rigorously with respect to a given\nobjective, resulting in very good performances. However,\nthey are often challenging to use in practice, as they rely\non very expensive GP simulations.\nWe propose here a novel SUR strategy to address the\nmulti-objective problem. It is based on a measure of un-\ncertainty of the current identification of the Pareto front\nX\u2217, hence avoiding some of the drawbacks of the existing\ncriteria (hierarchy between objectives, difficult-to-tune pa-\nrameters, etc.). Following Chevalier et al. (2012), explicit\nformulae for the expected uncertainty reduction are pro-\nvided, avoiding the need to rely on simulations.\nThe paper is organized as follows: section 2 presents the\nGP model and the basics of GP-based optimization. Then,\nwe describe our SUR strategy for a single objective in sec-\ntion 3 and for several objectives in section 4. We provide\nsome numerical experiments in section 5 and compare our\nmethod to the state-of-the-art. Finally, advantages and\ndrawbacks of the method are discussed in section 6.\n1"},{"page":2,"text":"2 Some\nprocess-based optimization\nconceptsof Gaussian-\n2.1 Gaussian process emulation\nWe consider first the emulation of a single computer re-\nsponse y. The response is modelled as\nY (.) = f(.)T\u03b2 + Z(.), (1)\nwhere f(.)T= (f1(.),...,fp(.)) is a vector of trend func-\ntions, \u03b2 a vector of (unknown) coefficients and Z(.) is a\nGaussian process (GP) Z with zero mean and known co-\nvariance kernel k (Cressie, 1993; Rasmussen and Williams,\n2006). Let us call Anthe event:\n{Y (x1) = y1,...,Y (xn) = yn};\nconditionally on An, the mean and covariance of Y are\ngiven by:\nE?Y (x)??An\ncn(x,x\u2032)=\nk(x,x\u2032) \u2212 kn(x)TK\u22121\n+\n?f(x\u2032)T\u2212 kn(x\u2032)TK\u22121\nwhere\nmn(x)=\n?=\n=\nf(x)T\u02c6\u03b2 + kn(x)TK\u22121\ncov?Y (x),Y (x\u2032)??An\n?f(x)T\u2212 kn(x)TK\u22121\nn(yn\u2212 Fn\u02c6\u03b2),\n?\n?T?FT\n=\nnkn(x\u2032)\nnFn\nnK\u22121\nnFn\n?\u22121\nnFn\n?,\n\u2022 yn= (y1,...,yn)Tare the observations,\n\u2022 Kn= (k(xi,xj))1\u2264i,j\u2264nis the observation covariance\nmatrix,\n\u2022 kn(x)T= (k(x,x1),...,k(x,xn)),\n\u2022 Fn=?f(x1)T,...,f(xn)T?T, and\n\u2022\u02c6\u03b2 =?FT\nIn addition, the prediction variance is defined as\nnK\u22121\nnFn\n?\u22121FT\nnK\u22121\nnynis the best linear un-\nbiased estimate of \u03b2.\ns2\nn(x) = cn(x,x).\nThe covariance kernel depends on parameters that are\nusually unknown and must be estimated from an initial set\nof responses. Typically, maximum likelihood estimates are\nobtained by numerical optimization and used as face value,\nthe estimates being updated when new observations are\nadded to the model. The reader can refer to Stein (1999)\n(chapter 6), Rasmussen and Williams (2006) (chapter 5)\nor Roustant et al. (2012) for detailed calculations and im-\nplementation issues.\nWhen several functions y(1),...,y(q)are predicted si-\nmultaneously, it is possible to take their dependency into\naccount (Kennedy and O\u2019Hagan, 2001; Craig et al., 2001).\nHowever, in this work we consider all the processes Y(i)\nindependent, hence modelled as above, which is in line\nwith current practice.\n2.2 Gaussian-process-based optimization\nwith a single objective\nThe EGO strategy, as well as most of its modifications,\nis based on the following scheme. An initial set of ob-\nservations is generated, from which the GP model is con-\nstructed and validated. Then, new observations are ob-\ntained sequentially, at the point in the design space that\nmaximizes the infill criterion, and the model is updated\nevery time a new observation is added to the training set.\nThe two later steps are repeated until a stopping criterion\nis met.\nThe expected improvement criterion (EI) used in EGO\nrelies on the idea that progress is achieved by perform-\ning an evaluation at step n if the (n + 1)thdesign has a\nlower objective function value than any of the n previous\ndesigns. Hence, the improvement is defined as the differ-\nence between the current observed minimum and the new\nfunction value if it is positive, or zero otherwise, and EI\nis its conditional expectation under the GP model:\nEI(x) = E?max?0,ymin\nwhere ymin\nn\ndenotes the current minimum of y found at\nstep n: ymin\nn\n= min(y1,...,yn).\nEGO is the one-step optimal strategy (in expectation)\nregarding improvement: at step n, the new measurement\nis chosen as\nxn+1= argmax\nn\n\u2212 Y (x)?|An\n?,\nx\u2208XEI(x),\nwhich is in practice done by running an optimization al-\ngorithm. It has been shown in Jones (2001) that EGO\nprovides, among numerous alternatives, an efficient solu-\ntion for global optimization.\n2.3Gaussian-process-based optimization\nwith several objectives\nSeveral adaptations of EGO to the multi-objective frame-\nwork have been proposed; a review can be found in\nPonweiser et al. (2008). The main difficulty is that the\nconcept of improvement cannot be transferred directly, as\nthe current best point is here a set, and the gain is mea-\nsured on several objectives simultaneously. In Knowles\n(2006), the objectives are aggregated in a single func-\ntion using random weights, which allows using the stan-\ndard EGO. Keane (2006) derived an EI with respect to\nmultiple objectives. Ponweiser et al. (2008) proposed an\nhypervolume-based infill criterion, where the improvement\nis measured in terms of hypervolume increase.\n3Single objective optimization by\nstepwise uncertainty reduction\nWe consider first the case of a problem with a single ob-\njective y to minimize. In this section, we propose a new\nstrategy in a form similar to EGO that uses an alterna-\ntive infill criterion based on stepwise uncertainty reduction\nprinciples. The adaptation of this criterion to the multi-\nobjective case is presented in Section 4.\n2"},{"page":3,"text":"3.1 Definition of an uncertainty measure\nfor optimization\nThe EGO strategy focuses on progress in terms of objec-\ntive function value. It does not account (or only indirectly)\nfor the knowledge improvement that a new measurement\nwould provide to the GP model, nor for the discrepancy\nbetween the location of the current best design found and\nthe actual minimizer (which is actually most users\u2019 objec-\ntive).\nAlternative sampling criteria have been proposed to ac-\ncount for these two aspects. In Villemonteix et al. (2009),\nthe IAGO stategy chooses the point that minimizes the\nposterior Shannon entropy of the minimizer: the inter-\nest of performing a new observation is measured in gain of\ninformation about the location of the minimizer. Unfortu-\nnately, it relies on expensive GP simulations, which makes\nits use challenging in practice. Gramacy and Lee (2011)\nproposed an integrated expected conditional improvement\nto measure a global informational gain of an observation.\nIn the noisy case, Scott et al. (2011) proposed a some-\nhow similar knowledge gradient policy that also measures\nglobal information gain. However, as both criteria rely on\nnotions of improvement, it makes them difficult to adapt\nto the multiobjective case. The criterion we propose below\naddress this issue.\nConsider that n measurements have been performed.\nAs a measure of performance regarding the optimization\nproblem, we consider the expected volume of excursion set\nbelow the current minimum ymin\n?P?Y (x) \u2264 ymin\nSimilarly to the Shannon entropy measure in IAGO, a\nlarge volume indicates that the optimum is not yet pre-\ncisely located (see Figure 1); on the contrary, a small vol-\nume indicates that very little can be gained by pursuing\nthe optimization process. Following the stepwise uncer-\ntainty reduction paradigm, this volume is an uncertainty\nmeasure related to our objective (finding the minimizer\nof y); minimizing the uncertainty amounts to solving the\noptimization problem.\nThe probability pn(x,ymin\nn\nwhich is often referred to as probability of improvement\n(Jones, 2001), can be expressed in closed form, and Eq. (2)\nwrites:\n?\nwhere \u03a6(.) is the cumulative distribution function (CDF)\nof the standard Gaussian distribution. Hypothesizing that\na measurement yn+1 is performed at a point xn+1, its\nbenefit can be measured by the reduction of the expected\nvolume of excursion set \u2206 = evn\u2212 evn+1, with:\n?\n?\nOf course, evn+1 cannot be known exactly without eval-\nuating yn+1. However, we show in the following that its\nn\n:\nevn= EX\nn\n|An\n??. (2)\n) := P?Y (x) \u2264 ymin\nn\n|An\n?,\nevn=\nX\npn(x,ymin\nn\n)dx =\n?\nX\n\u03a6\n?ymin\nn\n\u2212 mn(x)\nsn(x)\n?\ndx, (3)\nevn+1\n=\nX\npn+1(x,min?ymin\n\u03a6\nn\n,yn+1\n?\u2212 mn+1(x)\nsn+1(x)\n?)dx\n=\nX\n?\nmin?ymin\nn\n,yn+1\n?\ndx.\nexpectation can be calculated in closed form, leading to\na suitable infill criterion. To do so, we first formulate a\nseries of propositions in the next subsection.\n3.2 Probabilities updates\nAn interesting property of the GP model is that, when a\nnew observation yn+1= y(xn+1) is added to the training\nset, its new predictive distribution can be expressed simply\nas a function of the old one (Emery, 2009):\nmn+1(x)=mn(x) +\ncn(x,xn+1)\ncn(xn+1,xn+1)(yn+1\u2212 mn(xn+1));\nn(x) \u2212cn(x,xn+1)2\ns2\nn(xn+1)\ns2\nn+1(x)=s2\n.(4)\nNote that only mn+1(x) depends on the value of the new\nobservation yn+1. Now, conditionally on the n first obser-\nvations, Yn+1is a random variable (as the new observation\nhas not yet been performed) with its moments given by\nthe GP model:\nYn+1\u223c N?mn(xn+1),s2\nWe can then define the future expectation Mn+1(x) (or\nany quantity depending on it) as a random variable con-\nditionally on Anand on the fact that the next observation\nwill be at xn+1. This applies to any quantity depending\non Yn+1or Mn+1(x), for instance, the probability of being\nbelow a threshold a \u2208 R:\n?a \u2212 Mn+1(x)\nProposition 3.1. Without any restriction on the value\nof Yn+1, the expectation of the future probability of being\nbelow the threshold is equal to the current probability:\nn(xn+1)?.\nPn+1(x,a) = \u03a6\nsn+1(x)\n?\n.\nP(Y (x) \u2264 a|An,Y (xn+1) = Yn+1)=\n=\nE?Pn+1(x,a)??An\n?\npn(x,a).\nProposition 3.2. Conditioning further by Yn+1 \u2264 b,\nthe probability expectation writes in simple form using the\nGaussian bivariate CDF:\nP?Y (x) \u2264 a??An,Y (xn+1) = Yn+1,Yn+1\u2264 b?\n=\n?\u00afb,\u02dc a?,\nwhere \u03a6\u03c1 is the Gaussian bivariate CDF with zero mean\n?1\n\u03c1 =\nsn(xn+1)sn(x).\nq(x,b,a) :=\n\u00d7\nP?Yn+1\u2264 b??An\n\u03a6\u03c1\n?\nE?Pn+1(x,a) \u00d7\n?Yn+1\u2264b\n??An\n?\n=\n(5)\nand covariance\n\u03c1\n1\u03c1\n?\n,\u00afb =\nb\u2212mn(xn+1)\nsn(xn+1), \u02dc a =a\u2212mn(x)\nsn(x)\nand\ncn(x,xn+1)\nCorollary 3.3. Similarly, conditioning by Yn+1\u2265 b leads\nto:\nP?Y (x) \u2264 a??An,Y (xn+1) = Yn+1,Yn+1\u2265 b?\n=\n\u03a6\u2212\u03c1\nr(x,b,a):=\n\u00d7\nP?Yn+1\u2265 b??An\n?\n?\u2212\u00afb,\u02dc a?. (6)\n3"},{"page":4,"text":"The final proposition resembles Proposition 3.2, but the\nfixed threshold a is here replaced by Yn+1:\nProposition 3.4. The expectation of the probability that\nY (x) is smaller than Yn+1, conditionally on Yn+1\u2264 b, is\ngiven by:\nP?Y (x) \u2264 Yn+1|An,Y (xn+1)\n=\n=\n?\u00afb,\u03b7?,\nwith:\nh(x,b) :=\nYn+1,Yn+1\u2264 b?P?Yn+1\u2264 b??An\n\u03a6\u03bd\n?\nE?Pn+1(x,Yn+1) \u00d7\n?Yn+1\u2264b\n??An\n?\n=(7)\n\u03b7=\nmn(xn+1) \u2212 mn(x)\nn(x) + s2\ncn(x,xn+1) \u2212 s2\nsn(xn+1)?s2\nAll the proofs are reported in Appendix A.\n?s2\nn(xn+1) \u2212 2cn(x,xn+1)\nand\n\u03bd=\nn(xn+1)\nn(x) + s2\nn(xn+1) \u2212 2cn(x,xn+1).\n3.3A Stepwise uncertainty reduction cri-\nterion\nComing back to the SUR criterion, at step n the future\nvolume of excursion set EVn+1is a random variable, and\nits expectation is:\nE?EVn+1\n=\nX\n??An,Y (xn+1) = Yn+1\nLet \u03d5(yn+1) be the probability density function (PDF) of\nYn+1conditionally on An. We have:\nEEV (xn+1) :=\n??An,Y (xn+1) = Yn+1\nsn+1(x)\n?\n?\nE\n?\n\u03a6\n?\nmin?ymin\nn\n,Yn+1\n?\u2212 Mn+1(x)\n?\n?\ndx.\nEEV (xn+1)\n?\n?\n?+\u221e\n?\n=\nX\n?\n??ymin\n\u03a6\nR\n\u03a6\n?\nmin?ymin\n?yn+1\u2212 mn+1(x)\n?ymin\n?h(x,ymin\nThe first term of the integrand is given by Eq. (7) in Propo-\nsition 3.4, with b = ymin\nn\n, and the second term is given by\nEq. (6) in Corrolary 3.3, with a = b = ymin\n?\nn\n,yn+1\nsn+1(x)\n?\u2212 mn+1(x)\n?\n?\n,ymin\nn\n?\nd\u03d5(yn+1)dx\n=\nX\nn\n\u2212\u221e\n\u03a6\nsn+1(x)\n+\nymin\nn\nn\n\u2212 mn+1(x)\nsn+1(x)\nd\u03d5(yn+1)?dx\n)?dx.=\nX\nn\n) + r(x,ymin\nn\nn\n, hence:\nEEV (xn+1) =\nX\n?\u03a6\u03bd\n?ymin\nn\n,\u03b7?+ \u03a6\u03c1\n?\u2212ymin\nn\n, ? ymin\nn\n??dx,\n(8)\nwith:\nymin\nn\n= (ymin\nn\n\u2212 mn(xn+1))\/sn(xn+1)\nand\n? ymin\nn\n= (ymin\nn\n\u2212 mn(x))\/sn(x).\nThe SUR optimization strategy consists in adding the\nexperiment that minimizes the expected volume of excur-\nsion set (or maximizes the difference), that is, the one-step\noptimal policy in terms of reduction of the uncertainty on\nthe objective function minimizer:\nxn+1= arg min\nx+\u2208XEEV (x+) (9)\nRemark In general, the probability of improvement\npn(x,ymin\nn\n) is high where the prediction mean mn(.) is\nlow and\/or the prediction variance s2\nply choosing points that maximize pn(x,ymin\nto be inefficient (Jones, 2001), as it does not consider the\namplitude of the gain in the objective function.\nEEV (x+) strongly depends on the potential gain am-\nplitude. Indeed, minimizing the expected volume relies\non two mecanisms: reducing the local uncertainty and\nlowering the current minimum value (ymin\nachieved by adding measurements in unsampled regions\n(high s2\nn(.)), the second in regions where this potential re-\nduction is high. Hence, the EEV criterion can be seen as\na mixed measure of uncertainty on the current minimum\nlocation and of potential gain in the objective function.\nn(.) is high. Sim-\nn\n) is known\nHere,\nn\n). The first is\n3.4 Illustration\nFigure 1 illustrates the concept of reduction of volume of\nexcursion on a toy example. A GP model is built on a six-\npoint training set, from which the probability of improve-\nment p6(x,ymin\n6\n) is computed for every point in X = [0,1].\nWe see that it can be intepreted as an indicator of the\nuncertainty we have about the location of the actual min-\nimizer x\u2217= 0.47, as the model can only predict that x\u2217\nis likely to be between 0.4 and 0.6. Then, we consider\ntwo candidate points (x+= 0.2 and x+= 0.5) and com-\npute, for each, the expected new probability (integrand\nin Eq. (8)). We see that the probability is likely to re-\nmain mostly unchanged by adding the measurement at\nx+= 0.2 (which is, indeed, a region with high response\nvalue), while it would be considerably reduced by adding\na measurement at x+= 0.5. In terms of volume of excur-\nsion set, we have EEV (0.2) \u2248 ev6 (no reduction), while\nEEV (0.5) \u2248 ev6\/3 (large reduction): the EEV criterion\nclearly indicates x+= 0.5 as a better sampling location.\n4Multi-objective optimization by\nstepwise uncertainty reduction\n4.1 Volume\nPareto front\n?y(1)(x),...,y(q)(x)?\nother point x\u2032if y(k)(x) \u2264 y(k)(x\u2032) for all k in {1,...,q},\nwhich we denote by x\u2032\u227a x in the following. At step n,\nXn = {x1,...,xn} is the current experimental set and\nYn = {y(x1),...,y(xn)} the corresponding set of mea-\nsures. The non-dominated subset X\u2217\nthe current Pareto front (of size m \u2264 n). In the objective\nofexcursion behind the\nLet y(x) =\njective functions to minimize. A point x dominates an-\nbe the vector of ob-\nnof Xn constitutes\n4"},{"page":5,"text":"0.0 0.20.4 0.60.81.0\n0.0\n0.5\n1.0\nGP model\n0.00.2 0.4 0.60.8 1.0\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nProba of improvement\nFigure 1: Illustration of the effect of a new observation on the EV criterion. Left: actual objective function (dotted\nline), GP model (depicted by its mean in black plain line and 95% confidence interval in grey) based on six observations\n(black circles). The horizontal line shows the current minimum; the vertical bars are placed at two candidate locations.\nRight: probability of improvement given by the current model and expected updated probability for each candidate.\nAdding a point at x+= 0.5 (mixed line) is likely to reduce substantially the probability, while adding a point at\nx+= 0.05 (dotted line) has little expected effect.\nspace, the corresponding subset Y\u2217\ndominated and not dominated by the experimental set.\nThen, we decompose the objective space plane using a\ntesselation {\u03a9i}i\u2208{1,...,I}of size I = (m+1)q(\u222ai\u2208I\u03a9i= Rq\nand \u2229i\u2208I\u03a9i= \u2205), each cell being a hyperrectangle defined\nas:\nnseparates the regions\n\u03a9i= {y \u2208 Rq|y(k)\nEach couple (y(k)\nof the vector?\u2212\u221e,y(k)(x\u2217\nA cell \u03a9i dominates another cell \u03a9j (\u03a9j \u227a \u03a9i) if any\npoint in \u03a9i dominates any point in \u03a9j, and it partially\ndominates \u03a9j if there exists a point in \u03a9j that is domi-\nnated by any point in \u03a9i. Otherwise, we say that \u03a9j is\nnot dominated by \u03a9i(\u03a9j?\u227a \u03a9i).\nWe denote by I\u2217the indices of all the non-dominated\ncells at step n, that is, the cells that are not dominated by\nany point of X\u2217\nn. In two dimensions, the non-dominated\ncells are located in the bottom left half of the plane (Figure\n2).\nNow, let us assume that GP models are fitted to each\nobjective y(k). At step n, the probability that Y(x) be-\nlongs to the cell \u03a9iis:\nP?Y(x) \u2208 \u03a9i\n=\n\u03a6\ns(k)\nn (x)\ni\u2212\u2264 y(k)< y(k)\ni\u2212,y(k)\n1),...,y(k)(x\u2217\ni+,k \u2208 {1,...,q}}.\ni+) consists of two consecutive values\nm),+\u221e?. An illus-\ntration is given in Figure 2.\npi\nn(x)=\n??An\n?\nq?\nq?\nk=1\n?\ny(k)\ni+\u2212 m(k)\nn (x)\n?\n\u2212 \u03a6\n?\ny(k)\ni\u2212\u2212 m(k)\ns(k)\nn (x)\nn (x)\n?\n:=\nk=1\npi(k)\nn\nby pairwise independence of Y(1),...,Y(q). The probabil-\nity that x is not dominated by any point of Xnis then the\nprobability that Y(x) belongs to one of the non-dominated\nparts of the objective space. As the \u03a9i\u2019s are disjoint, it is\nequal to:\nP(x ?\u227a Xn\n??An) =\n?\ni\u2208I\u2217\npi\nn(x). (10)\nFigure 2: Example of Pareto front generated by four points\n(circles), and associated tesselation. The grey area corre-\nsponds to the dominated cells.\nFigure 3: Example of Pareto front modification due to\na new measurement. Two points are removed from the\nPareto front while the new point is added. The hatched\narea represents the additional dominated region.\n5"},{"page":6,"text":"Finally, the volume of the excursion sets behind the\nPareto front is equal to the integral of this probability\nover X:\n?\n=\nX\ni\u2208I\u2217\nevn\n=\nX\nP(x ?\u227a Xn\n?\n??An)dx\n?\npi\nn(x)dx =\n?\ni\u2208I\u2217\n?\nX\npi\nn(x)dx. (11)\nWhen evnis high, a large proportion of the design space is\nlikely to be better than the current Pareto set; inversely,\nwhen X\u2217\ntends to zero. Hence, it defines naturally an uncertainty\nindicator for a SUR strategy.\nnapproaches the actual Pareto set X\u2217, the volume\n4.2SUR criterion derivation\nNow, let us consider that a measurement yn+1 is per-\nformed at a point xn+1. Compared to step n, the vol-\nume ev is modified by two means. First, the new mea-\nsurement will modify the quantities m(k)\n{1,...,q}), hence, the probabilities pi\nnew measurement is not dominated by the current Pareto\nset, it modifies the Pareto optimal front, as the new value\ny(xn+1) is added to Y\u2217and the values of Y\u2217dominated\nby y(xn+1) (if they exist) are removed. An example of\nsuch update is given in Figure 3.\nFocusing on the probability that a point remains non-\ndominated (Eq. (10)), accounting for the modifications\nof the models is relatively easy (that is, computing the\nquantity pi\nn+1(.)), but accounting for modifications in the\nPareto front is complex, as both the number of elements\nand their values might change. To address this issue, we\nconsider that the updated probability P(x ?\u227a Xn+1\ncan be computed using the same sum as for P(x ?\u227a Xn\n(Eq. (10)) by modifying its elements pi\nn (x), s(k)\nn(x). Second, if the\nn (x) (k \u2208\n??An+1)\n??An)\nn(x):\nP(x ?\u227a Xn+1\n??An+1) =\n?\ni\u2208I\u2217\n\u02dc pi\nn+1(x),\nwith\n\u02dc pi\nn+1(x) = P\n?\nx ?\u227a Xn+1\u2229Y(x) \u2208 \u03a9i\n???An,y(xn+1) = yn+1\nn+1(x) are random, as\n?\nand the \u03a9i\u2019s defined using Y\u2217\nSeing from step n, the\u02dcPj\nn(not Y\u2217\nn+1).\nY (xn+1)(k)\u223c N\n?\nm(k)\nn(xn+1),s(k)2\nn\n(xn+1)\n?\n,\n\u2200k \u2208 {1,...,q}.\nThe expectation of the new volume is then:\nEEV (xn+1)=\nE\n\uf8ee\n\uf8f0\n?\nX\n?\n?\nj\u2208I\u2217\n\u02dcPj\nn+1(x)dx\n\uf8f9\n\uf8fb\n=\n?\nj\u2208I\u2217\nX\nE\n?\u02dcPj\nn+1(x)\n?\ndx.\nThis expression can be decomposed by conditioning on\nthe range values of the new observation (using the fact\nthat the \u03a9i\u2019s are disjoint):\n?\u02dcPj\n=\nPn+1\nE\nn+1(x)\n?\n?\ni\u2208I\n?\nx\n?\u227a Xn+1\u2229 Y(x) \u2208 \u03a9j\n?\n???Yn+1\u2208 \u03a9i\n?\n\u00d7\nPn+1\nYn+1\u2208 \u03a9i\n?\n:=\n?\ni\u2208I\npij(x),\nwhere Pn+1is the probability conditional on\n?\nWe first note from Proposition 3.1 that\nAn,Y(xn+1) = Yn+1\n?\n.\nPn+1[Yn+1\u2208 \u03a9i] = pi\nn(xn+1).\nThen, leaving aside non-domination, the probability that\nY(x) belongs to \u03a9j knowing that Yn+1belongs to \u03a9iis\ngiven by:\nPn+1\n?\nY(x) \u2208 \u03a9j\n???Yn+1\u2208 \u03a9i\n?\n(xn+1),\n?\n\u00d7 pi\nn(xn+1) =\nq?\nk=1\nb(k)\nij(x),\nwith:\nb(k)\nij(x)=\nPn+1\ny(k)\nj\u2212\u2264 Y(k)(x) < y(k)\nj+\n???y(k)\ni\u2212\u2264 Y(k)\nn+1< y(k)\ni+\n?\n\u00d7\npi(k)\nn\npi(k)\nn\n(xn+1) = Pn\n?\ny(k)\ni\u2212\u2264 Y(k)\nn+1< y(k)\ni+\n?\n,\nby pairwise independence of Y(1),...,Y(q). We show in\nAppendix B that b(k)\nij(x) can be expressed in closed form\nas:\n?\n\u2212\nb(k)\nij(x)=\n\u03a6(k)\n\u03c1\ny(k)\ni+,?\ny(k)\ny(k)\nj+\n?\n?\n\u2212 \u03a6(k)\n\u03c1\n?\n?\ny(k)\ni+,?\ny(k)\ny(k)\nj\u2212\n?\n?\n\u03a6(k)\n\u03c1\n?\ni\u2212,?\ny(k)\nj+\n+ \u03a6(k)\n\u03c1\ni\u2212,?\ny(k)\nj\u2212\nwith the notations introduced in Section 3.2.\nNow, we define:\n?\ny(k)\nd(k)\nij(x)=\n???\nPn+1\ny(k)\nj\u2212\u2264 Y(k)(x) < y(k)\ni\u2212\u2264 Y(k)\nj+\u2229 Y(k)\n\u00d7 pi(k)\nn+1\u2264 Y(k)(x)\n(xn+1),\nn+1< y(k)\ni+\n?\nn\nwhich is identical to b(k)\nY(k)\nponent of the new observation dominates the k-th compo-\nnent of Y(x). We have x \u227a xn+1 only if the condition\nY(k)\nprobability of occurence?p\n\u2022 y(k)\nwhich implies d(k)\nij(x) = 0;\nij(x) with the additional condition\nn+1\u2264 Y(k)(x). This condition is met when the k-th com-\nn+1\u2264 Y(k)(x) is met for all components, hence, with\nk=1d(k)\nij(x). Three cases arise:\ni\u2212\u2265 y(k)\nj+: the component cannot be dominated,\n\u2022 y(k)\nwhich implies d(k)\ni+\n\u2264 y(k)\nj\u2212: the component is always dominated,\nij(x) = b(k)\nij(x);\n6"},{"page":7,"text":"\u2022 y(k)\nthe same interval of variation, and:\ni+= y(k)\nj+(and y(k)\ni\u2212= y(k)\nj\u2212): Y(k)(x) and Y(k)\nn+1share\nd(k)\nij(x)=\nPn+1\n?\nF(k)\nn+1\u2264 Y(k)(x) < y(k)\n(xn+1),\ni+\n???y(k)\ni\u2212\u2264 Y(k)\nn+1< y(k)\ni+\n?\n\u00d7\npi(k)\nn\nwhich is equal (as shown in Appendix B) to:\n?\n\u03a6(k)\n\u03bd\nd(k)\nij(x)=\n\u03a6(k)\n\u03c1\ny(k)\ni+,?\ny(k)\ny(k)\nj+\n?\n\u2212 \u03a6(k)\n\u03bd\n?\n?\ny(k)\ni+,\u03b7(k)?\ny(k)\ny(k)\n+\n?\ni\u2212,\u03b7(k)?\n\u2212 \u03a6(k)\n\u03c1\ni\u2212,?\nj+\n?\n.\nThe probability of Y(x) being non-dominated while in\n\u03a9j(and Yn+1being in \u03a9i) is then:\npij(x) =\nq?\nk=1\nb(k)\nij(x) \u2212\nq?\nk=1\nd(k)\nij(x).\nIf \u03a9j \u227a \u03a9i, the new observation dominates any point\nin \u03a9j, hence d(k)\nij(x) for all k, which gives\npij(x) = 0. Inversely, if \u03a9j?\u227a \u03a9i, the new observation can-\nnot dominate any point in the cell \u03a9j. We have d(k)\nfor at least one value of k, and pij(x) is the probability\nthat Y(x) belongs to \u03a9j: pij(x) =?q\nability that it is non-dominated at step n + 1 using:\nij(x) = b(k)\nij(x) = 0\nk=1b(k)\nij(x).\nFinally, for a given point x \u2208 X, we compute the prob-\nPn+1(x ?\u227a Xn+1) =\n?\ni\u2208I\n?\nj\u2208I\u2217\npij(x),\nand the SUR criterion is:\nEEV (xn+1) =\n?\ni\u2208I\n?\nj\u2208I\u2217\n?\nX\npij(x)dx, (12)\nwith:\npij(x) =\n\uf8f1\n\uf8f4\n\uf8f4\n\uf8f3\n\uf8f2\n0\n?q\nif \u03a9j\u227a \u03a9i\nif \u03a9j?\u227a \u03a9i\notherwise\nk=1b(k)\n?q\nij(x)\nij(x) \u2212?q\nk=1b(k)\nk=1d(k)\nij(x)\n(13)\nThe first sum in Eq. (12) accounts for Yn+1 potentially\nbeing in any cell \u03a9i; the second sum accounts for Y(x)\npotentially being in a non-dominated cell \u03a9j.\n4.3 Computation\nEvaluating the criterion as in Eq. (12) is a non-trivial task;\nbesides, a relatively fast computation is needed, as it may\nbe embedded in an optimization loop to search for the\nbest new observation (Eq. (9)). We provide here some\ntechnical solutions to ease its computation. Some of these\nissues have also been experienced with SUR criteria for\ninversion, as reported in Chevalier et al. (2012, 2013).\nFirstly, as no closed form exists for the integration over\nthe design domain X in Eq. (12), one may rely on Monte-\nCarlo integration, with approximations of the form:\n?\nX\npij(x)dx \u22481\nL\nL\n?\nl=1\nwlpij(xl),\nwhere the xl\u2019s and wl\u2019s are integration points and weights,\nrespectively. One solution to alleviate the computational\ncost is to use a fixed set of integration points while search-\ning for the best new observation. Then, many quantities\nthat do not depend on xn+1can be precalculated only once\nbeforehand outside the optimization loop, as suggested in\nChevalier et al. (2012).\nSecondly, the criterion relies on the bivariate normal\ndistribution, which also must be computed numerically.\nVery efficient programs can be found, such as the R pack-\nage pbivnorm (Kenkel, 2012), which makes this task rela-\ntively inexpensive.\nThirdly, the tesselation used in the previous section has\nI = (m + 1)qelements, with I\u2217= I\/2 non-dominated\nelements, making the computation of the double sum in\nEq. (12) intensive. As detailed in Section 4.4 for the two\ndimensional case, the number of elements can be very sub-\nstantially reduced by grouping cells together. Note how-\never that such decomposition may not be straightforward\nin high dimension.\nFinally, as the optimization progresses, it is likely that\nthe Pareto set grows, making the criterion more expen-\nsive to compute as more cells are to be considered. This\nproblem is shared by all GP-based strategies, and some so-\nlutions have been proposed to filter the Pareto set and re-\ntain a small representative set (Wagner et al., 2010). Such\ntypes of strategies may be applicable to our criterion, as\nsome small cells would contribute to a very small part of\nthe volume of excursion sets and could be neglected with-\nout introducing a critical error, and would reduce substan-\ntially the computational cost, especially when the number\nof observations is high.\n4.4Efficient formulas in the two-objective\ncase\nWe consider here the two-objective case, for which the\nEEV criterion can be expressed in a compact and compu-\ntationally efficent way. With two objectives, the Pareto set\ncan be ordered as follows (the first and second objective\nfunctions in ascending and descending order, respectively):\ny(1)\u2217\n1\n\u2264 ... \u2264 y(1)\u2217\nThe non-dominated part of the objective space can be\ndivided in m + 1 cells. Then, given a non-dominated cell\n\u03a9j, only four cases arise for \u03a9i (the cell of the new ob-\nservation), as shown in Figure 4, for which the quantities\npij(x) need to be computed.\nm\nand y(2)\u2217\n1\n\u2265 ... \u2265 y(2)\u2217\nm .\nHence, the criterion can be expressed as a sum of at\nmost (m+1)\u00d74 terms. As many terms can be factorized,\nwe finally obtain:\nEEV (xn+1) =\nm\n?\nj=0\n?\nX\n\u03b1j(x),\n7"},{"page":8,"text":"Figure 4: Left: the m+1 non-dominated cells (in white). Right: the four cases for \u03a9igiven \u03a9j: three are represented\nby the different hatched regions, the fourth corresponds to \u03a9j= \u03a9i.\nwith:\n\u03b10(x)=\n?\n\u03a6(1)\n\u03c1\n?\n?\u03a6(1)\n\u03a6(1)\n\u03bd\n?\n\u03a6\n?\n\u00af y(1)\u2217\n1\n\u03b7(2)?\n\u00af y(1)\u2217\n?\n\u03a6(2)\n\u03bd\n?\n{1,...,m \u2212 1},\n, \u02dc y(1)\u2217\n1\n?\nj+1\n,\u03b7(1)?\n?\n\u2212 \u03a6(1)\n?\n\u2212 \u03a6(1)\n\u2212 \u03a6(1)\n\u2212 \u03a6(2)\n\u02dc y(1)\u2217\nj\n\u03bd\n?\n\u00af y(1)\u2217\n1\n,\u03b7(1)??\n\u00d7\n=\n\u03a6\n?\n\u03c1\n\u2212 1+ \u03a6\u02dc y(1)\u2217\n1\n?\n,\n\u03b1j(x)\n?\n\u00af y(1)\u2217\nj\n?\n\u02dc y(1)\u2217\nj+1\nj+1, \u02dc y(1)\u2217\n?\n\u03bd\n?\nj\n\u00af y(1)\u2217\nj+1,\u03b7(1)?\n\u00af y(1)\u2217\n, \u02dc y(1)\u2217\n?\n\u03a6\u02dc y(2)\u2217\nj\n+\n\u03c1\n?\nj\n??\n\u00d7\n+\n\u00af y(2)\u2217\nj\n?\n,\u03b7(2)?\n\u2212 \u03a6\n\u03c1\n\u00af y(2)\u2217\nj\n?\n,y(2)\u2217\nj\n?\n??\n?\n?\n??\n,\n\u2200j\n\u2208\nand:\n\u03b1m(x)=\n?1 \u2212 \u03a6\n\u03a6(1)\n\u03c1\n?\n1 \u2212 \u03a6\n?\nm , \u02dc y(1)\u2217\n?\n\u00af y(1)\u2217\nm\n\u03b7(1)?\n+ \u03a6(1)\n??\n??\n\u03bd\n?\n\u00af y(1)\u2217\nm ,\u03b7(1)?\n\u2212\n\u00d7\n+\n?\n\u00af y(1)\u2217\nm\n\u03a6(2)\n\u03bd\n?\n\u00af y(2)\u2217\n?\nm ,\u03b7(2)?\n\u2212 \u03a6(2)\n?\n\u03c1\n?\n.\n\u00af y(2)\u2217\nm , \u02dc y(2)\u2217\nm\n??\n\u03a6\u00af y(2)\u2217\nm\n?\nCalculations are not detailed, as they are straightforward\ndevelopments of Eq. (13). The two extremal terms (j = 0\nand j = m+1) correspond to special cases of \u03a9j(first and\nlast cells in Figure 4, right).\n5 Numerical experiments\n5.1 One-dimensional, bi-objective prob-\nlem\nIn this section, we apply the method to the follow-\ning bi-objective problem:F(1)and F(2)are indepen-\ndent realizations of one-dimensional GPs, indexed by\na 300-point regular grid on [0,1], with a stationary\nMatern covariance with regularity parameter \u03bd = 3\/2\n(Rasmussen and Williams, 2006, chapter 4). The variance\nand range parameters are taken as one and 1\/5, respec-\ntively.\nNow, two GP models are built based on four randomly\nchosen observations. The covariance function is considered\nas known. Figure 5 shows the initial models and Pareto\nfront. Here, a single point dominates the three others. Af-\nter building the tesselation as described in Section 4.1, we\ncompute the volume of the excursion sets corresponding to\neach cell (Eq. (11)). As there are only four observations,\nthe probability to belong to a non-dominated cell is rela-\ntively high (Figure 5, bottom right). Then, the criterion\nis computed for each point in the grid (Figure 5, bottom\nright). Its maximum is obtained in a region with high un-\ncertainty and low expected values for the two functions.\nAfter 10 iterations (Figure 6), the Pareto front is well-\napproximated. The models are accurate in the optimal\nregions and have high prediction variances in the other\nregions, which indicates a good allocation of the compu-\ntational resources.\nNext, we compare these results to a state-of-the-art\nmethod, called SMS-EGO (Ponweiser et al., 2008), which\nhas been shown to outperform significantly non-GP based\nmethods (such as NSGA-II), in particular when only\na limited budget of evaluation is available.\nsuring performances is non-trivial in multi-criteria op-\ntimization, we use a series of three indicators: hyper-\nvolume, epsilon and R2 indicators (Zitzler et al., 2003;\nHansen and Jaszkiewicz, 1998), all available in the R\npackage EMOA (Mersmann, 2012). They provide different\nmeasures of distance to the actual Pareto set and coverage\nof the objective space. Results are reported in Figure 7.\nThe Pareto front obtained with SMS-EGO shows that the\nalgorithm only detected one of the two Pareto optimal re-\ngions. As a consequence, the Pareto front is locally more\naccurate than the one obtained with the SUR strategy,\nbut the indicators are much poorer.\nAs mea-\n5.2 Six-dimensional, bi-objective problem\nHere, the objectives functions are realizations of six-\ndimensional GPs indexed by a 2000-point Sobol sequence\non [0,1]6, with a stationary Matern covariance with regu-\nlarity parameter \u03bd = 5\/2. The variance and range param-\neters are taken as one and\u221a6\/6, respectively. The initial\nexperimental set consists of 10 points randomly chosen,\nand 40 points are added iteratively using the SUR and\nSMS-EGO strategies. The results are given in Figure 8.\nAgain, the SUR strategy shows better performances com-\n8"},{"page":9,"text":"0.00.2 0.4\nCriterion\n0.6 0.81.0\n\u22122\n\u22121\n0\n1\n2\nF(1)\n0.0 0.2 0.4 0.60.81.0\n\u22122\n\u22121\n0\n1\n2\nF(2)\n0.00.2 0.40.6 0.81.0\n0.00\n0.04\n0.08\n\u22121.5\u22121.0\u22120.5 0.00.5\n\u22121.5\n\u22120.5\nPareto front\n0.170\n0.0690.062\nFigure 5: Top graphs: initial models (same representation as Figure 1); the actual Pareto-optimal points are repre-\nsented by red crosses. Bottom right: observations (black circles) represented in the objective space, actual Pareto\nfront (red) and current front (blue). Bottom left: criterion value as a function of x. The vertical bars show the new\nobservation location; the green circle is the new observation.\n0.00.20.4 0.60.81.0\n\u22121.5 \u22121.0 \u22120.5\n0.0\n0.5\nF(1)\n0.00.2 0.40.6 0.81.0\n\u22122.0\n\u22121.0\n0.0\n0.5\nF(2)\n\u22121.5 \u22121.0 \u22120.5 0.0 0.5\n\u22121.5\n\u22121.0\n\u22120.5\n0.0\nPareto front\nFigure 6: Models and Pareto front after 10 iterations.\n\u22121.5 \u22120.5\nY(1)\n0.5\n\u22121.5\n\u22120.5\nSMSEGO\nY(2)\n2468 10\n1.5\n2.0\n2.5\n3.0\nHypervolume indicator\nIteration\n2468 10\n0.2\n0.6\n1.0\nEpsilon indicator\nIteration\n2468 10\n0.0\n0.1\n0.2\n0.3\n0.4\nR2 indicator\nIteration\nFigure 7: SMS-EGO Pareto front after 10 iterations (left) and performance comparison between SUR (plain line)\nand SMS-EGO (dotted line) on a one-dimensional problem. Hypervolume indicator: higher is better; other indicators\nshould tend to zero.\npared to SMS-EGO.\n6 Discussion\nWe have proposed a new sequential sampling strategy,\nbased on stepwise uncertainty reduction principles, for\nmulti-objective optimization.Closed-form expressions\n9"},{"page":10,"text":"\u22122 \u221210\nY(1)\n123\n\u22123\n\u22121\n0\n1\n2\n3\nPareto front\nY(2)\n\u22122\u221210\nY(1)\n123\n\u22123\n\u22121\n0\n1\n2\n3\nSUR\nY(2)\n\u22122 \u221210\nY(1)\n123\n\u22123\n\u22121\n0\n1\n2\n3\nSMSEGO\nY(2)\n0 102030 40\n22\n24\n26\n28\n30\nHypervolume indicator\nIteration\n010 2030 40\n0.8\n1.2\n1.6\nEpsilon indicator\nIteration\n010 20 3040\n0.10\n0.15\n0.20\nR2 indicator\nIteration\nFigure 8: Performance comparison between SUR (plain line) and SMS-EGO (dotted line) on a six-dimensional problem.\nTop left: all 2000 points in the objective space; Pareto-optimal points are the red crosses. Top middle and right: Pareto\nfronts after 40 iterations.\nwere provided for the infill criterion. Numerical exper-\niments showed promising performances of our strategy\ncompared to a state-of-the-art method.\nsome strengths and weaknesses of our approach.\nWe point here\nFirst of all, as it is based on Gaussian process modeling,\nit shares the limits inherents to the model. In particu-\nlar, it is well-known that classical GP models cannot cope\nwith large datasets (> 1000) or high-dimensional spaces\n(> 100). Most models also have restrictive conditions on\nthe approximated function (typically, stationarity), and\nthe strategy efficiency may be greatly penalized by impor-\ntant inadequations between the model hypothesis and the\nactual function characteristics. Using the proposed strat-\negy on more complex GP models (Gramacy and Lee, 2008;\nBanerjee et al., 2013) may help mitigate these issues.\nSecondly, we wish to emphasize here that the proposed\nmethod has a non-negligible computational cost, as (a) the\ncriterion is evaluated by numerical integration and (b) it\nis embedded in an optimization loop. Hence, its use may\nbe limited to simulators for which the time to compute\nan evaluation is much higher than the time to choose the\nnext point to evaluate. However, one may note that the\nuse of closed-form expressions, although relying on the\nbivariate normal CDF, avoid the need to use conditional\nsimulations (as in Villemonteix et al. (2009)) that would\nhave made the method overly expensive.\nOn the other hand, moving away from the expected im-\nprovement paradigm allowed us to provide a method that\ndoes not necessitate any artificial ranking or trade-off be-\ntween objective functions. It is also scale-invariant, which\ncan be of great advantage when dealing with objectives of\ndifferent nature. Finally, one advantage of the proposed\nstrategy is that it considers progress in the design space\nrather than in the objective space, which corresponds to\nwhat practitioners are eventually interested in.\nPossible extensions of this work are various. Account-\ning for the uncertainty due to the estimation of the model\nhyperparameters were left appart here; Bayesian ap-\nproaches, in the fashion of Kennedy and O\u2019Hagan (2001)\nor Gramacy and Lee (2008) for instance, may help address\nthis issue. Objective functions were considered as not cor-\nrelated to ease calculations and allow the use of simple\nmodels. As objectives are likely to be negatively corre-\nlated in practice, accounting for it while keeping tractable\ncriteria is an important question. Finally, the stepwise\nuncertainty reduction strategy may be easily adapted to\nother frameworks, such as constrained or noisy optimiza-\ntion.\nAProbabilities update\nA.1Proof of Proposition 3.2\nUsing the model update equations (4), we note first that:\npn+1(x,a) = \u03a6\n\uf8ee\n\uf8f0a \u2212 mn(x) +cn(x,xn+1)\ns2\nn(xn+1)[mn(xn+1) \u2212 yn+1]\nsn+1(x)\n\uf8f9\n\uf8fb\n10"},{"page":11,"text":"Now, let \u03d5(yn+1) be the PDF of Yn+1(conditional on An).\nWe have:\nq(x,b,a)\n?b\n?b\nd\u03d5(yn+1)\nAs Yn+1\u223c N?mn(xn+1),s2\nYn+1= mn(xn+1) + sn(xn+1)U\n=\n\u2212\u221e\npn+1(x,a)d\u03d5(yn+1)\n\uf8ee\n=\n\u2212\u221e\n\u03a6\n\uf8f0a \u2212 mn(x) +cn(x,xn+1)\ns2\nn(xn+1)[mn(xn+1) \u2212 yn+1]\nsn+1(x)\n\uf8f9\n\uf8fb\nn(xn+1)?, we can write (fol-\nlowing Chevalier et al. (2012)):\nwith\nU \u223c N (0,1),\nwhich allows to simplify the previous equations to:\nq(x,b,a)\n? \u00afb\n? \u00afb\n=\n\u2212\u221e\n\u03a6\n?a \u2212 mn(x)\nsn+1(x)\n\u2212\n?\ncn(x,xn+1)\nsn(xn+1)sn+1(x)\n?\nu\n?\nd\u03d5(u)\n=\n\u2212\u221e\n\u03a6[\u02c6 a \u2212 \u03b2u]d\u03d5(u),\n(14)\nwith\n\u03b2=(cn(x,xn+1))\/(sn(xn+1)sn+1(x)),\n(a \u2212 mn(x))\/sn+1(x) and\n(b \u2212 mn(xn+1))\/sn(xn+1).\nThis quantity can be written as a bivariate Gaussian CDF.\nIndeed:\n? \u00afb\n1\n\u221a2\u03c0\n\u2212\u221e\n? \u00afb\n1\n2\u03c0\n\u2212\u221e \u2212\u221e\n2\n? \u00afb\n?1\nis the standard form of the bivariate Gaussian CDF with\nzero mean and covariance matrix \u03a3\u03b2, hence:\n\u02c6 a\n\u00afb\n=\n=\n\u2212\u221e\n\u03a6[\u02c6 a \u2212 \u03b2u]d\u03d5(u)\n? \u00afb\n?\u02c6 a\u2212\u03b2u\n? \u00afb\n1\n2\u03c0|\u03a3\u03b2|\n=\n\u03a6[\u02c6 a \u2212 \u03b2u]exp\n?\u2212u2\n?u2+ t2??\nu2+ [t \u2212 \u03b2u]2??\n\u22121\n2\n2\n?\ndu\n=\n1\n2\u03c0\n\u2212\u221e\u2212\u221e\n?\u02c6 a\nexp\n?\n\u22121\n?\n?\n2\ndtdu\n=\nexp\n?\n\u22121\ndtdu\n=\n\u2212\u221e\n?\u02c6 a\n\u03b2\n1 + \u03b22\n\u2212\u221e\nexp\n?ut?\u03a3\u22121\n\u03b2\n?u\nt\n??\ndtdu,\nwith \u03a3\u03b2 =\n\u03b2\n?\n(noting that |\u03a3\u03b2| = 1), which\nq(x,b,a) = \u03a6\u03a3\u03b2\n?\u00afb,\u02c6 a?.\nFinally, applying the normalization \u02dc a = \u02c6 a\/?1 + \u03b22, we\n\u03b2\n?1 + \u03b22=\nhave: q(x,b,a) = \u03a6\u03c1\n?\u00afb,\u02dc a?, with:\n\u03c1 =\ncn(x,xn+1)\nsn(xn+1)sn(x).\nA.2 Proof of Proposition 3.1\nThe result can be obtained directly from Proposition 3.2\nwith b \u2192 +\u221e.\npn(x,a).\nWe have then: q(x,b,a) \u2192 \u03a6(\u02dc a) =\nA.3Proof of Corollary 3.3\nFrom Eq. (14), we have directly:\nr(x,b,a)=\n?+\u221e\n?\u2212\u00afb\n\u03a6\u03a3\u2212\u03b2\n\u00afb\n\u03a6[\u02c6 a \u2212 \u03b2u]d\u03d5(u)\n=\n\u2212\u221e\n\u03a6[\u02c6 a + \u03b2u]d\u03d5(u)\n?\u2212\u00afb,\u02c6 a?= \u03a6\u2212\u03c1\n=\n?\u2212\u00afb,\u02dc a?.\nA.4Proof of Proposition 3.4\nThe steps of the proof are similar to those of Proposition\n3. Using the update equations (4), we have first:\nP(Y (x) \u2264 yn+1|An,yn+1= y(xn+1))\n?yn+1\u2212 mn+1(x)\n\uf8ee\n?mn(xn+1) \u2212 mn(x)\n= \u03a6\nsn+1(x)\n?\n= \u03a6\n\uf8f0\u2212mn(x) +cn(x,xn+1)mn(xn+1)\ns2\nn(xn+1)\n+\n?\n1 \u2212cn(x,xn+1)\ns2\nn(xn+1)\n?\nyn+1\nsn+1(x)\n?cn(x,xn+1) \u2212 s2\n\uf8f9\n\uf8fb\n= \u03a6\nsn+1(x)\n\u2212\nn(xn+1)\nsn(xn+1)sn+1(x)\n?\nu\n?\n.\nNow:\nh(x,b)\n?b\n? \u00afb\n?cn(x,xn+1) \u2212 s2\n? \u00afb\n= \u03a6\u03a3\u03c4\n=\n\u2212\u221e\nP(Y (x) \u2264 Yn+1|An,Yn+1= yn+1)d\u03d5(yn+1)\n?mn(xn+1) \u2212 mn(x)\nn(xn+1)\nsn(xn+1)sn+1(x)\n=\n\u2212\u221e\n\u03a6\nsn+1(x)\n\u2212\n?\nu\n?\nd\u03d5(u)\n=\n\u2212\u221e\n\u03a6[\u00b5 \u2212 \u03c4u]d\u03d5(u)\n?\u00afb,\u00b5?,\nas we get a form similar to Equation 14, with \u03a6\u03a3\u03c4the\nCDF of the centered bigaussian with covariance \u03a3\u03c4 =\n?1\u03c4\n\u03c41 + \u03c42\n?\n,\n\u00b5\n\u03c4\n=\n=\n(mn(xn+1) \u2212 mn(x))\/sn+1(x)\n(cn(x,xn+1) \u2212 s2\nNormalizing \u03b7 = \u00b5\/\u221a1 + \u03c42delivers the final result.\nn(xn+1))\/(sn(xn+1)sn+1(x)).\nB\nb(k)\nij(x) and d(k)\nij(x) computation\nLet X and Y be two dependent random variables, and\na, b, c and d four real numbers. By direct application of\n11"},{"page":12,"text":"Bayes formula, we have:\nP(a \u2264 X < b|c \u2264 Y < d)P(c \u2264 Y < d)\n= P(Y < d) \u00d7 [P(X < b|Y < d) \u2212 P(X \u2264 a|Y < d)]\n\u2212 P(Y \u2264 c) \u00d7 [P(X < b|Y \u2264 c) \u2212 P(X \u2264 a|Y \u2264 c)]\nP(Y \u2264 X < b|a \u2264 Y < b)P(a \u2264 Y < b)\n= P(Y < b) \u00d7 [P(X < b|Y < b) \u2212 P(X \u2264 Y |Y < b)]\n\u2212 P(Y \u2264 a) \u00d7 [P(X < b|Y \u2264 a) \u2212 P(X \u2264 Y |Y \u2264 a)]\nNow, by definition, b(k)\nij\nis of the form of the fist equa-\ntion:\nb(k)\nij(x):=\nPn+1\ny(k)\n?\nhence write as the sum of four terms:\nb(k)\nij(x)=p(k)\n?Y(k)(x) \u2264 y(k)\n\u2212\n\u2212\n=\nx,y(k)\nj+\nq(k)?\nwith q(k)(x,b,a) given by Eq. (5), thus:\n?\n\u2212\u03a6(k)\n?\ni\u2212\u2264 Y(k)\nj\u2212\u2264 Y(k)(x) < y(k)\nn+1< y(k)\nj+|y(k)\ni\u2212\u2264 Y(k)\nn+1< y(k)\ni+\n?\n\u00d7\nPn\ny(k)\ni+\n?\n,\nn(xn+1,y(k)\ni+)\n?\nPn+1\n?Y(k)(x) \u2264 y(k)\nn+1\u2264 y(k)\n?Y(k)(x) < y(k)\nn+1\u2264 y(k)\n\u2212 q(k)?\nx,y(k)\nj+\n??Y(k)\n??Y(k)\n?\n,\nn+1\u2264 y(k)\ni+\n?\n\u2212\nPn+1\nj\u2212\n??Y(k)\n??Y(k)\n+ q(k)?\n?\ny(k)\nj+\ni+\n??\n??\np(k)\nn(xn+1,y(k)\n?Y(k)(x) \u2264 y(k)\ni+,y(k)\ni\u2212)\n?\nPn+1\nj+\nn+1\u2264 y(k)\ni\u2212\n?\nBayesian forecasting for complex systems using com-\nputer simulators. Journal of the American Statistical\nAssociation 96(454), 717\u2013729 (2001)\nPn+1\nq(k)?\nj\u2212\ni\u2212\n?\nx,y(k)\ni+,y(k)\nj\u2212\n\u2212\nx,y(k)\ni\u2212,y(k)\nj+\n?\ni\u2212,y(k)\nj\u2212\n?\n?\nb(k)\nij(x)=\n\u03a6(k)\n\u03c1\ny(k)\n?\ni+,?\ny(k)\ny(k)\nj+\n\u2212 \u03a6(k)\n?\n\u03c1\n?\ny(k)\n?\ni+,?\ny(k)\ny(k)\nj\u2212\n\u03c1\ni\u2212,?\n+ \u03a6(k)\n\u03c1\ni\u2212,?\ny(k)\nj\u2212\n?\n.\nSimilary, d(k)\nStarting with the definition:\nij\nis of the form of the second equation:\nd(k)\nij(x) :=\nPn+1\n?\ni\u2212\u2264 Y(k)\nY(k)\nn+1\u2264 Y(k)(x) < y(k)\nn+1< y(k)\nj+\n??y(k)\ni\u2212\u2264 Y(k)\nn+1< y(k)\ni+\n?\n103(483) (2008)\n\u00d7\nPn\n?\ny(k)\ni+\n?\n,\nhence writes:\nd(k)\nij(x)=p(k)\nn(xn+1,y(k)\n?Y(k)(x) \u2264 Y(k)\np(k)\n?Y(k)(x) \u2264 Y(k)\nx,y(k)\nh(k)?\ni+)\n?\nPn+1\n?Y(k)(x) \u2264 y(k)\nn+1\u2264 y(k)\n?Y(k)(x) < y(k)\nn+1\u2264 y(k)\n\u2212 h(k)?\nx,y(k)\nj+\n??\nj+\n??\n??Y(k)\n??Y(k)\nn+1\u2264 y(k)\ni+\n?\n\u2212\n\u2212\n\u2212\n=\nPn+1\nn+1\n??Y(k)\n??Y(k)\ni+\nn(xn+1,y(k)\ni\u2212)\n?\nPn+1\nn+1\u2264 y(k)\ni\u2212\n?\nPn+1\nq(k)?\nn+1\ni\u2212\ni+,y(k)\n?\nj+\n+ q(k)?\n?\nx,y(k)\ni+\n?\n\u2212\nx,y(k)\ni\u2212\ni\u2212,y(k)\nj\u2212\n?\n,\nwith q(k)(x,b,a) given by Eq. (5) and h(k)(x,b) given by\nEq. (7), thus:\n?\n+\n\u03a6(k)\n\u03bd\ny(k)\nd(k)\nij(x)=\n\u03a6(k)\n\u03c1\ny(k)\ni+,?\ny(k)\nj+\n?\n\u2212 \u03a6(k)\n\u03bd\n?\n?\ny(k)\ni+,\u03b7(k)?\ny(k)\ny(k)\n?\ni\u2212,\u03b7(k)?\n\u2212 \u03a6(k)\n\u03c1\ni\u2212,?\nj+\n?\n.\nReferences\nBanerjee, A., Dunson, D.B., Tokdar, S.T.: Efficient gaus-\nsian process regression for large datasets. Biometrika\n100(1), 75\u201389 (2013)\nBect, J., Ginsbourger, D., Li, L., Picheny, V., Vazquez, E.:\nSequential design of computer experiments for the esti-\nmation of a probability of failure. Statistics and Com-\nputing 22(3), 773\u2013793 (2012)\nChevalier, C., Bect, J., Ginsbourger, D., Vazquez,\nE., Picheny, V., Richet, Y.:\nbased stepwiseuncertainty reduction\ncation to the identification of an excursion set.\nhttp:\/\/hal.inria.fr\/hal-00641108\/en (2012)\nFast parallel kriging-\nwithappli-\nChevalier, C., Picheny, V., Ginsbourger, D.:\nAn efficient and user-friendly implementation of batch-\nsequential inversion strategies based on kriging. Com-\nputational Statistics & Data Analysis (2013)\nKriginv:\nCollette, Y., Siarry, P.: Multiobjective optimization: prin-\nciples and case studies. Springer (2003)\nCraig, P.S., Goldstein, M., Rougier, J.C., Seheult, A.H.:\nCressie, N.: Statistics for Spatial Data, revised edition,\nvol. 928. Wiley, New York (1993)\nEmery, X.: The kriging update equations and their appli-\ncation to the selection of neighboring data. Computa-\ntional Geosciences 13(3), 269\u2013280 (2009)\nGramacy, L., Lee, H.: Optimization under unknown con-\nstraints. Bayesian Statistics 9, 229 (2011)\nGramacy, R.B., Lee, H.K.: Bayesian treed gaussian pro-\ncess models with an application to computer model-\ning.Journal of the American Statistical Association\nHansen, M.P., Jaszkiewicz, A.: Evaluating the quality of\napproximations to the non-dominated set. IMM, De-\npartment of Mathematical Modelling, Technical Univer-\nsity of Denmark (1998)\nJones, D.R.: A taxonomy of global optimization methods\nbased on response surfaces. Journal of global optimiza-\ntion 21(4), 345\u2013383 (2001)\nJones, D.R., Schonlau, M., Welch, W.J.: Efficient global\noptimization of expensive black-box functions. Journal\nof Global optimization 13(4), 455\u2013492 (1998)\nKeane, A.J.:\nin multiobjective design optimization.\n44(4), 879\u2013891 (2006)\nStatistical improvement criteria for use\nAIAA journal\nKenkel,\nvariate\nhttp:\/\/CRAN.R-project.org\/package=pbivnorm.\nR package version 0.5-1\nB.:\nNormal\npbivnorm:\nCDF\nVectorizedBi-\n(2012).URL\n12"},{"page":13,"text":"Kennedy, M.C., O\u2019Hagan, A.: Bayesian calibration of\ncomputer models. Journal of the Royal Statistical Soci-\nety: Series B (Statistical Methodology) 63(3), 425\u2013464\n(2001)\nKnowles, J.: Parego: A hybrid algorithm with on-line\nlandscape approximation for expensive multiobjective\noptimization problems.\nIEEE Transactions on 10(1), 50\u201366 (2006)\nEvolutionary Computation,\nMersmann,\ntive\nhttp:\/\/CRAN.R-project.org\/package=emoa.\npackage version 0.5-0\nO.: emoa:Evolutionary\nAlgorithms\nMultiobjec-\nOptimization(2012).URL\nR\nPonweiser, W., Wagner, T., Biermann, D., Vincze, M.:\nMultiobjective optimization on a limited budget of eval-\nuations using model-assisted s-metric selection.\nParallel Problem Solving from Nature, pp. 784\u2013794.\nSpringer (2008)\nIn:\nRasmussen, C., Williams, C.: Gaussian processes for ma-\nchine learning. MIT Press (2006)\nRoustant, O., Ginsbourger, D., Deville, Y.: Dicekriging,\ndiceoptim: Two r packages for the analysis of computer\nexperiments by kriging-based metamodeling and opti-\nmization. Journal of Statistical Software 51(1), 1\u201355\n(2012)\nScott, W., Frazier, P., Powell, W.: The correlated knowl-\nedge gradient for simulation optimization of continuous\nparameters using gaussian process regression.\nJournal on Optimization 21(3), 996\u20131026 (2011)\nSIAM\nStein, M.: Interpolation of spatial data: some theory for\nkriging. Springer Verlag (1999)\nVillemonteix, J., Vazquez, E., Walter, E.: An informa-\ntional approach to the global optimization of expensive-\nto-evaluate functions. Journal of Global Optimization\n44(4), 509\u2013534 (2009)\nWagner, T., Emmerich, M., Deutz, A., Ponweiser, W.: On\nexpected-improvement criteria for model-based multi-\nobjective optimization. In: Parallel Problem Solving\nfrom Nature, PPSN XI, pp. 718\u2013727. Springer (2010)\nWang, G.G., Shan, S.: Review of metamodeling tech-\nniques in support of engineering design optimization.\nJournal of Mechanical Design 129, 370 (2007)\nZitzler, E., Thiele, L., Laumanns, M., Fonseca, C.M.,\nDa Fonseca, V.G.: Performance assessment of multiob-\njective optimizers: An analysis and review. Evolution-\nary Computation, IEEE Transactions on 7(2), 117\u2013132\n(2003)\n13"}],"widgetId":"rgw26_56aba263ae6b7"},"id":"rgw26_56aba263ae6b7","partials":[],"templateName":"publicliterature\/stubs\/PublicationText.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationText.html?publicationUid=257299288&hide=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationDetailAd":{"data":{"googleDfpSlot":null,"widgetId":"rgw27_56aba263ae6b7"},"id":"rgw27_56aba263ae6b7","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAd.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAd.html?publicationUid=257299288&slotId=336x280_Publications_ATF_Right&collapseSlotMode=never&fallbackContainerEnabled=1","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationRelations":null,"publicationRelationsReverse":null,"publicationUid":257299288,"showSignUpDialog":false,"selectNewSignUpDialog":false,"publicationQuestions":null,"publicationCitations":null,"publicationReviewPromo":null,"publicationUsedInReviews":null,"publicationPdfJsReader":null,"useFulltextOptimizedLayout":false,"publicationActions":null,"requestFulltextPromo":null,"currentUrl":"publication\/257299288_Multiobjective_optimization_using_Gaussian_process_emulators_via_stepwise_uncertainty_reduction","isLeaderboardAd":false,"enableStickyBox":null,"googleDfpSlotMobileBottom":null,"fullTextExitPopup":null,"showExitPopupDialog":false,"widgetId":"rgw2_56aba263ae6b7"},"id":"rgw2_56aba263ae6b7","partials":{"romeo_legal_notice":"publicliterature\/stubs\/partials\/romeo_legal_notice.html"},"templateName":"publicliterature\/stubs\/PublicPublicationDetails_NewLayout.html","templateExtensions":["generalHelpers"],"attrs":{"publicationUid":257299288},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicPublicationDetailsOld.html?publicationUid=257299288&isTestOldDesign=0","viewClass":"views.publicliterature.PublicPublicationDetailsOldView","yuiModules":["rg.views.publicliterature.PublicPublicationDetailsOldView"],"stylesheets":[],"_isYUI":true},"widgetId":"rgw1_56aba263ae6b7"},"id":"rgw1_56aba263ae6b7","partials":[],"templateName":"publicliterature\/stubs\/PublicPublicationDetails.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicPublicationDetails.html","viewClass":"views.publicliterature.PublicPublicationDetailsView","yuiModules":["rg.views.publicliterature.PublicPublicationDetailsView"],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"uaClass":"","headPrefix":[],"rootUrl":"https:\/\/www.researchgate.net\/","requestToken":"HsyHixcmd\/IkWe1f7uBqNMG0qPyarIwAHyEX4eVuHJELLH8BqzzsfrPaoqkZjeHOo7vb2wZz+QJ+EwDT4q4qLIcSAZyc3nUua5ysGzVFWVLCatXL2IQrY5LFiq3\/gnbFoyozLcqPDwFdEkyn9WeJn+VxtyhlgHgqLtjV+sCxm2j4\/Dw05sQBmoY87uRgwmSKc\/p4t9N7l8xEihrXZmPC51Sih\/FH+lsoP3PmMfianCvGE\/jnJA5IgWRk8\/owjO1wJ1\/L4e2WYWxuH2uiXi8guI6sTzDyi11upmx61k5476c=","faviconCdnUrl":"https:\/\/c5.rgstatic.net\/m\/2390829798215018\/images\/favicon.ico","headerOutput":"<noscript><\/noscript><link rel=\"canonical\" href=\"https:\/\/www.researchgate.net\/publication\/257299288_Multiobjective_optimization_using_Gaussian_process_emulators_via_stepwise_uncertainty_reduction\" \/>\n<link rel=\"dns-prefetch\" href=\"\/\/c5.rgstatic.net\" \/>\n<link rel=\"dns-prefetch\" href=\"\/\/i1.rgstatic.net\" \/>\n<meta property=\"twitter:card\" content=\"summary\" \/>\n<meta property=\"twitter:site\" content=\"@ResearchGate\" \/>\n<meta property=\"og:title\" content=\"Multiobjective optimization using Gaussian process emulators via stepwise uncertainty reduction\" \/>\n<meta property=\"og:description\" content=\"Optimization of expensive computer models with the help of Gaussian process\nemulators in now commonplace. However, when several (competing) objectives are\nconsidered, choosing an appropriate...\" \/>\n<meta property=\"og:site_name\" content=\"ResearchGate\" \/>\n<meta property=\"og:image\" content=\"https:\/\/i1.rgstatic.net\/publication\/257299288_Multiobjective_optimization_using_Gaussian_process_emulators_via_stepwise_uncertainty_reduction\/links\/02f48f2c0cf21189773bf244\/smallpreview.png\" \/>\n<meta property=\"og:url\" content=\"https:\/\/www.researchgate.net\/publication\/257299288_Multiobjective_optimization_using_Gaussian_process_emulators_via_stepwise_uncertainty_reduction\" \/>\n<meta property=\"rg:id\" content=\"PB:257299288\" \/>\n<meta name=\"DC.identifier\" scheme=\"DCTERMS.URI\" content=\"http:\/\/dx.doi.org\/10.1007\/s11222-014-9477-x\" \/>\n<meta name=\"gs_meta_revision\" content=\"1.1\" \/>\n<meta name=\"citation_title\" content=\"Multiobjective optimization using Gaussian process emulators via stepwise uncertainty reduction\" \/>\n<meta name=\"citation_author\" content=\"Victor Picheny\" \/>\n<meta name=\"citation_publication_date\" content=\"2013\/10\/02\" \/>\n<meta name=\"citation_journal_title\" content=\"Statistics and Computing\" \/>\n<meta name=\"citation_issn\" content=\"0960-3174\" \/>\n<meta name=\"citation_volume\" content=\"25\" \/>\n<meta name=\"citation_issue\" content=\"6\" \/>\n<meta name=\"citation_doi\" content=\"10.1007\/s11222-014-9477-x\" \/>\n<meta name=\"citation_abstract_html_url\" content=\"https:\/\/www.researchgate.net\/publication\/257299288_Multiobjective_optimization_using_Gaussian_process_emulators_via_stepwise_uncertainty_reduction\" \/>\n<meta name=\"citation_fulltext_html_url\" content=\"https:\/\/www.researchgate.net\/publication\/257299288_Multiobjective_optimization_using_Gaussian_process_emulators_via_stepwise_uncertainty_reduction\" \/>\n<meta name=\"viewport\" content=\"width=device-width,initial-scale=1\" \/>\n<link href=\"\/\/c5.rgstatic.net\/m\/22664197317151888\/styles\/rg.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/21004998181197492\/styles\/rg2.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<!--[if lt IE 9]><link href=\"\/\/c5.rgstatic.net\/m\/238176252723686\/styles\/ie.css\" type=\"text\/css\" rel=\"stylesheet\"\/><![endif]-->\n<link href=\"\/\/c5.rgstatic.net\/m\/217752362214895\/styles\/modules\/publicprofile.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<script src=\"\/\/c5.rgstatic.net\/m\/2321000301012716\/javascript\/vendor\/webfontloader\/webfontloader.js\" type=\"text\/javascript\"><\/script>\n <script>(function(i,s,o,g,r,a,m){i[\"GoogleAnalyticsObject\"]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,\"script\",\"\/\/www.google-analytics.com\/analytics.js\",\"ga\");\n ga(\"create\",\"UA-58591210-1\");ga(\"set\",\"anonymizeIp\",true);ga('set', 'dimension1', 'publication slurped');ga('set', 'dimension2', 'Article');ga('set', 'dimension3', 'Logged out');ga('set', 'dimension4', 'https');ga(\"send\",\"pageview\");<\/script>\n","webfont":"<noscript><\/noscript><script> WebFontConfig = { custom: { families: ['source_sans_pro_italic', 'source_sans_pro_bold', 'source_sans_pro', 'martel'], urls : ['\/\/c5.rgstatic.net\/m\/231392577336386\/styles\/fonts.css'] } }; WebFont.load(WebFontConfig); <\/script>\n","correlationId":"rgreq-005a772b-b15a-4347-9ffd-418fa1169797","accountId":null,"module":"publicliterature","action":"publicliterature.PublicPublicationDetails","page":"publicationDetail","product":"publications","backendTime":341,"continent":"Asia","stylesHome":"\/\/c5.rgstatic.net\/m\/","staticHost":"c5.rgstatic.net","useEarlyFlush":false,"longRunningRequestIdentifier":"LongRunningRequest.publicliterature.PublicPublicationDetails","longRunningRequestFp":"e9e5bbe1366c7ee8c8e41d02f793c884ac9be19b","widgetId":"rgw28_56aba263ae6b7"},"id":"rgw28_56aba263ae6b7","partials":[],"templateName":"application\/stubs\/StaticHeader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.StaticHeader.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){
            Y.rg.core.pagespeed.Monitoring.monitorPage("\/\/glassmoni.researchgate.net", "publicliterature.PublicPublicationDetails.run.html.loggedOut.get", "59de9668d07aeb77ab4de5f24d382b5d199d2437", "rgreq-005a772b-b15a-4347-9ffd-418fa1169797", "dc09ed03b1e41abf4c6f7245f342d25beab6fbc8");
        
            Y.rg.core.pagespeed.Monitoring.monitorPage("\/\/glassmoni.researchgate.net", "publicationDetail.loggedOut", "ed1993d9e20f6cefa83edacaa24401a18c071aea", "rgreq-005a772b-b15a-4347-9ffd-418fa1169797", "dc09ed03b1e41abf4c6f7245f342d25beab6fbc8");
        })();
(function(){Y.rg.createInitialWidget({"data":{"year":"2016","inlinePromo":null,"isAdmin":false,"contactUrl":"https:\/\/www.researchgate.net\/contact","aboutUsUrl":"https:\/\/www.researchgate.net\/about","widgetId":"rgw29_56aba263ae6b7"},"id":"rgw29_56aba263ae6b7","partials":[],"templateName":"application\/stubs\/DefaultFooter.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.DefaultFooter.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"headerLogin":{"data":{"urlAfterLogin":"publication\/257299288_Multiobjective_optimization_using_Gaussian_process_emulators_via_stepwise_uncertainty_reduction","requestToken":"V+edG0N+TrvyNpR7Q28hVA8xc6P8se5Ts1OmJ1OGBTuMby9U87GyAZAeog+SWDru9QRKL65DBJ6XRhqnjYGNnGM90Ft9v6incLBCyBK664yHBNYg4cBMs3Nrhd9a3vmcNO3o4ilNBBt8EsxrDMW+p3BlPioezudSVbmLUrwTMWlIJ2i0X8XOUZxjKQ9HU5XM6IP7yQEFVeVCNkdDsi+QoZdvxUA\/GXw+tGyBSOzTG0r4nhyewjViu3\/8b0SYF\/glCjZS26nK84fv7BY6\/upkWxGzYqvRPgdxIspSriY85t0=","loginUrl":"https:\/\/www.researchgate.net\/application.Login.html","signupUrl":"https:\/\/www.researchgate.net\/signup.SignUp.html?ev=su_chnl_index&hdrsu=1&_sg=-KKZpJNoMO5qfgAWyatvopEa2E1Eve9wm3hJ-7aHNZ-6ugGyFbGdINmsPXedR4_0","encodedUrlAfterLogin":"cHVibGljYXRpb24vMjU3Mjk5Mjg4X011bHRpb2JqZWN0aXZlX29wdGltaXphdGlvbl91c2luZ19HYXVzc2lhbl9wcm9jZXNzX2VtdWxhdG9yc192aWFfc3RlcHdpc2VfdW5jZXJ0YWludHlfcmVkdWN0aW9u","signupCallToAction":"Join for free","widgetId":"rgw31_56aba263ae6b7"},"id":"rgw31_56aba263ae6b7","partials":{"partial":"application\/stubs\/partials\/headerLoginDefault.html"},"templateName":"application\/stubs\/HeaderLogin.html","templateExtensions":[],"attrs":{"goal":"milestoneHeaderLoginSeen"},"widgetUrl":"https:\/\/www.researchgate.net\/application.HeaderLogin.html","viewClass":"views.application.HeaderLoginView","yuiModules":["rg.views.application.HeaderLoginView"],"stylesheets":[],"_isYUI":true},"cookieConsent":null,"logoSvgSrc":"https:\/\/c5.rgstatic.net\/m\/235107188705592\/images\/template\/brand-header-logo.svg","logoFallbackSrc":"https:\/\/c5.rgstatic.net\/m\/238113351022438\/images\/template\/brand-header-logo.png","widgetId":"rgw30_56aba263ae6b7"},"id":"rgw30_56aba263ae6b7","partials":{"schemaSocialProfiles":"application\/stubs\/partials\/schemaSocialProfiles.html"},"templateName":"application\/stubs\/HeaderLoggedOut.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.HeaderLoggedOut.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"logEvent":"su_banner","specialCopy":false,"widgetId":"rgw32_56aba263ae6b7"},"id":"rgw32_56aba263ae6b7","partials":[],"templateName":"application\/stubs\/LoggedOutBanner.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.LoggedOutBanner.html","viewClass":"views.application.LoggedOutBannerView","yuiModules":["rg.views.application.LoggedOutBannerView"],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.core.util.ParameterFilter.filter(["ev","cp","ch","ref","dbw","pli","loginT","uid","claimChannel","enrichId","enrichSource","utm_source","utm_medium","utm_campaign","el","ci"]);})();
});}); } else { throw 'YRG was not loaded when attaching widgets'; }</script><script> dataLayer = [{"pageCategory":"publication slurped","publicationType":"Article","eventCategory":"Publication page"}]; </script> <noscript><iframe src="//www.googletagmanager.com/ns.html?id=GTM-MKVKH7" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-MKVKH7');</script><script>(function(e){function n(n,t,o,a){"use strict";var i=e.document.createElement("link"),r=t||e.document.getElementsByTagName("script")[0],d=e.document.styleSheets;return i.rel="stylesheet",i.href=n,i.media="only x",a&&(i.onload=a),r.parentNode.insertBefore(i,r),i.onloadcssdefined=function(e){for(var t,o=0;d.length>o;o++)d[o].href&&d[o].href.indexOf(n)>-1&&(t=!0);t?e():setTimeout(function(){i.onloadcssdefined(e)})},i.onloadcssdefined(function(){i.media=o||"all"}),i}function t(e,n){e.onload=function(){e.onload=null,n&&n.call(e)},"isApplicationInstalled"in navigator&&"onloadcssdefined"in e&&e.onloadcssdefined(n)}var o=function(a,i){"use strict";if(a&&3===a.length){var r=e.Image,d=!(!document.createElementNS||!document.createElementNS("http://www.w3.org/2000/svg","svg").createSVGRect||!document.implementation.hasFeature("http://www.w3.org/TR/SVG11/feature#Image","1.1")||e.opera&&-1===navigator.userAgent.indexOf("Chrome")||-1!==navigator.userAgent.indexOf("Series40")),c=new r;c.onerror=function(){o.method="png",o.href=a[2],n(a[2])},c.onload=function(){var e=1===c.width&&1===c.height,r=a[e&&d?0:e?1:2];o.method=e&&d?"svg":e?"datapng":"png",o.href=r,t(n(r),i)},c.src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///ywAAAAAAQABAAACAUwAOw==",document.documentElement.className+=" grunticon"}};o.loadCSS=n,o.onloadCSS=t,e.grunticon=o})(this);grunticon(["https://c5.rgstatic.net/c/o1q2er/styles/icons/_header-ico.svg.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_header-ico.png.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_header-ico.fallback.scss"]);grunticon(["https://c5.rgstatic.net/c/o1q2er/styles/icons/_admin-ico.svg.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_admin-ico.png.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_admin-ico.fallback.scss"]);grunticon(["https://c5.rgstatic.net/c/o1q2er/styles/icons/_ico.svg.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_ico.png.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_ico.fallback.scss"]);</script></body>
</html>
