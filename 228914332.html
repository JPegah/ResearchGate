<!DOCTYPE html> <html lang="en" class="" id="rgw37_56ab1c1ddcb57"> <head > <meta charset="utf-8"/> <meta http-equiv="content-type" content="text/html; charset=UTF-8"/> <meta name="Rg-Request-Token" id="Rg-Request-Token" content="ihnvWS1JrZ8bHKyviXsBhA5ZTtgc6doIm4QpcfU/zjH6A2OTiN+/rd1e1uUmPfMG/gTkfGPLcDmBWOLE1W2CAm9UVsn0h3DaBpC1h4kIr6FExg7InazqWbFmuQ6pQ+fz+1aYQ0rrGaEsXNQQoEMtZe+8pFH7BAqz2LVVNtp5zBMYZDd4Wr+KBjBs+N3inRo9XlKhvMDilC6H6t2z1Z/oo078xWo0EEZDFiM54DWdG/J2a6mSMcJ7Qa2Sj1nHnQ4yD8q8seDILREnhSek3mbAAa44vRG0pKZtcMr4HWFX9cA="/> <meta http-equiv="expires" content="0"/> <link rel="apple-touch-icon" sizes="57x57" href="https://www.researchgate.net/apple-touch-icon-57x57.png"> <link rel="apple-touch-icon" sizes="60x60" href="https://www.researchgate.net/apple-touch-icon-60x60.png"> <link rel="apple-touch-icon" sizes="72x72" href="https://www.researchgate.net/apple-touch-icon-72x72.png"> <link rel="apple-touch-icon" sizes="76x76" href="https://www.researchgate.net/apple-touch-icon-76x76.png"> <link rel="apple-touch-icon" sizes="114x114" href="https://www.researchgate.net/apple-touch-icon-114x114.png"> <link rel="apple-touch-icon" sizes="120x120" href="https://www.researchgate.net/apple-touch-icon-120x120.png"> <link rel="apple-touch-icon" sizes="144x144" href="https://www.researchgate.net/apple-touch-icon-144x144.png"> <link rel="apple-touch-icon" sizes="152x152" href="https://www.researchgate.net/apple-touch-icon-152x152.png"> <link rel="apple-touch-icon" sizes="180x180" href="https://www.researchgate.net/apple-touch-icon-180x180.png"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-32x32.png" sizes="32x32"> <link rel="icon" type="image/png" href="https://www.researchgate.net/android-chrome-192x192.png" sizes="192x192"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-96x96.png" sizes="96x96"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-16x16.png" sizes="16x16"> <link rel="shortcut icon" type="image/x-icon" href="https://c5.rgstatic.net/m/2390829798215018/images/favicon.ico"/> <link rel="manifest" href="https://www.researchgate.net/manifest.json"> <meta name="msapplication-TileColor" content="#da532c"> <meta name="msapplication-TileImage" content="https://www.researchgate.net/mstile-144x144.png"> <meta name="theme-color" content="#444444"> <link rel="search" type="application/opensearchdescription+xml" title="ResearchGate search" href="https://www.researchgate.net/application.DownloadOpenSearchPlugin.html"/> <link rel="meta" type="application/rdf+xml" title="ICRA labels" href="https://www.researchgate.net/application.DownloadLabels.html"/> <link rel="http://oexchange.org/spec/0.8/rel/related-target" type="application/xrd+xml" href="https://www.researchgate.net/application.DownloadOExchange.html"/> <base href="https://www.researchgate.net/"/> <script>
    var rgConfig = {
        correlationId: "rgreq-951fede4-6d59-4cd2-bdb0-067fa2066236",
        accountId: "",
        module: "publicliterature",
        action: "publicliterature.PublicPublicationDetails",
        page: "publicationDetail",
        product: "publications",
        continent: "Asia",
        stylesHome: "//c5.rgstatic.net/m/",
        staticHost: "c5.rgstatic.net",
        longRunningRequestIdentifier: "LongRunningRequest.publicliterature.PublicPublicationDetails",
        longRunningRequestFp: "e9e5bbe1366c7ee8c8e41d02f793c884ac9be19b"
    };
    window.rootUrl = "https://www.researchgate.net/";
</script> <link rel="canonical" href="https://www.researchgate.net/publication/228914332_Bounded_Approximations_for_Marginal_Likelihoods" />
<link rel="dns-prefetch" href="//c5.rgstatic.net" />
<link rel="dns-prefetch" href="//i1.rgstatic.net" />
<meta property="twitter:card" content="summary" />
<meta property="twitter:site" content="@ResearchGate" />
<meta property="og:title" content="Bounded Approximations for Marginal Likelihoods" />
<meta property="og:description" content="We discuss novel approaches to evaluation of both upper and lower bounds on log marginal likelihoods for model comparison in Bayesian analysis. From posterior Monte Carlo samples, we show how..." />
<meta property="og:site_name" content="ResearchGate" />
<meta property="og:image" content="https://i1.rgstatic.net/publication/228914332_Bounded_Approximations_for_Marginal_Likelihoods/links/000495e90cf2ed98fb440b17/smallpreview.png" />
<meta property="og:url" content="https://www.researchgate.net/publication/228914332_Bounded_Approximations_for_Marginal_Likelihoods" />
<meta property="rg:id" content="PB:228914332" />
<meta name="DC.identifier" scheme="DCTERMS.URI" content="http://dx.doi.org/" />
<meta name="gs_meta_revision" content="1.1" />
<meta name="citation_title" content="Bounded Approximations for Marginal Likelihoods" />
<meta name="citation_author" content="Chunlin Ji" />
<meta name="citation_author" content="Haige Shen" />
<meta name="citation_author" content="Mike West" />
<meta name="citation_publication_date" content="2010/01/01" />
<meta name="citation_abstract_html_url" content="https://www.researchgate.net/publication/228914332_Bounded_Approximations_for_Marginal_Likelihoods" />
<meta name="citation_fulltext_html_url" content="https://www.researchgate.net/publication/228914332_Bounded_Approximations_for_Marginal_Likelihoods" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<link href="//c5.rgstatic.net/m/22664197317151888/styles/rg.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/21004998181197492/styles/rg2.css" type="text/css" rel="stylesheet"/>
<!--[if lt IE 9]><link href="//c5.rgstatic.net/m/238176252723686/styles/ie.css" type="text/css" rel="stylesheet"/><![endif]-->
<link href="//c5.rgstatic.net/m/217752362214895/styles/modules/publicprofile.css" type="text/css" rel="stylesheet"/>
<script src="//c5.rgstatic.net/m/2321000301012716/javascript/vendor/webfontloader/webfontloader.js" type="text/javascript"></script>
 <script>(function(i,s,o,g,r,a,m){i["GoogleAnalyticsObject"]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,"script","//www.google-analytics.com/analytics.js","ga");
 ga("create","UA-58591210-1");ga("set","anonymizeIp",true);ga('set', 'dimension1', 'publication slurped');ga('set', 'dimension2', 'Article');ga('set', 'dimension3', 'Logged out');ga('set', 'dimension4', 'https');ga("send","pageview");</script>
  <script> WebFontConfig = { custom: { families: ['source_sans_pro_italic', 'source_sans_pro_bold', 'source_sans_pro', 'martel'], urls : ['//c5.rgstatic.net/m/231392577336386/styles/fonts.css'] } }; WebFont.load(WebFontConfig); </script><noscript></noscript>

<title>Bounded Approximations for Marginal Likelihoods</title>
<meta name="description" content="Bounded Approximations for Marginal Likelihoods on ResearchGate, the professional network for scientists."/>
<meta name="keywords" content="scientific network, scientific platform, scientific community, research partner, research collaboration, journal articles, international collaboration, find researcher, lifescience researcher, interdisciplinary research, research collaboration"/>
</head>
<body class="use-svg-icons logged-out">
<div id="page-container">
<script type="text/javascript">var googletag = googletag || {}; googletag.cmd = googletag.cmd || [];
(function() { var gads = document.createElement("script"); gads.async = true; gads.type = "text/javascript"; var useSSL = "https:" == document.location.protocol; gads.src = (useSSL ? "https:" : "http:") + "//www.googletagservices.com/tag/js/gpt.js"; var node =document.getElementsByTagName("script")[0]; node.parentNode.insertBefore(gads, node); })();</script><div id="main" class="logged-out-header-support">
<div id="content" class="">

<noscript>
<div class="c-box-warning full-width-element" style="text-align: center; ">
    <div style="margin: auto; padding:10px;" class="container">
        <b>For full functionality of ResearchGate it is necessary to enable JavaScript.
            Here are the <a href="http://www.enable-javascript.com/" rel="nofollow" target="_blank">
                instructions how to enable JavaScript in your web browser</a>.</b>
    </div>
</div>
</noscript>

<div id="rgw1_56ab1c1ddcb57" itemscope itemtype="http://schema.org/ScholarlyArticle"><div class="publication-wrapper publication-wrapper-onecol" id="rgw2_56ab1c1ddcb57" itemscope itemtype="http://schema.org/ScholarlyArticle"> <div class="c-col-content"> <div class="c-content"> <div class="clearfix">  <div class="publication-header"> <div id="rgw5_56ab1c1ddcb57">  <div class="type-label"> Article   </div> <span class="Z3988" title="ctx_ver=Z39.88-2004&rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&rfr_id=info%3Asid%2Fresearchgate.net%3Aresearchgate&rft.atitle=Bounded%20Approximations%20for%20Marginal%20Likelihoods&rft.date=2010&rft.au=Chunlin%20Ji%2CHaige%20Shen%2CMike%20West&rft.genre=article"></span> <h1 class="pub-title" itemprop="name">Bounded Approximations for Marginal Likelihoods</h1> <meta itemprop="headline" content="Bounded Approximations for Marginal Likelihoods">  <meta itemprop="image" content="https://i1.rgstatic.net/publication/228914332_Bounded_Approximations_for_Marginal_Likelihoods/links/000495e90cf2ed98fb440b17/smallpreview.png">  <div id="rgw7_56ab1c1ddcb57" class="publication-detail-author-list"> <div> <ul class="clearfix js-people-list">  <li id="rgw8_56ab1c1ddcb57" itemprop="author" itemscope itemtype="http://schema.org/Person"> <a itemprop="sameAs" href="profile/Chunlin_Ji" class="pub-detail-item account-item"> <div class="indent-left"> <div class="people-img"> <img  src="https://c5.rgstatic.net/m/2671872220764/images/template/default/profile/profile_default_m.jpg" title="Chunlin Ji" alt="Chunlin Ji" height="20px" width="20px" style="height: 20px;"/> </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Chunlin Ji</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item  remove-action-indent   " id="rgw9_56ab1c1ddcb57" data-account-key="Chunlin_Ji">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="profile/Chunlin_Ji"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="Chunlin Ji" alt="Chunlin Ji" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">     </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="profile/Chunlin_Ji" class="display-name">Chunlin Ji</a>    </h5> <div class="truncate-single-line meta">    <span class="meta">Kuang-Chi Institute of Advanced Technology</span>    </div>  <a href="javascript:" class="btn btn-promote btn-large people-item-contact-author js-contact-author">Message author</a>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>  <li id="rgw10_56ab1c1ddcb57"> <a href="researcher/82093842_Haige_Shen" class="pub-detail-item author-item" itemprop="author" itemscope itemtype="http://schema.org/Person"> <div class="indent-left"> <div class="people-img">  <img src="https://c5.rgstatic.net/m/2951093203564/images/template/default/profile/profile_default_s.jpg" title="Haige Shen" alt="Haige Shen" height="20px" width="20px" style="height: 20px;"/>  </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Haige Shen</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item   not-claimed " id="rgw11_56ab1c1ddcb57">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="researcher/82093842_Haige_Shen"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="Haige Shen" alt="Haige Shen" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">       </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="researcher/82093842_Haige_Shen" class="display-name">Haige Shen</a>    </h5> <div class="truncate-single-line meta">   </div>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>  <li id="rgw12_56ab1c1ddcb57"> <a href="researcher/38910148_Mike_West" class="pub-detail-item author-item" itemprop="author" itemscope itemtype="http://schema.org/Person"> <div class="indent-left"> <div class="people-img">  <img src="https://c5.rgstatic.net/m/2951093203564/images/template/default/profile/profile_default_s.jpg" title="Mike West" alt="Mike West" height="20px" width="20px" style="height: 20px;"/>  </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Mike West</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item   not-claimed " id="rgw13_56ab1c1ddcb57">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="researcher/38910148_Mike_West"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="Mike West" alt="Mike West" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">       </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="researcher/38910148_Mike_West" class="display-name">Mike West</a>    </h5> <div class="truncate-single-line meta">   </div>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>   </ul> <div class="js-loading"></div>  </div> </div> <div class="pub-details js-pub-details">  <div> Department of Statistical Science, Duke University, 27708-0251, Durham, NC, USA </div>        <meta itemprop="datePublished" content="2010-01">  01/2010;               </div> <div id="rgw14_56ab1c1ddcb57" class="pub-abstract">  <div class="clearfix">   <div style="max-height: 54px;" class="js-expander-container js-expander-collapsed">  <p itemprop="description"> <strong>ABSTRACT</strong> <div>We discuss novel approaches to evaluation of both upper and lower bounds on log marginal likelihoods for model comparison in Bayesian analysis. From posterior Monte Carlo samples, we show how existing variational approxima-tion methods defining lower bounds on marginal likelihoods can be extended to also define upper bounds, and develop optimization methods to minimize such upper bounds. Further, using this new approach to upper bound evalu-ation, we suggest and exemplify a new quasi-optimized lower bound that can often be obtained with trivial computations compared to current methods. We further discuss the use of partial analytic marginalization of some model parameters as a way of significantly reducing the differences between upper and lower bounds to improve marginal likelihood approximation. To imple-ment this, however, traditional variational methods are intractable, and we provide solution in terms of a novel Monte Carlo Stochastic Approximation (MCSA). We provide theoretical results on convergence of the resulting ap-proximations to true bounds, and several simulation examples in regression and mixture models to demonstrate the accuracy and efficacy of the new methods.</div> </p>  </div>  </div>   </div>      <div class="action-container">   <div class="clear"></div> <div class="share-dialog-container" style="display: none;">  </div> </div> </div> <div style="margin-left: -20px; margin-right: -20px;">  </div> </div>  <div class="publication-detail-dfp-container rf"> <div id="rgw27_56ab1c1ddcb57">  </div> </div>  </div>  <div class="clearfix">  <noscript> <div id="rgw26_56ab1c1ddcb57"  itemprop="articleBody">  <p>Page 1</p> <p>Bounded Approximations for Marginal Likelihoods<br />Chunlin Jia, Haige Shenb, Mike Westc<br />aDepartment of Statistics, Harvard University, Science Center, 1 Oxford Street,<br />Cambridge, MA 02138-2901, USA<br />bNovartis Oncology, Biometrics, 180 Park Avenue,<br />Florham Park, NJ 07932, USA<br />cDepartment of Statistical Science, Duke University, Durham, NC 27708-0251, USA<br />Abstract<br />We discuss novel approaches to evaluation of both upper and lower bounds<br />on log marginal likelihoods for model comparison in Bayesian analysis. From<br />posterior Monte Carlo samples, we show how existing variational approxima-<br />tion methods defining lower bounds on marginal likelihoods can be extended<br />to also define upper bounds, and develop optimization methods to minimize<br />such upper bounds. Further, using this new approach to upper bound evalu-<br />ation, we suggest and exemplify a new quasi-optimized lower bound that can<br />often be obtained with trivial computations compared to current methods.<br />We further discuss the use of partial analytic marginalization of some model<br />parameters as a way of significantly reducing the differences between upper<br />and lower bounds to improve marginal likelihood approximation. To imple-<br />ment this, however, traditional variational methods are intractable, and we<br />provide solution in terms of a novel Monte Carlo Stochastic Approximation<br />(MCSA). We provide theoretical results on convergence of the resulting ap-<br />proximations to true bounds, and several simulation examples in regression<br />and mixture models to demonstrate the accuracy and efficacy of the new<br />methods.<br />Keywords:<br />Kullback-Leibler Divergence, Variational Methods<br />Bayesian Model Comparison, Marginal Likelihood,<br />∗Corresponding author: Chunlin Ji, tel/fax: 1(617)495-5496/496-8057<br />Email addresses: chunlin.ji@gmail.com (Chunlin Ji), haigeshen@yahoo.com<br />(Haige Shen), mw@stat.duke.edu (Mike West)<br />Manuscript submitted for publicationFebruary 9, 2010</p>  <p>Page 2</p> <p>1. Introduction<br />The marginal likelihood is the essential quantity in Bayesian model se-<br />lection, representing the evidence of a model. However, evaluating marginal<br />likelihoods often involves intractable integration and relies on numerical inte-<br />gration and approximation. Mean-field variational methods, initially devel-<br />oped in statistical physics and extensively studied by machine learning and<br />Bayesian learning communities for deterministic approximation of marginal<br />distributions (MacKay, 1995; Jordan et al., 1999; Jaakkola and Jordan, 2000;<br />Humphreys and Titterington, 2000; Ueda and Ghahramani, 2002; Jordan,<br />2004; Wang and Titterington, 2004), have been implemented in the model<br />selection context (Corduneanu and Bishop, 2001; Beal, 2003).<br />For a specified model with parameters θ = {θ1,...,θK} ∈ Θ and prior<br />density p(θ), the marginal likelihood based on observed data D is the quan-<br />tity<br />?<br />Θ<br />In many practical contexts, the required integration must be approximated<br />numerically. In certain cases, some of the parameters can be analytically in-<br />tegrated out, reducing the dimension of the integral while leaving a numerical<br />problem of the same form.<br />For any density function q(θ|γ) parameterized by γ = {γ1,...,γJ} ∈ Γ<br />and with the same support as the posterior p(θ|D), Jensen’s inequality gives<br />p(D) =p(D,θ)dθ =<br />?<br />Θ<br />p(D|θ)p(θ)dθ<br />(1)<br />logp(D) ≥ L(γ) =<br />?<br />Θ<br />q(θ|γ)logp(D,θ)<br />q(θ|γ)dθ. (2)<br />Maximizing L(γ) with respect to γ provides an optimized lower bound on log<br />marginal likelihood. This optimization is equivalent to minimization of the<br />Kullback-Leibler (KL) divergence of the true posterior p(θ|D) from q(θ|γ).<br />Current mean-field methods typically use a variational density form fac-<br />torized over hidden variables and model parameters (or construct such set-<br />tings by treating certain model parameters as hidden variables), and rely<br />on EM style iterative algorithms to provide solutions to the lower bound<br />optimization (Beal, 2003). Similar to application in variational MLE with<br />missing data (Celeux and Diebolt, 1992; Delyon et al., 1999), stochastic ap-<br />proximation (SA) algorithms based on an iterative Monte Carlo procedures<br />can be used in cases where the expectation step in the EM algorithm can-<br />2</p>  <p>Page 3</p> <p>not be performed in closed form. Wang and Titterington (2004) have shown<br />that, for the mean-field variational densities of exponential family form, this<br />optimization converges to the true local maximized lower bound.<br />The first question addressed here is that of adding an upper bound to<br />properly bracket the exact log marginal likelihood. Again using a class of<br />variational densities, we define a theoretical upper bound and develop a com-<br />putational approach to its minimization. This optimization is equivalent to<br />minimization of the KL divergence of the variational density q(θ|γ) from the<br />true posterior p(θ|D), complementing the lower bound approximation that<br />minimizes the (directional) KL divergence in the other direction. Further,<br />for variational densities of exponential family form, we show convergence to<br />the true global minimum upper bound.<br />We also discuss a quasi-optimized lower bound that can be obtained with<br />trivial computation – compared to current approaches – based on the result<br />of the optimized upper bound. In addition, we demonstrate that, if we can<br />marginalize with respect to a subset of parameters analytically, then we can<br />often significantly reduce the range between the upper and lower bounds and<br />hence improve the estimation. Further, we present a method that directly<br />uses a method of Monte Carlo stochastic approximation (MCSA) to maximize<br />the lower bound, and prove the convergence to the true local maximum lower<br />bound when q(θ|γ) takes an exponential family form.<br />Accuracy and performance of these new methods is demonstrated with<br />two examples. The first example is a Bayesian linear regression model, in<br />which the analytical form of marginal likelihood is available for assessment<br />of numerical approximations. The second example concerns finite mixture<br />models. We also refer to additional examples in applications.<br />2. Upper Bound on Marginal Likelihood<br />When q(θ|γ) = p(θ|D), the inequality in (2) turns into equality<br />logp(D) =<br />?<br />Θ<br />p(θ|D)logp(D,θ)dθ −<br />?<br />Θ<br />p(θ|D)logp(θ|D)dθ.<br />The second term here is the entropy of p(θ|D) which, using Gibbs’ inequality,<br />satisfies<br />−<br />?<br />Θ<br />p(θ|D)logp(θ|D)dθ ≤ −<br />?<br />Θ<br />p(θ|D)logq(θ|γ)dθ<br />3</p>  <p>Page 4</p> <p>for any q(θ|γ). We deduce the upper bound on log marginal likelihood<br />U(γ) =<br />?<br />Θ<br />p(θ|D)logp(θ,D)<br />q(θ|γ)dθ ≥ logp(D). (3)<br />Minimizing U(γ) with respect to γ provides the optimum. It is clear that<br />the optimal parameter, γU, also minimizes the KL divergence of q(θ|γ) from<br />p(θ|D), namely<br />?<br />Θ<br />D(p||q) =p(θ|D)logp(θ|D)<br />q(θ|γ)dθ. (4)<br />The minimized KL value is then just the discrepancy between the implied<br />estimate U(γU) and the true logp(D).<br />Assuming q(θ|γ) comes from the exponential family, D(p||q) as a lin-<br />ear functional of logq(θ|γ) is convex with respect to γ. Hence, the global<br />minimum can be found by solving the j = 1,...,J equations<br />∂<br />∂γjD(p||q) = −<br />?<br />Θ<br />p(θ|D)<br />?<br />∂<br />∂γj<br />logq(θ|γ)<br />?<br />dθ = 0. (5)<br />For q(θ|γ) of exponential family form, these equations can be solved analyt-<br />ically in terms of posterior moments. Typically, the posterior is represented<br />by a simulation sample such as from MCMC, and moments are approximated<br />via Monte Carlo. Given a Monte Carlo posterior sample {θ(i): i = 1,...,N},<br />it is trivial to prove that the resulting Monte Carlo estimated solution ˆ γU<br />converges (almost surely) with N to γU. The resulting global minimum upper<br />bound of log marginal likelihood Uois then estimated by<br />ˆUo=1<br />N<br />N<br />?<br />i=1<br />logp(θ(i),D)<br />q(θ(i)|ˆ γU)<br />(6)<br />which converges almost surely to Uo.<br />3. Optimal Lower Bound Approximation<br />We comment on the standard variational lower bound approximation and<br />then introduce two new methods: quasi-optimized lower bounds, for fast and<br />efficient computations relative to the standard method, and Monte Carlo<br />stochastic approximation, for problems with non-factored variational densi-<br />ties.<br />4</p>  <p>Page 5</p> <p>3.1. Standard Variational Methods<br />The standard lower bound is based on equation (2); maximization of<br />L(γ) over γ provides the optimized lower bound on the log marginal like-<br />lihood, equivalent to minimizing the KL divergence D(p||q) (Jordan et al.,<br />1999; Ghahramani and Beal, 2001; Xing et al., 2003; Blei and Jordan, 2004).<br />Computational tractability is achieved with factorized variational densities<br />q(θ|γ) =?J<br />densities have exponential family forms, i.e. q(θj|γj) = h(θj)exp{γ′<br />a(γj)}. Most practical examples assume this.<br />Substantial further simplification is achieved if each complete conditional<br />posterior p(θj|D,θ−j) is also of exponential family form.<br />arises in many contexts, and conditional exponential family forms of complete<br />conditional posteriors can sometimes be induced by use of latent variables<br />that augment initial parameters. Under such an assumption, that for each<br />j = 1,...,J,<br />j=1q(θj|γj), where γ = {γ1,...,γJ}, and when the component<br />jθj−<br />This structure<br />p(θj|D,θ−j) = h(θj)exp{g(θ−j,D)′θj− b(g(θ−j,D))},<br />where g(θ−j,D) is the posterior complete conditional natural parameter for<br />θj, then the conditional optimization steps run through iterative updates of<br />variational parameter subsets using<br />γj=<br />?<br />θ−j<br />g(θ−j,D)q(θ−j|γ−j)dθ−j,j = 1,...,J, (7)<br />i.e., matching the natural parameter of the variational density with the ex-<br />pected value of that of the complete conditional posterior. In such cases,<br />computation using coordinate ascent algorithms can be achieved, in which<br />we iteratively maximize the bound with respect to each γjholding all other<br />variational parameters γ−j fixed at “current” values; see Ghahramani and<br />Beal (2001), Blei and Jordan (2004).<br />3.2. Quasi-Optimized Lower Bound<br />As mentioned, the lower bound optimization via the standard variational<br />method can be computationally challenging, so raising interest in modifi-<br />cations and alternatives. A first path is suggested by the relative ease of<br />computation of the new optimized upper bound of Section 2. This suggests<br />the use of γU, or realistically the MC estimate ˆ γU, in lower bound evaluation<br />5</p>  <p>Page 6</p> <p>too. While γL and γU generally differ – since they are minimizers of the<br />generally different D(p||q) and D(q||p), respectively, they tend to be close in<br />problems with unimodal and increasingly concentrated posteriors, in many<br />model contexts.<br />Thus we define the quasi-optimized lower bound as follows. Draw a Monte<br />Carlo sample {θ(i): i = 1,...,N} from q(θ|ˆ γU) and use it to define and<br />evaluate the MC estimated quasi-optimized lower bound<br />ˆLo=1<br />N<br />N<br />?<br />i=1<br />logp(θ(i),D)<br />q(θ(i)|ˆ γU). (8)<br />This is a consistent estimate of L(γU), a lower bound that is not theoretically<br />optimized but offers a computationally attractive, and often effective, proxy<br />for the optimal L(γL). Examples below explore this.<br />3.3. Lower Bound Optimization by MCSA<br />If the variational distribution qγ(θ) is not a fully factorized distribution,<br />and/or the posterior complete conditionals intractable, then the analytical<br />iterative update equation for variational parameters derived in the varia-<br />tional algorithm is inapplicable. This is common. We will show later, for<br />example, that analytic marginalization of some model parameters – when<br />feasible – can significantly reduce the discrepancy between the bounds on log<br />marginal likelihood; doing so, however, moves us out of the context in which<br />the lower bound optimization is tractable. For these cases, we need an alter-<br />ative computational strategy, and here introduce a Monte Carlo stochastic<br />approximation (MCSA) to numerically maximize the lower bound directly.<br />We also show that the algorithm converges to the true local maximum lower<br />bound when q(θ|γ) takes an exponential family form.<br />First note that<br />˙L(γ) ≡dL(γ)<br />dγ<br />= −<br />?<br />Θ<br />h(θ|γ)q(θ|γ)dθ = 0<br />(9)<br />where<br />h(θ|γ) =<br />?<br />1 + logq(θ|γ)<br />p(θ,D)<br />?<br />d<br />dγlogq(θ|γ).<br />Our novel MCSA approach aims to solve equations (9) numerically. This<br />involves a modification of the standard stochastic approximation (SA) algo-<br />6</p>  <p>Page 7</p> <p>rithm (Robbins and Monro, 1951; Kushner and Yin, 1997) to define recursive<br />approximation of the solution of˙L(γ) = 0 based on noisy, approximate eval-<br />uation of the defining integral in equation (9).<br />For a current value of γ, assume we generate a Monte Carlo sample {θ(i):<br />i = 1,...,N} from q(θ|γ), defining the consistent (in N) MC approximation<br />to equation (9) as<br />λ(γ) ≡ −1<br />N<br />N<br />?<br />i=1<br />h(θ(i)|γ). (10)<br />A Robbins-Monroe SA algorithm then iteratively updates a sequence of val-<br />ues γ(t)over t = 1,2,... via the recursion<br />γ(t+1)= γ(t)+ s(t+1)λ(γ(t))<br />for some initial γ(0)and sequence of scalar step sizes s(t). The latter sequence<br />must satisfy standard conditions,?∞<br />der these conditions, it can be shown that the SA sequence γ(t)converges<br />to the lower bound optimizing value γL as N,t → ∞; the proof relies on<br />standard theory of convergence of SA algorithms from (Kushner and Yin,<br />1997); full mathematical details can be found in chapter 5 of the PhD thesis<br />of the first author here (Ji, 2009).<br />Terminating the MCSA after a series of steps yielding a terminal value<br />ˆ γL, a further MC sample {θ(i): i = 1,...,N} from q(θ|ˆ γL) defines the final<br />estimate of the optimal lower bound<br />t=1s(t)= ∞ and?∞<br />t=1<br />?s(t)?2&lt; ∞. Un-<br />ˆLo=1<br />N<br />N<br />?<br />i=1<br />logp(θ(i),D)<br />q(θ(i)|ˆ γL).(11)<br />4. Evaluation Examples<br />Two model classes provide evaluation and examples. The first involves<br />linear regression model comparison, a context where the exact values of<br />marginal likelihood are available so that bound approximations can be as-<br />sessed against true values. The second is Gaussian mixture models where an-<br />alytic marginal likelihoods are unavailable, and where comparisons are made<br />with various methods to approximate bounds as well as the “gold standard”<br />using Candidate’s formula (Chib, 1995).<br />7</p>  <p>Page 8</p> <p>4.1. Linear Regression<br />Assume a linear model with n × p design matrix X and n × 1 response<br />vector y, viz.<br />y ∼ N?Xβ,σ2In<br />β ∼ N?0p,τσ2Ip<br />σ2<br />∼ IG(h0,k0)<br />?<br />?<br />where hyperparameters τ, h0, and k0are assumed to be fixed and known.<br />Here D = {y}. Due to the conjugate setting, the exact marginal likelihood<br />has a closed form<br />p(D) = (2π)−n/2|C|−1/2kh0<br />0{Γ(h0+ n/2)/Γ(h0)}(k0+ y′C−1y/2)−(h0+n/2)<br />where C = In+ τXX′.<br />To assess marginal likelihood bound approximations we consider and com-<br />pare the two choices:<br />• the full parameter context, setting θ = {β,σ2};<br />• the reduced parameter context, in this case marginalizing β away an-<br />alytically and performing numerical approximations for bounds using<br />only θ = {σ2}.<br />In the reduced parameter context we make use of<br />p(D|σ2) = (2π)−n/2|σ2C|−1/2exp(−y′B−1y/(2σ2)).<br />In each case, the prior conjugacy means we can trivially sample posteriors to<br />provide MC samples for bound approximations.<br />We focus on simulated polynomial regression models and the problem of<br />comparing polynomial order; marginal likelihoods for each model order are<br />key ingredients. The design matrix has rows of the x′<br />for some r &gt; 0, with the n design points x1,...,xndrawn across a grid of<br />values. Synthetic response data y come from a model with r = 3, n = 20,<br />β = [0.2,2,−2,0.5]Tand σ2= 10. The hyperparameters are set as τ = 0.1,<br />h0= 1, and k0= 1.<br />Seven log marginal likelihood values are reported for each model analysis,<br />as follows.<br />i= (1,xi,x2<br />i,...,xr<br />i)<br />8</p>  <p>Page 9</p> <p>ML:<br />ML is the exact log marginal likelihood p(D).<br />U1:<br />U1 is the estimate of the upper bound of log marginal likelihood in<br />the reduced parameter context. Here the variational distribution is<br />q(θ|γ) = IG(σ2|h,k) with γ = (h,k). Posterior samples of σ2yield<br />optimal variational parameters (hU,kU) via equation (5) and resulting<br />U1from equation (6).<br />U2:<br />U2is the estimate of the upper bound in the full parameter context.<br />Here q(θ|γ) = N(β|µ,Ω)IG(σ2|h,k) and optimal variational param-<br />eters γ = {µU,ΩU,hU,kU} are estimated using equations (5), where-<br />upon U2is approximated via equation (6).<br />L1:<br />L1is the estimate of the lower bound in the reduced parameter context<br />as for U1, and using the MCSA method of Section 3.3 with estimate of<br />equation (11).<br />L2:<br />L2is the estimate of the quasi-optimized lower bound in the reduced<br />parameter context as for L1, but now with inverse gamma variational<br />parameters set to the quasi-optimized values (h,k) ← (hU,kU) of U1.<br />L3:<br />L3is the quasi-optimized lower bound estimate in the full parameter<br />context. The normal and inverse gamma variational parameters are<br />set to the quasi-optimized values γ = {µU,ΩU,hU,kU} from the upper<br />bound analysis defining U2, and used to estimate the quasi-optimized<br />lower bound of equation (8).<br />L4:<br />L4 is the lower bound using the standard variational method. The<br />variational parameters γ = {µU,ΩU,h,k} are estimated using the co-<br />ordinate ascent algorithm noted in Section 3.1. At these parameters,<br />samples of θ = {β,σ2} are drawn from q(θ|γ) and used to approximate<br />the lower bound via equation (11).<br />We show one example of a synthetic data set generated from a polyno-<br />mial regression with r = 3, together with fitted models of several orders, in<br />Figure 1. Simulations were repeated 100 times and each of the 7 marginal<br />likelihood bound approximations evaluated for each. Table 1 shows results.<br />We see that U1is more accurate than than U2, and L1, L2better than L3, L4,<br />empirically confirming the view that, by marginalizing out some parameters,<br />we can significantly reduce the discrepancy between the marginal likelihood<br />9</p>  <p>Page 10</p> <p>−4−20<br />x<br />24<br />−60<br />−40<br />−20<br />0<br />20<br />r=1<br />y<br />−4 −20<br />x<br />24<br />−60<br />−40<br />−20<br />0<br />20<br />r=2<br />y<br />−4 −20<br />x<br />24<br />−60<br />−40<br />−20<br />0<br />20<br />r=3<br />y<br />−4 −20<br />x<br />24<br />−60<br />−40<br />−20<br />0<br />20<br />r=4<br />y<br />−4 −20<br />x<br />24<br />−60<br />−40<br />−20<br />0<br />20<br />r=5<br />y<br />−4−20<br />x<br />24<br />−60<br />−40<br />−20<br />0<br />20<br />r=6<br />y<br />Figure 1: Synthetic data approximated by polynomials of varying orders.<br />10</p>  <p>Page 11</p> <p>123456<br />−86<br />−84<br />−82<br />−80<br />−78<br />−76<br />−74<br />−72<br />−70<br />Polynomial order<br />Log marginal likelihood<br /> <br /> <br />Upper bound: U1<br />Exact marginal loglikelihood: ML<br />Lower bound: L1 <br />Quasi−optimized lower bound: L2<br />Figure 2: Plot of the analytic value of the log marginal likelihood of the Bayesian<br />linear model with varying number of order q, and means of upper bound U1, lower<br />bound L1and quasi-optimized lower bound L2of the log marginal likelihood for<br />100 Monte Carlo runs.<br />11</p>  <p>Page 12</p> <p>and its upper/lower bounds. Moreover, averages of U1,L1and L2over the<br />100 simulations are plotted in Figure 2, illustrating the irrelevance of the<br />approximation errors in estimating bounds in this example.<br />4.2. Mixture Model<br />A second study concerns evaluation of marginal likelihoods in multivariate<br />normal, k−component mixture models, especially for comparison of models<br />with respect to the number k of mixture components. Denoting inherent,<br />latent mixture component indicators by z, the model for a random sample<br />of p−variate observations xi,i = 1,...,n, is<br />(xi|zi= j) ∼ N(µj,Σj),zi∼ Mn(1,π),<br />where π = (π1,...,πk)′is the vector of mixing probabilities and Mn(1,π)<br />denotes the multinomial with sample size 1 on cells 1,...,k. We use tra-<br />ditional, conditionally conjugate priors: normal, inverse-Wishart priors for<br />the p−vector means and p × p covariances matrices, (µj|Σj) ∼ N(0,τ−1Σj)<br />and Σj∼ IW(d,S) independently over j = 1,...,k, and with specified hy-<br />perparameters τ,d,S; a uniform Dirichlet prior for component probabilities<br />π ∼ Dir(1/k) where 1 is the k−vector of ones. Under this specification,<br />posterior simulation using Gibbs sampling is easy and widely used in routine<br />applications (e.g. Lavine and West, 1992; Chan et al., 2008). This applies to<br />generate posterior samples for the full set of uncertain parameters and latent<br />variables<br />{zi; i = 1,...,n},{µj,Σj; j = 1,...,k} and<br />π<br />(13)<br />given data D ≡ {xi,i = 1,...,n.}. To apply the methods for marginal<br />likelihood bounds, we can consider several possibilities for partial analytic<br />posterior marginalization in order to improve approximations. We consider<br />the cases below, where in each case we include the latent zias part of the θ<br />parameter.<br />• the standard or reduced−π context, when θ represents the quantities<br />in (13) above with the exception of π that can always be analytically<br />integrated away conditional on the indicators zi;<br />• the reduced−(π,µ) context, when π and the µj, (j = 1,...,k) are<br />12</p>  <p>Page 13</p> <p>Table 1: Exact value and approximate bounds on the log marginal likelihood in the linear regression model<br />example. The Monte Carlo estimates of bounds are given in terms of Monte Carlo mean and standard<br />deviations over simulations.<br />U2<br />U1<br />ML<br />L1<br />L2<br />L3<br />L4<br />1<br />−84.9591<br />±0.0045<br />−73.8644<br />±0.0067<br />−70.3021<br />±0.0079<br />−72.6467<br />±0.0093<br />−77.9364<br />±0.00105<br />−80.5663<br />±0.00127<br />−85.0046<br />±0.0012<br />−73.9329<br />±0.0015)<br />−70.3933<br />±0.0021<br />−72.7603<br />±0.0027<br />−78.0741<br />±0.0029<br />−80.7266<br />±0.0039<br />−85.0068<br />−85.0074<br />±0.0006<br />−73.9395<br />±0.0010<br />−70.4054<br />±0.0012<br />−72.7792<br />±0.0016<br />−78.1013<br />±0.0016<br />−80.7622<br />±0.0020<br />−85.0089<br />±0.0008<br />−73.9414<br />±0.0011<br />−70.4077<br />±0.0013<br />−72.7825<br />±0.0020<br />−78.1045<br />±0.0018<br />−80.7656<br />±0.0020<br />−85.0521<br />±0.0049<br />−74.0038<br />±0.0052<br />−70.4871<br />±0.0060<br />−72.8781<br />±0.0065<br />−78.2152<br />±0.0078<br />−80.8920<br />±0.0085<br />−85.0475<br />±0.0028<br />−73.9974<br />±0.0032<br />−70.4791<br />±0.0039<br />−72.8676<br />±0.0040<br />−78.2040<br />±0.0042<br />−80.8781<br />±0.0048<br />2−73.9374<br />3−70.4009<br />4−72.7720<br />5−78.0906<br />6−80.7477<br />13</p>  <p>Page 14</p> <p>integrated out analytically, so that<br />θ = {(zi, i = 1,...,n),(Σj, j = 1,...,k)};<br />• the reduced−(π,µ,Σ) context, when π and the (µj,Σj), (j = 1,...,k)<br />are integrated out analytically, so that<br />θ = {(zi, i = 1,...,n)}.<br />Given the prior conjugacy, in each case, the required densities p(D|θ),p(θ)<br />and p(θ|D) are analytically available.<br />We consider evaluation of seven log marginal likelihood estimates, as fol-<br />lows.<br />U1,L1:<br />U1is the upper bound estimate in the reduced−(π,µ,Σ) context,<br />when θ represents just the configuration indicators zi. The variational<br />distribution is q(θ|γ) =?n<br />γ = {wi,i = 1,...,n} where wi= (wi1,...,wik)′is a separate multi-<br />nomial probability vector for each i. The posterior simulation samples<br />immediately provide the optimizing w using equation (5), and the up-<br />per bound then follows from equation (6).<br />i=1Mn(zi|1,wi) with variational parameters<br />L1 is the quasi-optimized lower bound estimate in this case. Using<br />the above optimized variational parameters, the quasi-optimized lower<br />bound is estimated by equation (8).<br />U2,L2:<br />U2is the upper bound estimate in the reduced−(π,µ) context where<br />θ comprises the Σjand zi. We use variational distribution<br />q(θ|γ) = {<br />k?<br />j=1<br />IW(Σj|κj,Ψj)}<br />n<br />?<br />i=1<br />Mn(zi|1,wi)<br />with variational parameter γ comprised of the set of κj,Ψj and wi<br />quantities. From the posterior MCMC summaries, the optimizing γ is<br />evaluated using equation (5) and the upper bound follows from equa-<br />tion (6).<br />L2 is the quasi-optimized lower bound estimate in this case. Using<br />the above optimized variational parameters, the quasi-optimized lower<br />bound is estimated by equation (8).<br />14</p>  <p>Page 15</p> <p>U3,L3:<br />U3is upper bound estimate in the reduced−π context, using vari-<br />ational distribution<br />q(θ|γ) = {<br />k?<br />j=1<br />N(µj|νj,Ωj)IW(Σj|κj,Ψj)}<br />n<br />?<br />i=1<br />Mn(zi|1,wi) (14)<br />with variational parameter γ comprising all νj,Ωj,κj,Ψjand wiquan-<br />tities. From the posterior MCMC summaries, the optimizing γ is evalu-<br />ated using equation (5) and the upper bound follows from equation (6).<br />L3 is the quasi-optimized lower bound estimate in this case. Using<br />the above optimized variational parameters, the quasi-optimized lower<br />bound is estimated by equation (8).<br />L4: L4is the estimate of lower bound of log marginal likelihood using the<br />traditional variational method (Corduneanu and Bishop, 2001; Wang<br />and Titterington, 2004). With variational distribution of equation (14),<br />optimal parameters γ are estimated using the coordinate ascent algo-<br />rithm. Samples are then generated from q(θ|γ) at the optimized values<br />and used to estimate the lower bound via equation (11).<br />These bounds are evaluated on synthetic data analogous to an example<br />in Corduneanu and Bishop (2001): n = 600 data points generated from a<br />mixture of five bivariate normals with means [0,0]′, [3,−3]′, [3,3]′, [−3,3]′,<br />[−3,−3]′and covariance matrices [1,0;0,1], [1,0.5;0.5,1], [1,−0.5;−0.5,1],<br />[1,0.5;0.5,1], [1,−0.5;−0.5,1]; see Figure 3. We ran 20 repeat simulations<br />and report the mean and standard deviations across replicates for each of<br />the bounds in Table 2. Evidently, U1,L1 are more accurate than U2,L2,<br />which themselves dominate U3,L3. This again shows that marginalizing out<br />some parameters can significantly reduce the spread between the upper/lower<br />bounds, and that the resulting bounds can define accurate estimates of the<br />exact but non-computable value – each pair of upper and lower bounds is<br />guaranteed to bracket the true value so that, when the spread is small on<br />the log likelihood scale, they can define practically acceptable values even<br />though they may not be quite the “optimal” bounds. The traditional varia-<br />tional method for lower bounds, which can only be applied to the standard<br />parameter context, fails to achieve performance as good as either L1or L2;<br />as shown in Figure 4 this standard method clearly fails to give anything close<br />to a practically useful lower bound in many cases.<br />15</p>  <p>Page 16</p> <p>Table 2: Monte Carlo estimates of bounds in the mixture model example. Table displays the mean and standard<br />deviation over 20 repeat simulations.<br />U3<br />U2<br />U1<br />−2895.4<br />±22.6±21.6±25.5±27.5<br />−2836.7<br />±80.6±38.8±21.1±14.3<br />−2781.6<br />±21.8±21.9±21.1±21.4<br />−2683.0<br />±0.15±0.23±0.09±0.06<br />−2777.1<br />±1.73±1.93±1.57±1.20<br />−2857.4<br />±2.44±2.39±2.31±1.77<br />−2925.7<br />±2.88±3.42±3.31±2.12<br />−2982.6<br />±8.01±8.92±7.23±4.23<br />−3038.9<br />±3.10±4.14±3.98±2.19<br />L1<br />L2<br />L3<br />L4<br />k=2<br />−2895.7−2901.9−2908.9−2909.4<br />±27.7<br />−2877.0<br />±15.4<br />−2786.3<br />±22.5<br />−2688.6<br />±0.08<br />−2788.2<br />±1.12<br />−2873.4<br />±1.60<br />−2946.5<br />±1.95<br />−3010.9<br />±3.98<br />−3067.6<br />±1.89<br />−2911.2<br />±27.5<br />−2884.8<br />±26.9<br />−2786.9<br />±22.6<br />−2689.2<br />±0.07<br />−2821.6<br />±4.05<br />−2946.0<br />±9.48<br />−3059.7<br />±8.18<br />−3153.5<br />±17.8<br />−3246.1<br />±10.5<br />−2910.2<br />±27.3<br />−2884.2<br />±24.8<br />−2787.2<br />±22.6<br />−2689.2<br />±0.08<br />−2822.2<br />±4.58<br />−2945.7<br />±8.68<br />−3058.5<br />±8.41<br />−3151.9<br />±17.1<br />−3243.8<br />±10.4<br />k=3<br />−2848.3−2859.8−2863.4<br />k=4<br />−2782.3−2784.1−2785.1<br />k=5<br />−2683.8−2686.0−2687.2<br />k=6<br />−2779.5−2782.5−2785.4<br />k=7<br />−2860.5−2863.7−2869.4<br />k=8<br />−2931.3−2934.4−2941.2<br />k=9<br />−2990.9−2993.7−3002.7<br />k=10<br />−3049.0−3052.3−3060.5<br />16</p>  <p>Page 17</p> <p>−6 −4−20<br />x1<br />246<br />−6<br />−4<br />−2<br />0<br />2<br />4<br />6<br />8<br />x2<br />Figure 3: One sample of 600 data points sampled from the mixture of 5 bivariate<br />Gaussians.<br />5. Discussion<br />The new approach to defining both upper and lower bounds for log<br />marginal likelihoods extends the prior, standard approach using variational<br />methods in several ways, and the examples show the major benefit and prac-<br />tical utility. First, the utility of our approach to evaluation of optimized<br />upper bounds to couple with lower bounds is obvious. Having bounds that<br />“bracket” the true value, even though the bounds may not be absolutely<br />optimized, provides opportunity to clearly assess practical adequacy of the<br />bounds based on the spread between upper and lower values. If the spread<br />is tight on the log likelihood scale, we can be comfortable with the bound<br />values as defining practically useful estimates. On the other hand, a large<br />spread will indicate that the chosen class of variational densities does not<br />provide a satisfactory approximation to the posterior. Second, the novel<br />quasi-optimized lower bound, that uses the same variational parameters as<br />our optimized upper bound, can in many cases define practically satisfactory<br />lower bounds at minimal computational costs relative to the formally opti-<br />mized value. Third, it is evident that our methods apply to models in which<br />17</p>  <p>Page 18</p> <p>234<br />Number of mixture components<br />56789 10<br />−3300<br />−3200<br />−3100<br />−3000<br />−2900<br />−2800<br />−2700<br />−2600<br />Log marginal likelihood<br /> <br /> <br />Upper bound: U1<br />Quasi−optimized lower bound: L1<br />Variational method lower bound: L4<br />Figure 4: Plot of log marginal likelihood bounds U1,L1, in the mixture model<br />example; the model was fitted at each different value of k indicated, and the bound<br />computations repeated across 20 replicate samples; the average bound values across<br />these samples are plotted. For comparison, the lower bound L4estimated by the<br />variational method is also shown.<br />18</p>  <p>Page 19</p> <p>we can marginalize with respect to a subset of the model parameters and<br />latent variables, and this can be expected to reduce the bound spread and<br />hence improve accuracy, often very substantially.<br />In all cases the tightness of the spread between upper and lower bounds<br />is essentially determined by how good an approximation q(θ|γ) is to p(θ|D).<br />We have an effective and efficient method for computing and optimizing the<br />upper bound; though we can compute and optimize lower bounds similarly<br />using our new MCSA approach, the computations are intensive compared to<br />the upper bound analysis, and hence the quasi-optimized lower bound idea<br />becomes attractive. More research is needed to theoretically understand this<br />use of upper and lower bounds based on the variational parameter computed<br />on the upper bound. We have performed simulation studies in several model<br />classes that show that the quasi-optimized lower bound variational parame-<br />ters are often very close to the optimal values, so expect this to be productive.<br />Finally, we note additional examples in more complex settings are developed<br />in Shen and West (2010) and Merl et al. (2010), based on original studies in<br />Shen (2007). Those studies use our methods in problems where θ includes<br />thousands of binary variables, so the inherent dimension is very high. Shen<br />and West (2010) also explore comparisons with other methods in restricted<br />examples where other methods can be applied, and bear out the results of<br />our examples here in demonstrating the utility of our strategy and specific<br />algorithms for evaluation of upper and lower bounds on marginal likelihoods.<br />Acknowledgements<br />This work was performed while the first two authors were PhD students<br />in the Department of Statistical Science at Duke University. We acknowledge<br />support of the NSF (grant DMS-0342172) and NIH (grant U54-CA-112952).<br />Any opinions, findings and conclusions or recommendations expressed in this<br />work are those of the authors and do not necessarily reflect the views of the<br />NSF or NIH.<br />19</p>  <p>Page 20</p> <p>References<br />Beal, M., 2003. Variational algorithms for approximate Bayesian inference.<br />Ph.D. thesis. Gatsby Computational Neuroscience Unit, University College<br />London.<br />Blei, D., Jordan, M., 2004. Variational inference for Dirichlet process mix-<br />tures. Bayesian Analysis 1, 121–144.<br />Celeux, G., Diebolt, J., 1992. A stochastic approximation type EM algorithm<br />for the mixture problem. Stochastics and Stochastics Reports 41, 127–146.<br />Chan, C., Feng, F., West, M., Kepler, T., 2008. Statistical mixture modelling<br />for cell subtype identification in flow cytometry. Cytometry, A 73, 693–701.<br />Chib, S., 1995. Marginal likelihood from the Gibbs output. Journal of the<br />American Statistical Association 90, 1313–1321.<br />Corduneanu, A., Bishop, C., 2001. Variational Bayesian model selection for<br />mixture distributions, in: Richardson, T., Jaakkola, T. (Eds.), Proceedings<br />Eighth International Conference on Artificial Intelligence and Statistics,<br />Morgan Kaufmann. pp. 27–34.<br />Delyon, B., Lavielle, M., Moulines, E., 1999. Convergence of a stochastic<br />approximation version of the EM algorithm. The Annals of Statistics 27,<br />94–128.<br />Ghahramani, Z., Beal, M., 2001. Propagation algorithms for variational<br />Bayesian learning, in: Leen, T., Dietterich, T., Tresp, V. (Eds.), Advances<br />in Neural Information Processing Systems. MIT Press. volume 13, pp.<br />507–513.<br />Humphreys, K., Titterington, D., 2000. Approximate Bayesian inference<br />for simple mixtures, in: Proceedings in Computational Statistics, COMP-<br />STAT’2000. Springer-Verlag.<br />Jaakkola, T., Jordan, M., 2000. Bayesian parameter estimation via varia-<br />tional methods. Statistics and Computing 10, 25–37.<br />Ji, C., 2009. Advances in Bayesian modelling and computation: Spatio-<br />temporal processes, model assessment and adaptive MCMC.<br />http://<br />20</p>  <p>Page 21</p> <p>stat.duke.edu/people/theses/ChunlinJi.html. Ph.D. thesis, Depart-<br />ment of Statistical Science, Duke University.<br />Jordan, M., 2004. Graphical models. Statistical Science 19, 140–15.<br />Jordan, M., Ghahramani, Z., Jaakkola, T., Saul, K., 1999. An introduction to<br />variational methods for graphical models. Machine Learning 37, 183–233.<br />Kushner, H.J., Yin, G.G., 1997. Stochastic Approximation Algorithms and<br />Applications. Springer-Verlag, New York.<br />Lavine, M., West, M., 1992. A Bayesian method for classification and dis-<br />crimination. Canadian Journal of Statistics 20, 451–461.<br />MacKay, D., 1995.<br />networks ensemble learning, in: Neural Networks: Artificial Intelligence<br />and Industrial Applications. Proceedings of the 3rd Annual Symposium<br />on Neural Networks, Nijmegen, Netherlands. pp. 191–198.<br />Developments in probabilistic modelling with neural<br />Merl, D., Lucas, J., Nevins, J., Shen, H., West, M., 2010. Trans-study<br />projection of genomic biomarkers using sparse factor regression models,<br />in: O´Hagan, A., West, M. (Eds.), The Handbook of Applied Bayesian<br />Analysis. Oxford University Press, pp. 118–154.<br />Robbins, H., Monro, S., 1951. A stochastic approximation method. Annals<br />of Mathematical Statstics 22, 400–407.<br />Shen, H., 2007. Bayesian analysis in cancer pathway studies and probabilis-<br />tic pathway annotation. http://stat.duke.edu/people/theses/ShenH.<br />html. Ph.D. thesis, Department of Statistical Science, Duke University.<br />Shen, H., West, M., 2010. Bayesian modelling for biological pathway anno-<br />tation of gene expression pathway signatures, in: Chen, M.H., Dey, D.,<br />M¨ uller, P., Sun, D., Ye, K. (Eds.), Frontiers of Statistical Decision Making<br />and Bayesian Analysis. New York: Springer-Verlag.<br />Ueda, N., Ghahramani, Z., 2002. Bayesian model search for mixture models<br />based on optimizing variational bounds. Neural Networks 15, 1223–1241.<br />Wang, B., Titterington, D., 2004. Convergence and asymptotic normality<br />of variational Bayesian approximations for exponential family models with<br />21</p>  <p>Page 22</p> <p>missing values, in: Chickering, M., Halpern, J. (Eds.), Proceedings of the<br />20th Conference in Uncertainty in Artificial Intelligence, pp. 577–584.<br />Xing, E., Jordan, M., Russell, S., 2003. A generalized mean field algorithm<br />for variational inference in exponential families, in: Meek, C., Kjerulff, U.<br />(Eds.), Proceedings of the 19th Annual Conference on Uncertainty in AI,<br />Morgan Kaufmann Publishers. pp. 583–591.<br />22</p>   </div> <div id="rgw19_56ab1c1ddcb57" class="c-box pub-resource-container js-toggle" style=""> <h4 class="lf js-expand-list"><small><a href="javascript:" class="lf">View other sources <span class="ico-expand-list"></span></a></small></h4> <h4 class="lf js-collapse-list hidden"><small><a href="javascript:" class="lf">Hide other sources <span class="ico-collapse-list"></span></a></small></h4> <div class="clear"></div> <div class="scroll-wrapper hidden"> <ul class="files-list c-list" id="rgw20_56ab1c1ddcb57">  <li class="c-list-item pub-resource-item"  data-type="fulltext" id="rgw21_56ab1c1ddcb57"> <span class="ico-pub"></span> <div class="file-content"> <div class="download"> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.153.5845&amp;amp;rep=rep1&amp;amp;type=pdf" target="_blank" rel="nofollow" class="publication-viewer" title="Bounded Approximations for Marginal Likelihoods">Bounded Approximations for Marginal Likelihoods</a> </div>  <div class="details">   Available from <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.153.5845&amp;amp;rep=rep1&amp;amp;type=pdf" target="_blank" rel="nofollow">psu.edu</a>  </div>    </div> </li>  </ul> </div> </div> </noscript> <div class="clearfix"> <div class="action-container">  </div> <div class="pub-legal"> Data provided are for informational purposes only. Although carefully collected, accuracy cannot be guaranteed. The impact factor represents a rough estimation of the journal's impact factor and does not reflect the actual current impact factor. Publisher conditions are provided by RoMEO. Differing provisions from the publisher's actual policy or licence agreement may be applicable. </div>  <div id="rgw28_56ab1c1ddcb57" class="citations-container"> <div class="tab-container"> <ul class="tab-list"> <li class="lf tab-item  js-citations"> <a href="javascript:void(0);" class="tab-link"> References  </small> </a> </li>  <li class="lf tab-item tab-item-active js-cited-in js-cited-in-tooltip"> <a href="javascript:void(0);" class="tab-link"> Cited In <small> (3) </small> </a> </li>    <li class="rf"> <div class="dropdown js-citations-sorter dropdown-right-align" style="position: relative; bottom: -1px;display:none;"> <a href="javascript:void(0);" class="dropdown-toggle"> Sorted by: <strong class="js-current-sorting"> Order of availability  </strong> <span class="caret"></span> </a> <ul class="dropdown-menu"> <li><a href="javascript:void(0);" data-sort="normal">Order of availability</a></li> <li><a href="javascript:void(0);" data-sort="original">Appearance in publication</a></li> </ul> </div> </li>  </ul> <div class="tab-section tab-section-active js-citations-list-container"> <div id="rgw29_56ab1c1ddcb57" class="pub-citations-list">  <ul class="c-list">  <li class="c-list-item li-publication   includes-citation-list"  id="rgw30_56ab1c1ddcb57" >  <div class="indent-left">  <div id="rgw31_56ab1c1ddcb57" class="js-publication-item-fulltext fulltext-thumb">    <a class="publication-preview ga-publication-viewer js-publication-item-fulltext-content" href="publication/230732835_A_Stochastic_Variational_Framework_for_Fitting_and_Diagnosing_Generalized_Linear_Mixed_Models">       </a>   <div class="preview-source-info"> <a class="details js-show-source ga-source-url" href="deref/http%3A%2F%2Farxiv.org%2Fpdf%2F1208.4949" target="_blank" >Source</a>  <div class="tooltip-content" style="display: none"> Available from: arxiv.org </div> </div>   </div>  </div>  <div class="indent-right">      </div>  <ul class="citation-contexts" id="rgw32_56ab1c1ddcb57">  <li class="citation-context-item"> "Paisley et al. (2012) proposed a stochastic optimization algorithm using control variates that allows direct maximization of the variational lower bound involving intractable integrals. Similar algorithms were considered by Ji et al. (2010) and Nott et al. (2012). Hoffman et al. (2010) and Wang et al. (2011) developed online VB algorithms for latent Dirichlet allocation and the hierarchical Dirichlet process respectively using stochastic natural gradient optimization of the variational lower bound. " </li>  </ul>   <div  style="margin-top: -2px">  <h5 class="pub-type-and-title">  <span class="publication-type">Article:</span>    <a class="js-publication-title-link js-go-to-publication ga-publication-item" href="publication/230732835_A_Stochastic_Variational_Framework_for_Fitting_and_Diagnosing_Generalized_Linear_Mixed_Models"> <span class="publication-title js-publication-title">A Stochastic Variational Framework for Fitting and Diagnosing Generalized Linear Mixed Models</span> </a>     </h5>  </div>    <div class="authors">     <a href="researcher/2067864256_Linda_S_L_Tan" class="authors js-author-name ga-publications-authors">Linda S. L. Tan</a> &middot;     <a href="researcher/8484000_David_J_Nott" class="authors js-author-name ga-publications-authors">David J. Nott</a>      </div>        <div class="abstract"> <span class="shorten"> <a href="javascript:" class="js-toggle-abstract">[Show abstract]</a> </span> <span class="full"> <a href="javascript:" class="js-toggle-abstract">[Hide abstract]</a><br/>  <strong>ABSTRACT:</strong> In stochastic variational inference, the variational Bayes objective function
is optimized using stochastic gradient approximation, where gradients computed
on small random subsets of data are used to approximate the true gradient over
the whole data set. This enables complex models to be fit to large data sets as
data can be processed in mini-batches. In this article, we extend stochastic
variational inference for conjugate-exponential models to nonconjugate models
and present a stochastic nonconjugate variational message passing algorithm for
fitting generalized linear mixed models that is scalable to large data sets. In
addition, we show that diagnostics for prior-likelihood conflict, which are
useful for Bayesian model criticism, can be obtained from nonconjugate
variational message passing automatically, as an alternative to
simulation-based Markov chain Monte Carlo methods. Finally, we demonstrate that
for moderate-sized data sets, convergence can be accelerated by using the
stochastic version of nonconjugate variational message passing in the initial
stage of optimization before switching to the standard version. </span> </div>    <div class="publication-meta publication-meta">  <span class="ico-publication-preview reset-background"></span> Preview    &middot; Article &middot; Aug 2012  </div>        <div class="publication-actions"> <div class="btn-group">  <a class="btn btn-plain action-request-external  " href="javascript:;" data-context="pubCit">  <span class="js-btn-label">Request full-text</span> </a>    </div> </div>      </li>  <li class="c-list-item li-publication   "  id="rgw33_56ab1c1ddcb57" >  <div class="indent-left">  <div id="rgw34_56ab1c1ddcb57" class="js-publication-item-fulltext fulltext-thumb">    <a class="publication-preview preview-not-available ga-publication-viewer-not-available js-publication-item-fulltext-content" href="publication/261248409_Minimum_Uncertainty_Gap_for_Robust_Visual_Tracking">       </a>    </div>  </div>  <div class="indent-right">      </div>   <div  style="margin-top: -2px">  <h5 class="pub-type-and-title">  <span class="publication-type">Conference Paper:</span>    <a class="js-publication-title-link js-go-to-publication ga-publication-item" href="publication/261248409_Minimum_Uncertainty_Gap_for_Robust_Visual_Tracking"> <span class="publication-title js-publication-title">Minimum Uncertainty Gap for Robust Visual Tracking</span> </a>     </h5>  </div>    <div class="authors">     <a href="researcher/69893771_Junseok_Kwon" class="authors js-author-name ga-publications-authors">Junseok Kwon</a> &middot;     <a href="researcher/7868586_Kyoung_Mu_Lee" class="authors js-author-name ga-publications-authors">Kyoung Mu Lee</a>      </div>        <div class="abstract"> <span class="shorten"> <a href="javascript:" class="js-toggle-abstract">[Show abstract]</a> </span> <span class="full"> <a href="javascript:" class="js-toggle-abstract">[Hide abstract]</a><br/>  <strong>ABSTRACT:</strong> We propose a novel tracking algorithm that robustly tracks the target by finding the state which minimizes uncertainty of the likelihood at current state. The uncertainty of the likelihood is estimated by obtaining the gap between the lower and upper bounds of the likelihood. By minimizing the gap between the two bounds, our method finds the confident and reliable state of the target. In the paper, the state that gives the Minimum Uncertainty Gap (MUG) between likelihood bounds is shown to be more reliable than the state which gives the maximum likelihood only, especially when there are severe illumination changes, occlusions, and pose variations. A rigorous derivation of the lower and upper bounds of the likelihood for the visual tracking problem is provided to address this issue. Additionally, an efficient inference algorithm using Interacting Markov Chain Monte Carlo is presented to find the best state that maximizes the average of the lower and upper bounds of the likelihood and minimizes the gap between two bounds simultaneously. Experimental results demonstrate that our method successfully tracks the target in realistic videos and outperforms conventional tracking methods. </span> </div>    <div class="publication-meta publication-meta">    No preview  &middot; Conference Paper &middot; Jun 2013  </div>        <div class="publication-actions"> <div class="btn-group">  <a class="btn btn-plain action-request-external  " href="javascript:;" data-context="pubCit">  <span class="js-btn-label">Request full-text</span> </a>    </div> </div>      </li>  <li class="c-list-item li-publication   "  id="rgw35_56ab1c1ddcb57" >  <div class="indent-left">  <div id="rgw36_56ab1c1ddcb57" class="js-publication-item-fulltext fulltext-thumb">    <a class="publication-preview ga-publication-viewer js-publication-item-fulltext-content" href="publication/279309917_An_Empirical_Study_of_Stochastic_Variational_Algorithms_for_the_Beta_Bernoulli_Process">       </a>   <div class="preview-source-info"> <a class="details js-show-source ga-source-url" href="profile/David_Knowles2" >Source</a>  <div class="tooltip-content" style="display: none"> Available from: David A. Knowles </div> </div>   </div>  </div>  <div class="indent-right">      </div>   <div  style="margin-top: -2px">  <h5 class="pub-type-and-title">  <span class="publication-type">Article:</span>    <a class="js-publication-title-link js-go-to-publication ga-publication-item" href="publication/279309917_An_Empirical_Study_of_Stochastic_Variational_Algorithms_for_the_Beta_Bernoulli_Process"> <span class="publication-title js-publication-title">An Empirical Study of Stochastic Variational Algorithms for the Beta Bernoulli Process</span> </a>     </h5>  </div>    <div class="authors">     <a href="researcher/2076919269_Amar_Shah" class="authors js-author-name ga-publications-authors">Amar Shah</a> &middot;     <a href="researcher/54244192_David_A_Knowles" class="authors js-author-name ga-publications-authors">David A. Knowles</a> &middot;     <a href="researcher/8159937_Zoubin_Ghahramani" class="authors js-author-name ga-publications-authors">Zoubin Ghahramani</a>      </div>        <div class="abstract"> <span class="shorten"> <a href="javascript:" class="js-toggle-abstract">[Show abstract]</a> </span> <span class="full"> <a href="javascript:" class="js-toggle-abstract">[Hide abstract]</a><br/>  <strong>ABSTRACT:</strong> Stochastic variational inference (SVI) is emerging as the most promising
candidate for scaling inference in Bayesian probabilistic models to large
datasets. However, the performance of these methods has been assessed primarily
in the context of Bayesian topic models, particularly latent Dirichlet
allocation (LDA). Deriving several new algorithms, and using synthetic, image
and genomic datasets, we investigate whether the understanding gleaned from LDA
applies in the setting of sparse latent factor models, specifically beta
process factor analysis (BPFA). We demonstrate that the big picture is
consistent: using Gibbs sampling within SVI to maintain certain posterior
dependencies is extremely effective. However, we find that different posterior
dependencies are important in BPFA relative to LDA. Particularly,
approximations able to model intra-local variable dependence perform best. </span> </div>    <div class="publication-meta publication-meta">   <span class="ico-publication-fulltext reset-background"></span> Full-text   &middot; Article &middot; Jun 2015  </div>        <div class="publication-actions"> <div class="btn-group">  <a class="btn btn-plain action-download primary  open-viewer" href="profile/David_Knowles2/publication/279309917_An_Empirical_Study_of_Stochastic_Variational_Algorithms_for_the_Beta_Bernoulli_Process/links/55a53c7b08aef604aa042e0b.pdf?origin=publication_list">  <span class="js-btn-label">Download</span> </a>    </div> </div>      </li>  </ul>    <div class="clearfix"></div>  </div> </div> </div> </div> </div> </div> <div class="clearfix">     <div id="rgw23_56ab1c1ddcb57" class="c-box pub-resource-container js-toggle" style="display: none;"> <h4 class="lf js-expand-list"><small><a href="javascript:" class="lf">View other sources <span class="ico-expand-list"></span></a></small></h4> <h4 class="lf js-collapse-list hidden"><small><a href="javascript:" class="lf">Hide other sources <span class="ico-collapse-list"></span></a></small></h4> <div class="clear"></div> <div class="scroll-wrapper hidden"> <ul class="files-list c-list" id="rgw24_56ab1c1ddcb57">  </ul> </div> </div>   <div id="rgw15_56ab1c1ddcb57" class="similar-publications"> <h2>Similar Publications</h2> <ul class="list-bordered">  <li class="c-list-item li-publication-teaser" id="rgw16_56ab1c1ddcb57"> <div> <h5> <a href="publication/284476357_A_deconvolution_path_for_mixtures" class="color-inherit ga-similar-publication-title"><span class="publication-title">A deconvolution path for mixtures</span></a>  </h5>  <div class="authors"> <a href="researcher/2067841296_Oscar_Hernan_Madrid_Padilla" class="authors ga-similar-publication-author">Oscar Hernan Madrid Padilla</a>, <a href="researcher/8853449_Nicholas_G_Polson" class="authors ga-similar-publication-author">Nicholas G. Polson</a>, <a href="researcher/46236443_James_G_Scott" class="authors ga-similar-publication-author">James G. Scott</a>  </div>  </div> <div class="clear"></div> </li>  <li class="c-list-item li-publication-teaser" id="rgw17_56ab1c1ddcb57"> <div> <h5> <a href="publication/283828647_Variational_Inference_for_Watson_Mixture_Model" class="color-inherit ga-similar-publication-title"><span class="publication-title">Variational Inference for Watson Mixture Model</span></a>  </h5>  <div class="authors"> <a href="researcher/30400442_Jalil_Taghia" class="authors ga-similar-publication-author">Jalil Taghia</a>, <a href="researcher/11378087_Arne_Leijon" class="authors ga-similar-publication-author">Arne Leijon</a>  </div>  </div> <div class="clear"></div> </li>  <li class="c-list-item li-publication-teaser" id="rgw18_56ab1c1ddcb57"> <div> <h5> <a href="publication/282844353_Mixture_models_applied_to_heterogeneous_populations" class="color-inherit ga-similar-publication-title"><span class="publication-title">Mixture models applied to heterogeneous populations</span></a>  </h5>  <div class="authors"> <a href="researcher/2082764072_Carolina_Valani_Cavalcante" class="authors ga-similar-publication-author">Carolina Valani Cavalcante</a>, <a href="researcher/2082758529_Kelly_Cristina_Mota_Goncalves" class="authors ga-similar-publication-author">Kelly Cristina Mota Gonçalves</a>  </div>  </div> <div class="clear"></div> </li>  </ul> </div> </div> </div> </div> </div></div></div>
<div class="clear"></div><div id="rgw38_56ab1c1ddcb57" class="default-footer"> <div id="footer" class="clearfix"> <span class="footer-left"> &copy; 2008&dash;2016 researchgate.net. All rights reserved. </span> <span class="footer-right"> <a href="https://www.researchgate.net/about">About us</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="https://www.researchgate.net/contact">Contact us</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="careers">Careers</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="developers">Developers</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="blog" target="_blank">News</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="application.PrivacyPolicy.html">Privacy</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="application.TermsAndConditions.html">Terms</a> <span class="footer-link-separator" style="padding: 0 5px;">&nbsp;|&nbsp;</span> <a href="advertising?_ref=ft">Advertising</a> <span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="recruiters?_ref=ft">Recruiting</a> </span> </div>  </div></div>
<div id="rgw39_56ab1c1ddcb57">  <div class="header-wrapper-logged-out"> <div id="header"> <div class="header-content"> <a href="" class="g-l-logo"> <svg width="149" height="19"> <image xlink:href="https://c5.rgstatic.net/m/235107188705592/images/template/brand-header-logo.svg" src="https://c5.rgstatic.net/m/238113351022438/images/template/brand-header-logo.png" width="149" height="19"/> </svg> </a> <a href="" class="g-l-logo-ico"> <svg width="127" height="17" viewbox="0 0 127 22"> <image xlink:href="https://c5.rgstatic.net/m/235107188705592/images/template/brand-header-logo.svg" src="https://c5.rgstatic.net/m/238113351022438/images/template/brand-header-logo.png" width="127" height="17"/> </svg> </a> <div id="rgw40_56ab1c1ddcb57" class="header-login-wrapper js-header-login"> <div class="dropdown-right-align"> <div class="login-signup-container lf"> <a href="https://www.researchgate.net/signup.SignUp.html?ev=su_chnl_index&amp;hdrsu=1&amp;_sg=-_AXte2K6-uCMEPJTrf7R8znTc35FnXLIarjM6_JdFY4g47e913kJUiCkhWI7XBu" class="dropdown-toggle lf">Join for free</a> </div> <div class="dropdown lf" style="height: 20px;"> <a href="https://www.researchgate.net/application.Login.html" class="js-login-url dropdown-toggle lf">Log in <span class="caret"></span></a> <div class="dropdown-menu"> <div class="header-login-form-wrapper"> <!--[if IE 6]><p class="box-warning" style="margin-bottom: 0;">Sorry, ResearchGate no longer supports the version of Internet Explorer you are using. <a href="http://whatbrowser.org/" rel="nofollow" target="_blank">Update your web browser</a> and then log in. </p><![endif]--> <form method="post" action="https://www.researchgate.net/application.Login.html" class="form-big header-login-form js-login-form" name="loginForm" id="headerLoginForm"> <input type="hidden" name="request_token" value="NMjF2gk6wBjgks0z8rIWRQOMyQEHuqe34YvNBoIygVnmoGUL3XLLfL7tBZKk5SrVW05Pt/3IKfu33Vt7T/koh8z908k8TvDM4mRxe2jm3cx094cp/FfJba9c/O8er+QFXWIp5fDQyZNQgg514giYL4DUQrAZQE3DXSvWSAjgR9stNSid38IXeo6LvZzdsp4e9I5zoZ8lIylZvajHMfJB6xtwGPuZgRd0h7o9cCOSo0nTs0kSKi2Zel7QVBUveSZLzAJdi3F5g6AYW8P4lrDAAEBNYAdFN1XKocS8iK46yt0="/> <input type="hidden" name="urlAfterLogin" value="publication/228914332_Bounded_Approximations_for_Marginal_Likelihoods"/> <input type="hidden" name="invalidPasswordCount" value="0"/> <input type="hidden" name="headerLogin" value="yes"/> <label for="input-header-login">Email</label> <div class="login-input"> <div class="info-tip-wrapper"> <span class="ico-info js-info"></span> </div> <input type="email" value="" name="login" class="login js-login-input text" id="input-header-login" tabindex="1"/> </div> <div class="clear"></div> <label class="lf" for="input-header-password"> Password </label> <a class="rf forgot-password js-forgot-password" href="application.LostPassword.html">Forgot password?</a> <div class="clear"></div> <input type="password" value="" name="password" class="password js-password-input text" id="input-header-password" tabindex="2"/> <div class="clear"></div> <label class="remember-me" for="headerLoginCookie"> <input type="checkbox" checked="checked" value="yes" name="setLoginCookie" class="lf checkbox" id="headerLoginCookie" tabindex="3"/> Keep me logged in </label> <div class="clear"></div> <input value="Log in" name="loginSubmit" class="btn btn-promote btn-fullwidth btn-large allow-leave js-submit-button" type="submit" tabindex="4"/> </form> <div class="connectors"> <div class="text">or log in with</div> <div class="connector-actions"> <a href="connector/linkedin/" class="li-connect js-li-connect" data-redirect-url="cHVibGljYXRpb24vMjI4OTE0MzMyX0JvdW5kZWRfQXBwcm94aW1hdGlvbnNfZm9yX01hcmdpbmFsX0xpa2VsaWhvb2Rz"> <span class="icon ico-linkedin-round-grey"></span> <span class="icon ico-linkedin-round"></span> </a> <a href="connector/facebook/" class="fb-connect middle js-fb-connect" data-redirect-url="cHVibGljYXRpb24vMjI4OTE0MzMyX0JvdW5kZWRfQXBwcm94aW1hdGlvbnNfZm9yX01hcmdpbmFsX0xpa2VsaWhvb2Rz"> <span class="icon ico-facebook-round-grey"></span> <span class="icon ico-facebook-round"></span> </a> <a href="connector/google/" class="g-connect js-g-connect" data-redirect-url="cHVibGljYXRpb24vMjI4OTE0MzMyX0JvdW5kZWRfQXBwcm94aW1hdGlvbnNfZm9yX01hcmdpbmFsX0xpa2VsaWhvb2Rz"> <span class="icon ico-google-round-grey"></span> <span class="icon ico-google-round"></span> </a> </div> </div> </div> </div> </div> </div> </div> </div> </div> <script type="application/ld+json">
{ "@context" : "http://schema.org",
  "@type" : "Organization",
  "name" : "ResearchGate",
  "url" : "http://www.researchgate.net",
  "logo" : "http://www.researchgate.net/images/template/rg_logo_square_brand.png",
  "sameAs" : [ "https://www.facebook.com/ResearchGate",
    "https://twitter.com/ResearchGate",
    "https://plus.google.com/+researchgate",
    "https://www.linkedin.com/company/researchgate"] 
}
</script> </div> </div><div class="c-signup-bar" id="rgw41_56ab1c1ddcb57"> <div class="banner-contents">   <span class="message">ResearchGate is the professional network for scientists and researchers.</span> <a href="signup.SignUp.html?ev=su_banner" class="btn btn-large btn-promote">Join for free</a>  </div> </div></div>
<script>
rgConfig.backendTime = 739;
</script>
<script src="//c5.rgstatic.net/m/2277196935388619/javascript/lib/yui3/yui/yui-min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/2448732603281275/javascript/yuiLoaderConfig-min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/23178613132105398/javascript/vendor/babel-core/browser-polyfill.min.js" type="text/javascript"></script>
<script>
(function (){
if (typeof YRG === "undefined") {
var xmlHttpRequest = new XMLHttpRequest();
xmlHttpRequest.open("post", "go.Error.html");
xmlHttpRequest.setRequestHeader("Content-Type", "application/json");
xmlHttpRequest.setRequestHeader("Accept", "application/json"); var loadedScripts = "";
if (window.performance && window.performance.getEntriesByType) {
    var result = [];
    var resources = performance.getEntriesByType("resource");
    for (var i in resources) {
        if (resources.hasOwnProperty(i)) {
            result.push({
                name: resources[i].name,
                duration: resources[i].duration
            });
        }
    }
    loadedScripts += "&loadedScripts=" + encodeURIComponent(JSON.stringify(result));
}
if (typeof YUI === "undefined") {
    loadedScripts += "&yuiLoaded=false";
} else {
    loadedScripts += "&yuiLoaded=true";
}
xmlHttpRequest.send("Type=InformationException&message=" + encodeURIComponent("Error loading YUI") + loadedScripts);
}
})();
</script>
<script>if (typeof YRG !== 'undefined') { YRG.use('rg-base',function(Y){Y.applyConfig({ignore: ["css-rg","css-rg2","css-ie","css-modules-publicprofile"]});Y.use(["rg.core.pagespeed.Monitoring"],function(Y){(function(){Y.rg.createInitialWidget({"data":{"content":{"data":{"profileSmallHeader":{"data":{"profileBadge":{"data":{"fullname":"Chunlin Ji","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2671872220764\/images\/template\/default\/profile\/profile_default_m.jpg","profileStats":[],"profileFollowButton":null,"profileReputationScoreNumber":null,"profileUrl":"profile\/Chunlin_Ji","institution":"Kuang-Chi Institute of Advanced Technology","institutionUrl":false,"widgetId":"rgw4_56ab1c1ddcb57"},"id":"rgw4_56ab1c1ddcb57","partials":[],"templateName":"publicprofile\/stubs\/ProfileBadge.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicprofile.ProfileBadge.html?accountId=9666075","viewClass":null,"yuiModules":["css-modules-publicprofile"],"stylesheets":["modules\/publicprofile.css"],"_isYUI":true},"widgetId":"rgw3_56ab1c1ddcb57"},"id":"rgw3_56ab1c1ddcb57","partials":[],"templateName":"publicprofile\/stubs\/ProfileSmallHeader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicprofile.ProfileSmallHeader.html?publicationUid=228914332","viewClass":null,"yuiModules":["css-modules-publicprofile"],"stylesheets":["modules\/publicprofile.css"],"_isYUI":true},"publication":{"data":{"publicationUid":228914332,"title":"Bounded Approximations for Marginal Likelihoods","journalTitle":false,"journalDetailsTooltip":false,"affiliation":"Department of Statistical Science, Duke University, 27708-0251, Durham, NC, USA","type":"Article","details":{"journalInfos":{"journal":"","publicationDate":"01\/2010;","publicationDateRobot":"2010-01","article":""}},"source":false,"publicationActions":null,"publicationCoins":{"data":{"tags":[{"key":"ctx_ver","value":"Z39.88-2004"},{"key":"rft_val_fmt","value":"info:ofi\/fmt:kev:mtx:journal"},{"key":"rfr_id","value":"info:sid\/researchgate.net:researchgate"},{"key":"rft.atitle","value":"Bounded Approximations for Marginal Likelihoods"},{"key":"rft.date","value":"2010"},{"key":"rft.au","value":"Chunlin Ji,Haige Shen,Mike West"},{"key":"rft.genre","value":"article"}],"widgetId":"rgw6_56ab1c1ddcb57"},"id":"rgw6_56ab1c1ddcb57","partials":[],"templateName":"publicliterature\/stubs\/PublicationCoins.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationCoins.html?publicationUid=228914332","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationAuthors":{"data":{"publicationUid":228914332,"peopleItems":[{"data":{"authorNameOnPublication":"Chunlin Ji","accountUrl":"profile\/Chunlin_Ji","accountKey":"Chunlin_Ji","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2671872220764\/images\/template\/default\/profile\/profile_default_m.jpg","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Chunlin Ji","profile":{"professionalInstitution":{"professionalInstitutionName":"Kuang-Chi Institute of Advanced Technology","professionalInstitutionUrl":false}},"professionalInstitutionName":"Kuang-Chi Institute of Advanced Technology","professionalInstitutionUrl":false,"url":"profile\/Chunlin_Ji","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":false,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":true,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"accountKey":"Chunlin_Ji","hasInfoPopup":false,"hasTeaserPopup":true,"showContactAuthorButton":true,"widgetId":"rgw9_56ab1c1ddcb57"},"id":"rgw9_56ab1c1ddcb57","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAccountItem.html?entityId=9666075&enableUnfollow=0&imageSize=l&enableFollowButton=0&showContactAuthorButton=1","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"accountInstitution":"Kuang-Chi Institute of Advanced Technology","score":null,"largeTooltip":false,"useRebrandedImageStyle":null,"authorCount":3,"accountCount":1,"publicationUid":228914332,"widgetId":"rgw8_56ab1c1ddcb57"},"id":"rgw8_56ab1c1ddcb57","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAccountItem.html","templateExtensions":[],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAccountItem.html?accountId=9666075&context=pubdetail_authors_xflw&showContactAuthorButton=1&authorCount=3&accountCount=1&publicationUid=228914332","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true},{"data":{"authorUrl":"researcher\/82093842_Haige_Shen","authorNameOnPublication":"Haige Shen","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg","imageSize":"s","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Haige Shen","profile":{"professionalInstitution":{"professionalInstitutionName":false,"professionalInstitutionUrl":null}},"professionalInstitutionName":false,"professionalInstitutionUrl":null,"url":"researcher\/82093842_Haige_Shen","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":true,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":false,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"widgetId":"rgw11_56ab1c1ddcb57"},"id":"rgw11_56ab1c1ddcb57","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAuthorItem.html?entityId=82093842&imageSize=l&enableAuthorInviteButton=0","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"largeTooltip":false,"useRebrandedImageStyle":null,"widgetId":"rgw10_56ab1c1ddcb57"},"id":"rgw10_56ab1c1ddcb57","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorItem.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorItem.html?authorUid=82093842&authorNameOnPublication=Haige%20Shen","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true},{"data":{"authorUrl":"researcher\/38910148_Mike_West","authorNameOnPublication":"Mike West","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg","imageSize":"s","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Mike West","profile":{"professionalInstitution":{"professionalInstitutionName":false,"professionalInstitutionUrl":null}},"professionalInstitutionName":false,"professionalInstitutionUrl":null,"url":"researcher\/38910148_Mike_West","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":true,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":false,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"widgetId":"rgw13_56ab1c1ddcb57"},"id":"rgw13_56ab1c1ddcb57","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAuthorItem.html?entityId=38910148&imageSize=l&enableAuthorInviteButton=0","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"largeTooltip":false,"useRebrandedImageStyle":null,"widgetId":"rgw12_56ab1c1ddcb57"},"id":"rgw12_56ab1c1ddcb57","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorItem.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorItem.html?authorUid=38910148&authorNameOnPublication=Mike%20West","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true}],"hasMore":false,"nextOffset":6,"useRebrandedImageStyle":null,"widgetId":"rgw7_56ab1c1ddcb57"},"id":"rgw7_56ab1c1ddcb57","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorList.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorList.html?publicationUid=228914332&context=pubdetail_authors_xflw&showContactAuthorButton=1","viewClass":"views.publicliterature.PublicationDetailAuthorListView","yuiModules":["rg.views.publicliterature.PublicationDetailAuthorListView"],"stylesheets":[],"_isYUI":true},"publicationAbstract":{"data":{"publicationUid":228914332,"abstract":"<noscript><\/noscript><div>We discuss novel approaches to evaluation of both upper and lower bounds on log marginal likelihoods for model comparison in Bayesian analysis. From posterior Monte Carlo samples, we show how existing variational approxima-tion methods defining lower bounds on marginal likelihoods can be extended to also define upper bounds, and develop optimization methods to minimize such upper bounds. Further, using this new approach to upper bound evalu-ation, we suggest and exemplify a new quasi-optimized lower bound that can often be obtained with trivial computations compared to current methods. We further discuss the use of partial analytic marginalization of some model parameters as a way of significantly reducing the differences between upper and lower bounds to improve marginal likelihood approximation. To imple-ment this, however, traditional variational methods are intractable, and we provide solution in terms of a novel Monte Carlo Stochastic Approximation (MCSA). We provide theoretical results on convergence of the resulting ap-proximations to true bounds, and several simulation examples in regression and mixture models to demonstrate the accuracy and efficacy of the new methods.<\/div>","canEdit":false,"isAdmin":false,"isArtifact":false,"showFullAbstract":false,"widgetId":"rgw14_56ab1c1ddcb57"},"id":"rgw14_56ab1c1ddcb57","partials":[],"templateName":"publicliterature\/stubs\/PublicationAbstract.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationAbstract.html?publicationUid=228914332","viewClass":"views.publicliterature.PublicationAbstractView","yuiModules":["rg.views.publicliterature.PublicationAbstractView"],"stylesheets":[],"_isYUI":true},"publicationKeywords":null,"publicationState":null,"isGuest":true,"isAdminEditingAllowed":false,"isArtifact":false,"figureListWidget":null,"previewImage":"https:\/\/i1.rgstatic.net\/publication\/228914332_Bounded_Approximations_for_Marginal_Likelihoods\/links\/000495e90cf2ed98fb440b17\/smallpreview.png","nativeAdDisclosure":null,"showFollowPublicationButton":false,"followPublicationPromo":"","widgetId":"rgw5_56ab1c1ddcb57"},"id":"rgw5_56ab1c1ddcb57","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailItem.html","templateExtensions":["generalHelpers"],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailItem.html?publicationUid=228914332&showActionBar=0&showContactAuthorButton=1&showRequestFulltextExperience=0&showNoRgAuthorsRequestFulltextExperience=0&showFollowPublicationPromo=0","viewClass":"views.publicliterature.PublicationDetailItemView","yuiModules":["rg.views.publicliterature.PublicationDetailItemView"],"stylesheets":[],"_isYUI":true},"similarPublications":{"data":{"publicationListItems":[{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore","clickThrough":"experimentMilestoneClickedToPublicationFromReferenceWithNoFulltext","clickThroughWithContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":2067841296,"url":"researcher\/2067841296_Oscar_Hernan_Madrid_Padilla","fullname":"Oscar Hernan Madrid Padilla","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":8853449,"url":"researcher\/8853449_Nicholas_G_Polson","fullname":"Nicholas G. Polson","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":46236443,"url":"researcher\/46236443_James_G_Scott","fullname":"James G. Scott","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Nov 2015","journal":null,"showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/284476357_A_deconvolution_path_for_mixtures","usePlainButton":true,"publicationUid":284476357,"feedStubs":null,"hasFeedStubs":false,"impactPoints":false,"url":"publication\/284476357_A_deconvolution_path_for_mixtures","title":"A deconvolution path for mixtures","displayTitleAsLink":true,"authors":[{"id":2067841296,"url":"researcher\/2067841296_Oscar_Hernan_Madrid_Padilla","fullname":"Oscar Hernan Madrid Padilla","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":8853449,"url":"researcher\/8853449_Nicholas_G_Polson","fullname":"Nicholas G. Polson","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":46236443,"url":"researcher\/46236443_James_G_Scott","fullname":"James G. Scott","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":[],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/284476357_A_deconvolution_path_for_mixtures","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/284476357_A_deconvolution_path_for_mixtures\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw16_56ab1c1ddcb57"},"id":"rgw16_56ab1c1ddcb57","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=284476357","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore","clickThrough":"experimentMilestoneClickedToPublicationFromReferenceWithNoFulltext","clickThroughWithContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":30400442,"url":"researcher\/30400442_Jalil_Taghia","fullname":"Jalil Taghia","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":11378087,"url":"researcher\/11378087_Arne_Leijon","fullname":"Arne Leijon","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Nov 2015","journal":"IEEE Transactions on Pattern Analysis and Machine Intelligence","showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/283828647_Variational_Inference_for_Watson_Mixture_Model","usePlainButton":true,"publicationUid":283828647,"feedStubs":null,"hasFeedStubs":false,"impactPoints":"5.78","url":"publication\/283828647_Variational_Inference_for_Watson_Mixture_Model","title":"Variational Inference for Watson Mixture Model","displayTitleAsLink":true,"authors":[{"id":30400442,"url":"researcher\/30400442_Jalil_Taghia","fullname":"Jalil Taghia","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":11378087,"url":"researcher\/11378087_Arne_Leijon","fullname":"Arne Leijon","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["IEEE Transactions on Pattern Analysis and Machine Intelligence 11\/2015;  DOI:10.1109\/TPAMI.2015.2498935"],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/283828647_Variational_Inference_for_Watson_Mixture_Model","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/283828647_Variational_Inference_for_Watson_Mixture_Model\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw17_56ab1c1ddcb57"},"id":"rgw17_56ab1c1ddcb57","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=283828647","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore","clickThrough":"experimentMilestoneClickedToPublicationFromReferenceWithNoFulltext","clickThroughWithContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":2082764072,"url":"researcher\/2082764072_Carolina_Valani_Cavalcante","fullname":"Carolina Valani Cavalcante","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2082758529,"url":"researcher\/2082758529_Kelly_Cristina_Mota_Goncalves","fullname":"Kelly Cristina Mota Gon\u00e7alves","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Oct 2015","journal":null,"showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/282844353_Mixture_models_applied_to_heterogeneous_populations","usePlainButton":true,"publicationUid":282844353,"feedStubs":null,"hasFeedStubs":false,"impactPoints":false,"url":"publication\/282844353_Mixture_models_applied_to_heterogeneous_populations","title":"Mixture models applied to heterogeneous populations","displayTitleAsLink":true,"authors":[{"id":2082764072,"url":"researcher\/2082764072_Carolina_Valani_Cavalcante","fullname":"Carolina Valani Cavalcante","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2082758529,"url":"researcher\/2082758529_Kelly_Cristina_Mota_Goncalves","fullname":"Kelly Cristina Mota Gon\u00e7alves","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":[],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/282844353_Mixture_models_applied_to_heterogeneous_populations","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/282844353_Mixture_models_applied_to_heterogeneous_populations\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw18_56ab1c1ddcb57"},"id":"rgw18_56ab1c1ddcb57","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=282844353","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"viewClass":"sidebar","widgetId":"rgw15_56ab1c1ddcb57"},"id":"rgw15_56ab1c1ddcb57","partials":[],"templateName":"publicliterature\/stubs\/SimilarPublications.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.SimilarPublications.html?referencePublicationId=228914332&view=sidebar","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationFulltextPreview":null,"publicationResourcesFulltext":{"data":{"publicationUid":228914332,"publicationResourceList":{"data":{"publicationResourceItems":[{"data":{"publicationUid":228914332,"publicationType":"article","linkId":"000495e90cf2ed98fb440b17","fileName":"Bounded Approximations for Marginal Likelihoods","fileUrl":"http:\/\/citeseerx.ist.psu.edu\/viewdoc\/download?doi=10.1.1.153.5845&amp;rep=rep1&amp;type=pdf","name":"psu.edu","nameUrl":"http:\/\/citeseerx.ist.psu.edu\/viewdoc\/download?doi=10.1.1.153.5845&amp;rep=rep1&amp;type=pdf","canRemove":false,"fileIcon":"ico-pub","canPreview":true,"hasPublisherLink":null,"hasMetaData":true,"hide":false,"fulltext":"ico-pub","origin":"publication_list","isLastLink":true,"isUserLink":false,"widgetId":"rgw21_56ab1c1ddcb57"},"id":"rgw21_56ab1c1ddcb57","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceItem.html","templateExtensions":["generalHelpers"],"attrs":{"fileRequiredPublicationTypes":["code","coverPage","experimentFindings","method","negativeResults","presentation","rawData","researchProposal","workingPaper","artifact","dataset"]},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceItem.html?publicationUid=228914332&linkId=000495e90cf2ed98fb440b17&hide=0&disableJavascript=disableJavascript&useAlternativeTemplate=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"widgetId":"rgw20_56ab1c1ddcb57"},"id":"rgw20_56ab1c1ddcb57","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceList.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceList.html?publicationUid=228914332&limit=3&disableJavascript=disableJavascript&type=fulltextFile","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"resourceCount":1,"hidden":false,"showMore":false,"fulltext":true,"publicationDownloadCount":{"data":{"value":3,"valueFormatted":"3","widgetId":"rgw22_56ab1c1ddcb57"},"id":"rgw22_56ab1c1ddcb57","partials":[],"templateName":"publicliterature\/stubs\/PublicationDownloadCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDownloadCount.html?publicationUid=228914332","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw19_56ab1c1ddcb57"},"id":"rgw19_56ab1c1ddcb57","partials":[],"templateName":"publicliterature\/stubs\/PublicationResources.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResources.html?publicationUid=228914332&type=fulltextFile&disableJavascript=1","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationResourcesAttachments":{"data":{"publicationUid":228914332,"publicationResourceList":{"data":{"publicationResourceItems":[],"widgetId":"rgw24_56ab1c1ddcb57"},"id":"rgw24_56ab1c1ddcb57","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceList.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceList.html?publicationUid=228914332&limit=3&disableJavascript=disableJavascript&type=attachmentFile","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"resourceCount":0,"hidden":true,"showMore":false,"fulltext":false,"publicationDownloadCount":{"data":{"value":3,"valueFormatted":"3","widgetId":"rgw25_56ab1c1ddcb57"},"id":"rgw25_56ab1c1ddcb57","partials":[],"templateName":"publicliterature\/stubs\/PublicationDownloadCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDownloadCount.html?publicationUid=228914332","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw23_56ab1c1ddcb57"},"id":"rgw23_56ab1c1ddcb57","partials":[],"templateName":"publicliterature\/stubs\/PublicationResources.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResources.html?publicationUid=228914332&type=attachmentFile","viewClass":"views.publicliterature.PublicationResourcesView","yuiModules":["rg.views.publicliterature.PublicationResourcesView"],"stylesheets":[],"_isYUI":true},"publicationText":{"data":{"hide":false,"pages":[{"page":1,"text":"Bounded Approximations for Marginal Likelihoods\nChunlin Jia, Haige Shenb, Mike Westc\naDepartment of Statistics, Harvard University, Science Center, 1 Oxford Street,\nCambridge, MA 02138-2901, USA\nbNovartis Oncology, Biometrics, 180 Park Avenue,\nFlorham Park, NJ 07932, USA\ncDepartment of Statistical Science, Duke University, Durham, NC 27708-0251, USA\nAbstract\nWe discuss novel approaches to evaluation of both upper and lower bounds\non log marginal likelihoods for model comparison in Bayesian analysis. From\nposterior Monte Carlo samples, we show how existing variational approxima-\ntion methods defining lower bounds on marginal likelihoods can be extended\nto also define upper bounds, and develop optimization methods to minimize\nsuch upper bounds. Further, using this new approach to upper bound evalu-\nation, we suggest and exemplify a new quasi-optimized lower bound that can\noften be obtained with trivial computations compared to current methods.\nWe further discuss the use of partial analytic marginalization of some model\nparameters as a way of significantly reducing the differences between upper\nand lower bounds to improve marginal likelihood approximation. To imple-\nment this, however, traditional variational methods are intractable, and we\nprovide solution in terms of a novel Monte Carlo Stochastic Approximation\n(MCSA). We provide theoretical results on convergence of the resulting ap-\nproximations to true bounds, and several simulation examples in regression\nand mixture models to demonstrate the accuracy and efficacy of the new\nmethods.\nKeywords:\nKullback-Leibler Divergence, Variational Methods\nBayesian Model Comparison, Marginal Likelihood,\n\u2217Corresponding author: Chunlin Ji, tel\/fax: 1(617)495-5496\/496-8057\nEmail addresses: chunlin.ji@gmail.com (Chunlin Ji), haigeshen@yahoo.com\n(Haige Shen), mw@stat.duke.edu (Mike West)\nManuscript submitted for publicationFebruary 9, 2010"},{"page":2,"text":"1. Introduction\nThe marginal likelihood is the essential quantity in Bayesian model se-\nlection, representing the evidence of a model. However, evaluating marginal\nlikelihoods often involves intractable integration and relies on numerical inte-\ngration and approximation. Mean-field variational methods, initially devel-\noped in statistical physics and extensively studied by machine learning and\nBayesian learning communities for deterministic approximation of marginal\ndistributions (MacKay, 1995; Jordan et al., 1999; Jaakkola and Jordan, 2000;\nHumphreys and Titterington, 2000; Ueda and Ghahramani, 2002; Jordan,\n2004; Wang and Titterington, 2004), have been implemented in the model\nselection context (Corduneanu and Bishop, 2001; Beal, 2003).\nFor a specified model with parameters \u03b8 = {\u03b81,...,\u03b8K} \u2208 \u0398 and prior\ndensity p(\u03b8), the marginal likelihood based on observed data D is the quan-\ntity\n?\n\u0398\nIn many practical contexts, the required integration must be approximated\nnumerically. In certain cases, some of the parameters can be analytically in-\ntegrated out, reducing the dimension of the integral while leaving a numerical\nproblem of the same form.\nFor any density function q(\u03b8|\u03b3) parameterized by \u03b3 = {\u03b31,...,\u03b3J} \u2208 \u0393\nand with the same support as the posterior p(\u03b8|D), Jensen\u2019s inequality gives\np(D) =p(D,\u03b8)d\u03b8 =\n?\n\u0398\np(D|\u03b8)p(\u03b8)d\u03b8\n(1)\nlogp(D) \u2265 L(\u03b3) =\n?\n\u0398\nq(\u03b8|\u03b3)logp(D,\u03b8)\nq(\u03b8|\u03b3)d\u03b8. (2)\nMaximizing L(\u03b3) with respect to \u03b3 provides an optimized lower bound on log\nmarginal likelihood. This optimization is equivalent to minimization of the\nKullback-Leibler (KL) divergence of the true posterior p(\u03b8|D) from q(\u03b8|\u03b3).\nCurrent mean-field methods typically use a variational density form fac-\ntorized over hidden variables and model parameters (or construct such set-\ntings by treating certain model parameters as hidden variables), and rely\non EM style iterative algorithms to provide solutions to the lower bound\noptimization (Beal, 2003). Similar to application in variational MLE with\nmissing data (Celeux and Diebolt, 1992; Delyon et al., 1999), stochastic ap-\nproximation (SA) algorithms based on an iterative Monte Carlo procedures\ncan be used in cases where the expectation step in the EM algorithm can-\n2"},{"page":3,"text":"not be performed in closed form. Wang and Titterington (2004) have shown\nthat, for the mean-field variational densities of exponential family form, this\noptimization converges to the true local maximized lower bound.\nThe first question addressed here is that of adding an upper bound to\nproperly bracket the exact log marginal likelihood. Again using a class of\nvariational densities, we define a theoretical upper bound and develop a com-\nputational approach to its minimization. This optimization is equivalent to\nminimization of the KL divergence of the variational density q(\u03b8|\u03b3) from the\ntrue posterior p(\u03b8|D), complementing the lower bound approximation that\nminimizes the (directional) KL divergence in the other direction. Further,\nfor variational densities of exponential family form, we show convergence to\nthe true global minimum upper bound.\nWe also discuss a quasi-optimized lower bound that can be obtained with\ntrivial computation \u2013 compared to current approaches \u2013 based on the result\nof the optimized upper bound. In addition, we demonstrate that, if we can\nmarginalize with respect to a subset of parameters analytically, then we can\noften significantly reduce the range between the upper and lower bounds and\nhence improve the estimation. Further, we present a method that directly\nuses a method of Monte Carlo stochastic approximation (MCSA) to maximize\nthe lower bound, and prove the convergence to the true local maximum lower\nbound when q(\u03b8|\u03b3) takes an exponential family form.\nAccuracy and performance of these new methods is demonstrated with\ntwo examples. The first example is a Bayesian linear regression model, in\nwhich the analytical form of marginal likelihood is available for assessment\nof numerical approximations. The second example concerns finite mixture\nmodels. We also refer to additional examples in applications.\n2. Upper Bound on Marginal Likelihood\nWhen q(\u03b8|\u03b3) = p(\u03b8|D), the inequality in (2) turns into equality\nlogp(D) =\n?\n\u0398\np(\u03b8|D)logp(D,\u03b8)d\u03b8 \u2212\n?\n\u0398\np(\u03b8|D)logp(\u03b8|D)d\u03b8.\nThe second term here is the entropy of p(\u03b8|D) which, using Gibbs\u2019 inequality,\nsatisfies\n\u2212\n?\n\u0398\np(\u03b8|D)logp(\u03b8|D)d\u03b8 \u2264 \u2212\n?\n\u0398\np(\u03b8|D)logq(\u03b8|\u03b3)d\u03b8\n3"},{"page":4,"text":"for any q(\u03b8|\u03b3). We deduce the upper bound on log marginal likelihood\nU(\u03b3) =\n?\n\u0398\np(\u03b8|D)logp(\u03b8,D)\nq(\u03b8|\u03b3)d\u03b8 \u2265 logp(D). (3)\nMinimizing U(\u03b3) with respect to \u03b3 provides the optimum. It is clear that\nthe optimal parameter, \u03b3U, also minimizes the KL divergence of q(\u03b8|\u03b3) from\np(\u03b8|D), namely\n?\n\u0398\nD(p||q) =p(\u03b8|D)logp(\u03b8|D)\nq(\u03b8|\u03b3)d\u03b8. (4)\nThe minimized KL value is then just the discrepancy between the implied\nestimate U(\u03b3U) and the true logp(D).\nAssuming q(\u03b8|\u03b3) comes from the exponential family, D(p||q) as a lin-\near functional of logq(\u03b8|\u03b3) is convex with respect to \u03b3. Hence, the global\nminimum can be found by solving the j = 1,...,J equations\n\u2202\n\u2202\u03b3jD(p||q) = \u2212\n?\n\u0398\np(\u03b8|D)\n?\n\u2202\n\u2202\u03b3j\nlogq(\u03b8|\u03b3)\n?\nd\u03b8 = 0. (5)\nFor q(\u03b8|\u03b3) of exponential family form, these equations can be solved analyt-\nically in terms of posterior moments. Typically, the posterior is represented\nby a simulation sample such as from MCMC, and moments are approximated\nvia Monte Carlo. Given a Monte Carlo posterior sample {\u03b8(i): i = 1,...,N},\nit is trivial to prove that the resulting Monte Carlo estimated solution \u02c6 \u03b3U\nconverges (almost surely) with N to \u03b3U. The resulting global minimum upper\nbound of log marginal likelihood Uois then estimated by\n\u02c6Uo=1\nN\nN\n?\ni=1\nlogp(\u03b8(i),D)\nq(\u03b8(i)|\u02c6 \u03b3U)\n(6)\nwhich converges almost surely to Uo.\n3. Optimal Lower Bound Approximation\nWe comment on the standard variational lower bound approximation and\nthen introduce two new methods: quasi-optimized lower bounds, for fast and\nefficient computations relative to the standard method, and Monte Carlo\nstochastic approximation, for problems with non-factored variational densi-\nties.\n4"},{"page":5,"text":"3.1. Standard Variational Methods\nThe standard lower bound is based on equation (2); maximization of\nL(\u03b3) over \u03b3 provides the optimized lower bound on the log marginal like-\nlihood, equivalent to minimizing the KL divergence D(p||q) (Jordan et al.,\n1999; Ghahramani and Beal, 2001; Xing et al., 2003; Blei and Jordan, 2004).\nComputational tractability is achieved with factorized variational densities\nq(\u03b8|\u03b3) =?J\ndensities have exponential family forms, i.e. q(\u03b8j|\u03b3j) = h(\u03b8j)exp{\u03b3\u2032\na(\u03b3j)}. Most practical examples assume this.\nSubstantial further simplification is achieved if each complete conditional\nposterior p(\u03b8j|D,\u03b8\u2212j) is also of exponential family form.\narises in many contexts, and conditional exponential family forms of complete\nconditional posteriors can sometimes be induced by use of latent variables\nthat augment initial parameters. Under such an assumption, that for each\nj = 1,...,J,\nj=1q(\u03b8j|\u03b3j), where \u03b3 = {\u03b31,...,\u03b3J}, and when the component\nj\u03b8j\u2212\nThis structure\np(\u03b8j|D,\u03b8\u2212j) = h(\u03b8j)exp{g(\u03b8\u2212j,D)\u2032\u03b8j\u2212 b(g(\u03b8\u2212j,D))},\nwhere g(\u03b8\u2212j,D) is the posterior complete conditional natural parameter for\n\u03b8j, then the conditional optimization steps run through iterative updates of\nvariational parameter subsets using\n\u03b3j=\n?\n\u03b8\u2212j\ng(\u03b8\u2212j,D)q(\u03b8\u2212j|\u03b3\u2212j)d\u03b8\u2212j,j = 1,...,J, (7)\ni.e., matching the natural parameter of the variational density with the ex-\npected value of that of the complete conditional posterior. In such cases,\ncomputation using coordinate ascent algorithms can be achieved, in which\nwe iteratively maximize the bound with respect to each \u03b3jholding all other\nvariational parameters \u03b3\u2212j fixed at \u201ccurrent\u201d values; see Ghahramani and\nBeal (2001), Blei and Jordan (2004).\n3.2. Quasi-Optimized Lower Bound\nAs mentioned, the lower bound optimization via the standard variational\nmethod can be computationally challenging, so raising interest in modifi-\ncations and alternatives. A first path is suggested by the relative ease of\ncomputation of the new optimized upper bound of Section 2. This suggests\nthe use of \u03b3U, or realistically the MC estimate \u02c6 \u03b3U, in lower bound evaluation\n5"},{"page":6,"text":"too. While \u03b3L and \u03b3U generally differ \u2013 since they are minimizers of the\ngenerally different D(p||q) and D(q||p), respectively, they tend to be close in\nproblems with unimodal and increasingly concentrated posteriors, in many\nmodel contexts.\nThus we define the quasi-optimized lower bound as follows. Draw a Monte\nCarlo sample {\u03b8(i): i = 1,...,N} from q(\u03b8|\u02c6 \u03b3U) and use it to define and\nevaluate the MC estimated quasi-optimized lower bound\n\u02c6Lo=1\nN\nN\n?\ni=1\nlogp(\u03b8(i),D)\nq(\u03b8(i)|\u02c6 \u03b3U). (8)\nThis is a consistent estimate of L(\u03b3U), a lower bound that is not theoretically\noptimized but offers a computationally attractive, and often effective, proxy\nfor the optimal L(\u03b3L). Examples below explore this.\n3.3. Lower Bound Optimization by MCSA\nIf the variational distribution q\u03b3(\u03b8) is not a fully factorized distribution,\nand\/or the posterior complete conditionals intractable, then the analytical\niterative update equation for variational parameters derived in the varia-\ntional algorithm is inapplicable. This is common. We will show later, for\nexample, that analytic marginalization of some model parameters \u2013 when\nfeasible \u2013 can significantly reduce the discrepancy between the bounds on log\nmarginal likelihood; doing so, however, moves us out of the context in which\nthe lower bound optimization is tractable. For these cases, we need an alter-\native computational strategy, and here introduce a Monte Carlo stochastic\napproximation (MCSA) to numerically maximize the lower bound directly.\nWe also show that the algorithm converges to the true local maximum lower\nbound when q(\u03b8|\u03b3) takes an exponential family form.\nFirst note that\n\u02d9L(\u03b3) \u2261dL(\u03b3)\nd\u03b3\n= \u2212\n?\n\u0398\nh(\u03b8|\u03b3)q(\u03b8|\u03b3)d\u03b8 = 0\n(9)\nwhere\nh(\u03b8|\u03b3) =\n?\n1 + logq(\u03b8|\u03b3)\np(\u03b8,D)\n?\nd\nd\u03b3logq(\u03b8|\u03b3).\nOur novel MCSA approach aims to solve equations (9) numerically. This\ninvolves a modification of the standard stochastic approximation (SA) algo-\n6"},{"page":7,"text":"rithm (Robbins and Monro, 1951; Kushner and Yin, 1997) to define recursive\napproximation of the solution of\u02d9L(\u03b3) = 0 based on noisy, approximate eval-\nuation of the defining integral in equation (9).\nFor a current value of \u03b3, assume we generate a Monte Carlo sample {\u03b8(i):\ni = 1,...,N} from q(\u03b8|\u03b3), defining the consistent (in N) MC approximation\nto equation (9) as\n\u03bb(\u03b3) \u2261 \u22121\nN\nN\n?\ni=1\nh(\u03b8(i)|\u03b3). (10)\nA Robbins-Monroe SA algorithm then iteratively updates a sequence of val-\nues \u03b3(t)over t = 1,2,... via the recursion\n\u03b3(t+1)= \u03b3(t)+ s(t+1)\u03bb(\u03b3(t))\nfor some initial \u03b3(0)and sequence of scalar step sizes s(t). The latter sequence\nmust satisfy standard conditions,?\u221e\nder these conditions, it can be shown that the SA sequence \u03b3(t)converges\nto the lower bound optimizing value \u03b3L as N,t \u2192 \u221e; the proof relies on\nstandard theory of convergence of SA algorithms from (Kushner and Yin,\n1997); full mathematical details can be found in chapter 5 of the PhD thesis\nof the first author here (Ji, 2009).\nTerminating the MCSA after a series of steps yielding a terminal value\n\u02c6 \u03b3L, a further MC sample {\u03b8(i): i = 1,...,N} from q(\u03b8|\u02c6 \u03b3L) defines the final\nestimate of the optimal lower bound\nt=1s(t)= \u221e and?\u221e\nt=1\n?s(t)?2< \u221e. Un-\n\u02c6Lo=1\nN\nN\n?\ni=1\nlogp(\u03b8(i),D)\nq(\u03b8(i)|\u02c6 \u03b3L).(11)\n4. Evaluation Examples\nTwo model classes provide evaluation and examples. The first involves\nlinear regression model comparison, a context where the exact values of\nmarginal likelihood are available so that bound approximations can be as-\nsessed against true values. The second is Gaussian mixture models where an-\nalytic marginal likelihoods are unavailable, and where comparisons are made\nwith various methods to approximate bounds as well as the \u201cgold standard\u201d\nusing Candidate\u2019s formula (Chib, 1995).\n7"},{"page":8,"text":"4.1. Linear Regression\nAssume a linear model with n \u00d7 p design matrix X and n \u00d7 1 response\nvector y, viz.\ny \u223c N?X\u03b2,\u03c32In\n\u03b2 \u223c N?0p,\u03c4\u03c32Ip\n\u03c32\n\u223c IG(h0,k0)\n?\n?\nwhere hyperparameters \u03c4, h0, and k0are assumed to be fixed and known.\nHere D = {y}. Due to the conjugate setting, the exact marginal likelihood\nhas a closed form\np(D) = (2\u03c0)\u2212n\/2|C|\u22121\/2kh0\n0{\u0393(h0+ n\/2)\/\u0393(h0)}(k0+ y\u2032C\u22121y\/2)\u2212(h0+n\/2)\nwhere C = In+ \u03c4XX\u2032.\nTo assess marginal likelihood bound approximations we consider and com-\npare the two choices:\n\u2022 the full parameter context, setting \u03b8 = {\u03b2,\u03c32};\n\u2022 the reduced parameter context, in this case marginalizing \u03b2 away an-\nalytically and performing numerical approximations for bounds using\nonly \u03b8 = {\u03c32}.\nIn the reduced parameter context we make use of\np(D|\u03c32) = (2\u03c0)\u2212n\/2|\u03c32C|\u22121\/2exp(\u2212y\u2032B\u22121y\/(2\u03c32)).\nIn each case, the prior conjugacy means we can trivially sample posteriors to\nprovide MC samples for bound approximations.\nWe focus on simulated polynomial regression models and the problem of\ncomparing polynomial order; marginal likelihoods for each model order are\nkey ingredients. The design matrix has rows of the x\u2032\nfor some r > 0, with the n design points x1,...,xndrawn across a grid of\nvalues. Synthetic response data y come from a model with r = 3, n = 20,\n\u03b2 = [0.2,2,\u22122,0.5]Tand \u03c32= 10. The hyperparameters are set as \u03c4 = 0.1,\nh0= 1, and k0= 1.\nSeven log marginal likelihood values are reported for each model analysis,\nas follows.\ni= (1,xi,x2\ni,...,xr\ni)\n8"},{"page":9,"text":"ML:\nML is the exact log marginal likelihood p(D).\nU1:\nU1 is the estimate of the upper bound of log marginal likelihood in\nthe reduced parameter context. Here the variational distribution is\nq(\u03b8|\u03b3) = IG(\u03c32|h,k) with \u03b3 = (h,k). Posterior samples of \u03c32yield\noptimal variational parameters (hU,kU) via equation (5) and resulting\nU1from equation (6).\nU2:\nU2is the estimate of the upper bound in the full parameter context.\nHere q(\u03b8|\u03b3) = N(\u03b2|\u00b5,\u03a9)IG(\u03c32|h,k) and optimal variational param-\neters \u03b3 = {\u00b5U,\u03a9U,hU,kU} are estimated using equations (5), where-\nupon U2is approximated via equation (6).\nL1:\nL1is the estimate of the lower bound in the reduced parameter context\nas for U1, and using the MCSA method of Section 3.3 with estimate of\nequation (11).\nL2:\nL2is the estimate of the quasi-optimized lower bound in the reduced\nparameter context as for L1, but now with inverse gamma variational\nparameters set to the quasi-optimized values (h,k) \u2190 (hU,kU) of U1.\nL3:\nL3is the quasi-optimized lower bound estimate in the full parameter\ncontext. The normal and inverse gamma variational parameters are\nset to the quasi-optimized values \u03b3 = {\u00b5U,\u03a9U,hU,kU} from the upper\nbound analysis defining U2, and used to estimate the quasi-optimized\nlower bound of equation (8).\nL4:\nL4 is the lower bound using the standard variational method. The\nvariational parameters \u03b3 = {\u00b5U,\u03a9U,h,k} are estimated using the co-\nordinate ascent algorithm noted in Section 3.1. At these parameters,\nsamples of \u03b8 = {\u03b2,\u03c32} are drawn from q(\u03b8|\u03b3) and used to approximate\nthe lower bound via equation (11).\nWe show one example of a synthetic data set generated from a polyno-\nmial regression with r = 3, together with fitted models of several orders, in\nFigure 1. Simulations were repeated 100 times and each of the 7 marginal\nlikelihood bound approximations evaluated for each. Table 1 shows results.\nWe see that U1is more accurate than than U2, and L1, L2better than L3, L4,\nempirically confirming the view that, by marginalizing out some parameters,\nwe can significantly reduce the discrepancy between the marginal likelihood\n9"},{"page":10,"text":"\u22124\u221220\nx\n24\n\u221260\n\u221240\n\u221220\n0\n20\nr=1\ny\n\u22124 \u221220\nx\n24\n\u221260\n\u221240\n\u221220\n0\n20\nr=2\ny\n\u22124 \u221220\nx\n24\n\u221260\n\u221240\n\u221220\n0\n20\nr=3\ny\n\u22124 \u221220\nx\n24\n\u221260\n\u221240\n\u221220\n0\n20\nr=4\ny\n\u22124 \u221220\nx\n24\n\u221260\n\u221240\n\u221220\n0\n20\nr=5\ny\n\u22124\u221220\nx\n24\n\u221260\n\u221240\n\u221220\n0\n20\nr=6\ny\nFigure 1: Synthetic data approximated by polynomials of varying orders.\n10"},{"page":11,"text":"123456\n\u221286\n\u221284\n\u221282\n\u221280\n\u221278\n\u221276\n\u221274\n\u221272\n\u221270\nPolynomial order\nLog marginal likelihood\n \n \nUpper bound: U1\nExact marginal loglikelihood: ML\nLower bound: L1 \nQuasi\u2212optimized lower bound: L2\nFigure 2: Plot of the analytic value of the log marginal likelihood of the Bayesian\nlinear model with varying number of order q, and means of upper bound U1, lower\nbound L1and quasi-optimized lower bound L2of the log marginal likelihood for\n100 Monte Carlo runs.\n11"},{"page":12,"text":"and its upper\/lower bounds. Moreover, averages of U1,L1and L2over the\n100 simulations are plotted in Figure 2, illustrating the irrelevance of the\napproximation errors in estimating bounds in this example.\n4.2. Mixture Model\nA second study concerns evaluation of marginal likelihoods in multivariate\nnormal, k\u2212component mixture models, especially for comparison of models\nwith respect to the number k of mixture components. Denoting inherent,\nlatent mixture component indicators by z, the model for a random sample\nof p\u2212variate observations xi,i = 1,...,n, is\n(xi|zi= j) \u223c N(\u00b5j,\u03a3j),zi\u223c Mn(1,\u03c0),\nwhere \u03c0 = (\u03c01,...,\u03c0k)\u2032is the vector of mixing probabilities and Mn(1,\u03c0)\ndenotes the multinomial with sample size 1 on cells 1,...,k. We use tra-\nditional, conditionally conjugate priors: normal, inverse-Wishart priors for\nthe p\u2212vector means and p \u00d7 p covariances matrices, (\u00b5j|\u03a3j) \u223c N(0,\u03c4\u22121\u03a3j)\nand \u03a3j\u223c IW(d,S) independently over j = 1,...,k, and with specified hy-\nperparameters \u03c4,d,S; a uniform Dirichlet prior for component probabilities\n\u03c0 \u223c Dir(1\/k) where 1 is the k\u2212vector of ones. Under this specification,\nposterior simulation using Gibbs sampling is easy and widely used in routine\napplications (e.g. Lavine and West, 1992; Chan et al., 2008). This applies to\ngenerate posterior samples for the full set of uncertain parameters and latent\nvariables\n{zi; i = 1,...,n},{\u00b5j,\u03a3j; j = 1,...,k} and\n\u03c0\n(13)\ngiven data D \u2261 {xi,i = 1,...,n.}. To apply the methods for marginal\nlikelihood bounds, we can consider several possibilities for partial analytic\nposterior marginalization in order to improve approximations. We consider\nthe cases below, where in each case we include the latent zias part of the \u03b8\nparameter.\n\u2022 the standard or reduced\u2212\u03c0 context, when \u03b8 represents the quantities\nin (13) above with the exception of \u03c0 that can always be analytically\nintegrated away conditional on the indicators zi;\n\u2022 the reduced\u2212(\u03c0,\u00b5) context, when \u03c0 and the \u00b5j, (j = 1,...,k) are\n12"},{"page":13,"text":"Table 1: Exact value and approximate bounds on the log marginal likelihood in the linear regression model\nexample. The Monte Carlo estimates of bounds are given in terms of Monte Carlo mean and standard\ndeviations over simulations.\nU2\nU1\nML\nL1\nL2\nL3\nL4\n1\n\u221284.9591\n\u00b10.0045\n\u221273.8644\n\u00b10.0067\n\u221270.3021\n\u00b10.0079\n\u221272.6467\n\u00b10.0093\n\u221277.9364\n\u00b10.00105\n\u221280.5663\n\u00b10.00127\n\u221285.0046\n\u00b10.0012\n\u221273.9329\n\u00b10.0015)\n\u221270.3933\n\u00b10.0021\n\u221272.7603\n\u00b10.0027\n\u221278.0741\n\u00b10.0029\n\u221280.7266\n\u00b10.0039\n\u221285.0068\n\u221285.0074\n\u00b10.0006\n\u221273.9395\n\u00b10.0010\n\u221270.4054\n\u00b10.0012\n\u221272.7792\n\u00b10.0016\n\u221278.1013\n\u00b10.0016\n\u221280.7622\n\u00b10.0020\n\u221285.0089\n\u00b10.0008\n\u221273.9414\n\u00b10.0011\n\u221270.4077\n\u00b10.0013\n\u221272.7825\n\u00b10.0020\n\u221278.1045\n\u00b10.0018\n\u221280.7656\n\u00b10.0020\n\u221285.0521\n\u00b10.0049\n\u221274.0038\n\u00b10.0052\n\u221270.4871\n\u00b10.0060\n\u221272.8781\n\u00b10.0065\n\u221278.2152\n\u00b10.0078\n\u221280.8920\n\u00b10.0085\n\u221285.0475\n\u00b10.0028\n\u221273.9974\n\u00b10.0032\n\u221270.4791\n\u00b10.0039\n\u221272.8676\n\u00b10.0040\n\u221278.2040\n\u00b10.0042\n\u221280.8781\n\u00b10.0048\n2\u221273.9374\n3\u221270.4009\n4\u221272.7720\n5\u221278.0906\n6\u221280.7477\n13"},{"page":14,"text":"integrated out analytically, so that\n\u03b8 = {(zi, i = 1,...,n),(\u03a3j, j = 1,...,k)};\n\u2022 the reduced\u2212(\u03c0,\u00b5,\u03a3) context, when \u03c0 and the (\u00b5j,\u03a3j), (j = 1,...,k)\nare integrated out analytically, so that\n\u03b8 = {(zi, i = 1,...,n)}.\nGiven the prior conjugacy, in each case, the required densities p(D|\u03b8),p(\u03b8)\nand p(\u03b8|D) are analytically available.\nWe consider evaluation of seven log marginal likelihood estimates, as fol-\nlows.\nU1,L1:\nU1is the upper bound estimate in the reduced\u2212(\u03c0,\u00b5,\u03a3) context,\nwhen \u03b8 represents just the configuration indicators zi. The variational\ndistribution is q(\u03b8|\u03b3) =?n\n\u03b3 = {wi,i = 1,...,n} where wi= (wi1,...,wik)\u2032is a separate multi-\nnomial probability vector for each i. The posterior simulation samples\nimmediately provide the optimizing w using equation (5), and the up-\nper bound then follows from equation (6).\ni=1Mn(zi|1,wi) with variational parameters\nL1 is the quasi-optimized lower bound estimate in this case. Using\nthe above optimized variational parameters, the quasi-optimized lower\nbound is estimated by equation (8).\nU2,L2:\nU2is the upper bound estimate in the reduced\u2212(\u03c0,\u00b5) context where\n\u03b8 comprises the \u03a3jand zi. We use variational distribution\nq(\u03b8|\u03b3) = {\nk?\nj=1\nIW(\u03a3j|\u03baj,\u03a8j)}\nn\n?\ni=1\nMn(zi|1,wi)\nwith variational parameter \u03b3 comprised of the set of \u03baj,\u03a8j and wi\nquantities. From the posterior MCMC summaries, the optimizing \u03b3 is\nevaluated using equation (5) and the upper bound follows from equa-\ntion (6).\nL2 is the quasi-optimized lower bound estimate in this case. Using\nthe above optimized variational parameters, the quasi-optimized lower\nbound is estimated by equation (8).\n14"},{"page":15,"text":"U3,L3:\nU3is upper bound estimate in the reduced\u2212\u03c0 context, using vari-\national distribution\nq(\u03b8|\u03b3) = {\nk?\nj=1\nN(\u00b5j|\u03bdj,\u03a9j)IW(\u03a3j|\u03baj,\u03a8j)}\nn\n?\ni=1\nMn(zi|1,wi) (14)\nwith variational parameter \u03b3 comprising all \u03bdj,\u03a9j,\u03baj,\u03a8jand wiquan-\ntities. From the posterior MCMC summaries, the optimizing \u03b3 is evalu-\nated using equation (5) and the upper bound follows from equation (6).\nL3 is the quasi-optimized lower bound estimate in this case. Using\nthe above optimized variational parameters, the quasi-optimized lower\nbound is estimated by equation (8).\nL4: L4is the estimate of lower bound of log marginal likelihood using the\ntraditional variational method (Corduneanu and Bishop, 2001; Wang\nand Titterington, 2004). With variational distribution of equation (14),\noptimal parameters \u03b3 are estimated using the coordinate ascent algo-\nrithm. Samples are then generated from q(\u03b8|\u03b3) at the optimized values\nand used to estimate the lower bound via equation (11).\nThese bounds are evaluated on synthetic data analogous to an example\nin Corduneanu and Bishop (2001): n = 600 data points generated from a\nmixture of five bivariate normals with means [0,0]\u2032, [3,\u22123]\u2032, [3,3]\u2032, [\u22123,3]\u2032,\n[\u22123,\u22123]\u2032and covariance matrices [1,0;0,1], [1,0.5;0.5,1], [1,\u22120.5;\u22120.5,1],\n[1,0.5;0.5,1], [1,\u22120.5;\u22120.5,1]; see Figure 3. We ran 20 repeat simulations\nand report the mean and standard deviations across replicates for each of\nthe bounds in Table 2. Evidently, U1,L1 are more accurate than U2,L2,\nwhich themselves dominate U3,L3. This again shows that marginalizing out\nsome parameters can significantly reduce the spread between the upper\/lower\nbounds, and that the resulting bounds can define accurate estimates of the\nexact but non-computable value \u2013 each pair of upper and lower bounds is\nguaranteed to bracket the true value so that, when the spread is small on\nthe log likelihood scale, they can define practically acceptable values even\nthough they may not be quite the \u201coptimal\u201d bounds. The traditional varia-\ntional method for lower bounds, which can only be applied to the standard\nparameter context, fails to achieve performance as good as either L1or L2;\nas shown in Figure 4 this standard method clearly fails to give anything close\nto a practically useful lower bound in many cases.\n15"},{"page":16,"text":"Table 2: Monte Carlo estimates of bounds in the mixture model example. Table displays the mean and standard\ndeviation over 20 repeat simulations.\nU3\nU2\nU1\n\u22122895.4\n\u00b122.6\u00b121.6\u00b125.5\u00b127.5\n\u22122836.7\n\u00b180.6\u00b138.8\u00b121.1\u00b114.3\n\u22122781.6\n\u00b121.8\u00b121.9\u00b121.1\u00b121.4\n\u22122683.0\n\u00b10.15\u00b10.23\u00b10.09\u00b10.06\n\u22122777.1\n\u00b11.73\u00b11.93\u00b11.57\u00b11.20\n\u22122857.4\n\u00b12.44\u00b12.39\u00b12.31\u00b11.77\n\u22122925.7\n\u00b12.88\u00b13.42\u00b13.31\u00b12.12\n\u22122982.6\n\u00b18.01\u00b18.92\u00b17.23\u00b14.23\n\u22123038.9\n\u00b13.10\u00b14.14\u00b13.98\u00b12.19\nL1\nL2\nL3\nL4\nk=2\n\u22122895.7\u22122901.9\u22122908.9\u22122909.4\n\u00b127.7\n\u22122877.0\n\u00b115.4\n\u22122786.3\n\u00b122.5\n\u22122688.6\n\u00b10.08\n\u22122788.2\n\u00b11.12\n\u22122873.4\n\u00b11.60\n\u22122946.5\n\u00b11.95\n\u22123010.9\n\u00b13.98\n\u22123067.6\n\u00b11.89\n\u22122911.2\n\u00b127.5\n\u22122884.8\n\u00b126.9\n\u22122786.9\n\u00b122.6\n\u22122689.2\n\u00b10.07\n\u22122821.6\n\u00b14.05\n\u22122946.0\n\u00b19.48\n\u22123059.7\n\u00b18.18\n\u22123153.5\n\u00b117.8\n\u22123246.1\n\u00b110.5\n\u22122910.2\n\u00b127.3\n\u22122884.2\n\u00b124.8\n\u22122787.2\n\u00b122.6\n\u22122689.2\n\u00b10.08\n\u22122822.2\n\u00b14.58\n\u22122945.7\n\u00b18.68\n\u22123058.5\n\u00b18.41\n\u22123151.9\n\u00b117.1\n\u22123243.8\n\u00b110.4\nk=3\n\u22122848.3\u22122859.8\u22122863.4\nk=4\n\u22122782.3\u22122784.1\u22122785.1\nk=5\n\u22122683.8\u22122686.0\u22122687.2\nk=6\n\u22122779.5\u22122782.5\u22122785.4\nk=7\n\u22122860.5\u22122863.7\u22122869.4\nk=8\n\u22122931.3\u22122934.4\u22122941.2\nk=9\n\u22122990.9\u22122993.7\u22123002.7\nk=10\n\u22123049.0\u22123052.3\u22123060.5\n16"},{"page":17,"text":"\u22126 \u22124\u221220\nx1\n246\n\u22126\n\u22124\n\u22122\n0\n2\n4\n6\n8\nx2\nFigure 3: One sample of 600 data points sampled from the mixture of 5 bivariate\nGaussians.\n5. Discussion\nThe new approach to defining both upper and lower bounds for log\nmarginal likelihoods extends the prior, standard approach using variational\nmethods in several ways, and the examples show the major benefit and prac-\ntical utility. First, the utility of our approach to evaluation of optimized\nupper bounds to couple with lower bounds is obvious. Having bounds that\n\u201cbracket\u201d the true value, even though the bounds may not be absolutely\noptimized, provides opportunity to clearly assess practical adequacy of the\nbounds based on the spread between upper and lower values. If the spread\nis tight on the log likelihood scale, we can be comfortable with the bound\nvalues as defining practically useful estimates. On the other hand, a large\nspread will indicate that the chosen class of variational densities does not\nprovide a satisfactory approximation to the posterior. Second, the novel\nquasi-optimized lower bound, that uses the same variational parameters as\nour optimized upper bound, can in many cases define practically satisfactory\nlower bounds at minimal computational costs relative to the formally opti-\nmized value. Third, it is evident that our methods apply to models in which\n17"},{"page":18,"text":"234\nNumber of mixture components\n56789 10\n\u22123300\n\u22123200\n\u22123100\n\u22123000\n\u22122900\n\u22122800\n\u22122700\n\u22122600\nLog marginal likelihood\n \n \nUpper bound: U1\nQuasi\u2212optimized lower bound: L1\nVariational method lower bound: L4\nFigure 4: Plot of log marginal likelihood bounds U1,L1, in the mixture model\nexample; the model was fitted at each different value of k indicated, and the bound\ncomputations repeated across 20 replicate samples; the average bound values across\nthese samples are plotted. For comparison, the lower bound L4estimated by the\nvariational method is also shown.\n18"},{"page":19,"text":"we can marginalize with respect to a subset of the model parameters and\nlatent variables, and this can be expected to reduce the bound spread and\nhence improve accuracy, often very substantially.\nIn all cases the tightness of the spread between upper and lower bounds\nis essentially determined by how good an approximation q(\u03b8|\u03b3) is to p(\u03b8|D).\nWe have an effective and efficient method for computing and optimizing the\nupper bound; though we can compute and optimize lower bounds similarly\nusing our new MCSA approach, the computations are intensive compared to\nthe upper bound analysis, and hence the quasi-optimized lower bound idea\nbecomes attractive. More research is needed to theoretically understand this\nuse of upper and lower bounds based on the variational parameter computed\non the upper bound. We have performed simulation studies in several model\nclasses that show that the quasi-optimized lower bound variational parame-\nters are often very close to the optimal values, so expect this to be productive.\nFinally, we note additional examples in more complex settings are developed\nin Shen and West (2010) and Merl et al. (2010), based on original studies in\nShen (2007). Those studies use our methods in problems where \u03b8 includes\nthousands of binary variables, so the inherent dimension is very high. Shen\nand West (2010) also explore comparisons with other methods in restricted\nexamples where other methods can be applied, and bear out the results of\nour examples here in demonstrating the utility of our strategy and specific\nalgorithms for evaluation of upper and lower bounds on marginal likelihoods.\nAcknowledgements\nThis work was performed while the first two authors were PhD students\nin the Department of Statistical Science at Duke University. We acknowledge\nsupport of the NSF (grant DMS-0342172) and NIH (grant U54-CA-112952).\nAny opinions, findings and conclusions or recommendations expressed in this\nwork are those of the authors and do not necessarily reflect the views of the\nNSF or NIH.\n19"},{"page":20,"text":"References\nBeal, M., 2003. Variational algorithms for approximate Bayesian inference.\nPh.D. thesis. Gatsby Computational Neuroscience Unit, University College\nLondon.\nBlei, D., Jordan, M., 2004. Variational inference for Dirichlet process mix-\ntures. Bayesian Analysis 1, 121\u2013144.\nCeleux, G., Diebolt, J., 1992. A stochastic approximation type EM algorithm\nfor the mixture problem. Stochastics and Stochastics Reports 41, 127\u2013146.\nChan, C., Feng, F., West, M., Kepler, T., 2008. Statistical mixture modelling\nfor cell subtype identification in flow cytometry. Cytometry, A 73, 693\u2013701.\nChib, S., 1995. Marginal likelihood from the Gibbs output. Journal of the\nAmerican Statistical Association 90, 1313\u20131321.\nCorduneanu, A., Bishop, C., 2001. Variational Bayesian model selection for\nmixture distributions, in: Richardson, T., Jaakkola, T. (Eds.), Proceedings\nEighth International Conference on Artificial Intelligence and Statistics,\nMorgan Kaufmann. pp. 27\u201334.\nDelyon, B., Lavielle, M., Moulines, E., 1999. Convergence of a stochastic\napproximation version of the EM algorithm. The Annals of Statistics 27,\n94\u2013128.\nGhahramani, Z., Beal, M., 2001. Propagation algorithms for variational\nBayesian learning, in: Leen, T., Dietterich, T., Tresp, V. (Eds.), Advances\nin Neural Information Processing Systems. MIT Press. volume 13, pp.\n507\u2013513.\nHumphreys, K., Titterington, D., 2000. Approximate Bayesian inference\nfor simple mixtures, in: Proceedings in Computational Statistics, COMP-\nSTAT\u20192000. Springer-Verlag.\nJaakkola, T., Jordan, M., 2000. Bayesian parameter estimation via varia-\ntional methods. Statistics and Computing 10, 25\u201337.\nJi, C., 2009. Advances in Bayesian modelling and computation: Spatio-\ntemporal processes, model assessment and adaptive MCMC.\nhttp:\/\/\n20"},{"page":21,"text":"stat.duke.edu\/people\/theses\/ChunlinJi.html. Ph.D. thesis, Depart-\nment of Statistical Science, Duke University.\nJordan, M., 2004. Graphical models. Statistical Science 19, 140\u201315.\nJordan, M., Ghahramani, Z., Jaakkola, T., Saul, K., 1999. An introduction to\nvariational methods for graphical models. Machine Learning 37, 183\u2013233.\nKushner, H.J., Yin, G.G., 1997. Stochastic Approximation Algorithms and\nApplications. Springer-Verlag, New York.\nLavine, M., West, M., 1992. A Bayesian method for classification and dis-\ncrimination. Canadian Journal of Statistics 20, 451\u2013461.\nMacKay, D., 1995.\nnetworks ensemble learning, in: Neural Networks: Artificial Intelligence\nand Industrial Applications. Proceedings of the 3rd Annual Symposium\non Neural Networks, Nijmegen, Netherlands. pp. 191\u2013198.\nDevelopments in probabilistic modelling with neural\nMerl, D., Lucas, J., Nevins, J., Shen, H., West, M., 2010. Trans-study\nprojection of genomic biomarkers using sparse factor regression models,\nin: O\u00b4Hagan, A., West, M. (Eds.), The Handbook of Applied Bayesian\nAnalysis. Oxford University Press, pp. 118\u2013154.\nRobbins, H., Monro, S., 1951. A stochastic approximation method. Annals\nof Mathematical Statstics 22, 400\u2013407.\nShen, H., 2007. Bayesian analysis in cancer pathway studies and probabilis-\ntic pathway annotation. http:\/\/stat.duke.edu\/people\/theses\/ShenH.\nhtml. Ph.D. thesis, Department of Statistical Science, Duke University.\nShen, H., West, M., 2010. Bayesian modelling for biological pathway anno-\ntation of gene expression pathway signatures, in: Chen, M.H., Dey, D.,\nM\u00a8 uller, P., Sun, D., Ye, K. (Eds.), Frontiers of Statistical Decision Making\nand Bayesian Analysis. New York: Springer-Verlag.\nUeda, N., Ghahramani, Z., 2002. Bayesian model search for mixture models\nbased on optimizing variational bounds. Neural Networks 15, 1223\u20131241.\nWang, B., Titterington, D., 2004. Convergence and asymptotic normality\nof variational Bayesian approximations for exponential family models with\n21"},{"page":22,"text":"missing values, in: Chickering, M., Halpern, J. (Eds.), Proceedings of the\n20th Conference in Uncertainty in Artificial Intelligence, pp. 577\u2013584.\nXing, E., Jordan, M., Russell, S., 2003. A generalized mean field algorithm\nfor variational inference in exponential families, in: Meek, C., Kjerulff, U.\n(Eds.), Proceedings of the 19th Annual Conference on Uncertainty in AI,\nMorgan Kaufmann Publishers. pp. 583\u2013591.\n22"}],"widgetId":"rgw26_56ab1c1ddcb57"},"id":"rgw26_56ab1c1ddcb57","partials":[],"templateName":"publicliterature\/stubs\/PublicationText.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationText.html?publicationUid=228914332&hide=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationDetailAd":{"data":{"googleDfpSlot":null,"widgetId":"rgw27_56ab1c1ddcb57"},"id":"rgw27_56ab1c1ddcb57","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAd.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAd.html?publicationUid=228914332&slotId=336x280_Publications_ATF_Right&collapseSlotMode=never&fallbackContainerEnabled=1","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationRelations":null,"publicationRelationsReverse":null,"publicationUid":228914332,"showSignUpDialog":false,"selectNewSignUpDialog":false,"publicationQuestions":null,"publicationCitations":{"data":{"publicationUid":228914332,"publicationCitationsList":{"data":{"citationItems":[{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore","clickThrough":"experimentMilestoneClickedToPublicationFromCitationWithSlurp","clickThroughWithContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextSlurp","nextPublicationViewId":null,"authorsPartOne":[{"id":2067864256,"url":"researcher\/2067864256_Linda_S_L_Tan","fullname":"Linda S. L. Tan","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":8484000,"url":"researcher\/8484000_David_J_Nott","fullname":"David J. Nott","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":[["includes-citation-list"]],"isFulltext":false,"isSlurp":true,"isNoText":false,"publicationType":"Article","publicationDate":"Aug 2012","journal":null,"showEnrichedPublicationItem":false,"citationCount":5,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/230732835_A_Stochastic_Variational_Framework_for_Fitting_and_Diagnosing_Generalized_Linear_Mixed_Models","usePlainButton":true,"publicationUid":230732835,"feedStubs":null,"hasFeedStubs":false,"impactPoints":false,"url":"publication\/230732835_A_Stochastic_Variational_Framework_for_Fitting_and_Diagnosing_Generalized_Linear_Mixed_Models","title":"A Stochastic Variational Framework for Fitting and Diagnosing Generalized Linear Mixed Models","displayTitleAsLink":true,"authors":[{"id":2067864256,"url":"researcher\/2067864256_Linda_S_L_Tan","fullname":"Linda S. L. Tan","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":8484000,"url":"researcher\/8484000_David_J_Nott","fullname":"David J. Nott","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["08\/2012; 9(4). DOI:10.1214\/14-BA885"],"abstract":"In stochastic variational inference, the variational Bayes objective function\nis optimized using stochastic gradient approximation, where gradients computed\non small random subsets of data are used to approximate the true gradient over\nthe whole data set. This enables complex models to be fit to large data sets as\ndata can be processed in mini-batches. In this article, we extend stochastic\nvariational inference for conjugate-exponential models to nonconjugate models\nand present a stochastic nonconjugate variational message passing algorithm for\nfitting generalized linear mixed models that is scalable to large data sets. In\naddition, we show that diagnostics for prior-likelihood conflict, which are\nuseful for Bayesian model criticism, can be obtained from nonconjugate\nvariational message passing automatically, as an alternative to\nsimulation-based Markov chain Monte Carlo methods. Finally, we demonstrate that\nfor moderate-sized data sets, convergence can be accelerated by using the\nstochastic version of nonconjugate variational message passing in the initial\nstage of optimization before switching to the standard version.","description":false,"swapJournalAndAuthorPositions":false,"showAbstract":true,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/230732835_A_Stochastic_Variational_Framework_for_Fitting_and_Diagnosing_Generalized_Linear_Mixed_Models","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":false,"actions":[{"type":"request-external","text":"Request full-text","url":"javascript:;","active":false,"primary":false,"extraClass":null,"icon":null,"data":[{"key":"context","value":"pubCit"}]}],"actionWidgets":[],"publicationItemFulltext":{"data":{"isDataset":false,"isResearch":false,"isFulltext":true,"source":{"isPreview":true,"sourceUrl":"deref\/http%3A%2F%2Farxiv.org%2Fpdf%2F1208.4949","sourceName":"arxiv.org","hasSourceUrl":true},"publicationUid":230732835,"publicationUrl":"publication\/230732835_A_Stochastic_Variational_Framework_for_Fitting_and_Diagnosing_Generalized_Linear_Mixed_Models","eventCode":"","citationCount":0,"additionalContentWidgets":[],"disableViewer":true,"showLoggedOutRequestButton":false,"context":null,"previewUrl":"https:\/\/i1.rgstatic.net\/publication\/230732835_A_Stochastic_Variational_Framework_for_Fitting_and_Diagnosing_Generalized_Linear_Mixed_Models\/links\/02b190b30cf2b0632955ab00\/smallpreview.png","linkId":"02b190b30cf2b0632955ab00","origin":"publication_list","showRequestCount":false,"publish":false,"request":false,"showAction":false,"displayAsLink":true,"documentViewerUrl":"publicliterature.PublicLiteratureDocumentViewer.html?publicationId=230732835&reference=02b190b30cf2b0632955ab00&eventCode=&origin=publication_list","widgetId":"rgw31_56ab1c1ddcb57"},"id":"rgw31_56ab1c1ddcb57","partials":[],"templateName":"publicliterature\/stubs\/PublicationItemFulltext.html","templateExtensions":["generalHelpers"],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItemFulltext.html?publicationUid=230732835&showAction=1&eventCode=&hideSource=0&displayAsLink=1&showPublishAsSelectFile=0","viewClass":"views.publicliterature.PublicationItemFulltextView","yuiModules":["rg.views.publicliterature.PublicationItemFulltextView"],"stylesheets":[],"_isYUI":true},"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":true,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":228914332,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/230732835_A_Stochastic_Variational_Framework_for_Fitting_and_Diagnosing_Generalized_Linear_Mixed_Models\/review","additionalRightSideTopWidgets":[{"data":{"citationContexts":["Paisley et al. (2012) proposed a stochastic optimization algorithm using control variates that allows direct maximization of the variational lower bound involving intractable integrals. Similar algorithms were considered by Ji et al. (2010) and Nott et al. (2012). Hoffman et al. (2010) and Wang et al. (2011) developed online VB algorithms for latent Dirichlet allocation and the hierarchical Dirichlet process respectively using stochastic natural gradient optimization of the variational lower bound. "],"widgetId":"rgw32_56ab1c1ddcb57"},"id":"rgw32_56ab1c1ddcb57","partials":[],"templateName":"publicliterature\/stubs\/PublicationItemCitationContexts.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItemCitationContexts.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":true,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw30_56ab1c1ddcb57"},"id":"rgw30_56ab1c1ddcb57","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":true,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItem.html?showEnrichedPublicationItem=0&showRequestButton=1&publicationUid=230732835&additionalCssClasses%5B0%5D=includes-citation-list&citationContextItemVersion=old&isIncomingCitation=1","viewClass":"views.publicliterature.PublicationItemView","yuiModules":["rg.views.publicliterature.PublicationItemView"],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore","clickThrough":"experimentMilestoneClickedToPublicationFromCitationWithNoFulltext","clickThroughWithContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":69893771,"url":"researcher\/69893771_Junseok_Kwon","fullname":"Junseok Kwon","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":7868586,"url":"researcher\/7868586_Kyoung_Mu_Lee","fullname":"Kyoung Mu Lee","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":[[]],"isFulltext":false,"isSlurp":false,"isNoText":true,"publicationType":"Conference Paper","publicationDate":"Jun 2013","journal":null,"showEnrichedPublicationItem":false,"citationCount":5,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/261248409_Minimum_Uncertainty_Gap_for_Robust_Visual_Tracking","usePlainButton":true,"publicationUid":261248409,"feedStubs":null,"hasFeedStubs":false,"impactPoints":false,"url":"publication\/261248409_Minimum_Uncertainty_Gap_for_Robust_Visual_Tracking","title":"Minimum Uncertainty Gap for Robust Visual Tracking","displayTitleAsLink":true,"authors":[{"id":69893771,"url":"researcher\/69893771_Junseok_Kwon","fullname":"Junseok Kwon","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":7868586,"url":"researcher\/7868586_Kyoung_Mu_Lee","fullname":"Kyoung Mu Lee","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["Computer Vision and Pattern Recognition (CVPR), 2013 IEEE Conference on; 06\/2013"],"abstract":"We propose a novel tracking algorithm that robustly tracks the target by finding the state which minimizes uncertainty of the likelihood at current state. The uncertainty of the likelihood is estimated by obtaining the gap between the lower and upper bounds of the likelihood. By minimizing the gap between the two bounds, our method finds the confident and reliable state of the target. In the paper, the state that gives the Minimum Uncertainty Gap (MUG) between likelihood bounds is shown to be more reliable than the state which gives the maximum likelihood only, especially when there are severe illumination changes, occlusions, and pose variations. A rigorous derivation of the lower and upper bounds of the likelihood for the visual tracking problem is provided to address this issue. Additionally, an efficient inference algorithm using Interacting Markov Chain Monte Carlo is presented to find the best state that maximizes the average of the lower and upper bounds of the likelihood and minimizes the gap between two bounds simultaneously. Experimental results demonstrate that our method successfully tracks the target in realistic videos and outperforms conventional tracking methods.","description":false,"swapJournalAndAuthorPositions":false,"showAbstract":true,"type":"Conference Paper","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/261248409_Minimum_Uncertainty_Gap_for_Robust_Visual_Tracking","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":false,"actions":[{"type":"request-external","text":"Request full-text","url":"javascript:;","active":false,"primary":false,"extraClass":null,"icon":null,"data":[{"key":"context","value":"pubCit"}]}],"actionWidgets":[],"publicationItemFulltext":{"data":{"isDataset":false,"isResearch":false,"isFulltext":true,"source":null,"publicationUid":261248409,"publicationUrl":"publication\/261248409_Minimum_Uncertainty_Gap_for_Robust_Visual_Tracking","eventCode":"","citationCount":0,"additionalContentWidgets":[],"disableViewer":true,"showLoggedOutRequestButton":false,"context":null,"showRequestCount":false,"publish":false,"request":false,"showAction":false,"displayAsLink":true,"documentViewerUrl":"publicliterature.PublicLiteratureDocumentViewer.html?publicationId=261248409&eventCode=","widgetId":"rgw34_56ab1c1ddcb57"},"id":"rgw34_56ab1c1ddcb57","partials":[],"templateName":"publicliterature\/stubs\/PublicationItemFulltext.html","templateExtensions":["generalHelpers"],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItemFulltext.html?publicationUid=261248409&showAction=1&eventCode=&hideSource=0&displayAsLink=1&showPublishAsSelectFile=0","viewClass":"views.publicliterature.PublicationItemFulltextView","yuiModules":["rg.views.publicliterature.PublicationItemFulltextView"],"stylesheets":[],"_isYUI":true},"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":true,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":228914332,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/261248409_Minimum_Uncertainty_Gap_for_Robust_Visual_Tracking\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":true,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw33_56ab1c1ddcb57"},"id":"rgw33_56ab1c1ddcb57","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItem.html?showEnrichedPublicationItem=0&showRequestButton=1&publicationUid=261248409&citationContextItemVersion=old&isIncomingCitation=1","viewClass":"views.publicliterature.PublicationItemView","yuiModules":["rg.views.publicliterature.PublicationItemView"],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore","clickThrough":"experimentMilestoneClickedToPublicationFromCitationWithFulltext","clickThroughWithContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextSlurp","nextPublicationViewId":null,"authorsPartOne":[{"id":2076919269,"url":"researcher\/2076919269_Amar_Shah","fullname":"Amar Shah","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":54244192,"url":"researcher\/54244192_David_A_Knowles","fullname":"David A. Knowles","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":8159937,"url":"researcher\/8159937_Zoubin_Ghahramani","fullname":"Zoubin Ghahramani","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":[[]],"isFulltext":true,"isSlurp":false,"isNoText":false,"publicationType":"Article","publicationDate":"Jun 2015","journal":null,"showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/279309917_An_Empirical_Study_of_Stochastic_Variational_Algorithms_for_the_Beta_Bernoulli_Process","usePlainButton":true,"publicationUid":279309917,"feedStubs":null,"hasFeedStubs":false,"impactPoints":false,"url":"publication\/279309917_An_Empirical_Study_of_Stochastic_Variational_Algorithms_for_the_Beta_Bernoulli_Process","title":"An Empirical Study of Stochastic Variational Algorithms for the Beta Bernoulli Process","displayTitleAsLink":true,"authors":[{"id":2076919269,"url":"researcher\/2076919269_Amar_Shah","fullname":"Amar Shah","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":54244192,"url":"researcher\/54244192_David_A_Knowles","fullname":"David A. Knowles","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":8159937,"url":"researcher\/8159937_Zoubin_Ghahramani","fullname":"Zoubin Ghahramani","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":[],"abstract":"Stochastic variational inference (SVI) is emerging as the most promising\ncandidate for scaling inference in Bayesian probabilistic models to large\ndatasets. However, the performance of these methods has been assessed primarily\nin the context of Bayesian topic models, particularly latent Dirichlet\nallocation (LDA). Deriving several new algorithms, and using synthetic, image\nand genomic datasets, we investigate whether the understanding gleaned from LDA\napplies in the setting of sparse latent factor models, specifically beta\nprocess factor analysis (BPFA). We demonstrate that the big picture is\nconsistent: using Gibbs sampling within SVI to maintain certain posterior\ndependencies is extremely effective. However, we find that different posterior\ndependencies are important in BPFA relative to LDA. Particularly,\napproximations able to model intra-local variable dependence perform best.","description":false,"swapJournalAndAuthorPositions":false,"showAbstract":true,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/279309917_An_Empirical_Study_of_Stochastic_Variational_Algorithms_for_the_Beta_Bernoulli_Process","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":true,"actions":[{"type":"download","text":"Download","url":"profile\/David_Knowles2\/publication\/279309917_An_Empirical_Study_of_Stochastic_Variational_Algorithms_for_the_Beta_Bernoulli_Process\/links\/55a53c7b08aef604aa042e0b.pdf?origin=publication_list","active":false,"primary":true,"extraClass":"open-viewer","icon":null,"data":[]}],"actionWidgets":[],"publicationItemFulltext":{"data":{"isDataset":false,"isResearch":false,"isFulltext":true,"source":{"isPreview":false,"sourceUrl":"profile\/David_Knowles2","sourceName":"David A. Knowles","hasSourceUrl":true},"publicationUid":279309917,"publicationUrl":"publication\/279309917_An_Empirical_Study_of_Stochastic_Variational_Algorithms_for_the_Beta_Bernoulli_Process","eventCode":"","citationCount":0,"additionalContentWidgets":[],"disableViewer":true,"showLoggedOutRequestButton":false,"context":null,"previewUrl":"https:\/\/i1.rgstatic.net\/publication\/279309917_An_Empirical_Study_of_Stochastic_Variational_Algorithms_for_the_Beta_Bernoulli_Process\/links\/55a53c7b08aef604aa042e0b\/smallpreview.png","linkId":"55a53c7b08aef604aa042e0b","origin":"publication_list","showRequestCount":false,"publish":false,"request":false,"showAction":false,"displayAsLink":true,"documentViewerUrl":"publicliterature.PublicLiteratureDocumentViewer.html?publicationId=279309917&reference=55a53c7b08aef604aa042e0b&eventCode=&origin=publication_list","widgetId":"rgw36_56ab1c1ddcb57"},"id":"rgw36_56ab1c1ddcb57","partials":[],"templateName":"publicliterature\/stubs\/PublicationItemFulltext.html","templateExtensions":["generalHelpers"],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItemFulltext.html?publicationUid=279309917&showAction=1&eventCode=&hideSource=0&displayAsLink=1&showPublishAsSelectFile=0","viewClass":"views.publicliterature.PublicationItemFulltextView","yuiModules":["rg.views.publicliterature.PublicationItemFulltextView"],"stylesheets":[],"_isYUI":true},"linkId":"55a53c7b08aef604aa042e0b","context":null,"contextId":null,"eventCode":"","isCitation":true,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":228914332,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/279309917_An_Empirical_Study_of_Stochastic_Variational_Algorithms_for_the_Beta_Bernoulli_Process\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":true,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read full-text","widgetId":"rgw35_56ab1c1ddcb57"},"id":"rgw35_56ab1c1ddcb57","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":true,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItem.html?showEnrichedPublicationItem=0&showRequestButton=1&publicationUid=279309917&citationContextItemVersion=old&isIncomingCitation=1","viewClass":"views.publicliterature.PublicationItemView","yuiModules":["rg.views.publicliterature.PublicationItemView"],"stylesheets":[],"_isYUI":true}],"hasCitations":true,"isPublicationAuthor":false,"isPublicationVisitor":false,"publicationUid":228914332,"publicationLink":"publication\/228914332_Bounded_Approximations_for_Marginal_Likelihoods","hasShowMore":false,"newOffset":3,"pageSize":10,"widgetId":"rgw29_56ab1c1ddcb57"},"id":"rgw29_56ab1c1ddcb57","partials":[],"templateName":"publicliterature\/stubs\/PublicationIncomingCitationsList.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationIncomingCitationsList.html?publicationUid=228914332&citedInPage=1&swapJournalAndAuthorPositions=0&showAbstract=1&showType=1&showPublicationPreview=1&totalCount=3","viewClass":"views.publicliterature.PublicationIncomingCitationsListView","yuiModules":["rg.views.publicliterature.PublicationIncomingCitationsListView"],"stylesheets":[],"_isYUI":true},"hasCitations":false,"citationsCount":0,"hasIncomingCitations":true,"incomingCitationsCount":3,"showCitationsSorter":true,"showAbstract":true,"showType":true,"showPublicationPreview":true,"swapJournalAndAuthorPositions":false,"sort":"","sortOriginal":false,"citationList":"incoming","showsIncoming":true,"showSorting":false,"usePlainButton":null,"useEnrichedContext":null,"widgetId":"rgw28_56ab1c1ddcb57"},"id":"rgw28_56ab1c1ddcb57","partials":[],"templateName":"publicliterature\/stubs\/PublicationCitations.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationCitations.html?publicationUid=228914332&citationList=&citedInPage=1&sort=","viewClass":"views.publicliterature.PublicationCitationsView","yuiModules":["rg.views.publicliterature.PublicationCitationsView"],"stylesheets":[],"_isYUI":true},"publicationReviewPromo":null,"publicationUsedInReviews":null,"publicationPdfJsReader":null,"useFulltextOptimizedLayout":false,"publicationActions":null,"requestFulltextPromo":null,"currentUrl":"publication\/228914332_Bounded_Approximations_for_Marginal_Likelihoods","isLeaderboardAd":false,"enableStickyBox":null,"googleDfpSlotMobileBottom":null,"fullTextExitPopup":null,"showExitPopupDialog":false,"widgetId":"rgw2_56ab1c1ddcb57"},"id":"rgw2_56ab1c1ddcb57","partials":{"romeo_legal_notice":"publicliterature\/stubs\/partials\/romeo_legal_notice.html"},"templateName":"publicliterature\/stubs\/PublicPublicationDetails_NewLayout.html","templateExtensions":["generalHelpers"],"attrs":{"publicationUid":228914332},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicPublicationDetailsOld.html?publicationUid=228914332&isTestOldDesign=0","viewClass":"views.publicliterature.PublicPublicationDetailsOldView","yuiModules":["rg.views.publicliterature.PublicPublicationDetailsOldView"],"stylesheets":[],"_isYUI":true},"widgetId":"rgw1_56ab1c1ddcb57"},"id":"rgw1_56ab1c1ddcb57","partials":[],"templateName":"publicliterature\/stubs\/PublicPublicationDetails.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicPublicationDetails.html","viewClass":"views.publicliterature.PublicPublicationDetailsView","yuiModules":["rg.views.publicliterature.PublicPublicationDetailsView"],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"uaClass":"","headPrefix":[],"rootUrl":"https:\/\/www.researchgate.net\/","requestToken":"ihnvWS1JrZ8bHKyviXsBhA5ZTtgc6doIm4QpcfU\/zjH6A2OTiN+\/rd1e1uUmPfMG\/gTkfGPLcDmBWOLE1W2CAm9UVsn0h3DaBpC1h4kIr6FExg7InazqWbFmuQ6pQ+fz+1aYQ0rrGaEsXNQQoEMtZe+8pFH7BAqz2LVVNtp5zBMYZDd4Wr+KBjBs+N3inRo9XlKhvMDilC6H6t2z1Z\/oo078xWo0EEZDFiM54DWdG\/J2a6mSMcJ7Qa2Sj1nHnQ4yD8q8seDILREnhSek3mbAAa44vRG0pKZtcMr4HWFX9cA=","faviconCdnUrl":"https:\/\/c5.rgstatic.net\/m\/2390829798215018\/images\/favicon.ico","headerOutput":"<noscript><\/noscript><link rel=\"canonical\" href=\"https:\/\/www.researchgate.net\/publication\/228914332_Bounded_Approximations_for_Marginal_Likelihoods\" \/>\n<link rel=\"dns-prefetch\" href=\"\/\/c5.rgstatic.net\" \/>\n<link rel=\"dns-prefetch\" href=\"\/\/i1.rgstatic.net\" \/>\n<meta property=\"twitter:card\" content=\"summary\" \/>\n<meta property=\"twitter:site\" content=\"@ResearchGate\" \/>\n<meta property=\"og:title\" content=\"Bounded Approximations for Marginal Likelihoods\" \/>\n<meta property=\"og:description\" content=\"We discuss novel approaches to evaluation of both upper and lower bounds on log marginal likelihoods for model comparison in Bayesian analysis. From posterior Monte Carlo samples, we show how...\" \/>\n<meta property=\"og:site_name\" content=\"ResearchGate\" \/>\n<meta property=\"og:image\" content=\"https:\/\/i1.rgstatic.net\/publication\/228914332_Bounded_Approximations_for_Marginal_Likelihoods\/links\/000495e90cf2ed98fb440b17\/smallpreview.png\" \/>\n<meta property=\"og:url\" content=\"https:\/\/www.researchgate.net\/publication\/228914332_Bounded_Approximations_for_Marginal_Likelihoods\" \/>\n<meta property=\"rg:id\" content=\"PB:228914332\" \/>\n<meta name=\"DC.identifier\" scheme=\"DCTERMS.URI\" content=\"http:\/\/dx.doi.org\/\" \/>\n<meta name=\"gs_meta_revision\" content=\"1.1\" \/>\n<meta name=\"citation_title\" content=\"Bounded Approximations for Marginal Likelihoods\" \/>\n<meta name=\"citation_author\" content=\"Chunlin Ji\" \/>\n<meta name=\"citation_author\" content=\"Haige Shen\" \/>\n<meta name=\"citation_author\" content=\"Mike West\" \/>\n<meta name=\"citation_publication_date\" content=\"2010\/01\/01\" \/>\n<meta name=\"citation_abstract_html_url\" content=\"https:\/\/www.researchgate.net\/publication\/228914332_Bounded_Approximations_for_Marginal_Likelihoods\" \/>\n<meta name=\"citation_fulltext_html_url\" content=\"https:\/\/www.researchgate.net\/publication\/228914332_Bounded_Approximations_for_Marginal_Likelihoods\" \/>\n<meta name=\"viewport\" content=\"width=device-width,initial-scale=1\" \/>\n<link href=\"\/\/c5.rgstatic.net\/m\/22664197317151888\/styles\/rg.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/21004998181197492\/styles\/rg2.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<!--[if lt IE 9]><link href=\"\/\/c5.rgstatic.net\/m\/238176252723686\/styles\/ie.css\" type=\"text\/css\" rel=\"stylesheet\"\/><![endif]-->\n<link href=\"\/\/c5.rgstatic.net\/m\/217752362214895\/styles\/modules\/publicprofile.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<script src=\"\/\/c5.rgstatic.net\/m\/2321000301012716\/javascript\/vendor\/webfontloader\/webfontloader.js\" type=\"text\/javascript\"><\/script>\n <script>(function(i,s,o,g,r,a,m){i[\"GoogleAnalyticsObject\"]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,\"script\",\"\/\/www.google-analytics.com\/analytics.js\",\"ga\");\n ga(\"create\",\"UA-58591210-1\");ga(\"set\",\"anonymizeIp\",true);ga('set', 'dimension1', 'publication slurped');ga('set', 'dimension2', 'Article');ga('set', 'dimension3', 'Logged out');ga('set', 'dimension4', 'https');ga(\"send\",\"pageview\");<\/script>\n","webfont":"<noscript><\/noscript><script> WebFontConfig = { custom: { families: ['source_sans_pro_italic', 'source_sans_pro_bold', 'source_sans_pro', 'martel'], urls : ['\/\/c5.rgstatic.net\/m\/231392577336386\/styles\/fonts.css'] } }; WebFont.load(WebFontConfig); <\/script>\n","correlationId":"rgreq-951fede4-6d59-4cd2-bdb0-067fa2066236","accountId":null,"module":"publicliterature","action":"publicliterature.PublicPublicationDetails","page":"publicationDetail","product":"publications","backendTime":710,"continent":"Asia","stylesHome":"\/\/c5.rgstatic.net\/m\/","staticHost":"c5.rgstatic.net","useEarlyFlush":false,"longRunningRequestIdentifier":"LongRunningRequest.publicliterature.PublicPublicationDetails","longRunningRequestFp":"e9e5bbe1366c7ee8c8e41d02f793c884ac9be19b","widgetId":"rgw37_56ab1c1ddcb57"},"id":"rgw37_56ab1c1ddcb57","partials":[],"templateName":"application\/stubs\/StaticHeader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.StaticHeader.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){
            Y.rg.core.pagespeed.Monitoring.monitorPage("\/\/glassmoni.researchgate.net", "publicliterature.PublicPublicationDetails.run.html.loggedOut.get", "59de9668d07aeb77ab4de5f24d382b5d199d2437", "rgreq-951fede4-6d59-4cd2-bdb0-067fa2066236", "36261a69a93c146ad094ddcc5c9d49e2ec38b783");
        
            Y.rg.core.pagespeed.Monitoring.monitorPage("\/\/glassmoni.researchgate.net", "publicationDetail.loggedOut", "ed1993d9e20f6cefa83edacaa24401a18c071aea", "rgreq-951fede4-6d59-4cd2-bdb0-067fa2066236", "36261a69a93c146ad094ddcc5c9d49e2ec38b783");
        })();
(function(){Y.rg.createInitialWidget({"data":{"year":"2016","inlinePromo":null,"isAdmin":false,"contactUrl":"https:\/\/www.researchgate.net\/contact","aboutUsUrl":"https:\/\/www.researchgate.net\/about","widgetId":"rgw38_56ab1c1ddcb57"},"id":"rgw38_56ab1c1ddcb57","partials":[],"templateName":"application\/stubs\/DefaultFooter.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.DefaultFooter.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"headerLogin":{"data":{"urlAfterLogin":"publication\/228914332_Bounded_Approximations_for_Marginal_Likelihoods","requestToken":"NMjF2gk6wBjgks0z8rIWRQOMyQEHuqe34YvNBoIygVnmoGUL3XLLfL7tBZKk5SrVW05Pt\/3IKfu33Vt7T\/koh8z908k8TvDM4mRxe2jm3cx094cp\/FfJba9c\/O8er+QFXWIp5fDQyZNQgg514giYL4DUQrAZQE3DXSvWSAjgR9stNSid38IXeo6LvZzdsp4e9I5zoZ8lIylZvajHMfJB6xtwGPuZgRd0h7o9cCOSo0nTs0kSKi2Zel7QVBUveSZLzAJdi3F5g6AYW8P4lrDAAEBNYAdFN1XKocS8iK46yt0=","loginUrl":"https:\/\/www.researchgate.net\/application.Login.html","signupUrl":"https:\/\/www.researchgate.net\/signup.SignUp.html?ev=su_chnl_index&hdrsu=1&_sg=-_AXte2K6-uCMEPJTrf7R8znTc35FnXLIarjM6_JdFY4g47e913kJUiCkhWI7XBu","encodedUrlAfterLogin":"cHVibGljYXRpb24vMjI4OTE0MzMyX0JvdW5kZWRfQXBwcm94aW1hdGlvbnNfZm9yX01hcmdpbmFsX0xpa2VsaWhvb2Rz","signupCallToAction":"Join for free","widgetId":"rgw40_56ab1c1ddcb57"},"id":"rgw40_56ab1c1ddcb57","partials":{"partial":"application\/stubs\/partials\/headerLoginDefault.html"},"templateName":"application\/stubs\/HeaderLogin.html","templateExtensions":[],"attrs":{"goal":"milestoneHeaderLoginSeen"},"widgetUrl":"https:\/\/www.researchgate.net\/application.HeaderLogin.html","viewClass":"views.application.HeaderLoginView","yuiModules":["rg.views.application.HeaderLoginView"],"stylesheets":[],"_isYUI":true},"cookieConsent":null,"logoSvgSrc":"https:\/\/c5.rgstatic.net\/m\/235107188705592\/images\/template\/brand-header-logo.svg","logoFallbackSrc":"https:\/\/c5.rgstatic.net\/m\/238113351022438\/images\/template\/brand-header-logo.png","widgetId":"rgw39_56ab1c1ddcb57"},"id":"rgw39_56ab1c1ddcb57","partials":{"schemaSocialProfiles":"application\/stubs\/partials\/schemaSocialProfiles.html"},"templateName":"application\/stubs\/HeaderLoggedOut.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.HeaderLoggedOut.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"logEvent":"su_banner","specialCopy":false,"widgetId":"rgw41_56ab1c1ddcb57"},"id":"rgw41_56ab1c1ddcb57","partials":[],"templateName":"application\/stubs\/LoggedOutBanner.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.LoggedOutBanner.html","viewClass":"views.application.LoggedOutBannerView","yuiModules":["rg.views.application.LoggedOutBannerView"],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.core.util.ParameterFilter.filter(["ev","cp","ch","ref","dbw","pli","loginT","uid","claimChannel","enrichId","enrichSource","utm_source","utm_medium","utm_campaign","el","ci"]);})();
});}); } else { throw 'YRG was not loaded when attaching widgets'; }</script><script> dataLayer = [{"pageCategory":"publication slurped","publicationType":"Article","eventCategory":"Publication page"}]; </script> <noscript><iframe src="//www.googletagmanager.com/ns.html?id=GTM-MKVKH7" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-MKVKH7');</script><script>(function(e){function n(n,t,o,a){"use strict";var i=e.document.createElement("link"),r=t||e.document.getElementsByTagName("script")[0],d=e.document.styleSheets;return i.rel="stylesheet",i.href=n,i.media="only x",a&&(i.onload=a),r.parentNode.insertBefore(i,r),i.onloadcssdefined=function(e){for(var t,o=0;d.length>o;o++)d[o].href&&d[o].href.indexOf(n)>-1&&(t=!0);t?e():setTimeout(function(){i.onloadcssdefined(e)})},i.onloadcssdefined(function(){i.media=o||"all"}),i}function t(e,n){e.onload=function(){e.onload=null,n&&n.call(e)},"isApplicationInstalled"in navigator&&"onloadcssdefined"in e&&e.onloadcssdefined(n)}var o=function(a,i){"use strict";if(a&&3===a.length){var r=e.Image,d=!(!document.createElementNS||!document.createElementNS("http://www.w3.org/2000/svg","svg").createSVGRect||!document.implementation.hasFeature("http://www.w3.org/TR/SVG11/feature#Image","1.1")||e.opera&&-1===navigator.userAgent.indexOf("Chrome")||-1!==navigator.userAgent.indexOf("Series40")),c=new r;c.onerror=function(){o.method="png",o.href=a[2],n(a[2])},c.onload=function(){var e=1===c.width&&1===c.height,r=a[e&&d?0:e?1:2];o.method=e&&d?"svg":e?"datapng":"png",o.href=r,t(n(r),i)},c.src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///ywAAAAAAQABAAACAUwAOw==",document.documentElement.className+=" grunticon"}};o.loadCSS=n,o.onloadCSS=t,e.grunticon=o})(this);grunticon(["https://c5.rgstatic.net/c/o1o9o3/styles/icons/_header-ico.svg.css", "https://c5.rgstatic.net/c/o1o9o3/styles/icons/_header-ico.png.css", "https://c5.rgstatic.net/c/o1o9o3/styles/icons/_header-ico.fallback.scss"]);grunticon(["https://c5.rgstatic.net/c/o1o9o3/styles/icons/_admin-ico.svg.css", "https://c5.rgstatic.net/c/o1o9o3/styles/icons/_admin-ico.png.css", "https://c5.rgstatic.net/c/o1o9o3/styles/icons/_admin-ico.fallback.scss"]);grunticon(["https://c5.rgstatic.net/c/o1o9o3/styles/icons/_ico.svg.css", "https://c5.rgstatic.net/c/o1o9o3/styles/icons/_ico.png.css", "https://c5.rgstatic.net/c/o1o9o3/styles/icons/_ico.fallback.scss"]);</script></body>
</html>
