<!DOCTYPE html> <html lang="en" class="" id="rgw39_56ab9e94a3e5b"> <head > <meta charset="utf-8"/> <meta http-equiv="content-type" content="text/html; charset=UTF-8"/> <meta name="Rg-Request-Token" id="Rg-Request-Token" content="yp53KpWy8sHfvYP9vK44mTyKLNalwpX8Fju0FiPbtJ8JPku/uY5K5z/+6Dbe0CgNqsyZBDc2UzMrTWoUDCWU7qIWOCIPb9sk9iUctNpdWVCbdHKD1h41Xns/VUuHNxfMZZNeXfJ6SDMlI1+Cg1OThJbNlcNa/vXfHJncveZXuXFVDnzaJsFQ7IMklkbn0FYQDh6YV7+4k1pnhIHVw5I/76v7nw5GGFQBbOTjr0Rs7mb7GvqRj7CcecyukDtDiL0baTCmyeAw2TYL5qSszuJWEyWJw3iq5ifk510S3efVkDs="/> <meta http-equiv="expires" content="0"/> <link rel="apple-touch-icon" sizes="57x57" href="https://www.researchgate.net/apple-touch-icon-57x57.png"> <link rel="apple-touch-icon" sizes="60x60" href="https://www.researchgate.net/apple-touch-icon-60x60.png"> <link rel="apple-touch-icon" sizes="72x72" href="https://www.researchgate.net/apple-touch-icon-72x72.png"> <link rel="apple-touch-icon" sizes="76x76" href="https://www.researchgate.net/apple-touch-icon-76x76.png"> <link rel="apple-touch-icon" sizes="114x114" href="https://www.researchgate.net/apple-touch-icon-114x114.png"> <link rel="apple-touch-icon" sizes="120x120" href="https://www.researchgate.net/apple-touch-icon-120x120.png"> <link rel="apple-touch-icon" sizes="144x144" href="https://www.researchgate.net/apple-touch-icon-144x144.png"> <link rel="apple-touch-icon" sizes="152x152" href="https://www.researchgate.net/apple-touch-icon-152x152.png"> <link rel="apple-touch-icon" sizes="180x180" href="https://www.researchgate.net/apple-touch-icon-180x180.png"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-32x32.png" sizes="32x32"> <link rel="icon" type="image/png" href="https://www.researchgate.net/android-chrome-192x192.png" sizes="192x192"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-96x96.png" sizes="96x96"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-16x16.png" sizes="16x16"> <link rel="shortcut icon" type="image/x-icon" href="https://c5.rgstatic.net/m/2390829798215018/images/favicon.ico"/> <link rel="manifest" href="https://www.researchgate.net/manifest.json"> <meta name="msapplication-TileColor" content="#da532c"> <meta name="msapplication-TileImage" content="https://www.researchgate.net/mstile-144x144.png"> <meta name="theme-color" content="#444444"> <link rel="search" type="application/opensearchdescription+xml" title="ResearchGate search" href="https://www.researchgate.net/application.DownloadOpenSearchPlugin.html"/> <link rel="meta" type="application/rdf+xml" title="ICRA labels" href="https://www.researchgate.net/application.DownloadLabels.html"/> <link rel="http://oexchange.org/spec/0.8/rel/related-target" type="application/xrd+xml" href="https://www.researchgate.net/application.DownloadOExchange.html"/> <base href="https://www.researchgate.net/"/> <script>
    var rgConfig = {
        correlationId: "rgreq-b098bda4-4e74-4587-8fdd-8e78734b0d43",
        accountId: "",
        module: "publicliterature",
        action: "publicliterature.PublicPublicationDetails",
        page: "publicationDetail",
        product: "publications",
        continent: "Asia",
        stylesHome: "//c5.rgstatic.net/m/",
        staticHost: "c5.rgstatic.net",
        longRunningRequestIdentifier: "LongRunningRequest.publicliterature.PublicPublicationDetails",
        longRunningRequestFp: "e9e5bbe1366c7ee8c8e41d02f793c884ac9be19b"
    };
    window.rootUrl = "https://www.researchgate.net/";
</script> <link rel="canonical" href="https://www.researchgate.net/publication/220286498_Slice_sampling_mixture_models" />
<link rel="dns-prefetch" href="//c5.rgstatic.net" />
<link rel="dns-prefetch" href="//i1.rgstatic.net" />
<meta property="twitter:card" content="summary" />
<meta property="twitter:site" content="@ResearchGate" />
<meta property="og:title" content="Slice sampling mixture models" />
<meta property="og:description" content="We propose a more efficient version of the slice sampler for Dirichlet process mixture models described by Walker (Commun.
Stat., Simul. Comput. 36:45–54, 2007). This new sampler allows for the..." />
<meta property="og:site_name" content="ResearchGate" />
<meta property="og:image" content="https://i1.rgstatic.net/publication/220286498_Slice_sampling_mixture_models/links/00b7d51a4630de552f000000/smallpreview.png" />
<meta property="og:url" content="https://www.researchgate.net/publication/220286498_Slice_sampling_mixture_models" />
<meta property="rg:id" content="PB:220286498" />
<meta name="DC.identifier" scheme="DCTERMS.URI" content="http://dx.doi.org/10.1007/s11222-009-9150-y" />
<meta name="gs_meta_revision" content="1.1" />
<meta name="citation_title" content="Slice sampling mixture models" />
<meta name="citation_author" content="Maria Kalli" />
<meta name="citation_author" content="Jim E. Griffin" />
<meta name="citation_author" content="Stephen G. Walker" />
<meta name="citation_publication_date" content="2011/01/01" />
<meta name="citation_journal_title" content="Statistics and Computing" />
<meta name="citation_issn" content="0960-3174" />
<meta name="citation_volume" content="21" />
<meta name="citation_issue" content="1" />
<meta name="citation_firstpage" content="93" />
<meta name="citation_lastpage" content="105" />
<meta name="citation_doi" content="10.1007/s11222-009-9150-y" />
<meta name="citation_pdf_url" content="https://www.researchgate.net/profile/Jim_Griffin2/publication/220286498_Slice_sampling_mixture_models/links/00b7d51a4630de552f000000.pdf" />
<meta name="citation_abstract_html_url" content="https://www.researchgate.net/publication/220286498_Slice_sampling_mixture_models" />
<meta name="citation_fulltext_html_url" content="https://www.researchgate.net/publication/220286498_Slice_sampling_mixture_models" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<link href="//c5.rgstatic.net/m/22664197317151888/styles/rg.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/21004998181197492/styles/rg2.css" type="text/css" rel="stylesheet"/>
<!--[if lt IE 9]><link href="//c5.rgstatic.net/m/238176252723686/styles/ie.css" type="text/css" rel="stylesheet"/><![endif]-->
<link href="//c5.rgstatic.net/m/217752362214895/styles/modules/publicprofile.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/21993347442549/styles/pow/publicliterature/FollowPublicationPromo.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/282514599719602/styles/pow/application/PdfJsReader.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/23819663151220/styles/pow/publicliterature/PublicationInlineReader.css" type="text/css" rel="stylesheet"/>
<script src="//c5.rgstatic.net/m/2321000301012716/javascript/vendor/webfontloader/webfontloader.js" type="text/javascript"></script>
 <script>(function(i,s,o,g,r,a,m){i["GoogleAnalyticsObject"]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,"script","//www.google-analytics.com/analytics.js","ga");
 ga("create","UA-58591210-1");ga("set","anonymizeIp",true);ga('set', 'dimension1', 'publication full-text');ga('set', 'dimension2', 'Article');ga('set', 'dimension3', 'Logged out');ga('set', 'dimension4', 'https');ga("send","pageview");</script>
  <script> WebFontConfig = { custom: { families: ['source_sans_pro_italic', 'source_sans_pro_bold', 'source_sans_pro', 'martel'], urls : ['//c5.rgstatic.net/m/231392577336386/styles/fonts.css'] } }; WebFont.load(WebFontConfig); </script><noscript></noscript>

<title>Slice sampling mixture models (PDF Download Available)</title>
<meta name="description" content="Official Full-Text Publication: Slice sampling mixture models on ResearchGate, the professional network for scientists."/>
<meta name="keywords" content="scientific network, scientific platform, scientific community, research partner, research collaboration, journal articles, international collaboration, find researcher, lifescience researcher, interdisciplinary research, research collaboration"/>
</head>
<body class="use-svg-icons logged-out">
<div id="page-container">
<script type="text/javascript">var googletag = googletag || {}; googletag.cmd = googletag.cmd || [];
(function() { var gads = document.createElement("script"); gads.async = true; gads.type = "text/javascript"; var useSSL = "https:" == document.location.protocol; gads.src = (useSSL ? "https:" : "http:") + "//www.googletagservices.com/tag/js/gpt.js"; var node =document.getElementsByTagName("script")[0]; node.parentNode.insertBefore(gads, node); })();</script><div id="main" class="logged-out-header-support">
<div id="content" class="">

<noscript>
<div class="c-box-warning full-width-element" style="text-align: center; ">
    <div style="margin: auto; padding:10px;" class="container">
        <b>For full functionality of ResearchGate it is necessary to enable JavaScript.
            Here are the <a href="http://www.enable-javascript.com/" rel="nofollow" target="_blank">
                instructions how to enable JavaScript in your web browser</a>.</b>
    </div>
</div>
</noscript>

<div id="rgw1_56ab9e94a3e5b" itemscope itemtype="http://schema.org/ScholarlyArticle"><div class="publication-wrapper publication-wrapper-onecol" id="rgw2_56ab9e94a3e5b" itemscope itemtype="http://schema.org/ScholarlyArticle"> <div class="c-col-content"> <div class="c-content"> <div class="clearfix">  <div class="publication-header"> <div id="rgw5_56ab9e94a3e5b">  <div class="type-label"> Article   </div> <span class="Z3988" title="ctx_ver=Z39.88-2004&rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&rfr_id=info%3Asid%2Fresearchgate.net%3Aresearchgate&rft_id=info%3Adoi%2F10.1007%2Fs11222-009-9150-y&rft.atitle=Slice%20sampling%20mixture%20models&rft.title=Statistics%20and%20Computing&rft.jtitle=Statistics%20and%20Computing&rft.volume=21&rft.issue=1&rft.date=2011&rft.pages=93-105&rft.issn=0960-3174&rft.au=Maria%20Kalli%2CJim%20E.%20Griffin%2CStephen%20G.%20Walker&rft.genre=article"></span> <h1 class="pub-title" itemprop="name">Slice sampling mixture models</h1> <meta itemprop="headline" content="Slice sampling mixture models">  <meta itemprop="image" content="https://i1.rgstatic.net/publication/220286498_Slice_sampling_mixture_models/links/00b7d51a4630de552f000000/smallpreview.png">  <div id="rgw8_56ab9e94a3e5b" class="publication-detail-author-list"> <div> <ul class="clearfix js-people-list">  <li id="rgw9_56ab9e94a3e5b"> <a href="researcher/70950184_Maria_Kalli" class="pub-detail-item author-item" itemprop="author" itemscope itemtype="http://schema.org/Person"> <div class="indent-left"> <div class="people-img">  <img src="https://c5.rgstatic.net/m/2951093203564/images/template/default/profile/profile_default_s.jpg" title="Maria Kalli" alt="Maria Kalli" height="20px" width="20px" style="height: 20px;"/>  </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Maria Kalli</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item   not-claimed " id="rgw10_56ab9e94a3e5b">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="researcher/70950184_Maria_Kalli"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="Maria Kalli" alt="Maria Kalli" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">       </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="researcher/70950184_Maria_Kalli" class="display-name">Maria Kalli</a>    </h5> <div class="truncate-single-line meta">   </div>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>  <li id="rgw11_56ab9e94a3e5b" itemprop="author" itemscope itemtype="http://schema.org/Person"> <a itemprop="sameAs" href="profile/Jim_Griffin2" class="pub-detail-item account-item"> <div class="indent-left"> <div class="people-img"> <img  src="https://i1.rgstatic.net/ii/profile.image/AS%3A272751797731334%401442040504288_m/Jim_Griffin2.png" title="Jim E Griffin" alt="Jim E Griffin" height="20px" width="20px" style="height: 20px;"/> </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Jim E Griffin</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item  remove-action-indent   " id="rgw12_56ab9e94a3e5b" data-account-key="Jim_Griffin2">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="profile/Jim_Griffin2"> <img class="lazyload" data-src="https://i1.rgstatic.net/ii/profile.image/AS%3A272751797731334%401442040504288_l/Jim_Griffin2.png" title="Jim E Griffin" alt="Jim E Griffin" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">     </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="profile/Jim_Griffin2" class="display-name">Jim E Griffin</a>    </h5> <div class="truncate-single-line meta">   <a class="meta ga-top-coauthor-institution" href="institution/University_of_Kent" title="University of Kent">University of Kent</a>     </div>  <a href="javascript:" class="btn btn-promote btn-large people-item-contact-author js-contact-author">Message author</a>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>  <li id="rgw13_56ab9e94a3e5b"> <a href="researcher/11566371_Stephen_G_Walker" class="pub-detail-item author-item" itemprop="author" itemscope itemtype="http://schema.org/Person"> <div class="indent-left"> <div class="people-img">  <img src="https://c5.rgstatic.net/m/2951093203564/images/template/default/profile/profile_default_s.jpg" title="Stephen G. Walker" alt="Stephen G. Walker" height="20px" width="20px" style="height: 20px;"/>  </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Stephen G. Walker</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item   not-claimed " id="rgw14_56ab9e94a3e5b">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="researcher/11566371_Stephen_G_Walker"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="Stephen G. Walker" alt="Stephen G. Walker" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">       </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="researcher/11566371_Stephen_G_Walker" class="display-name">Stephen G. Walker</a>    </h5> <div class="truncate-single-line meta">   </div>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>   </ul> <div class="js-loading"></div>  </div> </div> <div class="pub-details js-pub-details">      <span itemprop="isPartOf" itemscope itemtype="http://schema.org/Periodical"> <a itemprop="sameAs" href="journal/0960-3174_Statistics_and_Computing"><span itemprop="name">Statistics and Computing</span></a> </span>    (Impact Factor: 1.62).     <meta itemprop="datePublished" content="2011-01">  01/2011;  21(1):93-105.    DOI:&nbsp;10.1007/s11222-009-9150-y           <div class="pub-source"> Source: <a href="http://dblp.uni-trier.de/db/journals/sac/sac21.html#KalliGW11" rel="nofollow">DBLP</a> </div>  </div> <div id="rgw15_56ab9e94a3e5b" class="pub-abstract">  <div class="clearfix">   <div style="max-height: 54px;" class="js-expander-container js-expander-collapsed">  <p itemprop="description"> <strong>ABSTRACT</strong> <div>We propose a more efficient version of the slice sampler for Dirichlet process mixture models described by Walker (Commun.<br />
Stat., Simul. Comput. 36:45&ndash;54, 2007). This new sampler allows for the fitting of infinite mixture models with a wide-range of prior specifications. To illustrate<br />
this flexibility we consider priors defined through infinite sequences of independent positive random variables. Two applications<br />
are considered: density estimation using mixture models and hazard function estimation. In each case we show how the slice<br />
efficient sampler can be applied to make inference in the models. In the mixture case, two submodels are studied in detail.<br />
The first one assumes that the positive random variables are Gamma distributed and the second assumes that they are inverse-Gaussian<br />
distributed. Both priors have two hyperparameters and we consider their effect on the prior distribution of the number of<br />
occupied clusters in a sample. Extensive computational comparisons with alternative &ldquo;conditional&rdquo; simulation techniques for<br />
mixture models using the standard Dirichlet process prior and our new priors are made. The properties of the new priors are<br />
illustrated on a density estimation problem.</div> </p>  </div>  </div>   </div>      <div class="action-container"> <div id="rgw16_56ab9e94a3e5b" class="follow-publication-promo"> <table> <tr> <td class="follow-publication-promo-text-cell"> <p>Get notified about updates to this publication</p> <a class="btn btn-large btn-promote js-follow-publication ga-follow-publication-new-promo">Follow publication</a> </td> <td> <div class="follow-publication-publication-image"></div> </td> </tr> </table> </div>  <div class="clear"></div> <div class="share-dialog-container" style="display: none;">  </div> </div> </div> <div style="margin-left: -20px; margin-right: -20px;">  </div> </div>  <div class="publication-detail-dfp-container rf"> <div id="rgw30_56ab9e94a3e5b">  </div> </div>  </div>  <div class="clearfix"> <div class="pdf-js-container clearfix " id="rgw31_56ab9e94a3e5b">  <div class="pdf-js-header js-sticky-header clear">  <a class="blue-link js-download rf btn btn-promote" href="https://www.researchgate.net/profile/Jim_Griffin2/publication/220286498_Slice_sampling_mixture_models/links/00b7d51a4630de552f000000.pdf?inViewer=0&amp;pdfJsDownload=0&amp;origin=publication_detail">Download full-text</a>  <h3>Full-text</h3> <span class="publication-info">  <span class="js-doi-container" style="display: none;"> DOI: <span class="js-doi"></span> &middot; </span> Available from: <a class="js-name" href="profile/Jim_Griffin2">Jim E Griffin</a>   </span>  </div>  <div class="social-share-container"><div id="rgw33_56ab9e94a3e5b" class="social-share js-social-share"> <div class="social-share-heading">Share</div>  <a id="rgw34_56ab9e94a3e5b" href="javascript:" title="Share on Facebook" class="link-nostyle js-share-item share-icon "  data-url="http://www.facebook.com/share.php?u={{url}}{{#title}}&amp;t={{title}}{{/title}}" data-width="600" data-height="350" data-name="Facebook"> <span class="share-icon ico-share-facebook-round reset-background ga-share-blog-facebook"></span> </a>  <a id="rgw35_56ab9e94a3e5b" href="javascript:" title="Share on Twitter" class="link-nostyle js-share-item share-icon "  data-url="http://twitter.com/intent/tweet?text={{#title}}{{title}}: {{/title}}{{url}}&amp;via=researchgate" data-width="600" data-height="350" data-name="Twitter"> <span class="share-icon ico-share-twitter-round reset-background ga-share-blog-twitter"></span> </a>  <a id="rgw36_56ab9e94a3e5b" href="javascript:" title="Share on Google+" class="link-nostyle js-share-item share-icon "  data-url="https://plus.google.com/share?url={{url}}" data-width="600" data-height="600" data-name="Google+"> <span class="share-icon ico-share-gplus-round reset-background ga-share-blog-gplus"></span> </a>  <a id="rgw37_56ab9e94a3e5b" href="javascript:" title="Share on LinkedIn" class="link-nostyle js-share-item share-icon "  data-url="http://www.linkedin.com/shareArticle?mini=true&amp;url={{url}}{{#title}}&amp;title={{title}}{{/title}}&amp;source=ResearchGate" data-width="520" data-height="570" data-name="LinkedIn"> <span class="share-icon ico-share-linkedin-round reset-background ga-share-blog-linkedin"></span> </a>  <a id="rgw38_56ab9e94a3e5b" href="javascript:" title="Share on Reddit" class="link-nostyle js-share-item share-icon "  data-url="https://www.reddit.com/submit?url={{url}}{{#title}}&amp;title={{title}}{{/title}}" data-width="600" data-height="600" data-name="Reddit"> <span class="share-icon ico-share-reddit reset-background ga-share-blog-reddit"></span> </a>  </div></div>    <iframe id="rgw32_56ab9e94a3e5b" src="https://www.researchgate.net/c/o1q2er/javascript/lib/pdfjs/web/viewer.html?file=https%3A%2F%2Fwww.researchgate.net%2Fprofile%2FJim_Griffin2%2Fpublication%2F220286498_Slice_sampling_mixture_models%2Flinks%2F00b7d51a4630de552f000000.pdf%3FinViewer%3D1%26pdfJsDownload%3D1%26origin%3Dpublication_detail" allowfullscreen frameborder="0" style="width: 100%; height: 100%; box-sizing: border-box;"></iframe>    </div> <noscript> <div id="rgw29_56ab9e94a3e5b"  itemprop="articleBody">  <p>Page 1</p> <p>Slice Sampling Mixture Models<br />Maria Kalli†, Jim E. Griffin∗&amp; Stephen G. Walker∗<br />†Centre for Health Services Studies, University of Kent<br />?Institute of Mathematics, Statistics &amp; Actuarial Science,<br />University of Kent<br />Abstract<br />We propose a more efficient version of the slice sampler for Dirichlet process<br />mixture models described by Walker (2007). This sampler allows the fitting of<br />infinite mixture models with a wide–range of prior specification. To illustrate<br />this flexiblity we develop a new nonparametric prior for mixture models by<br />normalizing an infinite sequence of independent positive random variables and<br />show how the slice sampler can be applied to make inference in this model. Two<br />submodels are studied in detail. The first one assumes that the positive random<br />variables are Gamma distributed and the second assumes that they are inverse–<br />Gaussian distributed. Both priors have two hyperparameters and we consider<br />their effect on the prior distribution of the number of occupied clusters in a<br />sample. Extensive computational comparisons with alternative ”conditional”<br />simulation techniques for mixture models using the standard Dirichlet process<br />prior and our new prior are made. The properties of the new prior are illus-<br />trated on a density estimation problem.<br />Keywords: Dirichlet process; Markov chain Monte Carlo; Mixture model; Nor-<br />malized Weights; Slice sampler.<br />∗Corresponding author: Jim E. Griffin, Institute of Mathematics, Statistics &amp; Actuarial Sci-<br />ence, University of Kent, Canterbury, U. K. Tel.: +44-1227-823627; Fax: +44-1227-827932; Email:<br />jeg28@kent.ac.uk<br />1</p>  <p>Page 2</p> <p>1 Introduction<br />The well known and widely used mixture of Dirichlet process (MDP) model was first<br />introduced by Lo (1984). The MDP model, with Gaussian kernel, is given by<br />?<br />with K(y;φ) being a normal kernel and P ∼ D(M,P0) . We write P ∼ D(M,P0) to<br />denote that P is a Dirichlet process (Ferguson, 1973) with parameters M &gt; 0, the<br />scale parameter, and P0, a distribution on the real line and φ = (µ,σ2) with µ to<br />represent the mean and σ2the variance of the normal component. Since the advent<br />of Markov chain Monte Carlo methods within the mainstream statistics literature<br />(Smith and Roberts, 1993), and the specific application to the MDP model (Escobar,<br />1988; Escobar, 1994; Escobar and West, 1995), the model has become one of the<br />most popular in Bayesian nonparametrics since it is possible to integrate P from the<br />posterior defined by this model.<br />Variations of the original algorithm of Escobar (1988) have been numerous; for<br />example, MacEachern (1994); M¨ uller and MacEachern (1998); Neal (2000). All of<br />these algorithms rely on integrating out the random distribution function from the<br />model, removing the infinite dimensional problem. These are usually referred to as<br />“marginal” methods. Recent ideas have left the infinite dimensional distribution in<br />the model and found ways of sampling a sufficient but finite number of variables<br />at each iteration of a Markov chain with the correct stationary distribution. See<br />Papaspiliopoulos and Roberts (2008) and Walker (2007); the latter paper using slice<br />sampling ideas. These define so–called “conditional” methods.<br />There has recently been interest in defining nonparametric priors for P that move<br />beyond the Dirichlet process (see e.g. Lijoi et al (2007)) in infinite mixture models.<br />These alternative priors allow more control over the prior cluster structure than would<br />be possible with the Dirichlet process. The availability of computational methods for<br />posterior inference,that do not integrate out P, allows us to implement these priors.<br />The purpose of this paper is two fold: 1) to develop an efficient version of the<br />slice sampling algorithm for MDP models proposed by Walker (2007) and to extend<br />it to more general nonparametric priors such as general stick–breaking processes and<br />normalised weights priors and 2) to develop a new class of nonparametric prior for<br />infinite mixture models by normalizing an infinite sequence of positive random vari-<br />ables, which will be termed a Normalized Weights prior. The lay–out of the paper is<br />fP(y) =K(y;φ)dP(φ)<br />2</p>  <p>Page 3</p> <p>as follows. In Section 2 we describe the slice–efficient sampler for the MDP model.<br />Section 3 describes the normalized weights prior and discusses constructing a slice<br />sampler for infinite mixture models with this prior. Section 4 discusses an applica-<br />tion of the normalized weights prior to modelling the hazard in survival analysis and<br />Section 5 contains numerical illustrations and an application of the normalized weight<br />prior to density estimation. Finally, Section 6 contains conclusions and a discussion.<br />2The slice–efficient sampler for the MDP<br />It is well known that P ∼ D(M,P0) has a stick–breaking representation (Sethuraman,<br />1994) given by<br />∞<br />?<br />where the {φj} are independent and identically distributed from P0and<br />w1= z1, wj= zj<br />P =<br />j=1<br />wjδφj,<br />?<br />l&lt;j<br />(1 − zl)<br />with the {zj} being independent and identically distributed from beta(1,M). It is<br />possible to integrate P from the posterior defined by the MDP model. However, the<br />stick–breaking representation is essential to estimation via the non–marginal methods<br />of Papaspiliopoulos and Roberts (2008) and Walker (2007). The idea is that we can<br />write<br />∞<br />?<br />and the key is to find exactly which (finite number of) variables need to be sampled<br />to produce a valid Markov chain with correct stationary distribution.<br />The details of the slice sampler algorithm are given in Walker (2007), but we briefly<br />describe the basis for the algorithm here and note an improvement, also noticed by<br />Papaspiliopoulos (2008). The joint density<br />fz,φ(y) =<br />j=1<br />wjK(y;φj)<br />fz,φ(y,u) =<br />∞<br />?<br />j=1<br />1(u &lt; wj)K(y;φj)<br />is the starting point. Given the latent variable u, the number of mixtures is finite,<br />the indices being Au= {k : wk&gt; u}. One has<br />fz,φ(y|u) = N−1<br />u<br />?<br />j∈Au<br />K(y;φj),<br />3</p>  <p>Page 4</p> <p>and the size of Auis Nu=?∞<br />finite number of mixtures provides the observation to give the joint density<br />j=11(wj&gt; u).<br />One can then introduce a further latent variable, d, which indicates which of these<br />fz,φ(y,u,d) = 1(u &lt; wd)K(y;φd).<br />Hence, a complete likelihood function for (z,φ) is available as a simple product of<br />terms and crucially d is finite. Without u, d can take an infinite number of values<br />which would make the implementation of a Markov chain Monte Carlo algorithm<br />problematic.<br />We briefly describe the simulation algorithm, but only provide the sampling pro-<br />cedure without derivation since this has appeared elsewhere (Walker, 2007). How-<br />ever, as mentioned earlier, we do sample one of the full conditionals in a different<br />and more efficient manner. We sample π(z,u|···) as a block and this involves sam-<br />pling π(z|··· exclude u) and then π(u|z,···), where π(z|··· exclude u) is obtained<br />by integrating out u from π(z,u|···). The distribution π(z|··· exclude u) will be<br />the standard full conditional for a stick–breaking process (see Ishwaran and James<br />(2001)). Standard MCMC theory on blocking suggests that this should lead to a<br />more efficient sampler.<br />Recall that we have the model<br />f(y) =<br />∞<br />?<br />j=1<br />wjK(y;φj),<br />where the {φj} are independent and identically distributed from P0, the {wj} have a<br />stick–breaking process based on the Dirichlet process, described earlier in this section.<br />The variables that need to be sampled at each sweep of a Gibbs sampler are<br />{(φj,zj),j = 1,2,...;(di,ui),i = 1,...,n}.<br />1. π(φj|···) ∝ p0(φj)?<br />2. π(zj|··· exclude u) ∝ beta(zj;aj,bj), where<br />di=jK(yi;φj).<br />aj= 1 +<br />n<br />?<br />i=1<br />1(di= j)<br />and<br />bj= M +<br />n<br />?<br />i=1<br />1(di&gt; j).<br />4</p>  <p>Page 5</p> <p>3. π(ui|···) ∝ 1(0 &lt; ui&lt; wdi).<br />4. P(di= k|···) ∝ 1(k : wk&gt; ui)K(yi;φk).<br />Obviously, we can not sample all of the (φj,zj). But it is not required to in order<br />to proceed with the chain. We only need to sample up to the integer N for which<br />we have found all the appropriate wkin order to do step 4 exactly. Since the weights<br />sum to 1 if we find Nisuch that?Ni<br />There are some important points to make here. First, it is a trivial extension to<br />consider more general stick–breaking processes for which zj∼ beta(αj,βj) indepen-<br />dently. Then, in this case, we would have<br />k=1wk&gt; 1 − uithen it is not possible for any of<br />the wk, for k &gt; Ni, to be greater than ui.<br />aj= αj+<br />n<br />?<br />i=1<br />1(di= j)<br />and<br />bj= βj+<br />n<br />?<br />i=1<br />1(di&gt; j).<br />This easy extension to more general priors is not a feature of alternative, marginal<br />sampling algorithms. Secondly, the algorithm is remarkably simple to implement; all<br />full conditionals are standard.<br />Later, for the illustrations and comparison, we will consider two types of slice<br />sampler. The “slice–efficient” which is the one described above and the “slice” which<br />is the original algorithm appearing in Walker (2007) and is noted by the fact that the<br />v is sampled conditional on u in this case.<br />The retrospective sampler (Papaspiliopoulos and Roberts 2008) is an alternative,<br />conditional method. The following argument gives some understanding for the dif-<br />ference between retrospective sampling (which uses Metropolis sampling) and slice<br />sampling. Suppose we wish to sample from f(x) ∝ l(x)π(x) using Metropolis sam-<br />pling and use π(x) as the proposal density. Let xcbe the current sample and x∗∼ π(x)<br />and u ∼ Un(0,1), so the new sample xnis x∗if u &lt; l(x∗)/l(xc) or else is xc.<br />On the other hand, the slice sampler would work by considering f(x,u) ∝ 1(u &lt;<br />l(x))π(x) and so a move from xcto xnwould work by sampling xnfrom π(x) restricted<br />to {x : l(x)/l(xc) &gt; u} where u ∼ Un(0,1). So the two sampling strategies are<br />using the same variables but in a fundamentally different way, which allows the slice<br />sampling version to always move.<br />5</p>  <p>Page 6</p> <p>This illustration is obviously demonstrated on a simple level, but we believe the<br />principle applies to the difference between the retrospective sampler and the slice<br />sampler for the mixture of Dirichlet process model.<br />3 Mixtures Based on Normalized Weights<br />3.1 Definition and Properties<br />The slice sampling idea can be extended to mixture models with weights obtained<br />via normalization. The Dirichlet process has been the dominant prior in nonpara-<br />metrics but the definition of alternative nonparametric priors has been a recent area<br />of interest. For example, Lijoi et al (2007) define nonparametric priors through the<br />normalization of the generalized Gamma process. We discuss an alternative form of<br />normalization. We consider<br />f(y) =<br />∞<br />?<br />j=1<br />wjK(y;φj)<br />where wj= λj/Λ and Λ =?∞<br />These must be constructed so as to ensure that?∞<br />X is a random variable whose distribution is discrete on the positive integers. For<br />example, we could assume that X = Y +1 where Y follows a geometric distribution.<br />Then<br />qj= (1 − θ)θj−1.<br />The parameter θ controls the rate at which E[λ1],E[λ2],E[λ2],... tends to zero. We<br />have defined a nonparametric prior with two parameters θ and ξ. As we will see<br />in the following examples, the choice of the distributions π1,π2,π3,... controls the<br />properties of the process. Many other families of nonparametric prior distribution can<br />be generated by different choices of X. For example, we could assume that X = Y +1<br />where Y follows a Poisson distribution.<br />j=1λj. We will also use Λm=?∞<br />j=m+1λj. Here the {λj}<br />are positive and will be assigned independent prior distributions, say λj ∼ πj(λj).<br />j=1λj &lt; +∞ a.s. We suggest<br />defining specific priors by defining E[λj] = ξqjwhere ξ &gt; 0 and qj= P(X = j) where<br />Example 1: Gamma distribution.<br />Here we take the {λj} to be independent gamma distributions, say λj∼ Ga(γj,1).<br />To ensure that Λ &lt; +∞ a.s. we take?∞<br />6<br />j=1γj&lt; +∞. Clearly, wj has expectation</p>  <p>Page 7</p> <p>ξ = 0.1ξ = 1ξ = 10<br />θ = 0.4<br />05 10 1520 25<br />0<br />1000<br />2000<br />3000<br />4000<br />5000<br />6000<br />7000<br />8000<br />9000<br />10000<br />05 10152025<br />0<br />1000<br />2000<br />3000<br />4000<br />5000<br />6000<br />7000<br />8000<br />9000<br />10000<br />05 10 1520 25<br />0<br />1000<br />2000<br />3000<br />4000<br />5000<br />6000<br />7000<br />8000<br />9000<br />10000<br />θ = 0.7<br />05 101520 25<br />0<br />1000<br />2000<br />3000<br />4000<br />5000<br />6000<br />7000<br />8000<br />9000<br />10000<br />05 1015 2025<br />0<br />1000<br />2000<br />3000<br />4000<br />5000<br />6000<br />7000<br />8000<br />9000<br />10000<br />05 10 152025<br />0<br />1000<br />2000<br />3000<br />4000<br />5000<br />6000<br />7000<br />8000<br />9000<br />10000<br />θ = 0.9<br />05 10152025<br />0<br />1000<br />2000<br />3000<br />4000<br />5000<br />6000<br />7000<br />8000<br />9000<br />10000<br />0510 152025<br />0<br />1000<br />2000<br />3000<br />4000<br />5000<br />6000<br />7000<br />8000<br />9000<br />10000<br />0510 1520 25<br />0<br />1000<br />2000<br />3000<br />4000<br />5000<br />6000<br />7000<br />8000<br />9000<br />10000<br />Figure 1: Prior distribution of the number of clusters from 30 observations with the<br />infinite Dirichlet prior<br />qj and variance qj(1 − qj)/(ξ + 1) and we can interpret ξ as a mass parameter.<br />We will refer to this model as an infinite Dirichlet prior since if we have a finite<br />number of unnormalized weights λ1,λ2,...,λNthen w1,w2,...,wNwould be Dirichlet<br />distributed. In infinite mixture models, the prior distribution on the number of<br />clusters from n observations is important. Figure 1 shows this distribution for n = 30.<br />Larger values of θ for fixed ξ place more mass on larger numbers of clusters (as we<br />would expect since the weights decay increasingly slowly with larger θ). The mass<br />parameter ξ also plays an important role. Larger values of ξ lead to more dispersed<br />distributions with a larger median value.<br />Stick–breaking priors were introduced to Bayesian nonparametrics by Ishwaran<br />and James (2001). They are defined by two infinite vectors of parameters. Clearly,<br />there is a need to develop priors within this class that have a few hyperparameters to<br />allow easy prior specification. The Dirichlet process and Poisson-Dirichlet process are<br />two such priors and the infinite Dirichlet prior represents another. The stick-breaking<br />representation of the infinite Dirichlet prior takes αj= ξqjand βj= ξ<br />?<br />1 −?j<br />i=1qi<br />?<br />.<br />7</p>  <p>Page 8</p> <p>Example 2: Inverse–Gaussian distribution<br />The inverse–Gaussian distribution, IG(γ,η), has a density function given by<br />π(λ) =<br />γ<br />√2πλ−3/2exp<br />?<br />−1<br />2<br />?γ2<br />λ+ η2λ<br />?<br />+ ηγ<br />?<br />,<br />where γ and η can be interpreted as a shape and a scale parameter, respectively. We<br />take λjto follow independent IG(γj,1) distributions. Then Λm=?∞<br />ξ = 0.1ξ = 1<br />j=m+1λjis dis-<br />ξ = 10<br />θ = 0.4<br />05 1015 2025<br />0<br />1000<br />2000<br />3000<br />4000<br />5000<br />6000<br />7000<br />8000<br />9000<br />10000<br />05 10152025<br />0<br />1000<br />2000<br />3000<br />4000<br />5000<br />6000<br />7000<br />8000<br />9000<br />10000<br />0510 152025<br />0<br />1000<br />2000<br />3000<br />4000<br />5000<br />6000<br />7000<br />8000<br />9000<br />10000<br />θ = 0.7<br />05 10152025<br />0<br />1000<br />2000<br />3000<br />4000<br />5000<br />6000<br />7000<br />8000<br />9000<br />10000<br />0510152025<br />0<br />1000<br />2000<br />3000<br />4000<br />5000<br />6000<br />7000<br />8000<br />9000<br />10000<br />05101520 25<br />0<br />1000<br />2000<br />3000<br />4000<br />5000<br />6000<br />7000<br />8000<br />9000<br />10000<br />θ = 0.9<br />0510 152025<br />0<br />1000<br />2000<br />3000<br />4000<br />5000<br />6000<br />7000<br />8000<br />9000<br />10000<br />05 10152025<br />0<br />1000<br />2000<br />3000<br />4000<br />5000<br />6000<br />7000<br />8000<br />9000<br />10000<br />05 1015 2025<br />0<br />1000<br />2000<br />3000<br />4000<br />5000<br />6000<br />7000<br />8000<br />9000<br />10000<br />Figure 2: Prior distribution of the number of clusters for infinite normalized inverse–<br />Gaussian prior<br />tributed as IG(?∞<br />bution (λ1/Λ,λ2/Λ,...,λm/Λ) has been studied by Lijoi et al. (2005) as the normal-<br />ized inverse–Gaussian distribution. We again define γj= ξqjand it follows directly<br />from their results that wihas expectation qiand variance qi(1−qi)ξ2exp{ξ}Γ(−2,ξ).<br />This prior will be referred to as the infinite normalized inverse–Gaussian prior. Fig-<br />ure 2 shows the prior distribution of the number of clusters in 30 observations. The<br />effects of ξ and θ follow the same pattern as the infinite Dirichlet case discussed above.<br />However, the effect of ξ is less marked for small ξ. In the infinite Dirichlet case for<br />ξ = 0.1, the distributions are almost indistinguishable for different values of θ but in<br />j=m+1γj,1) and the normalization is well–defined if?∞<br />j=1γj&lt; +∞<br />which implies that Λ is almost surely finite. The finite dimensional normalized distri-<br />8</p>  <p>Page 9</p> <p>this case it is clear that the location of the distribution is increasing with θ. This<br />allows easier prior specification for the infinite normalized–inverse Gaussian prior<br />3.2Slice sampler<br />The model can be fitted using an extension of the slice sampler developed in section 2.<br />We will assume that the distribution of Λmhas a known form for all m, which we will<br />denote by π?<br />trickier. Simpler updating is possible when we introduce the additional latent variable<br />v, and consider the joint density<br />m(Λm). The introduction of a normalizing constant, Λ, makes MCMC<br />f(y,v,u,d) = exp(−vΛ)1(u &lt; λd)K(y;φd).<br />Clearly the marginal density<br />f(y,d) =λd<br />ΛK(y;φd),<br />as required. The likelihood function based on a sample of size n is given by<br />n<br />?<br />i=1<br />exp(−viΛ)1(ui&lt; λdi)K(yi;φdi).<br />We will only consider those conditional distributions which are not immediately triv-<br />ial; those that are completely trivial being ui, viand φj. The distribution of diis<br />trivial but as before we need to find the number of λj’s (and also φj’s) to be sampled<br />in order to implement the sampling of di.<br />Hence, the non–trivial aspect to the algorithm is the sampling of the sufficient<br />number of {λj} and Λ. We will, as before, work on the conditional distribution<br />of the ({λj},Λ) excluding the {ui}. We simulate λ1,...,λm,Λm (where m is the<br />number of atoms given in the previous iteration) in a block from their full conditional<br />distribution which is proportional to<br />exp{−V Λm}π?<br />m(Λm)<br />m<br />?<br />i=1vi. We need to find the smallest value of<br />j=1<br />exp{−V λj}λnj<br />jπj(λj),<br />where nj=?n<br />of di. This value can be found by sequentially simulating [λj,Λj|Λj−1] for j = m +<br />1,...,m?. The conditional distribution of [λj= x,Λj= Λj−1− x|Λj−1] is given by<br />f(x) ∝ πj(x)π?<br />i=11(di= j) and V =?n<br />m?for which Λm? &lt; mini{ui} so that we can evaluate the full conditional distribution<br />j(Λj−1− x),0 &lt; x &lt; Λj−1.<br />9</p>  <p>Page 10</p> <p>In some cases simulation from the distribution will be straightforward. If not, generic<br />univariate simulation methods such as Adaptive Rejection Metropolis Sampling (Gilks<br />et al. 1995) can be employed. We now consider a couple of examples.<br />Example 1: Gamma distribution<br />It is easy to see that<br />π(λ1/Λ,...,λm/Λ|Λ,··· , exclude u) = Dir<br />?<br />γ1+ n1,...,γm+ nm,<br />∞<br />?<br />l=m+1<br />γl<br />?<br />and<br />Λm∼ Ga<br />?<br />∞<br />?<br />j=m+1<br />γj,1 + V<br />?<br />.<br />The conditional distribution of λj/Λj is Be(γj,?∞<br />i=j+1γi). This prior can also be<br />represented as a stick–breaking prior.<br />Example 2: Inverse–Gaussian distribution<br />The full conditional distribution of λjis given by<br />π(λj|···) ∝ λnj−3/2<br />j<br />exp<br />?<br />−1<br />2<br />?γ2<br />j<br />λj<br />+ (1 + 2V )λj<br />??<br />,<br />where njis the number of observations allocated to component j. The full conditional<br />distribution of Λmis proportional to<br />?<br />These are both generalized inverse–Gaussian distributions which can be simulated<br />directly; see e.g. Devroye (1986).<br />We can simulate from [λj+1,Λj+1|Λj] by defining λj+1 = xj+1Λj and Λj+1 =<br />(1 − xj+1)Λjwhere the density of xj+1is given by<br />?<br />Λ−3/2<br />m<br />exp−1<br />2<br />?(?∞<br />i=m+1γi)2<br />λj<br />+ (1 + 2V )λj<br />??<br />.<br />g(xj+1) ∝ x−3/2<br />j+1(1 − xj+1)−3/2exp−1<br />2<br />?<br />γ2<br />j<br />Λjxj+1<br />+(?∞<br />Λj(1 − xj+1)<br />i=j+1γi)2<br />??<br />.<br />Unlike the gamma case, this conditional distribution depends on Λm. The distribution<br />of xj+1/(1−xj+1) can be identified as a two–mixture of generalized inverse–Gaussian<br />distributions and hence can be sampled easily (details are given in the Appendix).<br />10</p>  <p>Page 11</p> <p>4 Hazard Functions<br />The normalized procedure can also be applied to the modeling of random hazard<br />functions. Suppose we model the unknown hazard function h(t), for t &gt; 0, using a<br />set of known functions {hk(t)}∞<br />∞<br />?<br />Here the {λk&gt; 0} are the model parameters and can be assigned independent gamma<br />prior distributions; say λk∼ Ga(ak,bk). Obviously we will need to select (ak,bk) to<br />ensure that h(t) &lt; +∞ a.s. for all t &lt; +∞. The corresponding density function is<br />given by<br />∞<br />?<br />where Hkis the cumulative hazard corresponding to hk.<br />So with observations {ti}n<br />n<br />?<br />Our approach is based on the introduction of a latent variable, say u, so that we<br />consider the joint density with t given by<br />k=1, via<br />h(t) =<br />k=1<br />λkhk(t).<br />f(t) =<br />k=1<br />λkhk(t) exp<br />?<br />−<br />∞<br />?<br />k=1<br />λkHk(t)<br />?<br />,<br />i=1, the likelihood function is given by<br />?∞<br />k=1<br />l(λ|t) ∝<br />i=1<br />?<br />λkhk(ti) exp<br />?<br />−<br />∞<br />?<br />k=1<br />λkHk(ti)<br />??<br />.<br />f(t,u) =<br />∞<br />?<br />k=1<br />1(u &lt; λk)hk(t) exp<br />?<br />−<br />∞<br />?<br />k=1<br />λkHk(t)<br />?<br />.<br />A further latent variable d picks out the mixture component from which (t,u) come,<br />f(t,u,d) = 1(u &lt; λd)hd(t) exp<br />?<br />−<br />∞<br />?<br />k=1<br />λkHk(t)<br />?<br />.<br />We will now introduce the key latent variables, one for each observation, and label<br />them (ui,di), into the likelihood, which is given by<br />l(λ|t,u,d) ∝<br />n<br />?<br />i=1<br />1(ui&lt; λdi)hdi(ti) exp<br />?<br />−<br />∞<br />?<br />k=1<br />λkHk(ti)<br />?<br />.<br />The point is that the choice of diis finite. It is now clear that the sampling algorithm<br />for this model is basically the same now as for the normalized case. We could take<br />11</p>  <p>Page 12</p> <p>the λj to be gamma with parameters aj+?<br />sample the diwe need to find all the λjgreater than ui. We can do this by sampling<br />ΛM =?<br />found all the λj&gt; ui, we can sample difrom Pr(di= j) ∝ 1(λj&gt; ui)hj(ti).<br />di=j1 and bj+?<br />di=jHj(ti) and we<br />would first sample up to M = maxidi. Then the uiare from Un(0,λdi). In order to<br />j&gt;Mλj as a gamma distribution and then sampling [λM+1,...λNi]|ΛM so<br />that Niis the smallest integer for which?Ni<br />j=M+1λj&gt; ΛM−ui. Finally, once we have<br />5Illustration and Comparisons<br />In this section we carry out a comparison of the slice sampling algorithm with the<br />retrospective sampler using the Dirichlet process and the normalized weights prior.<br />The algorithms are compared using the normal kernel K(y|φ) with components φ =<br />(µ,ζ), and P0(µ,ζ) = N(µ|µ0,ξ2) × G(ζ|γ,β). Here G(γ,β) denotes the gamma<br />distribution. We also consider inference for the commonly used galaxy data set with<br />the infinite Dirichlet and infinite normalized inverse–Gaussian priors.<br />For comparison purposes we consider two real data sets and two simulated data<br />sets. The real data sets are:<br />1. Galaxy data set which consists of the velocities of 82 distant galaxies diverging<br />from our own galaxy. This is the most commonly used data set in density<br />estimation studies, due to its mulimodality. We will also use it to illustrate the<br />effect of the prior choice on the posterior density in Section 5.3.<br />2. S &amp; P 500 data set which consist of 2023 daily index returns. This is yet another<br />commonly used data set in density estimation and volatility studies of financial<br />asset returns; see, Jacquier, Polson, and Rossi (1994, 2004). This data set is<br />unimodal, not necessarily symmetric, around zero, and it is characterized by<br />heavy tails.<br />We chose these data sets because of their size, as we would like to study the<br />performance of the algorithms on both small and large data sets.<br />The simulated data sets are based on the models used in Green and Richardson<br />(2001) and consist of 100 draws from a bimodal and a leptokurtic mixture.<br />1. The bimodal mixture: 0.5N(−1,0.52) + 0.5N(1,0.52).<br />2. The leptokurtic mixture: 0.67N(0,1) + 0.33N(0.3,0.252).<br />12</p>  <p>Page 13</p> <p>Both of these simulated data sets were used in the algorithm comparison study<br />carried out in Papaspiliopoulos and Roberts (2008); since we are comparing our slice<br />sampler with the retrospective sampler, we decided to use these simulated data sets.<br />The parameters for our MDP mixture are also set according to Green and Richard-<br />son (2001). If R is the range of the data; then we take µ0= R/2, ξ = R, γ = 2, and<br />β = 0.2R2. The precision parameter of the Dirichlet Process is set at M = 1. In the<br />comparison of the estimates of the statistics used, we took the Monte Carlo sample<br />size to be S = 250,000 for each algorithm, with the initial 10,000 used as a burn<br />in period. Density estimates using the retrospective and slice–efficient samplers are<br />shown in figure 3 for the Dirichlet process mixture model.<br />Bi–modalLeptokurticS &amp; P 500<br />(a)<br />−3−2 −10123<br />0<br />0.05<br />0.1<br />0.15<br />0.2<br />0.25<br />0.3<br />0.35<br />−3 −2 −10123<br />0<br />0.1<br />0.2<br />0.3<br />0.4<br />0.5<br />0.6<br />0.7<br />−6−4 −20246<br />0<br />0.05<br />0.1<br />0.15<br />0.2<br />0.25<br />0.3<br />0.35<br />0.4<br />0.45<br />0.5<br />(b)<br />−3 −2−10123<br />0<br />0.05<br />0.1<br />0.15<br />0.2<br />0.25<br />0.3<br />0.35<br />−3 −2 −10123<br />0<br />0.1<br />0.2<br />0.3<br />0.4<br />0.5<br />0.6<br />0.7<br />−6 −4−20246<br />0<br />0.05<br />0.1<br />0.15<br />0.2<br />0.25<br />0.3<br />0.35<br />0.4<br />0.45<br />0.5<br />Figure 3: Predictive densities: (a) retrospective and (b) slice–efficient<br />5.1 Algorithmic performance<br />To monitor the performance of the algorithms we look at the convergence of two<br />quantities:<br />• The number of clusters: at each iteration there are j = 1,...,N clusters of<br />the i = 1,...,n data points with mj being the size of the j cluster, so that<br />?N<br />• The deviance, D, of the estimated density, calculated as<br />n<br />?<br />j=1mj= n.<br />D = −2<br />i=1<br />log<br />??<br />j<br />mj<br />nK(yi|φj)<br />?<br />.<br />13</p>  <p>Page 14</p> <p>These variables have been used in the previous comparison studies of Papaspiliopoulos<br />and Roberts (2008), Green and Richardson (2001) and Neal (2000). Here D is one<br />of the most common functionals used in comparing algorithms, because it is seen as<br />a global function of all model parameters. Although we produce this variable and<br />study its algorithmic performance we are also concerned with the convergence of the<br />number of clusters.<br />The efficiency of the algorithms is summarized by computing an estimate ? τ of the<br />tion time is defined in Sokal (1997) as<br />integrated autocorrelation time, τ, for each of the variables. Integrated autocorrela-<br />τ =1<br />2+<br />∞<br />?<br />l=1<br />ρl.<br />where ρl is the autocorrelation at lag l. An estimate of τ has been used in Pa-<br />paspiliopoulos and Roberts (2008), Green and Richardson (2001) and Neal (2000).<br />Integrated autocorrelation time is of interest as it controls the statistical error in<br />Monte Carlo measurements of a desired function f. To clarify this point, consider<br />the Monte Carlo sample mean,<br />¯f ≡1<br />S<br />S<br />?<br />l=1<br />fj,<br />where S is the number of iterations. The variance of¯f according to Sokal (1997) is<br />Var(¯f) ≈1<br />S2τ × V,<br />where V is the marginal variance. Sokal (1997) concludes that Var(¯f) is a factor<br />2τ larger than what it would be if the {fj} were statistically independent. In other<br />words, τ determines the statistical error of the Monte Carlo measurements of f once<br />equilibrium has been attained. Therefore a run of S iterations contains only S/(2τ)<br />“effectively independent data points”. This means that the algorithm with the smallest<br />estimated value of τ will be the most efficient. The problem with the calculation of τ<br />lies in accurately estimating the covariance between the states, which in turn is used<br />to calculate the autocorrelation ρl. It must be noted that in MCMC the covariance<br />and the autocorrelation are not single values but random variables. Based on Sokal<br />(1997) the estimator for τ is given by<br />? τ =1<br />2+<br />C−1<br />?<br />l=1<br />? ρl.<br />14</p>  <p>Page 15</p> <p>where ? ρlis the estimated autocorrelation at lag l (obtained via MatLab) and C is<br />commonly done,<br />C = min<br />a cut–off point, normally set by the researcher. In our comparisons we define, as is<br />?<br />l : |? ρl| &lt; 2/√S<br />?<br />.<br />Then C is the smallest lag for which we would not reject the null hypothesis H0:<br />ρl= 0. A similar approach has also been used in Papaspiliopoulos (2008). The issue<br />here, see Sokal (1997), is the cut off point C; it introduces bias equal to<br />?<br />On the other hand, the variance of ? τ can be computed using<br />Bias(? τ) =1<br />2<br />|l|&gt;C<br />ρl+ o<br />?1<br />S<br />?<br />.<br />Var(? τ) ≈2(2C − 1)<br />S<br />τ2.<br />The choice of C will be a trade off between the bias and the variance of ˆ τ, which<br />means that we really cannot say how “good” an algorithm is since the choice of C<br />point is left to the researcher. According to Sokal (1997), this approach works well<br />when a sufficient quantity of data is available which we can control by running the<br />sampler for a sufficient number of iterations.<br />5.2Results<br />The following tables compare the estimated integrated autocorrelation time ? τ of the<br />two variables of interest; the number of clusters and the deviance.<br />5.2.1 Dirichlet process<br />Looking at the estimates of ? τ for the real data sets we come to the following conclu-<br />• For the galaxy data set there is little difference between the two samplers. Even<br />though the retrospective sampler performs marginally better, the slice–efficient<br />sampler is easier to use as simulating the z and k is carried out in an easy way,<br />as opposed to the complexity of the set up of the retrospective sampling steps.<br />sions:<br />• For the S&amp;P data set which is large, unimodal, asymmetric and heavy–tailed,<br />it is the slice–efficient sampler that outperforms the retrospective sampler, in<br />terms of ? τ for the number of clusters; ? τ for the slice–efficient sampler is about<br />15<br />half that of the retrospective sampler.</p>  <p>Page 16</p> <p>Galaxy data<br />? τ for ? clust<br />10.2868<br />6.7677<br />Leptokurtic data<br />? τ for ? clust<br />33.0470<br />13.6639<br />? τ for D<br />4.3849<br />2.9857<br />? τ for D<br />26.0547<br />9.3014<br />Slice<br />Slice–efficient<br />Retrospective<br />31.5268 10.2683157.0064 119.3368<br />Bimodal data<br />? τ for ? clust<br />26.8114<br />14.7202<br />S&amp;P 500 data<br />? τ for ? clust<br />4.1923<br />7.1464<br />? τ for D<br />10.8374<br />7.1603<br />? τ for D<br />5.2390<br />1.5779<br />Slice<br />Slice–efficient<br />Retrospective<br />167.499554.6059 142.6566 81.4236<br />Table 1: Estimates of the integrated autocorrelation times for the deviance (D) and<br />for the number of clusters with four data sets with the Dirichlet process mixture<br />model<br />Galaxy Bimodal Leptokurtic S &amp; P 500<br />?<br />clust<br />0 50 100 150 200250 300350400450 500<br />0<br />0.1<br />0.2<br />0.3<br />0.4<br />0.5<br />0.6<br />0.7<br />0.8<br />0.9<br />1<br />050100 150200250300 350400450500<br />0<br />0.1<br />0.2<br />0.3<br />0.4<br />0.5<br />0.6<br />0.7<br />0.8<br />0.9<br />1<br />050100150200250300 350400450 500<br />0<br />0.1<br />0.2<br />0.3<br />0.4<br />0.5<br />0.6<br />0.7<br />0.8<br />0.9<br />1<br />0 50 100 150200 250300350400 450500<br />0<br />0.1<br />0.2<br />0.3<br />0.4<br />0.5<br />0.6<br />0.7<br />0.8<br />0.9<br />1<br />Dev.<br />0 50100 150 200250 300350400450500<br />0<br />0.1<br />0.2<br />0.3<br />0.4<br />0.5<br />0.6<br />0.7<br />0.8<br />0.9<br />1<br />050 100150 200250300350400 450500<br />0<br />0.1<br />0.2<br />0.3<br />0.4<br />0.5<br />0.6<br />0.7<br />0.8<br />0.9<br />1<br />0 50 100150200 250300350400 450500<br />0<br />0.1<br />0.2<br />0.3<br />0.4<br />0.5<br />0.6<br />0.7<br />0.8<br />0.9<br />1<br />050100 150200 250300350400450 500<br />0<br />0.1<br />0.2<br />0.3<br />0.4<br />0.5<br />0.6<br />0.7<br />0.8<br />0.9<br />1<br />Figure 4: Autocorrelation of MCMC output for: slice sampler (red), efficient slice<br />sampler (blue) and retrospective sampler (green)<br />5.2.2Mixtures based on normalized weights<br />We reject the slice sampler in favour of the slice–efficient sampler. We use the infinite<br />Dirichlet and infinite normalized inverse–Gaussian mixtures models with ξ = 1 and<br />θ = 0.5 on the four data sets. We find similar performance for the normalized weights<br />prior as for the Dirichlet process prior. The retrospective sampler is usually more<br />efficient than the slice sampler with a two times relative improvement on average.<br />16</p>  <p>Page 17</p> <p>Galaxy data<br />? τ for ? clust<br />27.12<br />Leptokurtic data<br />? τ for ? clust<br />48.32<br />? τ for D<br />7.08<br />? τ for D<br />29.13<br />Slice–efficient<br />Retrospective<br />25.5012.21115.3679.70<br />Bimodal data<br />? τ for ? clust<br />44.05<br />S&amp;P 500 data<br />? τ for ? clust<br />14.17<br />? τ for D<br />8.64<br />? τ for D<br />3.22<br />Slice–efficient<br />Retrospective<br />64.1917.0321.6911.99<br />Table 2: Estimates of the integrated autocorrelation times for the deviance (D) and<br />for the number of clusters with four data sets with the infinite Dirichlet distribution<br />mixture model<br />The improvement is typically larger for the simulated rather than the real data sets.<br />The effect is also more pronounced for the infinite Dirichlet distribution prior rather<br />than the infinite normalized inverse–Gaussian prior.<br />Galaxy data<br />? τ for ? clust<br />16.91<br />Leptokurtic data<br />? τ for ? clust<br />27.63<br />? τ for D<br />4.75<br />? τ for D<br />21.52<br />Slice–efficient<br />Retrospective<br />22.41 8.89 41.95 31.64<br />Bimodal data<br />? τ for ? clust<br />23.20<br />S&amp;P 500 data<br />? τ for ? clust<br />85.57<br />? τ for D<br />9.45<br />? τ for D<br />3.01<br />Slice–efficient<br />Retrospective<br />34.72 15.79 28.42 8.38<br />Table 3: Estimates of the integrated autocorrelation times for the deviance (D) and<br />for the number of clusters with four data sets with the infinite normalized inverse–<br />Gaussian distribution mixture model<br />These results are not surprising. The slice sampler introduces auxiliary variables<br />to help simulation which will slow convergence through over–conditioning. The slice–<br />efficient sampler reduces this effect by jointly updating u and λ (or V in the Dirichlet<br />17</p>  <p>Page 18</p> <p>process case) in a block. The retrospective sampler will mix slowly when the proposal<br />distribution is a poor approximation to the full conditional distribution. Therefore it<br />is usually difficult to be sure about the ranking of the methods. In these illustrations,<br />we have seen examples where the slice–efficient sampler is more efficient than the<br />retrospective sampler.<br />5.3Inference for the Normalized Weights Priors<br />The galaxy data has been a popular data set in Bayesian nonparametric modelling<br />and we will illustrate the infinite Dirichlet and infinite normalized inverse–Gaussian<br />priors on it. The posterior mean density estimates are shown in figure 5 for the in-<br />finite Dirichlet prior and figure 6 for the infinite normalized inverse–Gaussian prior.<br />The hyperparameters of the prior distributions have a clear effect on the posterior<br />ξ = 0.1ξ = 1ξ = 10<br />θ = 0.4<br />10 20 30 40<br />0<br />0.05<br />0.1<br />0.15<br />0.2<br />0.25<br />10 20 3040<br />0<br />0.05<br />0.1<br />0.15<br />0.2<br />0.25<br />10 2030 40<br />0<br />0.05<br />0.1<br />0.15<br />0.2<br />0.25<br />θ = 0.7<br />10 20 3040<br />0<br />0.05<br />0.1<br />0.15<br />0.2<br />0.25<br />10 20 3040<br />0<br />0.05<br />0.1<br />0.15<br />0.2<br />0.25<br />10 20 3040<br />0<br />0.05<br />0.1<br />0.15<br />0.2<br />0.25<br />θ = 0.9<br />10 20 3040<br />0<br />0.05<br />0.1<br />0.15<br />0.2<br />0.25<br />1020 30 40<br />0<br />0.05<br />0.1<br />0.15<br />0.2<br />0.25<br />102030 40<br />0<br />0.05<br />0.1<br />0.15<br />0.2<br />0.25<br />Figure 5: Posterior mean density estimates for the galaxy data using the infinite<br />Dirichlet prior with different values of M and θ<br />mean estimates. Prior distributions that places more mass on a small number of com-<br />ponents tend to find estimates with three clear modes. As the prior mean number<br />of components increases so do the number of modes in the estimate from 4 to 5 for<br />18</p>  <p>Page 19</p> <p>the prior within each class that places most mass on a large number of components<br />(ξ = 10 and φ = 0.9). However, there are some clear differences between the two<br />ξ = 0.1ξ = 1ξ = 10<br />θ = 0.4<br />1020 3040<br />0<br />0.05<br />0.1<br />0.15<br />0.2<br />0.25<br />10 20 30 40<br />0<br />0.05<br />0.1<br />0.15<br />0.2<br />0.25<br />10 203040<br />0<br />0.05<br />0.1<br />0.15<br />0.2<br />0.25<br />θ = 0.7<br />10 20 30 40<br />0<br />0.05<br />0.1<br />0.15<br />0.2<br />0.25<br />10 2030 40<br />0<br />0.05<br />0.1<br />0.15<br />0.2<br />0.25<br />10 2030 40<br />0<br />0.05<br />0.1<br />0.15<br />0.2<br />0.25<br />θ = 0.9<br />10 20 30 40<br />0<br />0.05<br />0.1<br />0.15<br />0.2<br />0.25<br />102030 40<br />0<br />0.05<br />0.1<br />0.15<br />0.2<br />0.25<br />102030 40<br />0<br />0.05<br />0.1<br />0.15<br />0.2<br />0.25<br />Figure 6: Posterior mean density estimates for the galaxy data using the infinite<br />normalized inverse–Gaussian prior with different values of ξ and θ<br />classes of prior. The effects of the two hyperparameters on the prior distribution<br />of the number of non–empty components were more clearly distinguishable in the<br />infinite normalized inverse–Gaussian prior than the infinite Dirichlet prior. In the<br />infinite normalized inverse–Gaussian prior θ controls the mean number of non–empty<br />components whereas ξ controls the dispersion around the mean. This property is car-<br />ried forward to the posterior mean density and the number of modes in the posterior<br />mean increases with θ. For example, when ξ = 0.1, there are three modes in the<br />posterior mean if θ = 0.4 whereas there are 4 when θ = 0.9. Similarly, larger values<br />of ξ are associated with larger variability in the prior mean and favour distributions<br />which uses a larger number of components. This suggests that infinite normalized<br />inverse–Gaussian distribution may be a more easily specified prior distribution than<br />the infinite Dirichlet prior.<br />19</p>  <p>Page 20</p> <p>6 Conclusions and Discussion<br />This paper has shown how mixture models based on random probability measures, of<br />either the stick–breaking or normalized types, can be easily handled via the introduc-<br />tion of a key latent variable which makes finite the number of mixtures. The more<br />complicated of the two is the normalized type, which requires particular distributions<br />of the unnormalized weights in order to be able to make the simulation algorithm<br />work. Nevertheless, such distributions based on the gamma and inverse–Gaussian<br />distributions are popular choices anyway.<br />Further ideas which need to be worked out include the case when we can generate<br />weights which are decreasing. This for example would make the search for those<br />wj&gt; u are far simpler exercise and would lead to more efficient algorithms.<br />In conclusion, concerning performance of slice–efficient and retrospective sam-<br />plers, we note that once running, both samplers are approximately the same in terms<br />of efficiency and performance. In terms of time efficiency we have found that for<br />large data sets, like the S&amp;P 500 the slice–efficient sampler is more efficient than the<br />retrospective sampler, it takes approximately half the time to run than the retro-<br />spective sampler. The most notable savings of the slice–efficient sampler are in the<br />pre–running work where setting up a slice sampler is far easier than setting up a<br />retrospective sampler.<br />The slice sampler allows the Gibbs sampling step for a finite mixture model to<br />be used at each iteration and introduce a method for updating the truncation point<br />in each iteration. This allows standard methods for finite mixture models to be used<br />directly. For example, Van Gael et al (2008) fit an infinite hidden Markov model<br />using the forward–backward sampler for finite hidden Markov model using the slice<br />sampling idea. This would be difficult to implement in a retrospective framework<br />since the truncation point changes when updating the allocations.<br />20</p>  <p>Page 21</p> <p>References<br />Devroye, L. (1986): “Non–Uniform Random Variate Generation,” Springer–Verlag:<br />New York.<br />Escobar, M.D. 1988. Estimating the means of several normal populations by non-<br />parametric estimation of the distribution of the means. Unpublished Ph.D.<br />dissertation, Department of Statistics, Yale University.<br />Escobar, M.D. (1994). Estimating normal means with a Dirichlet process prior.<br />Journal of the American Statistical Association 89, 268–277.<br />Escobar, M.D. and West, M. (1995). Bayesian density estimation and inference<br />using mixtures. Journal of the American Statistical Association 90, 577–588.<br />Ferguson, T.S. (1973). A Bayesian analysis of some nonparametric problems. Annals<br />of Statistics 1, 209–230.<br />Gilks, W.R., Best, N.G. and Tan, K.K.C. (1995). Adaptive rejection Metropolis<br />sampling within Gibbs sampling. Applied Statistics 44, 455–472.<br />Green, P. J. and Richardson, S. (2001). Modelling heterogeneity with and without<br />the Dirichlet process. Scandinavian Journal of Statistics 28, 355–375.<br />Ishwaran, H. and James, L.F. (2001). Gibbs sampling methods for stick–breaking<br />priors. Journal of the American Statistical Association 96, 161–173.<br />Jacquier, E., Polson, N., and Rossi P.E. (1994). Bayesian Analysis of stochastic<br />volatility models. Journal of Business and Economic Statistics 12, 371–417.<br />Jacquier, E., Polson, N., and Rossi P.E. (2004). Bayesian Analysis of stochastic<br />volatility models with fat tails and correlated errors. Journal of Econometrics<br />122, 185–212.<br />Lijoi, A., Mena, R. H. and Pr¨ unster, I. (2005). Hierarchical Mixture Modeling<br />with Normalized Inverse–Gaussian Priors. Journal of the American Statistical<br />Association 100, 1278–1291.<br />Lijoi, A., Mena, R. H. and Pr¨ uenster, I (2007): “Controlling the reinforcement<br />in Bayesian nonparametric mixture models,” Journal of the Royal Statistical<br />Society B, 69, 715–740.<br />21</p>  <p>Page 22</p> <p>Lo, A.Y. (1984). On a class of Bayesian nonparametric estimates I. Density esti-<br />mates. Annals of Statistics 12, 351–357.<br />MacEachern, S.N. (1994). Estimating normal means with a conjugate style Dirichlet<br />process prior. Communications in Statistics: Simulation and Computation 23,<br />727–741.<br />MacEachern, S.N. and M¨ uller, P. (1998). Estimating mixtures of Dirichlet process<br />models. Journal of Computational and Graphical Statistics 7, 223–238.<br />Neal, R. (2000). Markov chain sampling methods for Dirichlet process mixture<br />models. Journal of Computational and Graphical Statistics 9, 249–265.<br />Papaspiliopoulos, O. and Roberts, G.O. (2008). Retrospective Markov chain Monte<br />Carlo methods for Dirichlet process hierarchical models. Biometrika 95, 169–<br />186.<br />Papaspiliopoulos, O. (2008). A note on posterior sampling from Dirichlet mixture<br />models. Preprint.<br />Sethuraman, J. (1994). A constructive definition of Dirichlet priors. Statistica Sinica<br />4, 639–650.<br />Sokal, A. (1997). Monte Carlo Methods in Statistical Mechanics: Foundations and<br />New Algorithms. Functional Integration (Carg´ ese, 1996) 361of NATO Adv.<br />Sci. Inst. Ser. B Phys., New York: Plenum, 131–192.<br />Smith, A.F.M. and Roberts, G.O. (1993). Bayesian computations via the Gibbs<br />sampler and related Markov chain Monte Carlo methods. Journal of the Royal<br />Statistical Society, Series B 55, 3–23.<br />Van Gael, J., Saatchi, Y., Teh, Y.W., and Ghahramani, Z. (2008). Beam Sam-<br />pling for the Infinite Hidden Markov Model. Technical Report : Engineering<br />Department, University of Cambridge.<br />Walker, S.G. (2007). Sampling the Dirichlet mixture model with slices. Communi-<br />cations in Statistics: Simulation and Computation 36, 45–54.<br />22</p>  <p>Page 23</p> <p>Appendix<br />Simulation for the Inverse–Gaussian model. We wish to simulate from the<br />density g(xj+1)<br />?<br />g(xj+1) ∝ x−3/2<br />j+1(1 − xj+1)−3/2exp−1<br />2<br />?<br />γ2<br />j<br />Λjxj+1<br />+(?∞<br />Λj(1 − xj+1)<br />i=j+1γi)2<br />??<br />.<br />The transformation yj+1=<br />xj+1<br />1−xj+1has the density<br />?<br />g(yj+1) ∝ y−3/2<br />j+1(1 + yj+1)exp−1<br />2<br />?<br />γ2<br />j<br />Λjyj+1<br />+(?∞<br />i=j+1γi)2<br />Λj<br />yj+1<br />??<br />.<br />which can be expressed as a mixture of two generalized inverse–Gaussian distributions<br />?<br />i=j+1<br />wGIG−1/2,γj/Λj,<br />∞<br />?<br />γi/Λj<br />?<br />+ (1 − w)GIG<br />?<br />1/2,γj/Λj,<br />∞<br />?<br />i=j+1<br />γi/Λj<br />?<br />where<br />w =<br />γj<br />?∞<br />i=j+1γi<br />and GIG(p,a,b) denotes a distribution with density<br />(b/a)p/2<br />?√ab2Kp<br />?x(p−1)exp{−(a/x + bx)/2}<br />where Kνdenotes the modified Bessel function of the third kind with index ν.<br />23</p>  <a href="https://www.researchgate.net/profile/Jim_Griffin2/publication/220286498_Slice_sampling_mixture_models/links/00b7d51a4630de552f000000.pdf">Download full-text</a> </div> <div id="rgw21_56ab9e94a3e5b" class="c-box pub-resource-container js-toggle" style=""> <h4 class="lf js-expand-list"><small><a href="javascript:" class="lf">View other sources <span class="ico-expand-list"></span></a></small></h4> <h4 class="lf js-collapse-list hidden"><small><a href="javascript:" class="lf">Hide other sources <span class="ico-collapse-list"></span></a></small></h4> <div class="clear"></div> <div class="scroll-wrapper hidden"> <ul class="files-list c-list" id="rgw22_56ab9e94a3e5b">  <li class="c-list-item pub-resource-item"  data-type="fulltext" id="rgw23_56ab9e94a3e5b"> <span class="ico-pub"></span> <div class="file-content"> <div class="download"> <a href="profile/Jim_Griffin2/publication/220286498_Slice_sampling_mixture_models/links/00b7d51a4630de552f000000.pdf" class="publication-viewer" title="00b7d51a4630de552f000000.pdf">00b7d51a4630de552f000000.pdf</a> </div>  <div class="details">  <span> Available from <a href="profile/Jim_Griffin2">Jim E Griffin</a> &middot; Jan 19, 2016 </span>   </div>    </div> </li>  <li class="c-list-item pub-resource-item"  data-type="fulltext" id="rgw24_56ab9e94a3e5b"> <span class="ico-pub"></span> <div class="file-content"> <div class="download"> <a href="http://kar.kent.ac.uk/24721/1/slice_mix.pdf" target="_blank" rel="nofollow" class="publication-viewer" title="Slice sampling mixture models">Slice sampling mixture models</a> </div>  <div class="details">   Available from <a href="http://kar.kent.ac.uk/24721/1/slice_mix.pdf" target="_blank" rel="nofollow">kar.kent.ac.uk</a>  </div>    </div> </li>  </ul> </div> </div> </noscript> <div class="clearfix"> <div class="action-container">  </div> <div class="pub-legal"> Data provided are for informational purposes only. Although carefully collected, accuracy cannot be guaranteed. The impact factor represents a rough estimation of the journal's impact factor and does not reflect the actual current impact factor. Publisher conditions are provided by RoMEO. Differing provisions from the publisher's actual policy or licence agreement may be applicable. </div>   </div> </div> <div class="clearfix">     <div id="rgw26_56ab9e94a3e5b" class="c-box pub-resource-container js-toggle" style="display: none;"> <h4 class="lf js-expand-list"><small><a href="javascript:" class="lf">View other sources <span class="ico-expand-list"></span></a></small></h4> <h4 class="lf js-collapse-list hidden"><small><a href="javascript:" class="lf">Hide other sources <span class="ico-collapse-list"></span></a></small></h4> <div class="clear"></div> <div class="scroll-wrapper hidden"> <ul class="files-list c-list" id="rgw27_56ab9e94a3e5b">  </ul> </div> </div>   <div id="rgw17_56ab9e94a3e5b" class="similar-publications"> <h2>Similar Publications</h2> <ul class="list-bordered">  <li class="c-list-item li-publication-teaser" id="rgw18_56ab9e94a3e5b"> <div> <h5> <a href="publication/286524469_Rate_exact_Bayesian_adaptation_with_modified_block_priors" class="color-inherit ga-similar-publication-title"><span class="publication-title">Rate exact Bayesian adaptation with modified block priors</span></a>  </h5>  <div class="authors"> <a href="researcher/2026152469_Chao_Gao" class="authors ga-similar-publication-author">Chao Gao</a>, <a href="researcher/15068853_Harrison_H_Zhou" class="authors ga-similar-publication-author">Harrison H. Zhou</a>  </div>  </div> <div class="clear"></div> </li>  <li class="c-list-item li-publication-teaser" id="rgw19_56ab9e94a3e5b"> <div> <h5> <a href="publication/291422204_Nonparametric_Density_Estimation_Based_on_Self-Organizing_Incremental_Neural_Network_for_Large_Noisy_Data" class="color-inherit ga-similar-publication-title"><span class="publication-title">Nonparametric Density Estimation Based on Self-Organizing Incremental Neural Network for Large Noisy Data</span></a>  </h5>  <div class="authors"> <a href="researcher/2095281355_Yoshihiro_Nakamura" class="authors ga-similar-publication-author">Yoshihiro Nakamura</a>, <a href="researcher/2095209091_Osamu_Hasegawa" class="authors ga-similar-publication-author">Osamu Hasegawa</a>  </div>  </div> <div class="clear"></div> </li>  <li class="c-list-item li-publication-teaser" id="rgw20_56ab9e94a3e5b"> <div> <h5> <a href="publication/291437542_Smooth_Kernel_Estimation_of_a_Circular_Density_Function_A_Connection_to_Orthogonal_Polynomials_on_the_Unit_Circle" class="color-inherit ga-similar-publication-title"><span class="publication-title">Smooth Kernel Estimation of a Circular Density Function: A Connection to Orthogonal Polynomials on the Unit Circle</span></a>  </h5>  <div class="authors"> <a href="researcher/2095324564_Yogendra_P_Chaubey" class="authors ga-similar-publication-author">Yogendra P. Chaubey</a>  </div>  </div> <div class="clear"></div> </li>  </ul> </div> </div> </div> </div> </div></div></div>
<div class="clear"></div><div id="rgw40_56ab9e94a3e5b" class="default-footer"> <div id="footer" class="clearfix"> <span class="footer-left"> &copy; 2008&dash;2016 researchgate.net. All rights reserved. </span> <span class="footer-right"> <a href="https://www.researchgate.net/about">About us</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="https://www.researchgate.net/contact">Contact us</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="careers">Careers</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="developers">Developers</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="blog" target="_blank">News</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="application.PrivacyPolicy.html">Privacy</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="application.TermsAndConditions.html">Terms</a> <span class="footer-link-separator" style="padding: 0 5px;">&nbsp;|&nbsp;</span> <a href="advertising?_ref=ft">Advertising</a> <span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="recruiters?_ref=ft">Recruiting</a> </span> </div>  </div></div>
<div id="rgw41_56ab9e94a3e5b">  <div class="header-wrapper-logged-out"> <div id="header"> <div class="header-content"> <a href="" class="g-l-logo"> <svg width="149" height="19"> <image xlink:href="https://c5.rgstatic.net/m/235107188705592/images/template/brand-header-logo.svg" src="https://c5.rgstatic.net/m/238113351022438/images/template/brand-header-logo.png" width="149" height="19"/> </svg> </a> <a href="" class="g-l-logo-ico"> <svg width="127" height="17" viewbox="0 0 127 22"> <image xlink:href="https://c5.rgstatic.net/m/235107188705592/images/template/brand-header-logo.svg" src="https://c5.rgstatic.net/m/238113351022438/images/template/brand-header-logo.png" width="127" height="17"/> </svg> </a> <div id="rgw42_56ab9e94a3e5b" class="header-login-wrapper js-header-login"> <div class="dropdown-right-align"> <div class="login-signup-container lf"> <a href="https://www.researchgate.net/signup.SignUp.html?ev=su_chnl_index&amp;hdrsu=1&amp;_sg=Dp67iwfWt6iLIdRsYqcSOMv1RZAcAyEB2eUo-eChN8rpWtywnxOKkDUT0ZSWby-N" class="dropdown-toggle lf">Join for free</a> </div> <div class="dropdown lf" style="height: 20px;"> <a href="https://www.researchgate.net/application.Login.html" class="js-login-url dropdown-toggle lf">Log in <span class="caret"></span></a> <div class="dropdown-menu"> <div class="header-login-form-wrapper"> <!--[if IE 6]><p class="box-warning" style="margin-bottom: 0;">Sorry, ResearchGate no longer supports the version of Internet Explorer you are using. <a href="http://whatbrowser.org/" rel="nofollow" target="_blank">Update your web browser</a> and then log in. </p><![endif]--> <form method="post" action="https://www.researchgate.net/application.Login.html" class="form-big header-login-form js-login-form" name="loginForm" id="headerLoginForm"> <input type="hidden" name="request_token" value="d85K/KB/XilUx3VgBZSigZbk0l5LltIevi1aKS9D7XpWIYKTc0gbCKfiEMRbe3ICFhL9JKK/gInx6ucP1UkZl2eryODHF6rxZvGwc4oi+q9kcnxtLRNQ33svKmaTkJpm+blDabBWAPe4FODp0nAqBIZyVL8mrMw4XwK7GDCfoMtZms9S/eiEO2jIt2l4Wclg/jTfpRge/R0p7Qvl6+IGOhXl4riVuoNTo+6P5ab/ixKIV5a4cIC3TZfXnvTfs8lD8RFRJ4KE21OMihTAjwK3SbCSHsNKn4FYuLOTnBfKtEg="/> <input type="hidden" name="urlAfterLogin" value="publication/220286498_Slice_sampling_mixture_models"/> <input type="hidden" name="invalidPasswordCount" value="0"/> <input type="hidden" name="headerLogin" value="yes"/> <label for="input-header-login">Email</label> <div class="login-input"> <div class="info-tip-wrapper"> <span class="ico-info js-info"></span> </div> <input type="email" value="" name="login" class="login js-login-input text" id="input-header-login" tabindex="1"/> </div> <div class="clear"></div> <label class="lf" for="input-header-password"> Password </label> <a class="rf forgot-password js-forgot-password" href="application.LostPassword.html">Forgot password?</a> <div class="clear"></div> <input type="password" value="" name="password" class="password js-password-input text" id="input-header-password" tabindex="2"/> <div class="clear"></div> <label class="remember-me" for="headerLoginCookie"> <input type="checkbox" checked="checked" value="yes" name="setLoginCookie" class="lf checkbox" id="headerLoginCookie" tabindex="3"/> Keep me logged in </label> <div class="clear"></div> <input value="Log in" name="loginSubmit" class="btn btn-promote btn-fullwidth btn-large allow-leave js-submit-button" type="submit" tabindex="4"/> </form> <div class="connectors"> <div class="text">or log in with</div> <div class="connector-actions"> <a href="connector/linkedin/" class="li-connect js-li-connect" data-redirect-url="cHVibGljYXRpb24vMjIwMjg2NDk4X1NsaWNlX3NhbXBsaW5nX21peHR1cmVfbW9kZWxz"> <span class="icon ico-linkedin-round-grey"></span> <span class="icon ico-linkedin-round"></span> </a> <a href="connector/facebook/" class="fb-connect middle js-fb-connect" data-redirect-url="cHVibGljYXRpb24vMjIwMjg2NDk4X1NsaWNlX3NhbXBsaW5nX21peHR1cmVfbW9kZWxz"> <span class="icon ico-facebook-round-grey"></span> <span class="icon ico-facebook-round"></span> </a> <a href="connector/google/" class="g-connect js-g-connect" data-redirect-url="cHVibGljYXRpb24vMjIwMjg2NDk4X1NsaWNlX3NhbXBsaW5nX21peHR1cmVfbW9kZWxz"> <span class="icon ico-google-round-grey"></span> <span class="icon ico-google-round"></span> </a> </div> </div> </div> </div> </div> </div> </div> </div> </div> <script type="application/ld+json">
{ "@context" : "http://schema.org",
  "@type" : "Organization",
  "name" : "ResearchGate",
  "url" : "http://www.researchgate.net",
  "logo" : "http://www.researchgate.net/images/template/rg_logo_square_brand.png",
  "sameAs" : [ "https://www.facebook.com/ResearchGate",
    "https://twitter.com/ResearchGate",
    "https://plus.google.com/+researchgate",
    "https://www.linkedin.com/company/researchgate"] 
}
</script> </div> </div><div class="c-signup-bar" id="rgw43_56ab9e94a3e5b"> <div class="banner-contents">   <span class="message">ResearchGate is the professional network for scientists and researchers.</span> <a href="signup.SignUp.html?ev=su_banner" class="btn btn-large btn-promote">Join for free</a>  </div> </div></div>
<script>
rgConfig.backendTime = 403;
</script>
<script src="//c5.rgstatic.net/m/2277196935388619/javascript/lib/yui3/yui/yui-min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/21832295316281274/javascript/yuiLoaderConfig-min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/23178613132105398/javascript/vendor/babel-core/browser-polyfill.min.js" type="text/javascript"></script>
<script>
(function (){
if (typeof YRG === "undefined") {
var xmlHttpRequest = new XMLHttpRequest();
xmlHttpRequest.open("post", "go.Error.html");
xmlHttpRequest.setRequestHeader("Content-Type", "application/json");
xmlHttpRequest.setRequestHeader("Accept", "application/json"); var loadedScripts = "";
if (window.performance && window.performance.getEntriesByType) {
    var result = [];
    var resources = performance.getEntriesByType("resource");
    for (var i in resources) {
        if (resources.hasOwnProperty(i)) {
            result.push({
                name: resources[i].name,
                duration: resources[i].duration
            });
        }
    }
    loadedScripts += "&loadedScripts=" + encodeURIComponent(JSON.stringify(result));
}
if (typeof YUI === "undefined") {
    loadedScripts += "&yuiLoaded=false";
} else {
    loadedScripts += "&yuiLoaded=true";
}
xmlHttpRequest.send("Type=InformationException&message=" + encodeURIComponent("Error loading YUI") + loadedScripts);
}
})();
</script>
<script>if (typeof YRG !== 'undefined') { YRG.use('rg-base',function(Y){Y.applyConfig({ignore: ["css-rg","css-rg2","css-ie","css-modules-publicprofile","css-pow-publicliterature-FollowPublicationPromo","css-pow-application-PdfJsReader","css-pow-publicliterature-PublicationInlineReader"]});Y.use(["rg.core.pagespeed.Monitoring"],function(Y){(function(){Y.rg.createInitialWidget({"data":{"content":{"data":{"profileSmallHeader":{"data":{"profileBadge":{"data":{"fullname":"Jim E Griffin","imageUrl":"https:\/\/i1.rgstatic.net\/ii\/profile.image\/AS%3A272751797731334%401442040504288_m\/Jim_Griffin2.png","profileStats":[],"profileFollowButton":null,"profileReputationScoreNumber":null,"profileUrl":"profile\/Jim_Griffin2","institution":"University of Kent","institutionUrl":false,"widgetId":"rgw4_56ab9e94a3e5b"},"id":"rgw4_56ab9e94a3e5b","partials":[],"templateName":"publicprofile\/stubs\/ProfileBadge.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicprofile.ProfileBadge.html?accountId=3053619","viewClass":null,"yuiModules":["css-modules-publicprofile"],"stylesheets":["modules\/publicprofile.css"],"_isYUI":true},"widgetId":"rgw3_56ab9e94a3e5b"},"id":"rgw3_56ab9e94a3e5b","partials":[],"templateName":"publicprofile\/stubs\/ProfileSmallHeader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicprofile.ProfileSmallHeader.html?publicationUid=220286498","viewClass":null,"yuiModules":["css-modules-publicprofile"],"stylesheets":["modules\/publicprofile.css"],"_isYUI":true},"publication":{"data":{"publicationUid":220286498,"title":"Slice sampling mixture models","journalTitle":"Statistics and Computing","journalDetailsTooltip":{"data":{"journalTitle":"Statistics and Computing","journalAbbrev":"STAT COMPUT","publisher":"Springer Verlag","issn":"0960-3174","impactFactor":"1.62","fiveYearImpactFactor":"1.92","citedHalfLife":">10.0","immediacyIndex":"0.27","eigenFactor":"0.01","articleInfluence":"1.66","widgetId":"rgw6_56ab9e94a3e5b"},"id":"rgw6_56ab9e94a3e5b","partials":[],"templateName":"publicliterature\/stubs\/JournalInfo.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.JournalInfo.html?issn=0960-3174","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"affiliation":false,"type":"Article","details":{"doi":"10.1007\/s11222-009-9150-y","journalInfos":{"journal":"","publicationDate":"01\/2011;","publicationDateRobot":"2011-01","article":"21(1):93-105.","journalTitle":"Statistics and Computing","journalUrl":"journal\/0960-3174_Statistics_and_Computing","impactFactor":1.62}},"source":{"sourceUrl":"http:\/\/dblp.uni-trier.de\/db\/journals\/sac\/sac21.html#KalliGW11","sourceName":"DBLP"},"publicationActions":null,"publicationCoins":{"data":{"tags":[{"key":"ctx_ver","value":"Z39.88-2004"},{"key":"rft_val_fmt","value":"info:ofi\/fmt:kev:mtx:journal"},{"key":"rfr_id","value":"info:sid\/researchgate.net:researchgate"},{"key":"rft_id","value":"info:doi\/10.1007\/s11222-009-9150-y"},{"key":"rft.atitle","value":"Slice sampling mixture models"},{"key":"rft.title","value":"Statistics and Computing"},{"key":"rft.jtitle","value":"Statistics and Computing"},{"key":"rft.volume","value":"21"},{"key":"rft.issue","value":"1"},{"key":"rft.date","value":"2011"},{"key":"rft.pages","value":"93-105"},{"key":"rft.issn","value":"0960-3174"},{"key":"rft.au","value":"Maria Kalli,Jim E. Griffin,Stephen G. Walker"},{"key":"rft.genre","value":"article"}],"widgetId":"rgw7_56ab9e94a3e5b"},"id":"rgw7_56ab9e94a3e5b","partials":[],"templateName":"publicliterature\/stubs\/PublicationCoins.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationCoins.html?publicationUid=220286498","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationAuthors":{"data":{"publicationUid":220286498,"peopleItems":[{"data":{"authorUrl":"researcher\/70950184_Maria_Kalli","authorNameOnPublication":"Maria Kalli","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg","imageSize":"s","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Maria Kalli","profile":{"professionalInstitution":{"professionalInstitutionName":false,"professionalInstitutionUrl":null}},"professionalInstitutionName":false,"professionalInstitutionUrl":null,"url":"researcher\/70950184_Maria_Kalli","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":true,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":false,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"widgetId":"rgw10_56ab9e94a3e5b"},"id":"rgw10_56ab9e94a3e5b","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAuthorItem.html?entityId=70950184&imageSize=l&enableAuthorInviteButton=0","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"largeTooltip":false,"useRebrandedImageStyle":null,"widgetId":"rgw9_56ab9e94a3e5b"},"id":"rgw9_56ab9e94a3e5b","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorItem.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorItem.html?authorUid=70950184&authorNameOnPublication=Maria%20Kalli","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true},{"data":{"authorNameOnPublication":"Jim E Griffin","accountUrl":"profile\/Jim_Griffin2","accountKey":"Jim_Griffin2","imageUrl":"https:\/\/i1.rgstatic.net\/ii\/profile.image\/AS%3A272751797731334%401442040504288_m\/Jim_Griffin2.png","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Jim E Griffin","profile":{"professionalInstitution":{"professionalInstitutionName":"University of Kent","professionalInstitutionUrl":"institution\/University_of_Kent"}},"professionalInstitutionName":"University of Kent","professionalInstitutionUrl":"institution\/University_of_Kent","url":"profile\/Jim_Griffin2","imageUrl":"https:\/\/i1.rgstatic.net\/ii\/profile.image\/AS%3A272751797731334%401442040504288_l\/Jim_Griffin2.png","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":false,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":true,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"accountKey":"Jim_Griffin2","hasInfoPopup":false,"hasTeaserPopup":true,"showContactAuthorButton":true,"widgetId":"rgw12_56ab9e94a3e5b"},"id":"rgw12_56ab9e94a3e5b","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAccountItem.html?entityId=3053619&enableUnfollow=0&imageSize=l&enableFollowButton=0&showContactAuthorButton=1","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"accountInstitution":"University of Kent","score":null,"largeTooltip":false,"useRebrandedImageStyle":null,"authorCount":3,"accountCount":1,"publicationUid":220286498,"widgetId":"rgw11_56ab9e94a3e5b"},"id":"rgw11_56ab9e94a3e5b","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAccountItem.html","templateExtensions":[],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAccountItem.html?accountId=3053619&context=pubdetail_authors_xflw&showContactAuthorButton=1&authorCount=3&accountCount=1&publicationUid=220286498","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true},{"data":{"authorUrl":"researcher\/11566371_Stephen_G_Walker","authorNameOnPublication":"Stephen G. Walker","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg","imageSize":"s","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Stephen G. Walker","profile":{"professionalInstitution":{"professionalInstitutionName":false,"professionalInstitutionUrl":null}},"professionalInstitutionName":false,"professionalInstitutionUrl":null,"url":"researcher\/11566371_Stephen_G_Walker","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":true,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":false,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"widgetId":"rgw14_56ab9e94a3e5b"},"id":"rgw14_56ab9e94a3e5b","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAuthorItem.html?entityId=11566371&imageSize=l&enableAuthorInviteButton=0","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"largeTooltip":false,"useRebrandedImageStyle":null,"widgetId":"rgw13_56ab9e94a3e5b"},"id":"rgw13_56ab9e94a3e5b","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorItem.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorItem.html?authorUid=11566371&authorNameOnPublication=Stephen%20G.%20Walker","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true}],"hasMore":false,"nextOffset":6,"useRebrandedImageStyle":null,"widgetId":"rgw8_56ab9e94a3e5b"},"id":"rgw8_56ab9e94a3e5b","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorList.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorList.html?publicationUid=220286498&context=pubdetail_authors_xflw&showContactAuthorButton=1","viewClass":"views.publicliterature.PublicationDetailAuthorListView","yuiModules":["rg.views.publicliterature.PublicationDetailAuthorListView"],"stylesheets":[],"_isYUI":true},"publicationAbstract":{"data":{"publicationUid":220286498,"abstract":"<noscript><\/noscript><div>We propose a more efficient version of the slice sampler for Dirichlet process mixture models described by Walker (Commun.<br \/>\nStat., Simul. Comput. 36:45&ndash;54, 2007). This new sampler allows for the fitting of infinite mixture models with a wide-range of prior specifications. To illustrate<br \/>\nthis flexibility we consider priors defined through infinite sequences of independent positive random variables. Two applications<br \/>\nare considered: density estimation using mixture models and hazard function estimation. In each case we show how the slice<br \/>\nefficient sampler can be applied to make inference in the models. In the mixture case, two submodels are studied in detail.<br \/>\nThe first one assumes that the positive random variables are Gamma distributed and the second assumes that they are inverse-Gaussian<br \/>\ndistributed. Both priors have two hyperparameters and we consider their effect on the prior distribution of the number of<br \/>\noccupied clusters in a sample. Extensive computational comparisons with alternative &ldquo;conditional&rdquo; simulation techniques for<br \/>\nmixture models using the standard Dirichlet process prior and our new priors are made. The properties of the new priors are<br \/>\nillustrated on a density estimation problem.<\/div>","canEdit":false,"isAdmin":false,"isArtifact":false,"showFullAbstract":false,"widgetId":"rgw15_56ab9e94a3e5b"},"id":"rgw15_56ab9e94a3e5b","partials":[],"templateName":"publicliterature\/stubs\/PublicationAbstract.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationAbstract.html?publicationUid=220286498","viewClass":"views.publicliterature.PublicationAbstractView","yuiModules":["rg.views.publicliterature.PublicationAbstractView"],"stylesheets":[],"_isYUI":true},"publicationKeywords":null,"publicationState":null,"isGuest":true,"isAdminEditingAllowed":false,"isArtifact":false,"figureListWidget":null,"previewImage":"https:\/\/i1.rgstatic.net\/publication\/220286498_Slice_sampling_mixture_models\/links\/00b7d51a4630de552f000000\/smallpreview.png","nativeAdDisclosure":null,"showFollowPublicationButton":false,"followPublicationPromo":{"data":{"widgetId":"rgw16_56ab9e94a3e5b"},"id":"rgw16_56ab9e94a3e5b","partials":[],"templateName":"publicliterature\/stubs\/FollowPublicationPromo.html","templateExtensions":[],"attrs":{"context":null,"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.FollowPublicationPromo.html","viewClass":null,"yuiModules":["css-pow-publicliterature-FollowPublicationPromo"],"stylesheets":["pow\/publicliterature\/FollowPublicationPromo.css"],"_isYUI":true},"widgetId":"rgw5_56ab9e94a3e5b"},"id":"rgw5_56ab9e94a3e5b","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailItem.html","templateExtensions":["generalHelpers"],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailItem.html?publicationUid=220286498&showActionBar=0&showContactAuthorButton=1&showRequestFulltextExperience=0&showNoRgAuthorsRequestFulltextExperience=0&showFollowPublicationPromo=1","viewClass":"views.publicliterature.PublicationDetailItemView","yuiModules":["rg.views.publicliterature.PublicationDetailItemView"],"stylesheets":[],"_isYUI":true},"similarPublications":{"data":{"publicationListItems":[{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":2026152469,"url":"researcher\/2026152469_Chao_Gao","fullname":"Chao Gao","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":15068853,"url":"researcher\/15068853_Harrison_H_Zhou","fullname":"Harrison H. Zhou","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Feb 2016","journal":"The Annals of Statistics","showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/286524469_Rate_exact_Bayesian_adaptation_with_modified_block_priors","usePlainButton":true,"publicationUid":286524469,"feedStubs":null,"hasFeedStubs":false,"impactPoints":"2.18","url":"publication\/286524469_Rate_exact_Bayesian_adaptation_with_modified_block_priors","title":"Rate exact Bayesian adaptation with modified block priors","displayTitleAsLink":true,"authors":[{"id":2026152469,"url":"researcher\/2026152469_Chao_Gao","fullname":"Chao Gao","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":15068853,"url":"researcher\/15068853_Harrison_H_Zhou","fullname":"Harrison H. Zhou","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["The Annals of Statistics 02\/2016; 44(1):318-345. DOI:10.1214\/15-AOS1368"],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/286524469_Rate_exact_Bayesian_adaptation_with_modified_block_priors","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/286524469_Rate_exact_Bayesian_adaptation_with_modified_block_priors\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw18_56ab9e94a3e5b"},"id":"rgw18_56ab9e94a3e5b","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=286524469","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":2095281355,"url":"researcher\/2095281355_Yoshihiro_Nakamura","fullname":"Yoshihiro Nakamura","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2095209091,"url":"researcher\/2095209091_Osamu_Hasegawa","fullname":"Osamu Hasegawa","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Jan 2016","journal":"IEEE transactions on neural networks and learning systems","showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/291422204_Nonparametric_Density_Estimation_Based_on_Self-Organizing_Incremental_Neural_Network_for_Large_Noisy_Data","usePlainButton":true,"publicationUid":291422204,"feedStubs":null,"hasFeedStubs":false,"impactPoints":"4.29","url":"publication\/291422204_Nonparametric_Density_Estimation_Based_on_Self-Organizing_Incremental_Neural_Network_for_Large_Noisy_Data","title":"Nonparametric Density Estimation Based on Self-Organizing Incremental Neural Network for Large Noisy Data","displayTitleAsLink":true,"authors":[{"id":2095281355,"url":"researcher\/2095281355_Yoshihiro_Nakamura","fullname":"Yoshihiro Nakamura","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2095209091,"url":"researcher\/2095209091_Osamu_Hasegawa","fullname":"Osamu Hasegawa","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["IEEE transactions on neural networks and learning systems 01\/2016;  DOI:10.1109\/TNNLS.2015.2489225"],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/291422204_Nonparametric_Density_Estimation_Based_on_Self-Organizing_Incremental_Neural_Network_for_Large_Noisy_Data","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/291422204_Nonparametric_Density_Estimation_Based_on_Self-Organizing_Incremental_Neural_Network_for_Large_Noisy_Data\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw19_56ab9e94a3e5b"},"id":"rgw19_56ab9e94a3e5b","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=291422204","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":2095324564,"url":"researcher\/2095324564_Yogendra_P_Chaubey","fullname":"Yogendra P. Chaubey","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Jan 2016","journal":null,"showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/291437542_Smooth_Kernel_Estimation_of_a_Circular_Density_Function_A_Connection_to_Orthogonal_Polynomials_on_the_Unit_Circle","usePlainButton":true,"publicationUid":291437542,"feedStubs":null,"hasFeedStubs":false,"impactPoints":false,"url":"publication\/291437542_Smooth_Kernel_Estimation_of_a_Circular_Density_Function_A_Connection_to_Orthogonal_Polynomials_on_the_Unit_Circle","title":"Smooth Kernel Estimation of a Circular Density Function: A Connection to Orthogonal Polynomials on the Unit Circle","displayTitleAsLink":true,"authors":[{"id":2095324564,"url":"researcher\/2095324564_Yogendra_P_Chaubey","fullname":"Yogendra P. Chaubey","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":[],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/291437542_Smooth_Kernel_Estimation_of_a_Circular_Density_Function_A_Connection_to_Orthogonal_Polynomials_on_the_Unit_Circle","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/291437542_Smooth_Kernel_Estimation_of_a_Circular_Density_Function_A_Connection_to_Orthogonal_Polynomials_on_the_Unit_Circle\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw20_56ab9e94a3e5b"},"id":"rgw20_56ab9e94a3e5b","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=291437542","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"viewClass":"sidebar","widgetId":"rgw17_56ab9e94a3e5b"},"id":"rgw17_56ab9e94a3e5b","partials":[],"templateName":"publicliterature\/stubs\/SimilarPublications.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.SimilarPublications.html?referencePublicationId=220286498&view=sidebar","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationFulltextPreview":null,"publicationResourcesFulltext":{"data":{"publicationUid":220286498,"publicationResourceList":{"data":{"publicationResourceItems":[{"data":{"publicationUid":220286498,"publicationType":"article","linkId":"00b7d51a4630de552f000000","fileName":"00b7d51a4630de552f000000.pdf","fileUrl":"profile\/Jim_Griffin2\/publication\/220286498_Slice_sampling_mixture_models\/links\/00b7d51a4630de552f000000.pdf","name":"Jim E Griffin","nameUrl":"profile\/Jim_Griffin2","canRemove":false,"fileIcon":"ico-pub","canPreview":true,"hasPublisherLink":null,"hasMetaData":true,"hide":false,"fulltext":"ico-pub","origin":"publication_list","isLastLink":false,"isUserLink":true,"uploadDate":"Jan 19, 2016","fileSize":"287.74 KB","widgetId":"rgw23_56ab9e94a3e5b"},"id":"rgw23_56ab9e94a3e5b","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceItem.html","templateExtensions":["generalHelpers"],"attrs":{"fileRequiredPublicationTypes":["code","coverPage","experimentFindings","method","negativeResults","presentation","rawData","researchProposal","workingPaper","artifact","dataset"]},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceItem.html?publicationUid=220286498&linkId=00b7d51a4630de552f000000&hide=0&disableJavascript=disableJavascript&useAlternativeTemplate=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"publicationUid":220286498,"publicationType":"article","linkId":"0fe09d8b0cf2a39235de0b94","fileName":"Slice sampling mixture models","fileUrl":"http:\/\/kar.kent.ac.uk\/24721\/1\/slice_mix.pdf","name":"kar.kent.ac.uk","nameUrl":"http:\/\/kar.kent.ac.uk\/24721\/1\/slice_mix.pdf","canRemove":false,"fileIcon":"ico-pub","canPreview":true,"hasPublisherLink":null,"hasMetaData":true,"hide":false,"fulltext":"ico-pub","origin":"publication_list","isLastLink":false,"isUserLink":false,"widgetId":"rgw24_56ab9e94a3e5b"},"id":"rgw24_56ab9e94a3e5b","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceItem.html","templateExtensions":["generalHelpers"],"attrs":{"fileRequiredPublicationTypes":["code","coverPage","experimentFindings","method","negativeResults","presentation","rawData","researchProposal","workingPaper","artifact","dataset"]},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceItem.html?publicationUid=220286498&linkId=0fe09d8b0cf2a39235de0b94&hide=0&disableJavascript=disableJavascript&useAlternativeTemplate=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"widgetId":"rgw22_56ab9e94a3e5b"},"id":"rgw22_56ab9e94a3e5b","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceList.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceList.html?publicationUid=220286498&limit=3&disableJavascript=disableJavascript&type=fulltextFile","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"resourceCount":2,"hidden":false,"showMore":false,"fulltext":true,"publicationDownloadCount":{"data":{"value":48,"valueFormatted":"48","widgetId":"rgw25_56ab9e94a3e5b"},"id":"rgw25_56ab9e94a3e5b","partials":[],"templateName":"publicliterature\/stubs\/PublicationDownloadCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDownloadCount.html?publicationUid=220286498","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw21_56ab9e94a3e5b"},"id":"rgw21_56ab9e94a3e5b","partials":[],"templateName":"publicliterature\/stubs\/PublicationResources.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResources.html?publicationUid=220286498&type=fulltextFile&disableJavascript=1","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationResourcesAttachments":{"data":{"publicationUid":220286498,"publicationResourceList":{"data":{"publicationResourceItems":[],"widgetId":"rgw27_56ab9e94a3e5b"},"id":"rgw27_56ab9e94a3e5b","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceList.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceList.html?publicationUid=220286498&limit=3&disableJavascript=disableJavascript&type=attachmentFile","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"resourceCount":0,"hidden":true,"showMore":false,"fulltext":false,"publicationDownloadCount":{"data":{"value":48,"valueFormatted":"48","widgetId":"rgw28_56ab9e94a3e5b"},"id":"rgw28_56ab9e94a3e5b","partials":[],"templateName":"publicliterature\/stubs\/PublicationDownloadCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDownloadCount.html?publicationUid=220286498","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw26_56ab9e94a3e5b"},"id":"rgw26_56ab9e94a3e5b","partials":[],"templateName":"publicliterature\/stubs\/PublicationResources.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResources.html?publicationUid=220286498&type=attachmentFile","viewClass":"views.publicliterature.PublicationResourcesView","yuiModules":["rg.views.publicliterature.PublicationResourcesView"],"stylesheets":[],"_isYUI":true},"publicationText":{"data":{"hide":false,"pages":[{"page":1,"text":"Slice Sampling Mixture Models\nMaria Kalli\u2020, Jim E. Griffin\u2217& Stephen G. Walker\u2217\n\u2020Centre for Health Services Studies, University of Kent\n?Institute of Mathematics, Statistics & Actuarial Science,\nUniversity of Kent\nAbstract\nWe propose a more efficient version of the slice sampler for Dirichlet process\nmixture models described by Walker (2007). This sampler allows the fitting of\ninfinite mixture models with a wide\u2013range of prior specification. To illustrate\nthis flexiblity we develop a new nonparametric prior for mixture models by\nnormalizing an infinite sequence of independent positive random variables and\nshow how the slice sampler can be applied to make inference in this model. Two\nsubmodels are studied in detail. The first one assumes that the positive random\nvariables are Gamma distributed and the second assumes that they are inverse\u2013\nGaussian distributed. Both priors have two hyperparameters and we consider\ntheir effect on the prior distribution of the number of occupied clusters in a\nsample. Extensive computational comparisons with alternative \u201dconditional\u201d\nsimulation techniques for mixture models using the standard Dirichlet process\nprior and our new prior are made. The properties of the new prior are illus-\ntrated on a density estimation problem.\nKeywords: Dirichlet process; Markov chain Monte Carlo; Mixture model; Nor-\nmalized Weights; Slice sampler.\n\u2217Corresponding author: Jim E. Griffin, Institute of Mathematics, Statistics & Actuarial Sci-\nence, University of Kent, Canterbury, U. K. Tel.: +44-1227-823627; Fax: +44-1227-827932; Email:\njeg28@kent.ac.uk\n1"},{"page":2,"text":"1 Introduction\nThe well known and widely used mixture of Dirichlet process (MDP) model was first\nintroduced by Lo (1984). The MDP model, with Gaussian kernel, is given by\n?\nwith K(y;\u03c6) being a normal kernel and P \u223c D(M,P0) . We write P \u223c D(M,P0) to\ndenote that P is a Dirichlet process (Ferguson, 1973) with parameters M > 0, the\nscale parameter, and P0, a distribution on the real line and \u03c6 = (\u00b5,\u03c32) with \u00b5 to\nrepresent the mean and \u03c32the variance of the normal component. Since the advent\nof Markov chain Monte Carlo methods within the mainstream statistics literature\n(Smith and Roberts, 1993), and the specific application to the MDP model (Escobar,\n1988; Escobar, 1994; Escobar and West, 1995), the model has become one of the\nmost popular in Bayesian nonparametrics since it is possible to integrate P from the\nposterior defined by this model.\nVariations of the original algorithm of Escobar (1988) have been numerous; for\nexample, MacEachern (1994); M\u00a8 uller and MacEachern (1998); Neal (2000). All of\nthese algorithms rely on integrating out the random distribution function from the\nmodel, removing the infinite dimensional problem. These are usually referred to as\n\u201cmarginal\u201d methods. Recent ideas have left the infinite dimensional distribution in\nthe model and found ways of sampling a sufficient but finite number of variables\nat each iteration of a Markov chain with the correct stationary distribution. See\nPapaspiliopoulos and Roberts (2008) and Walker (2007); the latter paper using slice\nsampling ideas. These define so\u2013called \u201cconditional\u201d methods.\nThere has recently been interest in defining nonparametric priors for P that move\nbeyond the Dirichlet process (see e.g. Lijoi et al (2007)) in infinite mixture models.\nThese alternative priors allow more control over the prior cluster structure than would\nbe possible with the Dirichlet process. The availability of computational methods for\nposterior inference,that do not integrate out P, allows us to implement these priors.\nThe purpose of this paper is two fold: 1) to develop an efficient version of the\nslice sampling algorithm for MDP models proposed by Walker (2007) and to extend\nit to more general nonparametric priors such as general stick\u2013breaking processes and\nnormalised weights priors and 2) to develop a new class of nonparametric prior for\ninfinite mixture models by normalizing an infinite sequence of positive random vari-\nables, which will be termed a Normalized Weights prior. The lay\u2013out of the paper is\nfP(y) =K(y;\u03c6)dP(\u03c6)\n2"},{"page":3,"text":"as follows. In Section 2 we describe the slice\u2013efficient sampler for the MDP model.\nSection 3 describes the normalized weights prior and discusses constructing a slice\nsampler for infinite mixture models with this prior. Section 4 discusses an applica-\ntion of the normalized weights prior to modelling the hazard in survival analysis and\nSection 5 contains numerical illustrations and an application of the normalized weight\nprior to density estimation. Finally, Section 6 contains conclusions and a discussion.\n2The slice\u2013efficient sampler for the MDP\nIt is well known that P \u223c D(M,P0) has a stick\u2013breaking representation (Sethuraman,\n1994) given by\n\u221e\n?\nwhere the {\u03c6j} are independent and identically distributed from P0and\nw1= z1, wj= zj\nP =\nj=1\nwj\u03b4\u03c6j,\n?\nl<j\n(1 \u2212 zl)\nwith the {zj} being independent and identically distributed from beta(1,M). It is\npossible to integrate P from the posterior defined by the MDP model. However, the\nstick\u2013breaking representation is essential to estimation via the non\u2013marginal methods\nof Papaspiliopoulos and Roberts (2008) and Walker (2007). The idea is that we can\nwrite\n\u221e\n?\nand the key is to find exactly which (finite number of) variables need to be sampled\nto produce a valid Markov chain with correct stationary distribution.\nThe details of the slice sampler algorithm are given in Walker (2007), but we briefly\ndescribe the basis for the algorithm here and note an improvement, also noticed by\nPapaspiliopoulos (2008). The joint density\nfz,\u03c6(y) =\nj=1\nwjK(y;\u03c6j)\nfz,\u03c6(y,u) =\n\u221e\n?\nj=1\n1(u < wj)K(y;\u03c6j)\nis the starting point. Given the latent variable u, the number of mixtures is finite,\nthe indices being Au= {k : wk> u}. One has\nfz,\u03c6(y|u) = N\u22121\nu\n?\nj\u2208Au\nK(y;\u03c6j),\n3"},{"page":4,"text":"and the size of Auis Nu=?\u221e\nfinite number of mixtures provides the observation to give the joint density\nj=11(wj> u).\nOne can then introduce a further latent variable, d, which indicates which of these\nfz,\u03c6(y,u,d) = 1(u < wd)K(y;\u03c6d).\nHence, a complete likelihood function for (z,\u03c6) is available as a simple product of\nterms and crucially d is finite. Without u, d can take an infinite number of values\nwhich would make the implementation of a Markov chain Monte Carlo algorithm\nproblematic.\nWe briefly describe the simulation algorithm, but only provide the sampling pro-\ncedure without derivation since this has appeared elsewhere (Walker, 2007). How-\never, as mentioned earlier, we do sample one of the full conditionals in a different\nand more efficient manner. We sample \u03c0(z,u|\u00b7\u00b7\u00b7) as a block and this involves sam-\npling \u03c0(z|\u00b7\u00b7\u00b7 exclude u) and then \u03c0(u|z,\u00b7\u00b7\u00b7), where \u03c0(z|\u00b7\u00b7\u00b7 exclude u) is obtained\nby integrating out u from \u03c0(z,u|\u00b7\u00b7\u00b7). The distribution \u03c0(z|\u00b7\u00b7\u00b7 exclude u) will be\nthe standard full conditional for a stick\u2013breaking process (see Ishwaran and James\n(2001)). Standard MCMC theory on blocking suggests that this should lead to a\nmore efficient sampler.\nRecall that we have the model\nf(y) =\n\u221e\n?\nj=1\nwjK(y;\u03c6j),\nwhere the {\u03c6j} are independent and identically distributed from P0, the {wj} have a\nstick\u2013breaking process based on the Dirichlet process, described earlier in this section.\nThe variables that need to be sampled at each sweep of a Gibbs sampler are\n{(\u03c6j,zj),j = 1,2,...;(di,ui),i = 1,...,n}.\n1. \u03c0(\u03c6j|\u00b7\u00b7\u00b7) \u221d p0(\u03c6j)?\n2. \u03c0(zj|\u00b7\u00b7\u00b7 exclude u) \u221d beta(zj;aj,bj), where\ndi=jK(yi;\u03c6j).\naj= 1 +\nn\n?\ni=1\n1(di= j)\nand\nbj= M +\nn\n?\ni=1\n1(di> j).\n4"},{"page":5,"text":"3. \u03c0(ui|\u00b7\u00b7\u00b7) \u221d 1(0 < ui< wdi).\n4. P(di= k|\u00b7\u00b7\u00b7) \u221d 1(k : wk> ui)K(yi;\u03c6k).\nObviously, we can not sample all of the (\u03c6j,zj). But it is not required to in order\nto proceed with the chain. We only need to sample up to the integer N for which\nwe have found all the appropriate wkin order to do step 4 exactly. Since the weights\nsum to 1 if we find Nisuch that?Ni\nThere are some important points to make here. First, it is a trivial extension to\nconsider more general stick\u2013breaking processes for which zj\u223c beta(\u03b1j,\u03b2j) indepen-\ndently. Then, in this case, we would have\nk=1wk> 1 \u2212 uithen it is not possible for any of\nthe wk, for k > Ni, to be greater than ui.\naj= \u03b1j+\nn\n?\ni=1\n1(di= j)\nand\nbj= \u03b2j+\nn\n?\ni=1\n1(di> j).\nThis easy extension to more general priors is not a feature of alternative, marginal\nsampling algorithms. Secondly, the algorithm is remarkably simple to implement; all\nfull conditionals are standard.\nLater, for the illustrations and comparison, we will consider two types of slice\nsampler. The \u201cslice\u2013efficient\u201d which is the one described above and the \u201cslice\u201d which\nis the original algorithm appearing in Walker (2007) and is noted by the fact that the\nv is sampled conditional on u in this case.\nThe retrospective sampler (Papaspiliopoulos and Roberts 2008) is an alternative,\nconditional method. The following argument gives some understanding for the dif-\nference between retrospective sampling (which uses Metropolis sampling) and slice\nsampling. Suppose we wish to sample from f(x) \u221d l(x)\u03c0(x) using Metropolis sam-\npling and use \u03c0(x) as the proposal density. Let xcbe the current sample and x\u2217\u223c \u03c0(x)\nand u \u223c Un(0,1), so the new sample xnis x\u2217if u < l(x\u2217)\/l(xc) or else is xc.\nOn the other hand, the slice sampler would work by considering f(x,u) \u221d 1(u <\nl(x))\u03c0(x) and so a move from xcto xnwould work by sampling xnfrom \u03c0(x) restricted\nto {x : l(x)\/l(xc) > u} where u \u223c Un(0,1). So the two sampling strategies are\nusing the same variables but in a fundamentally different way, which allows the slice\nsampling version to always move.\n5"},{"page":6,"text":"This illustration is obviously demonstrated on a simple level, but we believe the\nprinciple applies to the difference between the retrospective sampler and the slice\nsampler for the mixture of Dirichlet process model.\n3 Mixtures Based on Normalized Weights\n3.1 Definition and Properties\nThe slice sampling idea can be extended to mixture models with weights obtained\nvia normalization. The Dirichlet process has been the dominant prior in nonpara-\nmetrics but the definition of alternative nonparametric priors has been a recent area\nof interest. For example, Lijoi et al (2007) define nonparametric priors through the\nnormalization of the generalized Gamma process. We discuss an alternative form of\nnormalization. We consider\nf(y) =\n\u221e\n?\nj=1\nwjK(y;\u03c6j)\nwhere wj= \u03bbj\/\u039b and \u039b =?\u221e\nThese must be constructed so as to ensure that?\u221e\nX is a random variable whose distribution is discrete on the positive integers. For\nexample, we could assume that X = Y +1 where Y follows a geometric distribution.\nThen\nqj= (1 \u2212 \u03b8)\u03b8j\u22121.\nThe parameter \u03b8 controls the rate at which E[\u03bb1],E[\u03bb2],E[\u03bb2],... tends to zero. We\nhave defined a nonparametric prior with two parameters \u03b8 and \u03be. As we will see\nin the following examples, the choice of the distributions \u03c01,\u03c02,\u03c03,... controls the\nproperties of the process. Many other families of nonparametric prior distribution can\nbe generated by different choices of X. For example, we could assume that X = Y +1\nwhere Y follows a Poisson distribution.\nj=1\u03bbj. We will also use \u039bm=?\u221e\nj=m+1\u03bbj. Here the {\u03bbj}\nare positive and will be assigned independent prior distributions, say \u03bbj \u223c \u03c0j(\u03bbj).\nj=1\u03bbj < +\u221e a.s. We suggest\ndefining specific priors by defining E[\u03bbj] = \u03beqjwhere \u03be > 0 and qj= P(X = j) where\nExample 1: Gamma distribution.\nHere we take the {\u03bbj} to be independent gamma distributions, say \u03bbj\u223c Ga(\u03b3j,1).\nTo ensure that \u039b < +\u221e a.s. we take?\u221e\n6\nj=1\u03b3j< +\u221e. Clearly, wj has expectation"},{"page":7,"text":"\u03be = 0.1\u03be = 1\u03be = 10\n\u03b8 = 0.4\n05 10 1520 25\n0\n1000\n2000\n3000\n4000\n5000\n6000\n7000\n8000\n9000\n10000\n05 10152025\n0\n1000\n2000\n3000\n4000\n5000\n6000\n7000\n8000\n9000\n10000\n05 10 1520 25\n0\n1000\n2000\n3000\n4000\n5000\n6000\n7000\n8000\n9000\n10000\n\u03b8 = 0.7\n05 101520 25\n0\n1000\n2000\n3000\n4000\n5000\n6000\n7000\n8000\n9000\n10000\n05 1015 2025\n0\n1000\n2000\n3000\n4000\n5000\n6000\n7000\n8000\n9000\n10000\n05 10 152025\n0\n1000\n2000\n3000\n4000\n5000\n6000\n7000\n8000\n9000\n10000\n\u03b8 = 0.9\n05 10152025\n0\n1000\n2000\n3000\n4000\n5000\n6000\n7000\n8000\n9000\n10000\n0510 152025\n0\n1000\n2000\n3000\n4000\n5000\n6000\n7000\n8000\n9000\n10000\n0510 1520 25\n0\n1000\n2000\n3000\n4000\n5000\n6000\n7000\n8000\n9000\n10000\nFigure 1: Prior distribution of the number of clusters from 30 observations with the\ninfinite Dirichlet prior\nqj and variance qj(1 \u2212 qj)\/(\u03be + 1) and we can interpret \u03be as a mass parameter.\nWe will refer to this model as an infinite Dirichlet prior since if we have a finite\nnumber of unnormalized weights \u03bb1,\u03bb2,...,\u03bbNthen w1,w2,...,wNwould be Dirichlet\ndistributed. In infinite mixture models, the prior distribution on the number of\nclusters from n observations is important. Figure 1 shows this distribution for n = 30.\nLarger values of \u03b8 for fixed \u03be place more mass on larger numbers of clusters (as we\nwould expect since the weights decay increasingly slowly with larger \u03b8). The mass\nparameter \u03be also plays an important role. Larger values of \u03be lead to more dispersed\ndistributions with a larger median value.\nStick\u2013breaking priors were introduced to Bayesian nonparametrics by Ishwaran\nand James (2001). They are defined by two infinite vectors of parameters. Clearly,\nthere is a need to develop priors within this class that have a few hyperparameters to\nallow easy prior specification. The Dirichlet process and Poisson-Dirichlet process are\ntwo such priors and the infinite Dirichlet prior represents another. The stick-breaking\nrepresentation of the infinite Dirichlet prior takes \u03b1j= \u03beqjand \u03b2j= \u03be\n?\n1 \u2212?j\ni=1qi\n?\n.\n7"},{"page":8,"text":"Example 2: Inverse\u2013Gaussian distribution\nThe inverse\u2013Gaussian distribution, IG(\u03b3,\u03b7), has a density function given by\n\u03c0(\u03bb) =\n\u03b3\n\u221a2\u03c0\u03bb\u22123\/2exp\n?\n\u22121\n2\n?\u03b32\n\u03bb+ \u03b72\u03bb\n?\n+ \u03b7\u03b3\n?\n,\nwhere \u03b3 and \u03b7 can be interpreted as a shape and a scale parameter, respectively. We\ntake \u03bbjto follow independent IG(\u03b3j,1) distributions. Then \u039bm=?\u221e\n\u03be = 0.1\u03be = 1\nj=m+1\u03bbjis dis-\n\u03be = 10\n\u03b8 = 0.4\n05 1015 2025\n0\n1000\n2000\n3000\n4000\n5000\n6000\n7000\n8000\n9000\n10000\n05 10152025\n0\n1000\n2000\n3000\n4000\n5000\n6000\n7000\n8000\n9000\n10000\n0510 152025\n0\n1000\n2000\n3000\n4000\n5000\n6000\n7000\n8000\n9000\n10000\n\u03b8 = 0.7\n05 10152025\n0\n1000\n2000\n3000\n4000\n5000\n6000\n7000\n8000\n9000\n10000\n0510152025\n0\n1000\n2000\n3000\n4000\n5000\n6000\n7000\n8000\n9000\n10000\n05101520 25\n0\n1000\n2000\n3000\n4000\n5000\n6000\n7000\n8000\n9000\n10000\n\u03b8 = 0.9\n0510 152025\n0\n1000\n2000\n3000\n4000\n5000\n6000\n7000\n8000\n9000\n10000\n05 10152025\n0\n1000\n2000\n3000\n4000\n5000\n6000\n7000\n8000\n9000\n10000\n05 1015 2025\n0\n1000\n2000\n3000\n4000\n5000\n6000\n7000\n8000\n9000\n10000\nFigure 2: Prior distribution of the number of clusters for infinite normalized inverse\u2013\nGaussian prior\ntributed as IG(?\u221e\nbution (\u03bb1\/\u039b,\u03bb2\/\u039b,...,\u03bbm\/\u039b) has been studied by Lijoi et al. (2005) as the normal-\nized inverse\u2013Gaussian distribution. We again define \u03b3j= \u03beqjand it follows directly\nfrom their results that wihas expectation qiand variance qi(1\u2212qi)\u03be2exp{\u03be}\u0393(\u22122,\u03be).\nThis prior will be referred to as the infinite normalized inverse\u2013Gaussian prior. Fig-\nure 2 shows the prior distribution of the number of clusters in 30 observations. The\neffects of \u03be and \u03b8 follow the same pattern as the infinite Dirichlet case discussed above.\nHowever, the effect of \u03be is less marked for small \u03be. In the infinite Dirichlet case for\n\u03be = 0.1, the distributions are almost indistinguishable for different values of \u03b8 but in\nj=m+1\u03b3j,1) and the normalization is well\u2013defined if?\u221e\nj=1\u03b3j< +\u221e\nwhich implies that \u039b is almost surely finite. The finite dimensional normalized distri-\n8"},{"page":9,"text":"this case it is clear that the location of the distribution is increasing with \u03b8. This\nallows easier prior specification for the infinite normalized\u2013inverse Gaussian prior\n3.2Slice sampler\nThe model can be fitted using an extension of the slice sampler developed in section 2.\nWe will assume that the distribution of \u039bmhas a known form for all m, which we will\ndenote by \u03c0?\ntrickier. Simpler updating is possible when we introduce the additional latent variable\nv, and consider the joint density\nm(\u039bm). The introduction of a normalizing constant, \u039b, makes MCMC\nf(y,v,u,d) = exp(\u2212v\u039b)1(u < \u03bbd)K(y;\u03c6d).\nClearly the marginal density\nf(y,d) =\u03bbd\n\u039bK(y;\u03c6d),\nas required. The likelihood function based on a sample of size n is given by\nn\n?\ni=1\nexp(\u2212vi\u039b)1(ui< \u03bbdi)K(yi;\u03c6di).\nWe will only consider those conditional distributions which are not immediately triv-\nial; those that are completely trivial being ui, viand \u03c6j. The distribution of diis\ntrivial but as before we need to find the number of \u03bbj\u2019s (and also \u03c6j\u2019s) to be sampled\nin order to implement the sampling of di.\nHence, the non\u2013trivial aspect to the algorithm is the sampling of the sufficient\nnumber of {\u03bbj} and \u039b. We will, as before, work on the conditional distribution\nof the ({\u03bbj},\u039b) excluding the {ui}. We simulate \u03bb1,...,\u03bbm,\u039bm (where m is the\nnumber of atoms given in the previous iteration) in a block from their full conditional\ndistribution which is proportional to\nexp{\u2212V \u039bm}\u03c0?\nm(\u039bm)\nm\n?\ni=1vi. We need to find the smallest value of\nj=1\nexp{\u2212V \u03bbj}\u03bbnj\nj\u03c0j(\u03bbj),\nwhere nj=?n\nof di. This value can be found by sequentially simulating [\u03bbj,\u039bj|\u039bj\u22121] for j = m +\n1,...,m?. The conditional distribution of [\u03bbj= x,\u039bj= \u039bj\u22121\u2212 x|\u039bj\u22121] is given by\nf(x) \u221d \u03c0j(x)\u03c0?\ni=11(di= j) and V =?n\nm?for which \u039bm? < mini{ui} so that we can evaluate the full conditional distribution\nj(\u039bj\u22121\u2212 x),0 < x < \u039bj\u22121.\n9"},{"page":10,"text":"In some cases simulation from the distribution will be straightforward. If not, generic\nunivariate simulation methods such as Adaptive Rejection Metropolis Sampling (Gilks\net al. 1995) can be employed. We now consider a couple of examples.\nExample 1: Gamma distribution\nIt is easy to see that\n\u03c0(\u03bb1\/\u039b,...,\u03bbm\/\u039b|\u039b,\u00b7\u00b7\u00b7 , exclude u) = Dir\n?\n\u03b31+ n1,...,\u03b3m+ nm,\n\u221e\n?\nl=m+1\n\u03b3l\n?\nand\n\u039bm\u223c Ga\n?\n\u221e\n?\nj=m+1\n\u03b3j,1 + V\n?\n.\nThe conditional distribution of \u03bbj\/\u039bj is Be(\u03b3j,?\u221e\ni=j+1\u03b3i). This prior can also be\nrepresented as a stick\u2013breaking prior.\nExample 2: Inverse\u2013Gaussian distribution\nThe full conditional distribution of \u03bbjis given by\n\u03c0(\u03bbj|\u00b7\u00b7\u00b7) \u221d \u03bbnj\u22123\/2\nj\nexp\n?\n\u22121\n2\n?\u03b32\nj\n\u03bbj\n+ (1 + 2V )\u03bbj\n??\n,\nwhere njis the number of observations allocated to component j. The full conditional\ndistribution of \u039bmis proportional to\n?\nThese are both generalized inverse\u2013Gaussian distributions which can be simulated\ndirectly; see e.g. Devroye (1986).\nWe can simulate from [\u03bbj+1,\u039bj+1|\u039bj] by defining \u03bbj+1 = xj+1\u039bj and \u039bj+1 =\n(1 \u2212 xj+1)\u039bjwhere the density of xj+1is given by\n?\n\u039b\u22123\/2\nm\nexp\u22121\n2\n?(?\u221e\ni=m+1\u03b3i)2\n\u03bbj\n+ (1 + 2V )\u03bbj\n??\n.\ng(xj+1) \u221d x\u22123\/2\nj+1(1 \u2212 xj+1)\u22123\/2exp\u22121\n2\n?\n\u03b32\nj\n\u039bjxj+1\n+(?\u221e\n\u039bj(1 \u2212 xj+1)\ni=j+1\u03b3i)2\n??\n.\nUnlike the gamma case, this conditional distribution depends on \u039bm. The distribution\nof xj+1\/(1\u2212xj+1) can be identified as a two\u2013mixture of generalized inverse\u2013Gaussian\ndistributions and hence can be sampled easily (details are given in the Appendix).\n10"},{"page":11,"text":"4 Hazard Functions\nThe normalized procedure can also be applied to the modeling of random hazard\nfunctions. Suppose we model the unknown hazard function h(t), for t > 0, using a\nset of known functions {hk(t)}\u221e\n\u221e\n?\nHere the {\u03bbk> 0} are the model parameters and can be assigned independent gamma\nprior distributions; say \u03bbk\u223c Ga(ak,bk). Obviously we will need to select (ak,bk) to\nensure that h(t) < +\u221e a.s. for all t < +\u221e. The corresponding density function is\ngiven by\n\u221e\n?\nwhere Hkis the cumulative hazard corresponding to hk.\nSo with observations {ti}n\nn\n?\nOur approach is based on the introduction of a latent variable, say u, so that we\nconsider the joint density with t given by\nk=1, via\nh(t) =\nk=1\n\u03bbkhk(t).\nf(t) =\nk=1\n\u03bbkhk(t) exp\n?\n\u2212\n\u221e\n?\nk=1\n\u03bbkHk(t)\n?\n,\ni=1, the likelihood function is given by\n?\u221e\nk=1\nl(\u03bb|t) \u221d\ni=1\n?\n\u03bbkhk(ti) exp\n?\n\u2212\n\u221e\n?\nk=1\n\u03bbkHk(ti)\n??\n.\nf(t,u) =\n\u221e\n?\nk=1\n1(u < \u03bbk)hk(t) exp\n?\n\u2212\n\u221e\n?\nk=1\n\u03bbkHk(t)\n?\n.\nA further latent variable d picks out the mixture component from which (t,u) come,\nf(t,u,d) = 1(u < \u03bbd)hd(t) exp\n?\n\u2212\n\u221e\n?\nk=1\n\u03bbkHk(t)\n?\n.\nWe will now introduce the key latent variables, one for each observation, and label\nthem (ui,di), into the likelihood, which is given by\nl(\u03bb|t,u,d) \u221d\nn\n?\ni=1\n1(ui< \u03bbdi)hdi(ti) exp\n?\n\u2212\n\u221e\n?\nk=1\n\u03bbkHk(ti)\n?\n.\nThe point is that the choice of diis finite. It is now clear that the sampling algorithm\nfor this model is basically the same now as for the normalized case. We could take\n11"},{"page":12,"text":"the \u03bbj to be gamma with parameters aj+?\nsample the diwe need to find all the \u03bbjgreater than ui. We can do this by sampling\n\u039bM =?\nfound all the \u03bbj> ui, we can sample difrom Pr(di= j) \u221d 1(\u03bbj> ui)hj(ti).\ndi=j1 and bj+?\ndi=jHj(ti) and we\nwould first sample up to M = maxidi. Then the uiare from Un(0,\u03bbdi). In order to\nj>M\u03bbj as a gamma distribution and then sampling [\u03bbM+1,...\u03bbNi]|\u039bM so\nthat Niis the smallest integer for which?Ni\nj=M+1\u03bbj> \u039bM\u2212ui. Finally, once we have\n5Illustration and Comparisons\nIn this section we carry out a comparison of the slice sampling algorithm with the\nretrospective sampler using the Dirichlet process and the normalized weights prior.\nThe algorithms are compared using the normal kernel K(y|\u03c6) with components \u03c6 =\n(\u00b5,\u03b6), and P0(\u00b5,\u03b6) = N(\u00b5|\u00b50,\u03be2) \u00d7 G(\u03b6|\u03b3,\u03b2). Here G(\u03b3,\u03b2) denotes the gamma\ndistribution. We also consider inference for the commonly used galaxy data set with\nthe infinite Dirichlet and infinite normalized inverse\u2013Gaussian priors.\nFor comparison purposes we consider two real data sets and two simulated data\nsets. The real data sets are:\n1. Galaxy data set which consists of the velocities of 82 distant galaxies diverging\nfrom our own galaxy. This is the most commonly used data set in density\nestimation studies, due to its mulimodality. We will also use it to illustrate the\neffect of the prior choice on the posterior density in Section 5.3.\n2. S & P 500 data set which consist of 2023 daily index returns. This is yet another\ncommonly used data set in density estimation and volatility studies of financial\nasset returns; see, Jacquier, Polson, and Rossi (1994, 2004). This data set is\nunimodal, not necessarily symmetric, around zero, and it is characterized by\nheavy tails.\nWe chose these data sets because of their size, as we would like to study the\nperformance of the algorithms on both small and large data sets.\nThe simulated data sets are based on the models used in Green and Richardson\n(2001) and consist of 100 draws from a bimodal and a leptokurtic mixture.\n1. The bimodal mixture: 0.5N(\u22121,0.52) + 0.5N(1,0.52).\n2. The leptokurtic mixture: 0.67N(0,1) + 0.33N(0.3,0.252).\n12"},{"page":13,"text":"Both of these simulated data sets were used in the algorithm comparison study\ncarried out in Papaspiliopoulos and Roberts (2008); since we are comparing our slice\nsampler with the retrospective sampler, we decided to use these simulated data sets.\nThe parameters for our MDP mixture are also set according to Green and Richard-\nson (2001). If R is the range of the data; then we take \u00b50= R\/2, \u03be = R, \u03b3 = 2, and\n\u03b2 = 0.2R2. The precision parameter of the Dirichlet Process is set at M = 1. In the\ncomparison of the estimates of the statistics used, we took the Monte Carlo sample\nsize to be S = 250,000 for each algorithm, with the initial 10,000 used as a burn\nin period. Density estimates using the retrospective and slice\u2013efficient samplers are\nshown in figure 3 for the Dirichlet process mixture model.\nBi\u2013modalLeptokurticS & P 500\n(a)\n\u22123\u22122 \u221210123\n0\n0.05\n0.1\n0.15\n0.2\n0.25\n0.3\n0.35\n\u22123 \u22122 \u221210123\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n\u22126\u22124 \u221220246\n0\n0.05\n0.1\n0.15\n0.2\n0.25\n0.3\n0.35\n0.4\n0.45\n0.5\n(b)\n\u22123 \u22122\u221210123\n0\n0.05\n0.1\n0.15\n0.2\n0.25\n0.3\n0.35\n\u22123 \u22122 \u221210123\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n\u22126 \u22124\u221220246\n0\n0.05\n0.1\n0.15\n0.2\n0.25\n0.3\n0.35\n0.4\n0.45\n0.5\nFigure 3: Predictive densities: (a) retrospective and (b) slice\u2013efficient\n5.1 Algorithmic performance\nTo monitor the performance of the algorithms we look at the convergence of two\nquantities:\n\u2022 The number of clusters: at each iteration there are j = 1,...,N clusters of\nthe i = 1,...,n data points with mj being the size of the j cluster, so that\n?N\n\u2022 The deviance, D, of the estimated density, calculated as\nn\n?\nj=1mj= n.\nD = \u22122\ni=1\nlog\n??\nj\nmj\nnK(yi|\u03c6j)\n?\n.\n13"},{"page":14,"text":"These variables have been used in the previous comparison studies of Papaspiliopoulos\nand Roberts (2008), Green and Richardson (2001) and Neal (2000). Here D is one\nof the most common functionals used in comparing algorithms, because it is seen as\na global function of all model parameters. Although we produce this variable and\nstudy its algorithmic performance we are also concerned with the convergence of the\nnumber of clusters.\nThe efficiency of the algorithms is summarized by computing an estimate ? \u03c4 of the\ntion time is defined in Sokal (1997) as\nintegrated autocorrelation time, \u03c4, for each of the variables. Integrated autocorrela-\n\u03c4 =1\n2+\n\u221e\n?\nl=1\n\u03c1l.\nwhere \u03c1l is the autocorrelation at lag l. An estimate of \u03c4 has been used in Pa-\npaspiliopoulos and Roberts (2008), Green and Richardson (2001) and Neal (2000).\nIntegrated autocorrelation time is of interest as it controls the statistical error in\nMonte Carlo measurements of a desired function f. To clarify this point, consider\nthe Monte Carlo sample mean,\n\u00aff \u22611\nS\nS\n?\nl=1\nfj,\nwhere S is the number of iterations. The variance of\u00aff according to Sokal (1997) is\nVar(\u00aff) \u22481\nS2\u03c4 \u00d7 V,\nwhere V is the marginal variance. Sokal (1997) concludes that Var(\u00aff) is a factor\n2\u03c4 larger than what it would be if the {fj} were statistically independent. In other\nwords, \u03c4 determines the statistical error of the Monte Carlo measurements of f once\nequilibrium has been attained. Therefore a run of S iterations contains only S\/(2\u03c4)\n\u201ceffectively independent data points\u201d. This means that the algorithm with the smallest\nestimated value of \u03c4 will be the most efficient. The problem with the calculation of \u03c4\nlies in accurately estimating the covariance between the states, which in turn is used\nto calculate the autocorrelation \u03c1l. It must be noted that in MCMC the covariance\nand the autocorrelation are not single values but random variables. Based on Sokal\n(1997) the estimator for \u03c4 is given by\n? \u03c4 =1\n2+\nC\u22121\n?\nl=1\n? \u03c1l.\n14"},{"page":15,"text":"where ? \u03c1lis the estimated autocorrelation at lag l (obtained via MatLab) and C is\ncommonly done,\nC = min\na cut\u2013off point, normally set by the researcher. In our comparisons we define, as is\n?\nl : |? \u03c1l| < 2\/\u221aS\n?\n.\nThen C is the smallest lag for which we would not reject the null hypothesis H0:\n\u03c1l= 0. A similar approach has also been used in Papaspiliopoulos (2008). The issue\nhere, see Sokal (1997), is the cut off point C; it introduces bias equal to\n?\nOn the other hand, the variance of ? \u03c4 can be computed using\nBias(? \u03c4) =1\n2\n|l|>C\n\u03c1l+ o\n?1\nS\n?\n.\nVar(? \u03c4) \u22482(2C \u2212 1)\nS\n\u03c42.\nThe choice of C will be a trade off between the bias and the variance of \u02c6 \u03c4, which\nmeans that we really cannot say how \u201cgood\u201d an algorithm is since the choice of C\npoint is left to the researcher. According to Sokal (1997), this approach works well\nwhen a sufficient quantity of data is available which we can control by running the\nsampler for a sufficient number of iterations.\n5.2Results\nThe following tables compare the estimated integrated autocorrelation time ? \u03c4 of the\ntwo variables of interest; the number of clusters and the deviance.\n5.2.1 Dirichlet process\nLooking at the estimates of ? \u03c4 for the real data sets we come to the following conclu-\n\u2022 For the galaxy data set there is little difference between the two samplers. Even\nthough the retrospective sampler performs marginally better, the slice\u2013efficient\nsampler is easier to use as simulating the z and k is carried out in an easy way,\nas opposed to the complexity of the set up of the retrospective sampling steps.\nsions:\n\u2022 For the S&P data set which is large, unimodal, asymmetric and heavy\u2013tailed,\nit is the slice\u2013efficient sampler that outperforms the retrospective sampler, in\nterms of ? \u03c4 for the number of clusters; ? \u03c4 for the slice\u2013efficient sampler is about\n15\nhalf that of the retrospective sampler."},{"page":16,"text":"Galaxy data\n? \u03c4 for ? clust\n10.2868\n6.7677\nLeptokurtic data\n? \u03c4 for ? clust\n33.0470\n13.6639\n? \u03c4 for D\n4.3849\n2.9857\n? \u03c4 for D\n26.0547\n9.3014\nSlice\nSlice\u2013efficient\nRetrospective\n31.5268 10.2683157.0064 119.3368\nBimodal data\n? \u03c4 for ? clust\n26.8114\n14.7202\nS&P 500 data\n? \u03c4 for ? clust\n4.1923\n7.1464\n? \u03c4 for D\n10.8374\n7.1603\n? \u03c4 for D\n5.2390\n1.5779\nSlice\nSlice\u2013efficient\nRetrospective\n167.499554.6059 142.6566 81.4236\nTable 1: Estimates of the integrated autocorrelation times for the deviance (D) and\nfor the number of clusters with four data sets with the Dirichlet process mixture\nmodel\nGalaxy Bimodal Leptokurtic S & P 500\n?\nclust\n0 50 100 150 200250 300350400450 500\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\n050100 150200250300 350400450500\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\n050100150200250300 350400450 500\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\n0 50 100 150200 250300350400 450500\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\nDev.\n0 50100 150 200250 300350400450500\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\n050 100150 200250300350400 450500\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\n0 50 100150200 250300350400 450500\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\n050100 150200 250300350400450 500\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\nFigure 4: Autocorrelation of MCMC output for: slice sampler (red), efficient slice\nsampler (blue) and retrospective sampler (green)\n5.2.2Mixtures based on normalized weights\nWe reject the slice sampler in favour of the slice\u2013efficient sampler. We use the infinite\nDirichlet and infinite normalized inverse\u2013Gaussian mixtures models with \u03be = 1 and\n\u03b8 = 0.5 on the four data sets. We find similar performance for the normalized weights\nprior as for the Dirichlet process prior. The retrospective sampler is usually more\nefficient than the slice sampler with a two times relative improvement on average.\n16"},{"page":17,"text":"Galaxy data\n? \u03c4 for ? clust\n27.12\nLeptokurtic data\n? \u03c4 for ? clust\n48.32\n? \u03c4 for D\n7.08\n? \u03c4 for D\n29.13\nSlice\u2013efficient\nRetrospective\n25.5012.21115.3679.70\nBimodal data\n? \u03c4 for ? clust\n44.05\nS&P 500 data\n? \u03c4 for ? clust\n14.17\n? \u03c4 for D\n8.64\n? \u03c4 for D\n3.22\nSlice\u2013efficient\nRetrospective\n64.1917.0321.6911.99\nTable 2: Estimates of the integrated autocorrelation times for the deviance (D) and\nfor the number of clusters with four data sets with the infinite Dirichlet distribution\nmixture model\nThe improvement is typically larger for the simulated rather than the real data sets.\nThe effect is also more pronounced for the infinite Dirichlet distribution prior rather\nthan the infinite normalized inverse\u2013Gaussian prior.\nGalaxy data\n? \u03c4 for ? clust\n16.91\nLeptokurtic data\n? \u03c4 for ? clust\n27.63\n? \u03c4 for D\n4.75\n? \u03c4 for D\n21.52\nSlice\u2013efficient\nRetrospective\n22.41 8.89 41.95 31.64\nBimodal data\n? \u03c4 for ? clust\n23.20\nS&P 500 data\n? \u03c4 for ? clust\n85.57\n? \u03c4 for D\n9.45\n? \u03c4 for D\n3.01\nSlice\u2013efficient\nRetrospective\n34.72 15.79 28.42 8.38\nTable 3: Estimates of the integrated autocorrelation times for the deviance (D) and\nfor the number of clusters with four data sets with the infinite normalized inverse\u2013\nGaussian distribution mixture model\nThese results are not surprising. The slice sampler introduces auxiliary variables\nto help simulation which will slow convergence through over\u2013conditioning. The slice\u2013\nefficient sampler reduces this effect by jointly updating u and \u03bb (or V in the Dirichlet\n17"},{"page":18,"text":"process case) in a block. The retrospective sampler will mix slowly when the proposal\ndistribution is a poor approximation to the full conditional distribution. Therefore it\nis usually difficult to be sure about the ranking of the methods. In these illustrations,\nwe have seen examples where the slice\u2013efficient sampler is more efficient than the\nretrospective sampler.\n5.3Inference for the Normalized Weights Priors\nThe galaxy data has been a popular data set in Bayesian nonparametric modelling\nand we will illustrate the infinite Dirichlet and infinite normalized inverse\u2013Gaussian\npriors on it. The posterior mean density estimates are shown in figure 5 for the in-\nfinite Dirichlet prior and figure 6 for the infinite normalized inverse\u2013Gaussian prior.\nThe hyperparameters of the prior distributions have a clear effect on the posterior\n\u03be = 0.1\u03be = 1\u03be = 10\n\u03b8 = 0.4\n10 20 30 40\n0\n0.05\n0.1\n0.15\n0.2\n0.25\n10 20 3040\n0\n0.05\n0.1\n0.15\n0.2\n0.25\n10 2030 40\n0\n0.05\n0.1\n0.15\n0.2\n0.25\n\u03b8 = 0.7\n10 20 3040\n0\n0.05\n0.1\n0.15\n0.2\n0.25\n10 20 3040\n0\n0.05\n0.1\n0.15\n0.2\n0.25\n10 20 3040\n0\n0.05\n0.1\n0.15\n0.2\n0.25\n\u03b8 = 0.9\n10 20 3040\n0\n0.05\n0.1\n0.15\n0.2\n0.25\n1020 30 40\n0\n0.05\n0.1\n0.15\n0.2\n0.25\n102030 40\n0\n0.05\n0.1\n0.15\n0.2\n0.25\nFigure 5: Posterior mean density estimates for the galaxy data using the infinite\nDirichlet prior with different values of M and \u03b8\nmean estimates. Prior distributions that places more mass on a small number of com-\nponents tend to find estimates with three clear modes. As the prior mean number\nof components increases so do the number of modes in the estimate from 4 to 5 for\n18"},{"page":19,"text":"the prior within each class that places most mass on a large number of components\n(\u03be = 10 and \u03c6 = 0.9). However, there are some clear differences between the two\n\u03be = 0.1\u03be = 1\u03be = 10\n\u03b8 = 0.4\n1020 3040\n0\n0.05\n0.1\n0.15\n0.2\n0.25\n10 20 30 40\n0\n0.05\n0.1\n0.15\n0.2\n0.25\n10 203040\n0\n0.05\n0.1\n0.15\n0.2\n0.25\n\u03b8 = 0.7\n10 20 30 40\n0\n0.05\n0.1\n0.15\n0.2\n0.25\n10 2030 40\n0\n0.05\n0.1\n0.15\n0.2\n0.25\n10 2030 40\n0\n0.05\n0.1\n0.15\n0.2\n0.25\n\u03b8 = 0.9\n10 20 30 40\n0\n0.05\n0.1\n0.15\n0.2\n0.25\n102030 40\n0\n0.05\n0.1\n0.15\n0.2\n0.25\n102030 40\n0\n0.05\n0.1\n0.15\n0.2\n0.25\nFigure 6: Posterior mean density estimates for the galaxy data using the infinite\nnormalized inverse\u2013Gaussian prior with different values of \u03be and \u03b8\nclasses of prior. The effects of the two hyperparameters on the prior distribution\nof the number of non\u2013empty components were more clearly distinguishable in the\ninfinite normalized inverse\u2013Gaussian prior than the infinite Dirichlet prior. In the\ninfinite normalized inverse\u2013Gaussian prior \u03b8 controls the mean number of non\u2013empty\ncomponents whereas \u03be controls the dispersion around the mean. This property is car-\nried forward to the posterior mean density and the number of modes in the posterior\nmean increases with \u03b8. For example, when \u03be = 0.1, there are three modes in the\nposterior mean if \u03b8 = 0.4 whereas there are 4 when \u03b8 = 0.9. Similarly, larger values\nof \u03be are associated with larger variability in the prior mean and favour distributions\nwhich uses a larger number of components. This suggests that infinite normalized\ninverse\u2013Gaussian distribution may be a more easily specified prior distribution than\nthe infinite Dirichlet prior.\n19"},{"page":20,"text":"6 Conclusions and Discussion\nThis paper has shown how mixture models based on random probability measures, of\neither the stick\u2013breaking or normalized types, can be easily handled via the introduc-\ntion of a key latent variable which makes finite the number of mixtures. The more\ncomplicated of the two is the normalized type, which requires particular distributions\nof the unnormalized weights in order to be able to make the simulation algorithm\nwork. Nevertheless, such distributions based on the gamma and inverse\u2013Gaussian\ndistributions are popular choices anyway.\nFurther ideas which need to be worked out include the case when we can generate\nweights which are decreasing. This for example would make the search for those\nwj> u are far simpler exercise and would lead to more efficient algorithms.\nIn conclusion, concerning performance of slice\u2013efficient and retrospective sam-\nplers, we note that once running, both samplers are approximately the same in terms\nof efficiency and performance. In terms of time efficiency we have found that for\nlarge data sets, like the S&P 500 the slice\u2013efficient sampler is more efficient than the\nretrospective sampler, it takes approximately half the time to run than the retro-\nspective sampler. The most notable savings of the slice\u2013efficient sampler are in the\npre\u2013running work where setting up a slice sampler is far easier than setting up a\nretrospective sampler.\nThe slice sampler allows the Gibbs sampling step for a finite mixture model to\nbe used at each iteration and introduce a method for updating the truncation point\nin each iteration. This allows standard methods for finite mixture models to be used\ndirectly. For example, Van Gael et al (2008) fit an infinite hidden Markov model\nusing the forward\u2013backward sampler for finite hidden Markov model using the slice\nsampling idea. This would be difficult to implement in a retrospective framework\nsince the truncation point changes when updating the allocations.\n20"},{"page":21,"text":"References\nDevroye, L. (1986): \u201cNon\u2013Uniform Random Variate Generation,\u201d Springer\u2013Verlag:\nNew York.\nEscobar, M.D. 1988. Estimating the means of several normal populations by non-\nparametric estimation of the distribution of the means. Unpublished Ph.D.\ndissertation, Department of Statistics, Yale University.\nEscobar, M.D. (1994). Estimating normal means with a Dirichlet process prior.\nJournal of the American Statistical Association 89, 268\u2013277.\nEscobar, M.D. and West, M. (1995). Bayesian density estimation and inference\nusing mixtures. Journal of the American Statistical Association 90, 577\u2013588.\nFerguson, T.S. (1973). A Bayesian analysis of some nonparametric problems. Annals\nof Statistics 1, 209\u2013230.\nGilks, W.R., Best, N.G. and Tan, K.K.C. (1995). Adaptive rejection Metropolis\nsampling within Gibbs sampling. Applied Statistics 44, 455\u2013472.\nGreen, P. J. and Richardson, S. (2001). Modelling heterogeneity with and without\nthe Dirichlet process. Scandinavian Journal of Statistics 28, 355\u2013375.\nIshwaran, H. and James, L.F. (2001). Gibbs sampling methods for stick\u2013breaking\npriors. Journal of the American Statistical Association 96, 161\u2013173.\nJacquier, E., Polson, N., and Rossi P.E. (1994). Bayesian Analysis of stochastic\nvolatility models. Journal of Business and Economic Statistics 12, 371\u2013417.\nJacquier, E., Polson, N., and Rossi P.E. (2004). Bayesian Analysis of stochastic\nvolatility models with fat tails and correlated errors. Journal of Econometrics\n122, 185\u2013212.\nLijoi, A., Mena, R. H. and Pr\u00a8 unster, I. (2005). Hierarchical Mixture Modeling\nwith Normalized Inverse\u2013Gaussian Priors. Journal of the American Statistical\nAssociation 100, 1278\u20131291.\nLijoi, A., Mena, R. H. and Pr\u00a8 uenster, I (2007): \u201cControlling the reinforcement\nin Bayesian nonparametric mixture models,\u201d Journal of the Royal Statistical\nSociety B, 69, 715\u2013740.\n21"},{"page":22,"text":"Lo, A.Y. (1984). On a class of Bayesian nonparametric estimates I. Density esti-\nmates. Annals of Statistics 12, 351\u2013357.\nMacEachern, S.N. (1994). Estimating normal means with a conjugate style Dirichlet\nprocess prior. Communications in Statistics: Simulation and Computation 23,\n727\u2013741.\nMacEachern, S.N. and M\u00a8 uller, P. (1998). Estimating mixtures of Dirichlet process\nmodels. Journal of Computational and Graphical Statistics 7, 223\u2013238.\nNeal, R. (2000). Markov chain sampling methods for Dirichlet process mixture\nmodels. Journal of Computational and Graphical Statistics 9, 249\u2013265.\nPapaspiliopoulos, O. and Roberts, G.O. (2008). Retrospective Markov chain Monte\nCarlo methods for Dirichlet process hierarchical models. Biometrika 95, 169\u2013\n186.\nPapaspiliopoulos, O. (2008). A note on posterior sampling from Dirichlet mixture\nmodels. Preprint.\nSethuraman, J. (1994). A constructive definition of Dirichlet priors. Statistica Sinica\n4, 639\u2013650.\nSokal, A. (1997). Monte Carlo Methods in Statistical Mechanics: Foundations and\nNew Algorithms. Functional Integration (Carg\u00b4 ese, 1996) 361of NATO Adv.\nSci. Inst. Ser. B Phys., New York: Plenum, 131\u2013192.\nSmith, A.F.M. and Roberts, G.O. (1993). Bayesian computations via the Gibbs\nsampler and related Markov chain Monte Carlo methods. Journal of the Royal\nStatistical Society, Series B 55, 3\u201323.\nVan Gael, J., Saatchi, Y., Teh, Y.W., and Ghahramani, Z. (2008). Beam Sam-\npling for the Infinite Hidden Markov Model. Technical Report : Engineering\nDepartment, University of Cambridge.\nWalker, S.G. (2007). Sampling the Dirichlet mixture model with slices. Communi-\ncations in Statistics: Simulation and Computation 36, 45\u201354.\n22"},{"page":23,"text":"Appendix\nSimulation for the Inverse\u2013Gaussian model. We wish to simulate from the\ndensity g(xj+1)\n?\ng(xj+1) \u221d x\u22123\/2\nj+1(1 \u2212 xj+1)\u22123\/2exp\u22121\n2\n?\n\u03b32\nj\n\u039bjxj+1\n+(?\u221e\n\u039bj(1 \u2212 xj+1)\ni=j+1\u03b3i)2\n??\n.\nThe transformation yj+1=\nxj+1\n1\u2212xj+1has the density\n?\ng(yj+1) \u221d y\u22123\/2\nj+1(1 + yj+1)exp\u22121\n2\n?\n\u03b32\nj\n\u039bjyj+1\n+(?\u221e\ni=j+1\u03b3i)2\n\u039bj\nyj+1\n??\n.\nwhich can be expressed as a mixture of two generalized inverse\u2013Gaussian distributions\n?\ni=j+1\nwGIG\u22121\/2,\u03b3j\/\u039bj,\n\u221e\n?\n\u03b3i\/\u039bj\n?\n+ (1 \u2212 w)GIG\n?\n1\/2,\u03b3j\/\u039bj,\n\u221e\n?\ni=j+1\n\u03b3i\/\u039bj\n?\nwhere\nw =\n\u03b3j\n?\u221e\ni=j+1\u03b3i\nand GIG(p,a,b) denotes a distribution with density\n(b\/a)p\/2\n?\u221aab2Kp\n?x(p\u22121)exp{\u2212(a\/x + bx)\/2}\nwhere K\u03bddenotes the modified Bessel function of the third kind with index \u03bd.\n23"}],"fullTextUrl":"https:\/\/www.researchgate.net\/profile\/Jim_Griffin2\/publication\/220286498_Slice_sampling_mixture_models\/links\/00b7d51a4630de552f000000.pdf","widgetId":"rgw29_56ab9e94a3e5b"},"id":"rgw29_56ab9e94a3e5b","partials":[],"templateName":"publicliterature\/stubs\/PublicationText.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationText.html?publicationUid=220286498&hide=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationDetailAd":{"data":{"googleDfpSlot":null,"widgetId":"rgw30_56ab9e94a3e5b"},"id":"rgw30_56ab9e94a3e5b","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAd.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAd.html?publicationUid=220286498&slotId=336x280_Publications_ATF_Right&collapseSlotMode=never&fallbackContainerEnabled=1","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationRelations":null,"publicationRelationsReverse":null,"publicationUid":220286498,"showSignUpDialog":false,"selectNewSignUpDialog":false,"publicationQuestions":null,"publicationCitations":null,"publicationReviewPromo":null,"publicationUsedInReviews":null,"publicationPdfJsReader":{"data":{"isPreview":false,"licenseUrl":null,"licenseInfo":null,"defaultLinkData":{"linkId":"00b7d51a4630de552f000000","name":"Jim E Griffin","date":null,"nameLink":"profile\/Jim_Griffin2","filename":"","downloadLink":"https:\/\/www.researchgate.net\/profile\/Jim_Griffin2\/publication\/220286498_Slice_sampling_mixture_models\/links\/00b7d51a4630de552f000000.pdf?inViewer=0&pdfJsDownload=0&origin=publication_detail","viewerUrl":"https:\/\/www.researchgate.net\/profile\/Jim_Griffin2\/publication\/220286498_Slice_sampling_mixture_models\/links\/00b7d51a4630de552f000000.pdf?inViewer=1&pdfJsDownload=1&origin=publication_detail","downloadHash":"127467c80a43cb2919c402c868a66d88","showFileSizeNote":false,"fileSize":"287.74 KB","noFollow":false,"isDefault":true,"doi":null},"displayableLinks":[{"linkId":"00b7d51a4630de552f000000","name":"Jim E Griffin","date":null,"nameLink":"profile\/Jim_Griffin2","filename":"","downloadLink":"https:\/\/www.researchgate.net\/profile\/Jim_Griffin2\/publication\/220286498_Slice_sampling_mixture_models\/links\/00b7d51a4630de552f000000.pdf?inViewer=0&pdfJsDownload=0&origin=publication_detail","viewerUrl":"https:\/\/www.researchgate.net\/profile\/Jim_Griffin2\/publication\/220286498_Slice_sampling_mixture_models\/links\/00b7d51a4630de552f000000.pdf?inViewer=1&pdfJsDownload=1&origin=publication_detail","downloadHash":"127467c80a43cb2919c402c868a66d88","showFileSizeNote":false,"fileSize":"287.74 KB","noFollow":false,"isDefault":true,"doi":null}],"hasDisplayableLinks":false,"reader":{"data":{"pdfCommentsActive":false,"publicationType":"Article","onlyRenderFirstPage":false,"readMoreExperimentGoal":"goalPublicationPdfClicksReadMore","readMoreExperimentViewId":null,"comments":null,"figures":[],"figureAssetIds":[],"figureOverlayUrls":{"clickOnOverlay":"publication.PublicationFigures.html?_sg=pO8NrGkue2Zxr_37mnQvdXeLdRNJ7hAQySOxVha3T4hFSRdc1CReHLS_swYk2Lpnzt4ptzw3fV3Tx9HFGphO2A.zCrRVgcGJlZNsueLRjvbD8ANHsqaHYN25k_7TBK0VtVQC3eoRFT3v6MfaJ-BsYTkGPgxihUQggkM09roZT99Ng","clickOnPill":"publication.PublicationFigures.html?_sg=ht4xArzKaHQViMwlUGRFcl-kPqpwIoLkucdcdq6kDAxNzraelljK3wSZznU-KAVnu12T-ouwA-EsDjyJ6DJvcQ.I8ovr7dybcFrq682luoC9midm5V5B-G56Ge3wMLdWZi8ZNKBZTYayMX_y_36Qvs7hBUfFoUYBNz-TFP_nIGrZQ"},"canSelect":false,"javascriptPath":"https:\/\/www.researchgate.net\/c\/o1q2er\/","downloadUrl":"https%3A%2F%2Fwww.researchgate.net%2Fprofile%2FJim_Griffin2%2Fpublication%2F220286498_Slice_sampling_mixture_models%2Flinks%2F00b7d51a4630de552f000000.pdf%3FinViewer%3D1%26pdfJsDownload%3D1%26origin%3Dpublication_detail","viewerUrl":"https:\/\/www.researchgate.net\/c\/o1q2er\/javascript\/lib\/pdfjs\/web\/viewer.html","commentEndpoint":"https:\/\/www.researchgate.net\/rgformat\/api\/comment","experimentEndpoint":"https:\/\/www.researchgate.net\/rgformat\/api\/experiment?key=u-Zfq0JvnpQFcBmd_WifAXxeVtIQsiDa6LijfTrihJ3MWS4s2KN3GUBc3d85-XMiB4FrGzCQsae53cnCOWF1kw","urlHash":"7cfcbeb79e15526c4b071f59b22c474a","downloadTrackUrl":"application.PdfJsReader.ajaxTrackDownload.html?msrp=8AGU7jRpHdxiFrYMxwMjPJ7MTWNI6zdHvYFnRx9D_VfCta2s-oSend4oTFXEmLvDSm7JCVJzjhLJE7boLXIuacN-DoTMOowEiDO_FpASNWA.5GhBp6xaSAAX12CC0u9pNJRVsj2qx3S6oa7W2E4ObibYy0eYcMZr9cad_5f3w0s87-jPkRvjnyeSTNN5-IDNEA.CMM20tE1PuEB08Qjca1sZY0b9-cSrw9uRIfG93P90sYa5JYAgel9PITv93-oHstiAtxGj2Bfg4pwY4XbieC2IQ","viewportMilestoneTrackUrl":"application.PdfJsReader.ajaxTrackViewportMilestone.html","linkId":"00b7d51a4630de552f000000","trackedDownloads":{"00b7d51a4630de552f000000":{"v":false,"d":false}},"assetId":"AS:101338981601297@1401172504969","readerDocId":null,"assetType":"fulltext","interactionType":{"comment":"comment","highlight":"highlight"},"publicationUid":220286498,"commentCursorPromo":null,"widgetId":"rgw32_56ab9e94a3e5b"},"id":"rgw32_56ab9e94a3e5b","partials":[],"templateName":"application\/stubs\/PdfJsReader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PdfJsReader.html?fileHref=https%3A%2F%2Fwww.researchgate.net%2Fprofile%2FJim_Griffin2%2Fpublication%2F220286498_Slice_sampling_mixture_models%2Flinks%2F00b7d51a4630de552f000000.pdf%3FinViewer%3D1%26pdfJsDownload%3D1%26origin%3Dpublication_detail&assetId=AS%3A101338981601297%401401172504969&publicationUid=220286498&linkId=00b7d51a4630de552f000000&onlyShowFirstPage=0","viewClass":null,"yuiModules":["css-pow-application-PdfJsReader"],"stylesheets":["pow\/application\/PdfJsReader.css"],"_isYUI":true},"showHeader":true,"title":"Slice sampling mixture models","publicationType":"Article","downloadTrackUrl":"publicliterature.PublicationInlineReader.ajaxTrackDownload.html?msrp=tIHj0atNAHVfEdnfAV_p2a0F6UoGuBeJA1zjlA2Vmz3GRU3z_M19raDNl2LL34FLNCWmYysqSbrlQoBEOLsJljv6j5qx2c30AYd5j2Y6j7g.ImaZR7Xep-84aN7cUYgwHD0Tccd8wWgcG5c8_VdF1LxbS-jDlZSP-yRXtHMWicMZIlVtCnhcBt7ye1fNl-3j7A.ErtC9QfAEjQVwzSfYyPFgw2GiYwD0yc37n1Tm7YWggdSTfu1L0YNCUhR_U9mOvskAU7k-FrZDjNDoi9OdtEM8g","publicationUid":220286498,"trackedDownloads":{"00b7d51a4630de552f000000":{"v":false,"d":false}},"inlinePdf":false,"publicationComments":null,"showDownloadButton":true,"socialShare":{"data":{"shareItems":[{"data":{"name":"Facebook","url":"http:\/\/www.facebook.com\/share.php?u={{url}}{{#title}}&t={{title}}{{\/title}}","width":600,"height":350,"useUtmTags":true,"utmSource":"facebook","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareFacebook.ajaxTrackSocialShare.html","widgetId":"rgw34_56ab9e94a3e5b"},"id":"rgw34_56ab9e94a3e5b","partials":{"shareIcon":"application\/stubs\/partials\/shareFacebookBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareFacebook.html?provider=Facebook&shareIcon=shareIconBlog&utmSource=facebook&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"Twitter","url":"http:\/\/twitter.com\/intent\/tweet?text={{#title}}{{title}}: {{\/title}}{{url}}&via=researchgate","width":600,"height":350,"useUtmTags":true,"utmSource":"twitter","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareTwitter.ajaxTrackSocialShare.html","widgetId":"rgw35_56ab9e94a3e5b"},"id":"rgw35_56ab9e94a3e5b","partials":{"shareIcon":"application\/stubs\/partials\/shareTwitterBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareTwitter.html?provider=Twitter&shareIcon=shareIconBlog&utmSource=twitter&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"Google+","url":"https:\/\/plus.google.com\/share?url={{url}}","width":600,"height":600,"useUtmTags":true,"utmSource":"googleplus","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareGooglePlus.ajaxTrackSocialShare.html","widgetId":"rgw36_56ab9e94a3e5b"},"id":"rgw36_56ab9e94a3e5b","partials":{"shareIcon":"application\/stubs\/partials\/shareGooglePlusBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareGooglePlus.html?provider=Google%2B&shareIcon=shareIconBlog&utmSource=googleplus&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"LinkedIn","url":"http:\/\/www.linkedin.com\/shareArticle?mini=true&url={{url}}{{#title}}&title={{title}}{{\/title}}&source=ResearchGate","width":520,"height":570,"useUtmTags":true,"utmSource":"linkedin","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareLinkedIn.ajaxTrackSocialShare.html","widgetId":"rgw37_56ab9e94a3e5b"},"id":"rgw37_56ab9e94a3e5b","partials":{"shareIcon":"application\/stubs\/partials\/shareLinkedInBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareLinkedIn.html?provider=LinkedIn&shareIcon=shareIconBlog&utmSource=linkedin&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"Reddit","url":"https:\/\/www.reddit.com\/submit?url={{url}}{{#title}}&title={{title}}{{\/title}}","width":600,"height":600,"useUtmTags":true,"utmSource":"reddit","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareReddit.ajaxTrackSocialShare.html","widgetId":"rgw38_56ab9e94a3e5b"},"id":"rgw38_56ab9e94a3e5b","partials":{"shareIcon":"application\/stubs\/partials\/shareRedditBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareReddit.html?provider=Reddit&shareIcon=shareIconBlog&utmSource=reddit&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true}],"widgetId":"rgw33_56ab9e94a3e5b"},"id":"rgw33_56ab9e94a3e5b","partials":[],"templateName":"application\/stubs\/SocialShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.SocialShare.html?campaign=shareFullTextPublication&trackClick=1&shareIcon=shareIconBlog","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw31_56ab9e94a3e5b"},"id":"rgw31_56ab9e94a3e5b","partials":[],"templateName":"publicliterature\/stubs\/PublicationInlineReader.html","templateExtensions":["generalHelpers"],"attrs":{"showFulltextDownloadedSignupDialog":true,"preSignUpDialogContext":null,"requestFulltext":false},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationInlineReader.html","viewClass":"views.publicliterature.PublicationInlineReaderView","yuiModules":["rg.views.publicliterature.PublicationInlineReaderView","css-pow-publicliterature-PublicationInlineReader"],"stylesheets":["pow\/publicliterature\/PublicationInlineReader.css"],"_isYUI":true},"useFulltextOptimizedLayout":false,"publicationActions":null,"requestFulltextPromo":null,"currentUrl":"publication\/220286498_Slice_sampling_mixture_models","isLeaderboardAd":false,"enableStickyBox":null,"googleDfpSlotMobileBottom":null,"fullTextExitPopup":null,"showExitPopupDialog":false,"widgetId":"rgw2_56ab9e94a3e5b"},"id":"rgw2_56ab9e94a3e5b","partials":{"romeo_legal_notice":"publicliterature\/stubs\/partials\/romeo_legal_notice.html"},"templateName":"publicliterature\/stubs\/PublicPublicationDetails_NewLayout.html","templateExtensions":["generalHelpers"],"attrs":{"publicationUid":220286498},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicPublicationDetailsOld.html?publicationUid=220286498&isTestOldDesign=0","viewClass":"views.publicliterature.PublicPublicationDetailsOldView","yuiModules":["rg.views.publicliterature.PublicPublicationDetailsOldView"],"stylesheets":[],"_isYUI":true},"widgetId":"rgw1_56ab9e94a3e5b"},"id":"rgw1_56ab9e94a3e5b","partials":[],"templateName":"publicliterature\/stubs\/PublicPublicationDetails.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicPublicationDetails.html","viewClass":"views.publicliterature.PublicPublicationDetailsView","yuiModules":["rg.views.publicliterature.PublicPublicationDetailsView"],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"uaClass":"","headPrefix":[],"rootUrl":"https:\/\/www.researchgate.net\/","requestToken":"yp53KpWy8sHfvYP9vK44mTyKLNalwpX8Fju0FiPbtJ8JPku\/uY5K5z\/+6Dbe0CgNqsyZBDc2UzMrTWoUDCWU7qIWOCIPb9sk9iUctNpdWVCbdHKD1h41Xns\/VUuHNxfMZZNeXfJ6SDMlI1+Cg1OThJbNlcNa\/vXfHJncveZXuXFVDnzaJsFQ7IMklkbn0FYQDh6YV7+4k1pnhIHVw5I\/76v7nw5GGFQBbOTjr0Rs7mb7GvqRj7CcecyukDtDiL0baTCmyeAw2TYL5qSszuJWEyWJw3iq5ifk510S3efVkDs=","faviconCdnUrl":"https:\/\/c5.rgstatic.net\/m\/2390829798215018\/images\/favicon.ico","headerOutput":"<noscript><\/noscript><link rel=\"canonical\" href=\"https:\/\/www.researchgate.net\/publication\/220286498_Slice_sampling_mixture_models\" \/>\n<link rel=\"dns-prefetch\" href=\"\/\/c5.rgstatic.net\" \/>\n<link rel=\"dns-prefetch\" href=\"\/\/i1.rgstatic.net\" \/>\n<meta property=\"twitter:card\" content=\"summary\" \/>\n<meta property=\"twitter:site\" content=\"@ResearchGate\" \/>\n<meta property=\"og:title\" content=\"Slice sampling mixture models\" \/>\n<meta property=\"og:description\" content=\"We propose a more efficient version of the slice sampler for Dirichlet process mixture models described by Walker (Commun.\nStat., Simul. Comput. 36:45\u201354, 2007). This new sampler allows for the...\" \/>\n<meta property=\"og:site_name\" content=\"ResearchGate\" \/>\n<meta property=\"og:image\" content=\"https:\/\/i1.rgstatic.net\/publication\/220286498_Slice_sampling_mixture_models\/links\/00b7d51a4630de552f000000\/smallpreview.png\" \/>\n<meta property=\"og:url\" content=\"https:\/\/www.researchgate.net\/publication\/220286498_Slice_sampling_mixture_models\" \/>\n<meta property=\"rg:id\" content=\"PB:220286498\" \/>\n<meta name=\"DC.identifier\" scheme=\"DCTERMS.URI\" content=\"http:\/\/dx.doi.org\/10.1007\/s11222-009-9150-y\" \/>\n<meta name=\"gs_meta_revision\" content=\"1.1\" \/>\n<meta name=\"citation_title\" content=\"Slice sampling mixture models\" \/>\n<meta name=\"citation_author\" content=\"Maria Kalli\" \/>\n<meta name=\"citation_author\" content=\"Jim E. Griffin\" \/>\n<meta name=\"citation_author\" content=\"Stephen G. Walker\" \/>\n<meta name=\"citation_publication_date\" content=\"2011\/01\/01\" \/>\n<meta name=\"citation_journal_title\" content=\"Statistics and Computing\" \/>\n<meta name=\"citation_issn\" content=\"0960-3174\" \/>\n<meta name=\"citation_volume\" content=\"21\" \/>\n<meta name=\"citation_issue\" content=\"1\" \/>\n<meta name=\"citation_firstpage\" content=\"93\" \/>\n<meta name=\"citation_lastpage\" content=\"105\" \/>\n<meta name=\"citation_doi\" content=\"10.1007\/s11222-009-9150-y\" \/>\n<meta name=\"citation_pdf_url\" content=\"https:\/\/www.researchgate.net\/profile\/Jim_Griffin2\/publication\/220286498_Slice_sampling_mixture_models\/links\/00b7d51a4630de552f000000.pdf\" \/>\n<meta name=\"citation_abstract_html_url\" content=\"https:\/\/www.researchgate.net\/publication\/220286498_Slice_sampling_mixture_models\" \/>\n<meta name=\"citation_fulltext_html_url\" content=\"https:\/\/www.researchgate.net\/publication\/220286498_Slice_sampling_mixture_models\" \/>\n<meta name=\"viewport\" content=\"width=device-width,initial-scale=1\" \/>\n<link href=\"\/\/c5.rgstatic.net\/m\/22664197317151888\/styles\/rg.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/21004998181197492\/styles\/rg2.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<!--[if lt IE 9]><link href=\"\/\/c5.rgstatic.net\/m\/238176252723686\/styles\/ie.css\" type=\"text\/css\" rel=\"stylesheet\"\/><![endif]-->\n<link href=\"\/\/c5.rgstatic.net\/m\/217752362214895\/styles\/modules\/publicprofile.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/21993347442549\/styles\/pow\/publicliterature\/FollowPublicationPromo.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/282514599719602\/styles\/pow\/application\/PdfJsReader.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/23819663151220\/styles\/pow\/publicliterature\/PublicationInlineReader.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<script src=\"\/\/c5.rgstatic.net\/m\/2321000301012716\/javascript\/vendor\/webfontloader\/webfontloader.js\" type=\"text\/javascript\"><\/script>\n <script>(function(i,s,o,g,r,a,m){i[\"GoogleAnalyticsObject\"]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,\"script\",\"\/\/www.google-analytics.com\/analytics.js\",\"ga\");\n ga(\"create\",\"UA-58591210-1\");ga(\"set\",\"anonymizeIp\",true);ga('set', 'dimension1', 'publication full-text');ga('set', 'dimension2', 'Article');ga('set', 'dimension3', 'Logged out');ga('set', 'dimension4', 'https');ga(\"send\",\"pageview\");<\/script>\n","webfont":"<noscript><\/noscript><script> WebFontConfig = { custom: { families: ['source_sans_pro_italic', 'source_sans_pro_bold', 'source_sans_pro', 'martel'], urls : ['\/\/c5.rgstatic.net\/m\/231392577336386\/styles\/fonts.css'] } }; WebFont.load(WebFontConfig); <\/script>\n","correlationId":"rgreq-b098bda4-4e74-4587-8fdd-8e78734b0d43","accountId":null,"module":"publicliterature","action":"publicliterature.PublicPublicationDetails","page":"publicationDetail","product":"publications","backendTime":386,"continent":"Asia","stylesHome":"\/\/c5.rgstatic.net\/m\/","staticHost":"c5.rgstatic.net","useEarlyFlush":false,"longRunningRequestIdentifier":"LongRunningRequest.publicliterature.PublicPublicationDetails","longRunningRequestFp":"e9e5bbe1366c7ee8c8e41d02f793c884ac9be19b","widgetId":"rgw39_56ab9e94a3e5b"},"id":"rgw39_56ab9e94a3e5b","partials":[],"templateName":"application\/stubs\/StaticHeader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.StaticHeader.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){
            Y.rg.core.pagespeed.Monitoring.monitorPage("\/\/glassmoni.researchgate.net", "publicliterature.PublicPublicationDetails.run.html.loggedOut.get", "59de9668d07aeb77ab4de5f24d382b5d199d2437", "rgreq-b098bda4-4e74-4587-8fdd-8e78734b0d43", "300d1791d77ee4be2c7deba282210a09c972c287");
        
            Y.rg.core.pagespeed.Monitoring.monitorPage("\/\/glassmoni.researchgate.net", "publicationDetail.loggedOut", "ed1993d9e20f6cefa83edacaa24401a18c071aea", "rgreq-b098bda4-4e74-4587-8fdd-8e78734b0d43", "300d1791d77ee4be2c7deba282210a09c972c287");
        })();
(function(){Y.rg.createInitialWidget({"data":{"year":"2016","inlinePromo":null,"isAdmin":false,"contactUrl":"https:\/\/www.researchgate.net\/contact","aboutUsUrl":"https:\/\/www.researchgate.net\/about","widgetId":"rgw40_56ab9e94a3e5b"},"id":"rgw40_56ab9e94a3e5b","partials":[],"templateName":"application\/stubs\/DefaultFooter.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.DefaultFooter.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"headerLogin":{"data":{"urlAfterLogin":"publication\/220286498_Slice_sampling_mixture_models","requestToken":"d85K\/KB\/XilUx3VgBZSigZbk0l5LltIevi1aKS9D7XpWIYKTc0gbCKfiEMRbe3ICFhL9JKK\/gInx6ucP1UkZl2eryODHF6rxZvGwc4oi+q9kcnxtLRNQ33svKmaTkJpm+blDabBWAPe4FODp0nAqBIZyVL8mrMw4XwK7GDCfoMtZms9S\/eiEO2jIt2l4Wclg\/jTfpRge\/R0p7Qvl6+IGOhXl4riVuoNTo+6P5ab\/ixKIV5a4cIC3TZfXnvTfs8lD8RFRJ4KE21OMihTAjwK3SbCSHsNKn4FYuLOTnBfKtEg=","loginUrl":"https:\/\/www.researchgate.net\/application.Login.html","signupUrl":"https:\/\/www.researchgate.net\/signup.SignUp.html?ev=su_chnl_index&hdrsu=1&_sg=Dp67iwfWt6iLIdRsYqcSOMv1RZAcAyEB2eUo-eChN8rpWtywnxOKkDUT0ZSWby-N","encodedUrlAfterLogin":"cHVibGljYXRpb24vMjIwMjg2NDk4X1NsaWNlX3NhbXBsaW5nX21peHR1cmVfbW9kZWxz","signupCallToAction":"Join for free","widgetId":"rgw42_56ab9e94a3e5b"},"id":"rgw42_56ab9e94a3e5b","partials":{"partial":"application\/stubs\/partials\/headerLoginDefault.html"},"templateName":"application\/stubs\/HeaderLogin.html","templateExtensions":[],"attrs":{"goal":"milestoneHeaderLoginSeen"},"widgetUrl":"https:\/\/www.researchgate.net\/application.HeaderLogin.html","viewClass":"views.application.HeaderLoginView","yuiModules":["rg.views.application.HeaderLoginView"],"stylesheets":[],"_isYUI":true},"cookieConsent":null,"logoSvgSrc":"https:\/\/c5.rgstatic.net\/m\/235107188705592\/images\/template\/brand-header-logo.svg","logoFallbackSrc":"https:\/\/c5.rgstatic.net\/m\/238113351022438\/images\/template\/brand-header-logo.png","widgetId":"rgw41_56ab9e94a3e5b"},"id":"rgw41_56ab9e94a3e5b","partials":{"schemaSocialProfiles":"application\/stubs\/partials\/schemaSocialProfiles.html"},"templateName":"application\/stubs\/HeaderLoggedOut.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.HeaderLoggedOut.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"logEvent":"su_banner","specialCopy":false,"widgetId":"rgw43_56ab9e94a3e5b"},"id":"rgw43_56ab9e94a3e5b","partials":[],"templateName":"application\/stubs\/LoggedOutBanner.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.LoggedOutBanner.html","viewClass":"views.application.LoggedOutBannerView","yuiModules":["rg.views.application.LoggedOutBannerView"],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.core.util.ParameterFilter.filter(["ev","cp","ch","ref","dbw","pli","loginT","uid","claimChannel","enrichId","enrichSource","utm_source","utm_medium","utm_campaign","el","ci"]);})();
});}); } else { throw 'YRG was not loaded when attaching widgets'; }</script><script> dataLayer = [{"pageCategory":"publication full-text","publicationType":"Article","eventCategory":"Publication page"}]; </script> <noscript><iframe src="//www.googletagmanager.com/ns.html?id=GTM-MKVKH7" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-MKVKH7');</script><script>(function(e){function n(n,t,o,a){"use strict";var i=e.document.createElement("link"),r=t||e.document.getElementsByTagName("script")[0],d=e.document.styleSheets;return i.rel="stylesheet",i.href=n,i.media="only x",a&&(i.onload=a),r.parentNode.insertBefore(i,r),i.onloadcssdefined=function(e){for(var t,o=0;d.length>o;o++)d[o].href&&d[o].href.indexOf(n)>-1&&(t=!0);t?e():setTimeout(function(){i.onloadcssdefined(e)})},i.onloadcssdefined(function(){i.media=o||"all"}),i}function t(e,n){e.onload=function(){e.onload=null,n&&n.call(e)},"isApplicationInstalled"in navigator&&"onloadcssdefined"in e&&e.onloadcssdefined(n)}var o=function(a,i){"use strict";if(a&&3===a.length){var r=e.Image,d=!(!document.createElementNS||!document.createElementNS("http://www.w3.org/2000/svg","svg").createSVGRect||!document.implementation.hasFeature("http://www.w3.org/TR/SVG11/feature#Image","1.1")||e.opera&&-1===navigator.userAgent.indexOf("Chrome")||-1!==navigator.userAgent.indexOf("Series40")),c=new r;c.onerror=function(){o.method="png",o.href=a[2],n(a[2])},c.onload=function(){var e=1===c.width&&1===c.height,r=a[e&&d?0:e?1:2];o.method=e&&d?"svg":e?"datapng":"png",o.href=r,t(n(r),i)},c.src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///ywAAAAAAQABAAACAUwAOw==",document.documentElement.className+=" grunticon"}};o.loadCSS=n,o.onloadCSS=t,e.grunticon=o})(this);grunticon(["https://c5.rgstatic.net/c/o1q2er/styles/icons/_header-ico.svg.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_header-ico.png.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_header-ico.fallback.scss"]);grunticon(["https://c5.rgstatic.net/c/o1q2er/styles/icons/_admin-ico.svg.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_admin-ico.png.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_admin-ico.fallback.scss"]);grunticon(["https://c5.rgstatic.net/c/o1q2er/styles/icons/_ico.svg.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_ico.png.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_ico.fallback.scss"]);</script></body>
</html>
