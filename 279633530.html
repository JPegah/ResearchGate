<!DOCTYPE html> <html lang="en" class="" id="rgw38_56ab9d3a58c4a"> <head > <meta charset="utf-8"/> <meta http-equiv="content-type" content="text/html; charset=UTF-8"/> <meta name="Rg-Request-Token" id="Rg-Request-Token" content="B0kc5LtgBc8ZuMFoxXx6khK4qXdojaGyLjhdKG/gPSLWK80C7oOsdTl5hhyoiMw7zDgjrDJ0O44wtr+O7pGrtQTWeq2xLlBVsfM5PlqJLMF2xlMzYxbWFvIXTT3m0xIb5LdH2LmN74Ta0YyZzlmr0tIbXFgqD5hj5x76T0Zt3ifZKA0zIGJScQCozFVoqizKMW5GK1lFWnW6BmpooEwWxCZgt/qfU/DGZqAg+8pdCWLojqy2nsoa4hyf0eQJKTXIRj2JoClGw6+P1H0Nm2niU7PGFJww6h3TzxhG4I3s1bE="/> <meta http-equiv="expires" content="0"/> <link rel="apple-touch-icon" sizes="57x57" href="https://www.researchgate.net/apple-touch-icon-57x57.png"> <link rel="apple-touch-icon" sizes="60x60" href="https://www.researchgate.net/apple-touch-icon-60x60.png"> <link rel="apple-touch-icon" sizes="72x72" href="https://www.researchgate.net/apple-touch-icon-72x72.png"> <link rel="apple-touch-icon" sizes="76x76" href="https://www.researchgate.net/apple-touch-icon-76x76.png"> <link rel="apple-touch-icon" sizes="114x114" href="https://www.researchgate.net/apple-touch-icon-114x114.png"> <link rel="apple-touch-icon" sizes="120x120" href="https://www.researchgate.net/apple-touch-icon-120x120.png"> <link rel="apple-touch-icon" sizes="144x144" href="https://www.researchgate.net/apple-touch-icon-144x144.png"> <link rel="apple-touch-icon" sizes="152x152" href="https://www.researchgate.net/apple-touch-icon-152x152.png"> <link rel="apple-touch-icon" sizes="180x180" href="https://www.researchgate.net/apple-touch-icon-180x180.png"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-32x32.png" sizes="32x32"> <link rel="icon" type="image/png" href="https://www.researchgate.net/android-chrome-192x192.png" sizes="192x192"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-96x96.png" sizes="96x96"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-16x16.png" sizes="16x16"> <link rel="shortcut icon" type="image/x-icon" href="https://c5.rgstatic.net/m/2390829798215018/images/favicon.ico"/> <link rel="manifest" href="https://www.researchgate.net/manifest.json"> <meta name="msapplication-TileColor" content="#da532c"> <meta name="msapplication-TileImage" content="https://www.researchgate.net/mstile-144x144.png"> <meta name="theme-color" content="#444444"> <link rel="search" type="application/opensearchdescription+xml" title="ResearchGate search" href="https://www.researchgate.net/application.DownloadOpenSearchPlugin.html"/> <link rel="meta" type="application/rdf+xml" title="ICRA labels" href="https://www.researchgate.net/application.DownloadLabels.html"/> <link rel="http://oexchange.org/spec/0.8/rel/related-target" type="application/xrd+xml" href="https://www.researchgate.net/application.DownloadOExchange.html"/> <base href="https://www.researchgate.net/"/> <script>
    var rgConfig = {
        correlationId: "rgreq-3263a1e0-e9b9-475c-99d4-a0870be9e987",
        accountId: "",
        module: "publicliterature",
        action: "publicliterature.PublicPublicationDetails",
        page: "publicationDetail",
        product: "publications",
        continent: "Asia",
        stylesHome: "//c5.rgstatic.net/m/",
        staticHost: "c5.rgstatic.net",
        longRunningRequestIdentifier: "LongRunningRequest.publicliterature.PublicPublicationDetails",
        longRunningRequestFp: "e9e5bbe1366c7ee8c8e41d02f793c884ac9be19b"
    };
    window.rootUrl = "https://www.researchgate.net/";
</script> <link rel="canonical" href="https://www.researchgate.net/publication/279633530_Subsampling-Based_Approximate_Monte_Carlo_for_Discrete_Distributions" />
<link rel="dns-prefetch" href="//c5.rgstatic.net" />
<link rel="dns-prefetch" href="//i1.rgstatic.net" />
<meta property="twitter:card" content="summary" />
<meta property="twitter:site" content="@ResearchGate" />
<meta property="og:title" content="Subsampling-Based Approximate Monte Carlo for Discrete Distributions" />
<meta property="og:description" content="Drawing a sample from a discrete distribution is one of the building
components for Monte Carlo methods. Like other sampling algorithms, discrete
sampling also suffers from high computational..." />
<meta property="og:site_name" content="ResearchGate" />
<meta property="og:image" content="https://i1.rgstatic.net/publication/279633530_Subsampling-Based_Approximate_Monte_Carlo_for_Discrete_Distributions/links/565d728808aeafc2aac7970f/smallpreview.png" />
<meta property="og:url" content="https://www.researchgate.net/publication/279633530_Subsampling-Based_Approximate_Monte_Carlo_for_Discrete_Distributions" />
<meta property="rg:id" content="PB:279633530" />
<meta name="DC.identifier" scheme="DCTERMS.URI" content="http://dx.doi.org/" />
<meta name="gs_meta_revision" content="1.1" />
<meta name="citation_title" content="Subsampling-Based Approximate Monte Carlo for Discrete Distributions" />
<meta name="citation_author" content="Yutian Chen" />
<meta name="citation_author" content="Zoubin Ghahramani" />
<meta name="citation_publication_date" content="2015/06/30" />
<meta name="citation_pdf_url" content="https://www.researchgate.net/profile/Yutian_Chen3/publication/279633530_Subsampling-Based_Approximate_Monte_Carlo_for_Discrete_Distributions/links/565d728808aeafc2aac7970f.pdf" />
<meta name="citation_abstract_html_url" content="https://www.researchgate.net/publication/279633530_Subsampling-Based_Approximate_Monte_Carlo_for_Discrete_Distributions" />
<meta name="citation_fulltext_html_url" content="https://www.researchgate.net/publication/279633530_Subsampling-Based_Approximate_Monte_Carlo_for_Discrete_Distributions" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<link href="//c5.rgstatic.net/m/22664197317151888/styles/rg.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/21004998181197492/styles/rg2.css" type="text/css" rel="stylesheet"/>
<!--[if lt IE 9]><link href="//c5.rgstatic.net/m/238176252723686/styles/ie.css" type="text/css" rel="stylesheet"/><![endif]-->
<link href="//c5.rgstatic.net/m/217752362214895/styles/modules/publicprofile.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/21993347442549/styles/pow/publicliterature/FollowPublicationPromo.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/282514599719602/styles/pow/application/PdfJsReader.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/23819663151220/styles/pow/publicliterature/PublicationInlineReader.css" type="text/css" rel="stylesheet"/>
<script src="//c5.rgstatic.net/m/2321000301012716/javascript/vendor/webfontloader/webfontloader.js" type="text/javascript"></script>
 <script>(function(i,s,o,g,r,a,m){i["GoogleAnalyticsObject"]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,"script","//www.google-analytics.com/analytics.js","ga");
 ga("create","UA-58591210-1");ga("set","anonymizeIp",true);ga('set', 'dimension1', 'publication full-text');ga('set', 'dimension2', 'Article');ga('set', 'dimension3', 'Logged out');ga('set', 'dimension4', 'https');ga("send","pageview");</script>
  <script> WebFontConfig = { custom: { families: ['source_sans_pro_italic', 'source_sans_pro_bold', 'source_sans_pro', 'martel'], urls : ['//c5.rgstatic.net/m/231392577336386/styles/fonts.css'] } }; WebFont.load(WebFontConfig); </script><noscript></noscript>

<title>Subsampling-Based Approximate Monte Carlo for Discrete Distributions (PDF Download Available)</title>
<meta name="description" content="Official Full-Text Publication: Subsampling-Based Approximate Monte Carlo for Discrete Distributions on ResearchGate, the professional network for scientists."/>
<meta name="keywords" content="scientific network, scientific platform, scientific community, research partner, research collaboration, journal articles, international collaboration, find researcher, lifescience researcher, interdisciplinary research, research collaboration"/>
</head>
<body class="use-svg-icons logged-out">
<div id="page-container">
<script type="text/javascript">var googletag = googletag || {}; googletag.cmd = googletag.cmd || [];
(function() { var gads = document.createElement("script"); gads.async = true; gads.type = "text/javascript"; var useSSL = "https:" == document.location.protocol; gads.src = (useSSL ? "https:" : "http:") + "//www.googletagservices.com/tag/js/gpt.js"; var node =document.getElementsByTagName("script")[0]; node.parentNode.insertBefore(gads, node); })();</script><div id="main" class="logged-out-header-support">
<div id="content" class="">

<noscript>
<div class="c-box-warning full-width-element" style="text-align: center; ">
    <div style="margin: auto; padding:10px;" class="container">
        <b>For full functionality of ResearchGate it is necessary to enable JavaScript.
            Here are the <a href="http://www.enable-javascript.com/" rel="nofollow" target="_blank">
                instructions how to enable JavaScript in your web browser</a>.</b>
    </div>
</div>
</noscript>

<div id="rgw1_56ab9d3a58c4a" itemscope itemtype="http://schema.org/ScholarlyArticle"><div class="publication-wrapper publication-wrapper-onecol" id="rgw2_56ab9d3a58c4a" itemscope itemtype="http://schema.org/ScholarlyArticle"> <div class="c-col-content"> <div class="c-content"> <div class="clearfix">  <div class="publication-header"> <div id="rgw5_56ab9d3a58c4a">  <div class="type-label"> Article   </div> <span class="Z3988" title="ctx_ver=Z39.88-2004&rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&rfr_id=info%3Asid%2Fresearchgate.net%3Aresearchgate&rft.atitle=Subsampling-Based%20Approximate%20Monte%20Carlo%20for%20Discrete%20Distributions&rft.date=2015&rft.au=Yutian%20Chen%2CZoubin%20Ghahramani&rft.genre=article"></span> <h1 class="pub-title" itemprop="name">Subsampling-Based Approximate Monte Carlo for Discrete Distributions</h1> <meta itemprop="headline" content="Subsampling-Based Approximate Monte Carlo for Discrete Distributions">  <meta itemprop="image" content="https://i1.rgstatic.net/publication/279633530_Subsampling-Based_Approximate_Monte_Carlo_for_Discrete_Distributions/links/565d728808aeafc2aac7970f/smallpreview.png">  <div id="rgw7_56ab9d3a58c4a" class="publication-detail-author-list"> <div> <ul class="clearfix js-people-list">  <li id="rgw8_56ab9d3a58c4a" itemprop="author" itemscope itemtype="http://schema.org/Person"> <a itemprop="sameAs" href="profile/Yutian_Chen3" class="pub-detail-item account-item"> <div class="indent-left"> <div class="people-img"> <img  src="https://i1.rgstatic.net/ii/profile.image/AS%3A278543817822209%401443421429383_m" title="Yutian Chen" alt="Yutian Chen" height="20px" width="20px" style="height: 20px;"/> </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Yutian Chen</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item  remove-action-indent   " id="rgw9_56ab9d3a58c4a" data-account-key="Yutian_Chen3">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="profile/Yutian_Chen3"> <img class="lazyload" data-src="https://i1.rgstatic.net/ii/profile.image/AS%3A278543817822209%401443421429383_l" title="Yutian Chen" alt="Yutian Chen" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">     </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="profile/Yutian_Chen3" class="display-name">Yutian Chen</a>    </h5> <div class="truncate-single-line meta">   <a class="meta ga-top-coauthor-institution" href="institution/University_of_Cambridge" title="University of Cambridge">University of Cambridge</a>     </div>  <a href="javascript:" class="btn btn-promote btn-large people-item-contact-author js-contact-author">Message author</a>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>  <li id="rgw10_56ab9d3a58c4a"> <a href="researcher/8159937_Zoubin_Ghahramani" class="pub-detail-item author-item" itemprop="author" itemscope itemtype="http://schema.org/Person"> <div class="indent-left"> <div class="people-img">  <img src="https://c5.rgstatic.net/m/2951093203564/images/template/default/profile/profile_default_s.jpg" title="Zoubin Ghahramani" alt="Zoubin Ghahramani" height="20px" width="20px" style="height: 20px;"/>  </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Zoubin Ghahramani</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item   not-claimed " id="rgw11_56ab9d3a58c4a">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="researcher/8159937_Zoubin_Ghahramani"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="Zoubin Ghahramani" alt="Zoubin Ghahramani" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">       </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="researcher/8159937_Zoubin_Ghahramani" class="display-name">Zoubin Ghahramani</a>    </h5> <div class="truncate-single-line meta">   </div>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>   </ul> <div class="js-loading"></div>  </div> </div> <div class="pub-details js-pub-details">        <meta itemprop="datePublished" content="2015-06">  06/2015;               <div class="pub-source"> Source: <a href="http://arxiv.org/abs/1506.09039" rel="nofollow">arXiv</a> </div>  </div> <div id="rgw12_56ab9d3a58c4a" class="pub-abstract">  <div class="clearfix">   <div style="max-height: 54px;" class="js-expander-container js-expander-collapsed">  <p itemprop="description"> <strong>ABSTRACT</strong> <div>Drawing a sample from a discrete distribution is one of the building<br />
components for Monte Carlo methods. Like other sampling algorithms, discrete<br />
sampling also suffers from high computational burden in large-scale inference<br />
problems. We study the problem of sampling a discrete random variable with a<br />
high degree of dependency that is typical in large-scale Bayesian inference and<br />
graphical models, and propose an efficient approximate solution with a<br />
subsampling approach. We make a novel connection between the discrete sampling<br />
and Multi-Armed Bandits problems with a finite reward population and provide<br />
three algorithms with theoretical guarantees. Empirical evaluations show the<br />
robustness and efficiency of the approximate algorithms in both synthetic and<br />
real-world large-scale problems.</div> </p>  </div>  </div>   </div>      <div class="action-container"> <div id="rgw13_56ab9d3a58c4a" class="follow-publication-promo"> <table> <tr> <td class="follow-publication-promo-text-cell"> <p>Get notified about updates to this publication</p> <a class="btn btn-large btn-promote js-follow-publication ga-follow-publication-new-promo">Follow publication</a> </td> <td> <div class="follow-publication-publication-image"></div> </td> </tr> </table> </div>  <div class="clear"></div> <div class="share-dialog-container" style="display: none;">  </div> </div> </div> <div style="margin-left: -20px; margin-right: -20px;">  </div> </div>  <div class="publication-detail-dfp-container rf"> <div id="rgw27_56ab9d3a58c4a">  </div> </div>  </div>  <div class="clearfix"> <div class="pdf-js-container clearfix " id="rgw30_56ab9d3a58c4a">  <div class="pdf-js-header js-sticky-header clear">  <a class="blue-link js-download rf btn btn-promote" href="https://www.researchgate.net/profile/Yutian_Chen3/publication/279633530_Subsampling-Based_Approximate_Monte_Carlo_for_Discrete_Distributions/links/565d728808aeafc2aac7970f.pdf?inViewer=0&amp;pdfJsDownload=0&amp;origin=publication_detail">Download full-text</a>  <h3>Full-text</h3> <span class="publication-info">  <span class="js-doi-container" style="display: none;"> DOI: <span class="js-doi"></span> &middot; </span> Available from: <a class="js-name" href="profile/Yutian_Chen3">Yutian Chen</a>, <span class="js-publication-date"> Dec 01, 2015 </span>   </span>  </div>  <div class="social-share-container"><div id="rgw32_56ab9d3a58c4a" class="social-share js-social-share"> <div class="social-share-heading">Share</div>  <a id="rgw33_56ab9d3a58c4a" href="javascript:" title="Share on Facebook" class="link-nostyle js-share-item share-icon "  data-url="http://www.facebook.com/share.php?u={{url}}{{#title}}&amp;t={{title}}{{/title}}" data-width="600" data-height="350" data-name="Facebook"> <span class="share-icon ico-share-facebook-round reset-background ga-share-blog-facebook"></span> </a>  <a id="rgw34_56ab9d3a58c4a" href="javascript:" title="Share on Twitter" class="link-nostyle js-share-item share-icon "  data-url="http://twitter.com/intent/tweet?text={{#title}}{{title}}: {{/title}}{{url}}&amp;via=researchgate" data-width="600" data-height="350" data-name="Twitter"> <span class="share-icon ico-share-twitter-round reset-background ga-share-blog-twitter"></span> </a>  <a id="rgw35_56ab9d3a58c4a" href="javascript:" title="Share on Google+" class="link-nostyle js-share-item share-icon "  data-url="https://plus.google.com/share?url={{url}}" data-width="600" data-height="600" data-name="Google+"> <span class="share-icon ico-share-gplus-round reset-background ga-share-blog-gplus"></span> </a>  <a id="rgw36_56ab9d3a58c4a" href="javascript:" title="Share on LinkedIn" class="link-nostyle js-share-item share-icon "  data-url="http://www.linkedin.com/shareArticle?mini=true&amp;url={{url}}{{#title}}&amp;title={{title}}{{/title}}&amp;source=ResearchGate" data-width="520" data-height="570" data-name="LinkedIn"> <span class="share-icon ico-share-linkedin-round reset-background ga-share-blog-linkedin"></span> </a>  <a id="rgw37_56ab9d3a58c4a" href="javascript:" title="Share on Reddit" class="link-nostyle js-share-item share-icon "  data-url="https://www.reddit.com/submit?url={{url}}{{#title}}&amp;title={{title}}{{/title}}" data-width="600" data-height="600" data-name="Reddit"> <span class="share-icon ico-share-reddit reset-background ga-share-blog-reddit"></span> </a>  </div></div>    <iframe id="rgw31_56ab9d3a58c4a" src="https://www.researchgate.net/c/o1q2er/javascript/lib/pdfjs/web/viewer.html?file=https%3A%2F%2Fwww.researchgate.net%2Fprofile%2FYutian_Chen3%2Fpublication%2F279633530_Subsampling-Based_Approximate_Monte_Carlo_for_Discrete_Distributions%2Flinks%2F565d728808aeafc2aac7970f.pdf%3FinViewer%3D1%26pdfJsDownload%3D1%26origin%3Dpublication_detail" allowfullscreen frameborder="0" style="width: 100%; height: 100%; box-sizing: border-box;"></iframe>    </div> <noscript> <div id="rgw26_56ab9d3a58c4a"  itemprop="articleBody">  <p>Page 1</p> <p>Subsampling-Based Approximate Monte Carlo for<br />Discrete Distributions<br />Yutian Chen<br />Department of Engineering<br />University of Cambridge<br />yutian.chen@eng.cam.ac.uk<br />Zoubin Ghahramani<br />Department of Engineering<br />University of Cambridge<br />zoubin@eng.cam.ac.uk<br />Abstract<br />Drawing a sample from a discrete distribution is one of the building components<br />for Monte Carlo methods. Like other sampling algorithms, discrete sampling also<br />suffers from high computational burden in large-scale inference problems. We<br />study the problem of sampling a discrete random variable with a high degree of<br />dependency that is typical in large-scale Bayesian inference and graphical models,<br />and propose an efficient approximate solution with a subsampling approach. We<br />make a novel connection between the discrete sampling and Multi-Armed Bandits<br />problems with a finite reward population and provide three algorithms with the-<br />oretical guarantees. Empirical evaluations show the robustness and efficiency of<br />the approximate algorithms in both synthetic and real-world large-scale problems.<br />1 Introduction<br />Sampling a random variable from a discrete (conditional) distribution is one of the core operations<br />in Monte Carlo methods. It is an ubiquitous and often necessary component for inference algorithms<br />such as Gibbs sampling and particle filtering. Applying discrete sampling for large-scale problems<br />has been a challenging task like other Monte Carlo algorithms due to the high computational burden.<br />Various approaches have been proposed to address different types of “large scales”. For example,<br />distributed algorithms have been used to sample a model with a large number of random discrete<br />variables [1, 2, 3], smart transition kernels were described for Markov chain Monte Carlo (MCMC)<br />algorithms to sample a variable efficiently in a large or even infinite state space [4, 5].<br />This paper is focused on the problem where the variable to sample has a large degree of dependency.<br />Specifically, a random variable with a finite domain X ∈ X follows the following distribution<br />p(X = x) ∝ ˜ p(X = x), with ˜ p(X = x) = f0(x)<br />N<br />?<br />n=1<br />fn(x)<br />(1)<br />where fncan be any function of x and f0denotes the computation that does not scale with the<br />number of dependencies N. Such distribution occurs frequently in machine learning problems. For<br />example, in Bayesian inference for a model with parameter X and N observations D = {yn}N<br />the unnormalized posterior distribution is ˜ p(X|D) = p(X)?N<br />conditional distribution is ˜ p(Xi|x−i) =?N<br />sampling X in a manner that is scalable in N.<br />A few scalable algorithms have been recently proposed for a general state space in the MCMC<br />framework such as Metropolis-Hastings (MH) [6, 7, 8], slice sampling [9] and Gibbs for binary<br />variables [7] based on an approximate subsampling approach. Approximate algorithms introduce<br />n=1,<br />i=1p(yi|X); in undirected graphical<br />model inference problems where a node Xiappears in N potential functions, the unnormalized<br />n=1φn(Xi,x−i) where x−idenotes the value of all the<br />other nodes in the graph and φndenotes a potential function that depends on Xi. Here we examine<br />1<br />arXiv:1506.09039v1  [stat.ML]  30 Jun 2015</p>  <p>Page 2</p> <p>bias in the stationary distribution of the Markov chain but given a fixed amount of runtime they could<br />reduce the expected error in the Monte Carlo estimate via a proper trade-off between variance and<br />bias by mixing faster as analyzed in [7, 10]. This is particularly important for large-scale learning<br />problems when the runtime is one of the limiting factors for generalization performance [11].<br />In this paper we propose a novel sampling algorithm to improve the efficiency of sampling discrete<br />distributions with the approximate subsampling approach. We first reformulate the problem in Eq. 1<br />as a Multi-Armed Bandit (MAB) problem with a finite reward population via the Gumbel trick<br />[12, 13], and then propose three algorithms with theoretical guarantees on the approximation error<br />and an upper bound of N|X| on the sample size. This is to our knowledge the first attempt to<br />address discrete sampling problem with a large number of dependencies and our work will likely<br />contributetoamorecompletelibraryofscalableMCMCalgorithms. Moreover, theracingalgorithm<br />in Sec. 3.3 provides a unified framework for subsampling-based discrete sampling, MH [7, 8] and<br />slice sampling [9] algorithms as discussed in Sec. 4. The proposed algorithms also deserve their<br />own interest for MAB problems under this particular setting.<br />We first review an alternative way of drawing discrete variables and build a connection with MABs<br />in Sec. 2, then propose three algorithms in Sec. 3. We discuss related work in Sec. 4 and evaluate<br />the proposed algorithms on both synthetic data and real-world problems of Bayesian inference and<br />graphical model inference in Sec. 5. Sec. 6 concludes the paper with a discussion.<br />2 Approximate Discrete Sampling<br />2.1 Discrete Sampling as an Optimization Problem<br />The common procedure to sample X from a discrete domain X = {1,2,...,D} is to first normalize<br />˜ p(X) and compute the CDF F(X = x) =?x<br />computing the sum of all the unnormalized probabilities. For ˜ p in the form of Eq. 1 this is O(ND).<br />An alternative procedure is to first draw D i.i.d. samples from the standard Gumbel distribution1<br />εi∼ Gumbel(0,1), and then solve the following optimization problem:<br />x = argmax<br />i∈X<br />It is shown in [14] that x follows the distribution p(X). With this method after drawing random<br />variables that do not depend on ˜ p, we turn a random sampling problem to an optimization problem.<br />While the computational complexity is the same to draw an exact sample, an approximate algorithm<br />may potentially save computations by avoiding computing accurate values of ˜ p(X = x) when x is<br />considered unlikely to be the maximum as discussed next.<br />i=1p(X = i). Then draw a uniform random variable<br />u ∼ Uniform(0,1], and find x that satisfies F(x − 1) &lt; u ≤ F(x). This procedure requires<br />log ˜ p(i) + εi.<br />(2)<br />2.2 Approximate Discrete Sampling as a Multi-Armed Bandits Problem<br />In a Multi-Armed Bandit (MAB) problem, the i’th bandit is a slot machine with an arm, which when<br />pulled generates an i.i.d. reward lifrom a distribution associated with that arm with an unknown<br />mean µi. The optimal arm identification problem for MABs [15, 16] in the fixed confidence setting<br />is to find the arm with the highest mean reward with a confidence 1−δ using as few pulls as possible.<br />Under the assumption of Eq. 1, the solution in Eq. 2 can be expressed as<br />x = argmax<br />i∈X<br />N<br />?<br />n=1<br />logfn(i) + logf0(i) + εi= argmax<br />i∈X<br />N<br />?<br />n=1<br />?<br />?<br />logfn(i) +1<br />N(logf0(i) + εi)<br />??<br />?<br />?<br />def<br />=li,n<br />= argmax<br />i∈X<br />1<br />N<br />N<br />?<br />n=1<br />li,n= argmax<br />i∈X<br />Eli∼Uniform(Li)[li]<br />def<br />= argmax<br />i∈X<br />µi<br />(3)<br />1The Gumbel distribution is used to model the maximum extreme value distribution. If a random variable<br />Z ∼ Exp(1), then −log(Z) ∼ Gumbel(0,1). ε can be easily drawn as −log(−log(u)) with u ∼ U[0,1].<br />2</p>  <p>Page 3</p> <p>where Li<br />pling problem into the optimal arm identification problem in MABs where the reward liis uniformly<br />sampled from a finite population Li. An approximate algorithm that solves the problem with a fixed<br />confidence may avoid drawing all the rewards from an obviously sub-optimal arm and save compu-<br />tations. We show the induced bias in the sample distribution as follows with proof in Appx. A.1.<br />Proposition 1. If an algorithm solves (2) exactly with a probability at least 1 − δ for any value of<br />ε, the total variation between the sample distribution ˆ p and the true distribution is bounded by<br />?ˆ p(X) − p(X)?TV≤ δ<br />WhenappliedintheMCMCframeworkasatransitionkernel, wecanapplyimmediatelythetheories<br />in [17, 10] to show that the approximate Markov chain satisfies uniform ergodicity under regular<br />conditions and the analysis of convergence rate are readily available under various assumptions.<br />def<br />= {li,1,li,2,...,li,N}. After drawing D Gumbel variables εi, we turn the discrete sam-<br />(4)<br />3 Algorithms for MABs with a Finite Population and Fixed Confidence<br />The key difference of our problem from the regular MABs is that our rewards are generated from<br />a finite population while regular MABs assume i.i.d. rewards. Because one can obtain the exact<br />mean by sampling all the N values li,nfor arm i without replacement, a good algorithm should pull<br />no more than N times for each arm regardless of the mean gap between arms. We introduce three<br />algorithms in this section whose sample complexity is upper bounded by O(ND).<br />3.1<br />The iteration of an algorithm is indexed by t.<br />{1,2,...,N}, the sampled set of reward indices up to t’th iteration from arm i with N(t)<br />[N], and the corresponding number of sampled rewards with T(t)<br />mean for i’th arm with ˆ µ(t)<br />i<br />=<br />|N(t)<br />(ˆ σ(t)<br />=<br />|N(t)<br />with (ˆ σ(t)<br />=<br />|N(t)<br />the bound of the reward value Ci<br />= maxn,n?{li,n− li,n?}. The subscripts and superscripts may be<br />dropped for notational simplicity when the meaning is clear from the context.<br />Notations<br />We denote the entire index set with [N] =<br />i<br />⊆<br />i. We define the estimated<br />def<br />1<br />i<br />i)2, the variance estimate of the mean gap between two arm<br />|<br />?<br />n∈N(t)<br />i<br />li,n, the natural variance (biased) estimate with<br />i)2def<br />1<br />i<br />|<br />?<br />i<br />n∈N(t)<br />?<br />i<br />(li,n− ˆ µ(t)<br />((li,n− lj,n) − (ˆ µ(t)<br />def<br />i,j)2def<br />1<br />|<br />n∈N(t)<br />i<br />i<br />− ˆ µ(t)<br />j))2(defined only when N(t)<br />i<br />= N(t)<br />j),<br />3.2<br />We first study one of the state-of-the-art algorithms for fixed-confidence optimal arm identification<br />problem and adjust it for the finite population setting. The lil’UCB algorithm [18] maintains an<br />upper confidence bound (UCB) of µithat is inspired by the law of the iterated logarithm (LIL) for<br />every arm. At each iteration, it draws a single sample from the arm with the highest bound and<br />updates it. The algorithm terminates when some arm is sampled much more often than all the other<br />arms. We refer readers to [18, Fig 1] for details. The time complexity for t iterations is O(log(D)t).<br />It was shown in [18] that lil’UCB achieved the optimal sample complexity up to constants.<br />However, lil’UCB requires i.i.d. rewards for each arm i, that is, sampled with replacement from Li.<br />Therefore, the total number of samples t is unbounded and could be ? ND when the means are<br />close to each other. We adapt lil’UCB for our problem with the following modifications:<br />Adapted lil’UCB<br />1. Samples li,nwithout replacement for each arm but keep different arms independent.<br />2. When T(t)<br />i<br />= N for some arm i, the estimate ˆ µ(t)<br />3. The algorithm terminates either with the original stopping criterion or when the arm with<br />the highest upper bound has an exact mean estimate, whichever comes first.<br />i<br />becomes exact. So set its UCB to ˆ µ(t)<br />i.<br />The adapted algorithm satisfies all the theoretical guarantees in [18, Thm 2] with additional proper-<br />ties as shown in the following proposition with proof in Sec. A.2.<br />Proposition 2. Theorem 2 of [18] holds for the adjusted lil’UCB algorithm. Moreover T(t)<br />N,∀i,t. Therefore, when the algorithm terminates, t =?<br />3<br />i<br />≤<br />i∈XT(t)<br />i<br />≤ ND.</p>  <p>Page 4</p> <p>Algorithm 1 Racing Algorithm with a Finite Reward Population<br />Require: Number of arms D, population size N, mini-batch sizes {m(t)}t∗<br />1 − δ, uncertainty bound function G(δ,T, ˆ σ,C), range of samples Ci(optional).<br />t ← 0, T ← 0, D ← {1,2,...,D}, N ← ∅<br />while |D| &gt; 1 do<br />t ← t + 1<br />Sample w/o replacement m(t)indices M ⊆ [N]\N, and set N ← N ∪ M, T ← T + m(t)<br />Compute li,n,∀i ∈ D,n ∈ M, and update ˆ µiand ˆ σi(or ˆ σi,j), ∀i ∈ D.<br />Find the best arm x ← argmaxi∈Dˆ µi<br />Eliminate sub-optimal arms when the estimated gap is large D ← D\{i : ˆ µx− ˆ µi &gt;<br />G(δ<br />end while<br />return D<br />t=1, confidence level<br />D,T, ˆ σx,Cx) + G(δ<br />D,T, ˆ σi,Ci)} (or D ← D\{i : ˆ µx− ˆ µi&gt; G(<br />δ<br />D−1,T, ˆ σx,i),Cx+ Ci})<br />3.3Racing Algorithm for a Finite Population<br />When rewards are sampled without replacement, the negative correlation between rewards would<br />generally improve the convergence of ˆ µi. Unfortunately, the bound in lil’UCB ignores the nega-<br />tive correlation when T(t)<br />i<br />&lt; N even with the adaptations. We introduce a new family of racing<br />algorithms [19] that takes advantage of the finite population setting.<br />Our proposed algorithm is shown in Alg 1. It maintains a set of candidate set D initialized with<br />all arms. At iteration t, a shared mini-batch of m(t)indices are drawn w/o replacement for all<br />survived arms in D. Then an uncertainty bound G is used to eliminate sub-optimal arms with a<br />given confidence. The algorithm stops when only one arm remains. We require for m(t)that the<br />total number of sampled indices T(t∗)=?t∗<br />parameter. We also require the confidence bound G = 0 at iteration t whenever T = N so that<br />Alg. 1 always stops within t∗iterations. The computational complexity for t iterations is O(DT(t))<br />with the marginal estimate ˆ σiand O(D2T(t)) with the pairwise estimate ˆ σi,j. The former version<br />is more efficient than the latter when D is large at the price of a looser bound. The choice of G<br />differentiates specific algorithms and will be discussed in the following sections.<br />Proposition 3. If G satisfies<br />def<br />= P(∃t &lt; t∗, ˆ µ(t)− µ &gt; G(δ,T(t), ˆ σ(t),C)) ≤ δ, ∀δ ∈ (0,1),<br />with a probability at least 1 − δ, Alg. 1 returns the optimal arm with at most ND samples.<br />The proof is provided in Appx. A.3. Unlike adapted lil’UCB, Racing draws a shared set of sample<br />indices among all the arms and could provide a tighter bound with pairwise variance estimates ˆ σi,j<br />when there is positive correlation which is a typical case in Bayesian inference problems.<br />t=1m(t)equals N at the last iteration t∗. Particularly,<br />N<br />m(1)? + 1) and leave m(1)as a free<br />we take a doubling schedule T(t)= 2T(t−1)(so t∗= ?log2<br />E<br />(5)<br />3.3.1Racing with Serfling Concentration bounds for G<br />Serfling [20] studied the concentration inequalities of sampling without replacement and obtained<br />an improved Hoeffding bound. [21] extended the work and provided an empirical Bernstein-Serfling<br />bound that was later used in [8] for the subsampling-based MH algorithm: for any δ ∈ (0,1] and<br />any n ≤ N, with probability 1 − δ, it holds that<br />?<br />n<br />where κ =7<br />3+<br />(1 − πn)(1 +1<br />ρnthat is missing in regular empirical Bernstein bounds reduces the bound significantly when n is<br />close to N. We set m(1)= 2 in Alg. 1 to provide a valid ˆ σ(t)for any t and set the uncertain bound<br />G with the empirical Bernstein-Serfling (EBS) bounds as<br />ˆ µn− µ ≤ ˆ σn<br />2ρnlog(5/δ)<br />+κC log(5/δ)<br />n<br />if n ≤ N/2<br />if n &gt; N/2, with πn<br />def<br />= BEBS(δ,n, ˆ σn,C)<br />(6)<br />3<br />√2, and ρn=<br />?<br />1 − πn−1<br />n)<br />def<br />=<br />n<br />N. The extra term<br />GEBS(δ,T, ˆ σ,C) = BEBS<br />?<br />δ<br />t∗− 1,T, ˆ σ,C<br />?<br />(7)<br />4</p>  <p>Page 5</p> <p>It is trivial to prove that GEBSsatisfies the condition in Eq. 5 using a union bound over t &lt; t∗.<br />3.3.2Racing with a Normal Assumption for G<br />The concentration bounds often give a conservative strategy as it assume an arbitrary bounded re-<br />ward distribution. When the number of drawn samples is large, the central limit theorem suggests<br />that ˆ µ(t)follows approximately a Gaussian distribution. [7] made such an assumption and obtained<br />a tighter bound. We first provide an immediate corollary of Prop. 2 of [7, Appx. A].<br />Corollary 4. Let ˆ µ(t)<br />from any finite population with mean µ and unit variance. The joint normal random variables ˜ µ(t)<br />that match the mean and covariance matrix with ˆ µ(t)<br />unit,t = 1,2,...,t∗be the estimated means using sampling without replacement<br />unitfollow a Gaussian random walk process as<br />pµ(˜ µ(t)|˜ µ(1),..., ˜ µ(t−1)) = N(mt(˜ µ(t−1)),St)<br />Bt<br />T(t)<br />(8)<br />where mt= µ + At(˜ µt−1− µ),St=<br />πtshort for πT(t).<br />Remark 5. The marginal distribution p(˜ µ(t)) = N<br />approaches 0 when T(t)→ N.<br />Assumption 6. When T(t)? 1,∀t, we assume ˆ σ(t)≈ σ and the central limit theorem suggests that<br />the joint distribution of ˆ µ(t)/ˆ σ(t)can be approximated by the joint distribution of ˜ µ(t).<br />?<br />1 −T(t)−1<br />N−1<br />?<br />, At=<br />πt−1(1−πt)<br />πt(1−πt−1), Bt=<br />πt−πt−1<br />πt(1−πt−1)with<br />?<br />µ,<br />1<br />T(t)<br />?<br />1 −T(t)−1<br />N−1<br />??<br />where the variance<br />With the normal assumption, we choose the uncertainty bound G in the following form<br />GNormal(δ,T, ˆ σ) =<br />ˆ σ<br />√T<br />?<br />1 −T − 1<br />N − 1<br />?1/2<br />BNormal<br />(9)<br />Intuitively we use a constant confidence level, Φ(BNormal), for all marginal distributions of ˆ µ(t)over<br />t where Φ(·) is the CDF of the standard normal. To choose the constant BNormal, we plug GNormal<br />into the condition for G in Eq. 5 and apply the normal distribution (8) to solve the univariate equation<br />E(B) = δ. This way of computing the bound G is better than applying the union bound across t as in<br />the previous section because it takes into account the correlation of mean estimates across iterations.<br />Appx. B provides a table and a plot of BNormal(δ) = E−1(δ). Notice that BNormalonly needs<br />to be computed once and we can obtain it for any δ by either interpolating the table or computing<br />numerically with code to be shared (runtime &lt; 1 second). For the parameter of the first mini-batch<br />size m(1), a value of 50 performs robustly in all experiments.<br />We provide the sample complexity below with the proof in Appx. A.4. T∗(∆) → DN, as ∆ → 0.<br />Proposition 7. Let x∗be the best arm and ∆ be the minimal normalized gap of means from other<br />arms, defined as mini?=x∗µx∗−µi<br />when using pairwise variance estimate ˆ σx,i. If Assump. 6 holds, with a probability at least 1 − δ<br />Racing-Normal draws no more rewards than<br /><br />(N − 1)<br />def<br />= m2?log2n/m?∧ N ≥ n,∀n ≤ N. D?def<br />σx∗+σiwhen using marginal variance estimate ˆ σiand mini?=x∗µx∗−µi<br />σx∗,i<br />T∗(∆) = D<br /><br />N<br />∆2<br />4B2<br />Normal(δ/D?)+ 1<br /><br /><br />m(1)<br />(10)<br />where ?n?m<br />= D if using ˆ σiand is D − 1 if using ˆ σx,i.<br />3.4Variance Reduction for Random Rewards with Control Variates<br />The difficulty of MABs depends heavily on the ratio of the mean gap to the reward noise ∆. To<br />improve the signal noise ratio, we exploit the control variates technique [22] to reduce the reward<br />variance. Consider a variable hi,nwhose expectation En∼[N][hi,n] can be computed efficiently.<br />The residue reward li,n− hi,n+ En[hi,n] has the same mean as li,nand the variance is reduced if<br />hi,n≈ li,n. In the Bayesian inference experiment where the factor fn(X = i) = p(yn|X = i), we<br />adopt a similar approach as [23] and take the Taylor expansion of li,naround a reference point ˆ y as<br />li,n≈ li(ˆ y) + gT<br />i(yn− ˆ y) +1<br />2(yn− ˆ y)THi(yn− ˆ y)<br />def<br />= hi,n<br />(11)<br />5</p>  <p>Page 6</p> <p>where giand Hiare the gradient and Hessian matrix of logp(y|i) respectively evaluated at ˆ y.<br />E[hi,n] can computed analytically with the first two moments of yn. A typical choice of ˆ y is E[y].<br />The control variate method is mostly useful for Racing-Normal because for algorithms depending<br />on a reward bound C it could be hard to get a tight bound for li,n− hi,nand we often end up with<br />an even more conservative strategy.<br />4 Related Work<br />The Gumbel trick has been exploited in [14, 12, 13] for different problems. The closest work is [13]<br />where this trick is extended to draw continuous random variables with a Gumbel process, reminis-<br />cent to adaptive rejection sampling.<br />Our work is closely related to the optimal arm identification problem for MABs with a fixed con-<br />fidence. This is, to our knowledge, the first work to consider MABs with a finite population. The<br />proposed algorithms tailored under this setting could be of interest beyond the discrete sampling<br />problem. The normal assumption in Sec. 3.3.2 is similar to UCB-Normal in [24] but the latter<br />assumes a normal distribution for individual rewards and will perform poorly when it does not hold.<br />The racing algorithm in Sec. 3.3 is also related to the subsampling-based MH algorithms in [8, 7].<br />In fact, let x and x?be the current and proposed value in an MH iteration, Racing-EBS and Racing-<br />Normal reduce to the algorithms in [8] and [7] respectively if we set<br />X = {x,x?}, f0(1) = u p(x)q(x?|x), f0(2) = p(x?)q(x|x?), fn(x) = p(yn|x)<br />where p(x) is the prior distribution, u ∼ Uniform[0,1] and q(·|·) is the proposal distribution. The<br />difference with [8] is that we distribute the error δ evenly across t in Eq. 7 while [8] set δt =<br />(p − 1)/(p(T(t))p)δ with p a free parameter. The differences with [7] are that we take a doubling<br />schedule for m(t)and replace the t-test with the normal assumption. We find that our algorithms<br />show more efficient and robust performance than both original algorithms in practice. Moreover,<br />the binary Gibbs sampling in [7, Appx. F] is also a special case of Racing-Normal with D = 2.<br />Therefore, Alg. 1 provides a unifying approach to a family of subsampling-based samplers.<br />(12)<br />5<br />Since this is the first work to discuss efficient discrete sampling for problem (1), we compare the<br />adapted lil’UCB, Racing-EBS, Racing-Normal with the exact sampler only. We report the result of<br />Racing-Normal in real data experiments only as the speed gains of the other two are marginal.<br />Experiments<br />5.1 Synthetic Data<br />We construct a distribution with D = 10 by sampling N = 105reward of li,nfor each state from<br />one of the three distributions N(0,1), Uniform[0,1], LogNormal(0,2). We normalized li,nto have<br />a fixed distribution in Fig. 1a and a reward variance σ2that controls the difficulty. The normal dis-<br />tribution is the idea setting for Racing-Normal, and the uniform distribution is desirable for adapted<br />lil’UCB and Racing-EBS as the reward bound is close to σ . The LogNormal distribution, whose ex.<br />kurtosis ≈ 4000, is difficult for all due to the heavy tail. We use a tight bound C = max{li,n−li,n?}<br />for Racing-EBS. We set the scale parameter of adapted lil’UCB with C/2 and other parameters with<br />the heuristic setting in [18]. Racing uses the pairwise variance estimate.<br />Fig. 1b-d show the empirical error of best arm identification by drawing 104samples of X for each<br />setting and vary the target error bound δ ∈ [10−3,0.1]. The bound appears very loose for lil’UCB<br />and Racing-EBS but is sharp for Racing-Normal when the noise is large (1b) and δ ? 1. This is<br />consistentwiththedirectcomparisonofuncertaintyboundsinFig.1e. Consequently, giventhesame<br />error tolerance δ Racing-Normal requires much fewer rewards than the other conservative strategies<br />in all the settings except when σ = 10−5and li,n∼ Uniform[0,1], as shown in Fig. 1f-h. We justify<br />the observations with more experiments in Appx. C.1 with D ∈ {2,100} and marginal estimate ˆ σi.<br />Surprisingly, Racing-Normal performs robustly regardless of reward distributions with the first mini-<br />batch size m(1)= 50 while it was shown in [8] that the algorithm with the same normal assumption<br />in [7] failed with LogNormal even when m(1)= 500. The difference is due to our doubling scheme<br />where central limit theorem applies quickly with m(t)increasing exponentially.<br />6</p>  <p>Page 7</p> <p>123456789 10<br />0<br />0.05<br />0.1<br />0.15<br />0.2<br />0.25<br />0.3<br />0.35<br />0.4<br />X<br />p(X)<br />(a) p(X)<br />10<br />−3<br />10<br />−2<br />10<br />−1<br />10<br />−3<br />10<br />−2<br />10<br />−1<br />Error Torelance δ<br />Empirical Error<br /> <br /> <br />δ<br />Racing−Normal<br />Racing−EBS<br />Adapted lil’UCB<br />No error occurs for Racing EBS<br />and Adapted lil’UCB<br />(b) σ = 0.1, very hard<br />1<br />10<br />−3<br />10<br />−2<br />10<br />−1<br />10<br />−3<br />10<br />−2<br />10<br />−1<br />Error Torelance δ<br />Empirical Error<br />(c) σ = 10−4, easy<br />10<br />−3<br />10<br />−2<br />10<br />−1<br />10<br />−3<br />10<br />−2<br />10<br />−1<br />Error Torelance δ<br />Empirical Error<br />(d) σ = 10−5, very easy<br />10<br />Number of Sampled Rewards T<br />0<br />10<br />1<br />10<br />2<br />10<br />3<br />10<br />4<br />10<br />5<br />10<br />−4<br />10<br />−2<br />10<br />0<br />10<br />2<br />10<br />4<br />Bound G<br /> <br /> <br />EBS<br />Normal<br />LIL’UCB<br />(e)<br />G(T) with δ = 0.1.<br />Uncertainty bounds<br />10<br />−3<br />10<br />−2<br />10<br />−1<br />0.5<br />0.6<br />0.7<br />0.8<br />0.9<br />Error Torelance δ<br />Data Percentage<br /> <br /> <br />Racing−Normal<br />Racing−EBS<br />Adapted lil’UCB<br />(f) σ = 0.1<br />10<br />−3<br />10<br />−2<br />10<br />−1<br />10<br />−3<br />10<br />−2<br />10<br />−1<br />10<br />0<br />Error Torelance δ<br />Data Percentage<br />(g) σ = 10−4, in log scale<br />10<br />−3<br />10<br />−2<br />10<br />−1<br />10<br />−3<br />10<br />−2<br />10<br />−1<br />10<br />0<br />Error Torelance δ<br />Data Percentage<br />(h) σ = 10−5, in log scale<br />Figure 1: Synthetic data. (b,c,d) Estimated error with 95% confidence interval. Plots not shown if<br />no error occured. (f,g,h) proportion of sampled rewards. li,nis sampled from Normal (×), Uniform<br />(?) and LogNormal (?) distributions. Plots of Racing-Normal overlap in (f,g,h).<br />5.2Bayesian ARCH Model Selection<br />We evaluate Racing-Normal in a Bayesian model selection problem for the auto-regressive condi-<br />tional heteroskedasticity (ARCH) models. Specifically, we use a mixture of ARCH models for the<br />return rtof stock price series with student-t innovations, each component with a different order q:<br />q<br />?<br />whereπ = {πq: q ∈ Q}isthepriordistributionof acandidatemodelinthesetQ. Therandomvari-<br />ables to infer include the discrete model choice q and continuous parameters {αi}q<br />the augmented MCMC algorithm in [25] to avoid transdimensional moves. We apply subsampling-<br />based scalable algorithms to sample all variables: Racing-Normal Gibbs for q, stochastic gradient<br />Langevin dynamics (SGLD) [6] corrected with Racing-Normal MH (Sec. 4) for αiand ν. We use<br />adjusted priors ˜ πqas suggested by [25] for sufficient mixing between all models and tune them<br />with adaptive MCMC. The adjusted posterior ˜ p(q|r) ∝ ˜ πqp(r|q) is then close to uniform and the<br />value πq/˜ πqprovides an estimate to the real unnormalized posterior p(q|r). Control variates are also<br />applied to reduce variance. Details of the sampling algorithm are provided in Appx. C.2.<br />We apply the model on the 5-minute Shanghai stock exchange composite index of one year con-<br />sisting of about 13,000 data points (Fig. 2a). Q = {5,10,15,20,25,30}. We set m(1)= 50 and<br />δ = 0.05. The control variate method reduces the reward variance by about 2∼3 orders of magni-<br />tude. Fig. 2b shows the estimated log-posterior of q by normalizing πq/˜ πqin the adaptive MCMC as<br />afunctionofthenumberoflikelihoodevaluations(consistentwithruntime). Thesubsampling-based<br />sampler (Sub) converges about three times faster. We then fix ˜ πqfor a fixed stationary distribution<br />and run MCMC for 105iterations to compare Sub with the exact sampler. The empirical error rates<br />for Racing-Normal Gibbs and MH are about 4 × 10−4and 2 × 10−3respectively. Fig. 2c shows<br />estimated adjusted posterior from 5 runs, and Fig. 2d compares the auto-correlation of sample q.<br />Sub obtains over twice the effective sample size without noticeable bias after the burn-in period.<br />5.3Author Coreference<br />rt= σtzt; zt<br />iid<br />∼ tν(0,1); σ2<br />t= α0+<br />i=1<br />αir2<br />t−i; q ∼ Discrete(π); αi,ν<br />iid<br />∼ Gamma(1,1)<br />i=0,ν. We adopt<br />We then study the performance in a large-scale graphical model inference problem. The author<br />coreference problem for a database of scientific paper citations is to cluster the mentions of authors<br />into real persons. [26] addressed this problem with a conditional random field model with pairwise<br />factors. The joint and conditional distributions are respectively<br /><br />yi=yj,i?=j,∀i,j<br />pθ(y|x) ∝ exp<br /><br />?<br />fθ(xi,xj)<br /><br />, pθ(Yi= yi|y−i,x) ∝ exp<br />7<br /><br /><br />?<br />yj∈Cy={j:yj=y,j?=i}<br />fθ(xi,xj)<br /><br /></p>  <p>Page 8</p> <p>0 2000 400060008000100001200014000<br />−0.03<br />−0.02<br />−0.01<br />0<br />0.01<br />0.02<br />0.03<br />(a) Stock index return rt<br />10<br />5<br />10<br />6<br />10<br />7<br />10<br />8<br />10<br />9<br />−120<br />−100<br />−80<br />−60<br />−40<br />−20<br />0<br /># likelihood evaluations<br />Estimated log p(q)<br /> <br /> <br />q=5<br />q=10<br />q=15<br />q=20<br />q=25<br />q=30<br />(b) Estimated logp(q|r)<br />51015202530<br />0<br />0.05<br />0.1<br />0.15<br />0.2<br />q<br />˜ p(q|D)<br /> <br /> <br />Gibbs + LD with MH<br />Sub Gibbs + SGLD with Sub MH<br />(c) Adjusted post. ˜ p(q|r)<br />Figure 2: Bayesian ARCH Model Selection.<br />dashed: approximate using Sub Gibbs + SGLD with Sub MH.<br />00.51 1.52<br />7<br />x 10<br />0<br />0.2<br />0.4<br />0.6<br />0.8<br />1<br /># likelihood evaluations<br />Auto−correlation<br /> <br /> <br />Exact, ESS/eval: 2.6e−07<br />Sub,    ESS/eval: 5.9e−07<br />(d) Auto-correlation of q<br />Solid: exact,<br />0246810<br />10<br />x 10<br />0.2<br />0.3<br />0.4<br />0.5<br />0.6<br />0.7<br />Number of factors evaluated<br />B3 F−1 Score<br /> <br /> <br />Exact Gibbs<br />Sub Gibbs<br />(a) B3F-1 vs #factor evaluations<br />0055 1010 15 1520<br />55<br />x 10 x 10<br />0.2<br />0.3<br />0.4<br />0.5<br />0.6<br />0.7<br />Number of iterations<br />B3 F−1 Score<br /> <br /> <br />20<br />0.2<br />0.4<br />0.6<br />0.8<br />1<br />Relative # of evaluated factors<br />Exact Gibbs<br />Sub Gibbs<br />Exact overlaps with Sub<br />(b) B3F-1 vs iteration<br />Figure 3: Author Coreference.<br />Bigger B3F-1 score is better.<br />where x = {xi}N<br />i’th mention. The factor fθ(xi,xj) measures the similarity between two mentions based on author<br />names, coauthors, paper title, etc, parameterized by θ. In the conditional distribution, yican take a<br />value of any non-empty cluster or another empty cluster index. When a cluster Cycontains a lot of<br />mentions, a typical case for common author names, the number of factors to be evaluated Ny= |Cy|<br />will be large. We consider the MAP inference problem with fixed θ using annealed Gibbs sampling<br />[27]. We apply Racing-Normal to sample Yiby subsampling Cyfor each candidate value y. An<br />important difference of this problem from Eq. 1 is that Ny?= Ny?,∀y ?= y?and Nyhas a heavy tail<br />distribution. We let the mini-batch size depend on Nywith details provided in Appx. C.3.<br />We run the experiment on the union of an unlabeled DBLP dataset of BibTex entries with about 5M<br />authors and a Rexa corpus of about 11K author mentions with 3160 entries labeled. We monitor the<br />clustering performance on the labeled subset with the B3F-1 score [28]. We use δ = 0.05 and the<br />empirical error rate is about 0.046. The number of candidate values D varies in 2 ∼ 215 and Ny<br />varies in 1 ∼ 1829 upon convergence. Fig. 3a shows the F-1 score as a function of the number of<br />factor evaluations with 7 random runs for each algorithm. Sub Gibbs converges about three times<br />faster than exact Gibbs. Fig. 3b shows F-1 as a function of iterations that renders almost identical<br />behavior for both algorithms, which suggests negligible bias in Sub Gibbs. The relative number of<br />the evaluated factors of sub to exact Gibbs indicates about a 5-time speed up near convergence. The<br />initial speed up is small because every cluster is initialized with a single mention, i.e. Ny= 1.<br />i=1is the set of observed author mentions and yi ∈ N+is the cluster index for<br />6 Discussion<br />We consider the discrete sampling problem with a high degree of dependency and proposed three<br />approximate algorithms under the framework of MABs with theoretical guarantees. The Racing<br />algorithm provides a unifying approaches to various subsampling-based Monte Carlo algorithms<br />and also improves the robustness of the original MH algorithm in [7]. This is also the first work to<br />discuss MABs under the setting of a finite reward population.<br />Empirical evaluations show that Racing-Normal achieves a robust and the highest speed-up among<br />all competitors. Whilst adaptive lil’UCB shows inferior empirical performance to Racing-Normal, it<br />has a better sample complexity w.r.t. the number of arms. It will be a future direction to combine the<br />bound of Racing-Normal with other MAB algorithms including lil’UCB. Other interesting problems<br />include how to relax the normal assumptions without sacrificing the performance and how to extend<br />our work to draw continuous random variables efficiently with the Gumbel process[13].<br />8</p>  <p>Page 9</p> <p>References<br />[1] David Newman, Arthur Asuncion, Padhraic Smyth, and Max Welling. Distributed algorithms for topic<br />models. The Journal of Machine Learning Research, 10:1801–1828, 2009.<br />[2] S. Bratires, J. van Gael, A. Vlachos, and Z. Ghahramani. Scaling the iHMM: Parallelization versus<br />hadoop. In Computer and Information Technology (CIT), 2010 IEEE 10th International Conference on,<br />pages 1235–1240, June 2010.<br />[3] Yao Wu, Qiang Yan, Danny Bickson, Yucheng Low, and Qing Yang. Efficient multicore collaborative<br />filtering. In ACM KDD CUP workshop, 2011.<br />[4] Aaron Li, Amr Ahmed, Sujith Ravi, and Alex Smola. Reducing the sampling complexity of topic models.<br />In Proceedings of the ACM Conference on Knowledge Discovery and Data Mining (KDD), 2014.<br />[5] Maria Kalli, Jim E Griffin, and Stephen G Walker. Slice sampling mixture models. Statistics and com-<br />puting, 21(1):93–105, 2011.<br />[6] Max Welling and Yee W Teh. Bayesian learning via stochastic gradient langevin dynamics. In Proceed-<br />ings of ICML 2011, pages 681–688, 2011.<br />[7] Anoop Korattikara, Yutian Chen, and Max Welling. Austerity in MCMC land: Cutting the Metropolis-<br />Hastings budget. In Proceedings of the 31th International Conference on Machine Learning, ICML 2014,<br />Beijing, China, 21-26 June 2014, pages 181–189, 2014.<br />[8] R´ emi Bardenet, Arnaud Doucet, and Chris Holmes. Towards scaling up Markov chain Monte Carlo:<br />an adaptive subsampling approach. In Proceedings of The 31st International Conference on Machine<br />Learning, pages 405–413, 2014.<br />[9] Christopher DuBois, Anoop Korattikara, Max Welling, and Padhraic Smyth. Approximate slice sampling<br />for Bayesian posterior inference. In Proceedings of AISTATS, pages 185–193, 2014.<br />[10] Natesh S Pillai and Aaron Smith. Ergodicity of approximate MCMC chains with applications to large<br />data sets. arXiv preprint arXiv:1405.0182, 2014.<br />[11] L. Bottou and O. Bousquet. The tradeoffs of large scale learning. In NIPS, volume 20, pages 161–168,<br />2008.<br />[12] G. Papandreou and A. Yuille. Perturb-and-MAP random fields: Using discrete optimization to learn and<br />sample from energy models. In Proceedings of ICCV, pages 193–200, Barcelona, Spain, November 2011.<br />[13] Chris J Maddison, Daniel Tarlow, and Tom Minka. A∗ sampling. In Z. Ghahramani, M. Welling,<br />C. Cortes, N.D. Lawrence, and K.Q. Weinberger, editors, NIPS, pages 3086–3094, 2014.<br />[14] Dima Kuzmin and Manfred K Warmuth. Optimum follow the leader algorithm. In Proceedings of the<br />18th annual conference on Learning Theory, pages 684–686. Springer-Verlag, 2005.<br />[15] Robert E Bechhofer. A sequential multiple-decision procedure for selecting the best one of several normal<br />populations with a common unknown variance, and its use with various experimental designs. Biometrics,<br />14(3):408–429, 1958.<br />[16] Edward Paulson. A sequential procedure for selecting the population with the largest mean from k normal<br />populations. The Annals of Mathematical Statistics, pages 174–180, 1964.<br />[17] A Yu Mitrophanov. Sensitivity and convergence of uniformly ergodic markov chains. Journal of Applied<br />Probability, pages 1003–1014, 2005.<br />[18] Kevin Jamieson, Matthew Malloy, Robert Nowak, and S´ ebastien Bubeck. lil’UCB: An optimal explo-<br />ration algorithm for multi-armed bandits. In Proceedings of The 27th COLT, pages 423–439, 2014.<br />[19] Oded Maron and Andrew W. Moore. Hoeffding races: Accelerating model selection search for classifica-<br />tion and function approximation. In Advances in Neural Information Processing Systems 6, pages 59–66.<br />Morgan-Kaufmann, 1994.<br />[20] R. J. Serfling. Probability inequalities for the sum in sampling without replacement. Ann. Statist., 2(1):39–<br />48, 01 1974.<br />[21] R´ emi Bardenet and Odalric-Ambrym Maillard. Concentration inequalities for sampling without replace-<br />ment. arXiv preprint arXiv:1309.4029, 2013.<br />[22] James R Wilson. Variance reduction techniques for digital simulation. American Journal of Mathematical<br />and Management Sciences, 4(3-4):277–312, 1984.<br />[23] Chong Wang, Xi Chen, Alex J Smola, and Eric P Xing. Variance reduction for stochastic gradient opti-<br />mization. In Advances in Neural Information Processing Systems, pages 181–189, 2013.<br />[24] PeterAuer, NicoloCesa-Bianchi, andPaulFischer. Finite-timeanalysisofthemultiarmedbanditproblem.<br />Machine learning, 47(2-3):235–256, 2002.<br />[25] B.P. Carlin and S. Chib. Bayesian model choice via Markov chain Monte Carlo. Journal of the Royal<br />Statistical Society, Series B, 57:473–484, 1995.<br />[26] Sameer Singh, Michael Wick, and Andrew McCallum. Monte Carlo MCMC: efficient inference by ap-<br />proximate sampling. In Proceedings of EMNLP-CoNLL 2012, pages 1104–1113, 2012.<br />[27] Jenny Rose Finkel, Trond Grenager, and Christopher Manning. Incorporating non-local information into<br />information extraction systems by gibbs sampling. In Proceedings of the 43rd ACL, pages 363–370, 2005.<br />[28] Amit Bagga and Breck Baldwin. Algorithms for scoring coreference chains. In LREC workshop on<br />linguistics coreference, volume 1, pages 563–566, 1998.<br />[29] Wassily Hoeffding. Probability inequalities for sums of bounded random variables. Journal of the Amer-<br />ican statistical association, 58(301):13–30, 1963.<br />9</p>  <p>Page 10</p> <p>A Proofs<br />A.1Proof of Prop. 1<br />Proof. For a discrete state space, the total variation is equivalent to half of L1distance between<br />two probability vectors. Denote by ˆ p(X = i|ε) the distribution of the output of the approximate<br />algorithm conditioned on the vector of Gumbel variables ε, and x(ε) the solution of Eq. 2 as a<br />function of ε. According to the premise of Prop. 1, ˆ p(X = x(ε)|ε) ≥ 1 − δ,∀ε. We can bound the<br />L1error of the conditional probability as<br />?<br />where δi,jis the Kronecker delta function. Then we can show<br />?<br />=1<br />2<br />i∈X<br />≤1<br />2<br />i∈X<br />=1<br />2<br />ε<br />i∈X<br />≤ δ<br />i∈X<br />??ˆ p(X = i|ε) − δi,x(ε)<br />??= |ˆ p(X = x(ε)|ε) − 1| +<br />?<br />i?=x(ε)<br />|ˆ p(X = i|ε)| ≤ 2δ,∀ε<br />(13)<br />?ˆ p(X) − p(X)?TV=1<br />2<br />i∈X<br />?<br />?<br />?<br />|˜ p(X = i) − p(X = i)|<br />????<br />ε<br />??<br />?<br />ε<br />?ˆ p(X = i|ε) − δi,x(ε)<br />??ˆ p(X = i|ε) − δi,x(ε)<br />??ˆ p(X = i|ε) − δi,x(ε)<br />?dP(ε)<br />??dP(ε)<br />??<br />????<br />?<br />?<br />dP(ε)<br />(14)<br />A.2 Sketch of the proof of Prop. 2<br />Proof. As the proof of this proposition is almost identical to the proof of [18], we only outlines the<br />difference due to the adaptation. In the proof of [18, Theorem 2], the i.i.d. assumption for rewards<br />from each arm was used only in Lemma 3 to provide Chernoff’s bound and Hoeffding’s bound. As<br />notedin[29, Sec.6]thoseboundswouldstillholdwhenrewardsaresampledfromafinitepopulation<br />without replacement. Therefore, when T(t)&lt; N all the bounds hold for adapted lil’UCB.<br />When T(t)<br />is a valid upper bound of µi, in fact much tighter than the bound in the original algorithm because<br />ˆ µ(t)<br />i<br />= µiexactly when the entire population is observed.<br />i<br />= N, the second modification sets the upper bound of the mean estimate to ˆ µ(t). That<br />Therefore, as long as T(t)<br />1 and 2 only.<br />i<br />≤ N,∀i, Theorem 2 in [18] applies to adapted lil’UCB with modification<br />With the third modification, T(t)could never be bigger than N at the stopping time, which proves<br />the second part of Prop 2. The proof can then be concluded if we can show modification 3 does not<br />change the output of adapted lil’UCB with the first two modifications only. This is true because if we<br />donotstopwhentheselectedarmisatisfiesT(t)<br />i<br />= N, wedonotneedtoupdatetheupperboundofi<br />because the estimated mean is already exact. Since no upper bound is changed, the arm i will always<br />be chosen for now on and eventually the original stopping criterion of T(t)<br />met and the same arm i will be returned.<br />i<br />≥ 1 + λ?<br />j?=iTj(t) is<br />A.3Proof of Prop. 3<br />Proof. Denote by x(t)the arm with the highest estimated mean at iteration t and x∗the optimal arm<br />with the highest true mean, µx∗ &gt; µi,∀i ?= x∗. If Alg. 1 does not stop in the first t∗− 1 iterations,<br />the estimated means of all the survived arms become exact at the last iteration t∗, ˆ µ(t∗)<br />we require T(t∗)= N. Then x(t∗)= x∗. As we require G(δ,T = N, ˆ σ,C) = 0,∀δ, ˆ σ,C, all the<br />i<br />= µibecause<br />10</p>  <p>Page 11</p> <p>sub-optimal arms will be eliminated by the last iteration and the algorithm always returns the correct<br />best arm. This proves the upper bound of the sample size of ND.<br />Now to prove the confidence level, all we need to show is that with at least a probability 1 − δ arm<br />x∗survived all the iterations t &lt; t∗.<br />Let us first consider the case when Alg. 1 uses the marginal variance estimate ˆ σ(t)<br />?<br />?<br />Applying condition Eq. 5 and the union bound, we get P(∪i∈XEi) ≤?<br />ˆ µx−ˆ µx∗ = (ˆ µx−µx)−(ˆ µx∗−µx∗)+(µx−µx∗) &lt; G<br />i. Let the events<br />Ei=<br />∃t &lt; t∗, ˆ µ(t)<br />i<br />− µi&gt; G<br />?δ<br />D,T(t), ˆ σ(t)<br />?δ<br />i,Ci<br />??<br />,∀i ?= x∗<br />??<br />i∈XEi = δ. So with a<br />?<br />Ex∗ =<br />∃t &lt; t∗,−ˆ µ(t)<br />x∗ − (−µx∗) &gt; G<br />D,T(t), ˆ σ(t)<br />i,Ci<br />(15)<br />probability at least 1 − δ, none of those events will happen. In that case for any iteration t &lt; t∗,<br />?δ<br />D,T(t), ˆ σ(t)<br />x,Cx<br />+G<br />?δ<br />D,T(t), ˆ σ(t)<br />x∗,Cx∗<br />?<br />(16)<br />So arm x∗won’t be eliminated at iteration t.<br />Similarly, for the case when Alg. 1 uses the pairwise variance estimate ˆ σ(t)<br />?<br />Applying condition Eq. 5 and the union bound, we get P(∪i∈X\{x∗}Ei,x) ≤?<br />x,i, let the events<br />Ei,x=<br />∃t &lt; t∗,(ˆ µ(t)<br />i<br />− ˆ µ(t)<br />x∗) − (µi− µx∗) &gt; G<br />?<br />δ<br />D − 1,T(t), ˆ σ(t)<br />i,Ci+ Cx∗<br />??<br />,∀i ?= x∗<br />(17)<br />i∈X\{x∗}Ei,x= δ.<br />So with a probability at least 1 − δ for any iteration t &lt; t∗,<br />ˆ µx− ˆ µx∗ = (ˆ µx− ˆ µx∗)−(µx−µx∗)+(µx−µx∗) &lt; G<br />Therefore arm x∗won’t be eliminated at iteration t.<br />?<br />δ<br />D − 1,T(t), ˆ σ(t)<br />x,x∗,Cx+ Cx∗<br />?<br />(18)<br />A.4 Proof of Prop. 7<br />Proof. Denote by x(t)the arm with the highest estimated mean at iteration t. First consider the case<br />when Alg. 1 uses the marginal variance estimate ˆ σ(t)<br />P(∪i∈XEi) ≤?<br />ˆ µ(t)<br />i<br />&gt; µx∗ − µi− G<br />Alg. 1 will stop by iteration t if the RHS of the equation above satisfies the stopping criterion for all<br />i ?= x∗, that is,<br />?<br />Plugging in the definition of GNormalin Eq. 9 and applying the assumption ˆ σ(t)<br />?<br />Solve the above inequality for T(t)and use the definition of the gap ∆ we get<br />i. With the condition in Eq. 5, it follows that<br />i∈XP(Ei) ≤ δ where Eiis defined in Eq. 15. So with a probability at least 1−δ,<br />?δ<br />x∗ − ˆ µ(t)<br />D,T(t), ˆ σ(t)<br />x∗,Cx∗<br />?<br />− G<br />?δ<br />D,T(t), ˆ σ(t)<br />i,Ci<br />?<br />,∀i ?= x∗<br />(19)<br />µx∗ − µi&gt; 2G<br />?δ<br />D,T(t), ˆ σ(t)<br />x∗,Cx∗<br />?<br />+ G<br />?δ<br />D,T(t), ˆ σ(t)<br />i,Ci<br />??<br />,∀i ?= x∗<br />(20)<br />i<br />= σi, we will get<br />µx∗ − µi<br />(σx∗ + σi)&gt;<br />2<br />T(t)<br />√<br />1 −T(t)− 1<br />N − 1<br />?1/2<br />BNormal,∀i ?= x∗<br />(21)<br />T(t)&gt;<br />N<br />(N − 1)<br />∆2<br />4B2<br />Normal(δ/D)+ 1<br />def<br />=˜T<br />(22)<br />Since we use a doubling schedule T(t)= 2T(t−1)with T(1)= m(1)and T(t∗)= N, Alg. 1 stops at<br />an iteration no later than<br />t = ?log2(˜T/m(0))? + 1<br />(23)<br />11</p>  <p>Page 12</p> <p>And the total number of samples drawn by t is upper bounded by D(m(0)2t−1∧ N) = T∗(∆).<br />Now consider the case when Alg. 1 uses the pairwise variance estimate ˆ σ(t)<br />Eq. 5, it follows with the union bound that P(∪i∈X\{x∗}Ei) ≤?<br />ˆ µ(t)<br />i<br />&gt; µx∗ − µi− G<br />x,i. With the condition in<br />i∈X\{x∗}P(Ei) ≤ δ where Eiis<br />defined in Eq. 17. So with a probability at least 1 − δ,<br />x∗ − ˆ µ(t)<br />?<br />δ<br />D − 1,T(t), ˆ σ(t)<br />x∗,i,Cx∗ + Ci<br />?<br />,∀i ?= x∗<br />(24)<br />Now we can follow a similar argument as in the case with marginal variance estimate and prove the<br />proposition.<br />B Table and Figure of BNormal(δ,πT(1))<br />Table 1 shows BNormal(δ,πT(1)) with δ varying in [10−6,0.49], and the proportion of the first mini-<br />batch πT(1) = m(1)/N ∈ {5 × 10−5,10−4,5 × 10−4,10−3,5 × 10−3,10−2}. Φ(B) can be in-<br />terpreted as the marginal confidence level for one iteration. The function is also shown in Fig. 4<br />for visualization. We will release the code to generate the table and to compute BNormal(δ,πT(1))<br />numerically.<br />10<br />−610<br />−510<br />−410<br />−310<br />−210<br />−1<br />10<br />0<br />0<br />1<br />2<br />3<br />4<br />5<br />6<br />δ<br />B(δ,πT(1))<br /> <br /> <br />πT(1) = 5e − 05<br />πT(1) = 1e − 04<br />πT(1) = 5e − 04<br />πT(1) = 1e − 03<br />πT(1) = 5e − 03<br />πT(1) = 1e − 02<br />Figure 4: BNormal(δ,πT(1))<br />12</p>  <p>Page 13</p> <p>Table 1: BNormal(δ,πT(1))<br />πT(1)<br />δ5 × 10−5<br />5.27250<br />5.06504<br />4.96669<br />4.89969<br />4.85078<br />4.82952<br />4.60397<br />4.49660<br />4.42331<br />4.36853<br />4.34343<br />4.09380<br />3.97189<br />3.88945<br />3.82665<br />3.79932<br />3.51044<br />3.36685<br />3.26922<br />3.19383<br />3.16117<br />2.80261<br />2.61646<br />2.48285<br />2.37768<br />2.33161<br />2.21073<br />2.10639<br />2.01355<br />1.92898<br />1.84734<br />1.76920<br />1.69110<br />1.61302<br />1.52953<br />1.44411<br />1.33819<br />1.20662<br />0.97014<br />10−4<br />5.25978<br />5.05294<br />4.95260<br />4.88715<br />4.83613<br />4.81667<br />4.58943<br />4.48108<br />4.40694<br />4.35265<br />4.32914<br />4.07655<br />3.95539<br />3.87195<br />3.80955<br />3.78066<br />3.49128<br />3.34814<br />3.24913<br />3.17396<br />3.13913<br />2.77885<br />2.59217<br />2.45761<br />2.35127<br />2.30704<br />2.18499<br />2.08030<br />1.98592<br />1.90035<br />1.81893<br />1.73957<br />1.66145<br />1.58274<br />1.49919<br />1.41048<br />1.30896<br />1.17447<br />0.94399<br />5 × 10−4<br />5.21523<br />5.00570<br />4.90571<br />4.83793<br />4.78840<br />4.76734<br />4.53827<br />4.42961<br />4.35512<br />4.29963<br />4.27380<br />4.02027<br />3.89641<br />3.81223<br />3.74833<br />3.72003<br />3.42498<br />3.27812<br />3.17763<br />3.10034<br />3.06612<br />2.69625<br />2.50369<br />2.36449<br />2.25533<br />2.20851<br />2.08270<br />1.97430<br />1.87702<br />1.78969<br />1.70515<br />1.62421<br />1.54360<br />1.46319<br />1.37749<br />1.28960<br />1.18163<br />1.05191<br />0.81030<br />10−3<br />5.19704<br />4.98839<br />4.88735<br />4.82079<br />4.76941<br />4.74894<br />4.51911<br />4.40734<br />4.33353<br />4.27682<br />4.25455<br />3.99632<br />3.87263<br />3.78698<br />3.72365<br />3.69596<br />3.39721<br />3.25096<br />3.14844<br />3.07142<br />3.03755<br />2.66350<br />2.46819<br />2.33100<br />2.22026<br />2.17274<br />2.04536<br />1.93665<br />1.83878<br />1.74854<br />1.66472<br />1.58220<br />1.50171<br />1.42011<br />1.33482<br />1.24393<br />1.14025<br />1.00383<br />0.76485<br />5 × 10−3<br />5.15638<br />4.94490<br />4.84311<br />4.77535<br />4.72447<br />4.70377<br />4.47119<br />4.36137<br />4.28573<br />4.22961<br />4.20386<br />3.94601<br />3.82038<br />3.73467<br />3.66977<br />3.64066<br />3.34023<br />3.19048<br />3.08769<br />3.00871<br />2.97349<br />2.59450<br />2.39672<br />2.25369<br />2.14145<br />2.09292<br />1.96346<br />1.85177<br />1.75267<br />1.66259<br />1.57552<br />1.49310<br />1.41066<br />1.32819<br />1.24221<br />1.15002<br />1.04396<br />0.91939<br />0.69587<br />10−2<br />5.12982<br />4.91964<br />4.81818<br />4.75037<br />4.69877<br />4.67696<br />4.44485<br />4.33158<br />4.25692<br />4.19891<br />4.17608<br />3.91438<br />3.78605<br />3.70026<br />3.63422<br />3.60812<br />3.30253<br />3.15168<br />3.04691<br />2.96758<br />2.93484<br />2.55058<br />2.34862<br />2.20744<br />2.09317<br />2.04351<br />1.91214<br />1.80027<br />1.69949<br />1.60660<br />1.52056<br />1.43584<br />1.35354<br />1.27094<br />1.18303<br />1.09455<br />0.98381<br />0.85273<br />0.61783<br />1.0e-06<br />3.0e-06<br />5.0e-06<br />7.0e-06<br />9.0e-06<br />1.0e-05<br />3.0e-05<br />5.0e-05<br />7.0e-05<br />9.0e-05<br />1.0e-04<br />3.0e-04<br />5.0e-04<br />7.0e-04<br />9.0e-04<br />1.0e-03<br />3.0e-03<br />5.0e-03<br />7.0e-03<br />9.0e-03<br />1.0e-02<br />3.0e-02<br />5.0e-02<br />7.0e-02<br />9.0e-02<br />1.0e-01<br />1.3e-01<br />1.6e-01<br />1.9e-01<br />2.2e-01<br />2.5e-01<br />2.8e-01<br />3.1e-01<br />3.4e-01<br />3.7e-01<br />4.0e-01<br />4.3e-01<br />4.6e-01<br />4.9e-01<br />13</p>  <p>Page 14</p> <p>CExperiment Detailed Setting and Extra Results<br />C.1 More Results of the Synthetic Data Experiment<br />The results with the marginal variance estimate ˆ σifor Racing are shown in Fig. 5. The Racing<br />algorithms (both EBS and Normal) performs more conservatively compared to the plots when using<br />pairwise variance estimate ˆ σi,jin Fig. 1, but the relative performance of all the algorithms are very<br />similar to Fig. 1.<br />We also provide the results with D = 2 and D = 100 when Racing algorithms use pairwise variance<br />estimate in Fig. 6 and 7 respectively. Racing-Normal performs the best in all situations and the<br />empirical error never exceeds the provided bound δ with a statistical significance of 0.05.<br />Notice that the error of adaptive lil’UCB exceeds the error tolerance in the experiment with D = 100<br />and li,n∼ Uniform[0,1]. This is because we use the recommended heuristic setting of parameters<br />in [18] that unfortunately does not satisfy the theoretical guarantee of Thm. 2 in [18]. lil’UCB<br />(heuristic) performed significantly better than the setting with guarantees in [18]. So we expect that<br />adaptive lil’UCB with parameters satisfying Thm. 2 of [18] will perform significantly worse than<br />adaptive lil’UCB (heuristic) and Racing-Normal in terms of the reward sample complexity.<br />10<br />−3<br />10<br />−2<br />10<br />−1<br />10<br />−3<br />10<br />−2<br />10<br />−1<br />Error Torelance δ<br />Empirical Error<br /> <br /> <br />δ<br />Racing−Normal<br />Racing−EBS<br />Adapted LIL’UCB<br />(a) σ = 0.1, very hard<br />10<br />−3<br />10<br />−2<br />10<br />−1<br />10<br />−3<br />10<br />−2<br />10<br />−1<br />Error Torelance δ<br />Empirical Error<br />(b) σ = 10−4, easy<br />10<br />−3<br />10<br />−2<br />10<br />−1<br />10<br />−3<br />10<br />−2<br />10<br />−1<br />Error Torelance δ<br />Empirical Error<br />(c) σ = 10−5, very easy<br />10<br />−3<br />10<br />−2<br />10<br />−1<br />0.5<br />0.6<br />0.7<br />0.8<br />0.9<br />1<br />Error Torelance δ<br />Data Percentage<br /> <br /> <br />Racing−Normal<br />Racing−EBS<br />Adapted LIL’UCB<br />(d) σ = 0.1<br />10<br />−3<br />10<br />−2<br />10<br />−1<br />10<br />−3<br />10<br />−2<br />10<br />−1<br />10<br />0<br />Error Torelance δ<br />Data Percentage<br />(e) σ = 10−4, in log scale<br />10<br />−3<br />10<br />−2<br />10<br />−1<br />10<br />−3<br />10<br />−2<br />10<br />−1<br />10<br />0<br />Error Torelance δ<br />Data Percentage<br />(f) σ = 10−5, in log scale<br />Figure 5: Synthetic data. D = 10. Racing uses marginal variance estimate ˆ σi. (a,b,c) Estimated er-<br />ror with 95% confidence interval. Plots not shown if no error occured. (d,e,f) proportion of sampled<br />data. logfn(i) is sampled from Normal (×), Uniform (?) and LogNormal (?) distributions. Plots<br />of Racing-Normal overlap in (f,g,h).<br />C.2Details of the Bayesian ARCH Model Selection Experiment<br />An ARCH model is commonly used to model the stochastic volatility of financial times series. Let<br />rt<br />= log(pt/pt−1) be the logarithm return of some asset price ptat time t. We assume a constant<br />mean process for the return and remove the estimated mean in a pre-process step. An important<br />problem in applying ARCH for financial data is to choose the complexity, the order q of the auto-<br />regressive model. We treat the model selection problem as a Bayesian inference problem for the<br />random variable q. We use a uniform prior distribution, π(q) = 1/|Q|.<br />An MCMC algorithm was introduced in [25] to infer the posterior model distribution by augmenting<br />the parameter space to a complete parameter set for all models ((α(j)<br />ing the regular prior for the selected model j = q and pseudopriors for those models that are not<br />def<br />i)j<br />i=0,ν(j)),j ∈ Q, then assign-<br />14</p>  <p>Page 15</p> <p>10<br />−3<br />10<br />−2<br />10<br />−1<br />10<br />−3<br />10<br />−2<br />10<br />−1<br />Error Torelance δ<br />Empirical Error<br /> <br /> <br />δ<br />Racing−Normal<br />Racing−EBS<br />Adapted LIL’UCB<br />(a) σ = 0.1, very hard<br />10<br />−3<br />10<br />−2<br />10<br />−1<br />10<br />−3<br />10<br />−2<br />10<br />−1<br />Error Torelance δ<br />Empirical Error<br />(b) σ = 10−4, easy<br />10<br />−3<br />10<br />−2<br />10<br />−1<br />10<br />−3<br />10<br />−2<br />10<br />−1<br />Error Torelance δ<br />Empirical Error<br />(c) σ = 10−5, very easy<br />10<br />−3<br />10<br />−2<br />10<br />−1<br />0.5<br />0.6<br />0.7<br />0.8<br />0.9<br />1<br />Error Torelance δ<br />Data Percentage<br /> <br /> <br />Racing−Normal<br />Racing−EBS<br />Adapted LIL’UCB<br />(d) σ = 0.1<br />10<br />−3<br />10<br />−2<br />10<br />−1<br />10<br />−3<br />10<br />−2<br />10<br />−1<br />10<br />0<br />Error Torelance δ<br />Data Percentage<br />(e) σ = 10−4, in log scale<br />10<br />−3<br />10<br />−2<br />10<br />−1<br />10<br />−3<br />10<br />−2<br />10<br />−1<br />10<br />0<br />Error Torelance δ<br />Data Percentage<br />(f) σ = 10−5, in log scale<br />Figure 6: Synthetic data. D = 2. Racing uses pairwise variance estimate ˆ σi,j. (a,b,c) Estimated er-<br />ror with 95% confidence interval. Plots not shown if no error occured. (d,e,f) proportion of sampled<br />data. logfn(i) is sampled from Normal (×), Uniform (?) and LogNormal (?) distributions. Plots<br />of Racing-Normal overlap in (f,g,h).<br />10<br />−3<br />10<br />−2<br />10<br />−1<br />10<br />−3<br />10<br />−2<br />10<br />−1<br />Error Torelance δ<br />Empirical Error<br /> <br /> <br />δ<br />Racing−Normal<br />Racing−EBS<br />Adapted LIL’UCB<br />(a) σ = 0.1, very hard<br />10<br />−3<br />10<br />−2<br />10<br />−1<br />10<br />−3<br />10<br />−2<br />10<br />−1<br />Error Torelance δ<br />Empirical Error<br />(b) σ = 10−4, easy<br />10<br />−3<br />10<br />−2<br />10<br />−1<br />10<br />−3<br />10<br />−2<br />10<br />−1<br />Error Torelance δ<br />Empirical Error<br />(c) σ = 10−5, very easy<br />10<br />−3<br />10<br />−2<br />10<br />−1<br />0.5<br />0.6<br />0.7<br />0.8<br />0.9<br />1<br />Error Torelance δ<br />Data Percentage<br /> <br /> <br />Racing−Normal<br />Racing−EBS<br />Adapted LIL’UCB<br />(d) σ = 0.1<br />10<br />−3<br />10<br />−2<br />10<br />−1<br />10<br />−3<br />10<br />−2<br />10<br />−1<br />10<br />0<br />Error Torelance δ<br />Data Percentage<br />(e) σ = 10−4, in log scale<br />10<br />−3<br />10<br />−2<br />10<br />−1<br />10<br />−3<br />10<br />−2<br />10<br />−1<br />10<br />0<br />Error Torelance δ<br />Data Percentage<br />(f) σ = 10−5, in log scale<br />Figure 7: Synthetic data. D = 2. Racing uses pairwise variance estimate ˆ σi,j. (a,b,c) Estimated er-<br />ror with 95% confidence interval. Plots not shown if no error occured. (d,e,f) proportion of sampled<br />data. logfn(i) is sampled from Normal (×), Uniform (?) and LogNormal (?) distributions. Plots<br />of Racing-Normal overlap in (f,g,h).<br />15</p>  <p>Page 16</p> <p>selected j ?= q. Then regular MCMC algorithms can be applied to sample all the random variables<br />q,((α(j)<br />i)i,ν(j))jwithout the problem of transdimensional moves as in reversible jump MCMC.<br />The mixing rate of [25] depends on a proper choice of the pseudoprior for (α(j)<br />should be similar to the parameter posterior when the model is chosen p(α(j)<br />first reparameterize (α(j)<br />along the real axis and then take the Laplace approximation at the MAP of transformed parameters<br />as the pseudoprior for each model separately.<br />In order to avoid accessing the entire dataset each iteration, we use subsampling-based algorithms<br />to sample all the conditionals except the pseudoprior as follows<br />?<br />(α(q),ν(q))|q ∼ p(α(q))p(ν(q))<br />t<br />i,ν(j)). Ideally it<br />i,ν(j))|q = j,r). We<br />i,ν(j)) with a softplus function x = log(1+exp(x?)) to allow a full support<br />q|(α(j),ν(j))j∼ π(q)<br />t<br />p(rt|α(q),rt−q:t−1,ν(q)) with Racing-Normal<br />?<br />∼ ppseudoprior(α(j),ν(j)),∀j ?= q<br />wesampleα(q),ν(q)usingMHwithaproposalfromSGLDandarejectionstepprovidedbyRacing-<br />Normal MH. The rejection step controls the error introduced in SGLD when the step size is large.<br />As the marginal likelihood for each model could be differed by a few orders of magnitudes, to<br />make sure every model is sampled sufficiently often, we first adjust the prior distribution ˜ π with the<br />Wang-Landau algorithm with an annealing adaptation on log ˜ π, 1/(1+t/100), so that the posterior<br />distribution ˜ p(q|r) is approximately uniform. We then fix ˜ π and compare the exact and approximate<br />MCMC algorithms. The real posterior distribution can be computed as p(q|r) ∝ ˜ p(q|r)/˜ π(q).<br />We choose the step size separately for the exact and stochastic gradient Langevin dynamics [6] so<br />that the acceptance rate is about 36%.<br />p(rt|α(q),rt−q:t−1,ν(q)) with SGLD and Racing-Normal MH<br />(α(j),ν(j))|q<br />iid<br />(25)<br />We apply the control variates by first segmenting the 2-D space of zj,t<br />(α(j)<br />quantiles and then taking the reference points at the mean of each bin. We also notice that some<br />data points have large residual reward li,n− hi,nwhen zj,tis far from the reference point. We take<br />20% of the points with the largest distance in z as outliers, always compute them every iteration and<br />apply the subsampling algorithm for the rest data.<br />def<br />=(rt,α(j)<br />0<br />+<br />1:j)Trt−j:t−1), where α(j)takes the MAP value, equally into 100 bins according to marginal<br />C.3Details of the Author Coreference Experiment<br />The main differences of this sampling problem from Eq. 1 are that<br />1. |Cy| ?= |Cy?| and the distribution of the cluster size follows approximately a power law<br />with the value varying from as small as 1 to thousands. If we set m(1)= 50 as usual, we<br />already draw about 33% of all the rewards in the first mini-batch. So we slightly abuse the<br />Normal assumption and use a small size for m(1)= 3 and use doubling scheme for the<br />rest with m(2)<br />y<br />= (|Cy| − 3)/10 ∧ 1. The experiment shows an empirical error 0.045 of<br />mis-identification of the best arm with the provided bound δ = 0.05.<br />2. The distribution of {fθ(xi,xj) : j ∈ Cy} is independent from different clusters/arms. We<br />exploit the independence of rewards and choose the bound<br />?ˆ σi<br />This modification has the same performance as with the pairwise variance estimate and has<br />the same computational complexity as with the marginal variance estimate O(DN). We<br />compute BNormalwith a sub-optimal but simpler choice as<br />GNormal(δ,Ti,Tj, ˆ σi, ˆ σj) =<br />Ti<br />?<br />1 −Ti− 1<br />Ni− 1<br />?<br />+ˆ σj<br />Tj<br />?<br />1 −Tj− 1<br />Nj− 1<br />??−1/2<br />BNormal.<br />(26)<br />BNormal(δ) = Φ−1<br />?<br />1 −<br />δ<br />t∗− 1<br />?<br />.<br />(27)<br />16</p>  <p>Page 17</p> <p>It is easy to show that Eq. 5 still holds in this case using a union bound across t. The bound<br />in Eq. 27 is strictly looser than BNormal= E−1(δ) but the difference is small when δ ? 1<br />and diminishes to 0 as δ → 0.<br />We obtained the dataset from the authors of [26] but it is different from what is used in [26] with<br />more difficult citations. The best B3F-1 score reported in this paper is a reasonable value for this<br />data set according to personal communications with the authors of [26].<br />17</p>  <a href="https://www.researchgate.net/profile/Yutian_Chen3/publication/279633530_Subsampling-Based_Approximate_Monte_Carlo_for_Discrete_Distributions/links/565d728808aeafc2aac7970f.pdf">Download full-text</a> </div> <div id="rgw18_56ab9d3a58c4a" class="c-box pub-resource-container js-toggle" style=""> <h4 class="lf js-expand-list"><small><a href="javascript:" class="lf">View other sources <span class="ico-expand-list"></span></a></small></h4> <h4 class="lf js-collapse-list hidden"><small><a href="javascript:" class="lf">Hide other sources <span class="ico-collapse-list"></span></a></small></h4> <div class="clear"></div> <div class="scroll-wrapper hidden"> <ul class="files-list c-list" id="rgw19_56ab9d3a58c4a">  <li class="c-list-item pub-resource-item"  data-type="fulltext" id="rgw20_56ab9d3a58c4a"> <span class="ico-pub"></span> <div class="file-content"> <div class="download"> <a href="profile/Yutian_Chen3/publication/279633530_Subsampling-Based_Approximate_Monte_Carlo_for_Discrete_Distributions/links/565d728808aeafc2aac7970f.pdf" class="publication-viewer" title="565d728808aeafc2aac7970f.pdf">565d728808aeafc2aac7970f.pdf</a> </div>  <div class="details">  <span> Available from <a href="profile/Yutian_Chen3">Yutian Chen</a> &middot; Dec 1, 2015 </span>   </div>    </div> </li>  <li class="c-list-item pub-resource-item"  data-type="fulltext" id="rgw21_56ab9d3a58c4a"> <span class="ico-pub"></span> <div class="file-content"> <div class="download"> <a href="http://de.arxiv.org/pdf/1506.09039" target="_blank" rel="nofollow" class="publication-viewer" title="Subsampling-Based Approximate Monte Carlo for Discrete Distributions">Subsampling-Based Approximate Monte Carlo for Disc...</a> </div>  <div class="details">   Available from <a href="http://de.arxiv.org/pdf/1506.09039" target="_blank" rel="nofollow">de.arxiv.org</a>  </div>    </div> </li>  </ul> </div> </div> </noscript> <div class="clearfix"> <div class="action-container">  </div> <div class="pub-legal"> Data provided are for informational purposes only. Although carefully collected, accuracy cannot be guaranteed. The impact factor represents a rough estimation of the journal's impact factor and does not reflect the actual current impact factor. Publisher conditions are provided by RoMEO. Differing provisions from the publisher's actual policy or licence agreement may be applicable. </div>  <div id="rgw28_56ab9d3a58c4a" class="citations-container"> <div class="tab-container"> <ul class="tab-list"> <li class="lf tab-item tab-item-active js-citations"> <a href="javascript:void(0);" class="tab-link"> References  <small> (28)  </small> </a> </li>   <li class="lf tab-item"> <div class="tab-link tab-link-disabled js-cited-in-tooltip"> Cited In <small>(0)</small></div> </li>   <li class="rf"> <div class="dropdown js-citations-sorter dropdown-right-align" style="position: relative; bottom: -1px;"> <a href="javascript:void(0);" class="dropdown-toggle"> Sorted by: <strong class="js-current-sorting"> Order of availability  </strong> <span class="caret"></span> </a> <ul class="dropdown-menu"> <li><a href="javascript:void(0);" data-sort="normal">Order of availability</a></li> <li><a href="javascript:void(0);" data-sort="original">Appearance in publication</a></li> </ul> </div> </li>  </ul> <div class="tab-section tab-section-active js-citations-list-container"> <div id="rgw29_56ab9d3a58c4a" class="pub-citations-list">   <div class="publication-detail-sidebar-empty">This research doesn't cite any other publications.</div>   <a class="show-more-rebranded js-show-more rf text-gray-lighter">Show more</a> <div class="ajax-loading-small list-loading" style="display: none;"></div>  <div class="clearfix"></div> </div> </div> </div> </div> </div> </div> <div class="clearfix">     <div id="rgw23_56ab9d3a58c4a" class="c-box pub-resource-container js-toggle" style="display: none;"> <h4 class="lf js-expand-list"><small><a href="javascript:" class="lf">View other sources <span class="ico-expand-list"></span></a></small></h4> <h4 class="lf js-collapse-list hidden"><small><a href="javascript:" class="lf">Hide other sources <span class="ico-collapse-list"></span></a></small></h4> <div class="clear"></div> <div class="scroll-wrapper hidden"> <ul class="files-list c-list" id="rgw24_56ab9d3a58c4a">  </ul> </div> </div>   <div id="rgw14_56ab9d3a58c4a" class="similar-publications"> <h2>Similar Publications</h2> <ul class="list-bordered">  <li class="c-list-item li-publication-teaser" id="rgw15_56ab9d3a58c4a"> <div> <h5> <a href="publication/290529165_Markov_chain_Monte_Carlo_methods_an_introductory_example" class="color-inherit ga-similar-publication-title"><span class="publication-title">Markov chain Monte Carlo methods: an introductory example</span></a>  </h5>  <div class="authors"> <a href="researcher/13304353_Katy_Klauenberg" class="authors ga-similar-publication-author">Katy Klauenberg</a>, <a href="researcher/38532035_Clemens_Elster" class="authors ga-similar-publication-author">Clemens Elster</a>  </div>  </div> <div class="clear"></div> </li>  <li class="c-list-item li-publication-teaser" id="rgw16_56ab9d3a58c4a"> <div> <h5> <a href="publication/291387697_Sequential_Monte_Carlo_methods_for_filtering_of_unobservable_components_of_multidimensional_diffusion_Markov_processes" class="color-inherit ga-similar-publication-title"><span class="publication-title">Sequential Monte Carlo methods for filtering of unobservable components of multidimensional diffusion Markov processes</span></a>  </h5>  <div class="authors"> <a href="researcher/2095196393_Ellida_M_Khazen" class="authors ga-similar-publication-author">Ellida M. Khazen</a>, <a href="researcher/2095322154_Zudi_Lu" class="authors ga-similar-publication-author">Zudi Lu</a>  </div>  </div> <div class="clear"></div> </li>  <li class="c-list-item li-publication-teaser" id="rgw17_56ab9d3a58c4a"> <div> <h5> <a href="publication/292142563_Using_the_reliability_theory_for_assessing_the_decision_confidence_probability_for_comparative_Life_Cycle_Assessments" class="color-inherit ga-similar-publication-title"><span class="publication-title">Using the reliability theory for assessing the decision confidence probability for comparative Life Cycle Assessments</span></a>  </h5>  <div class="authors"> <a href="researcher/2059761357_Wei_Wei" class="authors ga-similar-publication-author">Wei Wei</a>, <a href="researcher/2039449925_Pyrene_Larrey-Lassalle" class="authors ga-similar-publication-author">Pyrene Larrey-Lassalle</a>, <a href="researcher/70205559_Thierry_Faure" class="authors ga-similar-publication-author">Thierry Faure</a>, <a href="researcher/70934225_Nicolas_Dumoulin" class="authors ga-similar-publication-author">Nicolas Dumoulin</a>, <a href="researcher/84702763_Philippe_Roux" class="authors ga-similar-publication-author">Philippe Roux</a>, <a href="researcher/57849934_Jean-Denis_Mathias" class="authors ga-similar-publication-author">Jean-Denis Mathias</a>  </div>  </div> <div class="clear"></div> </li>  </ul> </div> </div> </div> </div> </div></div></div>
<div class="clear"></div><div id="rgw39_56ab9d3a58c4a" class="default-footer"> <div id="footer" class="clearfix"> <span class="footer-left"> &copy; 2008&dash;2016 researchgate.net. All rights reserved. </span> <span class="footer-right"> <a href="https://www.researchgate.net/about">About us</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="https://www.researchgate.net/contact">Contact us</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="careers">Careers</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="developers">Developers</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="blog" target="_blank">News</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="application.PrivacyPolicy.html">Privacy</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="application.TermsAndConditions.html">Terms</a> <span class="footer-link-separator" style="padding: 0 5px;">&nbsp;|&nbsp;</span> <a href="advertising?_ref=ft">Advertising</a> <span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="recruiters?_ref=ft">Recruiting</a> </span> </div>  </div></div>
<div id="rgw40_56ab9d3a58c4a">  <div class="header-wrapper-logged-out"> <div id="header"> <div class="header-content"> <a href="" class="g-l-logo"> <svg width="149" height="19"> <image xlink:href="https://c5.rgstatic.net/m/235107188705592/images/template/brand-header-logo.svg" src="https://c5.rgstatic.net/m/238113351022438/images/template/brand-header-logo.png" width="149" height="19"/> </svg> </a> <a href="" class="g-l-logo-ico"> <svg width="127" height="17" viewbox="0 0 127 22"> <image xlink:href="https://c5.rgstatic.net/m/235107188705592/images/template/brand-header-logo.svg" src="https://c5.rgstatic.net/m/238113351022438/images/template/brand-header-logo.png" width="127" height="17"/> </svg> </a> <div id="rgw41_56ab9d3a58c4a" class="header-login-wrapper js-header-login"> <div class="dropdown-right-align"> <div class="login-signup-container lf"> <a href="https://www.researchgate.net/signup.SignUp.html?ev=su_chnl_index&amp;hdrsu=1&amp;_sg=YrwOCuKRLoWnZd9oFKS2ZH0m5Y7rvtLJv2YCTzXIBrILbkjtXAphycBx5eVl7prf" class="dropdown-toggle lf">Join for free</a> </div> <div class="dropdown lf" style="height: 20px;"> <a href="https://www.researchgate.net/application.Login.html" class="js-login-url dropdown-toggle lf">Log in <span class="caret"></span></a> <div class="dropdown-menu"> <div class="header-login-form-wrapper"> <!--[if IE 6]><p class="box-warning" style="margin-bottom: 0;">Sorry, ResearchGate no longer supports the version of Internet Explorer you are using. <a href="http://whatbrowser.org/" rel="nofollow" target="_blank">Update your web browser</a> and then log in. </p><![endif]--> <form method="post" action="https://www.researchgate.net/application.Login.html" class="form-big header-login-form js-login-form" name="loginForm" id="headerLoginForm"> <input type="hidden" name="request_token" value="GzPs79jkprsA6lv5GkFBWNh72l3oyKQ/UTuxr4iCdyo7MktpXVfRViJFT+ZAXeOu1pJHLd6X+HWDXY/+5UArkJ4HbtEitUfeT5hPlNjlMzNCWYgOkrXGTCepLUC59eja/B3HM2+ng436JLAfCMc2r/5v7WJot/oxharSxtAp4iE5VNgWCDWDmj6QnIiuNHefx2RQEz+eavETOuPKUoqZI0jZg8MVR7zI/SIdOfuKsdKTFJL5howOM6G4Z6Fto89F5TlaSNiw2+30tKOzag2RZwi7x06xKbco3H+72s8FPJI="/> <input type="hidden" name="urlAfterLogin" value="publication/279633530_Subsampling-Based_Approximate_Monte_Carlo_for_Discrete_Distributions?ev=auth_pub"/> <input type="hidden" name="invalidPasswordCount" value="0"/> <input type="hidden" name="headerLogin" value="yes"/> <label for="input-header-login">Email</label> <div class="login-input"> <div class="info-tip-wrapper"> <span class="ico-info js-info"></span> </div> <input type="email" value="" name="login" class="login js-login-input text" id="input-header-login" tabindex="1"/> </div> <div class="clear"></div> <label class="lf" for="input-header-password"> Password </label> <a class="rf forgot-password js-forgot-password" href="application.LostPassword.html">Forgot password?</a> <div class="clear"></div> <input type="password" value="" name="password" class="password js-password-input text" id="input-header-password" tabindex="2"/> <div class="clear"></div> <label class="remember-me" for="headerLoginCookie"> <input type="checkbox" checked="checked" value="yes" name="setLoginCookie" class="lf checkbox" id="headerLoginCookie" tabindex="3"/> Keep me logged in </label> <div class="clear"></div> <input value="Log in" name="loginSubmit" class="btn btn-promote btn-fullwidth btn-large allow-leave js-submit-button" type="submit" tabindex="4"/> </form> <div class="connectors"> <div class="text">or log in with</div> <div class="connector-actions"> <a href="connector/linkedin/" class="li-connect js-li-connect" data-redirect-url="cHVibGljYXRpb24vMjc5NjMzNTMwX1N1YnNhbXBsaW5nLUJhc2VkX0FwcHJveGltYXRlX01vbnRlX0NhcmxvX2Zvcl9EaXNjcmV0ZV9EaXN0cmlidXRpb25zP2V2PWF1dGhfcHVi"> <span class="icon ico-linkedin-round-grey"></span> <span class="icon ico-linkedin-round"></span> </a> <a href="connector/facebook/" class="fb-connect middle js-fb-connect" data-redirect-url="cHVibGljYXRpb24vMjc5NjMzNTMwX1N1YnNhbXBsaW5nLUJhc2VkX0FwcHJveGltYXRlX01vbnRlX0NhcmxvX2Zvcl9EaXNjcmV0ZV9EaXN0cmlidXRpb25zP2V2PWF1dGhfcHVi"> <span class="icon ico-facebook-round-grey"></span> <span class="icon ico-facebook-round"></span> </a> <a href="connector/google/" class="g-connect js-g-connect" data-redirect-url="cHVibGljYXRpb24vMjc5NjMzNTMwX1N1YnNhbXBsaW5nLUJhc2VkX0FwcHJveGltYXRlX01vbnRlX0NhcmxvX2Zvcl9EaXNjcmV0ZV9EaXN0cmlidXRpb25zP2V2PWF1dGhfcHVi"> <span class="icon ico-google-round-grey"></span> <span class="icon ico-google-round"></span> </a> </div> </div> </div> </div> </div> </div> </div> </div> </div> <script type="application/ld+json">
{ "@context" : "http://schema.org",
  "@type" : "Organization",
  "name" : "ResearchGate",
  "url" : "http://www.researchgate.net",
  "logo" : "http://www.researchgate.net/images/template/rg_logo_square_brand.png",
  "sameAs" : [ "https://www.facebook.com/ResearchGate",
    "https://twitter.com/ResearchGate",
    "https://plus.google.com/+researchgate",
    "https://www.linkedin.com/company/researchgate"] 
}
</script> </div> </div><div class="c-signup-bar" id="rgw42_56ab9d3a58c4a"> <div class="banner-contents">   <span class="message">ResearchGate is the professional network for scientists and researchers.</span> <a href="signup.SignUp.html?ev=su_banner" class="btn btn-large btn-promote">Join for free</a>  </div> </div></div>
<script>
rgConfig.backendTime = 414;
</script>
<script src="//c5.rgstatic.net/m/2277196935388619/javascript/lib/yui3/yui/yui-min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/21832295316281274/javascript/yuiLoaderConfig-min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/23178613132105398/javascript/vendor/babel-core/browser-polyfill.min.js" type="text/javascript"></script>
<script>
(function (){
if (typeof YRG === "undefined") {
var xmlHttpRequest = new XMLHttpRequest();
xmlHttpRequest.open("post", "go.Error.html");
xmlHttpRequest.setRequestHeader("Content-Type", "application/json");
xmlHttpRequest.setRequestHeader("Accept", "application/json"); var loadedScripts = "";
if (window.performance && window.performance.getEntriesByType) {
    var result = [];
    var resources = performance.getEntriesByType("resource");
    for (var i in resources) {
        if (resources.hasOwnProperty(i)) {
            result.push({
                name: resources[i].name,
                duration: resources[i].duration
            });
        }
    }
    loadedScripts += "&loadedScripts=" + encodeURIComponent(JSON.stringify(result));
}
if (typeof YUI === "undefined") {
    loadedScripts += "&yuiLoaded=false";
} else {
    loadedScripts += "&yuiLoaded=true";
}
xmlHttpRequest.send("Type=InformationException&message=" + encodeURIComponent("Error loading YUI") + loadedScripts);
}
})();
</script>
<script>if (typeof YRG !== 'undefined') { YRG.use('rg-base',function(Y){Y.applyConfig({ignore: ["css-rg","css-rg2","css-ie","css-modules-publicprofile","css-pow-publicliterature-FollowPublicationPromo","css-pow-application-PdfJsReader","css-pow-publicliterature-PublicationInlineReader"]});Y.use(["rg.core.pagespeed.Monitoring"],function(Y){(function(){Y.rg.createInitialWidget({"data":{"content":{"data":{"profileSmallHeader":{"data":{"profileBadge":{"data":{"fullname":"Yutian Chen","imageUrl":"https:\/\/i1.rgstatic.net\/ii\/profile.image\/AS%3A278543817822209%401443421429383_m","profileStats":[],"profileFollowButton":null,"profileReputationScoreNumber":null,"profileUrl":"profile\/Yutian_Chen3","institution":"University of Cambridge","institutionUrl":false,"widgetId":"rgw4_56ab9d3a58c4a"},"id":"rgw4_56ab9d3a58c4a","partials":[],"templateName":"publicprofile\/stubs\/ProfileBadge.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicprofile.ProfileBadge.html?accountId=4885109","viewClass":null,"yuiModules":["css-modules-publicprofile"],"stylesheets":["modules\/publicprofile.css"],"_isYUI":true},"widgetId":"rgw3_56ab9d3a58c4a"},"id":"rgw3_56ab9d3a58c4a","partials":[],"templateName":"publicprofile\/stubs\/ProfileSmallHeader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicprofile.ProfileSmallHeader.html?publicationUid=279633530","viewClass":null,"yuiModules":["css-modules-publicprofile"],"stylesheets":["modules\/publicprofile.css"],"_isYUI":true},"publication":{"data":{"publicationUid":279633530,"title":"Subsampling-Based Approximate Monte Carlo for Discrete Distributions","journalTitle":false,"journalDetailsTooltip":false,"affiliation":false,"type":"Article","details":{"journalInfos":{"journal":"","publicationDate":"06\/2015;","publicationDateRobot":"2015-06","article":""}},"source":{"sourceUrl":"http:\/\/arxiv.org\/abs\/1506.09039","sourceName":"arXiv"},"publicationActions":null,"publicationCoins":{"data":{"tags":[{"key":"ctx_ver","value":"Z39.88-2004"},{"key":"rft_val_fmt","value":"info:ofi\/fmt:kev:mtx:journal"},{"key":"rfr_id","value":"info:sid\/researchgate.net:researchgate"},{"key":"rft.atitle","value":"Subsampling-Based Approximate Monte Carlo for Discrete Distributions"},{"key":"rft.date","value":"2015"},{"key":"rft.au","value":"Yutian Chen,Zoubin Ghahramani"},{"key":"rft.genre","value":"article"}],"widgetId":"rgw6_56ab9d3a58c4a"},"id":"rgw6_56ab9d3a58c4a","partials":[],"templateName":"publicliterature\/stubs\/PublicationCoins.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationCoins.html?publicationUid=279633530","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationAuthors":{"data":{"publicationUid":279633530,"peopleItems":[{"data":{"authorNameOnPublication":"Yutian Chen","accountUrl":"profile\/Yutian_Chen3","accountKey":"Yutian_Chen3","imageUrl":"https:\/\/i1.rgstatic.net\/ii\/profile.image\/AS%3A278543817822209%401443421429383_m","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Yutian Chen","profile":{"professionalInstitution":{"professionalInstitutionName":"University of Cambridge","professionalInstitutionUrl":"institution\/University_of_Cambridge"}},"professionalInstitutionName":"University of Cambridge","professionalInstitutionUrl":"institution\/University_of_Cambridge","url":"profile\/Yutian_Chen3","imageUrl":"https:\/\/i1.rgstatic.net\/ii\/profile.image\/AS%3A278543817822209%401443421429383_l","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":false,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":true,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"accountKey":"Yutian_Chen3","hasInfoPopup":false,"hasTeaserPopup":true,"showContactAuthorButton":true,"widgetId":"rgw9_56ab9d3a58c4a"},"id":"rgw9_56ab9d3a58c4a","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAccountItem.html?entityId=4885109&enableUnfollow=0&imageSize=l&enableFollowButton=0&showContactAuthorButton=1","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"accountInstitution":"University of Cambridge","score":null,"largeTooltip":false,"useRebrandedImageStyle":null,"authorCount":2,"accountCount":1,"publicationUid":279633530,"widgetId":"rgw8_56ab9d3a58c4a"},"id":"rgw8_56ab9d3a58c4a","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAccountItem.html","templateExtensions":[],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAccountItem.html?accountId=4885109&context=pubdetail_authors_xflw&showContactAuthorButton=1&authorCount=2&accountCount=1&publicationUid=279633530","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true},{"data":{"authorUrl":"researcher\/8159937_Zoubin_Ghahramani","authorNameOnPublication":"Zoubin Ghahramani","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg","imageSize":"s","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Zoubin Ghahramani","profile":{"professionalInstitution":{"professionalInstitutionName":false,"professionalInstitutionUrl":null}},"professionalInstitutionName":false,"professionalInstitutionUrl":null,"url":"researcher\/8159937_Zoubin_Ghahramani","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":true,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":false,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"widgetId":"rgw11_56ab9d3a58c4a"},"id":"rgw11_56ab9d3a58c4a","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAuthorItem.html?entityId=8159937&imageSize=l&enableAuthorInviteButton=0","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"largeTooltip":false,"useRebrandedImageStyle":null,"widgetId":"rgw10_56ab9d3a58c4a"},"id":"rgw10_56ab9d3a58c4a","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorItem.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorItem.html?authorUid=8159937&authorNameOnPublication=Zoubin%20Ghahramani","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true}],"hasMore":false,"nextOffset":6,"useRebrandedImageStyle":null,"widgetId":"rgw7_56ab9d3a58c4a"},"id":"rgw7_56ab9d3a58c4a","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorList.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorList.html?publicationUid=279633530&context=pubdetail_authors_xflw&showContactAuthorButton=1","viewClass":"views.publicliterature.PublicationDetailAuthorListView","yuiModules":["rg.views.publicliterature.PublicationDetailAuthorListView"],"stylesheets":[],"_isYUI":true},"publicationAbstract":{"data":{"publicationUid":279633530,"abstract":"<noscript><\/noscript><div>Drawing a sample from a discrete distribution is one of the building<br \/>\ncomponents for Monte Carlo methods. Like other sampling algorithms, discrete<br \/>\nsampling also suffers from high computational burden in large-scale inference<br \/>\nproblems. We study the problem of sampling a discrete random variable with a<br \/>\nhigh degree of dependency that is typical in large-scale Bayesian inference and<br \/>\ngraphical models, and propose an efficient approximate solution with a<br \/>\nsubsampling approach. We make a novel connection between the discrete sampling<br \/>\nand Multi-Armed Bandits problems with a finite reward population and provide<br \/>\nthree algorithms with theoretical guarantees. Empirical evaluations show the<br \/>\nrobustness and efficiency of the approximate algorithms in both synthetic and<br \/>\nreal-world large-scale problems.<\/div>","canEdit":false,"isAdmin":false,"isArtifact":false,"showFullAbstract":false,"widgetId":"rgw12_56ab9d3a58c4a"},"id":"rgw12_56ab9d3a58c4a","partials":[],"templateName":"publicliterature\/stubs\/PublicationAbstract.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationAbstract.html?publicationUid=279633530","viewClass":"views.publicliterature.PublicationAbstractView","yuiModules":["rg.views.publicliterature.PublicationAbstractView"],"stylesheets":[],"_isYUI":true},"publicationKeywords":null,"publicationState":null,"isGuest":true,"isAdminEditingAllowed":false,"isArtifact":false,"figureListWidget":null,"previewImage":"https:\/\/i1.rgstatic.net\/publication\/279633530_Subsampling-Based_Approximate_Monte_Carlo_for_Discrete_Distributions\/links\/565d728808aeafc2aac7970f\/smallpreview.png","nativeAdDisclosure":null,"showFollowPublicationButton":false,"followPublicationPromo":{"data":{"widgetId":"rgw13_56ab9d3a58c4a"},"id":"rgw13_56ab9d3a58c4a","partials":[],"templateName":"publicliterature\/stubs\/FollowPublicationPromo.html","templateExtensions":[],"attrs":{"context":null,"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.FollowPublicationPromo.html","viewClass":null,"yuiModules":["css-pow-publicliterature-FollowPublicationPromo"],"stylesheets":["pow\/publicliterature\/FollowPublicationPromo.css"],"_isYUI":true},"widgetId":"rgw5_56ab9d3a58c4a"},"id":"rgw5_56ab9d3a58c4a","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailItem.html","templateExtensions":["generalHelpers"],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailItem.html?publicationUid=279633530&showActionBar=0&showContactAuthorButton=1&showRequestFulltextExperience=0&showNoRgAuthorsRequestFulltextExperience=0&showFollowPublicationPromo=1","viewClass":"views.publicliterature.PublicationDetailItemView","yuiModules":["rg.views.publicliterature.PublicationDetailItemView"],"stylesheets":[],"_isYUI":true},"similarPublications":{"data":{"publicationListItems":[{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":13304353,"url":"researcher\/13304353_Katy_Klauenberg","fullname":"Katy Klauenberg","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":38532035,"url":"researcher\/38532035_Clemens_Elster","fullname":"Clemens Elster","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Feb 2016","journal":"Metrologia","showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/290529165_Markov_chain_Monte_Carlo_methods_an_introductory_example","usePlainButton":true,"publicationUid":290529165,"feedStubs":null,"hasFeedStubs":false,"impactPoints":"2.04","url":"publication\/290529165_Markov_chain_Monte_Carlo_methods_an_introductory_example","title":"Markov chain Monte Carlo methods: an introductory example","displayTitleAsLink":true,"authors":[{"id":13304353,"url":"researcher\/13304353_Katy_Klauenberg","fullname":"Katy Klauenberg","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":38532035,"url":"researcher\/38532035_Clemens_Elster","fullname":"Clemens Elster","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["Metrologia 02\/2016; 53(1):S32-S39. DOI:10.1088\/0026-1394\/53\/1\/S32"],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/290529165_Markov_chain_Monte_Carlo_methods_an_introductory_example","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/290529165_Markov_chain_Monte_Carlo_methods_an_introductory_example\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw15_56ab9d3a58c4a"},"id":"rgw15_56ab9d3a58c4a","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=290529165","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":2095196393,"url":"researcher\/2095196393_Ellida_M_Khazen","fullname":"Ellida M. Khazen","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2095322154,"url":"researcher\/2095322154_Zudi_Lu","fullname":"Zudi Lu","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Jan 2016","journal":null,"showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/291387697_Sequential_Monte_Carlo_methods_for_filtering_of_unobservable_components_of_multidimensional_diffusion_Markov_processes","usePlainButton":true,"publicationUid":291387697,"feedStubs":null,"hasFeedStubs":false,"impactPoints":false,"url":"publication\/291387697_Sequential_Monte_Carlo_methods_for_filtering_of_unobservable_components_of_multidimensional_diffusion_Markov_processes","title":"Sequential Monte Carlo methods for filtering of unobservable components of multidimensional diffusion Markov processes","displayTitleAsLink":true,"authors":[{"id":2095196393,"url":"researcher\/2095196393_Ellida_M_Khazen","fullname":"Ellida M. Khazen","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2095322154,"url":"researcher\/2095322154_Zudi_Lu","fullname":"Zudi Lu","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["01\/2016;  DOI:10.1080\/23311835.2015.1134031"],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/291387697_Sequential_Monte_Carlo_methods_for_filtering_of_unobservable_components_of_multidimensional_diffusion_Markov_processes","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/291387697_Sequential_Monte_Carlo_methods_for_filtering_of_unobservable_components_of_multidimensional_diffusion_Markov_processes\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw16_56ab9d3a58c4a"},"id":"rgw16_56ab9d3a58c4a","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=291387697","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":2059761357,"url":"researcher\/2059761357_Wei_Wei","fullname":"Wei Wei","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2039449925,"url":"researcher\/2039449925_Pyrene_Larrey-Lassalle","fullname":"Pyrene Larrey-Lassalle","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":70205559,"url":"researcher\/70205559_Thierry_Faure","fullname":"Thierry Faure","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":{"id":70934225,"url":"researcher\/70934225_Nicolas_Dumoulin","fullname":"Nicolas Dumoulin","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},"surplusAuthors":2,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Jan 2016","journal":"Environmental Science & Technology","showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/292142563_Using_the_reliability_theory_for_assessing_the_decision_confidence_probability_for_comparative_Life_Cycle_Assessments","usePlainButton":true,"publicationUid":292142563,"feedStubs":null,"hasFeedStubs":false,"impactPoints":"5.33","url":"publication\/292142563_Using_the_reliability_theory_for_assessing_the_decision_confidence_probability_for_comparative_Life_Cycle_Assessments","title":"Using the reliability theory for assessing the decision confidence probability for comparative Life Cycle Assessments","displayTitleAsLink":true,"authors":[{"id":2059761357,"url":"researcher\/2059761357_Wei_Wei","fullname":"Wei Wei","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2039449925,"url":"researcher\/2039449925_Pyrene_Larrey-Lassalle","fullname":"Pyrene Larrey-Lassalle","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":70205559,"url":"researcher\/70205559_Thierry_Faure","fullname":"Thierry Faure","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":70934225,"url":"researcher\/70934225_Nicolas_Dumoulin","fullname":"Nicolas Dumoulin","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":84702763,"url":"researcher\/84702763_Philippe_Roux","fullname":"Philippe Roux","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":57849934,"url":"researcher\/57849934_Jean-Denis_Mathias","fullname":"Jean-Denis Mathias","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["Environmental Science & Technology 01\/2016;  DOI:10.1021\/acs.est.5b03683"],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/292142563_Using_the_reliability_theory_for_assessing_the_decision_confidence_probability_for_comparative_Life_Cycle_Assessments","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/292142563_Using_the_reliability_theory_for_assessing_the_decision_confidence_probability_for_comparative_Life_Cycle_Assessments\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw17_56ab9d3a58c4a"},"id":"rgw17_56ab9d3a58c4a","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=292142563","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"viewClass":"sidebar","widgetId":"rgw14_56ab9d3a58c4a"},"id":"rgw14_56ab9d3a58c4a","partials":[],"templateName":"publicliterature\/stubs\/SimilarPublications.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.SimilarPublications.html?referencePublicationId=279633530&view=sidebar","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationFulltextPreview":null,"publicationResourcesFulltext":{"data":{"publicationUid":279633530,"publicationResourceList":{"data":{"publicationResourceItems":[{"data":{"publicationUid":279633530,"publicationType":"article","linkId":"565d728808aeafc2aac7970f","fileName":"565d728808aeafc2aac7970f.pdf","fileUrl":"profile\/Yutian_Chen3\/publication\/279633530_Subsampling-Based_Approximate_Monte_Carlo_for_Discrete_Distributions\/links\/565d728808aeafc2aac7970f.pdf","name":"Yutian Chen","nameUrl":"profile\/Yutian_Chen3","canRemove":false,"fileIcon":"ico-pub","canPreview":true,"hasPublisherLink":null,"hasMetaData":true,"hide":false,"fulltext":"ico-pub","origin":"publication_list","isLastLink":false,"isUserLink":true,"uploadDate":"Dec 1, 2015","fileSize":"784.73 KB","widgetId":"rgw20_56ab9d3a58c4a"},"id":"rgw20_56ab9d3a58c4a","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceItem.html","templateExtensions":["generalHelpers"],"attrs":{"fileRequiredPublicationTypes":["code","coverPage","experimentFindings","method","negativeResults","presentation","rawData","researchProposal","workingPaper","artifact","dataset"]},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceItem.html?publicationUid=279633530&linkId=565d728808aeafc2aac7970f&hide=0&disableJavascript=disableJavascript&useAlternativeTemplate=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"publicationUid":279633530,"publicationType":"article","linkId":"5599d89808ae21086d25b8c2","fileName":"Subsampling-Based Approximate Monte Carlo for Discrete Distributions","fileUrl":"http:\/\/de.arxiv.org\/pdf\/1506.09039","name":"de.arxiv.org","nameUrl":"http:\/\/de.arxiv.org\/pdf\/1506.09039","canRemove":false,"fileIcon":"ico-pub","canPreview":true,"hasPublisherLink":null,"hasMetaData":true,"hide":false,"fulltext":"ico-pub","origin":"publication_list","isLastLink":false,"isUserLink":false,"widgetId":"rgw21_56ab9d3a58c4a"},"id":"rgw21_56ab9d3a58c4a","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceItem.html","templateExtensions":["generalHelpers"],"attrs":{"fileRequiredPublicationTypes":["code","coverPage","experimentFindings","method","negativeResults","presentation","rawData","researchProposal","workingPaper","artifact","dataset"]},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceItem.html?publicationUid=279633530&linkId=5599d89808ae21086d25b8c2&hide=0&disableJavascript=disableJavascript&useAlternativeTemplate=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"widgetId":"rgw19_56ab9d3a58c4a"},"id":"rgw19_56ab9d3a58c4a","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceList.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceList.html?publicationUid=279633530&limit=3&disableJavascript=disableJavascript&type=fulltextFile","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"resourceCount":2,"hidden":false,"showMore":false,"fulltext":true,"publicationDownloadCount":{"data":{"value":17,"valueFormatted":"17","widgetId":"rgw22_56ab9d3a58c4a"},"id":"rgw22_56ab9d3a58c4a","partials":[],"templateName":"publicliterature\/stubs\/PublicationDownloadCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDownloadCount.html?publicationUid=279633530","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw18_56ab9d3a58c4a"},"id":"rgw18_56ab9d3a58c4a","partials":[],"templateName":"publicliterature\/stubs\/PublicationResources.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResources.html?publicationUid=279633530&type=fulltextFile&disableJavascript=1","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationResourcesAttachments":{"data":{"publicationUid":279633530,"publicationResourceList":{"data":{"publicationResourceItems":[],"widgetId":"rgw24_56ab9d3a58c4a"},"id":"rgw24_56ab9d3a58c4a","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceList.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceList.html?publicationUid=279633530&limit=3&disableJavascript=disableJavascript&type=attachmentFile","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"resourceCount":0,"hidden":true,"showMore":false,"fulltext":false,"publicationDownloadCount":{"data":{"value":17,"valueFormatted":"17","widgetId":"rgw25_56ab9d3a58c4a"},"id":"rgw25_56ab9d3a58c4a","partials":[],"templateName":"publicliterature\/stubs\/PublicationDownloadCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDownloadCount.html?publicationUid=279633530","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw23_56ab9d3a58c4a"},"id":"rgw23_56ab9d3a58c4a","partials":[],"templateName":"publicliterature\/stubs\/PublicationResources.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResources.html?publicationUid=279633530&type=attachmentFile","viewClass":"views.publicliterature.PublicationResourcesView","yuiModules":["rg.views.publicliterature.PublicationResourcesView"],"stylesheets":[],"_isYUI":true},"publicationText":{"data":{"hide":false,"pages":[{"page":1,"text":"Subsampling-Based Approximate Monte Carlo for\nDiscrete Distributions\nYutian Chen\nDepartment of Engineering\nUniversity of Cambridge\nyutian.chen@eng.cam.ac.uk\nZoubin Ghahramani\nDepartment of Engineering\nUniversity of Cambridge\nzoubin@eng.cam.ac.uk\nAbstract\nDrawing a sample from a discrete distribution is one of the building components\nfor Monte Carlo methods. Like other sampling algorithms, discrete sampling also\nsuffers from high computational burden in large-scale inference problems. We\nstudy the problem of sampling a discrete random variable with a high degree of\ndependency that is typical in large-scale Bayesian inference and graphical models,\nand propose an efficient approximate solution with a subsampling approach. We\nmake a novel connection between the discrete sampling and Multi-Armed Bandits\nproblems with a finite reward population and provide three algorithms with the-\noretical guarantees. Empirical evaluations show the robustness and efficiency of\nthe approximate algorithms in both synthetic and real-world large-scale problems.\n1 Introduction\nSampling a random variable from a discrete (conditional) distribution is one of the core operations\nin Monte Carlo methods. It is an ubiquitous and often necessary component for inference algorithms\nsuch as Gibbs sampling and particle filtering. Applying discrete sampling for large-scale problems\nhas been a challenging task like other Monte Carlo algorithms due to the high computational burden.\nVarious approaches have been proposed to address different types of \u201clarge scales\u201d. For example,\ndistributed algorithms have been used to sample a model with a large number of random discrete\nvariables [1, 2, 3], smart transition kernels were described for Markov chain Monte Carlo (MCMC)\nalgorithms to sample a variable efficiently in a large or even infinite state space [4, 5].\nThis paper is focused on the problem where the variable to sample has a large degree of dependency.\nSpecifically, a random variable with a finite domain X \u2208 X follows the following distribution\np(X = x) \u221d \u02dc p(X = x), with \u02dc p(X = x) = f0(x)\nN\n?\nn=1\nfn(x)\n(1)\nwhere fncan be any function of x and f0denotes the computation that does not scale with the\nnumber of dependencies N. Such distribution occurs frequently in machine learning problems. For\nexample, in Bayesian inference for a model with parameter X and N observations D = {yn}N\nthe unnormalized posterior distribution is \u02dc p(X|D) = p(X)?N\nconditional distribution is \u02dc p(Xi|x\u2212i) =?N\nsampling X in a manner that is scalable in N.\nA few scalable algorithms have been recently proposed for a general state space in the MCMC\nframework such as Metropolis-Hastings (MH) [6, 7, 8], slice sampling [9] and Gibbs for binary\nvariables [7] based on an approximate subsampling approach. Approximate algorithms introduce\nn=1,\ni=1p(yi|X); in undirected graphical\nmodel inference problems where a node Xiappears in N potential functions, the unnormalized\nn=1\u03c6n(Xi,x\u2212i) where x\u2212idenotes the value of all the\nother nodes in the graph and \u03c6ndenotes a potential function that depends on Xi. Here we examine\n1\narXiv:1506.09039v1  [stat.ML]  30 Jun 2015"},{"page":2,"text":"bias in the stationary distribution of the Markov chain but given a fixed amount of runtime they could\nreduce the expected error in the Monte Carlo estimate via a proper trade-off between variance and\nbias by mixing faster as analyzed in [7, 10]. This is particularly important for large-scale learning\nproblems when the runtime is one of the limiting factors for generalization performance [11].\nIn this paper we propose a novel sampling algorithm to improve the efficiency of sampling discrete\ndistributions with the approximate subsampling approach. We first reformulate the problem in Eq. 1\nas a Multi-Armed Bandit (MAB) problem with a finite reward population via the Gumbel trick\n[12, 13], and then propose three algorithms with theoretical guarantees on the approximation error\nand an upper bound of N|X| on the sample size. This is to our knowledge the first attempt to\naddress discrete sampling problem with a large number of dependencies and our work will likely\ncontributetoamorecompletelibraryofscalableMCMCalgorithms. Moreover, theracingalgorithm\nin Sec. 3.3 provides a unified framework for subsampling-based discrete sampling, MH [7, 8] and\nslice sampling [9] algorithms as discussed in Sec. 4. The proposed algorithms also deserve their\nown interest for MAB problems under this particular setting.\nWe first review an alternative way of drawing discrete variables and build a connection with MABs\nin Sec. 2, then propose three algorithms in Sec. 3. We discuss related work in Sec. 4 and evaluate\nthe proposed algorithms on both synthetic data and real-world problems of Bayesian inference and\ngraphical model inference in Sec. 5. Sec. 6 concludes the paper with a discussion.\n2 Approximate Discrete Sampling\n2.1 Discrete Sampling as an Optimization Problem\nThe common procedure to sample X from a discrete domain X = {1,2,...,D} is to first normalize\n\u02dc p(X) and compute the CDF F(X = x) =?x\ncomputing the sum of all the unnormalized probabilities. For \u02dc p in the form of Eq. 1 this is O(ND).\nAn alternative procedure is to first draw D i.i.d. samples from the standard Gumbel distribution1\n\u03b5i\u223c Gumbel(0,1), and then solve the following optimization problem:\nx = argmax\ni\u2208X\nIt is shown in [14] that x follows the distribution p(X). With this method after drawing random\nvariables that do not depend on \u02dc p, we turn a random sampling problem to an optimization problem.\nWhile the computational complexity is the same to draw an exact sample, an approximate algorithm\nmay potentially save computations by avoiding computing accurate values of \u02dc p(X = x) when x is\nconsidered unlikely to be the maximum as discussed next.\ni=1p(X = i). Then draw a uniform random variable\nu \u223c Uniform(0,1], and find x that satisfies F(x \u2212 1) < u \u2264 F(x). This procedure requires\nlog \u02dc p(i) + \u03b5i.\n(2)\n2.2 Approximate Discrete Sampling as a Multi-Armed Bandits Problem\nIn a Multi-Armed Bandit (MAB) problem, the i\u2019th bandit is a slot machine with an arm, which when\npulled generates an i.i.d. reward lifrom a distribution associated with that arm with an unknown\nmean \u00b5i. The optimal arm identification problem for MABs [15, 16] in the fixed confidence setting\nis to find the arm with the highest mean reward with a confidence 1\u2212\u03b4 using as few pulls as possible.\nUnder the assumption of Eq. 1, the solution in Eq. 2 can be expressed as\nx = argmax\ni\u2208X\nN\n?\nn=1\nlogfn(i) + logf0(i) + \u03b5i= argmax\ni\u2208X\nN\n?\nn=1\n?\n?\nlogfn(i) +1\nN(logf0(i) + \u03b5i)\n??\n?\n?\ndef\n=li,n\n= argmax\ni\u2208X\n1\nN\nN\n?\nn=1\nli,n= argmax\ni\u2208X\nEli\u223cUniform(Li)[li]\ndef\n= argmax\ni\u2208X\n\u00b5i\n(3)\n1The Gumbel distribution is used to model the maximum extreme value distribution. If a random variable\nZ \u223c Exp(1), then \u2212log(Z) \u223c Gumbel(0,1). \u03b5 can be easily drawn as \u2212log(\u2212log(u)) with u \u223c U[0,1].\n2"},{"page":3,"text":"where Li\npling problem into the optimal arm identification problem in MABs where the reward liis uniformly\nsampled from a finite population Li. An approximate algorithm that solves the problem with a fixed\nconfidence may avoid drawing all the rewards from an obviously sub-optimal arm and save compu-\ntations. We show the induced bias in the sample distribution as follows with proof in Appx. A.1.\nProposition 1. If an algorithm solves (2) exactly with a probability at least 1 \u2212 \u03b4 for any value of\n\u03b5, the total variation between the sample distribution \u02c6 p and the true distribution is bounded by\n?\u02c6 p(X) \u2212 p(X)?TV\u2264 \u03b4\nWhenappliedintheMCMCframeworkasatransitionkernel, wecanapplyimmediatelythetheories\nin [17, 10] to show that the approximate Markov chain satisfies uniform ergodicity under regular\nconditions and the analysis of convergence rate are readily available under various assumptions.\ndef\n= {li,1,li,2,...,li,N}. After drawing D Gumbel variables \u03b5i, we turn the discrete sam-\n(4)\n3 Algorithms for MABs with a Finite Population and Fixed Confidence\nThe key difference of our problem from the regular MABs is that our rewards are generated from\na finite population while regular MABs assume i.i.d. rewards. Because one can obtain the exact\nmean by sampling all the N values li,nfor arm i without replacement, a good algorithm should pull\nno more than N times for each arm regardless of the mean gap between arms. We introduce three\nalgorithms in this section whose sample complexity is upper bounded by O(ND).\n3.1\nThe iteration of an algorithm is indexed by t.\n{1,2,...,N}, the sampled set of reward indices up to t\u2019th iteration from arm i with N(t)\n[N], and the corresponding number of sampled rewards with T(t)\nmean for i\u2019th arm with \u02c6 \u00b5(t)\ni\n=\n|N(t)\n(\u02c6 \u03c3(t)\n=\n|N(t)\nwith (\u02c6 \u03c3(t)\n=\n|N(t)\nthe bound of the reward value Ci\n= maxn,n?{li,n\u2212 li,n?}. The subscripts and superscripts may be\ndropped for notational simplicity when the meaning is clear from the context.\nNotations\nWe denote the entire index set with [N] =\ni\n\u2286\ni. We define the estimated\ndef\n1\ni\ni)2, the variance estimate of the mean gap between two arm\n|\n?\nn\u2208N(t)\ni\nli,n, the natural variance (biased) estimate with\ni)2def\n1\ni\n|\n?\ni\nn\u2208N(t)\n?\ni\n(li,n\u2212 \u02c6 \u00b5(t)\n((li,n\u2212 lj,n) \u2212 (\u02c6 \u00b5(t)\ndef\ni,j)2def\n1\n|\nn\u2208N(t)\ni\ni\n\u2212 \u02c6 \u00b5(t)\nj))2(defined only when N(t)\ni\n= N(t)\nj),\n3.2\nWe first study one of the state-of-the-art algorithms for fixed-confidence optimal arm identification\nproblem and adjust it for the finite population setting. The lil\u2019UCB algorithm [18] maintains an\nupper confidence bound (UCB) of \u00b5ithat is inspired by the law of the iterated logarithm (LIL) for\nevery arm. At each iteration, it draws a single sample from the arm with the highest bound and\nupdates it. The algorithm terminates when some arm is sampled much more often than all the other\narms. We refer readers to [18, Fig 1] for details. The time complexity for t iterations is O(log(D)t).\nIt was shown in [18] that lil\u2019UCB achieved the optimal sample complexity up to constants.\nHowever, lil\u2019UCB requires i.i.d. rewards for each arm i, that is, sampled with replacement from Li.\nTherefore, the total number of samples t is unbounded and could be ? ND when the means are\nclose to each other. We adapt lil\u2019UCB for our problem with the following modifications:\nAdapted lil\u2019UCB\n1. Samples li,nwithout replacement for each arm but keep different arms independent.\n2. When T(t)\ni\n= N for some arm i, the estimate \u02c6 \u00b5(t)\n3. The algorithm terminates either with the original stopping criterion or when the arm with\nthe highest upper bound has an exact mean estimate, whichever comes first.\ni\nbecomes exact. So set its UCB to \u02c6 \u00b5(t)\ni.\nThe adapted algorithm satisfies all the theoretical guarantees in [18, Thm 2] with additional proper-\nties as shown in the following proposition with proof in Sec. A.2.\nProposition 2. Theorem 2 of [18] holds for the adjusted lil\u2019UCB algorithm. Moreover T(t)\nN,\u2200i,t. Therefore, when the algorithm terminates, t =?\n3\ni\n\u2264\ni\u2208XT(t)\ni\n\u2264 ND."},{"page":4,"text":"Algorithm 1 Racing Algorithm with a Finite Reward Population\nRequire: Number of arms D, population size N, mini-batch sizes {m(t)}t\u2217\n1 \u2212 \u03b4, uncertainty bound function G(\u03b4,T, \u02c6 \u03c3,C), range of samples Ci(optional).\nt \u2190 0, T \u2190 0, D \u2190 {1,2,...,D}, N \u2190 \u2205\nwhile |D| > 1 do\nt \u2190 t + 1\nSample w\/o replacement m(t)indices M \u2286 [N]\\N, and set N \u2190 N \u222a M, T \u2190 T + m(t)\nCompute li,n,\u2200i \u2208 D,n \u2208 M, and update \u02c6 \u00b5iand \u02c6 \u03c3i(or \u02c6 \u03c3i,j), \u2200i \u2208 D.\nFind the best arm x \u2190 argmaxi\u2208D\u02c6 \u00b5i\nEliminate sub-optimal arms when the estimated gap is large D \u2190 D\\{i : \u02c6 \u00b5x\u2212 \u02c6 \u00b5i >\nG(\u03b4\nend while\nreturn D\nt=1, confidence level\nD,T, \u02c6 \u03c3x,Cx) + G(\u03b4\nD,T, \u02c6 \u03c3i,Ci)} (or D \u2190 D\\{i : \u02c6 \u00b5x\u2212 \u02c6 \u00b5i> G(\n\u03b4\nD\u22121,T, \u02c6 \u03c3x,i),Cx+ Ci})\n3.3Racing Algorithm for a Finite Population\nWhen rewards are sampled without replacement, the negative correlation between rewards would\ngenerally improve the convergence of \u02c6 \u00b5i. Unfortunately, the bound in lil\u2019UCB ignores the nega-\ntive correlation when T(t)\ni\n< N even with the adaptations. We introduce a new family of racing\nalgorithms [19] that takes advantage of the finite population setting.\nOur proposed algorithm is shown in Alg 1. It maintains a set of candidate set D initialized with\nall arms. At iteration t, a shared mini-batch of m(t)indices are drawn w\/o replacement for all\nsurvived arms in D. Then an uncertainty bound G is used to eliminate sub-optimal arms with a\ngiven confidence. The algorithm stops when only one arm remains. We require for m(t)that the\ntotal number of sampled indices T(t\u2217)=?t\u2217\nparameter. We also require the confidence bound G = 0 at iteration t whenever T = N so that\nAlg. 1 always stops within t\u2217iterations. The computational complexity for t iterations is O(DT(t))\nwith the marginal estimate \u02c6 \u03c3iand O(D2T(t)) with the pairwise estimate \u02c6 \u03c3i,j. The former version\nis more efficient than the latter when D is large at the price of a looser bound. The choice of G\ndifferentiates specific algorithms and will be discussed in the following sections.\nProposition 3. If G satisfies\ndef\n= P(\u2203t < t\u2217, \u02c6 \u00b5(t)\u2212 \u00b5 > G(\u03b4,T(t), \u02c6 \u03c3(t),C)) \u2264 \u03b4, \u2200\u03b4 \u2208 (0,1),\nwith a probability at least 1 \u2212 \u03b4, Alg. 1 returns the optimal arm with at most ND samples.\nThe proof is provided in Appx. A.3. Unlike adapted lil\u2019UCB, Racing draws a shared set of sample\nindices among all the arms and could provide a tighter bound with pairwise variance estimates \u02c6 \u03c3i,j\nwhen there is positive correlation which is a typical case in Bayesian inference problems.\nt=1m(t)equals N at the last iteration t\u2217. Particularly,\nN\nm(1)? + 1) and leave m(1)as a free\nwe take a doubling schedule T(t)= 2T(t\u22121)(so t\u2217= ?log2\nE\n(5)\n3.3.1Racing with Serfling Concentration bounds for G\nSerfling [20] studied the concentration inequalities of sampling without replacement and obtained\nan improved Hoeffding bound. [21] extended the work and provided an empirical Bernstein-Serfling\nbound that was later used in [8] for the subsampling-based MH algorithm: for any \u03b4 \u2208 (0,1] and\nany n \u2264 N, with probability 1 \u2212 \u03b4, it holds that\n?\nn\nwhere \u03ba =7\n3+\n(1 \u2212 \u03c0n)(1 +1\n\u03c1nthat is missing in regular empirical Bernstein bounds reduces the bound significantly when n is\nclose to N. We set m(1)= 2 in Alg. 1 to provide a valid \u02c6 \u03c3(t)for any t and set the uncertain bound\nG with the empirical Bernstein-Serfling (EBS) bounds as\n\u02c6 \u00b5n\u2212 \u00b5 \u2264 \u02c6 \u03c3n\n2\u03c1nlog(5\/\u03b4)\n+\u03baC log(5\/\u03b4)\nn\nif n \u2264 N\/2\nif n > N\/2, with \u03c0n\ndef\n= BEBS(\u03b4,n, \u02c6 \u03c3n,C)\n(6)\n3\n\u221a2, and \u03c1n=\n?\n1 \u2212 \u03c0n\u22121\nn)\ndef\n=\nn\nN. The extra term\nGEBS(\u03b4,T, \u02c6 \u03c3,C) = BEBS\n?\n\u03b4\nt\u2217\u2212 1,T, \u02c6 \u03c3,C\n?\n(7)\n4"},{"page":5,"text":"It is trivial to prove that GEBSsatisfies the condition in Eq. 5 using a union bound over t < t\u2217.\n3.3.2Racing with a Normal Assumption for G\nThe concentration bounds often give a conservative strategy as it assume an arbitrary bounded re-\nward distribution. When the number of drawn samples is large, the central limit theorem suggests\nthat \u02c6 \u00b5(t)follows approximately a Gaussian distribution. [7] made such an assumption and obtained\na tighter bound. We first provide an immediate corollary of Prop. 2 of [7, Appx. A].\nCorollary 4. Let \u02c6 \u00b5(t)\nfrom any finite population with mean \u00b5 and unit variance. The joint normal random variables \u02dc \u00b5(t)\nthat match the mean and covariance matrix with \u02c6 \u00b5(t)\nunit,t = 1,2,...,t\u2217be the estimated means using sampling without replacement\nunitfollow a Gaussian random walk process as\np\u00b5(\u02dc \u00b5(t)|\u02dc \u00b5(1),..., \u02dc \u00b5(t\u22121)) = N(mt(\u02dc \u00b5(t\u22121)),St)\nBt\nT(t)\n(8)\nwhere mt= \u00b5 + At(\u02dc \u00b5t\u22121\u2212 \u00b5),St=\n\u03c0tshort for \u03c0T(t).\nRemark 5. The marginal distribution p(\u02dc \u00b5(t)) = N\napproaches 0 when T(t)\u2192 N.\nAssumption 6. When T(t)? 1,\u2200t, we assume \u02c6 \u03c3(t)\u2248 \u03c3 and the central limit theorem suggests that\nthe joint distribution of \u02c6 \u00b5(t)\/\u02c6 \u03c3(t)can be approximated by the joint distribution of \u02dc \u00b5(t).\n?\n1 \u2212T(t)\u22121\nN\u22121\n?\n, At=\n\u03c0t\u22121(1\u2212\u03c0t)\n\u03c0t(1\u2212\u03c0t\u22121), Bt=\n\u03c0t\u2212\u03c0t\u22121\n\u03c0t(1\u2212\u03c0t\u22121)with\n?\n\u00b5,\n1\nT(t)\n?\n1 \u2212T(t)\u22121\nN\u22121\n??\nwhere the variance\nWith the normal assumption, we choose the uncertainty bound G in the following form\nGNormal(\u03b4,T, \u02c6 \u03c3) =\n\u02c6 \u03c3\n\u221aT\n?\n1 \u2212T \u2212 1\nN \u2212 1\n?1\/2\nBNormal\n(9)\nIntuitively we use a constant confidence level, \u03a6(BNormal), for all marginal distributions of \u02c6 \u00b5(t)over\nt where \u03a6(\u00b7) is the CDF of the standard normal. To choose the constant BNormal, we plug GNormal\ninto the condition for G in Eq. 5 and apply the normal distribution (8) to solve the univariate equation\nE(B) = \u03b4. This way of computing the bound G is better than applying the union bound across t as in\nthe previous section because it takes into account the correlation of mean estimates across iterations.\nAppx. B provides a table and a plot of BNormal(\u03b4) = E\u22121(\u03b4). Notice that BNormalonly needs\nto be computed once and we can obtain it for any \u03b4 by either interpolating the table or computing\nnumerically with code to be shared (runtime < 1 second). For the parameter of the first mini-batch\nsize m(1), a value of 50 performs robustly in all experiments.\nWe provide the sample complexity below with the proof in Appx. A.4. T\u2217(\u2206) \u2192 DN, as \u2206 \u2192 0.\nProposition 7. Let x\u2217be the best arm and \u2206 be the minimal normalized gap of means from other\narms, defined as mini?=x\u2217\u00b5x\u2217\u2212\u00b5i\nwhen using pairwise variance estimate \u02c6 \u03c3x,i. If Assump. 6 holds, with a probability at least 1 \u2212 \u03b4\nRacing-Normal draws no more rewards than\n\uf8ee\n(N \u2212 1)\ndef\n= m2?log2n\/m?\u2227 N \u2265 n,\u2200n \u2264 N. D?def\n\u03c3x\u2217+\u03c3iwhen using marginal variance estimate \u02c6 \u03c3iand mini?=x\u2217\u00b5x\u2217\u2212\u00b5i\n\u03c3x\u2217,i\nT\u2217(\u2206) = D\n\uf8ef\uf8ef\uf8ef\nN\n\u22062\n4B2\nNormal(\u03b4\/D?)+ 1\n\uf8f9\n\uf8fa\uf8fa\uf8fa\nm(1)\n(10)\nwhere ?n?m\n= D if using \u02c6 \u03c3iand is D \u2212 1 if using \u02c6 \u03c3x,i.\n3.4Variance Reduction for Random Rewards with Control Variates\nThe difficulty of MABs depends heavily on the ratio of the mean gap to the reward noise \u2206. To\nimprove the signal noise ratio, we exploit the control variates technique [22] to reduce the reward\nvariance. Consider a variable hi,nwhose expectation En\u223c[N][hi,n] can be computed efficiently.\nThe residue reward li,n\u2212 hi,n+ En[hi,n] has the same mean as li,nand the variance is reduced if\nhi,n\u2248 li,n. In the Bayesian inference experiment where the factor fn(X = i) = p(yn|X = i), we\nadopt a similar approach as [23] and take the Taylor expansion of li,naround a reference point \u02c6 y as\nli,n\u2248 li(\u02c6 y) + gT\ni(yn\u2212 \u02c6 y) +1\n2(yn\u2212 \u02c6 y)THi(yn\u2212 \u02c6 y)\ndef\n= hi,n\n(11)\n5"},{"page":6,"text":"where giand Hiare the gradient and Hessian matrix of logp(y|i) respectively evaluated at \u02c6 y.\nE[hi,n] can computed analytically with the first two moments of yn. A typical choice of \u02c6 y is E[y].\nThe control variate method is mostly useful for Racing-Normal because for algorithms depending\non a reward bound C it could be hard to get a tight bound for li,n\u2212 hi,nand we often end up with\nan even more conservative strategy.\n4 Related Work\nThe Gumbel trick has been exploited in [14, 12, 13] for different problems. The closest work is [13]\nwhere this trick is extended to draw continuous random variables with a Gumbel process, reminis-\ncent to adaptive rejection sampling.\nOur work is closely related to the optimal arm identification problem for MABs with a fixed con-\nfidence. This is, to our knowledge, the first work to consider MABs with a finite population. The\nproposed algorithms tailored under this setting could be of interest beyond the discrete sampling\nproblem. The normal assumption in Sec. 3.3.2 is similar to UCB-Normal in [24] but the latter\nassumes a normal distribution for individual rewards and will perform poorly when it does not hold.\nThe racing algorithm in Sec. 3.3 is also related to the subsampling-based MH algorithms in [8, 7].\nIn fact, let x and x?be the current and proposed value in an MH iteration, Racing-EBS and Racing-\nNormal reduce to the algorithms in [8] and [7] respectively if we set\nX = {x,x?}, f0(1) = u p(x)q(x?|x), f0(2) = p(x?)q(x|x?), fn(x) = p(yn|x)\nwhere p(x) is the prior distribution, u \u223c Uniform[0,1] and q(\u00b7|\u00b7) is the proposal distribution. The\ndifference with [8] is that we distribute the error \u03b4 evenly across t in Eq. 7 while [8] set \u03b4t =\n(p \u2212 1)\/(p(T(t))p)\u03b4 with p a free parameter. The differences with [7] are that we take a doubling\nschedule for m(t)and replace the t-test with the normal assumption. We find that our algorithms\nshow more efficient and robust performance than both original algorithms in practice. Moreover,\nthe binary Gibbs sampling in [7, Appx. F] is also a special case of Racing-Normal with D = 2.\nTherefore, Alg. 1 provides a unifying approach to a family of subsampling-based samplers.\n(12)\n5\nSince this is the first work to discuss efficient discrete sampling for problem (1), we compare the\nadapted lil\u2019UCB, Racing-EBS, Racing-Normal with the exact sampler only. We report the result of\nRacing-Normal in real data experiments only as the speed gains of the other two are marginal.\nExperiments\n5.1 Synthetic Data\nWe construct a distribution with D = 10 by sampling N = 105reward of li,nfor each state from\none of the three distributions N(0,1), Uniform[0,1], LogNormal(0,2). We normalized li,nto have\na fixed distribution in Fig. 1a and a reward variance \u03c32that controls the difficulty. The normal dis-\ntribution is the idea setting for Racing-Normal, and the uniform distribution is desirable for adapted\nlil\u2019UCB and Racing-EBS as the reward bound is close to \u03c3 . The LogNormal distribution, whose ex.\nkurtosis \u2248 4000, is difficult for all due to the heavy tail. We use a tight bound C = max{li,n\u2212li,n?}\nfor Racing-EBS. We set the scale parameter of adapted lil\u2019UCB with C\/2 and other parameters with\nthe heuristic setting in [18]. Racing uses the pairwise variance estimate.\nFig. 1b-d show the empirical error of best arm identification by drawing 104samples of X for each\nsetting and vary the target error bound \u03b4 \u2208 [10\u22123,0.1]. The bound appears very loose for lil\u2019UCB\nand Racing-EBS but is sharp for Racing-Normal when the noise is large (1b) and \u03b4 ? 1. This is\nconsistentwiththedirectcomparisonofuncertaintyboundsinFig.1e. Consequently, giventhesame\nerror tolerance \u03b4 Racing-Normal requires much fewer rewards than the other conservative strategies\nin all the settings except when \u03c3 = 10\u22125and li,n\u223c Uniform[0,1], as shown in Fig. 1f-h. We justify\nthe observations with more experiments in Appx. C.1 with D \u2208 {2,100} and marginal estimate \u02c6 \u03c3i.\nSurprisingly, Racing-Normal performs robustly regardless of reward distributions with the first mini-\nbatch size m(1)= 50 while it was shown in [8] that the algorithm with the same normal assumption\nin [7] failed with LogNormal even when m(1)= 500. The difference is due to our doubling scheme\nwhere central limit theorem applies quickly with m(t)increasing exponentially.\n6"},{"page":7,"text":"123456789 10\n0\n0.05\n0.1\n0.15\n0.2\n0.25\n0.3\n0.35\n0.4\nX\np(X)\n(a) p(X)\n10\n\u22123\n10\n\u22122\n10\n\u22121\n10\n\u22123\n10\n\u22122\n10\n\u22121\nError Torelance \u03b4\nEmpirical Error\n \n \n\u03b4\nRacing\u2212Normal\nRacing\u2212EBS\nAdapted lil\u2019UCB\nNo error occurs for Racing EBS\nand Adapted lil\u2019UCB\n(b) \u03c3 = 0.1, very hard\n1\n10\n\u22123\n10\n\u22122\n10\n\u22121\n10\n\u22123\n10\n\u22122\n10\n\u22121\nError Torelance \u03b4\nEmpirical Error\n(c) \u03c3 = 10\u22124, easy\n10\n\u22123\n10\n\u22122\n10\n\u22121\n10\n\u22123\n10\n\u22122\n10\n\u22121\nError Torelance \u03b4\nEmpirical Error\n(d) \u03c3 = 10\u22125, very easy\n10\nNumber of Sampled Rewards T\n0\n10\n1\n10\n2\n10\n3\n10\n4\n10\n5\n10\n\u22124\n10\n\u22122\n10\n0\n10\n2\n10\n4\nBound G\n \n \nEBS\nNormal\nLIL\u2019UCB\n(e)\nG(T) with \u03b4 = 0.1.\nUncertainty bounds\n10\n\u22123\n10\n\u22122\n10\n\u22121\n0.5\n0.6\n0.7\n0.8\n0.9\nError Torelance \u03b4\nData Percentage\n \n \nRacing\u2212Normal\nRacing\u2212EBS\nAdapted lil\u2019UCB\n(f) \u03c3 = 0.1\n10\n\u22123\n10\n\u22122\n10\n\u22121\n10\n\u22123\n10\n\u22122\n10\n\u22121\n10\n0\nError Torelance \u03b4\nData Percentage\n(g) \u03c3 = 10\u22124, in log scale\n10\n\u22123\n10\n\u22122\n10\n\u22121\n10\n\u22123\n10\n\u22122\n10\n\u22121\n10\n0\nError Torelance \u03b4\nData Percentage\n(h) \u03c3 = 10\u22125, in log scale\nFigure 1: Synthetic data. (b,c,d) Estimated error with 95% confidence interval. Plots not shown if\nno error occured. (f,g,h) proportion of sampled rewards. li,nis sampled from Normal (\u00d7), Uniform\n(?) and LogNormal (?) distributions. Plots of Racing-Normal overlap in (f,g,h).\n5.2Bayesian ARCH Model Selection\nWe evaluate Racing-Normal in a Bayesian model selection problem for the auto-regressive condi-\ntional heteroskedasticity (ARCH) models. Specifically, we use a mixture of ARCH models for the\nreturn rtof stock price series with student-t innovations, each component with a different order q:\nq\n?\nwhere\u03c0 = {\u03c0q: q \u2208 Q}isthepriordistributionof acandidatemodelinthesetQ. Therandomvari-\nables to infer include the discrete model choice q and continuous parameters {\u03b1i}q\nthe augmented MCMC algorithm in [25] to avoid transdimensional moves. We apply subsampling-\nbased scalable algorithms to sample all variables: Racing-Normal Gibbs for q, stochastic gradient\nLangevin dynamics (SGLD) [6] corrected with Racing-Normal MH (Sec. 4) for \u03b1iand \u03bd. We use\nadjusted priors \u02dc \u03c0qas suggested by [25] for sufficient mixing between all models and tune them\nwith adaptive MCMC. The adjusted posterior \u02dc p(q|r) \u221d \u02dc \u03c0qp(r|q) is then close to uniform and the\nvalue \u03c0q\/\u02dc \u03c0qprovides an estimate to the real unnormalized posterior p(q|r). Control variates are also\napplied to reduce variance. Details of the sampling algorithm are provided in Appx. C.2.\nWe apply the model on the 5-minute Shanghai stock exchange composite index of one year con-\nsisting of about 13,000 data points (Fig. 2a). Q = {5,10,15,20,25,30}. We set m(1)= 50 and\n\u03b4 = 0.05. The control variate method reduces the reward variance by about 2\u223c3 orders of magni-\ntude. Fig. 2b shows the estimated log-posterior of q by normalizing \u03c0q\/\u02dc \u03c0qin the adaptive MCMC as\nafunctionofthenumberoflikelihoodevaluations(consistentwithruntime). Thesubsampling-based\nsampler (Sub) converges about three times faster. We then fix \u02dc \u03c0qfor a fixed stationary distribution\nand run MCMC for 105iterations to compare Sub with the exact sampler. The empirical error rates\nfor Racing-Normal Gibbs and MH are about 4 \u00d7 10\u22124and 2 \u00d7 10\u22123respectively. Fig. 2c shows\nestimated adjusted posterior from 5 runs, and Fig. 2d compares the auto-correlation of sample q.\nSub obtains over twice the effective sample size without noticeable bias after the burn-in period.\n5.3Author Coreference\nrt= \u03c3tzt; zt\niid\n\u223c t\u03bd(0,1); \u03c32\nt= \u03b10+\ni=1\n\u03b1ir2\nt\u2212i; q \u223c Discrete(\u03c0); \u03b1i,\u03bd\niid\n\u223c Gamma(1,1)\ni=0,\u03bd. We adopt\nWe then study the performance in a large-scale graphical model inference problem. The author\ncoreference problem for a database of scientific paper citations is to cluster the mentions of authors\ninto real persons. [26] addressed this problem with a conditional random field model with pairwise\nfactors. The joint and conditional distributions are respectively\n\uf8eb\nyi=yj,i?=j,\u2200i,j\np\u03b8(y|x) \u221d exp\n\uf8ed\n?\nf\u03b8(xi,xj)\n\uf8f6\n\uf8f8, p\u03b8(Yi= yi|y\u2212i,x) \u221d exp\n7\n\uf8eb\n\uf8ed\n?\nyj\u2208Cy={j:yj=y,j?=i}\nf\u03b8(xi,xj)\n\uf8f6\n\uf8f8"},{"page":8,"text":"0 2000 400060008000100001200014000\n\u22120.03\n\u22120.02\n\u22120.01\n0\n0.01\n0.02\n0.03\n(a) Stock index return rt\n10\n5\n10\n6\n10\n7\n10\n8\n10\n9\n\u2212120\n\u2212100\n\u221280\n\u221260\n\u221240\n\u221220\n0\n# likelihood evaluations\nEstimated log p(q)\n \n \nq=5\nq=10\nq=15\nq=20\nq=25\nq=30\n(b) Estimated logp(q|r)\n51015202530\n0\n0.05\n0.1\n0.15\n0.2\nq\n\u02dc p(q|D)\n \n \nGibbs + LD with MH\nSub Gibbs + SGLD with Sub MH\n(c) Adjusted post. \u02dc p(q|r)\nFigure 2: Bayesian ARCH Model Selection.\ndashed: approximate using Sub Gibbs + SGLD with Sub MH.\n00.51 1.52\n7\nx 10\n0\n0.2\n0.4\n0.6\n0.8\n1\n# likelihood evaluations\nAuto\u2212correlation\n \n \nExact, ESS\/eval: 2.6e\u221207\nSub,    ESS\/eval: 5.9e\u221207\n(d) Auto-correlation of q\nSolid: exact,\n0246810\n10\nx 10\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\nNumber of factors evaluated\nB3 F\u22121 Score\n \n \nExact Gibbs\nSub Gibbs\n(a) B3F-1 vs #factor evaluations\n0055 1010 15 1520\n55\nx 10 x 10\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\nNumber of iterations\nB3 F\u22121 Score\n \n \n20\n0.2\n0.4\n0.6\n0.8\n1\nRelative # of evaluated factors\nExact Gibbs\nSub Gibbs\nExact overlaps with Sub\n(b) B3F-1 vs iteration\nFigure 3: Author Coreference.\nBigger B3F-1 score is better.\nwhere x = {xi}N\ni\u2019th mention. The factor f\u03b8(xi,xj) measures the similarity between two mentions based on author\nnames, coauthors, paper title, etc, parameterized by \u03b8. In the conditional distribution, yican take a\nvalue of any non-empty cluster or another empty cluster index. When a cluster Cycontains a lot of\nmentions, a typical case for common author names, the number of factors to be evaluated Ny= |Cy|\nwill be large. We consider the MAP inference problem with fixed \u03b8 using annealed Gibbs sampling\n[27]. We apply Racing-Normal to sample Yiby subsampling Cyfor each candidate value y. An\nimportant difference of this problem from Eq. 1 is that Ny?= Ny?,\u2200y ?= y?and Nyhas a heavy tail\ndistribution. We let the mini-batch size depend on Nywith details provided in Appx. C.3.\nWe run the experiment on the union of an unlabeled DBLP dataset of BibTex entries with about 5M\nauthors and a Rexa corpus of about 11K author mentions with 3160 entries labeled. We monitor the\nclustering performance on the labeled subset with the B3F-1 score [28]. We use \u03b4 = 0.05 and the\nempirical error rate is about 0.046. The number of candidate values D varies in 2 \u223c 215 and Ny\nvaries in 1 \u223c 1829 upon convergence. Fig. 3a shows the F-1 score as a function of the number of\nfactor evaluations with 7 random runs for each algorithm. Sub Gibbs converges about three times\nfaster than exact Gibbs. Fig. 3b shows F-1 as a function of iterations that renders almost identical\nbehavior for both algorithms, which suggests negligible bias in Sub Gibbs. The relative number of\nthe evaluated factors of sub to exact Gibbs indicates about a 5-time speed up near convergence. The\ninitial speed up is small because every cluster is initialized with a single mention, i.e. Ny= 1.\ni=1is the set of observed author mentions and yi \u2208 N+is the cluster index for\n6 Discussion\nWe consider the discrete sampling problem with a high degree of dependency and proposed three\napproximate algorithms under the framework of MABs with theoretical guarantees. The Racing\nalgorithm provides a unifying approaches to various subsampling-based Monte Carlo algorithms\nand also improves the robustness of the original MH algorithm in [7]. This is also the first work to\ndiscuss MABs under the setting of a finite reward population.\nEmpirical evaluations show that Racing-Normal achieves a robust and the highest speed-up among\nall competitors. Whilst adaptive lil\u2019UCB shows inferior empirical performance to Racing-Normal, it\nhas a better sample complexity w.r.t. the number of arms. It will be a future direction to combine the\nbound of Racing-Normal with other MAB algorithms including lil\u2019UCB. Other interesting problems\ninclude how to relax the normal assumptions without sacrificing the performance and how to extend\nour work to draw continuous random variables efficiently with the Gumbel process[13].\n8"},{"page":9,"text":"References\n[1] David Newman, Arthur Asuncion, Padhraic Smyth, and Max Welling. Distributed algorithms for topic\nmodels. The Journal of Machine Learning Research, 10:1801\u20131828, 2009.\n[2] S. Bratires, J. van Gael, A. Vlachos, and Z. Ghahramani. Scaling the iHMM: Parallelization versus\nhadoop. In Computer and Information Technology (CIT), 2010 IEEE 10th International Conference on,\npages 1235\u20131240, June 2010.\n[3] Yao Wu, Qiang Yan, Danny Bickson, Yucheng Low, and Qing Yang. Efficient multicore collaborative\nfiltering. In ACM KDD CUP workshop, 2011.\n[4] Aaron Li, Amr Ahmed, Sujith Ravi, and Alex Smola. Reducing the sampling complexity of topic models.\nIn Proceedings of the ACM Conference on Knowledge Discovery and Data Mining (KDD), 2014.\n[5] Maria Kalli, Jim E Griffin, and Stephen G Walker. Slice sampling mixture models. Statistics and com-\nputing, 21(1):93\u2013105, 2011.\n[6] Max Welling and Yee W Teh. Bayesian learning via stochastic gradient langevin dynamics. In Proceed-\nings of ICML 2011, pages 681\u2013688, 2011.\n[7] Anoop Korattikara, Yutian Chen, and Max Welling. Austerity in MCMC land: Cutting the Metropolis-\nHastings budget. In Proceedings of the 31th International Conference on Machine Learning, ICML 2014,\nBeijing, China, 21-26 June 2014, pages 181\u2013189, 2014.\n[8] R\u00b4 emi Bardenet, Arnaud Doucet, and Chris Holmes. Towards scaling up Markov chain Monte Carlo:\nan adaptive subsampling approach. In Proceedings of The 31st International Conference on Machine\nLearning, pages 405\u2013413, 2014.\n[9] Christopher DuBois, Anoop Korattikara, Max Welling, and Padhraic Smyth. Approximate slice sampling\nfor Bayesian posterior inference. In Proceedings of AISTATS, pages 185\u2013193, 2014.\n[10] Natesh S Pillai and Aaron Smith. Ergodicity of approximate MCMC chains with applications to large\ndata sets. arXiv preprint arXiv:1405.0182, 2014.\n[11] L. Bottou and O. Bousquet. The tradeoffs of large scale learning. In NIPS, volume 20, pages 161\u2013168,\n2008.\n[12] G. Papandreou and A. Yuille. Perturb-and-MAP random fields: Using discrete optimization to learn and\nsample from energy models. In Proceedings of ICCV, pages 193\u2013200, Barcelona, Spain, November 2011.\n[13] Chris J Maddison, Daniel Tarlow, and Tom Minka. A\u2217 sampling. In Z. Ghahramani, M. Welling,\nC. Cortes, N.D. Lawrence, and K.Q. Weinberger, editors, NIPS, pages 3086\u20133094, 2014.\n[14] Dima Kuzmin and Manfred K Warmuth. Optimum follow the leader algorithm. In Proceedings of the\n18th annual conference on Learning Theory, pages 684\u2013686. Springer-Verlag, 2005.\n[15] Robert E Bechhofer. A sequential multiple-decision procedure for selecting the best one of several normal\npopulations with a common unknown variance, and its use with various experimental designs. Biometrics,\n14(3):408\u2013429, 1958.\n[16] Edward Paulson. A sequential procedure for selecting the population with the largest mean from k normal\npopulations. The Annals of Mathematical Statistics, pages 174\u2013180, 1964.\n[17] A Yu Mitrophanov. Sensitivity and convergence of uniformly ergodic markov chains. Journal of Applied\nProbability, pages 1003\u20131014, 2005.\n[18] Kevin Jamieson, Matthew Malloy, Robert Nowak, and S\u00b4 ebastien Bubeck. lil\u2019UCB: An optimal explo-\nration algorithm for multi-armed bandits. In Proceedings of The 27th COLT, pages 423\u2013439, 2014.\n[19] Oded Maron and Andrew W. Moore. Hoeffding races: Accelerating model selection search for classifica-\ntion and function approximation. In Advances in Neural Information Processing Systems 6, pages 59\u201366.\nMorgan-Kaufmann, 1994.\n[20] R. J. Serfling. Probability inequalities for the sum in sampling without replacement. Ann. Statist., 2(1):39\u2013\n48, 01 1974.\n[21] R\u00b4 emi Bardenet and Odalric-Ambrym Maillard. Concentration inequalities for sampling without replace-\nment. arXiv preprint arXiv:1309.4029, 2013.\n[22] James R Wilson. Variance reduction techniques for digital simulation. American Journal of Mathematical\nand Management Sciences, 4(3-4):277\u2013312, 1984.\n[23] Chong Wang, Xi Chen, Alex J Smola, and Eric P Xing. Variance reduction for stochastic gradient opti-\nmization. In Advances in Neural Information Processing Systems, pages 181\u2013189, 2013.\n[24] PeterAuer, NicoloCesa-Bianchi, andPaulFischer. Finite-timeanalysisofthemultiarmedbanditproblem.\nMachine learning, 47(2-3):235\u2013256, 2002.\n[25] B.P. Carlin and S. Chib. Bayesian model choice via Markov chain Monte Carlo. Journal of the Royal\nStatistical Society, Series B, 57:473\u2013484, 1995.\n[26] Sameer Singh, Michael Wick, and Andrew McCallum. Monte Carlo MCMC: efficient inference by ap-\nproximate sampling. In Proceedings of EMNLP-CoNLL 2012, pages 1104\u20131113, 2012.\n[27] Jenny Rose Finkel, Trond Grenager, and Christopher Manning. Incorporating non-local information into\ninformation extraction systems by gibbs sampling. In Proceedings of the 43rd ACL, pages 363\u2013370, 2005.\n[28] Amit Bagga and Breck Baldwin. Algorithms for scoring coreference chains. In LREC workshop on\nlinguistics coreference, volume 1, pages 563\u2013566, 1998.\n[29] Wassily Hoeffding. Probability inequalities for sums of bounded random variables. Journal of the Amer-\nican statistical association, 58(301):13\u201330, 1963.\n9"},{"page":10,"text":"A Proofs\nA.1Proof of Prop. 1\nProof. For a discrete state space, the total variation is equivalent to half of L1distance between\ntwo probability vectors. Denote by \u02c6 p(X = i|\u03b5) the distribution of the output of the approximate\nalgorithm conditioned on the vector of Gumbel variables \u03b5, and x(\u03b5) the solution of Eq. 2 as a\nfunction of \u03b5. According to the premise of Prop. 1, \u02c6 p(X = x(\u03b5)|\u03b5) \u2265 1 \u2212 \u03b4,\u2200\u03b5. We can bound the\nL1error of the conditional probability as\n?\nwhere \u03b4i,jis the Kronecker delta function. Then we can show\n?\n=1\n2\ni\u2208X\n\u22641\n2\ni\u2208X\n=1\n2\n\u03b5\ni\u2208X\n\u2264 \u03b4\ni\u2208X\n??\u02c6 p(X = i|\u03b5) \u2212 \u03b4i,x(\u03b5)\n??= |\u02c6 p(X = x(\u03b5)|\u03b5) \u2212 1| +\n?\ni?=x(\u03b5)\n|\u02c6 p(X = i|\u03b5)| \u2264 2\u03b4,\u2200\u03b5\n(13)\n?\u02c6 p(X) \u2212 p(X)?TV=1\n2\ni\u2208X\n?\n?\n?\n|\u02dc p(X = i) \u2212 p(X = i)|\n????\n\u03b5\n??\n?\n\u03b5\n?\u02c6 p(X = i|\u03b5) \u2212 \u03b4i,x(\u03b5)\n??\u02c6 p(X = i|\u03b5) \u2212 \u03b4i,x(\u03b5)\n??\u02c6 p(X = i|\u03b5) \u2212 \u03b4i,x(\u03b5)\n?dP(\u03b5)\n??dP(\u03b5)\n??\n????\n?\n?\ndP(\u03b5)\n(14)\nA.2 Sketch of the proof of Prop. 2\nProof. As the proof of this proposition is almost identical to the proof of [18], we only outlines the\ndifference due to the adaptation. In the proof of [18, Theorem 2], the i.i.d. assumption for rewards\nfrom each arm was used only in Lemma 3 to provide Chernoff\u2019s bound and Hoeffding\u2019s bound. As\nnotedin[29, Sec.6]thoseboundswouldstillholdwhenrewardsaresampledfromafinitepopulation\nwithout replacement. Therefore, when T(t)< N all the bounds hold for adapted lil\u2019UCB.\nWhen T(t)\nis a valid upper bound of \u00b5i, in fact much tighter than the bound in the original algorithm because\n\u02c6 \u00b5(t)\ni\n= \u00b5iexactly when the entire population is observed.\ni\n= N, the second modification sets the upper bound of the mean estimate to \u02c6 \u00b5(t). That\nTherefore, as long as T(t)\n1 and 2 only.\ni\n\u2264 N,\u2200i, Theorem 2 in [18] applies to adapted lil\u2019UCB with modification\nWith the third modification, T(t)could never be bigger than N at the stopping time, which proves\nthe second part of Prop 2. The proof can then be concluded if we can show modification 3 does not\nchange the output of adapted lil\u2019UCB with the first two modifications only. This is true because if we\ndonotstopwhentheselectedarmisatisfiesT(t)\ni\n= N, wedonotneedtoupdatetheupperboundofi\nbecause the estimated mean is already exact. Since no upper bound is changed, the arm i will always\nbe chosen for now on and eventually the original stopping criterion of T(t)\nmet and the same arm i will be returned.\ni\n\u2265 1 + \u03bb?\nj?=iTj(t) is\nA.3Proof of Prop. 3\nProof. Denote by x(t)the arm with the highest estimated mean at iteration t and x\u2217the optimal arm\nwith the highest true mean, \u00b5x\u2217 > \u00b5i,\u2200i ?= x\u2217. If Alg. 1 does not stop in the first t\u2217\u2212 1 iterations,\nthe estimated means of all the survived arms become exact at the last iteration t\u2217, \u02c6 \u00b5(t\u2217)\nwe require T(t\u2217)= N. Then x(t\u2217)= x\u2217. As we require G(\u03b4,T = N, \u02c6 \u03c3,C) = 0,\u2200\u03b4, \u02c6 \u03c3,C, all the\ni\n= \u00b5ibecause\n10"},{"page":11,"text":"sub-optimal arms will be eliminated by the last iteration and the algorithm always returns the correct\nbest arm. This proves the upper bound of the sample size of ND.\nNow to prove the confidence level, all we need to show is that with at least a probability 1 \u2212 \u03b4 arm\nx\u2217survived all the iterations t < t\u2217.\nLet us first consider the case when Alg. 1 uses the marginal variance estimate \u02c6 \u03c3(t)\n?\n?\nApplying condition Eq. 5 and the union bound, we get P(\u222ai\u2208XEi) \u2264?\n\u02c6 \u00b5x\u2212\u02c6 \u00b5x\u2217 = (\u02c6 \u00b5x\u2212\u00b5x)\u2212(\u02c6 \u00b5x\u2217\u2212\u00b5x\u2217)+(\u00b5x\u2212\u00b5x\u2217) < G\ni. Let the events\nEi=\n\u2203t < t\u2217, \u02c6 \u00b5(t)\ni\n\u2212 \u00b5i> G\n?\u03b4\nD,T(t), \u02c6 \u03c3(t)\n?\u03b4\ni,Ci\n??\n,\u2200i ?= x\u2217\n??\ni\u2208XEi = \u03b4. So with a\n?\nEx\u2217 =\n\u2203t < t\u2217,\u2212\u02c6 \u00b5(t)\nx\u2217 \u2212 (\u2212\u00b5x\u2217) > G\nD,T(t), \u02c6 \u03c3(t)\ni,Ci\n(15)\nprobability at least 1 \u2212 \u03b4, none of those events will happen. In that case for any iteration t < t\u2217,\n?\u03b4\nD,T(t), \u02c6 \u03c3(t)\nx,Cx\n+G\n?\u03b4\nD,T(t), \u02c6 \u03c3(t)\nx\u2217,Cx\u2217\n?\n(16)\nSo arm x\u2217won\u2019t be eliminated at iteration t.\nSimilarly, for the case when Alg. 1 uses the pairwise variance estimate \u02c6 \u03c3(t)\n?\nApplying condition Eq. 5 and the union bound, we get P(\u222ai\u2208X\\{x\u2217}Ei,x) \u2264?\nx,i, let the events\nEi,x=\n\u2203t < t\u2217,(\u02c6 \u00b5(t)\ni\n\u2212 \u02c6 \u00b5(t)\nx\u2217) \u2212 (\u00b5i\u2212 \u00b5x\u2217) > G\n?\n\u03b4\nD \u2212 1,T(t), \u02c6 \u03c3(t)\ni,Ci+ Cx\u2217\n??\n,\u2200i ?= x\u2217\n(17)\ni\u2208X\\{x\u2217}Ei,x= \u03b4.\nSo with a probability at least 1 \u2212 \u03b4 for any iteration t < t\u2217,\n\u02c6 \u00b5x\u2212 \u02c6 \u00b5x\u2217 = (\u02c6 \u00b5x\u2212 \u02c6 \u00b5x\u2217)\u2212(\u00b5x\u2212\u00b5x\u2217)+(\u00b5x\u2212\u00b5x\u2217) < G\nTherefore arm x\u2217won\u2019t be eliminated at iteration t.\n?\n\u03b4\nD \u2212 1,T(t), \u02c6 \u03c3(t)\nx,x\u2217,Cx+ Cx\u2217\n?\n(18)\nA.4 Proof of Prop. 7\nProof. Denote by x(t)the arm with the highest estimated mean at iteration t. First consider the case\nwhen Alg. 1 uses the marginal variance estimate \u02c6 \u03c3(t)\nP(\u222ai\u2208XEi) \u2264?\n\u02c6 \u00b5(t)\ni\n> \u00b5x\u2217 \u2212 \u00b5i\u2212 G\nAlg. 1 will stop by iteration t if the RHS of the equation above satisfies the stopping criterion for all\ni ?= x\u2217, that is,\n?\nPlugging in the definition of GNormalin Eq. 9 and applying the assumption \u02c6 \u03c3(t)\n?\nSolve the above inequality for T(t)and use the definition of the gap \u2206 we get\ni. With the condition in Eq. 5, it follows that\ni\u2208XP(Ei) \u2264 \u03b4 where Eiis defined in Eq. 15. So with a probability at least 1\u2212\u03b4,\n?\u03b4\nx\u2217 \u2212 \u02c6 \u00b5(t)\nD,T(t), \u02c6 \u03c3(t)\nx\u2217,Cx\u2217\n?\n\u2212 G\n?\u03b4\nD,T(t), \u02c6 \u03c3(t)\ni,Ci\n?\n,\u2200i ?= x\u2217\n(19)\n\u00b5x\u2217 \u2212 \u00b5i> 2G\n?\u03b4\nD,T(t), \u02c6 \u03c3(t)\nx\u2217,Cx\u2217\n?\n+ G\n?\u03b4\nD,T(t), \u02c6 \u03c3(t)\ni,Ci\n??\n,\u2200i ?= x\u2217\n(20)\ni\n= \u03c3i, we will get\n\u00b5x\u2217 \u2212 \u00b5i\n(\u03c3x\u2217 + \u03c3i)>\n2\nT(t)\n\u221a\n1 \u2212T(t)\u2212 1\nN \u2212 1\n?1\/2\nBNormal,\u2200i ?= x\u2217\n(21)\nT(t)>\nN\n(N \u2212 1)\n\u22062\n4B2\nNormal(\u03b4\/D)+ 1\ndef\n=\u02dcT\n(22)\nSince we use a doubling schedule T(t)= 2T(t\u22121)with T(1)= m(1)and T(t\u2217)= N, Alg. 1 stops at\nan iteration no later than\nt = ?log2(\u02dcT\/m(0))? + 1\n(23)\n11"},{"page":12,"text":"And the total number of samples drawn by t is upper bounded by D(m(0)2t\u22121\u2227 N) = T\u2217(\u2206).\nNow consider the case when Alg. 1 uses the pairwise variance estimate \u02c6 \u03c3(t)\nEq. 5, it follows with the union bound that P(\u222ai\u2208X\\{x\u2217}Ei) \u2264?\n\u02c6 \u00b5(t)\ni\n> \u00b5x\u2217 \u2212 \u00b5i\u2212 G\nx,i. With the condition in\ni\u2208X\\{x\u2217}P(Ei) \u2264 \u03b4 where Eiis\ndefined in Eq. 17. So with a probability at least 1 \u2212 \u03b4,\nx\u2217 \u2212 \u02c6 \u00b5(t)\n?\n\u03b4\nD \u2212 1,T(t), \u02c6 \u03c3(t)\nx\u2217,i,Cx\u2217 + Ci\n?\n,\u2200i ?= x\u2217\n(24)\nNow we can follow a similar argument as in the case with marginal variance estimate and prove the\nproposition.\nB Table and Figure of BNormal(\u03b4,\u03c0T(1))\nTable 1 shows BNormal(\u03b4,\u03c0T(1)) with \u03b4 varying in [10\u22126,0.49], and the proportion of the first mini-\nbatch \u03c0T(1) = m(1)\/N \u2208 {5 \u00d7 10\u22125,10\u22124,5 \u00d7 10\u22124,10\u22123,5 \u00d7 10\u22123,10\u22122}. \u03a6(B) can be in-\nterpreted as the marginal confidence level for one iteration. The function is also shown in Fig. 4\nfor visualization. We will release the code to generate the table and to compute BNormal(\u03b4,\u03c0T(1))\nnumerically.\n10\n\u2212610\n\u2212510\n\u2212410\n\u2212310\n\u2212210\n\u22121\n10\n0\n0\n1\n2\n3\n4\n5\n6\n\u03b4\nB(\u03b4,\u03c0T(1))\n \n \n\u03c0T(1) = 5e \u2212 05\n\u03c0T(1) = 1e \u2212 04\n\u03c0T(1) = 5e \u2212 04\n\u03c0T(1) = 1e \u2212 03\n\u03c0T(1) = 5e \u2212 03\n\u03c0T(1) = 1e \u2212 02\nFigure 4: BNormal(\u03b4,\u03c0T(1))\n12"},{"page":13,"text":"Table 1: BNormal(\u03b4,\u03c0T(1))\n\u03c0T(1)\n\u03b45 \u00d7 10\u22125\n5.27250\n5.06504\n4.96669\n4.89969\n4.85078\n4.82952\n4.60397\n4.49660\n4.42331\n4.36853\n4.34343\n4.09380\n3.97189\n3.88945\n3.82665\n3.79932\n3.51044\n3.36685\n3.26922\n3.19383\n3.16117\n2.80261\n2.61646\n2.48285\n2.37768\n2.33161\n2.21073\n2.10639\n2.01355\n1.92898\n1.84734\n1.76920\n1.69110\n1.61302\n1.52953\n1.44411\n1.33819\n1.20662\n0.97014\n10\u22124\n5.25978\n5.05294\n4.95260\n4.88715\n4.83613\n4.81667\n4.58943\n4.48108\n4.40694\n4.35265\n4.32914\n4.07655\n3.95539\n3.87195\n3.80955\n3.78066\n3.49128\n3.34814\n3.24913\n3.17396\n3.13913\n2.77885\n2.59217\n2.45761\n2.35127\n2.30704\n2.18499\n2.08030\n1.98592\n1.90035\n1.81893\n1.73957\n1.66145\n1.58274\n1.49919\n1.41048\n1.30896\n1.17447\n0.94399\n5 \u00d7 10\u22124\n5.21523\n5.00570\n4.90571\n4.83793\n4.78840\n4.76734\n4.53827\n4.42961\n4.35512\n4.29963\n4.27380\n4.02027\n3.89641\n3.81223\n3.74833\n3.72003\n3.42498\n3.27812\n3.17763\n3.10034\n3.06612\n2.69625\n2.50369\n2.36449\n2.25533\n2.20851\n2.08270\n1.97430\n1.87702\n1.78969\n1.70515\n1.62421\n1.54360\n1.46319\n1.37749\n1.28960\n1.18163\n1.05191\n0.81030\n10\u22123\n5.19704\n4.98839\n4.88735\n4.82079\n4.76941\n4.74894\n4.51911\n4.40734\n4.33353\n4.27682\n4.25455\n3.99632\n3.87263\n3.78698\n3.72365\n3.69596\n3.39721\n3.25096\n3.14844\n3.07142\n3.03755\n2.66350\n2.46819\n2.33100\n2.22026\n2.17274\n2.04536\n1.93665\n1.83878\n1.74854\n1.66472\n1.58220\n1.50171\n1.42011\n1.33482\n1.24393\n1.14025\n1.00383\n0.76485\n5 \u00d7 10\u22123\n5.15638\n4.94490\n4.84311\n4.77535\n4.72447\n4.70377\n4.47119\n4.36137\n4.28573\n4.22961\n4.20386\n3.94601\n3.82038\n3.73467\n3.66977\n3.64066\n3.34023\n3.19048\n3.08769\n3.00871\n2.97349\n2.59450\n2.39672\n2.25369\n2.14145\n2.09292\n1.96346\n1.85177\n1.75267\n1.66259\n1.57552\n1.49310\n1.41066\n1.32819\n1.24221\n1.15002\n1.04396\n0.91939\n0.69587\n10\u22122\n5.12982\n4.91964\n4.81818\n4.75037\n4.69877\n4.67696\n4.44485\n4.33158\n4.25692\n4.19891\n4.17608\n3.91438\n3.78605\n3.70026\n3.63422\n3.60812\n3.30253\n3.15168\n3.04691\n2.96758\n2.93484\n2.55058\n2.34862\n2.20744\n2.09317\n2.04351\n1.91214\n1.80027\n1.69949\n1.60660\n1.52056\n1.43584\n1.35354\n1.27094\n1.18303\n1.09455\n0.98381\n0.85273\n0.61783\n1.0e-06\n3.0e-06\n5.0e-06\n7.0e-06\n9.0e-06\n1.0e-05\n3.0e-05\n5.0e-05\n7.0e-05\n9.0e-05\n1.0e-04\n3.0e-04\n5.0e-04\n7.0e-04\n9.0e-04\n1.0e-03\n3.0e-03\n5.0e-03\n7.0e-03\n9.0e-03\n1.0e-02\n3.0e-02\n5.0e-02\n7.0e-02\n9.0e-02\n1.0e-01\n1.3e-01\n1.6e-01\n1.9e-01\n2.2e-01\n2.5e-01\n2.8e-01\n3.1e-01\n3.4e-01\n3.7e-01\n4.0e-01\n4.3e-01\n4.6e-01\n4.9e-01\n13"},{"page":14,"text":"CExperiment Detailed Setting and Extra Results\nC.1 More Results of the Synthetic Data Experiment\nThe results with the marginal variance estimate \u02c6 \u03c3ifor Racing are shown in Fig. 5. The Racing\nalgorithms (both EBS and Normal) performs more conservatively compared to the plots when using\npairwise variance estimate \u02c6 \u03c3i,jin Fig. 1, but the relative performance of all the algorithms are very\nsimilar to Fig. 1.\nWe also provide the results with D = 2 and D = 100 when Racing algorithms use pairwise variance\nestimate in Fig. 6 and 7 respectively. Racing-Normal performs the best in all situations and the\nempirical error never exceeds the provided bound \u03b4 with a statistical significance of 0.05.\nNotice that the error of adaptive lil\u2019UCB exceeds the error tolerance in the experiment with D = 100\nand li,n\u223c Uniform[0,1]. This is because we use the recommended heuristic setting of parameters\nin [18] that unfortunately does not satisfy the theoretical guarantee of Thm. 2 in [18]. lil\u2019UCB\n(heuristic) performed significantly better than the setting with guarantees in [18]. So we expect that\nadaptive lil\u2019UCB with parameters satisfying Thm. 2 of [18] will perform significantly worse than\nadaptive lil\u2019UCB (heuristic) and Racing-Normal in terms of the reward sample complexity.\n10\n\u22123\n10\n\u22122\n10\n\u22121\n10\n\u22123\n10\n\u22122\n10\n\u22121\nError Torelance \u03b4\nEmpirical Error\n \n \n\u03b4\nRacing\u2212Normal\nRacing\u2212EBS\nAdapted LIL\u2019UCB\n(a) \u03c3 = 0.1, very hard\n10\n\u22123\n10\n\u22122\n10\n\u22121\n10\n\u22123\n10\n\u22122\n10\n\u22121\nError Torelance \u03b4\nEmpirical Error\n(b) \u03c3 = 10\u22124, easy\n10\n\u22123\n10\n\u22122\n10\n\u22121\n10\n\u22123\n10\n\u22122\n10\n\u22121\nError Torelance \u03b4\nEmpirical Error\n(c) \u03c3 = 10\u22125, very easy\n10\n\u22123\n10\n\u22122\n10\n\u22121\n0.5\n0.6\n0.7\n0.8\n0.9\n1\nError Torelance \u03b4\nData Percentage\n \n \nRacing\u2212Normal\nRacing\u2212EBS\nAdapted LIL\u2019UCB\n(d) \u03c3 = 0.1\n10\n\u22123\n10\n\u22122\n10\n\u22121\n10\n\u22123\n10\n\u22122\n10\n\u22121\n10\n0\nError Torelance \u03b4\nData Percentage\n(e) \u03c3 = 10\u22124, in log scale\n10\n\u22123\n10\n\u22122\n10\n\u22121\n10\n\u22123\n10\n\u22122\n10\n\u22121\n10\n0\nError Torelance \u03b4\nData Percentage\n(f) \u03c3 = 10\u22125, in log scale\nFigure 5: Synthetic data. D = 10. Racing uses marginal variance estimate \u02c6 \u03c3i. (a,b,c) Estimated er-\nror with 95% confidence interval. Plots not shown if no error occured. (d,e,f) proportion of sampled\ndata. logfn(i) is sampled from Normal (\u00d7), Uniform (?) and LogNormal (?) distributions. Plots\nof Racing-Normal overlap in (f,g,h).\nC.2Details of the Bayesian ARCH Model Selection Experiment\nAn ARCH model is commonly used to model the stochastic volatility of financial times series. Let\nrt\n= log(pt\/pt\u22121) be the logarithm return of some asset price ptat time t. We assume a constant\nmean process for the return and remove the estimated mean in a pre-process step. An important\nproblem in applying ARCH for financial data is to choose the complexity, the order q of the auto-\nregressive model. We treat the model selection problem as a Bayesian inference problem for the\nrandom variable q. We use a uniform prior distribution, \u03c0(q) = 1\/|Q|.\nAn MCMC algorithm was introduced in [25] to infer the posterior model distribution by augmenting\nthe parameter space to a complete parameter set for all models ((\u03b1(j)\ning the regular prior for the selected model j = q and pseudopriors for those models that are not\ndef\ni)j\ni=0,\u03bd(j)),j \u2208 Q, then assign-\n14"},{"page":15,"text":"10\n\u22123\n10\n\u22122\n10\n\u22121\n10\n\u22123\n10\n\u22122\n10\n\u22121\nError Torelance \u03b4\nEmpirical Error\n \n \n\u03b4\nRacing\u2212Normal\nRacing\u2212EBS\nAdapted LIL\u2019UCB\n(a) \u03c3 = 0.1, very hard\n10\n\u22123\n10\n\u22122\n10\n\u22121\n10\n\u22123\n10\n\u22122\n10\n\u22121\nError Torelance \u03b4\nEmpirical Error\n(b) \u03c3 = 10\u22124, easy\n10\n\u22123\n10\n\u22122\n10\n\u22121\n10\n\u22123\n10\n\u22122\n10\n\u22121\nError Torelance \u03b4\nEmpirical Error\n(c) \u03c3 = 10\u22125, very easy\n10\n\u22123\n10\n\u22122\n10\n\u22121\n0.5\n0.6\n0.7\n0.8\n0.9\n1\nError Torelance \u03b4\nData Percentage\n \n \nRacing\u2212Normal\nRacing\u2212EBS\nAdapted LIL\u2019UCB\n(d) \u03c3 = 0.1\n10\n\u22123\n10\n\u22122\n10\n\u22121\n10\n\u22123\n10\n\u22122\n10\n\u22121\n10\n0\nError Torelance \u03b4\nData Percentage\n(e) \u03c3 = 10\u22124, in log scale\n10\n\u22123\n10\n\u22122\n10\n\u22121\n10\n\u22123\n10\n\u22122\n10\n\u22121\n10\n0\nError Torelance \u03b4\nData Percentage\n(f) \u03c3 = 10\u22125, in log scale\nFigure 6: Synthetic data. D = 2. Racing uses pairwise variance estimate \u02c6 \u03c3i,j. (a,b,c) Estimated er-\nror with 95% confidence interval. Plots not shown if no error occured. (d,e,f) proportion of sampled\ndata. logfn(i) is sampled from Normal (\u00d7), Uniform (?) and LogNormal (?) distributions. Plots\nof Racing-Normal overlap in (f,g,h).\n10\n\u22123\n10\n\u22122\n10\n\u22121\n10\n\u22123\n10\n\u22122\n10\n\u22121\nError Torelance \u03b4\nEmpirical Error\n \n \n\u03b4\nRacing\u2212Normal\nRacing\u2212EBS\nAdapted LIL\u2019UCB\n(a) \u03c3 = 0.1, very hard\n10\n\u22123\n10\n\u22122\n10\n\u22121\n10\n\u22123\n10\n\u22122\n10\n\u22121\nError Torelance \u03b4\nEmpirical Error\n(b) \u03c3 = 10\u22124, easy\n10\n\u22123\n10\n\u22122\n10\n\u22121\n10\n\u22123\n10\n\u22122\n10\n\u22121\nError Torelance \u03b4\nEmpirical Error\n(c) \u03c3 = 10\u22125, very easy\n10\n\u22123\n10\n\u22122\n10\n\u22121\n0.5\n0.6\n0.7\n0.8\n0.9\n1\nError Torelance \u03b4\nData Percentage\n \n \nRacing\u2212Normal\nRacing\u2212EBS\nAdapted LIL\u2019UCB\n(d) \u03c3 = 0.1\n10\n\u22123\n10\n\u22122\n10\n\u22121\n10\n\u22123\n10\n\u22122\n10\n\u22121\n10\n0\nError Torelance \u03b4\nData Percentage\n(e) \u03c3 = 10\u22124, in log scale\n10\n\u22123\n10\n\u22122\n10\n\u22121\n10\n\u22123\n10\n\u22122\n10\n\u22121\n10\n0\nError Torelance \u03b4\nData Percentage\n(f) \u03c3 = 10\u22125, in log scale\nFigure 7: Synthetic data. D = 2. Racing uses pairwise variance estimate \u02c6 \u03c3i,j. (a,b,c) Estimated er-\nror with 95% confidence interval. Plots not shown if no error occured. (d,e,f) proportion of sampled\ndata. logfn(i) is sampled from Normal (\u00d7), Uniform (?) and LogNormal (?) distributions. Plots\nof Racing-Normal overlap in (f,g,h).\n15"},{"page":16,"text":"selected j ?= q. Then regular MCMC algorithms can be applied to sample all the random variables\nq,((\u03b1(j)\ni)i,\u03bd(j))jwithout the problem of transdimensional moves as in reversible jump MCMC.\nThe mixing rate of [25] depends on a proper choice of the pseudoprior for (\u03b1(j)\nshould be similar to the parameter posterior when the model is chosen p(\u03b1(j)\nfirst reparameterize (\u03b1(j)\nalong the real axis and then take the Laplace approximation at the MAP of transformed parameters\nas the pseudoprior for each model separately.\nIn order to avoid accessing the entire dataset each iteration, we use subsampling-based algorithms\nto sample all the conditionals except the pseudoprior as follows\n?\n(\u03b1(q),\u03bd(q))|q \u223c p(\u03b1(q))p(\u03bd(q))\nt\ni,\u03bd(j)). Ideally it\ni,\u03bd(j))|q = j,r). We\ni,\u03bd(j)) with a softplus function x = log(1+exp(x?)) to allow a full support\nq|(\u03b1(j),\u03bd(j))j\u223c \u03c0(q)\nt\np(rt|\u03b1(q),rt\u2212q:t\u22121,\u03bd(q)) with Racing-Normal\n?\n\u223c ppseudoprior(\u03b1(j),\u03bd(j)),\u2200j ?= q\nwesample\u03b1(q),\u03bd(q)usingMHwithaproposalfromSGLDandarejectionstepprovidedbyRacing-\nNormal MH. The rejection step controls the error introduced in SGLD when the step size is large.\nAs the marginal likelihood for each model could be differed by a few orders of magnitudes, to\nmake sure every model is sampled sufficiently often, we first adjust the prior distribution \u02dc \u03c0 with the\nWang-Landau algorithm with an annealing adaptation on log \u02dc \u03c0, 1\/(1+t\/100), so that the posterior\ndistribution \u02dc p(q|r) is approximately uniform. We then fix \u02dc \u03c0 and compare the exact and approximate\nMCMC algorithms. The real posterior distribution can be computed as p(q|r) \u221d \u02dc p(q|r)\/\u02dc \u03c0(q).\nWe choose the step size separately for the exact and stochastic gradient Langevin dynamics [6] so\nthat the acceptance rate is about 36%.\np(rt|\u03b1(q),rt\u2212q:t\u22121,\u03bd(q)) with SGLD and Racing-Normal MH\n(\u03b1(j),\u03bd(j))|q\niid\n(25)\nWe apply the control variates by first segmenting the 2-D space of zj,t\n(\u03b1(j)\nquantiles and then taking the reference points at the mean of each bin. We also notice that some\ndata points have large residual reward li,n\u2212 hi,nwhen zj,tis far from the reference point. We take\n20% of the points with the largest distance in z as outliers, always compute them every iteration and\napply the subsampling algorithm for the rest data.\ndef\n=(rt,\u03b1(j)\n0\n+\n1:j)Trt\u2212j:t\u22121), where \u03b1(j)takes the MAP value, equally into 100 bins according to marginal\nC.3Details of the Author Coreference Experiment\nThe main differences of this sampling problem from Eq. 1 are that\n1. |Cy| ?= |Cy?| and the distribution of the cluster size follows approximately a power law\nwith the value varying from as small as 1 to thousands. If we set m(1)= 50 as usual, we\nalready draw about 33% of all the rewards in the first mini-batch. So we slightly abuse the\nNormal assumption and use a small size for m(1)= 3 and use doubling scheme for the\nrest with m(2)\ny\n= (|Cy| \u2212 3)\/10 \u2227 1. The experiment shows an empirical error 0.045 of\nmis-identification of the best arm with the provided bound \u03b4 = 0.05.\n2. The distribution of {f\u03b8(xi,xj) : j \u2208 Cy} is independent from different clusters\/arms. We\nexploit the independence of rewards and choose the bound\n?\u02c6 \u03c3i\nThis modification has the same performance as with the pairwise variance estimate and has\nthe same computational complexity as with the marginal variance estimate O(DN). We\ncompute BNormalwith a sub-optimal but simpler choice as\nGNormal(\u03b4,Ti,Tj, \u02c6 \u03c3i, \u02c6 \u03c3j) =\nTi\n?\n1 \u2212Ti\u2212 1\nNi\u2212 1\n?\n+\u02c6 \u03c3j\nTj\n?\n1 \u2212Tj\u2212 1\nNj\u2212 1\n??\u22121\/2\nBNormal.\n(26)\nBNormal(\u03b4) = \u03a6\u22121\n?\n1 \u2212\n\u03b4\nt\u2217\u2212 1\n?\n.\n(27)\n16"},{"page":17,"text":"It is easy to show that Eq. 5 still holds in this case using a union bound across t. The bound\nin Eq. 27 is strictly looser than BNormal= E\u22121(\u03b4) but the difference is small when \u03b4 ? 1\nand diminishes to 0 as \u03b4 \u2192 0.\nWe obtained the dataset from the authors of [26] but it is different from what is used in [26] with\nmore difficult citations. The best B3F-1 score reported in this paper is a reasonable value for this\ndata set according to personal communications with the authors of [26].\n17"}],"fullTextUrl":"https:\/\/www.researchgate.net\/profile\/Yutian_Chen3\/publication\/279633530_Subsampling-Based_Approximate_Monte_Carlo_for_Discrete_Distributions\/links\/565d728808aeafc2aac7970f.pdf","widgetId":"rgw26_56ab9d3a58c4a"},"id":"rgw26_56ab9d3a58c4a","partials":[],"templateName":"publicliterature\/stubs\/PublicationText.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationText.html?publicationUid=279633530&hide=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationDetailAd":{"data":{"googleDfpSlot":null,"widgetId":"rgw27_56ab9d3a58c4a"},"id":"rgw27_56ab9d3a58c4a","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAd.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAd.html?publicationUid=279633530&slotId=336x280_Publications_ATF_Right&collapseSlotMode=never&fallbackContainerEnabled=1","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationRelations":null,"publicationRelationsReverse":null,"publicationUid":279633530,"showSignUpDialog":false,"selectNewSignUpDialog":false,"publicationQuestions":null,"publicationCitations":{"data":{"publicationUid":279633530,"publicationCitationsList":{"data":{"citationItems":[],"hasCitations":false,"sort":"normal","sortNormal":true,"sortOriginal":false,"publicationUid":279633530,"publicationLink":"publication\/279633530_Subsampling-Based_Approximate_Monte_Carlo_for_Discrete_Distributions","showOriginalOrderSortingOption":true,"hasShowMore":true,"newOffset":10,"pageSize":10,"widgetId":"rgw29_56ab9d3a58c4a"},"id":"rgw29_56ab9d3a58c4a","partials":[],"templateName":"publicliterature\/stubs\/PublicationCitationsList.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationCitationsList.html?publicationUid=279633530&sort=&totalCount=28&swapJournalAndAuthorPositions=0&showAbstract=1&showType=1&showPublicationPreview=1","viewClass":"views.publicliterature.PublicationCitationsListView","yuiModules":["rg.views.publicliterature.PublicationCitationsListView"],"stylesheets":[],"_isYUI":true},"hasCitations":true,"citationsCount":28,"hasIncomingCitations":false,"incomingCitationsCount":0,"showCitationsSorter":true,"showAbstract":true,"showType":true,"showPublicationPreview":true,"swapJournalAndAuthorPositions":false,"sort":"","sortOriginal":false,"citationList":"outgoing","showsIncoming":false,"showSorting":true,"usePlainButton":null,"useEnrichedContext":null,"widgetId":"rgw28_56ab9d3a58c4a"},"id":"rgw28_56ab9d3a58c4a","partials":[],"templateName":"publicliterature\/stubs\/PublicationCitations.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationCitations.html?publicationUid=279633530&citationList=&citedInPage=1&sort=","viewClass":"views.publicliterature.PublicationCitationsView","yuiModules":["rg.views.publicliterature.PublicationCitationsView"],"stylesheets":[],"_isYUI":true},"publicationReviewPromo":null,"publicationUsedInReviews":null,"publicationPdfJsReader":{"data":{"isPreview":false,"licenseUrl":null,"licenseInfo":null,"defaultLinkData":{"linkId":"565d728808aeafc2aac7970f","name":"Yutian Chen","date":"Dec 01, 2015 ","nameLink":"profile\/Yutian_Chen3","filename":"","downloadLink":"https:\/\/www.researchgate.net\/profile\/Yutian_Chen3\/publication\/279633530_Subsampling-Based_Approximate_Monte_Carlo_for_Discrete_Distributions\/links\/565d728808aeafc2aac7970f.pdf?inViewer=0&pdfJsDownload=0&origin=publication_detail","viewerUrl":"https:\/\/www.researchgate.net\/profile\/Yutian_Chen3\/publication\/279633530_Subsampling-Based_Approximate_Monte_Carlo_for_Discrete_Distributions\/links\/565d728808aeafc2aac7970f.pdf?inViewer=1&pdfJsDownload=1&origin=publication_detail","downloadHash":"3bca779946eadada500a764cbcd39a66","showFileSizeNote":false,"fileSize":"784.73 KB","noFollow":false,"isDefault":true,"doi":null},"displayableLinks":[{"linkId":"565d728808aeafc2aac7970f","name":"Yutian Chen","date":"Dec 01, 2015 ","nameLink":"profile\/Yutian_Chen3","filename":"","downloadLink":"https:\/\/www.researchgate.net\/profile\/Yutian_Chen3\/publication\/279633530_Subsampling-Based_Approximate_Monte_Carlo_for_Discrete_Distributions\/links\/565d728808aeafc2aac7970f.pdf?inViewer=0&pdfJsDownload=0&origin=publication_detail","viewerUrl":"https:\/\/www.researchgate.net\/profile\/Yutian_Chen3\/publication\/279633530_Subsampling-Based_Approximate_Monte_Carlo_for_Discrete_Distributions\/links\/565d728808aeafc2aac7970f.pdf?inViewer=1&pdfJsDownload=1&origin=publication_detail","downloadHash":"3bca779946eadada500a764cbcd39a66","showFileSizeNote":false,"fileSize":"784.73 KB","noFollow":false,"isDefault":true,"doi":null}],"hasDisplayableLinks":false,"reader":{"data":{"pdfCommentsActive":false,"publicationType":"Article","onlyRenderFirstPage":false,"readMoreExperimentGoal":"goalPublicationPdfClicksReadMore","readMoreExperimentViewId":null,"comments":null,"figures":[],"figureAssetIds":[],"figureOverlayUrls":{"clickOnOverlay":"publication.PublicationFigures.html?_sg=yoY-JbCwcHVbWe0vdq8JnxnaDijsFBuDTIAmDhnRp7oN5PJ_MGlMmRGYl9IF6Iy5P7kkZprHcAqYxzJ9rCYvBw.ORTTmO6VdQi6fAzVD1c5Y1XKrHUUB9Z2c4-S-BIa9kcPtvsvRRHV5fidPD7nDYr9IaBxJXSrNEXJNMIp8kSnOQ","clickOnPill":"publication.PublicationFigures.html?_sg=1Yy0OlUWhyzhPSbWisp7PQ3bDeNMFyDODPRCKB3kpvdsHuavJ41szgFQqFmQJjMiUMFtpwSAuJDTFovnxiLGcQ.JD0j5tr3--Nts5yri7IlpMcvgrw34bWSEvcED_P1fznM7DPPMBy1aJJ3SvK-brhksd4t6FTNXgZFhfFdr01w0w"},"canSelect":false,"javascriptPath":"https:\/\/www.researchgate.net\/c\/o1q2er\/","downloadUrl":"https%3A%2F%2Fwww.researchgate.net%2Fprofile%2FYutian_Chen3%2Fpublication%2F279633530_Subsampling-Based_Approximate_Monte_Carlo_for_Discrete_Distributions%2Flinks%2F565d728808aeafc2aac7970f.pdf%3FinViewer%3D1%26pdfJsDownload%3D1%26origin%3Dpublication_detail","viewerUrl":"https:\/\/www.researchgate.net\/c\/o1q2er\/javascript\/lib\/pdfjs\/web\/viewer.html","commentEndpoint":"https:\/\/www.researchgate.net\/rgformat\/api\/comment","experimentEndpoint":"https:\/\/www.researchgate.net\/rgformat\/api\/experiment?key=vGxgWaDYGnooaAqxDa_D3DFO8SUgWd5KDHZqImouutkmlQmHkbGs3UC1wW2eb5i0Hr-EwtiCPc-80cpiFEkKMw","urlHash":"bccd90c3ecbcac7a12693a8a14d2b6de","downloadTrackUrl":"application.PdfJsReader.ajaxTrackDownload.html?msrp=dJLcllnIwb_YLEnQcMvDmSiUa-IffQEczWRfHpb9FpvCDMv-tml5LxiqHbeYCHfhHTr9q6p-0ZnqQskVpvZxAV8tY1Ds2HMDnFYg4MbOba8.UBzVtV5oVQXHe-pNU4FCofAjy378bOnj-fcQ0zQpdIlfi3CuDi7moeio5F0gsBhdAi-ZDb5kwgsQDZ8OwyoOvQ.jLve6kdMDq_yRO0yasDomd8bRMNWe7UJ9M4hlRHX5O5725l32X9nq1Zcii81FF1UQjSUBBk68nc3wv8h2R3DXg","viewportMilestoneTrackUrl":"application.PdfJsReader.ajaxTrackViewportMilestone.html","linkId":"565d728808aeafc2aac7970f","trackedDownloads":{"565d728808aeafc2aac7970f":{"v":false,"d":false}},"assetId":"AS:301794166099973@1448964744358","readerDocId":null,"assetType":"fulltext","interactionType":{"comment":"comment","highlight":"highlight"},"publicationUid":279633530,"commentCursorPromo":null,"widgetId":"rgw31_56ab9d3a58c4a"},"id":"rgw31_56ab9d3a58c4a","partials":[],"templateName":"application\/stubs\/PdfJsReader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PdfJsReader.html?fileHref=https%3A%2F%2Fwww.researchgate.net%2Fprofile%2FYutian_Chen3%2Fpublication%2F279633530_Subsampling-Based_Approximate_Monte_Carlo_for_Discrete_Distributions%2Flinks%2F565d728808aeafc2aac7970f.pdf%3FinViewer%3D1%26pdfJsDownload%3D1%26origin%3Dpublication_detail&assetId=AS%3A301794166099973%401448964744358&publicationUid=279633530&linkId=565d728808aeafc2aac7970f&onlyShowFirstPage=0","viewClass":null,"yuiModules":["css-pow-application-PdfJsReader"],"stylesheets":["pow\/application\/PdfJsReader.css"],"_isYUI":true},"showHeader":true,"title":"Subsampling-Based Approximate Monte Carlo for Discrete Distributions","publicationType":"Article","downloadTrackUrl":"publicliterature.PublicationInlineReader.ajaxTrackDownload.html?msrp=n6Kuxx9dO0EN7fVAYFDnDdYe72svn4ueN_sgJmFoXI1NL0nfePTm35HLf-4ZVjrmFClrKmSLsODsbDvPTz8tiNURFvoDDuAgImtlJU5AfFk.Np6yKTNJBguyWlpNZ1FSa8Zo0xkASHFHOoTZTX-YQG5VQBSuGQ4ZjZ8O93sF-LWUhHloYk6X2FkIbICgmxRD3A.Yirq9opHR8Eo6Ybl25fumhaS7zUbN-A8dVnIcWqtUhBYmTmHC9m4DndmbcNRPbYfba3vaogqC8lBOM0E8UVxJQ","publicationUid":279633530,"trackedDownloads":{"565d728808aeafc2aac7970f":{"v":false,"d":false}},"inlinePdf":false,"publicationComments":null,"showDownloadButton":true,"socialShare":{"data":{"shareItems":[{"data":{"name":"Facebook","url":"http:\/\/www.facebook.com\/share.php?u={{url}}{{#title}}&t={{title}}{{\/title}}","width":600,"height":350,"useUtmTags":true,"utmSource":"facebook","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareFacebook.ajaxTrackSocialShare.html","widgetId":"rgw33_56ab9d3a58c4a"},"id":"rgw33_56ab9d3a58c4a","partials":{"shareIcon":"application\/stubs\/partials\/shareFacebookBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareFacebook.html?provider=Facebook&shareIcon=shareIconBlog&utmSource=facebook&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"Twitter","url":"http:\/\/twitter.com\/intent\/tweet?text={{#title}}{{title}}: {{\/title}}{{url}}&via=researchgate","width":600,"height":350,"useUtmTags":true,"utmSource":"twitter","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareTwitter.ajaxTrackSocialShare.html","widgetId":"rgw34_56ab9d3a58c4a"},"id":"rgw34_56ab9d3a58c4a","partials":{"shareIcon":"application\/stubs\/partials\/shareTwitterBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareTwitter.html?provider=Twitter&shareIcon=shareIconBlog&utmSource=twitter&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"Google+","url":"https:\/\/plus.google.com\/share?url={{url}}","width":600,"height":600,"useUtmTags":true,"utmSource":"googleplus","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareGooglePlus.ajaxTrackSocialShare.html","widgetId":"rgw35_56ab9d3a58c4a"},"id":"rgw35_56ab9d3a58c4a","partials":{"shareIcon":"application\/stubs\/partials\/shareGooglePlusBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareGooglePlus.html?provider=Google%2B&shareIcon=shareIconBlog&utmSource=googleplus&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"LinkedIn","url":"http:\/\/www.linkedin.com\/shareArticle?mini=true&url={{url}}{{#title}}&title={{title}}{{\/title}}&source=ResearchGate","width":520,"height":570,"useUtmTags":true,"utmSource":"linkedin","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareLinkedIn.ajaxTrackSocialShare.html","widgetId":"rgw36_56ab9d3a58c4a"},"id":"rgw36_56ab9d3a58c4a","partials":{"shareIcon":"application\/stubs\/partials\/shareLinkedInBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareLinkedIn.html?provider=LinkedIn&shareIcon=shareIconBlog&utmSource=linkedin&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"Reddit","url":"https:\/\/www.reddit.com\/submit?url={{url}}{{#title}}&title={{title}}{{\/title}}","width":600,"height":600,"useUtmTags":true,"utmSource":"reddit","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareReddit.ajaxTrackSocialShare.html","widgetId":"rgw37_56ab9d3a58c4a"},"id":"rgw37_56ab9d3a58c4a","partials":{"shareIcon":"application\/stubs\/partials\/shareRedditBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareReddit.html?provider=Reddit&shareIcon=shareIconBlog&utmSource=reddit&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true}],"widgetId":"rgw32_56ab9d3a58c4a"},"id":"rgw32_56ab9d3a58c4a","partials":[],"templateName":"application\/stubs\/SocialShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.SocialShare.html?campaign=shareFullTextPublication&trackClick=1&shareIcon=shareIconBlog","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw30_56ab9d3a58c4a"},"id":"rgw30_56ab9d3a58c4a","partials":[],"templateName":"publicliterature\/stubs\/PublicationInlineReader.html","templateExtensions":["generalHelpers"],"attrs":{"showFulltextDownloadedSignupDialog":true,"preSignUpDialogContext":null,"requestFulltext":false},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationInlineReader.html","viewClass":"views.publicliterature.PublicationInlineReaderView","yuiModules":["rg.views.publicliterature.PublicationInlineReaderView","css-pow-publicliterature-PublicationInlineReader"],"stylesheets":["pow\/publicliterature\/PublicationInlineReader.css"],"_isYUI":true},"useFulltextOptimizedLayout":false,"publicationActions":null,"requestFulltextPromo":null,"currentUrl":"publication\/279633530_Subsampling-Based_Approximate_Monte_Carlo_for_Discrete_Distributions","isLeaderboardAd":false,"enableStickyBox":null,"googleDfpSlotMobileBottom":null,"fullTextExitPopup":null,"showExitPopupDialog":false,"widgetId":"rgw2_56ab9d3a58c4a"},"id":"rgw2_56ab9d3a58c4a","partials":{"romeo_legal_notice":"publicliterature\/stubs\/partials\/romeo_legal_notice.html"},"templateName":"publicliterature\/stubs\/PublicPublicationDetails_NewLayout.html","templateExtensions":["generalHelpers"],"attrs":{"publicationUid":279633530},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicPublicationDetailsOld.html?publicationUid=279633530&isTestOldDesign=0","viewClass":"views.publicliterature.PublicPublicationDetailsOldView","yuiModules":["rg.views.publicliterature.PublicPublicationDetailsOldView"],"stylesheets":[],"_isYUI":true},"widgetId":"rgw1_56ab9d3a58c4a"},"id":"rgw1_56ab9d3a58c4a","partials":[],"templateName":"publicliterature\/stubs\/PublicPublicationDetails.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicPublicationDetails.html","viewClass":"views.publicliterature.PublicPublicationDetailsView","yuiModules":["rg.views.publicliterature.PublicPublicationDetailsView"],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"uaClass":"","headPrefix":[],"rootUrl":"https:\/\/www.researchgate.net\/","requestToken":"B0kc5LtgBc8ZuMFoxXx6khK4qXdojaGyLjhdKG\/gPSLWK80C7oOsdTl5hhyoiMw7zDgjrDJ0O44wtr+O7pGrtQTWeq2xLlBVsfM5PlqJLMF2xlMzYxbWFvIXTT3m0xIb5LdH2LmN74Ta0YyZzlmr0tIbXFgqD5hj5x76T0Zt3ifZKA0zIGJScQCozFVoqizKMW5GK1lFWnW6BmpooEwWxCZgt\/qfU\/DGZqAg+8pdCWLojqy2nsoa4hyf0eQJKTXIRj2JoClGw6+P1H0Nm2niU7PGFJww6h3TzxhG4I3s1bE=","faviconCdnUrl":"https:\/\/c5.rgstatic.net\/m\/2390829798215018\/images\/favicon.ico","headerOutput":"<noscript><\/noscript><link rel=\"canonical\" href=\"https:\/\/www.researchgate.net\/publication\/279633530_Subsampling-Based_Approximate_Monte_Carlo_for_Discrete_Distributions\" \/>\n<link rel=\"dns-prefetch\" href=\"\/\/c5.rgstatic.net\" \/>\n<link rel=\"dns-prefetch\" href=\"\/\/i1.rgstatic.net\" \/>\n<meta property=\"twitter:card\" content=\"summary\" \/>\n<meta property=\"twitter:site\" content=\"@ResearchGate\" \/>\n<meta property=\"og:title\" content=\"Subsampling-Based Approximate Monte Carlo for Discrete Distributions\" \/>\n<meta property=\"og:description\" content=\"Drawing a sample from a discrete distribution is one of the building\ncomponents for Monte Carlo methods. Like other sampling algorithms, discrete\nsampling also suffers from high computational...\" \/>\n<meta property=\"og:site_name\" content=\"ResearchGate\" \/>\n<meta property=\"og:image\" content=\"https:\/\/i1.rgstatic.net\/publication\/279633530_Subsampling-Based_Approximate_Monte_Carlo_for_Discrete_Distributions\/links\/565d728808aeafc2aac7970f\/smallpreview.png\" \/>\n<meta property=\"og:url\" content=\"https:\/\/www.researchgate.net\/publication\/279633530_Subsampling-Based_Approximate_Monte_Carlo_for_Discrete_Distributions\" \/>\n<meta property=\"rg:id\" content=\"PB:279633530\" \/>\n<meta name=\"DC.identifier\" scheme=\"DCTERMS.URI\" content=\"http:\/\/dx.doi.org\/\" \/>\n<meta name=\"gs_meta_revision\" content=\"1.1\" \/>\n<meta name=\"citation_title\" content=\"Subsampling-Based Approximate Monte Carlo for Discrete Distributions\" \/>\n<meta name=\"citation_author\" content=\"Yutian Chen\" \/>\n<meta name=\"citation_author\" content=\"Zoubin Ghahramani\" \/>\n<meta name=\"citation_publication_date\" content=\"2015\/06\/30\" \/>\n<meta name=\"citation_pdf_url\" content=\"https:\/\/www.researchgate.net\/profile\/Yutian_Chen3\/publication\/279633530_Subsampling-Based_Approximate_Monte_Carlo_for_Discrete_Distributions\/links\/565d728808aeafc2aac7970f.pdf\" \/>\n<meta name=\"citation_abstract_html_url\" content=\"https:\/\/www.researchgate.net\/publication\/279633530_Subsampling-Based_Approximate_Monte_Carlo_for_Discrete_Distributions\" \/>\n<meta name=\"citation_fulltext_html_url\" content=\"https:\/\/www.researchgate.net\/publication\/279633530_Subsampling-Based_Approximate_Monte_Carlo_for_Discrete_Distributions\" \/>\n<meta name=\"viewport\" content=\"width=device-width,initial-scale=1\" \/>\n<link href=\"\/\/c5.rgstatic.net\/m\/22664197317151888\/styles\/rg.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/21004998181197492\/styles\/rg2.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<!--[if lt IE 9]><link href=\"\/\/c5.rgstatic.net\/m\/238176252723686\/styles\/ie.css\" type=\"text\/css\" rel=\"stylesheet\"\/><![endif]-->\n<link href=\"\/\/c5.rgstatic.net\/m\/217752362214895\/styles\/modules\/publicprofile.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/21993347442549\/styles\/pow\/publicliterature\/FollowPublicationPromo.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/282514599719602\/styles\/pow\/application\/PdfJsReader.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/23819663151220\/styles\/pow\/publicliterature\/PublicationInlineReader.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<script src=\"\/\/c5.rgstatic.net\/m\/2321000301012716\/javascript\/vendor\/webfontloader\/webfontloader.js\" type=\"text\/javascript\"><\/script>\n <script>(function(i,s,o,g,r,a,m){i[\"GoogleAnalyticsObject\"]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,\"script\",\"\/\/www.google-analytics.com\/analytics.js\",\"ga\");\n ga(\"create\",\"UA-58591210-1\");ga(\"set\",\"anonymizeIp\",true);ga('set', 'dimension1', 'publication full-text');ga('set', 'dimension2', 'Article');ga('set', 'dimension3', 'Logged out');ga('set', 'dimension4', 'https');ga(\"send\",\"pageview\");<\/script>\n","webfont":"<noscript><\/noscript><script> WebFontConfig = { custom: { families: ['source_sans_pro_italic', 'source_sans_pro_bold', 'source_sans_pro', 'martel'], urls : ['\/\/c5.rgstatic.net\/m\/231392577336386\/styles\/fonts.css'] } }; WebFont.load(WebFontConfig); <\/script>\n","correlationId":"rgreq-3263a1e0-e9b9-475c-99d4-a0870be9e987","accountId":null,"module":"publicliterature","action":"publicliterature.PublicPublicationDetails","page":"publicationDetail","product":"publications","backendTime":394,"continent":"Asia","stylesHome":"\/\/c5.rgstatic.net\/m\/","staticHost":"c5.rgstatic.net","useEarlyFlush":false,"longRunningRequestIdentifier":"LongRunningRequest.publicliterature.PublicPublicationDetails","longRunningRequestFp":"e9e5bbe1366c7ee8c8e41d02f793c884ac9be19b","widgetId":"rgw38_56ab9d3a58c4a"},"id":"rgw38_56ab9d3a58c4a","partials":[],"templateName":"application\/stubs\/StaticHeader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.StaticHeader.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){
            Y.rg.core.pagespeed.Monitoring.monitorPage("\/\/glassmoni.researchgate.net", "publicliterature.PublicPublicationDetails.run.html.loggedOut.get", "59de9668d07aeb77ab4de5f24d382b5d199d2437", "rgreq-3263a1e0-e9b9-475c-99d4-a0870be9e987", "1a2e2f46f1addceb2cbfe5edafdbb25b59ce8c15");
        
            Y.rg.core.pagespeed.Monitoring.monitorPage("\/\/glassmoni.researchgate.net", "publicationDetail.loggedOut", "ed1993d9e20f6cefa83edacaa24401a18c071aea", "rgreq-3263a1e0-e9b9-475c-99d4-a0870be9e987", "1a2e2f46f1addceb2cbfe5edafdbb25b59ce8c15");
        })();
(function(){Y.rg.createInitialWidget({"data":{"year":"2016","inlinePromo":null,"isAdmin":false,"contactUrl":"https:\/\/www.researchgate.net\/contact","aboutUsUrl":"https:\/\/www.researchgate.net\/about","widgetId":"rgw39_56ab9d3a58c4a"},"id":"rgw39_56ab9d3a58c4a","partials":[],"templateName":"application\/stubs\/DefaultFooter.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.DefaultFooter.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"headerLogin":{"data":{"urlAfterLogin":"publication\/279633530_Subsampling-Based_Approximate_Monte_Carlo_for_Discrete_Distributions?ev=auth_pub","requestToken":"GzPs79jkprsA6lv5GkFBWNh72l3oyKQ\/UTuxr4iCdyo7MktpXVfRViJFT+ZAXeOu1pJHLd6X+HWDXY\/+5UArkJ4HbtEitUfeT5hPlNjlMzNCWYgOkrXGTCepLUC59eja\/B3HM2+ng436JLAfCMc2r\/5v7WJot\/oxharSxtAp4iE5VNgWCDWDmj6QnIiuNHefx2RQEz+eavETOuPKUoqZI0jZg8MVR7zI\/SIdOfuKsdKTFJL5howOM6G4Z6Fto89F5TlaSNiw2+30tKOzag2RZwi7x06xKbco3H+72s8FPJI=","loginUrl":"https:\/\/www.researchgate.net\/application.Login.html","signupUrl":"https:\/\/www.researchgate.net\/signup.SignUp.html?ev=su_chnl_index&hdrsu=1&_sg=YrwOCuKRLoWnZd9oFKS2ZH0m5Y7rvtLJv2YCTzXIBrILbkjtXAphycBx5eVl7prf","encodedUrlAfterLogin":"cHVibGljYXRpb24vMjc5NjMzNTMwX1N1YnNhbXBsaW5nLUJhc2VkX0FwcHJveGltYXRlX01vbnRlX0NhcmxvX2Zvcl9EaXNjcmV0ZV9EaXN0cmlidXRpb25zP2V2PWF1dGhfcHVi","signupCallToAction":"Join for free","widgetId":"rgw41_56ab9d3a58c4a"},"id":"rgw41_56ab9d3a58c4a","partials":{"partial":"application\/stubs\/partials\/headerLoginDefault.html"},"templateName":"application\/stubs\/HeaderLogin.html","templateExtensions":[],"attrs":{"goal":"milestoneHeaderLoginSeen"},"widgetUrl":"https:\/\/www.researchgate.net\/application.HeaderLogin.html","viewClass":"views.application.HeaderLoginView","yuiModules":["rg.views.application.HeaderLoginView"],"stylesheets":[],"_isYUI":true},"cookieConsent":null,"logoSvgSrc":"https:\/\/c5.rgstatic.net\/m\/235107188705592\/images\/template\/brand-header-logo.svg","logoFallbackSrc":"https:\/\/c5.rgstatic.net\/m\/238113351022438\/images\/template\/brand-header-logo.png","widgetId":"rgw40_56ab9d3a58c4a"},"id":"rgw40_56ab9d3a58c4a","partials":{"schemaSocialProfiles":"application\/stubs\/partials\/schemaSocialProfiles.html"},"templateName":"application\/stubs\/HeaderLoggedOut.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.HeaderLoggedOut.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"logEvent":"su_banner","specialCopy":false,"widgetId":"rgw42_56ab9d3a58c4a"},"id":"rgw42_56ab9d3a58c4a","partials":[],"templateName":"application\/stubs\/LoggedOutBanner.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.LoggedOutBanner.html","viewClass":"views.application.LoggedOutBannerView","yuiModules":["rg.views.application.LoggedOutBannerView"],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.core.util.ParameterFilter.filter(["ev","cp","ch","ref","dbw","pli","loginT","uid","claimChannel","enrichId","enrichSource","utm_source","utm_medium","utm_campaign","el","ci"]);})();
});}); } else { throw 'YRG was not loaded when attaching widgets'; }</script><script> dataLayer = [{"pageCategory":"publication full-text","publicationType":"Article","eventCategory":"Publication page"}]; </script> <noscript><iframe src="//www.googletagmanager.com/ns.html?id=GTM-MKVKH7" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-MKVKH7');</script><script>(function(e){function n(n,t,o,a){"use strict";var i=e.document.createElement("link"),r=t||e.document.getElementsByTagName("script")[0],d=e.document.styleSheets;return i.rel="stylesheet",i.href=n,i.media="only x",a&&(i.onload=a),r.parentNode.insertBefore(i,r),i.onloadcssdefined=function(e){for(var t,o=0;d.length>o;o++)d[o].href&&d[o].href.indexOf(n)>-1&&(t=!0);t?e():setTimeout(function(){i.onloadcssdefined(e)})},i.onloadcssdefined(function(){i.media=o||"all"}),i}function t(e,n){e.onload=function(){e.onload=null,n&&n.call(e)},"isApplicationInstalled"in navigator&&"onloadcssdefined"in e&&e.onloadcssdefined(n)}var o=function(a,i){"use strict";if(a&&3===a.length){var r=e.Image,d=!(!document.createElementNS||!document.createElementNS("http://www.w3.org/2000/svg","svg").createSVGRect||!document.implementation.hasFeature("http://www.w3.org/TR/SVG11/feature#Image","1.1")||e.opera&&-1===navigator.userAgent.indexOf("Chrome")||-1!==navigator.userAgent.indexOf("Series40")),c=new r;c.onerror=function(){o.method="png",o.href=a[2],n(a[2])},c.onload=function(){var e=1===c.width&&1===c.height,r=a[e&&d?0:e?1:2];o.method=e&&d?"svg":e?"datapng":"png",o.href=r,t(n(r),i)},c.src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///ywAAAAAAQABAAACAUwAOw==",document.documentElement.className+=" grunticon"}};o.loadCSS=n,o.onloadCSS=t,e.grunticon=o})(this);grunticon(["https://c5.rgstatic.net/c/o1q2er/styles/icons/_header-ico.svg.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_header-ico.png.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_header-ico.fallback.scss"]);grunticon(["https://c5.rgstatic.net/c/o1q2er/styles/icons/_admin-ico.svg.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_admin-ico.png.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_admin-ico.fallback.scss"]);grunticon(["https://c5.rgstatic.net/c/o1q2er/styles/icons/_ico.svg.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_ico.png.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_ico.fallback.scss"]);</script></body>
</html>
