<!DOCTYPE html> <html lang="en" class="" id="rgw38_56ab1cd3a62b5"> <head > <meta charset="utf-8"/> <meta http-equiv="content-type" content="text/html; charset=UTF-8"/> <meta name="Rg-Request-Token" id="Rg-Request-Token" content="LOpEDj6wNv7Bo0HxWBTh5uP9bcx0eWGo/MuBgjDCxR21qhbOpxB3Gk+ajWW8L9+84oWoG6n3wQKb/64K4m7swgyaXlII1b8LQY1GEs8xQeywZXG+/wTJjzw+wUVwx0uPIzXhv3zODOs+UdwA+RWffJb6CjBd81aA3Q64V5LJxmkhzmgSMKfdtGA9JcrKW4mx04EpG8E6k2tXSglIP8r0aTggLkv9rkW17JmpbvtFfvT3RlmSLAtgtzeIUX+SVmPPcGNyNDLJRnBfk6TxrI3cNRWbrpsjlOcULECG5S66U9c="/> <meta http-equiv="expires" content="0"/> <link rel="apple-touch-icon" sizes="57x57" href="https://www.researchgate.net/apple-touch-icon-57x57.png"> <link rel="apple-touch-icon" sizes="60x60" href="https://www.researchgate.net/apple-touch-icon-60x60.png"> <link rel="apple-touch-icon" sizes="72x72" href="https://www.researchgate.net/apple-touch-icon-72x72.png"> <link rel="apple-touch-icon" sizes="76x76" href="https://www.researchgate.net/apple-touch-icon-76x76.png"> <link rel="apple-touch-icon" sizes="114x114" href="https://www.researchgate.net/apple-touch-icon-114x114.png"> <link rel="apple-touch-icon" sizes="120x120" href="https://www.researchgate.net/apple-touch-icon-120x120.png"> <link rel="apple-touch-icon" sizes="144x144" href="https://www.researchgate.net/apple-touch-icon-144x144.png"> <link rel="apple-touch-icon" sizes="152x152" href="https://www.researchgate.net/apple-touch-icon-152x152.png"> <link rel="apple-touch-icon" sizes="180x180" href="https://www.researchgate.net/apple-touch-icon-180x180.png"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-32x32.png" sizes="32x32"> <link rel="icon" type="image/png" href="https://www.researchgate.net/android-chrome-192x192.png" sizes="192x192"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-96x96.png" sizes="96x96"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-16x16.png" sizes="16x16"> <link rel="shortcut icon" type="image/x-icon" href="https://c5.rgstatic.net/m/2390829798215018/images/favicon.ico"/> <link rel="manifest" href="https://www.researchgate.net/manifest.json"> <meta name="msapplication-TileColor" content="#da532c"> <meta name="msapplication-TileImage" content="https://www.researchgate.net/mstile-144x144.png"> <meta name="theme-color" content="#444444"> <link rel="search" type="application/opensearchdescription+xml" title="ResearchGate search" href="https://www.researchgate.net/application.DownloadOpenSearchPlugin.html"/> <link rel="meta" type="application/rdf+xml" title="ICRA labels" href="https://www.researchgate.net/application.DownloadLabels.html"/> <link rel="http://oexchange.org/spec/0.8/rel/related-target" type="application/xrd+xml" href="https://www.researchgate.net/application.DownloadOExchange.html"/> <base href="https://www.researchgate.net/"/> <script>
    var rgConfig = {
        correlationId: "rgreq-ae859db4-64c7-4f45-abcd-143cfc579acd",
        accountId: "",
        module: "publicliterature",
        action: "publicliterature.PublicPublicationDetails",
        page: "publicationDetail",
        product: "publications",
        continent: "Asia",
        stylesHome: "//c5.rgstatic.net/m/",
        staticHost: "c5.rgstatic.net",
        longRunningRequestIdentifier: "LongRunningRequest.publicliterature.PublicPublicationDetails",
        longRunningRequestFp: "e9e5bbe1366c7ee8c8e41d02f793c884ac9be19b"
    };
    window.rootUrl = "https://www.researchgate.net/";
</script> <link rel="canonical" href="https://www.researchgate.net/publication/41781559_Gaussian_Process_for_Machine_Learning" />
<link rel="dns-prefetch" href="//c5.rgstatic.net" />
<link rel="dns-prefetch" href="//i1.rgstatic.net" />
<meta property="twitter:card" content="summary" />
<meta property="twitter:site" content="@ResearchGate" />
<meta property="og:title" content="Gaussian Process for Machine Learning" />
<meta property="og:description" content="Gaussian processes (GPs) provide a principled, practical, probabilistic approach to learning in kernel machines. GPs have received increased attention in the machine-learning community over the..." />
<meta property="og:site_name" content="ResearchGate" />
<meta property="og:image" content="https://i1.rgstatic.net/publication/41781559_Gaussian_Process_for_Machine_Learning/links/0e608559f0c46d4f0acd3d0d/smallpreview.png" />
<meta property="og:url" content="https://www.researchgate.net/publication/41781559_Gaussian_Process_for_Machine_Learning" />
<meta property="rg:id" content="PB:41781559" />
<meta name="DC.identifier" scheme="DCTERMS.URI" content="http://dx.doi.org/" />
<meta name="gs_meta_revision" content="1.1" />
<meta name="citation_title" content="Gaussian Process for Machine Learning" />
<meta name="citation_author" content="C. E. Rasmussen" />
<meta name="citation_author" content="C. K. I. Williams" />
<meta name="citation_publication_date" content="2006/01/01" />
<meta name="citation_abstract_html_url" content="https://www.researchgate.net/publication/41781559_Gaussian_Process_for_Machine_Learning" />
<meta name="citation_fulltext_html_url" content="https://www.researchgate.net/publication/41781559_Gaussian_Process_for_Machine_Learning" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<link href="//c5.rgstatic.net/m/22664197317151888/styles/rg.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/21004998181197492/styles/rg2.css" type="text/css" rel="stylesheet"/>
<!--[if lt IE 9]><link href="//c5.rgstatic.net/m/238176252723686/styles/ie.css" type="text/css" rel="stylesheet"/><![endif]-->
<link href="//c5.rgstatic.net/m/217752362214895/styles/modules/publicprofile.css" type="text/css" rel="stylesheet"/>
<script src="//c5.rgstatic.net/m/2321000301012716/javascript/vendor/webfontloader/webfontloader.js" type="text/javascript"></script>
 <script>(function(i,s,o,g,r,a,m){i["GoogleAnalyticsObject"]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,"script","//www.google-analytics.com/analytics.js","ga");
 ga("create","UA-58591210-1");ga("set","anonymizeIp",true);ga('set', 'dimension1', 'publication slurped');ga('set', 'dimension2', 'Article');ga('set', 'dimension3', 'Logged out');ga('set', 'dimension4', 'https');ga("send","pageview");</script>
  <script> WebFontConfig = { custom: { families: ['source_sans_pro_italic', 'source_sans_pro_bold', 'source_sans_pro', 'martel'], urls : ['//c5.rgstatic.net/m/231392577336386/styles/fonts.css'] } }; WebFont.load(WebFontConfig); </script><noscript></noscript>

<title>Gaussian Process for Machine Learning</title>
<meta name="description" content="Gaussian Process for Machine Learning on ResearchGate, the professional network for scientists."/>
<meta name="keywords" content="scientific network, scientific platform, scientific community, research partner, research collaboration, journal articles, international collaboration, find researcher, lifescience researcher, interdisciplinary research, research collaboration"/>
</head>
<body class="use-svg-icons logged-out">
<div id="page-container">
<script type="text/javascript">var googletag = googletag || {}; googletag.cmd = googletag.cmd || [];
(function() { var gads = document.createElement("script"); gads.async = true; gads.type = "text/javascript"; var useSSL = "https:" == document.location.protocol; gads.src = (useSSL ? "https:" : "http:") + "//www.googletagservices.com/tag/js/gpt.js"; var node =document.getElementsByTagName("script")[0]; node.parentNode.insertBefore(gads, node); })();</script><div id="main" class="logged-out-header-support">
<div id="content" class="">

<noscript>
<div class="c-box-warning full-width-element" style="text-align: center; ">
    <div style="margin: auto; padding:10px;" class="container">
        <b>For full functionality of ResearchGate it is necessary to enable JavaScript.
            Here are the <a href="http://www.enable-javascript.com/" rel="nofollow" target="_blank">
                instructions how to enable JavaScript in your web browser</a>.</b>
    </div>
</div>
</noscript>

<div id="rgw1_56ab1cd3a62b5" itemscope itemtype="http://schema.org/ScholarlyArticle"><div class="publication-wrapper publication-wrapper-onecol" id="rgw2_56ab1cd3a62b5" itemscope itemtype="http://schema.org/ScholarlyArticle"> <div class="c-col-content"> <div class="c-content"> <div class="clearfix">  <div class="publication-header"> <div id="rgw6_56ab1cd3a62b5">  <div class="type-label"> Article   </div> <span class="Z3988" title="ctx_ver=Z39.88-2004&rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&rfr_id=info%3Asid%2Fresearchgate.net%3Aresearchgate&rft.atitle=Gaussian%20Process%20for%20Machine%20Learning&rft.date=2006&rft.au=C.%20E.%20Rasmussen%2CC.%20K.%20I.%20Williams&rft.genre=article"></span> <h1 class="pub-title" itemprop="name">Gaussian Process for Machine Learning</h1> <meta itemprop="headline" content="Gaussian Process for Machine Learning">  <meta itemprop="image" content="https://i1.rgstatic.net/publication/41781559_Gaussian_Process_for_Machine_Learning/links/0e608559f0c46d4f0acd3d0d/smallpreview.png">  <div id="rgw8_56ab1cd3a62b5" class="publication-detail-author-list"> <div> <ul class="clearfix js-people-list">  <li id="rgw9_56ab1cd3a62b5"> <a href="researcher/2083187442_C_E_Rasmussen" class="pub-detail-item author-item" itemprop="author" itemscope itemtype="http://schema.org/Person"> <div class="indent-left"> <div class="people-img">  <img src="https://c5.rgstatic.net/m/2951093203564/images/template/default/profile/profile_default_s.jpg" title="C. E. Rasmussen" alt="C. E. Rasmussen" height="20px" width="20px" style="height: 20px;"/>  </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">C. E. Rasmussen</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item   not-claimed " id="rgw10_56ab1cd3a62b5">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="researcher/2083187442_C_E_Rasmussen"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="C. E. Rasmussen" alt="C. E. Rasmussen" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">       </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="researcher/2083187442_C_E_Rasmussen" class="display-name">C. E. Rasmussen</a>    </h5> <div class="truncate-single-line meta">   </div>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>  <li id="rgw11_56ab1cd3a62b5"> <a href="researcher/2037649422_C_K_I_Williams" class="pub-detail-item author-item" itemprop="author" itemscope itemtype="http://schema.org/Person"> <div class="indent-left"> <div class="people-img">  <img src="https://c5.rgstatic.net/m/2951093203564/images/template/default/profile/profile_default_s.jpg" title="C. K. I. Williams" alt="C. K. I. Williams" height="20px" width="20px" style="height: 20px;"/>  </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">C. K. I. Williams</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item   not-claimed " id="rgw12_56ab1cd3a62b5">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="researcher/2037649422_C_K_I_Williams"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="C. K. I. Williams" alt="C. K. I. Williams" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">       </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="researcher/2037649422_C_K_I_Williams" class="display-name">C. K. I. Williams</a>    </h5> <div class="truncate-single-line meta">   </div>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>   </ul> <div class="js-loading"></div>  </div> </div> <div class="pub-details js-pub-details">        <meta itemprop="datePublished" content="2006-01">  01/2006;               <div class="pub-source"> Source: <a href="http://edoc.mpg.de/312148" rel="nofollow">OAI</a> </div>  </div> <div id="rgw13_56ab1cd3a62b5" class="pub-abstract">  <div class="clearfix">   <p itemprop="description"> <strong>ABSTRACT</strong> <div>Gaussian processes (GPs) provide a principled, practical, probabilistic approach to learning in kernel machines. GPs have received increased attention in the machine-learning community over the past decade, and this book provides a long-needed systematic and unified treatment of theoretical and practical aspects of GPs in machine learning. The treatment is comprehensive and self-contained, targeted at researchers and students in machine learning and applied statistics. The book deals with the supervised-learning problem for both regression and classification, and includes detailed algorithms. A wide variety of covariance (kernel) functions are presented and their properties discussed. Model selection is discussed both from a Bayesian and a classical perspective. Many connections to other well-known techniques from machine learning and statistics are discussed, including support-vector machines, neural networks, splines, regularization networks, relevance vector machines and others. Theoretical issues including learning curves and the PAC-Bayesian framework are treated, and several approximation methods for learning with large datasets are discussed. The book contains illustrative examples and exercises, and code and datasets are available on the Web. Appendixes provide mathematical background and a discussion of Gaussian Markov processes.</div> </p>  </div>   </div>      <div class="action-container">   <div class="clear"></div> <div class="share-dialog-container" style="display: none;">  </div> </div> </div> <div style="margin-left: -20px; margin-right: -20px;">  </div> </div>  <div class="publication-detail-dfp-container rf"> <div id="rgw26_56ab1cd3a62b5">  </div> </div>  </div>  <div class="clearfix">  <noscript> <div id="rgw25_56ab1cd3a62b5"  itemprop="articleBody">  <p>Page 1</p> <p>Gaussian Processes for Machine Learning<br />Chris Williams<br />Institute for Adaptive and Neural Computation<br />School of Informatics, University of Edinburgh, UK<br />August 2007<br />Chris WilliamsANC<br />Gaussian Processes for Machine Learning</p>  <p>Page 2</p> <p>Overview<br />1 What is machine learning?<br />2 Gaussian Processes for Machine Learning<br />3 Multi-task Learning<br />Chris WilliamsANC<br />Gaussian Processes for Machine Learning</p>  <p>Page 3</p> <p>1. What is Machine Learning?<br />The goal of machine learning is to build computer systems<br />that can adapt and learn from their experience. (Dietterich,<br />1999)<br />Machine learning usually refers to changes in systems that<br />perform tasks associated with artificial intelligence (AI). Such<br />tasks involve recognition, diagnosis, planning, robot control,<br />prediction, etc. (Nilsson, 1996)<br />Some reasons for adaptation:<br />Some tasks can be hard to define except via examples<br />Adaptation can improve a human-built system, or track<br />changes over time<br />Goals can be autonomous machine performance, or enabling<br />humans to learn from data (data mining)<br />Chris WilliamsANC<br />Gaussian Processes for Machine Learning</p>  <p>Page 4</p> <p>Roots of Machine Learning<br />Statistical pattern recognition, adaptive control theory (EE)<br />Artificial Intelligence: e.g. discovering rules using decision<br />trees, inductive logic programming<br />Brain models, e.g. neural networks<br />Psychological models<br />Statistics<br />Chris WilliamsANC<br />Gaussian Processes for Machine Learning</p>  <p>Page 5</p> <p>Problems Addressed by Machine Learning<br />Supervised Learning<br />model p(y|x): regression,<br />classification, etc<br />Unsupervised Learning<br />model p(x): not just clustering!<br />Reinforcement Learning<br />Markov decision processes,<br />POMDPs, planning.<br />Chris WilliamsANC<br />Gaussian Processes for Machine Learning</p>  <p>Page 6</p> <p>123<br />456<br />Mask<br />Mask * Foreground<br />Mask<br />Mask * ForegroundBackground<br />(Williams and Titisias, 2004)<br />Chris WilliamsANC<br />Gaussian Processes for Machine Learning</p>  <p>Page 7</p> <p>Machine Learning and Statistics<br />Statistics<br />Machine Learning<br />probabilistic (graphical) models<br />Same models, but different problems?<br />Not all machine learning methods are based on probabilisic<br />models, e.g. SVMs, non-negative matrix factorization<br />Chris WilliamsANC<br />Gaussian Processes for Machine Learning</p>  <p>Page 8</p> <p>Some Differences<br />Statistics: focus on understanding data in terms of models<br />Statistics: interpretability, hypothesis testing<br />Machine Learning: greater focus on prediction<br />Machine Learning: focus on the analysis of learning<br />algorithms (not just large dataset issues)<br />Chris Williams ANC<br />Gaussian Processes for Machine Learning</p>  <p>Page 9</p> <p>Slide from Rob Tibshirani (early 1990s)<br />NEURAL NETS<br />network<br />weights<br />learning<br />generalization<br />supervised learning<br />unsupervised learning<br />optimal brain damage<br />large grant = $100,000<br />nice place to have a meeting:<br />Snowbird, Utah, French Alps<br />STATISTICS<br />model<br />parameters<br />fitting<br />test set performance<br />regression/classification<br />density estimation<br />model selection<br />large grant= $10,000<br />nice place to have a meeting:<br />Las Vegas in August<br />Chris WilliamsANC<br />Gaussian Processes for Machine Learning</p>  <p>Page 10</p> <p>2. Gaussian Processes for Machine Learning<br />Gaussian processes<br />History<br />Regression, classification and beyond<br />Covariance functions/kernels<br />Dealing with hyperparameters<br />Theory<br />Approximations for large datasets<br />Chris Williams ANC<br />Gaussian Processes for Machine Learning</p>  <p>Page 11</p> <p>Gaussian Processes<br />A Gaussian process is a stochastic process specified by its<br />mean and covariance functions<br />Mean function<br />µ(x) = E[f (x)]<br />often we take µ(x) ≡ 0 ∀x<br />Covariance function<br />k(x,x?) = E[(f (x) − µ(x))(f (x?) − µ(x?))]<br />Chris WilliamsANC<br />Gaussian Processes for Machine Learning</p>  <p>Page 12</p> <p>A Gaussian process prior over functions can be thought of as<br />a Gaussian prior on the coefficients w ∼ N(0,Λ) where<br />NF<br />?<br />In many interesting cases, NF= ∞<br />Can choose φ’s as eigenfunctions of the kernel k(x,x?) wrt<br />p(x) (Mercer)?<br />(For stationary covariance functions and Lebesgue measure we<br />get instead<br />?<br />where S(s) is the power spectrum)<br />Y(x) =<br />i=1<br />wiφi(x)<br />k(x,y)p(x)φi(x) dx = λiφi(y)<br />k(x − x?)e−2πis·xdx = S(s)e−2πis·x?<br />Chris WilliamsANC<br />Gaussian Processes for Machine Learning</p>  <p>Page 13</p> <p>k(x,x?) = σ2<br />0+ σ2<br />1xx?<br />k(x,x?) = exp−|x − x?|<br />k(x,x?) = exp−(x − x?)2<br />Chris WilliamsANC<br />Gaussian Processes for Machine Learning</p>  <p>Page 14</p> <p>Prediction with Gaussian Processes<br />A non-parametric prior<br />over functions<br />Although GPs can be<br />infinite-dimensional<br />objects, prediction from a<br />finite dataset is O(n3)<br />0 0.51<br />−2<br />−1<br />0<br />1<br />2<br />input, x<br />f(x)<br />00.51<br />−2<br />−1<br />0<br />1<br />2<br />input, x<br />f(x)<br />Chris Williams ANC<br />Gaussian Processes for Machine Learning</p>  <p>Page 15</p> <p>Gaussian Process Regression<br />Dataset D = (xi,yi)n<br />i=1, Gaussian likelihood p(yi|fi) ∼ N(0,σ2)<br />n<br />?<br />¯f (x) =<br />i=1<br />αik(x,xi)<br />where<br />α = (K + σ2I)−1y<br />var(f (x)) = k(x,x) − kT(x)(K + σ2I)−1k(x)<br />in time O(n3), with k(x) = (k(x,x1),...,k(x,xn))T<br />Chris Williams ANC<br />Gaussian Processes for Machine Learning</p>  <p>Page 16</p> <p>Some GP History<br />1940s: Wiener, Kolmogorov (time series)<br />Geostatistics (Matheron, 1973), Whittle (1963)<br />O’Hagan (1978); Sacks et al (Design and Analysis of<br />Computer Experiments, 1989)<br />Williams and Rasmussen (1996), inspired by Neal’s (1996)<br />construction of GPs from neural networks with an infinite<br />number of hidden units<br />Regularization framework (Tikhonov and Arsenin, 1977;<br />Poggio and Girosi, 1990); MAP rather than fully probabilistic<br />SVMs (Vapnik, 1995): non-probabilistic, use “kernel trick”<br />and quadratic programming<br />Chris WilliamsANC<br />Gaussian Processes for Machine Learning</p>  <p>Page 17</p> <p>Carl Edward Rasmussen and Chris<br />Williams, MIT Press, 2006<br />New: available online<br />Chris WilliamsANC<br />Gaussian Processes for Machine Learning</p>  <p>Page 18</p> <p>Regression, classification and beyond<br />Regression with Gausian noise: e.g. robot arm inverse<br />dynamics (21-d input space)<br />Classification: binary, multiclass, e.g. handwritten digit<br />classification<br />ML community tends to use approximations to deal with<br />non-Gaussian likelihoods, cf MCMC in statistics?<br />MAP solution, Laplace approximation<br />Expectation Propagation (Minka, 2001; see also Opper and<br />Winther, 2000)<br />Other likelihoods (e.g. Poisson), observations of derivatives,<br />uncertain inputs, mixtures of GPs<br />Chris WilliamsANC<br />Gaussian Processes for Machine Learning</p>  <p>Page 19</p> <p>Covariance functions<br />Covariance function is key entity, determining notion of<br />similarity<br />Squared exponential (“Gaussian”) covariance function is<br />widely applied in ML; Matern kernel not very widely used<br />Polynomial kernel k(x,x?) = (1 + x · x?)pis popular in kernel<br />machines literature<br />Neural network covariance function (Williams, 1998)<br />kNN(x,x?) = σ2<br />fsin−1?<br />2˜ x?M˜ x?<br />?(1 + 2˜ x?M˜ x)(1 + 2˜ x??M˜ x?)<br />?<br />where ˜ x = (1,x1,...,xD)?<br />Chris WilliamsANC<br />Gaussian Processes for Machine Learning</p>  <p>Page 20</p> <p>String kernels: let φs(x) denote the number of times a<br />substring s appears in string x<br />k(x,x?) =<br />?<br />s<br />wsφs(x)φs(x?)<br />(Watkins, 1999; Haussler, 1999).<br />Efficient methods using suffix trees to compute certain string<br />kernels in time |x|+|x?| (Leslie et al, 2003; Vishwanathan and<br />Smola, 2003)<br />Extended to tree kernels (Collins and Duffy, 2002)<br />Fisher kernel<br />φθ(x) = ∇θlogp(x|θ)<br />k(x,x?) = φθ(x)F−1φθ(x?)<br />where F is the Fisher information matrix (Jaakkola et al,<br />2000)<br />Chris WilliamsANC<br />Gaussian Processes for Machine Learning</p>  <p>Page 21</p> <p>Automatic Relevance Determination<br />kSE(x,x?) = σ2<br />fexp?−1<br />2(x − x?)?M(xp− xq)?<br />Isotropic M = ?−2I<br />ARD: M = diag(?−2<br />1,?−2<br />2,...,?−2<br />D)<br />−2<br />0<br />2<br />−2<br />0<br />2<br />−2<br />−1<br />0<br />1<br />2<br />input x1<br />input x2<br />output y<br />−2<br />0<br />2<br />−2<br />0<br />2<br />−2<br />−1<br />0<br />1<br />2<br />input x1<br />input x2<br />output y<br />Chris WilliamsANC<br />Gaussian Processes for Machine Learning</p>  <p>Page 22</p> <p>Dealing with hyperparameters<br />Criteria for model selection<br />Marginal likelihood p(y|X,θ)<br />Estimate the generalization error: LOO-CV<br />?n<br />Bound the generalization error (e.g. PAC-Bayes)<br />i=1logp(yi|y−i,X,θ)<br />Typically do ML-II rather than sampling of p(θ|X,y)<br />Optimize by gradient descent (etc) on objective function<br />SVMs do not generally have good methods for kernel selection<br />Chris Williams ANC<br />Gaussian Processes for Machine Learning</p>  <p>Page 23</p> <p>How the marginal likelihood works<br />10<br />0<br />−100<br />−80<br />−60<br />−40<br />−20<br />0<br />20<br />40<br />log probability<br />characteristic lengthscale<br />minus complexity penalty<br />data fit<br />marginal likelihood<br />logp(y|X,θ) = −1<br />2yTK−1<br />y y − log|Ky| −n<br />2log2π<br />Chris Williams ANC<br />Gaussian Processes for Machine Learning</p>  <p>Page 24</p> <p>Marginal Likelihood and Local Optima<br />−505<br />−2<br />−1<br />0<br />1<br />2<br />input, x<br />output, y<br />−505<br />−2<br />−1<br />0<br />1<br />2<br />input, x<br />output, y<br />There can be multiple optima of the marginal likelihood<br />These correspond to different interpretations of the data<br />Chris Williams ANC<br />Gaussian Processes for Machine Learning</p>  <p>Page 25</p> <p>The Baby and the Bathwater<br />MacKay (2003 ch 45): In moving from neural networks to<br />kernel machines did we throw out the baby with the<br />bathwater? i.e. the ability to learn hidden<br />features/representations<br />But consider M = ΛΛ?for Λ being D × k, for k &lt; D<br />The k columns of Λ can identify directions in the input space<br />with specially high relevance (Vivarelli and Williams, 1999)<br />Chris Williams ANC<br />Gaussian Processes for Machine Learning</p>  <p>Page 26</p> <p>Theory<br />Equivalent kernel (Silverman, 1984)<br />Consistency (Diaconis and Freedman, 1986; Choudhuri,<br />Ghoshal and Roy 2005; Choi and Schervish, 2004)<br />Average case learning curves<br />PAC-Bayesian analysis for GPs (Seeger, 2003)<br />pD{RL(fD) ≤ˆRL(fD) + gap(fD,D,δ)} ≥ 1 − δ<br />where RL(fD) is the expected risk, andˆRL(fD) is the empirical<br />(training) risk<br />Chris WilliamsANC<br />Gaussian Processes for Machine Learning</p>  <p>Page 27</p> <p>Approximation Methods for Large Datasets<br />Fast approximate solution of the linear system<br />Subset of Data<br />Subset of Regressors<br />Inducing Variables<br />Projected Process Approximation<br />FITC, PITC, BCM<br />SPGP<br />Empirical Comparison<br />Chris WilliamsANC<br />Gaussian Processes for Machine Learning</p>  <p>Page 28</p> <p>Some interesting recent uses for Gaussian Processes<br />Modelling transcriptional regulation using Gaussian Processes. Neil<br />D. Lawrence, Guido Sanguinetti, Magnus Rattray (NIPS 2006)<br />A Switched Gaussian Process for Estimating Disparity and<br />Segmentation in Binocular Stereo. Oliver Williams (NIPS 2006)<br />Learning to Control an Octopus Arm with Gaussian Process<br />Temporal Difference Methods. Yaakov Engel, Peter Szabo, Dmitry<br />Volkinshtein (NIPS 2005)<br />Worst-Case Bounds for Gaussian Process Models. Sham Kakade,<br />Matthias Seeger, Dean Foster (NIPS 2005)<br />Infinite Mixtures of Gaussian Process Experts. Carl Rasmussen,<br />Zoubin Ghahramani (NIPS 2002)<br />Chris Williams ANC<br />Gaussian Processes for Machine Learning</p>  <p>Page 29</p> <p>3. Multi-task Learning<br />There are multiple (possibly) related tasks, and we wish to<br />avoid tabula rasa learning by sharing information across tasks<br />E.g. Task clustering, inter-task correlations<br />Two cases:<br />With task-descriptor features t<br />Without task-descriptor features, based solely on task identities<br />Joint work with Edwin Bonilla &amp; Felix Agakov (AISTATS<br />2007) and Kian Ming Chai<br />Chris Williams ANC<br />Gaussian Processes for Machine Learning</p>  <p>Page 30</p> <p>Multi-task Learning using Task-specific Features<br />M tasks, learn mapping gi(x), i = 1,...,M<br />tiis task descriptor (task-specific feature vector) for task i<br />gi(x) = g(ti,x): potential for transfer across tasks<br />Out motivation is for compiler performance prediction, where<br />there are multiple benchmark programs (=tasks), and x<br />describes sequences of code transformations<br />Another example: predicting school pupil performance based<br />on pupil and school features<br />We particularly care about the case when we have very little<br />data from the test task; here inter-task transfer will be most<br />important<br />Chris Williams ANC<br />Gaussian Processes for Machine Learning</p>  <p>Page 31</p> <p>Overview<br />Model setup<br />Related work<br />Experimental setup, feature representation<br />Results<br />Discussion<br />Chris Williams ANC<br />Gaussian Processes for Machine Learning</p>  <p>Page 32</p> <p>Task-descriptor Model<br />z =<br />?<br />x<br />t<br />?<br />k(z,z?) = kx(x,x?)kt(t,t?)<br />Decomposition into task similarity (kt) and input similarity<br />(kx)<br />For the widely-used “Gaussian” kernel, this occurs naturally<br />Independent tasks if kt(ti,tj) = δij<br />C.f. co-kriging in geostatistics (e.g. Wackernagel, 1998)<br />Without task-descriptors, simply parameterize Kt<br />Chris WilliamsANC<br />Gaussian Processes for Machine Learning</p>  <p>Page 33</p> <p>x<br />f<br />Chris WilliamsANC<br />Gaussian Processes for Machine Learning</p>  <p>Page 34</p> <p>Related Work<br />Work using task-specific features<br />Bakker and Heskes (2003) use neural networks. These can be<br />tricky to train (local optima, number of hidden units etc)<br />Yu et al (NIPS 2006, Stochastic Relational Models for<br />Discriminative Link Prediction)<br />Chris WilliamsANC<br />Gaussian Processes for Machine Learning</p>  <p>Page 35</p> <p>General work on Multi-task Learning<br />What should be transferred?<br />Early work: Thrun (1996), Caruana (1997)<br />Minka and Picard (1999); multiple tasks share same GP<br />hyperparameters (but are uncorrelated)<br />Evgeniou et al (2005): induce correlations between tasks<br />based on a correlated prior over linear regression parameters<br />(special case of co-kriging)<br />Multilevel (or hierarchical) modelling in statistics (e.g.<br />Goldstein, 2003)<br />Chris WilliamsANC<br />Gaussian Processes for Machine Learning</p>  <p>Page 36</p> <p>Compiler Performance Prediction<br />Goal: Predict speedup of a new program under a given<br />sequence of compiler transformations<br />Only have a limited number of runs of the new program, but<br />also have data from other (related?) tasks<br />Speedup s measured as<br />s(x) =time(baseline)<br />time(x)<br />Chris WilliamsANC<br />Gaussian Processes for Machine Learning</p>  <p>Page 37</p> <p>Example Transformation<br />Loop unrolling<br />// original loop<br />for(i=0; i&lt;100; i++)<br />a[i] = b[i] + c[i];<br />// loop unrolled twice<br />for(i=0; i&lt;100; i+=2){<br />a[i]= b[i] + c[i];<br />a[i+1] = b[i+1] +<br />c[i+1];<br />}<br />Chris WilliamsANC<br />Gaussian Processes for Machine Learning</p>  <p>Page 38</p> <p>Experimental Setup<br />Benchmarks: 11 C programs from UTDSP<br />Transformations: Source-to-source using SUIF<br />Platform: TI C6713 board<br />13 transformations in sequences up to length 5, using each<br />transformation at most once ⇒ 88214 sequences per<br />benchmark (exhaustively enumerated)<br />Significant speedups can be obtained (max is 1.84)<br />Chris WilliamsANC<br />Gaussian Processes for Machine Learning</p>  <p>Page 39</p> <p>Input Features x<br />Code features (C), or transformation-based representation (T)<br />Code features: extract features from transformed program<br />based on knowledge of compiler experts (code size,<br />instructions executed, parallelism)<br />83 features reduced to 15-d with PCA<br />Transformation-based representation: length-13 bit vector<br />stating what transformations were used (“bag of characters”)<br />Chris WilliamsANC<br />Gaussian Processes for Machine Learning</p>  <p>Page 40</p> <p>Task-specific features t<br />Record the speedup on a small number of canonical<br />sequences: response-based approach<br />Canonical sequences selected by principal variables method<br />(McCabe, 1984)<br />A variety of possible criteria can be used, e.g. maximize<br />|ΣS(1)|, minimize tr(ΣS(2)|S(1)). Use greedy selection<br />We don’t use all 88214 sequences to define the canonical<br />sequences, only only 2048. In our experiments we use 8<br />canonical variables<br />Could consider e.g. code features from untransformed<br />programs, but experimentally response-based method is<br />superior<br />Chris WilliamsANC<br />Gaussian Processes for Machine Learning</p>  <p>Page 41</p> <p>Experiments<br />LOO-CV setup (leave out one task at a time)<br />Therefore 10 reference tasks for each prediction task; we used<br />nr= 256 examples per benchmark<br />Use nteexamples from the test task (nte≥ 8)<br />Assess performance using mean absolute error (MAE) on all<br />remaining test sequences<br />Comparison to baseline “no transfer” method using just data<br />from test task<br />Used GP regression prediction with squared exponential kernel<br />ARD was used, except for “no transfer” case when nte≤ 64<br />Chris Williams ANC<br />Gaussian Processes for Machine Learning</p>  <p>Page 42</p> <p>ADPCOMEDGFFT FIRHISIIRLATLMS LPCSPEAVG<br />0<br />0.05<br />0.1<br />0.15<br />0.2<br />0.25<br />0.3<br />0.35<br />MAE<br /> <br /> <br />[T] COMBINED<br />[T] GATING<br />[C] COMBINED<br />[C] GATING<br />MEDIAN CANONICALS<br />MEDIAN TEST<br />0.540<br />(0.007)<br />Chris WilliamsANC<br />Gaussian Processes for Machine Learning</p>  <p>Page 43</p> <p>Results<br />T-combined is best overall (av MAE is 0.0576, compared to<br />0.1162 for median canonicals)<br />T-combined generally either improves performance or leaves it<br />about the same compared to T-no-transfer-canonicals<br />Chris WilliamsANC<br />Gaussian Processes for Machine Learning</p>  <p>Page 44</p> <p>8163264128<br />0<br />0.05<br />0.1<br />0.15<br />0.2<br />0.25<br />0.3<br />0.35<br />0.4<br />HISTOGRAM<br />TEST SAMPLES INCLUDED FOR TRAINING<br />MAE<br /> <br /> <br />[T] COMBINED<br />[T] NO TRANSFER RANDOM<br />[T] NO TRANSFER CANONICALS<br />MEDIAN CANONICALS<br />8163264128<br />0<br />0.02<br />0.04<br />0.06<br />0.08<br />0.1<br />0.12<br />0.14<br />EDGE_DETECT<br />TEST SAMPLES INCLUDED FOR TRAINING<br />MAE<br /> <br /> <br />[T] COMBINED<br />[T] NO TRANSFER RANDOM<br />[T] NO TRANSFER CANONICALS<br />MEDIAN CANONICALS<br />Chris WilliamsANC<br />Gaussian Processes for Machine Learning</p>  <p>Page 45</p> <p>8163264128<br />0<br />0.02<br />0.04<br />0.06<br />0.08<br />0.1<br />0.12<br />0.14<br />0.16<br />ADPCM<br />TEST SAMPLES INCLUDED FOR TRAINING<br />MAE<br /> <br /> <br />[T] COMBINED<br />[T] NO TRANSFER RANDOM<br />[T] NO TRANSFER CANONICALS<br />MEDIAN CANONICALS<br />8163264 128<br />0<br />0.02<br />0.04<br />0.06<br />0.08<br />0.1<br />0.12<br />0.14<br />0.16<br />0.18<br />TEST SAMPLES INCLUDED FOR TRAINING<br />MAE<br />ALL BENCHMARKS<br /> <br /> <br />[T] COMBINED<br />[T] NO TRANSFER RANDOM<br />[T] NO TRANSFER CANONICALS<br />MEDIAN CANONICALS<br />T-combined generally improves performance or leaves it about<br />the same compared to the best “no transfer” scenario<br />Chris WilliamsANC<br />Gaussian Processes for Machine Learning</p>  <p>Page 46</p> <p>Understanding Task Relatedness<br />GP predictive mean is<br />s(z∗) = kT(z∗)(Kf⊗ Kx+ σ2I)−1s<br />Can look at Kf, but difficult to interpret?<br />Predictive mean s(z∗) = hT(z∗)s, where<br />hT(z) = (h1<br />1,...,h1<br />nr,...,hM<br />1,...,hM<br />nr,hM+1<br />1<br />,...,hM+1<br />nte<br />,)<br />Measure contribution of task i on test point z∗by computing<br />ri(z∗) =|hi(z∗)|<br />|h(z∗)|<br />Chris WilliamsANC<br />Gaussian Processes for Machine Learning</p>  <p>Page 47</p> <p>Average r’s over test examples<br />adpcom edg fftfir hisiirlat lms lpcspe<br />spe<br />lpc<br />lms<br />lat<br />iir<br />his<br />fir<br />fft<br />edg<br />com<br />adp<br />Chris WilliamsANC<br />Gaussian Processes for Machine Learning</p>  <p>Page 48</p> <p>Discussion<br />Our focus is on the hard problem of prediction on a new task<br />given very little data for that task<br />The presented method allows sharing over tasks. This should<br />be beneficial, but note that “no transfer” method has the<br />freedom to use different hyperparams on each task<br />Can learn similarity between tasks directly (unparameterized<br />Kt), but this is not so easy if nteis very small<br />Note that there is no inter-task transfer in noiseless case!<br />(autokrigeability)<br />Chris WilliamsANC<br />Gaussian Processes for Machine Learning</p>  <p>Page 49</p> <p>General Conclusions<br />Key issues:<br />Designing/discovering covariance functions suitable for various<br />types of data<br />Methods for setting/inference of hyperparameters<br />Dealing with large datasets<br />Chris WilliamsANC<br />Gaussian Processes for Machine Learning</p>  <p>Page 50</p> <p>Gaussian Process Regression<br />Dataset D = (xi,yi)n<br />i=1, Gaussian likelihood p(yi|fi) ∼ N(0,σ2)<br />n<br />?<br />¯f (x) =<br />i=1<br />αik(x,xi)<br />where<br />α = (K + σ2I)−1y<br />var(x) = k(x,x) − kT(x)(K + σ2I)−1k(x)<br />in time O(n3), with k(x) = (k(x,x1),...,k(x,xn))T<br />Chris WilliamsANC<br />Gaussian Processes for Machine Learning</p>   </div> <div id="rgw18_56ab1cd3a62b5" class="c-box pub-resource-container js-toggle" style=""> <h4 class="lf js-expand-list"><small><a href="javascript:" class="lf">View other sources <span class="ico-expand-list"></span></a></small></h4> <h4 class="lf js-collapse-list hidden"><small><a href="javascript:" class="lf">Hide other sources <span class="ico-collapse-list"></span></a></small></h4> <div class="clear"></div> <div class="scroll-wrapper hidden"> <ul class="files-list c-list" id="rgw19_56ab1cd3a62b5">  <li class="c-list-item pub-resource-item"  data-type="fulltext" id="rgw20_56ab1cd3a62b5"> <span class="ico-pub"></span> <div class="file-content"> <div class="download"> <a href="http://www.newton.ac.uk/programmes/BNR/seminars/080914001.pdf" target="_blank" rel="nofollow" class="publication-viewer" title="Gaussian Process for Machine Learning">Gaussian Process for Machine Learning</a> </div>  <div class="details">   Available from <a href="http://www.newton.ac.uk/programmes/BNR/seminars/080914001.pdf" target="_blank" rel="nofollow">newton.ac.uk</a>  </div>    </div> </li>  </ul> </div> </div> </noscript> <div class="clearfix"> <div class="action-container">  </div> <div class="pub-legal"> Data provided are for informational purposes only. Although carefully collected, accuracy cannot be guaranteed. The impact factor represents a rough estimation of the journal's impact factor and does not reflect the actual current impact factor. Publisher conditions are provided by RoMEO. Differing provisions from the publisher's actual policy or licence agreement may be applicable. </div>  <div id="rgw27_56ab1cd3a62b5" class="citations-container"> <div class="tab-container"> <ul class="tab-list"> <li class="lf tab-item  js-citations"> <a href="javascript:void(0);" class="tab-link"> References  </small> </a> </li>  <li class="lf tab-item tab-item-active js-cited-in js-cited-in-tooltip"> <a href="javascript:void(0);" class="tab-link"> Cited In <small> (1899) </small> </a> </li>    <li class="rf"> <div class="dropdown js-citations-sorter dropdown-right-align" style="position: relative; bottom: -1px;display:none;"> <a href="javascript:void(0);" class="dropdown-toggle"> Sorted by: <strong class="js-current-sorting"> Order of availability  </strong> <span class="caret"></span> </a> <ul class="dropdown-menu"> <li><a href="javascript:void(0);" data-sort="normal">Order of availability</a></li> <li><a href="javascript:void(0);" data-sort="original">Appearance in publication</a></li> </ul> </div> </li>  </ul> <div class="tab-section tab-section-active js-citations-list-container"> <div id="rgw28_56ab1cd3a62b5" class="pub-citations-list">  <ul class="c-list">  <li class="c-list-item li-publication   includes-citation-list"  id="rgw29_56ab1cd3a62b5" >  <div class="indent-left">  <div id="rgw30_56ab1cd3a62b5" class="js-publication-item-fulltext fulltext-thumb">    <a class="publication-preview ga-publication-viewer js-publication-item-fulltext-content" href="publication/273436999_Nonparametric_statistical_learning_control_of_robot_manipulators_for_trajectory_or_contour_tracking">       </a>   <div class="preview-source-info"> <a class="details js-show-source ga-source-url" href="profile/Cong_Wang19" >Source</a>  <div class="tooltip-content" style="display: none"> Available from: Cong Wang </div> </div>   </div>  </div>  <div class="indent-right">      </div>  <ul class="citation-contexts" id="rgw31_56ab1cd3a62b5">  <li class="citation-context-item"> "Note that the concepts of input and output used here should not be confused with those of general dynamic systems . Rather than assuming a parameterized structure for f, GPR assumes f to be random, and can be characterized using a mean function and a covariance function (also called a kernel) [12] " </li>  </ul>   <div  style="margin-top: -2px">  <h5 class="pub-type-and-title">  <span class="publication-type">Article:</span>    <a class="js-publication-title-link js-go-to-publication ga-publication-item" href="publication/273436999_Nonparametric_statistical_learning_control_of_robot_manipulators_for_trajectory_or_contour_tracking"> <span class="publication-title js-publication-title">Nonparametric statistical learning control of robot manipulators for trajectory or contour tracking</span> </a>     </h5>  </div>    <div class="authors">     <a href="researcher/2046328734_Cong_Wang" class="authors js-author-name ga-publications-authors">Cong Wang</a> &middot;     <a href="researcher/2046554452_Yu_Zhao" class="authors js-author-name ga-publications-authors">Yu Zhao</a> &middot;     <a href="researcher/2068973423_Yubei_Chen" class="authors js-author-name ga-publications-authors">Yubei Chen</a> &middot;     <a href="researcher/55939832_Masayoshi_Tomizuka" class="authors js-author-name ga-publications-authors">Masayoshi Tomizuka</a>      </div>        <div class="abstract"> <span class="shorten"> <a href="javascript:" class="js-toggle-abstract">[Show abstract]</a> </span> <span class="full"> <a href="javascript:" class="js-toggle-abstract">[Hide abstract]</a><br/>  <strong>ABSTRACT:</strong> This paper presents a method of precision tracking control for industrial robot manipulators. For robotic laser and plasma cutting tasks, the required tracking performance is much more demanding than that for material handling, spot welding, and machine tending tasks. Challenges in control come from the nonlinear coupled multi-body dynamics of robot manipulators, as well as the transmission error in the geared joints. The proposed method features data-driven iterative compensation of torque and motor reference. Motor side tracking and transmission error are handled by separate learning modules in a two-part compensation structure. Depending on the specific setup of end-effector sensing, the method can utilize either timed trajectory measurement or untimed two-dimensional contour inspection. Nonparametric statistical learning is used for the compensation. Considerations on incorporating analytical models and selecting data subsets for more efficient learning are discussed. The method is validated using a six-axis industrial robot. </span> </div>    <div class="publication-meta publication-meta">   <span class="ico-publication-fulltext reset-background"></span> Full-text   &middot; Article &middot; Oct 2015  &middot; Robotics and Computer-Integrated Manufacturing  </div>        <div class="publication-actions"> <div class="btn-group">  <a class="btn btn-plain action-download primary  open-viewer" href="profile/Cong_Wang19/publication/273436999_Nonparametric_statistical_learning_control_of_robot_manipulators_for_trajectory_or_contour_tracking/links/550f25d30cf21287416b02f3.pdf?origin=publication_list">  <span class="js-btn-label">Download</span> </a>    </div> </div>      </li>  <li class="c-list-item li-publication   includes-citation-list"  id="rgw32_56ab1cd3a62b5" >  <div class="indent-left">  <div id="rgw33_56ab1cd3a62b5" class="js-publication-item-fulltext fulltext-thumb">    <a class="publication-preview ga-publication-viewer js-publication-item-fulltext-content" href="publication/276365045_Bayesian_improved_model_migration_methodology_for_fast_process_modeling_by_incorporating_prior_information">       </a>   <div class="preview-source-info"> <a class="details js-show-source ga-source-url" href="profile/Yuan_Yao10" >Source</a>  <div class="tooltip-content" style="display: none"> Available from: Yuan Yao </div> </div>   </div>  </div>  <div class="indent-right">      </div>  <ul class="citation-contexts" id="rgw34_56ab1cd3a62b5">  <li class="citation-context-item"> "It is worth noting that the mean function and covariance function are not limited to what we use here. In fact, one can specify a fixed mean function (Sacks et al., 1989), and/or choose from a class of various covariance functions (Rasmussen, 2006, Chap. 4) for a problem of interest. " </li>  </ul>   <div  style="margin-top: -2px">  <h5 class="pub-type-and-title">  <span class="publication-type">Article:</span>    <a class="js-publication-title-link js-go-to-publication ga-publication-item" href="publication/276365045_Bayesian_improved_model_migration_methodology_for_fast_process_modeling_by_incorporating_prior_information"> <span class="publication-title js-publication-title">Bayesian improved model migration methodology for fast process modeling by incorporating prior information</span> </a>     </h5>  </div>    <div class="authors">     <a href="researcher/2067007832_Linkai_Luo" class="authors js-author-name ga-publications-authors">Linkai Luo</a> &middot;     <a href="researcher/70185089_Yuan_Yao" class="authors js-author-name ga-publications-authors">Yuan Yao</a> &middot;     <a href="researcher/7473905_Furong_Gao" class="authors js-author-name ga-publications-authors">Furong Gao</a>      </div>        <div class="abstract"> <span class="shorten"> <a href="javascript:" class="js-toggle-abstract">[Show abstract]</a> </span> <span class="full"> <a href="javascript:" class="js-toggle-abstract">[Hide abstract]</a><br/>  <strong>ABSTRACT:</strong> We consider a Bayesian inference approach to enhance model migration, building on concepts laid out in an earlier paper (Lu and Gao, 2008a). Previous studies have been limited to a least-squares solution and have failed to take prior knowledge into consideration, possibly tending to cause overfitting and inaccurate estimations. We present a framework for Bayesian migration that can naturally incorporate and use prior information. The approach involves imposing normal-inverse-gamma priors over the migration parameter and exploring the resulting posterior distributions using a Markov chain Monte Carlo method. In addition, we provide a batch sequential design framework for iterative implementation of model migration, which thus avoids an exhaustive treatment of a predetermined number of design points. The effectiveness of these proposed methods is demonstrated using two examples: a numerical study and an injection molding process. </span> </div>    <div class="publication-meta publication-meta">   <span class="ico-publication-fulltext reset-background"></span> Full-text   &middot; Article &middot; Sep 2015  &middot; Chemical Engineering Science  </div>        <div class="publication-actions"> <div class="btn-group">  <a class="btn btn-plain action-download primary  open-viewer" href="profile/Yuan_Yao10/publication/276365045_Bayesian_improved_model_migration_methodology_for_fast_process_modeling_by_incorporating_prior_information/links/555c295d08ae6aea081732c4.pdf?origin=publication_list">  <span class="js-btn-label">Download</span> </a>    </div> </div>      </li>  <li class="c-list-item li-publication   includes-citation-list"  id="rgw35_56ab1cd3a62b5" >  <div class="indent-left">  <div id="rgw36_56ab1cd3a62b5" class="js-publication-item-fulltext fulltext-thumb">    <a class="publication-preview ga-publication-viewer js-publication-item-fulltext-content" href="publication/280538283_Efficient_Calibration_for_Imperfect_Computer_Models">       </a>   <div class="preview-source-info"> <a class="details js-show-source ga-source-url" href="deref/http%3A%2F%2Fde.arxiv.org%2Fpdf%2F1507.07280" target="_blank" >Source</a>  <div class="tooltip-content" style="display: none"> Available from: de.arxiv.org </div> </div>   </div>  </div>  <div class="indent-right">      </div>  <ul class="citation-contexts" id="rgw37_56ab1cd3a62b5">  <li class="citation-context-item"> "We conducted 1000 random simulations to examine the performance of the L 2 calibration, the OLS calibration, and the KO calibration for σ 2 = 0.1 and σ 2 = 1 respectively. For the L 2 calibration and the KO calibration , the Gaussian correlation family Φ(x 1 , x 2 ) = exp{−φ(x 1 − x 2 ) 2 } is used with the model parameter φ chosen by the cross-validation method (Santner, Williams and Notz, 2003; Rasmussen and Williams, 2006). The tuning parameters in the nonparametric regression is selected by the generalized cross validation (Wahba, 1990). " </li>  </ul>   <div  style="margin-top: -2px">  <h5 class="pub-type-and-title">  <span class="publication-type">Article:</span>    <a class="js-publication-title-link js-go-to-publication ga-publication-item" href="publication/280538283_Efficient_Calibration_for_Imperfect_Computer_Models"> <span class="publication-title js-publication-title">Efficient Calibration for Imperfect Computer Models</span> </a>     </h5>  </div>    <div class="authors">     <a href="researcher/2055731435_Rui_Tuo" class="authors js-author-name ga-publications-authors">Rui Tuo</a> &middot;     <a href="researcher/15762776_C_F_Jeff_Wu" class="authors js-author-name ga-publications-authors">C. F. Jeff Wu</a>      </div>        <div class="abstract"> <span class="shorten"> <a href="javascript:" class="js-toggle-abstract">[Show abstract]</a> </span> <span class="full"> <a href="javascript:" class="js-toggle-abstract">[Hide abstract]</a><br/>  <strong>ABSTRACT:</strong> Many computer models contain unknown parameters which need to be estimated
using physical observations. Kennedy and O&#39;Hagan (2001) shows that the
calibration method based on Gaussian process models proposed by Kennedy and
O&#39;Hagan (2001) may lead to unreasonable estimate for imperfect computer models.
In this work, we extend their study to calibration problems with stochastic
physical data. We propose a novel method, called the $L_2$ calibration, and
show its semiparametric efficiency. The conventional method of the ordinary
least squares is also studied. Theoretical analysis shows that it is consistent
but not efficient. Numerical examples show that the proposed method outperforms
the existing ones. </span> </div>    <div class="publication-meta publication-meta">  <span class="ico-publication-preview reset-background"></span> Preview    &middot; Article &middot; Jul 2015  &middot; The Annals of Statistics  </div>        <div class="publication-actions"> <div class="btn-group">  <a class="btn btn-plain action-request-external  " href="javascript:;" data-context="pubCit">  <span class="js-btn-label">Request full-text</span> </a>    </div> </div>      </li>  </ul>    <a class="show-more-rebranded js-show-more rf text-gray-lighter">Show more</a> <span class="ajax-loading-small list-loading" style="display: none"></span>  <div class="clearfix"></div>  <div class="publication-detail-sidebar-legal">Note: This list is based on the publications in our database and might not be exhaustive.</div> <div class="clearfix"></div>  </div> </div> </div> </div> </div> </div> <div class="clearfix">     <div id="rgw22_56ab1cd3a62b5" class="c-box pub-resource-container js-toggle" style="display: none;"> <h4 class="lf js-expand-list"><small><a href="javascript:" class="lf">View other sources <span class="ico-expand-list"></span></a></small></h4> <h4 class="lf js-collapse-list hidden"><small><a href="javascript:" class="lf">Hide other sources <span class="ico-collapse-list"></span></a></small></h4> <div class="clear"></div> <div class="scroll-wrapper hidden"> <ul class="files-list c-list" id="rgw23_56ab1cd3a62b5">  </ul> </div> </div>   <div id="rgw14_56ab1cd3a62b5" class="similar-publications"> <h2>Similar Publications</h2> <ul class="list-bordered">  <li class="c-list-item li-publication-teaser" id="rgw15_56ab1cd3a62b5"> <div> <h5> <a href="publication/285362627_Material_synthesis_and_design_from_first_principle_calculations_and_machine_learning" class="color-inherit ga-similar-publication-title"><span class="publication-title">Material synthesis and design from first principle calculations and machine learning</span></a>  </h5>  <div class="authors"> <a href="researcher/2007778901_Keisuke_Takahashi" class="authors ga-similar-publication-author">Keisuke Takahashi</a>, <a href="researcher/2086689882_Yuzuru_Tanaka" class="authors ga-similar-publication-author">Yuzuru Tanaka</a>  </div>  </div> <div class="clear"></div> </li>  <li class="c-list-item li-publication-teaser" id="rgw16_56ab1cd3a62b5"> <div> <h5> <a href="publication/291373841_Comparative_Study_on_Theoretical_and_Machine_Learning_Methods_for_Acquiring_Compressed_Liquid_Densities_of_1112333-Heptafluoropropane_R227ea_via_Song_and_Mason_Equation_Support_Vector_Machine_and_Arti" class="color-inherit ga-similar-publication-title"><span class="publication-title">Comparative Study on Theoretical and Machine Learning Methods for Acquiring Compressed Liquid Densities of 1,1,1,2,3,3,3-Heptafluoropropane (R227ea) via Song and Mason Equation, Support Vector Machine, and Artificial Neural Networks</span></a>  </h5>  <div class="authors"> <a href="researcher/2049166781_Hao_Li" class="authors ga-similar-publication-author">Hao Li</a>, <a href="researcher/2095212588_Xindong_Tang" class="authors ga-similar-publication-author">Xindong Tang</a>, <a href="researcher/2095285995_Run_Wang" class="authors ga-similar-publication-author">Run Wang</a>, <a href="researcher/2090556423_Fan_Lin" class="authors ga-similar-publication-author">Fan Lin</a>, <a href="researcher/82301887_Zhijian_Liu" class="authors ga-similar-publication-author">Zhijian Liu</a>, <a href="researcher/2083068498_Kewei_Cheng" class="authors ga-similar-publication-author">Kewei Cheng</a>  </div>  </div> <div class="clear"></div> </li>  <li class="c-list-item li-publication-teaser" id="rgw17_56ab1cd3a62b5"> <div> <h5> <a href="publication/289122212_Early_warning_in_egg_production_curves_from_commercial_hens_A_SVM_approach" class="color-inherit ga-similar-publication-title"><span class="publication-title">Early warning in egg production curves from commercial hens: A SVM approach</span></a>  </h5>  <div class="authors"> <a href="researcher/2092024463_Ivan_Ramirez_Morales" class="authors ga-similar-publication-author">Iván Ramírez Morales</a>, <a href="researcher/2091984080_Daniel_Rivero_Cebrian" class="authors ga-similar-publication-author">Daniel Rivero Cebrián</a>, <a href="researcher/2078074129_Enrique_Fernandez_Blanco" class="authors ga-similar-publication-author">Enrique Fernández Blanco</a>, <a href="researcher/2095412982_Alejandro_Pazos_Sierra" class="authors ga-similar-publication-author">Alejandro Pazos Sierra</a>  </div>  </div> <div class="clear"></div> </li>  </ul> </div> </div> </div> </div> </div></div></div>
<div class="clear"></div><div id="rgw39_56ab1cd3a62b5" class="default-footer"> <div id="footer" class="clearfix"> <span class="footer-left"> &copy; 2008&dash;2016 researchgate.net. All rights reserved. </span> <span class="footer-right"> <a href="https://www.researchgate.net/about">About us</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="https://www.researchgate.net/contact">Contact us</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="careers">Careers</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="developers">Developers</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="blog" target="_blank">News</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="application.PrivacyPolicy.html">Privacy</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="application.TermsAndConditions.html">Terms</a> <span class="footer-link-separator" style="padding: 0 5px;">&nbsp;|&nbsp;</span> <a href="advertising?_ref=ft">Advertising</a> <span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="recruiters?_ref=ft">Recruiting</a> </span> </div>  </div></div>
<div id="rgw40_56ab1cd3a62b5">  <div class="header-wrapper-logged-out"> <div id="header"> <div class="header-content"> <a href="" class="g-l-logo"> <svg width="149" height="19"> <image xlink:href="https://c5.rgstatic.net/m/235107188705592/images/template/brand-header-logo.svg" src="https://c5.rgstatic.net/m/238113351022438/images/template/brand-header-logo.png" width="149" height="19"/> </svg> </a> <a href="" class="g-l-logo-ico"> <svg width="127" height="17" viewbox="0 0 127 22"> <image xlink:href="https://c5.rgstatic.net/m/235107188705592/images/template/brand-header-logo.svg" src="https://c5.rgstatic.net/m/238113351022438/images/template/brand-header-logo.png" width="127" height="17"/> </svg> </a> <div id="rgw41_56ab1cd3a62b5" class="header-login-wrapper js-header-login"> <div class="dropdown-right-align"> <div class="login-signup-container lf"> <a href="https://www.researchgate.net/signup.SignUp.html?ev=su_chnl_index&amp;hdrsu=1&amp;_sg=xEHTchJ4NMQE23b9UJxyJ9ANtg5mAW0FnDyqtII8xi-o64RPb5QdvdtcnEaQlljR" class="dropdown-toggle lf">Join for free</a> </div> <div class="dropdown lf" style="height: 20px;"> <a href="https://www.researchgate.net/application.Login.html" class="js-login-url dropdown-toggle lf">Log in <span class="caret"></span></a> <div class="dropdown-menu"> <div class="header-login-form-wrapper"> <!--[if IE 6]><p class="box-warning" style="margin-bottom: 0;">Sorry, ResearchGate no longer supports the version of Internet Explorer you are using. <a href="http://whatbrowser.org/" rel="nofollow" target="_blank">Update your web browser</a> and then log in. </p><![endif]--> <form method="post" action="https://www.researchgate.net/application.Login.html" class="form-big header-login-form js-login-form" name="loginForm" id="headerLoginForm"> <input type="hidden" name="request_token" value="bOPJvdid0ZOPk+JYkyG0Ui9bPUxzWE4GitmLKTCNXK00tfZHG2U8fSoPVGc2nXexJv/BK0JG/U2vOXZ7mdPyTbnKOXBMYEq0rWOsZqrxQeMWXAQMuPjtd4SugBHbUPX4HCPHzGGAohXSSL8jx5sRelwgaXwxzIHrg+6n/pUx+TINlKOGtEkl0ozMw732Ao7VYGUrd/881EVVfoZ+olL0oknolCO5daqODavqjyBUcZc+40YkyHaQpqmxYWqWSon7l0JpjwgzTs2wKmIppPZk4Qh46mye7iNrfBTOGAmKuwY="/> <input type="hidden" name="urlAfterLogin" value="publication/41781559_Gaussian_Process_for_Machine_Learning"/> <input type="hidden" name="invalidPasswordCount" value="0"/> <input type="hidden" name="headerLogin" value="yes"/> <label for="input-header-login">Email</label> <div class="login-input"> <div class="info-tip-wrapper"> <span class="ico-info js-info"></span> </div> <input type="email" value="" name="login" class="login js-login-input text" id="input-header-login" tabindex="1"/> </div> <div class="clear"></div> <label class="lf" for="input-header-password"> Password </label> <a class="rf forgot-password js-forgot-password" href="application.LostPassword.html">Forgot password?</a> <div class="clear"></div> <input type="password" value="" name="password" class="password js-password-input text" id="input-header-password" tabindex="2"/> <div class="clear"></div> <label class="remember-me" for="headerLoginCookie"> <input type="checkbox" checked="checked" value="yes" name="setLoginCookie" class="lf checkbox" id="headerLoginCookie" tabindex="3"/> Keep me logged in </label> <div class="clear"></div> <input value="Log in" name="loginSubmit" class="btn btn-promote btn-fullwidth btn-large allow-leave js-submit-button" type="submit" tabindex="4"/> </form> <div class="connectors"> <div class="text">or log in with</div> <div class="connector-actions"> <a href="connector/linkedin/" class="li-connect js-li-connect" data-redirect-url="cHVibGljYXRpb24vNDE3ODE1NTlfR2F1c3NpYW5fUHJvY2Vzc19mb3JfTWFjaGluZV9MZWFybmluZw%3D%3D"> <span class="icon ico-linkedin-round-grey"></span> <span class="icon ico-linkedin-round"></span> </a> <a href="connector/facebook/" class="fb-connect middle js-fb-connect" data-redirect-url="cHVibGljYXRpb24vNDE3ODE1NTlfR2F1c3NpYW5fUHJvY2Vzc19mb3JfTWFjaGluZV9MZWFybmluZw%3D%3D"> <span class="icon ico-facebook-round-grey"></span> <span class="icon ico-facebook-round"></span> </a> <a href="connector/google/" class="g-connect js-g-connect" data-redirect-url="cHVibGljYXRpb24vNDE3ODE1NTlfR2F1c3NpYW5fUHJvY2Vzc19mb3JfTWFjaGluZV9MZWFybmluZw%3D%3D"> <span class="icon ico-google-round-grey"></span> <span class="icon ico-google-round"></span> </a> </div> </div> </div> </div> </div> </div> </div> </div> </div> <script type="application/ld+json">
{ "@context" : "http://schema.org",
  "@type" : "Organization",
  "name" : "ResearchGate",
  "url" : "http://www.researchgate.net",
  "logo" : "http://www.researchgate.net/images/template/rg_logo_square_brand.png",
  "sameAs" : [ "https://www.facebook.com/ResearchGate",
    "https://twitter.com/ResearchGate",
    "https://plus.google.com/+researchgate",
    "https://www.linkedin.com/company/researchgate"] 
}
</script> </div> </div><div class="c-signup-bar" id="rgw42_56ab1cd3a62b5"> <div class="banner-contents">   <span class="message">ResearchGate is the professional network for scientists and researchers.</span> <a href="signup.SignUp.html?ev=su_banner" class="btn btn-large btn-promote">Join for free</a>  </div> </div></div>
<script>
rgConfig.backendTime = 627;
</script>
<script src="//c5.rgstatic.net/m/2277196935388619/javascript/lib/yui3/yui/yui-min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/2448732603281275/javascript/yuiLoaderConfig-min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/23178613132105398/javascript/vendor/babel-core/browser-polyfill.min.js" type="text/javascript"></script>
<script>
(function (){
if (typeof YRG === "undefined") {
var xmlHttpRequest = new XMLHttpRequest();
xmlHttpRequest.open("post", "go.Error.html");
xmlHttpRequest.setRequestHeader("Content-Type", "application/json");
xmlHttpRequest.setRequestHeader("Accept", "application/json"); var loadedScripts = "";
if (window.performance && window.performance.getEntriesByType) {
    var result = [];
    var resources = performance.getEntriesByType("resource");
    for (var i in resources) {
        if (resources.hasOwnProperty(i)) {
            result.push({
                name: resources[i].name,
                duration: resources[i].duration
            });
        }
    }
    loadedScripts += "&loadedScripts=" + encodeURIComponent(JSON.stringify(result));
}
if (typeof YUI === "undefined") {
    loadedScripts += "&yuiLoaded=false";
} else {
    loadedScripts += "&yuiLoaded=true";
}
xmlHttpRequest.send("Type=InformationException&message=" + encodeURIComponent("Error loading YUI") + loadedScripts);
}
})();
</script>
<script>if (typeof YRG !== 'undefined') { YRG.use('rg-base',function(Y){Y.applyConfig({ignore: ["css-rg","css-rg2","css-ie","css-modules-publicprofile"]});Y.use(["rg.core.pagespeed.Monitoring"],function(Y){(function(){Y.rg.createInitialWidget({"data":{"content":{"data":{"profileSmallHeader":{"data":{"profileBadge":{"data":{"profileUrl":"researcher\/2083187442_C_E_Rasmussen","fullname":"C. E. Rasmussen","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2549355721578\/images\/template\/default\/profile\/profile_default_m.png","profileStats":[null,{"data":{"publicationCount":1,"widgetId":"rgw5_56ab1cd3a62b5"},"id":"rgw5_56ab1cd3a62b5","partials":[],"templateName":"publicliterature\/stubs\/PublicLiteratureAuthorPublicationCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicLiteratureAuthorPublicationCount.html?authorUid=2083187442","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},null],"widgetId":"rgw4_56ab1cd3a62b5"},"id":"rgw4_56ab1cd3a62b5","partials":[],"templateName":"publicprofile\/stubs\/ProfileBadge.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicLiteratureAuthorBadge.html?authorUid=2083187442","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw3_56ab1cd3a62b5"},"id":"rgw3_56ab1cd3a62b5","partials":[],"templateName":"publicprofile\/stubs\/ProfileSmallHeader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicprofile.ProfileSmallHeader.html?publicationUid=41781559","viewClass":null,"yuiModules":["css-modules-publicprofile"],"stylesheets":["modules\/publicprofile.css"],"_isYUI":true},"publication":{"data":{"publicationUid":41781559,"title":"Gaussian Process for Machine Learning","journalTitle":false,"journalDetailsTooltip":false,"affiliation":false,"type":"Article","details":{"journalInfos":{"journal":"","publicationDate":"01\/2006;","publicationDateRobot":"2006-01","article":""}},"source":{"sourceUrl":"http:\/\/edoc.mpg.de\/312148","sourceName":"OAI"},"publicationActions":null,"publicationCoins":{"data":{"tags":[{"key":"ctx_ver","value":"Z39.88-2004"},{"key":"rft_val_fmt","value":"info:ofi\/fmt:kev:mtx:journal"},{"key":"rfr_id","value":"info:sid\/researchgate.net:researchgate"},{"key":"rft.atitle","value":"Gaussian Process for Machine Learning"},{"key":"rft.date","value":"2006"},{"key":"rft.au","value":"C. E. Rasmussen,C. K. I. Williams"},{"key":"rft.genre","value":"article"}],"widgetId":"rgw7_56ab1cd3a62b5"},"id":"rgw7_56ab1cd3a62b5","partials":[],"templateName":"publicliterature\/stubs\/PublicationCoins.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationCoins.html?publicationUid=41781559","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationAuthors":{"data":{"publicationUid":41781559,"peopleItems":[{"data":{"authorUrl":"researcher\/2083187442_C_E_Rasmussen","authorNameOnPublication":"C. E. Rasmussen","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg","imageSize":"s","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"C. E. Rasmussen","profile":{"professionalInstitution":{"professionalInstitutionName":false,"professionalInstitutionUrl":null}},"professionalInstitutionName":false,"professionalInstitutionUrl":null,"url":"researcher\/2083187442_C_E_Rasmussen","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":true,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":false,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"widgetId":"rgw10_56ab1cd3a62b5"},"id":"rgw10_56ab1cd3a62b5","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAuthorItem.html?entityId=2083187442&imageSize=l&enableAuthorInviteButton=0","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"largeTooltip":false,"useRebrandedImageStyle":null,"widgetId":"rgw9_56ab1cd3a62b5"},"id":"rgw9_56ab1cd3a62b5","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorItem.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorItem.html?authorUid=2083187442&authorNameOnPublication=C.%20E.%20Rasmussen","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true},{"data":{"authorUrl":"researcher\/2037649422_C_K_I_Williams","authorNameOnPublication":"C. K. I. Williams","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg","imageSize":"s","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"C. K. I. Williams","profile":{"professionalInstitution":{"professionalInstitutionName":false,"professionalInstitutionUrl":null}},"professionalInstitutionName":false,"professionalInstitutionUrl":null,"url":"researcher\/2037649422_C_K_I_Williams","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":true,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":false,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"widgetId":"rgw12_56ab1cd3a62b5"},"id":"rgw12_56ab1cd3a62b5","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAuthorItem.html?entityId=2037649422&imageSize=l&enableAuthorInviteButton=0","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"largeTooltip":false,"useRebrandedImageStyle":null,"widgetId":"rgw11_56ab1cd3a62b5"},"id":"rgw11_56ab1cd3a62b5","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorItem.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorItem.html?authorUid=2037649422&authorNameOnPublication=C.%20K.%20I.%20Williams","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true}],"hasMore":false,"nextOffset":6,"useRebrandedImageStyle":null,"widgetId":"rgw8_56ab1cd3a62b5"},"id":"rgw8_56ab1cd3a62b5","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorList.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorList.html?publicationUid=41781559&context=pubdetail_authors_xflw&showContactAuthorButton=1","viewClass":"views.publicliterature.PublicationDetailAuthorListView","yuiModules":["rg.views.publicliterature.PublicationDetailAuthorListView"],"stylesheets":[],"_isYUI":true},"publicationAbstract":{"data":{"publicationUid":41781559,"abstract":"<noscript><\/noscript><div>Gaussian processes (GPs) provide a principled, practical, probabilistic approach to learning in kernel machines. GPs have received increased attention in the machine-learning community over the past decade, and this book provides a long-needed systematic and unified treatment of theoretical and practical aspects of GPs in machine learning. The treatment is comprehensive and self-contained, targeted at researchers and students in machine learning and applied statistics. The book deals with the supervised-learning problem for both regression and classification, and includes detailed algorithms. A wide variety of covariance (kernel) functions are presented and their properties discussed. Model selection is discussed both from a Bayesian and a classical perspective. Many connections to other well-known techniques from machine learning and statistics are discussed, including support-vector machines, neural networks, splines, regularization networks, relevance vector machines and others. Theoretical issues including learning curves and the PAC-Bayesian framework are treated, and several approximation methods for learning with large datasets are discussed. The book contains illustrative examples and exercises, and code and datasets are available on the Web. Appendixes provide mathematical background and a discussion of Gaussian Markov processes.<\/div>","canEdit":false,"isAdmin":false,"isArtifact":false,"showFullAbstract":true,"widgetId":"rgw13_56ab1cd3a62b5"},"id":"rgw13_56ab1cd3a62b5","partials":[],"templateName":"publicliterature\/stubs\/PublicationAbstract.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationAbstract.html?publicationUid=41781559","viewClass":"views.publicliterature.PublicationAbstractView","yuiModules":["rg.views.publicliterature.PublicationAbstractView"],"stylesheets":[],"_isYUI":true},"publicationKeywords":null,"publicationState":null,"isGuest":true,"isAdminEditingAllowed":false,"isArtifact":false,"figureListWidget":null,"previewImage":"https:\/\/i1.rgstatic.net\/publication\/41781559_Gaussian_Process_for_Machine_Learning\/links\/0e608559f0c46d4f0acd3d0d\/smallpreview.png","nativeAdDisclosure":null,"showFollowPublicationButton":false,"followPublicationPromo":"","widgetId":"rgw6_56ab1cd3a62b5"},"id":"rgw6_56ab1cd3a62b5","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailItem.html","templateExtensions":["generalHelpers"],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailItem.html?publicationUid=41781559&showActionBar=0&showContactAuthorButton=1&showRequestFulltextExperience=0&showNoRgAuthorsRequestFulltextExperience=0&showFollowPublicationPromo=0","viewClass":"views.publicliterature.PublicationDetailItemView","yuiModules":["rg.views.publicliterature.PublicationDetailItemView"],"stylesheets":[],"_isYUI":true},"similarPublications":{"data":{"publicationListItems":[{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore","clickThrough":"experimentMilestoneClickedToPublicationFromReferenceWithNoFulltext","clickThroughWithContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":2007778901,"url":"researcher\/2007778901_Keisuke_Takahashi","fullname":"Keisuke Takahashi","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2086689882,"url":"researcher\/2086689882_Yuzuru_Tanaka","fullname":"Yuzuru Tanaka","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Feb 2016","journal":null,"showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/285362627_Material_synthesis_and_design_from_first_principle_calculations_and_machine_learning","usePlainButton":true,"publicationUid":285362627,"feedStubs":null,"hasFeedStubs":false,"impactPoints":false,"url":"publication\/285362627_Material_synthesis_and_design_from_first_principle_calculations_and_machine_learning","title":"Material synthesis and design from first principle calculations and machine learning","displayTitleAsLink":true,"authors":[{"id":2007778901,"url":"researcher\/2007778901_Keisuke_Takahashi","fullname":"Keisuke Takahashi","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2086689882,"url":"researcher\/2086689882_Yuzuru_Tanaka","fullname":"Yuzuru Tanaka","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":[],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/285362627_Material_synthesis_and_design_from_first_principle_calculations_and_machine_learning","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/285362627_Material_synthesis_and_design_from_first_principle_calculations_and_machine_learning\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw15_56ab1cd3a62b5"},"id":"rgw15_56ab1cd3a62b5","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=285362627","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore","clickThrough":"experimentMilestoneClickedToPublicationFromReferenceWithNoFulltext","clickThroughWithContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":2049166781,"url":"researcher\/2049166781_Hao_Li","fullname":"Hao Li","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2095212588,"url":"researcher\/2095212588_Xindong_Tang","fullname":"Xindong Tang","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2095285995,"url":"researcher\/2095285995_Run_Wang","fullname":"Run Wang","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":{"id":2090556423,"url":"researcher\/2090556423_Fan_Lin","fullname":"Fan Lin","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},"surplusAuthors":2,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Jan 2016","journal":"Applied Sciences","showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/291373841_Comparative_Study_on_Theoretical_and_Machine_Learning_Methods_for_Acquiring_Compressed_Liquid_Densities_of_1112333-Heptafluoropropane_R227ea_via_Song_and_Mason_Equation_Support_Vector_Machine_and_Arti","usePlainButton":true,"publicationUid":291373841,"feedStubs":null,"hasFeedStubs":false,"impactPoints":"1.48","url":"publication\/291373841_Comparative_Study_on_Theoretical_and_Machine_Learning_Methods_for_Acquiring_Compressed_Liquid_Densities_of_1112333-Heptafluoropropane_R227ea_via_Song_and_Mason_Equation_Support_Vector_Machine_and_Arti","title":"Comparative Study on Theoretical and Machine Learning Methods for Acquiring Compressed Liquid Densities of 1,1,1,2,3,3,3-Heptafluoropropane (R227ea) via Song and Mason Equation, Support Vector Machine, and Artificial Neural Networks","displayTitleAsLink":true,"authors":[{"id":2049166781,"url":"researcher\/2049166781_Hao_Li","fullname":"Hao Li","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2095212588,"url":"researcher\/2095212588_Xindong_Tang","fullname":"Xindong Tang","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2095285995,"url":"researcher\/2095285995_Run_Wang","fullname":"Run Wang","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2090556423,"url":"researcher\/2090556423_Fan_Lin","fullname":"Fan Lin","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":82301887,"url":"researcher\/82301887_Zhijian_Liu","fullname":"Zhijian Liu","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2083068498,"url":"researcher\/2083068498_Kewei_Cheng","fullname":"Kewei Cheng","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["Applied Sciences 01\/2016; 6(1):25. DOI:10.3390\/app6010025"],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/291373841_Comparative_Study_on_Theoretical_and_Machine_Learning_Methods_for_Acquiring_Compressed_Liquid_Densities_of_1112333-Heptafluoropropane_R227ea_via_Song_and_Mason_Equation_Support_Vector_Machine_and_Arti","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/291373841_Comparative_Study_on_Theoretical_and_Machine_Learning_Methods_for_Acquiring_Compressed_Liquid_Densities_of_1112333-Heptafluoropropane_R227ea_via_Song_and_Mason_Equation_Support_Vector_Machine_and_Arti\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw16_56ab1cd3a62b5"},"id":"rgw16_56ab1cd3a62b5","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=291373841","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore","clickThrough":"experimentMilestoneClickedToPublicationFromReferenceWithNoFulltext","clickThroughWithContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":2092024463,"url":"researcher\/2092024463_Ivan_Ramirez_Morales","fullname":"Iv\u00e1n Ram\u00edrez Morales","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2091984080,"url":"researcher\/2091984080_Daniel_Rivero_Cebrian","fullname":"Daniel Rivero Cebri\u00e1n","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2078074129,"url":"researcher\/2078074129_Enrique_Fernandez_Blanco","fullname":"Enrique Fern\u00e1ndez Blanco","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2095412982,"url":"researcher\/2095412982_Alejandro_Pazos_Sierra","fullname":"Alejandro Pazos Sierra","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Feb 2016","journal":"Computers and Electronics in Agriculture","showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/289122212_Early_warning_in_egg_production_curves_from_commercial_hens_A_SVM_approach","usePlainButton":true,"publicationUid":289122212,"feedStubs":null,"hasFeedStubs":false,"impactPoints":"1.76","url":"publication\/289122212_Early_warning_in_egg_production_curves_from_commercial_hens_A_SVM_approach","title":"Early warning in egg production curves from commercial hens: A SVM approach","displayTitleAsLink":true,"authors":[{"id":2092024463,"url":"researcher\/2092024463_Ivan_Ramirez_Morales","fullname":"Iv\u00e1n Ram\u00edrez Morales","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2091984080,"url":"researcher\/2091984080_Daniel_Rivero_Cebrian","fullname":"Daniel Rivero Cebri\u00e1n","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2078074129,"url":"researcher\/2078074129_Enrique_Fernandez_Blanco","fullname":"Enrique Fern\u00e1ndez Blanco","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2095412982,"url":"researcher\/2095412982_Alejandro_Pazos_Sierra","fullname":"Alejandro Pazos Sierra","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["Computers and Electronics in Agriculture 02\/2016; 121:169-179. DOI:10.1016\/j.compag.2015.12.009"],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/289122212_Early_warning_in_egg_production_curves_from_commercial_hens_A_SVM_approach","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/289122212_Early_warning_in_egg_production_curves_from_commercial_hens_A_SVM_approach\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw17_56ab1cd3a62b5"},"id":"rgw17_56ab1cd3a62b5","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=289122212","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"viewClass":"sidebar","widgetId":"rgw14_56ab1cd3a62b5"},"id":"rgw14_56ab1cd3a62b5","partials":[],"templateName":"publicliterature\/stubs\/SimilarPublications.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.SimilarPublications.html?referencePublicationId=41781559&view=sidebar","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationFulltextPreview":null,"publicationResourcesFulltext":{"data":{"publicationUid":41781559,"publicationResourceList":{"data":{"publicationResourceItems":[{"data":{"publicationUid":41781559,"publicationType":"article","linkId":"0e608559f0c46d4f0acd3d0d","fileName":"Gaussian Process for Machine Learning","fileUrl":"http:\/\/www.newton.ac.uk\/programmes\/BNR\/seminars\/080914001.pdf","name":"newton.ac.uk","nameUrl":"http:\/\/www.newton.ac.uk\/programmes\/BNR\/seminars\/080914001.pdf","canRemove":false,"fileIcon":"ico-pub","canPreview":true,"hasPublisherLink":null,"hasMetaData":true,"hide":false,"fulltext":"ico-pub","origin":"publication_list","isLastLink":true,"isUserLink":false,"widgetId":"rgw20_56ab1cd3a62b5"},"id":"rgw20_56ab1cd3a62b5","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceItem.html","templateExtensions":["generalHelpers"],"attrs":{"fileRequiredPublicationTypes":["code","coverPage","experimentFindings","method","negativeResults","presentation","rawData","researchProposal","workingPaper","artifact","dataset"]},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceItem.html?publicationUid=41781559&linkId=0e608559f0c46d4f0acd3d0d&hide=0&disableJavascript=disableJavascript&useAlternativeTemplate=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"widgetId":"rgw19_56ab1cd3a62b5"},"id":"rgw19_56ab1cd3a62b5","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceList.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceList.html?publicationUid=41781559&limit=3&disableJavascript=disableJavascript&type=fulltextFile","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"resourceCount":1,"hidden":false,"showMore":false,"fulltext":true,"publicationDownloadCount":{"data":{"value":9,"valueFormatted":"9","widgetId":"rgw21_56ab1cd3a62b5"},"id":"rgw21_56ab1cd3a62b5","partials":[],"templateName":"publicliterature\/stubs\/PublicationDownloadCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDownloadCount.html?publicationUid=41781559","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw18_56ab1cd3a62b5"},"id":"rgw18_56ab1cd3a62b5","partials":[],"templateName":"publicliterature\/stubs\/PublicationResources.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResources.html?publicationUid=41781559&type=fulltextFile&disableJavascript=1","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationResourcesAttachments":{"data":{"publicationUid":41781559,"publicationResourceList":{"data":{"publicationResourceItems":[],"widgetId":"rgw23_56ab1cd3a62b5"},"id":"rgw23_56ab1cd3a62b5","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceList.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceList.html?publicationUid=41781559&limit=3&disableJavascript=disableJavascript&type=attachmentFile","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"resourceCount":0,"hidden":true,"showMore":false,"fulltext":false,"publicationDownloadCount":{"data":{"value":9,"valueFormatted":"9","widgetId":"rgw24_56ab1cd3a62b5"},"id":"rgw24_56ab1cd3a62b5","partials":[],"templateName":"publicliterature\/stubs\/PublicationDownloadCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDownloadCount.html?publicationUid=41781559","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw22_56ab1cd3a62b5"},"id":"rgw22_56ab1cd3a62b5","partials":[],"templateName":"publicliterature\/stubs\/PublicationResources.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResources.html?publicationUid=41781559&type=attachmentFile","viewClass":"views.publicliterature.PublicationResourcesView","yuiModules":["rg.views.publicliterature.PublicationResourcesView"],"stylesheets":[],"_isYUI":true},"publicationText":{"data":{"hide":false,"pages":[{"page":1,"text":"Gaussian Processes for Machine Learning\nChris Williams\nInstitute for Adaptive and Neural Computation\nSchool of Informatics, University of Edinburgh, UK\nAugust 2007\nChris WilliamsANC\nGaussian Processes for Machine Learning"},{"page":2,"text":"Overview\n1 What is machine learning?\n2 Gaussian Processes for Machine Learning\n3 Multi-task Learning\nChris WilliamsANC\nGaussian Processes for Machine Learning"},{"page":3,"text":"1. What is Machine Learning?\nThe goal of machine learning is to build computer systems\nthat can adapt and learn from their experience. (Dietterich,\n1999)\nMachine learning usually refers to changes in systems that\nperform tasks associated with artificial intelligence (AI). Such\ntasks involve recognition, diagnosis, planning, robot control,\nprediction, etc. (Nilsson, 1996)\nSome reasons for adaptation:\nSome tasks can be hard to define except via examples\nAdaptation can improve a human-built system, or track\nchanges over time\nGoals can be autonomous machine performance, or enabling\nhumans to learn from data (data mining)\nChris WilliamsANC\nGaussian Processes for Machine Learning"},{"page":4,"text":"Roots of Machine Learning\nStatistical pattern recognition, adaptive control theory (EE)\nArtificial Intelligence: e.g. discovering rules using decision\ntrees, inductive logic programming\nBrain models, e.g. neural networks\nPsychological models\nStatistics\nChris WilliamsANC\nGaussian Processes for Machine Learning"},{"page":5,"text":"Problems Addressed by Machine Learning\nSupervised Learning\nmodel p(y|x): regression,\nclassification, etc\nUnsupervised Learning\nmodel p(x): not just clustering!\nReinforcement Learning\nMarkov decision processes,\nPOMDPs, planning.\nChris WilliamsANC\nGaussian Processes for Machine Learning"},{"page":6,"text":"123\n456\nMask\nMask * Foreground\nMask\nMask * ForegroundBackground\n(Williams and Titisias, 2004)\nChris WilliamsANC\nGaussian Processes for Machine Learning"},{"page":7,"text":"Machine Learning and Statistics\nStatistics\nMachine Learning\nprobabilistic (graphical) models\nSame models, but different problems?\nNot all machine learning methods are based on probabilisic\nmodels, e.g. SVMs, non-negative matrix factorization\nChris WilliamsANC\nGaussian Processes for Machine Learning"},{"page":8,"text":"Some Differences\nStatistics: focus on understanding data in terms of models\nStatistics: interpretability, hypothesis testing\nMachine Learning: greater focus on prediction\nMachine Learning: focus on the analysis of learning\nalgorithms (not just large dataset issues)\nChris Williams ANC\nGaussian Processes for Machine Learning"},{"page":9,"text":"Slide from Rob Tibshirani (early 1990s)\nNEURAL NETS\nnetwork\nweights\nlearning\ngeneralization\nsupervised learning\nunsupervised learning\noptimal brain damage\nlarge grant = $100,000\nnice place to have a meeting:\nSnowbird, Utah, French Alps\nSTATISTICS\nmodel\nparameters\nfitting\ntest set performance\nregression\/classification\ndensity estimation\nmodel selection\nlarge grant= $10,000\nnice place to have a meeting:\nLas Vegas in August\nChris WilliamsANC\nGaussian Processes for Machine Learning"},{"page":10,"text":"2. Gaussian Processes for Machine Learning\nGaussian processes\nHistory\nRegression, classification and beyond\nCovariance functions\/kernels\nDealing with hyperparameters\nTheory\nApproximations for large datasets\nChris Williams ANC\nGaussian Processes for Machine Learning"},{"page":11,"text":"Gaussian Processes\nA Gaussian process is a stochastic process specified by its\nmean and covariance functions\nMean function\n\u00b5(x) = E[f (x)]\noften we take \u00b5(x) \u2261 0 \u2200x\nCovariance function\nk(x,x?) = E[(f (x) \u2212 \u00b5(x))(f (x?) \u2212 \u00b5(x?))]\nChris WilliamsANC\nGaussian Processes for Machine Learning"},{"page":12,"text":"A Gaussian process prior over functions can be thought of as\na Gaussian prior on the coefficients w \u223c N(0,\u039b) where\nNF\n?\nIn many interesting cases, NF= \u221e\nCan choose \u03c6\u2019s as eigenfunctions of the kernel k(x,x?) wrt\np(x) (Mercer)?\n(For stationary covariance functions and Lebesgue measure we\nget instead\n?\nwhere S(s) is the power spectrum)\nY(x) =\ni=1\nwi\u03c6i(x)\nk(x,y)p(x)\u03c6i(x) dx = \u03bbi\u03c6i(y)\nk(x \u2212 x?)e\u22122\u03c0is\u00b7xdx = S(s)e\u22122\u03c0is\u00b7x?\nChris WilliamsANC\nGaussian Processes for Machine Learning"},{"page":13,"text":"k(x,x?) = \u03c32\n0+ \u03c32\n1xx?\nk(x,x?) = exp\u2212|x \u2212 x?|\nk(x,x?) = exp\u2212(x \u2212 x?)2\nChris WilliamsANC\nGaussian Processes for Machine Learning"},{"page":14,"text":"Prediction with Gaussian Processes\nA non-parametric prior\nover functions\nAlthough GPs can be\ninfinite-dimensional\nobjects, prediction from a\nfinite dataset is O(n3)\n0 0.51\n\u22122\n\u22121\n0\n1\n2\ninput, x\nf(x)\n00.51\n\u22122\n\u22121\n0\n1\n2\ninput, x\nf(x)\nChris Williams ANC\nGaussian Processes for Machine Learning"},{"page":15,"text":"Gaussian Process Regression\nDataset D = (xi,yi)n\ni=1, Gaussian likelihood p(yi|fi) \u223c N(0,\u03c32)\nn\n?\n\u00aff (x) =\ni=1\n\u03b1ik(x,xi)\nwhere\n\u03b1 = (K + \u03c32I)\u22121y\nvar(f (x)) = k(x,x) \u2212 kT(x)(K + \u03c32I)\u22121k(x)\nin time O(n3), with k(x) = (k(x,x1),...,k(x,xn))T\nChris Williams ANC\nGaussian Processes for Machine Learning"},{"page":16,"text":"Some GP History\n1940s: Wiener, Kolmogorov (time series)\nGeostatistics (Matheron, 1973), Whittle (1963)\nO\u2019Hagan (1978); Sacks et al (Design and Analysis of\nComputer Experiments, 1989)\nWilliams and Rasmussen (1996), inspired by Neal\u2019s (1996)\nconstruction of GPs from neural networks with an infinite\nnumber of hidden units\nRegularization framework (Tikhonov and Arsenin, 1977;\nPoggio and Girosi, 1990); MAP rather than fully probabilistic\nSVMs (Vapnik, 1995): non-probabilistic, use \u201ckernel trick\u201d\nand quadratic programming\nChris WilliamsANC\nGaussian Processes for Machine Learning"},{"page":17,"text":"Carl Edward Rasmussen and Chris\nWilliams, MIT Press, 2006\nNew: available online\nChris WilliamsANC\nGaussian Processes for Machine Learning"},{"page":18,"text":"Regression, classification and beyond\nRegression with Gausian noise: e.g. robot arm inverse\ndynamics (21-d input space)\nClassification: binary, multiclass, e.g. handwritten digit\nclassification\nML community tends to use approximations to deal with\nnon-Gaussian likelihoods, cf MCMC in statistics?\nMAP solution, Laplace approximation\nExpectation Propagation (Minka, 2001; see also Opper and\nWinther, 2000)\nOther likelihoods (e.g. Poisson), observations of derivatives,\nuncertain inputs, mixtures of GPs\nChris WilliamsANC\nGaussian Processes for Machine Learning"},{"page":19,"text":"Covariance functions\nCovariance function is key entity, determining notion of\nsimilarity\nSquared exponential (\u201cGaussian\u201d) covariance function is\nwidely applied in ML; Matern kernel not very widely used\nPolynomial kernel k(x,x?) = (1 + x \u00b7 x?)pis popular in kernel\nmachines literature\nNeural network covariance function (Williams, 1998)\nkNN(x,x?) = \u03c32\nfsin\u22121?\n2\u02dc x?M\u02dc x?\n?(1 + 2\u02dc x?M\u02dc x)(1 + 2\u02dc x??M\u02dc x?)\n?\nwhere \u02dc x = (1,x1,...,xD)?\nChris WilliamsANC\nGaussian Processes for Machine Learning"},{"page":20,"text":"String kernels: let \u03c6s(x) denote the number of times a\nsubstring s appears in string x\nk(x,x?) =\n?\ns\nws\u03c6s(x)\u03c6s(x?)\n(Watkins, 1999; Haussler, 1999).\nEfficient methods using suffix trees to compute certain string\nkernels in time |x|+|x?| (Leslie et al, 2003; Vishwanathan and\nSmola, 2003)\nExtended to tree kernels (Collins and Duffy, 2002)\nFisher kernel\n\u03c6\u03b8(x) = \u2207\u03b8logp(x|\u03b8)\nk(x,x?) = \u03c6\u03b8(x)F\u22121\u03c6\u03b8(x?)\nwhere F is the Fisher information matrix (Jaakkola et al,\n2000)\nChris WilliamsANC\nGaussian Processes for Machine Learning"},{"page":21,"text":"Automatic Relevance Determination\nkSE(x,x?) = \u03c32\nfexp?\u22121\n2(x \u2212 x?)?M(xp\u2212 xq)?\nIsotropic M = ?\u22122I\nARD: M = diag(?\u22122\n1,?\u22122\n2,...,?\u22122\nD)\n\u22122\n0\n2\n\u22122\n0\n2\n\u22122\n\u22121\n0\n1\n2\ninput x1\ninput x2\noutput y\n\u22122\n0\n2\n\u22122\n0\n2\n\u22122\n\u22121\n0\n1\n2\ninput x1\ninput x2\noutput y\nChris WilliamsANC\nGaussian Processes for Machine Learning"},{"page":22,"text":"Dealing with hyperparameters\nCriteria for model selection\nMarginal likelihood p(y|X,\u03b8)\nEstimate the generalization error: LOO-CV\n?n\nBound the generalization error (e.g. PAC-Bayes)\ni=1logp(yi|y\u2212i,X,\u03b8)\nTypically do ML-II rather than sampling of p(\u03b8|X,y)\nOptimize by gradient descent (etc) on objective function\nSVMs do not generally have good methods for kernel selection\nChris Williams ANC\nGaussian Processes for Machine Learning"},{"page":23,"text":"How the marginal likelihood works\n10\n0\n\u2212100\n\u221280\n\u221260\n\u221240\n\u221220\n0\n20\n40\nlog probability\ncharacteristic lengthscale\nminus complexity penalty\ndata fit\nmarginal likelihood\nlogp(y|X,\u03b8) = \u22121\n2yTK\u22121\ny y \u2212 log|Ky| \u2212n\n2log2\u03c0\nChris Williams ANC\nGaussian Processes for Machine Learning"},{"page":24,"text":"Marginal Likelihood and Local Optima\n\u2212505\n\u22122\n\u22121\n0\n1\n2\ninput, x\noutput, y\n\u2212505\n\u22122\n\u22121\n0\n1\n2\ninput, x\noutput, y\nThere can be multiple optima of the marginal likelihood\nThese correspond to different interpretations of the data\nChris Williams ANC\nGaussian Processes for Machine Learning"},{"page":25,"text":"The Baby and the Bathwater\nMacKay (2003 ch 45): In moving from neural networks to\nkernel machines did we throw out the baby with the\nbathwater? i.e. the ability to learn hidden\nfeatures\/representations\nBut consider M = \u039b\u039b?for \u039b being D \u00d7 k, for k < D\nThe k columns of \u039b can identify directions in the input space\nwith specially high relevance (Vivarelli and Williams, 1999)\nChris Williams ANC\nGaussian Processes for Machine Learning"},{"page":26,"text":"Theory\nEquivalent kernel (Silverman, 1984)\nConsistency (Diaconis and Freedman, 1986; Choudhuri,\nGhoshal and Roy 2005; Choi and Schervish, 2004)\nAverage case learning curves\nPAC-Bayesian analysis for GPs (Seeger, 2003)\npD{RL(fD) \u2264\u02c6RL(fD) + gap(fD,D,\u03b4)} \u2265 1 \u2212 \u03b4\nwhere RL(fD) is the expected risk, and\u02c6RL(fD) is the empirical\n(training) risk\nChris WilliamsANC\nGaussian Processes for Machine Learning"},{"page":27,"text":"Approximation Methods for Large Datasets\nFast approximate solution of the linear system\nSubset of Data\nSubset of Regressors\nInducing Variables\nProjected Process Approximation\nFITC, PITC, BCM\nSPGP\nEmpirical Comparison\nChris WilliamsANC\nGaussian Processes for Machine Learning"},{"page":28,"text":"Some interesting recent uses for Gaussian Processes\nModelling transcriptional regulation using Gaussian Processes. Neil\nD. Lawrence, Guido Sanguinetti, Magnus Rattray (NIPS 2006)\nA Switched Gaussian Process for Estimating Disparity and\nSegmentation in Binocular Stereo. Oliver Williams (NIPS 2006)\nLearning to Control an Octopus Arm with Gaussian Process\nTemporal Difference Methods. Yaakov Engel, Peter Szabo, Dmitry\nVolkinshtein (NIPS 2005)\nWorst-Case Bounds for Gaussian Process Models. Sham Kakade,\nMatthias Seeger, Dean Foster (NIPS 2005)\nInfinite Mixtures of Gaussian Process Experts. Carl Rasmussen,\nZoubin Ghahramani (NIPS 2002)\nChris Williams ANC\nGaussian Processes for Machine Learning"},{"page":29,"text":"3. Multi-task Learning\nThere are multiple (possibly) related tasks, and we wish to\navoid tabula rasa learning by sharing information across tasks\nE.g. Task clustering, inter-task correlations\nTwo cases:\nWith task-descriptor features t\nWithout task-descriptor features, based solely on task identities\nJoint work with Edwin Bonilla & Felix Agakov (AISTATS\n2007) and Kian Ming Chai\nChris Williams ANC\nGaussian Processes for Machine Learning"},{"page":30,"text":"Multi-task Learning using Task-specific Features\nM tasks, learn mapping gi(x), i = 1,...,M\ntiis task descriptor (task-specific feature vector) for task i\ngi(x) = g(ti,x): potential for transfer across tasks\nOut motivation is for compiler performance prediction, where\nthere are multiple benchmark programs (=tasks), and x\ndescribes sequences of code transformations\nAnother example: predicting school pupil performance based\non pupil and school features\nWe particularly care about the case when we have very little\ndata from the test task; here inter-task transfer will be most\nimportant\nChris Williams ANC\nGaussian Processes for Machine Learning"},{"page":31,"text":"Overview\nModel setup\nRelated work\nExperimental setup, feature representation\nResults\nDiscussion\nChris Williams ANC\nGaussian Processes for Machine Learning"},{"page":32,"text":"Task-descriptor Model\nz =\n?\nx\nt\n?\nk(z,z?) = kx(x,x?)kt(t,t?)\nDecomposition into task similarity (kt) and input similarity\n(kx)\nFor the widely-used \u201cGaussian\u201d kernel, this occurs naturally\nIndependent tasks if kt(ti,tj) = \u03b4ij\nC.f. co-kriging in geostatistics (e.g. Wackernagel, 1998)\nWithout task-descriptors, simply parameterize Kt\nChris WilliamsANC\nGaussian Processes for Machine Learning"},{"page":33,"text":"x\nf\nChris WilliamsANC\nGaussian Processes for Machine Learning"},{"page":34,"text":"Related Work\nWork using task-specific features\nBakker and Heskes (2003) use neural networks. These can be\ntricky to train (local optima, number of hidden units etc)\nYu et al (NIPS 2006, Stochastic Relational Models for\nDiscriminative Link Prediction)\nChris WilliamsANC\nGaussian Processes for Machine Learning"},{"page":35,"text":"General work on Multi-task Learning\nWhat should be transferred?\nEarly work: Thrun (1996), Caruana (1997)\nMinka and Picard (1999); multiple tasks share same GP\nhyperparameters (but are uncorrelated)\nEvgeniou et al (2005): induce correlations between tasks\nbased on a correlated prior over linear regression parameters\n(special case of co-kriging)\nMultilevel (or hierarchical) modelling in statistics (e.g.\nGoldstein, 2003)\nChris WilliamsANC\nGaussian Processes for Machine Learning"},{"page":36,"text":"Compiler Performance Prediction\nGoal: Predict speedup of a new program under a given\nsequence of compiler transformations\nOnly have a limited number of runs of the new program, but\nalso have data from other (related?) tasks\nSpeedup s measured as\ns(x) =time(baseline)\ntime(x)\nChris WilliamsANC\nGaussian Processes for Machine Learning"},{"page":37,"text":"Example Transformation\nLoop unrolling\n\/\/ original loop\nfor(i=0; i<100; i++)\na[i] = b[i] + c[i];\n\/\/ loop unrolled twice\nfor(i=0; i<100; i+=2){\na[i]= b[i] + c[i];\na[i+1] = b[i+1] +\nc[i+1];\n}\nChris WilliamsANC\nGaussian Processes for Machine Learning"},{"page":38,"text":"Experimental Setup\nBenchmarks: 11 C programs from UTDSP\nTransformations: Source-to-source using SUIF\nPlatform: TI C6713 board\n13 transformations in sequences up to length 5, using each\ntransformation at most once \u21d2 88214 sequences per\nbenchmark (exhaustively enumerated)\nSignificant speedups can be obtained (max is 1.84)\nChris WilliamsANC\nGaussian Processes for Machine Learning"},{"page":39,"text":"Input Features x\nCode features (C), or transformation-based representation (T)\nCode features: extract features from transformed program\nbased on knowledge of compiler experts (code size,\ninstructions executed, parallelism)\n83 features reduced to 15-d with PCA\nTransformation-based representation: length-13 bit vector\nstating what transformations were used (\u201cbag of characters\u201d)\nChris WilliamsANC\nGaussian Processes for Machine Learning"},{"page":40,"text":"Task-specific features t\nRecord the speedup on a small number of canonical\nsequences: response-based approach\nCanonical sequences selected by principal variables method\n(McCabe, 1984)\nA variety of possible criteria can be used, e.g. maximize\n|\u03a3S(1)|, minimize tr(\u03a3S(2)|S(1)). Use greedy selection\nWe don\u2019t use all 88214 sequences to define the canonical\nsequences, only only 2048. In our experiments we use 8\ncanonical variables\nCould consider e.g. code features from untransformed\nprograms, but experimentally response-based method is\nsuperior\nChris WilliamsANC\nGaussian Processes for Machine Learning"},{"page":41,"text":"Experiments\nLOO-CV setup (leave out one task at a time)\nTherefore 10 reference tasks for each prediction task; we used\nnr= 256 examples per benchmark\nUse nteexamples from the test task (nte\u2265 8)\nAssess performance using mean absolute error (MAE) on all\nremaining test sequences\nComparison to baseline \u201cno transfer\u201d method using just data\nfrom test task\nUsed GP regression prediction with squared exponential kernel\nARD was used, except for \u201cno transfer\u201d case when nte\u2264 64\nChris Williams ANC\nGaussian Processes for Machine Learning"},{"page":42,"text":"ADPCOMEDGFFT FIRHISIIRLATLMS LPCSPEAVG\n0\n0.05\n0.1\n0.15\n0.2\n0.25\n0.3\n0.35\nMAE\n \n \n[T] COMBINED\n[T] GATING\n[C] COMBINED\n[C] GATING\nMEDIAN CANONICALS\nMEDIAN TEST\n0.540\n(0.007)\nChris WilliamsANC\nGaussian Processes for Machine Learning"},{"page":43,"text":"Results\nT-combined is best overall (av MAE is 0.0576, compared to\n0.1162 for median canonicals)\nT-combined generally either improves performance or leaves it\nabout the same compared to T-no-transfer-canonicals\nChris WilliamsANC\nGaussian Processes for Machine Learning"},{"page":44,"text":"8163264128\n0\n0.05\n0.1\n0.15\n0.2\n0.25\n0.3\n0.35\n0.4\nHISTOGRAM\nTEST SAMPLES INCLUDED FOR TRAINING\nMAE\n \n \n[T] COMBINED\n[T] NO TRANSFER RANDOM\n[T] NO TRANSFER CANONICALS\nMEDIAN CANONICALS\n8163264128\n0\n0.02\n0.04\n0.06\n0.08\n0.1\n0.12\n0.14\nEDGE_DETECT\nTEST SAMPLES INCLUDED FOR TRAINING\nMAE\n \n \n[T] COMBINED\n[T] NO TRANSFER RANDOM\n[T] NO TRANSFER CANONICALS\nMEDIAN CANONICALS\nChris WilliamsANC\nGaussian Processes for Machine Learning"},{"page":45,"text":"8163264128\n0\n0.02\n0.04\n0.06\n0.08\n0.1\n0.12\n0.14\n0.16\nADPCM\nTEST SAMPLES INCLUDED FOR TRAINING\nMAE\n \n \n[T] COMBINED\n[T] NO TRANSFER RANDOM\n[T] NO TRANSFER CANONICALS\nMEDIAN CANONICALS\n8163264 128\n0\n0.02\n0.04\n0.06\n0.08\n0.1\n0.12\n0.14\n0.16\n0.18\nTEST SAMPLES INCLUDED FOR TRAINING\nMAE\nALL BENCHMARKS\n \n \n[T] COMBINED\n[T] NO TRANSFER RANDOM\n[T] NO TRANSFER CANONICALS\nMEDIAN CANONICALS\nT-combined generally improves performance or leaves it about\nthe same compared to the best \u201cno transfer\u201d scenario\nChris WilliamsANC\nGaussian Processes for Machine Learning"},{"page":46,"text":"Understanding Task Relatedness\nGP predictive mean is\ns(z\u2217) = kT(z\u2217)(Kf\u2297 Kx+ \u03c32I)\u22121s\nCan look at Kf, but difficult to interpret?\nPredictive mean s(z\u2217) = hT(z\u2217)s, where\nhT(z) = (h1\n1,...,h1\nnr,...,hM\n1,...,hM\nnr,hM+1\n1\n,...,hM+1\nnte\n,)\nMeasure contribution of task i on test point z\u2217by computing\nri(z\u2217) =|hi(z\u2217)|\n|h(z\u2217)|\nChris WilliamsANC\nGaussian Processes for Machine Learning"},{"page":47,"text":"Average r\u2019s over test examples\nadpcom edg fftfir hisiirlat lms lpcspe\nspe\nlpc\nlms\nlat\niir\nhis\nfir\nfft\nedg\ncom\nadp\nChris WilliamsANC\nGaussian Processes for Machine Learning"},{"page":48,"text":"Discussion\nOur focus is on the hard problem of prediction on a new task\ngiven very little data for that task\nThe presented method allows sharing over tasks. This should\nbe beneficial, but note that \u201cno transfer\u201d method has the\nfreedom to use different hyperparams on each task\nCan learn similarity between tasks directly (unparameterized\nKt), but this is not so easy if nteis very small\nNote that there is no inter-task transfer in noiseless case!\n(autokrigeability)\nChris WilliamsANC\nGaussian Processes for Machine Learning"},{"page":49,"text":"General Conclusions\nKey issues:\nDesigning\/discovering covariance functions suitable for various\ntypes of data\nMethods for setting\/inference of hyperparameters\nDealing with large datasets\nChris WilliamsANC\nGaussian Processes for Machine Learning"},{"page":50,"text":"Gaussian Process Regression\nDataset D = (xi,yi)n\ni=1, Gaussian likelihood p(yi|fi) \u223c N(0,\u03c32)\nn\n?\n\u00aff (x) =\ni=1\n\u03b1ik(x,xi)\nwhere\n\u03b1 = (K + \u03c32I)\u22121y\nvar(x) = k(x,x) \u2212 kT(x)(K + \u03c32I)\u22121k(x)\nin time O(n3), with k(x) = (k(x,x1),...,k(x,xn))T\nChris WilliamsANC\nGaussian Processes for Machine Learning"}],"widgetId":"rgw25_56ab1cd3a62b5"},"id":"rgw25_56ab1cd3a62b5","partials":[],"templateName":"publicliterature\/stubs\/PublicationText.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationText.html?publicationUid=41781559&hide=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationDetailAd":{"data":{"googleDfpSlot":null,"widgetId":"rgw26_56ab1cd3a62b5"},"id":"rgw26_56ab1cd3a62b5","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAd.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAd.html?publicationUid=41781559&slotId=336x280_Publications_ATF_Right&collapseSlotMode=never&fallbackContainerEnabled=1","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationRelations":null,"publicationRelationsReverse":null,"publicationUid":41781559,"showSignUpDialog":false,"selectNewSignUpDialog":false,"publicationQuestions":null,"publicationCitations":{"data":{"publicationUid":41781559,"publicationCitationsList":{"data":{"citationItems":[{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore","clickThrough":"experimentMilestoneClickedToPublicationFromCitationWithFulltext","clickThroughWithContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":2046328734,"url":"researcher\/2046328734_Cong_Wang","fullname":"Cong Wang","last":false,"imageUrl":"https:\/\/i1.rgstatic.net\/ii\/profile.image\/AS%3A284767061856256%401444905166141_m"},{"id":2046554452,"url":"researcher\/2046554452_Yu_Zhao","fullname":"Yu Zhao","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2068973423,"url":"researcher\/2068973423_Yubei_Chen","fullname":"Yubei Chen","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":55939832,"url":"researcher\/55939832_Masayoshi_Tomizuka","fullname":"Masayoshi Tomizuka","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":[["includes-citation-list"]],"isFulltext":true,"isSlurp":false,"isNoText":false,"publicationType":"Article","publicationDate":"Oct 2015","journal":"Robotics and Computer-Integrated Manufacturing","showEnrichedPublicationItem":false,"citationCount":1,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/273436999_Nonparametric_statistical_learning_control_of_robot_manipulators_for_trajectory_or_contour_tracking","usePlainButton":true,"publicationUid":273436999,"feedStubs":null,"hasFeedStubs":false,"impactPoints":"2.31","url":"publication\/273436999_Nonparametric_statistical_learning_control_of_robot_manipulators_for_trajectory_or_contour_tracking","title":"Nonparametric statistical learning control of robot manipulators for trajectory or contour tracking","displayTitleAsLink":true,"authors":[{"id":2046328734,"url":"researcher\/2046328734_Cong_Wang","fullname":"Cong Wang","last":false,"imageUrl":"https:\/\/i1.rgstatic.net\/ii\/profile.image\/AS%3A284767061856256%401444905166141_m"},{"id":2046554452,"url":"researcher\/2046554452_Yu_Zhao","fullname":"Yu Zhao","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2068973423,"url":"researcher\/2068973423_Yubei_Chen","fullname":"Yubei Chen","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":55939832,"url":"researcher\/55939832_Masayoshi_Tomizuka","fullname":"Masayoshi Tomizuka","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["Robotics and Computer-Integrated Manufacturing 10\/2015; 35. DOI:10.1016\/j.rcim.2015.03.002"],"abstract":"This paper presents a method of precision tracking control for industrial robot manipulators. For robotic laser and plasma cutting tasks, the required tracking performance is much more demanding than that for material handling, spot welding, and machine tending tasks. Challenges in control come from the nonlinear coupled multi-body dynamics of robot manipulators, as well as the transmission error in the geared joints. The proposed method features data-driven iterative compensation of torque and motor reference. Motor side tracking and transmission error are handled by separate learning modules in a two-part compensation structure. Depending on the specific setup of end-effector sensing, the method can utilize either timed trajectory measurement or untimed two-dimensional contour inspection. Nonparametric statistical learning is used for the compensation. Considerations on incorporating analytical models and selecting data subsets for more efficient learning are discussed. The method is validated using a six-axis industrial robot.","description":false,"swapJournalAndAuthorPositions":false,"showAbstract":true,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/273436999_Nonparametric_statistical_learning_control_of_robot_manipulators_for_trajectory_or_contour_tracking","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":true,"actions":[{"type":"download","text":"Download","url":"profile\/Cong_Wang19\/publication\/273436999_Nonparametric_statistical_learning_control_of_robot_manipulators_for_trajectory_or_contour_tracking\/links\/550f25d30cf21287416b02f3.pdf?origin=publication_list","active":false,"primary":true,"extraClass":"open-viewer","icon":null,"data":[]}],"actionWidgets":[],"publicationItemFulltext":{"data":{"isDataset":false,"isResearch":false,"isFulltext":true,"source":{"isPreview":false,"sourceUrl":"profile\/Cong_Wang19","sourceName":"Cong Wang","hasSourceUrl":true},"publicationUid":273436999,"publicationUrl":"publication\/273436999_Nonparametric_statistical_learning_control_of_robot_manipulators_for_trajectory_or_contour_tracking","eventCode":"","citationCount":0,"additionalContentWidgets":[],"disableViewer":true,"showLoggedOutRequestButton":false,"context":null,"previewUrl":"https:\/\/i1.rgstatic.net\/publication\/273436999_Nonparametric_statistical_learning_control_of_robot_manipulators_for_trajectory_or_contour_tracking\/links\/550f25d30cf21287416b02f3\/smallpreview.png","linkId":"550f25d30cf21287416b02f3","origin":"publication_list","showRequestCount":false,"publish":false,"request":false,"showAction":false,"displayAsLink":true,"documentViewerUrl":"publicliterature.PublicLiteratureDocumentViewer.html?publicationId=273436999&reference=550f25d30cf21287416b02f3&eventCode=&origin=publication_list","widgetId":"rgw30_56ab1cd3a62b5"},"id":"rgw30_56ab1cd3a62b5","partials":[],"templateName":"publicliterature\/stubs\/PublicationItemFulltext.html","templateExtensions":["generalHelpers"],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItemFulltext.html?publicationUid=273436999&showAction=1&eventCode=&hideSource=0&displayAsLink=1&showPublishAsSelectFile=0","viewClass":"views.publicliterature.PublicationItemFulltextView","yuiModules":["rg.views.publicliterature.PublicationItemFulltextView"],"stylesheets":[],"_isYUI":true},"linkId":"550f25d30cf21287416b02f3","context":null,"contextId":null,"eventCode":"","isCitation":true,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":41781559,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/273436999_Nonparametric_statistical_learning_control_of_robot_manipulators_for_trajectory_or_contour_tracking\/review","additionalRightSideTopWidgets":[{"data":{"citationContexts":["Note that the concepts of input and output used here should not be confused with those of general dynamic systems . Rather than assuming a parameterized structure for f, GPR assumes f to be random, and can be characterized using a mean function and a covariance function (also called a kernel) [12] "],"widgetId":"rgw31_56ab1cd3a62b5"},"id":"rgw31_56ab1cd3a62b5","partials":[],"templateName":"publicliterature\/stubs\/PublicationItemCitationContexts.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItemCitationContexts.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":true,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read full-text","widgetId":"rgw29_56ab1cd3a62b5"},"id":"rgw29_56ab1cd3a62b5","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":true,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItem.html?showEnrichedPublicationItem=0&showRequestButton=1&publicationUid=273436999&additionalCssClasses%5B0%5D=includes-citation-list&citationContextItemVersion=old&isIncomingCitation=1","viewClass":"views.publicliterature.PublicationItemView","yuiModules":["rg.views.publicliterature.PublicationItemView"],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore","clickThrough":"experimentMilestoneClickedToPublicationFromCitationWithFulltext","clickThroughWithContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":2067007832,"url":"researcher\/2067007832_Linkai_Luo","fullname":"Linkai Luo","last":false,"imageUrl":"https:\/\/i1.rgstatic.net\/ii\/profile.image\/AS%3A280154669633544%401443805486873_m\/Linkai_Luo.png"},{"id":70185089,"url":"researcher\/70185089_Yuan_Yao","fullname":"Yuan Yao","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":7473905,"url":"researcher\/7473905_Furong_Gao","fullname":"Furong Gao","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":[["includes-citation-list"]],"isFulltext":true,"isSlurp":false,"isNoText":false,"publicationType":"Article","publicationDate":"Sep 2015","journal":"Chemical Engineering Science","showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/276365045_Bayesian_improved_model_migration_methodology_for_fast_process_modeling_by_incorporating_prior_information","usePlainButton":true,"publicationUid":276365045,"feedStubs":null,"hasFeedStubs":false,"impactPoints":"2.34","url":"publication\/276365045_Bayesian_improved_model_migration_methodology_for_fast_process_modeling_by_incorporating_prior_information","title":"Bayesian improved model migration methodology for fast process modeling by incorporating prior information","displayTitleAsLink":true,"authors":[{"id":2067007832,"url":"researcher\/2067007832_Linkai_Luo","fullname":"Linkai Luo","last":false,"imageUrl":"https:\/\/i1.rgstatic.net\/ii\/profile.image\/AS%3A280154669633544%401443805486873_m\/Linkai_Luo.png"},{"id":70185089,"url":"researcher\/70185089_Yuan_Yao","fullname":"Yuan Yao","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":7473905,"url":"researcher\/7473905_Furong_Gao","fullname":"Furong Gao","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["Chemical Engineering Science 09\/2015; 134:23-35. DOI:10.1016\/j.ces.2015.04.045"],"abstract":"We consider a Bayesian inference approach to enhance model migration, building on concepts laid out in an earlier paper (Lu and Gao, 2008a). Previous studies have been limited to a least-squares solution and have failed to take prior knowledge into consideration, possibly tending to cause overfitting and inaccurate estimations. We present a framework for Bayesian migration that can naturally incorporate and use prior information. The approach involves imposing normal-inverse-gamma priors over the migration parameter and exploring the resulting posterior distributions using a Markov chain Monte Carlo method. In addition, we provide a batch sequential design framework for iterative implementation of model migration, which thus avoids an exhaustive treatment of a predetermined number of design points. The effectiveness of these proposed methods is demonstrated using two examples: a numerical study and an injection molding process.","description":false,"swapJournalAndAuthorPositions":false,"showAbstract":true,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/276365045_Bayesian_improved_model_migration_methodology_for_fast_process_modeling_by_incorporating_prior_information","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":true,"actions":[{"type":"download","text":"Download","url":"profile\/Yuan_Yao10\/publication\/276365045_Bayesian_improved_model_migration_methodology_for_fast_process_modeling_by_incorporating_prior_information\/links\/555c295d08ae6aea081732c4.pdf?origin=publication_list","active":false,"primary":true,"extraClass":"open-viewer","icon":null,"data":[]}],"actionWidgets":[],"publicationItemFulltext":{"data":{"isDataset":false,"isResearch":false,"isFulltext":true,"source":{"isPreview":false,"sourceUrl":"profile\/Yuan_Yao10","sourceName":"Yuan Yao","hasSourceUrl":true},"publicationUid":276365045,"publicationUrl":"publication\/276365045_Bayesian_improved_model_migration_methodology_for_fast_process_modeling_by_incorporating_prior_information","eventCode":"","citationCount":0,"additionalContentWidgets":[],"disableViewer":true,"showLoggedOutRequestButton":false,"context":null,"previewUrl":"https:\/\/i1.rgstatic.net\/publication\/276365045_Bayesian_improved_model_migration_methodology_for_fast_process_modeling_by_incorporating_prior_information\/links\/555c295d08ae6aea081732c4\/smallpreview.png","linkId":"555c295d08ae6aea081732c4","origin":"publication_list","showRequestCount":false,"publish":false,"request":false,"showAction":false,"displayAsLink":true,"documentViewerUrl":"publicliterature.PublicLiteratureDocumentViewer.html?publicationId=276365045&reference=555c295d08ae6aea081732c4&eventCode=&origin=publication_list","widgetId":"rgw33_56ab1cd3a62b5"},"id":"rgw33_56ab1cd3a62b5","partials":[],"templateName":"publicliterature\/stubs\/PublicationItemFulltext.html","templateExtensions":["generalHelpers"],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItemFulltext.html?publicationUid=276365045&showAction=1&eventCode=&hideSource=0&displayAsLink=1&showPublishAsSelectFile=0","viewClass":"views.publicliterature.PublicationItemFulltextView","yuiModules":["rg.views.publicliterature.PublicationItemFulltextView"],"stylesheets":[],"_isYUI":true},"linkId":"555c295d08ae6aea081732c4","context":null,"contextId":null,"eventCode":"","isCitation":true,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":41781559,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/276365045_Bayesian_improved_model_migration_methodology_for_fast_process_modeling_by_incorporating_prior_information\/review","additionalRightSideTopWidgets":[{"data":{"citationContexts":["It is worth noting that the mean function and covariance function are not limited to what we use here. In fact, one can specify a fixed mean function (Sacks et al., 1989), and\/or choose from a class of various covariance functions (Rasmussen, 2006, Chap. 4) for a problem of interest. "],"widgetId":"rgw34_56ab1cd3a62b5"},"id":"rgw34_56ab1cd3a62b5","partials":[],"templateName":"publicliterature\/stubs\/PublicationItemCitationContexts.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItemCitationContexts.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":true,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read full-text","widgetId":"rgw32_56ab1cd3a62b5"},"id":"rgw32_56ab1cd3a62b5","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":true,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItem.html?showEnrichedPublicationItem=0&showRequestButton=1&publicationUid=276365045&additionalCssClasses%5B0%5D=includes-citation-list&citationContextItemVersion=old&isIncomingCitation=1","viewClass":"views.publicliterature.PublicationItemView","yuiModules":["rg.views.publicliterature.PublicationItemView"],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore","clickThrough":"experimentMilestoneClickedToPublicationFromCitationWithSlurp","clickThroughWithContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextSlurp","nextPublicationViewId":null,"authorsPartOne":[{"id":2055731435,"url":"researcher\/2055731435_Rui_Tuo","fullname":"Rui Tuo","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":15762776,"url":"researcher\/15762776_C_F_Jeff_Wu","fullname":"C. F. Jeff Wu","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":[["includes-citation-list"]],"isFulltext":false,"isSlurp":true,"isNoText":false,"publicationType":"Article","publicationDate":"Jul 2015","journal":"The Annals of Statistics","showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/280538283_Efficient_Calibration_for_Imperfect_Computer_Models","usePlainButton":true,"publicationUid":280538283,"feedStubs":null,"hasFeedStubs":false,"impactPoints":"2.18","url":"publication\/280538283_Efficient_Calibration_for_Imperfect_Computer_Models","title":"Efficient Calibration for Imperfect Computer Models","displayTitleAsLink":true,"authors":[{"id":2055731435,"url":"researcher\/2055731435_Rui_Tuo","fullname":"Rui Tuo","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":15762776,"url":"researcher\/15762776_C_F_Jeff_Wu","fullname":"C. F. Jeff Wu","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["The Annals of Statistics 07\/2015; 43(6). DOI:10.1214\/15-AOS1314"],"abstract":"Many computer models contain unknown parameters which need to be estimated\nusing physical observations. Kennedy and O'Hagan (2001) shows that the\ncalibration method based on Gaussian process models proposed by Kennedy and\nO'Hagan (2001) may lead to unreasonable estimate for imperfect computer models.\nIn this work, we extend their study to calibration problems with stochastic\nphysical data. We propose a novel method, called the $L_2$ calibration, and\nshow its semiparametric efficiency. The conventional method of the ordinary\nleast squares is also studied. Theoretical analysis shows that it is consistent\nbut not efficient. Numerical examples show that the proposed method outperforms\nthe existing ones.","description":false,"swapJournalAndAuthorPositions":false,"showAbstract":true,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/280538283_Efficient_Calibration_for_Imperfect_Computer_Models","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":false,"actions":[{"type":"request-external","text":"Request full-text","url":"javascript:;","active":false,"primary":false,"extraClass":null,"icon":null,"data":[{"key":"context","value":"pubCit"}]}],"actionWidgets":[],"publicationItemFulltext":{"data":{"isDataset":false,"isResearch":false,"isFulltext":true,"source":{"isPreview":true,"sourceUrl":"deref\/http%3A%2F%2Fde.arxiv.org%2Fpdf%2F1507.07280","sourceName":"de.arxiv.org","hasSourceUrl":true},"publicationUid":280538283,"publicationUrl":"publication\/280538283_Efficient_Calibration_for_Imperfect_Computer_Models","eventCode":"","citationCount":0,"additionalContentWidgets":[],"disableViewer":true,"showLoggedOutRequestButton":false,"context":null,"previewUrl":"https:\/\/i1.rgstatic.net\/publication\/280538283_Efficient_Calibration_for_Imperfect_Computer_Models\/links\/55c2c20808aeca747d5dd560\/smallpreview.png","linkId":"55c2c20808aeca747d5dd560","origin":"publication_list","showRequestCount":false,"publish":false,"request":false,"showAction":false,"displayAsLink":true,"documentViewerUrl":"publicliterature.PublicLiteratureDocumentViewer.html?publicationId=280538283&reference=55c2c20808aeca747d5dd560&eventCode=&origin=publication_list","widgetId":"rgw36_56ab1cd3a62b5"},"id":"rgw36_56ab1cd3a62b5","partials":[],"templateName":"publicliterature\/stubs\/PublicationItemFulltext.html","templateExtensions":["generalHelpers"],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItemFulltext.html?publicationUid=280538283&showAction=1&eventCode=&hideSource=0&displayAsLink=1&showPublishAsSelectFile=0","viewClass":"views.publicliterature.PublicationItemFulltextView","yuiModules":["rg.views.publicliterature.PublicationItemFulltextView"],"stylesheets":[],"_isYUI":true},"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":true,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":41781559,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/280538283_Efficient_Calibration_for_Imperfect_Computer_Models\/review","additionalRightSideTopWidgets":[{"data":{"citationContexts":["We conducted 1000 random simulations to examine the performance of the L 2 calibration, the OLS calibration, and the KO calibration for \u03c3 2 = 0.1 and \u03c3 2 = 1 respectively. For the L 2 calibration and the KO calibration , the Gaussian correlation family \u03a6(x 1 , x 2 ) = exp{\u2212\u03c6(x 1 \u2212 x 2 ) 2 } is used with the model parameter \u03c6 chosen by the cross-validation method (Santner, Williams and Notz, 2003; Rasmussen and Williams, 2006). The tuning parameters in the nonparametric regression is selected by the generalized cross validation (Wahba, 1990). "],"widgetId":"rgw37_56ab1cd3a62b5"},"id":"rgw37_56ab1cd3a62b5","partials":[],"templateName":"publicliterature\/stubs\/PublicationItemCitationContexts.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItemCitationContexts.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":true,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw35_56ab1cd3a62b5"},"id":"rgw35_56ab1cd3a62b5","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":true,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItem.html?showEnrichedPublicationItem=0&showRequestButton=1&publicationUid=280538283&additionalCssClasses%5B0%5D=includes-citation-list&citationContextItemVersion=old&isIncomingCitation=1","viewClass":"views.publicliterature.PublicationItemView","yuiModules":["rg.views.publicliterature.PublicationItemView"],"stylesheets":[],"_isYUI":true}],"hasCitations":true,"isPublicationAuthor":false,"isPublicationVisitor":false,"publicationUid":41781559,"publicationLink":"publication\/41781559_Gaussian_Process_for_Machine_Learning","hasShowMore":true,"newOffset":3,"pageSize":10,"widgetId":"rgw28_56ab1cd3a62b5"},"id":"rgw28_56ab1cd3a62b5","partials":[],"templateName":"publicliterature\/stubs\/PublicationIncomingCitationsList.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationIncomingCitationsList.html?publicationUid=41781559&citedInPage=1&swapJournalAndAuthorPositions=0&showAbstract=1&showType=1&showPublicationPreview=1&totalCount=1899","viewClass":"views.publicliterature.PublicationIncomingCitationsListView","yuiModules":["rg.views.publicliterature.PublicationIncomingCitationsListView"],"stylesheets":[],"_isYUI":true},"hasCitations":false,"citationsCount":0,"hasIncomingCitations":true,"incomingCitationsCount":1899,"showCitationsSorter":true,"showAbstract":true,"showType":true,"showPublicationPreview":true,"swapJournalAndAuthorPositions":false,"sort":"","sortOriginal":false,"citationList":"incoming","showsIncoming":true,"showSorting":false,"usePlainButton":null,"useEnrichedContext":null,"widgetId":"rgw27_56ab1cd3a62b5"},"id":"rgw27_56ab1cd3a62b5","partials":[],"templateName":"publicliterature\/stubs\/PublicationCitations.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationCitations.html?publicationUid=41781559&citationList=&citedInPage=1&sort=","viewClass":"views.publicliterature.PublicationCitationsView","yuiModules":["rg.views.publicliterature.PublicationCitationsView"],"stylesheets":[],"_isYUI":true},"publicationReviewPromo":null,"publicationUsedInReviews":null,"publicationPdfJsReader":null,"useFulltextOptimizedLayout":false,"publicationActions":null,"requestFulltextPromo":null,"currentUrl":"publication\/41781559_Gaussian_Process_for_Machine_Learning","isLeaderboardAd":false,"enableStickyBox":null,"googleDfpSlotMobileBottom":null,"fullTextExitPopup":null,"showExitPopupDialog":false,"widgetId":"rgw2_56ab1cd3a62b5"},"id":"rgw2_56ab1cd3a62b5","partials":{"romeo_legal_notice":"publicliterature\/stubs\/partials\/romeo_legal_notice.html"},"templateName":"publicliterature\/stubs\/PublicPublicationDetails_NewLayout.html","templateExtensions":["generalHelpers"],"attrs":{"publicationUid":41781559},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicPublicationDetailsOld.html?publicationUid=41781559&isTestOldDesign=0","viewClass":"views.publicliterature.PublicPublicationDetailsOldView","yuiModules":["rg.views.publicliterature.PublicPublicationDetailsOldView"],"stylesheets":[],"_isYUI":true},"widgetId":"rgw1_56ab1cd3a62b5"},"id":"rgw1_56ab1cd3a62b5","partials":[],"templateName":"publicliterature\/stubs\/PublicPublicationDetails.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicPublicationDetails.html","viewClass":"views.publicliterature.PublicPublicationDetailsView","yuiModules":["rg.views.publicliterature.PublicPublicationDetailsView"],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"uaClass":"","headPrefix":[],"rootUrl":"https:\/\/www.researchgate.net\/","requestToken":"LOpEDj6wNv7Bo0HxWBTh5uP9bcx0eWGo\/MuBgjDCxR21qhbOpxB3Gk+ajWW8L9+84oWoG6n3wQKb\/64K4m7swgyaXlII1b8LQY1GEs8xQeywZXG+\/wTJjzw+wUVwx0uPIzXhv3zODOs+UdwA+RWffJb6CjBd81aA3Q64V5LJxmkhzmgSMKfdtGA9JcrKW4mx04EpG8E6k2tXSglIP8r0aTggLkv9rkW17JmpbvtFfvT3RlmSLAtgtzeIUX+SVmPPcGNyNDLJRnBfk6TxrI3cNRWbrpsjlOcULECG5S66U9c=","faviconCdnUrl":"https:\/\/c5.rgstatic.net\/m\/2390829798215018\/images\/favicon.ico","headerOutput":"<noscript><\/noscript><link rel=\"canonical\" href=\"https:\/\/www.researchgate.net\/publication\/41781559_Gaussian_Process_for_Machine_Learning\" \/>\n<link rel=\"dns-prefetch\" href=\"\/\/c5.rgstatic.net\" \/>\n<link rel=\"dns-prefetch\" href=\"\/\/i1.rgstatic.net\" \/>\n<meta property=\"twitter:card\" content=\"summary\" \/>\n<meta property=\"twitter:site\" content=\"@ResearchGate\" \/>\n<meta property=\"og:title\" content=\"Gaussian Process for Machine Learning\" \/>\n<meta property=\"og:description\" content=\"Gaussian processes (GPs) provide a principled, practical, probabilistic approach to learning in kernel machines. GPs have received increased attention in the machine-learning community over the...\" \/>\n<meta property=\"og:site_name\" content=\"ResearchGate\" \/>\n<meta property=\"og:image\" content=\"https:\/\/i1.rgstatic.net\/publication\/41781559_Gaussian_Process_for_Machine_Learning\/links\/0e608559f0c46d4f0acd3d0d\/smallpreview.png\" \/>\n<meta property=\"og:url\" content=\"https:\/\/www.researchgate.net\/publication\/41781559_Gaussian_Process_for_Machine_Learning\" \/>\n<meta property=\"rg:id\" content=\"PB:41781559\" \/>\n<meta name=\"DC.identifier\" scheme=\"DCTERMS.URI\" content=\"http:\/\/dx.doi.org\/\" \/>\n<meta name=\"gs_meta_revision\" content=\"1.1\" \/>\n<meta name=\"citation_title\" content=\"Gaussian Process for Machine Learning\" \/>\n<meta name=\"citation_author\" content=\"C. E. Rasmussen\" \/>\n<meta name=\"citation_author\" content=\"C. K. I. Williams\" \/>\n<meta name=\"citation_publication_date\" content=\"2006\/01\/01\" \/>\n<meta name=\"citation_abstract_html_url\" content=\"https:\/\/www.researchgate.net\/publication\/41781559_Gaussian_Process_for_Machine_Learning\" \/>\n<meta name=\"citation_fulltext_html_url\" content=\"https:\/\/www.researchgate.net\/publication\/41781559_Gaussian_Process_for_Machine_Learning\" \/>\n<meta name=\"viewport\" content=\"width=device-width,initial-scale=1\" \/>\n<link href=\"\/\/c5.rgstatic.net\/m\/22664197317151888\/styles\/rg.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/21004998181197492\/styles\/rg2.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<!--[if lt IE 9]><link href=\"\/\/c5.rgstatic.net\/m\/238176252723686\/styles\/ie.css\" type=\"text\/css\" rel=\"stylesheet\"\/><![endif]-->\n<link href=\"\/\/c5.rgstatic.net\/m\/217752362214895\/styles\/modules\/publicprofile.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<script src=\"\/\/c5.rgstatic.net\/m\/2321000301012716\/javascript\/vendor\/webfontloader\/webfontloader.js\" type=\"text\/javascript\"><\/script>\n <script>(function(i,s,o,g,r,a,m){i[\"GoogleAnalyticsObject\"]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,\"script\",\"\/\/www.google-analytics.com\/analytics.js\",\"ga\");\n ga(\"create\",\"UA-58591210-1\");ga(\"set\",\"anonymizeIp\",true);ga('set', 'dimension1', 'publication slurped');ga('set', 'dimension2', 'Article');ga('set', 'dimension3', 'Logged out');ga('set', 'dimension4', 'https');ga(\"send\",\"pageview\");<\/script>\n","webfont":"<noscript><\/noscript><script> WebFontConfig = { custom: { families: ['source_sans_pro_italic', 'source_sans_pro_bold', 'source_sans_pro', 'martel'], urls : ['\/\/c5.rgstatic.net\/m\/231392577336386\/styles\/fonts.css'] } }; WebFont.load(WebFontConfig); <\/script>\n","correlationId":"rgreq-ae859db4-64c7-4f45-abcd-143cfc579acd","accountId":null,"module":"publicliterature","action":"publicliterature.PublicPublicationDetails","page":"publicationDetail","product":"publications","backendTime":611,"continent":"Asia","stylesHome":"\/\/c5.rgstatic.net\/m\/","staticHost":"c5.rgstatic.net","useEarlyFlush":false,"longRunningRequestIdentifier":"LongRunningRequest.publicliterature.PublicPublicationDetails","longRunningRequestFp":"e9e5bbe1366c7ee8c8e41d02f793c884ac9be19b","widgetId":"rgw38_56ab1cd3a62b5"},"id":"rgw38_56ab1cd3a62b5","partials":[],"templateName":"application\/stubs\/StaticHeader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.StaticHeader.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){
            Y.rg.core.pagespeed.Monitoring.monitorPage("\/\/glassmoni.researchgate.net", "publicliterature.PublicPublicationDetails.run.html.loggedOut.get", "59de9668d07aeb77ab4de5f24d382b5d199d2437", "rgreq-ae859db4-64c7-4f45-abcd-143cfc579acd", "918f61cca25bc5e1a4caa780af3de7d67801de2e");
        
            Y.rg.core.pagespeed.Monitoring.monitorPage("\/\/glassmoni.researchgate.net", "publicationDetail.loggedOut", "ed1993d9e20f6cefa83edacaa24401a18c071aea", "rgreq-ae859db4-64c7-4f45-abcd-143cfc579acd", "918f61cca25bc5e1a4caa780af3de7d67801de2e");
        })();
(function(){Y.rg.createInitialWidget({"data":{"year":"2016","inlinePromo":null,"isAdmin":false,"contactUrl":"https:\/\/www.researchgate.net\/contact","aboutUsUrl":"https:\/\/www.researchgate.net\/about","widgetId":"rgw39_56ab1cd3a62b5"},"id":"rgw39_56ab1cd3a62b5","partials":[],"templateName":"application\/stubs\/DefaultFooter.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.DefaultFooter.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"headerLogin":{"data":{"urlAfterLogin":"publication\/41781559_Gaussian_Process_for_Machine_Learning","requestToken":"bOPJvdid0ZOPk+JYkyG0Ui9bPUxzWE4GitmLKTCNXK00tfZHG2U8fSoPVGc2nXexJv\/BK0JG\/U2vOXZ7mdPyTbnKOXBMYEq0rWOsZqrxQeMWXAQMuPjtd4SugBHbUPX4HCPHzGGAohXSSL8jx5sRelwgaXwxzIHrg+6n\/pUx+TINlKOGtEkl0ozMw732Ao7VYGUrd\/881EVVfoZ+olL0oknolCO5daqODavqjyBUcZc+40YkyHaQpqmxYWqWSon7l0JpjwgzTs2wKmIppPZk4Qh46mye7iNrfBTOGAmKuwY=","loginUrl":"https:\/\/www.researchgate.net\/application.Login.html","signupUrl":"https:\/\/www.researchgate.net\/signup.SignUp.html?ev=su_chnl_index&hdrsu=1&_sg=xEHTchJ4NMQE23b9UJxyJ9ANtg5mAW0FnDyqtII8xi-o64RPb5QdvdtcnEaQlljR","encodedUrlAfterLogin":"cHVibGljYXRpb24vNDE3ODE1NTlfR2F1c3NpYW5fUHJvY2Vzc19mb3JfTWFjaGluZV9MZWFybmluZw%3D%3D","signupCallToAction":"Join for free","widgetId":"rgw41_56ab1cd3a62b5"},"id":"rgw41_56ab1cd3a62b5","partials":{"partial":"application\/stubs\/partials\/headerLoginDefault.html"},"templateName":"application\/stubs\/HeaderLogin.html","templateExtensions":[],"attrs":{"goal":"milestoneHeaderLoginSeen"},"widgetUrl":"https:\/\/www.researchgate.net\/application.HeaderLogin.html","viewClass":"views.application.HeaderLoginView","yuiModules":["rg.views.application.HeaderLoginView"],"stylesheets":[],"_isYUI":true},"cookieConsent":null,"logoSvgSrc":"https:\/\/c5.rgstatic.net\/m\/235107188705592\/images\/template\/brand-header-logo.svg","logoFallbackSrc":"https:\/\/c5.rgstatic.net\/m\/238113351022438\/images\/template\/brand-header-logo.png","widgetId":"rgw40_56ab1cd3a62b5"},"id":"rgw40_56ab1cd3a62b5","partials":{"schemaSocialProfiles":"application\/stubs\/partials\/schemaSocialProfiles.html"},"templateName":"application\/stubs\/HeaderLoggedOut.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.HeaderLoggedOut.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"logEvent":"su_banner","specialCopy":false,"widgetId":"rgw42_56ab1cd3a62b5"},"id":"rgw42_56ab1cd3a62b5","partials":[],"templateName":"application\/stubs\/LoggedOutBanner.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.LoggedOutBanner.html","viewClass":"views.application.LoggedOutBannerView","yuiModules":["rg.views.application.LoggedOutBannerView"],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.core.util.ParameterFilter.filter(["ev","cp","ch","ref","dbw","pli","loginT","uid","claimChannel","enrichId","enrichSource","utm_source","utm_medium","utm_campaign","el","ci"]);})();
});}); } else { throw 'YRG was not loaded when attaching widgets'; }</script><script> dataLayer = [{"pageCategory":"publication slurped","publicationType":"Article","eventCategory":"Publication page"}]; </script> <noscript><iframe src="//www.googletagmanager.com/ns.html?id=GTM-MKVKH7" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-MKVKH7');</script><script>(function(e){function n(n,t,o,a){"use strict";var i=e.document.createElement("link"),r=t||e.document.getElementsByTagName("script")[0],d=e.document.styleSheets;return i.rel="stylesheet",i.href=n,i.media="only x",a&&(i.onload=a),r.parentNode.insertBefore(i,r),i.onloadcssdefined=function(e){for(var t,o=0;d.length>o;o++)d[o].href&&d[o].href.indexOf(n)>-1&&(t=!0);t?e():setTimeout(function(){i.onloadcssdefined(e)})},i.onloadcssdefined(function(){i.media=o||"all"}),i}function t(e,n){e.onload=function(){e.onload=null,n&&n.call(e)},"isApplicationInstalled"in navigator&&"onloadcssdefined"in e&&e.onloadcssdefined(n)}var o=function(a,i){"use strict";if(a&&3===a.length){var r=e.Image,d=!(!document.createElementNS||!document.createElementNS("http://www.w3.org/2000/svg","svg").createSVGRect||!document.implementation.hasFeature("http://www.w3.org/TR/SVG11/feature#Image","1.1")||e.opera&&-1===navigator.userAgent.indexOf("Chrome")||-1!==navigator.userAgent.indexOf("Series40")),c=new r;c.onerror=function(){o.method="png",o.href=a[2],n(a[2])},c.onload=function(){var e=1===c.width&&1===c.height,r=a[e&&d?0:e?1:2];o.method=e&&d?"svg":e?"datapng":"png",o.href=r,t(n(r),i)},c.src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///ywAAAAAAQABAAACAUwAOw==",document.documentElement.className+=" grunticon"}};o.loadCSS=n,o.onloadCSS=t,e.grunticon=o})(this);grunticon(["https://c5.rgstatic.net/c/o1o9o3/styles/icons/_header-ico.svg.css", "https://c5.rgstatic.net/c/o1o9o3/styles/icons/_header-ico.png.css", "https://c5.rgstatic.net/c/o1o9o3/styles/icons/_header-ico.fallback.scss"]);grunticon(["https://c5.rgstatic.net/c/o1o9o3/styles/icons/_admin-ico.svg.css", "https://c5.rgstatic.net/c/o1o9o3/styles/icons/_admin-ico.png.css", "https://c5.rgstatic.net/c/o1o9o3/styles/icons/_admin-ico.fallback.scss"]);grunticon(["https://c5.rgstatic.net/c/o1o9o3/styles/icons/_ico.svg.css", "https://c5.rgstatic.net/c/o1o9o3/styles/icons/_ico.png.css", "https://c5.rgstatic.net/c/o1o9o3/styles/icons/_ico.fallback.scss"]);</script></body>
</html>
