<!DOCTYPE html> <html lang="en" class="" id="rgw48_56ab1dd57cd9f"> <head > <meta charset="utf-8"/> <meta http-equiv="content-type" content="text/html; charset=UTF-8"/> <meta name="Rg-Request-Token" id="Rg-Request-Token" content="qvloLcsc42W2J8RIrg8ioEuOfGKPZ69Xtln8OhJa33yDoA6GzB7sCd8zZ4ZH5+mjkApDwDmr/YsKQd5VrDvVNrG5rbzXN6ADlSqpxcWAfQVkAcLhgLq38DNE1aamM3Mp5roP/RcgpBwCV/W2BgzMtEdjwwp+NgWqG4Hqk++RYCeuqLsh+Ev4EuZns6WtW08OH8JZpm5bigZsfqHc3WQVVIDzPusTwDw63twEyqbwLWZe0FUuMPS5qo6zwnzM6nBudavST8J69tSFL3hJZxQ4SjDhCryFXBFux58/9MVISH8="/> <meta http-equiv="expires" content="0"/> <link rel="apple-touch-icon" sizes="57x57" href="https://www.researchgate.net/apple-touch-icon-57x57.png"> <link rel="apple-touch-icon" sizes="60x60" href="https://www.researchgate.net/apple-touch-icon-60x60.png"> <link rel="apple-touch-icon" sizes="72x72" href="https://www.researchgate.net/apple-touch-icon-72x72.png"> <link rel="apple-touch-icon" sizes="76x76" href="https://www.researchgate.net/apple-touch-icon-76x76.png"> <link rel="apple-touch-icon" sizes="114x114" href="https://www.researchgate.net/apple-touch-icon-114x114.png"> <link rel="apple-touch-icon" sizes="120x120" href="https://www.researchgate.net/apple-touch-icon-120x120.png"> <link rel="apple-touch-icon" sizes="144x144" href="https://www.researchgate.net/apple-touch-icon-144x144.png"> <link rel="apple-touch-icon" sizes="152x152" href="https://www.researchgate.net/apple-touch-icon-152x152.png"> <link rel="apple-touch-icon" sizes="180x180" href="https://www.researchgate.net/apple-touch-icon-180x180.png"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-32x32.png" sizes="32x32"> <link rel="icon" type="image/png" href="https://www.researchgate.net/android-chrome-192x192.png" sizes="192x192"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-96x96.png" sizes="96x96"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-16x16.png" sizes="16x16"> <link rel="shortcut icon" type="image/x-icon" href="https://c5.rgstatic.net/m/2390829798215018/images/favicon.ico"/> <link rel="manifest" href="https://www.researchgate.net/manifest.json"> <meta name="msapplication-TileColor" content="#da532c"> <meta name="msapplication-TileImage" content="https://www.researchgate.net/mstile-144x144.png"> <meta name="theme-color" content="#444444"> <link rel="search" type="application/opensearchdescription+xml" title="ResearchGate search" href="https://www.researchgate.net/application.DownloadOpenSearchPlugin.html"/> <link rel="meta" type="application/rdf+xml" title="ICRA labels" href="https://www.researchgate.net/application.DownloadLabels.html"/> <link rel="http://oexchange.org/spec/0.8/rel/related-target" type="application/xrd+xml" href="https://www.researchgate.net/application.DownloadOExchange.html"/> <base href="https://www.researchgate.net/"/> <script>
    var rgConfig = {
        correlationId: "rgreq-55d4f05f-678c-4ba0-bca4-9b36c6227fbb",
        accountId: "",
        module: "publicliterature",
        action: "publicliterature.PublicPublicationDetails",
        page: "publicationDetail",
        product: "publications",
        continent: "Asia",
        stylesHome: "//c5.rgstatic.net/m/",
        staticHost: "c5.rgstatic.net",
        longRunningRequestIdentifier: "LongRunningRequest.publicliterature.PublicPublicationDetails",
        longRunningRequestFp: "e9e5bbe1366c7ee8c8e41d02f793c884ac9be19b"
    };
    window.rootUrl = "https://www.researchgate.net/";
</script> <link rel="canonical" href="https://www.researchgate.net/publication/23252767_The_Variational_Gaussian_Approximation_Revisited" />
<link rel="dns-prefetch" href="//c5.rgstatic.net" />
<link rel="dns-prefetch" href="//i1.rgstatic.net" />
<meta property="twitter:card" content="summary" />
<meta property="twitter:site" content="@ResearchGate" />
<meta property="og:title" content="The Variational Gaussian Approximation Revisited" />
<meta property="og:description" content="The variational approximation of posterior distributions by multivariate gaussians has been much less popular in the machine learning community compared to the corresponding approximation by..." />
<meta property="og:site_name" content="ResearchGate" />
<meta property="og:image" content="https://i1.rgstatic.net/publication/23252767_The_Variational_Gaussian_Approximation_Revisited/links/0912f50aca8ae75c77000000/smallpreview.png" />
<meta property="og:url" content="https://www.researchgate.net/publication/23252767_The_Variational_Gaussian_Approximation_Revisited" />
<meta property="rg:id" content="PB:23252767" />
<meta name="DC.identifier" scheme="DCTERMS.URI" content="http://dx.doi.org/10.1162/neco.2008.08-07-592" />
<meta name="gs_meta_revision" content="1.1" />
<meta name="citation_title" content="The Variational Gaussian Approximation Revisited" />
<meta name="citation_author" content="Manfred Opper" />
<meta name="citation_author" content="Cédric Archambeau" />
<meta name="citation_pmid" content="18785854" />
<meta name="citation_publication_date" content="2008/10/01" />
<meta name="citation_journal_title" content="Neural Computation" />
<meta name="citation_issn" content="0899-7667" />
<meta name="citation_volume" content="21" />
<meta name="citation_issue" content="3" />
<meta name="citation_firstpage" content="786" />
<meta name="citation_lastpage" content="92" />
<meta name="citation_doi" content="10.1162/neco.2008.08-07-592" />
<meta name="citation_pdf_url" content="https://www.researchgate.net/profile/Cedric_Archambeau/publication/23252767_The_Variational_Gaussian_Approximation_Revisited/links/0912f50aca8ae75c77000000.pdf" />
<meta name="citation_abstract_html_url" content="https://www.researchgate.net/publication/23252767_The_Variational_Gaussian_Approximation_Revisited" />
<meta name="citation_fulltext_html_url" content="https://www.researchgate.net/publication/23252767_The_Variational_Gaussian_Approximation_Revisited" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<link href="//c5.rgstatic.net/m/22664197317151888/styles/rg.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/21004998181197492/styles/rg2.css" type="text/css" rel="stylesheet"/>
<!--[if lt IE 9]><link href="//c5.rgstatic.net/m/238176252723686/styles/ie.css" type="text/css" rel="stylesheet"/><![endif]-->
<link href="//c5.rgstatic.net/m/217752362214895/styles/modules/publicprofile.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/21993347442549/styles/pow/publicliterature/FollowPublicationPromo.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/282514599719602/styles/pow/application/PdfJsReader.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/23819663151220/styles/pow/publicliterature/PublicationInlineReader.css" type="text/css" rel="stylesheet"/>
<script src="//c5.rgstatic.net/m/2321000301012716/javascript/vendor/webfontloader/webfontloader.js" type="text/javascript"></script>
 <script>(function(i,s,o,g,r,a,m){i["GoogleAnalyticsObject"]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,"script","//www.google-analytics.com/analytics.js","ga");
 ga("create","UA-58591210-1");ga("set","anonymizeIp",true);ga('set', 'dimension1', 'publication full-text');ga('set', 'dimension2', 'Article');ga('set', 'dimension3', 'Logged out');ga('set', 'dimension4', 'https');ga("send","pageview");</script>
  <script> WebFontConfig = { custom: { families: ['source_sans_pro_italic', 'source_sans_pro_bold', 'source_sans_pro', 'martel'], urls : ['//c5.rgstatic.net/m/231392577336386/styles/fonts.css'] } }; WebFont.load(WebFontConfig); </script><noscript></noscript>

<title>The Variational Gaussian Approximation Revisited (PDF Download Available)</title>
<meta name="description" content="Official Full-Text Publication: The Variational Gaussian Approximation Revisited on ResearchGate, the professional network for scientists."/>
<meta name="keywords" content="scientific network, scientific platform, scientific community, research partner, research collaboration, journal articles, international collaboration, find researcher, lifescience researcher, interdisciplinary research, research collaboration"/>
</head>
<body class="use-svg-icons logged-out">
<div id="page-container">
<script type="text/javascript">var googletag = googletag || {}; googletag.cmd = googletag.cmd || [];
(function() { var gads = document.createElement("script"); gads.async = true; gads.type = "text/javascript"; var useSSL = "https:" == document.location.protocol; gads.src = (useSSL ? "https:" : "http:") + "//www.googletagservices.com/tag/js/gpt.js"; var node =document.getElementsByTagName("script")[0]; node.parentNode.insertBefore(gads, node); })();</script><div id="main" class="logged-out-header-support">
<div id="content" class="">

<noscript>
<div class="c-box-warning full-width-element" style="text-align: center; ">
    <div style="margin: auto; padding:10px;" class="container">
        <b>For full functionality of ResearchGate it is necessary to enable JavaScript.
            Here are the <a href="http://www.enable-javascript.com/" rel="nofollow" target="_blank">
                instructions how to enable JavaScript in your web browser</a>.</b>
    </div>
</div>
</noscript>

<div id="rgw1_56ab1dd57cd9f" itemscope itemtype="http://schema.org/ScholarlyArticle"><div class="publication-wrapper publication-wrapper-onecol" id="rgw2_56ab1dd57cd9f" itemscope itemtype="http://schema.org/ScholarlyArticle"> <div class="c-col-content"> <div class="c-content"> <div class="clearfix">  <div class="publication-header"> <div id="rgw5_56ab1dd57cd9f">  <div class="type-label"> Article   </div> <span class="Z3988" title="ctx_ver=Z39.88-2004&rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&rfr_id=info%3Asid%2Fresearchgate.net%3Aresearchgate&rft_id=info%3Adoi%2F10.1162%2Fneco.2008.08-07-592&rft.atitle=The%20Variational%20Gaussian%20Approximation%20Revisited&rft.title=Neural%20computation&rft.jtitle=Neural%20computation&rft.volume=21&rft.issue=3&rft.date=2008&rft.pages=786-92&rft.issn=0899-7667&rft.au=Manfred%20Opper%2CC%C3%A9dric%20Archambeau&rft.genre=article"></span> <h1 class="pub-title" itemprop="name">The Variational Gaussian Approximation Revisited</h1> <meta itemprop="headline" content="The Variational Gaussian Approximation Revisited">  <meta itemprop="image" content="https://i1.rgstatic.net/publication/23252767_The_Variational_Gaussian_Approximation_Revisited/links/0912f50aca8ae75c77000000/smallpreview.png">  <div id="rgw8_56ab1dd57cd9f" class="publication-detail-author-list"> <div> <ul class="clearfix js-people-list">  <li id="rgw9_56ab1dd57cd9f" itemprop="author" itemscope itemtype="http://schema.org/Person"> <a itemprop="sameAs" href="profile/Manfred_Opper" class="pub-detail-item account-item"> <div class="indent-left"> <div class="people-img"> <img  src="https://i1.rgstatic.net/ii/profile.image/AS%3A272782856552477%401442047909729_m" title="Manfred Opper" alt="Manfred Opper" height="20px" width="20px" style="height: 20px;"/> </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Manfred Opper</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item  remove-action-indent   " id="rgw10_56ab1dd57cd9f" data-account-key="Manfred_Opper">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="profile/Manfred_Opper"> <img class="lazyload" data-src="https://i1.rgstatic.net/ii/profile.image/AS%3A272782856552477%401442047909729_l" title="Manfred Opper" alt="Manfred Opper" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">     </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="profile/Manfred_Opper" class="display-name">Manfred Opper</a>    </h5> <div class="truncate-single-line meta">   <a class="meta ga-top-coauthor-institution" href="institution/Technische_Universitaet_Berlin" title="Technische Universität Berlin">Technische Universität Berlin</a>     </div>  <a href="javascript:" class="btn btn-promote btn-large people-item-contact-author js-contact-author">Message author</a>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>  <li id="rgw11_56ab1dd57cd9f" itemprop="author" itemscope itemtype="http://schema.org/Person"> <a itemprop="sameAs" href="profile/Cedric_Archambeau" class="pub-detail-item account-item"> <div class="indent-left"> <div class="people-img"> <img  src="https://i1.rgstatic.net/ii/profile.image/AS%3A272180487389207%401441904293508_m" title="Cedric Archambeau" alt="Cedric Archambeau" height="20px" width="20px" style="height: 20px;"/> </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Cedric Archambeau</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item  remove-action-indent   " id="rgw12_56ab1dd57cd9f" data-account-key="Cedric_Archambeau">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="profile/Cedric_Archambeau"> <img class="lazyload" data-src="https://i1.rgstatic.net/ii/profile.image/AS%3A272180487389207%401441904293508_l" title="Cedric Archambeau" alt="Cedric Archambeau" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">     </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="profile/Cedric_Archambeau" class="display-name">Cedric Archambeau</a>    </h5> <div class="truncate-single-line meta">    <span class="meta">Amazon</span>    </div>  <a href="javascript:" class="btn btn-promote btn-large people-item-contact-author js-contact-author">Message author</a>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>   </ul> <div class="js-loading"></div>  </div> </div> <div class="pub-details js-pub-details">  <div> Department of Computer Science, Technical University Berlin, D-10587 Berlin, Germany.  </div>      <span itemprop="isPartOf" itemscope itemtype="http://schema.org/Periodical"> <a itemprop="sameAs" href="journal/0899-7667_Neural_Computation"><span itemprop="name">Neural Computation</span></a> </span>    (Impact Factor: 2.21).     <meta itemprop="datePublished" content="2008-10">  10/2008;  21(3):786-92.    DOI:&nbsp;10.1162/neco.2008.08-07-592           <div class="pub-source"> Source: <a href="http://www.ncbi.nlm.nih.gov/pubmed/18785854" rel="nofollow">PubMed</a> </div>  </div> <div id="rgw13_56ab1dd57cd9f" class="pub-abstract">  <div class="clearfix">   <p itemprop="description"> <strong>ABSTRACT</strong> <div>The variational approximation of posterior distributions by multivariate gaussians has been much less popular in the machine learning community compared to the corresponding approximation by factorizing distributions. This is for a good reason: the gaussian approximation is in general plagued by an Omicron(N)(2) number of variational parameters to be optimized, N being the number of random variables. In this letter, we discuss the relationship between the Laplace and the variational approximation, and we show that for models with gaussian priors and factorizing likelihoods, the number of variational parameters is actually Omicron(N). The approach is applied to gaussian process regression with nongaussian likelihoods.</div> </p>  </div>   </div>      <div class="action-container"> <div id="rgw14_56ab1dd57cd9f" class="follow-publication-promo"> <table> <tr> <td class="follow-publication-promo-text-cell"> <p>Get notified about updates to this publication</p> <a class="btn btn-large btn-promote js-follow-publication ga-follow-publication-new-promo">Follow publication</a> </td> <td> <div class="follow-publication-publication-image"></div> </td> </tr> </table> </div>  <div class="clear"></div> <div class="share-dialog-container" style="display: none;">  </div> </div> </div> <div style="margin-left: -20px; margin-right: -20px;">  </div> </div>  <div class="publication-detail-dfp-container rf"> <div id="rgw28_56ab1dd57cd9f">  </div> </div>  </div>  <div class="clearfix"> <div class="pdf-js-container clearfix " id="rgw40_56ab1dd57cd9f">  <div class="pdf-js-header js-sticky-header clear">  <a class="blue-link js-download rf btn btn-promote" href="https://www.researchgate.net/profile/Cedric_Archambeau/publication/23252767_The_Variational_Gaussian_Approximation_Revisited/links/0912f50aca8ae75c77000000.pdf?inViewer=0&amp;pdfJsDownload=0&amp;origin=publication_detail">Download full-text</a>  <h3>Full-text</h3> <span class="publication-info">  <span class="js-doi-container" style="display: none;"> DOI: <span class="js-doi"></span> &middot; </span> Available from: <a class="js-name" href="profile/Cedric_Archambeau">Cedric Archambeau</a>   </span>  </div>  <div class="social-share-container"><div id="rgw42_56ab1dd57cd9f" class="social-share js-social-share"> <div class="social-share-heading">Share</div>  <a id="rgw43_56ab1dd57cd9f" href="javascript:" title="Share on Facebook" class="link-nostyle js-share-item share-icon "  data-url="http://www.facebook.com/share.php?u={{url}}{{#title}}&amp;t={{title}}{{/title}}" data-width="600" data-height="350" data-name="Facebook"> <span class="share-icon ico-share-facebook-round reset-background ga-share-blog-facebook"></span> </a>  <a id="rgw44_56ab1dd57cd9f" href="javascript:" title="Share on Twitter" class="link-nostyle js-share-item share-icon "  data-url="http://twitter.com/intent/tweet?text={{#title}}{{title}}: {{/title}}{{url}}&amp;via=researchgate" data-width="600" data-height="350" data-name="Twitter"> <span class="share-icon ico-share-twitter-round reset-background ga-share-blog-twitter"></span> </a>  <a id="rgw45_56ab1dd57cd9f" href="javascript:" title="Share on Google+" class="link-nostyle js-share-item share-icon "  data-url="https://plus.google.com/share?url={{url}}" data-width="600" data-height="600" data-name="Google+"> <span class="share-icon ico-share-gplus-round reset-background ga-share-blog-gplus"></span> </a>  <a id="rgw46_56ab1dd57cd9f" href="javascript:" title="Share on LinkedIn" class="link-nostyle js-share-item share-icon "  data-url="http://www.linkedin.com/shareArticle?mini=true&amp;url={{url}}{{#title}}&amp;title={{title}}{{/title}}&amp;source=ResearchGate" data-width="520" data-height="570" data-name="LinkedIn"> <span class="share-icon ico-share-linkedin-round reset-background ga-share-blog-linkedin"></span> </a>  <a id="rgw47_56ab1dd57cd9f" href="javascript:" title="Share on Reddit" class="link-nostyle js-share-item share-icon "  data-url="https://www.reddit.com/submit?url={{url}}{{#title}}&amp;title={{title}}{{/title}}" data-width="600" data-height="600" data-name="Reddit"> <span class="share-icon ico-share-reddit reset-background ga-share-blog-reddit"></span> </a>  </div></div>    <iframe id="rgw41_56ab1dd57cd9f" src="https://www.researchgate.net/c/o1o9o3/javascript/lib/pdfjs/web/viewer.html?file=https%3A%2F%2Fwww.researchgate.net%2Fprofile%2FCedric_Archambeau%2Fpublication%2F23252767_The_Variational_Gaussian_Approximation_Revisited%2Flinks%2F0912f50aca8ae75c77000000.pdf%3FinViewer%3D1%26pdfJsDownload%3D1%26origin%3Dpublication_detail" allowfullscreen frameborder="0" style="width: 100%; height: 100%; box-sizing: border-box;"></iframe>    </div> <noscript> <div id="rgw27_56ab1dd57cd9f"  itemprop="articleBody">  <p>Page 1</p> <p>The Variational Gaussian Approximation<br />Revisited<br />Manfred Opper∗<br />C´ edric Archambeau†<br />March 16, 2009<br />Abstract<br />The variational approximation of posterior distributions by<br />multivariate Gaussians has been much less popular in the Ma-<br />chine Learning community compared to the corresponding ap-<br />proximation by factorising distributions. This is for a good rea-<br />son: the Gaussian approximation is in general plagued by an<br />O(N2) number of variational parameters to be optimised, N be-<br />ing the number of random variables. In this work, we discuss<br />the relationship between the Laplace and the variational approx-<br />imation and we show that for models with Gaussian priors and<br />factorising likelihoods, the number of variational parameters is<br />actually O(N). The approach is applied to Gaussian process re-<br />gression with non-Gaussian likelihoods.<br />1Introduction<br />The variational approximation is among the most important techniques for<br />treating intractable probabilistic models in the field of Machine Learning.<br />∗Department of Computer, Technical University Berlin, Franklinstr. 28/29, D-10587<br />Berlin, Germany. opperm@cs.tu-berlin.de<br />†Centre for Computational Statistics and Machine Learning, University College Lon-<br />don, Gower Street, London WC1E 6BT. c.archambeau@cs.ucl.ac.uk<br />1</p>  <p>Page 2</p> <p>An intractable probability distribution (usually the Bayesian posterior) is ap-<br />proximated by the closest distribution within a tractable family, where close-<br />ness is defined by the Kullback-Leibler divergence (Kullback &amp; Leibler, 1951).<br />In most applications, the tractable families contain distributions which fac-<br />torize in all or in tractable subgroups of random variables (Beal, 2003; Winn,<br />2003). Hence, the method neglects correlations between variables which may<br />be crucial in the learning of the hyperparameters.<br />If the random variables are continuous and unconstrained, the family of<br />multivariate Gaussian densities suggests itself as a natural alternative to fac-<br />torizing densities, allowing incorporation of correlations. Nevertheless, such<br />a variational Gaussian approximation has been applied, to our knowledge,<br />only a few times to problems in Machine Learning (e.g., Barber and Bishop<br />(1998), Seeger (2000), Honkela and Valpola (2005)). One possible expla-<br />nation is that the covariance matrix of the Gaussian requires a number of<br />variational parameters to be optimised, which scales quadratically with the<br />number of latent variables in the model.<br />However, we show that this prejudice against the variational Gaussian ap-<br />proximation is not always justified. We derive the exact fixed point conditions<br />for the optimal setting of the variational parameters and find that for certain<br />classes of probabilistic models, related to Gaussian processes (O’Hagan, 1978;<br />Rasmussen &amp; Williams, 2006), the number of free variational parameters will<br />be only 2N. While this fact seems to be known, at least in some parts of<br />the Machine Learning community (Seeger, 1999, p. 119), several discussions<br />have shown that many researchers were not aware of this result. We will<br />demonstrate the method only on toy regression problems. Our results have<br />also motivated the inclusion of the variational Gaussian approach within a<br />larger study of different methods for classification with Gaussian processes<br />(Nickisch &amp; Rasmussen, 2008). In this complementary work a variety of<br />comparisons can be found.<br />2 The variational Gaussian approximation<br />We consider probabilistic models for a set of observations y = (y1,...,yM)?<br />and a set of latent, unobserved random variables x = (x1,...,xN)?defined<br />by a joint probability distribution p(y,x|θ), where θ denotes a set of hyper-<br />parameters. We aim to approximate the posterior density p(x|y,θ) =<br />by a density q(x), which belongs to a family of tractable densities. The op-<br />p(y,x|θ)<br />p(y|θ)<br />2</p>  <p>Page 3</p> <p>timal q(x) is chosen to minimise the variational free energy<br />F(q,θ) = −lnp(y|θ) + KL[q?p], (1)<br />where KL[q?p] =?q(x)ln<br />of the observations and can be used to estimate hyperparameters by a vari-<br />ational EM algorithm (Dempster et al., 1977; Neal &amp; Hinton, 1998).<br />If we restrict the approximate posterior q(x) to be a multivariate Gaussian<br />with mean µ and covariance Σ, i.e.<br />q(x)<br />p(x|y,θ)dx is the Kullback-Leibler (KL) divergence.<br />The free energy is an upper bound to the negative log-marginal probability<br />q(x) = (2π)−N/2|Σ|−1<br />2e−1<br />2(x−µ)?Σ−1(x−µ),(2)<br />we get<br />F(q,θ) = − ?lnp(x,y|θ)?q−N<br />2ln2πe −1<br />2ln|Σ|.(3)<br />Hence, setting the derivatives of F(q,θ) with respect to the variational pa-<br />rameters equal to zero leads to<br />0 = ∇µ?lnp(x,y|θ)?q<br />In general, this will require the computation of N(N + 3)/2 free variational<br />parameters, which is much larger than the typically O(N) number of param-<br />eters often required for factorising variational distributions.<br />andΣ−1= −2∇Σ?lnp(x,y|θ)?q.(4)<br />General properties<br />The variational Gaussian approach can be compared to the well-known Laplace<br />approximation, where the mean of a Gaussian density is fitted locally at a<br />point x which maximises the posterior p(x|y,θ). The covariance is then built<br />from the curvature of the log-posterior at the maximum. Hence, we have<br />0 = ∇xlnp(x,y|θ)<br />By contrast, (4) can be rewritten in two different ways using (18) and (19)<br />andΣ−1= −∇x∇xlnp(x,y|θ). (5)<br />0 = ∇µ?lnp(x,y|θ)?q= ?∇xlnp(x,y|θ)?q,<br />Σ−1= −∇µ∇µ?lnp(x,y|θ)?q= −?∇x∇xlnp(x,y|θ)?q.<br />(6)<br />(7)<br />3</p>  <p>Page 4</p> <p>The second set of equalities on both lines shows that we have a global ap-<br />proximation: the conditions of the Laplace approximation hold on average.<br />Another interpretation comes from the first set of equalities. Here we see that<br />the variational Gaussian method is equivalent to applying Laplace’s method<br />to a new (implicitly defined) probability density ˜ q(µ) ∝ e?lnp(x,y|θ)?q, which<br />is defined over the space of parameters µ.<br />3 Gaussian prior models<br />We will now specialise to a class of models which are of the following form:<br />p(x,y|θ) =<br />1<br />Z0e−P<br />nVn−1<br />2x?K−1x,(8)<br />where K is a positive definite matrix, Vnis a shorthand notation for V (yn,xn)<br />and Z0is the normalization constant (including the factor |K|1/2). A typical<br />application is inference with Gaussian process (GP) models (O’Hagan, 1978;<br />Rasmussen &amp; Williams, 2006), where x = (x(s1),...,x(sN))?denotes the<br />values of a latent function x(s) at inputs s1,...,sN, K is the kernel matrix<br />and Vn= −lnp(yn|xn) denotes the negative log-likelihood.<br />From (8), we get<br />F(q,θ) =<br />?<br />+ lnZ0−N<br />n<br />?Vn?qn+1<br />2tr{K−1Σ} +1<br />2µ?K−1µ −1<br />2ln|Σ|<br />2ln2πe, (9)<br />where ? · ?qnindicates that the expectation is taken with respect to the<br />marginal q(xn), the univariate Gaussian with mean µnand variance Σnn.<br />Each term ?Vn?qndepends only on the mean µnand the diagonal element<br />Σnnof the full covariance Σ. As a result, the second equation in (4) shows<br />that the nondiagonal elements of Σ−1are simply equal to those of K−1and<br />that the optimal covariance will be of the form<br />Σ =?K−1+ Λ?−1,<br />where Λ is a diagonal matrix with λ ≡ ( ... λn ... )?on its diagonal.<br />Hence, we can use the N elements λnas new parameters. We found it also<br />useful to represent the mean parameters in the form µ = Kν with a vector<br />(10)<br />4</p>  <p>Page 5</p> <p>ν of N new effective parameters. Inserting these definitions into the free<br />energy, a short calculation shows that the gradients of the free energy with<br />respect to the new 2N parameters are given by<br />gν≡ ∇νF(q,θ) = K(ν − ¯ ν),<br />gλ≡ ∇λF(q,θ) =1<br />(11)<br />2(Σ ◦ Σ)(λ −¯λ),(12)<br />where ◦ denotes the Hadamard product. ¯ ν ≡ ( ... − ∂ ?Vn?qn/∂µn ... )?<br />and where¯λ ≡ ( ... 2∂ ?Vn?qn/∂Σnn ... )?. We use these gradients within<br />a nonlinear conjugate gradient method with back-tracking (Hager &amp; Zhang,<br />2005) to optimise the parameters.<br />One could generalize this approach to models where only a few of the<br />likelihood terms depend on more than a single variable. In this case as well,<br />a relatively small number of variational parameters would have to be be<br />optimised.<br />Derivatives of the Gaussian expectations<br />The computation of the gradients requires explicit expressions for ?Vn?qn<br />for which there is often no analytical solution. However, one can circum-<br />vent this problem by using the Gaussian identities (18) and (19), along with<br />?<br />−¯ νn=∂ ?Vn?qn<br />∂µn<br />∂xn<br />qn<br />¯λn<br />2∂Σnn<br />2 ∂x2<br />n<br />qn<br />∂Vn<br />∂xn<br />?<br />Σnn= ?(xn− µn)Vn?:<br />=<br />?∂Vn<br />=1<br />?<br />=?(xn− µn)Vn?qn<br />Σnn<br />?<br />,(13)<br />=∂ ?Vn?qn<br />?∂2Vn<br />=?(xn− µn)2Vn?qn− Σnn?Vn?qn<br />2Σ2<br />nn<br />. (14)<br />As a consequence, the evaluation of these expectations does not require to<br />compute the first and second order derivatives of Vn explicitly. They can<br />either be naively estimated by sample averages, the samples being generated<br />from the univariate Gaussian marginals qn, or by more elaborate techniques<br />such as Gauss-Hermite quadrature (Liu &amp; Pierce, 1994), provided Vnsatisfies<br />some smoothness properties.<br />5</p>  <p>Page 6</p> <p>4 Application to robust Gaussian process re-<br />gression<br />We test our approach on the Boston housing regression data. The aim is to<br />predict the median value of a home. The input data is 13-dimensional. More<br />information on this data set can be found at http://lib.stat.cmu.edu/datasets/.<br />We investigate two noise models, Laplace and Cauchy noise, which have heav-<br />ier tails compared to a simple Gaussian and are thus expected to be less<br />sensitive to outliers. The likelihoods are respectively given by<br />p(y|x,η) =η<br />2e−η|y−x|<br />andp(y|f,γ) =<br />1<br />πγ<br />?<br />1 +(y − x)2<br />γ2<br />?−1<br />, (15)<br />where η &gt; 0 and γ &gt; 0 are the noise parameters. In order to estimate the<br />kernel parameters, which we denote by θ = {θi}i, and the noise parameters,<br />we resort to gradient descent algorithms (Nocedal &amp; Wright, 2000). The<br />gradient of the variational free energy w.r.t. θiis given by<br />??¯ ν¯ ν?−¯B−1?∂K<br />where¯Λ is a diagonal matrix with¯λ on its diagonal. When computing this<br />gradient, we have kept the variational parameters fixed, that is ν = ¯ ν and<br />Λ =¯Λ. The reason is that the implicit derivatives vanish at ¯ ν and¯Λ,<br />which are stationary points of the free energy F(q,θ). The overall training<br />algorithm requires thus to perform an inner and an outer optimization loop.<br />After each gradient step (16), one needs to recompute ¯ ν and¯Λ using (11)<br />and (12). To compute approximate predictions for x(s∗) at inputs s∗which<br />are not in the training set using the approximate Gaussian on x, we follow<br />Rasmussen and Williams (2006, p. 44).<br />Table 1 shows the average test mean squared error (MSE) and the 1-<br />standard deviation of the MSE for the standard GP, the variational Gaus-<br />sian approximation assuming Laplace noise and the variational Gaussian<br />approximation assuming Cauchy noise. All models use a squared exponen-<br />tial kernel function with common length scale and common multiplicative<br />constant. The standard GP assumes additive Gaussian noise with variance<br />σ2. All hyperparameters are optimised by gradient techniques. We use 5-fold<br />cross-validation to estimate the MSE. It can be observed from Table 1 that<br />gθi= −1<br />2tr∂θi<br />?<br />,<br />¯B = K +¯Λ−1,(16)<br />6</p>  <p>Page 7</p> <p>Table 1: Average test mean squared error (MSE) and 1-standard deviation<br />of the MSE for the Boston housing data. See text for details.<br />likelihood<br />boston<br />Cauchy<br />47.92 ± 16.13<br />Laplace<br />42.35 ± 13.65<br />Gaussian<br />53.75 ± 22.02<br />both variational Gaussian approximations outperform the standard GP. As-<br />suming Laplace distributed noise seems to be advantageous over the Cauchy<br />noise, suggesting that there are no strong outliers in the data.<br />5Conclusion<br />In this paper, we have reconsidered the variational Gaussian approximation.<br />We have clarified its relation to the Laplace approximation. We have shown<br />that it is a tractable approach at least for models with Gaussian priors and<br />factorising likelihoods, which naturally occur within the Gaussian process<br />framework. We have also discussed several ways to compute the Gaussian<br />expectations. The variational Gaussian approximation may also be natu-<br />rally combined with variational sparse Gaussian approximations in order to<br />speed up the inference for large datasets. We will give such extensions and<br />comparisons of the method with other techniques in a forthcoming paper.<br />A Appendix<br />Derivatives of multivariate Gaussian expectations with respect to the mean µ<br />and the covariance Σ are most conveniently computed using the characteristic<br />function G(k) = ?eik?x?q= e−1<br />standard Fourier analysis, we can express expectations of any function V (x)<br />as<br />?<br />=<br />(2π)n<br />2k?Σk+ik?µof the Gaussian measure q. Using<br />?V (x)?q=<br />1<br />(2π)n<br />1<br />G(k)e−ik?yV (y) dy dk<br />?<br />e−1<br />2k?Σk+ik?(µ−y)V (y) dy dk. (17)<br />7</p>  <p>Page 8</p> <p>This shows that any derivative with respect to µ is equivalent to (−) the<br />derivative of the exponential under the integral with respect to y. This in<br />turn, using integrations by parts with respect to y, yields<br />∇µ?V (x)?q= ?∇xV (x)?q<br />∇Σ?V (x)?q=1<br />(18)<br />2?∇x∇xV (x)?q=1<br />2∇µ∇µ?V (x)?q. (19)<br />where the second equality in the last line follows from the first line.<br />References<br />Barber, D., &amp; Bishop, C. M. (1998). Ensemble learning for Multi-Layer<br />Networks. Advances in Neural Information Processing Systems 10 (NIPS).<br />The MIT Press.<br />Beal, M. J. (2003). Variational algorithms for approximate Bayesian in-<br />ference. Doctoral dissertation, Gatsby Computational Neuroscience Unit,<br />University College London, United Kingdom.<br />Dempster, A. P., Laird, N. M., &amp; Rubin, D. B. (1977). Maximum likelihood<br />from incomplete data via EM algorithm. Journal of the Royal Statistical<br />Society B, 39, 1–38.<br />Hager, W. W., &amp; Zhang, H. (2005).<br />with guaranteed descent and an efficient line search. SIAM Journal on<br />Optimization, 16, 170–192.<br />A new conjugate gradient method<br />Honkela, A., &amp; Valpola, H. (2005). Unsupervised variational Bayesian learn-<br />ing of nonlinear models. Advances in Neural Information Processing Sys-<br />tems 17 (NIPS) (pp. 593 – 600). The MIT Press.<br />Kullback, S., &amp; Leibler, R. A. (1951). On information and sufficiency. Annals<br />of Mathematical Statistics, 22, 79–86.<br />Liu, Q., &amp; Pierce, D. A. (1994).<br />Biometrika, 81, 624–629.<br />A note on Gauss-Hermite quadrature.<br />Neal, R. M., &amp; Hinton, G. E. (1998). A view of the EM algorithm that<br />justifies incremental, sparse, and other variants. In M. I. Jordan (Ed.),<br />Learning in graphical models, 355–368. The MIT press.<br />8</p>  <p>Page 9</p> <p>Nickisch, H., &amp; Rasmussen, C. E. (2008). Approximations for binary Gaus-<br />sian process classification. Journal of Machine Learning Research. Sub-<br />mitted.<br />Nocedal, J., &amp; Wright, S. J. (2000). Numerical optimization. Springer.<br />O’Hagan, A. (1978). Curve fitting and optimal design for prediction. Journal<br />of the Royal Statistical Society B, 40, 1–42.<br />Rasmussen, C. E., &amp; Williams, C. K. I. (2006).<br />machine learning. Cambridge, Massachusetts: The MIT Press.<br />Gaussian processes for<br />Seeger, M. (1999). Bayesian methods for support vector machines and Gaus-<br />sian processes. Master’s thesis, University of Karlsruhe, Germany.<br />Seeger, M. (2000). Bayesian model selection for support vector machines,<br />Gaussian processes and other kernel classifiers. Advances in Neural Infor-<br />mation Processing Systems 12 (NIPS) (pp. 603–609). The MIT Press.<br />Winn, J. (2003). Variational message passing and its applications. Doc-<br />toral dissertation, Department of Physics, University of Cambridge, United<br />Kingdom.<br />9</p>  <a href="https://www.researchgate.net/profile/Cedric_Archambeau/publication/23252767_The_Variational_Gaussian_Approximation_Revisited/links/0912f50aca8ae75c77000000.pdf">Download full-text</a> </div> <div id="rgw19_56ab1dd57cd9f" class="c-box pub-resource-container js-toggle" style=""> <h4 class="lf js-expand-list"><small><a href="javascript:" class="lf">View other sources <span class="ico-expand-list"></span></a></small></h4> <h4 class="lf js-collapse-list hidden"><small><a href="javascript:" class="lf">Hide other sources <span class="ico-collapse-list"></span></a></small></h4> <div class="clear"></div> <div class="scroll-wrapper hidden"> <ul class="files-list c-list" id="rgw20_56ab1dd57cd9f">  <li class="c-list-item pub-resource-item"  data-type="fulltext" id="rgw21_56ab1dd57cd9f"> <span class="ico-pub"></span> <div class="file-content"> <div class="download"> <a href="profile/Cedric_Archambeau/publication/23252767_The_Variational_Gaussian_Approximation_Revisited/links/0912f50aca8ae75c77000000.pdf" class="publication-viewer" title="download.pdf">download.pdf</a> </div>  <div class="details">  <span> Available from <a href="profile/Cedric_Archambeau">Cedric Archambeau</a> &middot; Jan 20, 2016 </span>   </div>    </div> </li>  <li class="c-list-item pub-resource-item"  data-type="fulltext" id="rgw22_56ab1dd57cd9f"> <span class="ico-pub"></span> <div class="file-content"> <div class="download"> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.154.9381&amp;amp;rep=rep1&amp;amp;type=pdf" target="_blank" rel="nofollow" class="publication-viewer" title="The Variational Gaussian Approximation Revisited">The Variational Gaussian Approximation Revisited</a> </div>  <div class="details">   Available from <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.154.9381&amp;amp;rep=rep1&amp;amp;type=pdf" target="_blank" rel="nofollow">psu.edu</a>  </div>    </div> </li>  </ul> </div> </div> </noscript> <div class="clearfix"> <div class="action-container">  </div> <div class="pub-legal"> Data provided are for informational purposes only. Although carefully collected, accuracy cannot be guaranteed. The impact factor represents a rough estimation of the journal's impact factor and does not reflect the actual current impact factor. Publisher conditions are provided by RoMEO. Differing provisions from the publisher's actual policy or licence agreement may be applicable. </div>  <div id="rgw29_56ab1dd57cd9f" class="citations-container"> <div class="tab-container"> <ul class="tab-list"> <li class="lf tab-item  js-citations"> <a href="javascript:void(0);" class="tab-link"> References  </small> </a> </li>  <li class="lf tab-item tab-item-active js-cited-in js-cited-in-tooltip"> <a href="javascript:void(0);" class="tab-link"> Cited In <small> (39) </small> </a> </li>    <li class="rf"> <div class="dropdown js-citations-sorter dropdown-right-align" style="position: relative; bottom: -1px;display:none;"> <a href="javascript:void(0);" class="dropdown-toggle"> Sorted by: <strong class="js-current-sorting"> Order of availability  </strong> <span class="caret"></span> </a> <ul class="dropdown-menu"> <li><a href="javascript:void(0);" data-sort="normal">Order of availability</a></li> <li><a href="javascript:void(0);" data-sort="original">Appearance in publication</a></li> </ul> </div> </li>  </ul> <div class="tab-section tab-section-active js-citations-list-container"> <div id="rgw30_56ab1dd57cd9f" class="pub-citations-list">  <ul class="c-list">  <li class="c-list-item li-publication   includes-citation-list"  id="rgw31_56ab1dd57cd9f" >  <div class="indent-left">  <div id="rgw32_56ab1dd57cd9f" class="js-publication-item-fulltext fulltext-thumb">    <a class="publication-preview ga-publication-viewer js-publication-item-fulltext-content" href="publication/286094850_Expectation_Propagation_for_Rectified_Linear_Poisson_Regression">       </a>   <div class="preview-source-info"> <a class="details js-show-source ga-source-url" href="deref/http%3A%2F%2Finfoscience.epfl.ch%2Frecord%2F214372%2Ffiles%2FKo49.pdf" target="_blank" >Source</a>  <div class="tooltip-content" style="display: none"> Available from: infoscience.epfl.ch </div> </div>   </div>  </div>  <div class="indent-right">      </div>  <ul class="citation-contexts" id="rgw33_56ab1dd57cd9f">  <li class="citation-context-item"> "While Laplace&#39;s method is the preferred method in the GP setting (Park and Pillow, 2013; Diggle et al., 2013; Park et al., 2014), it cannot be applied to SLMs, because by design we expect many transform coefficients to be zero, where the Laplace potential is not differentiable. Another popular variational Bayesian (VB) technique is referred to as Variational Gaussian approximation (Opper and Archambeau, 2009) or KL method (Nickisch and Rasmussen, 2008; Challis and Barber, 2013). It is analytically tractable for the exponential function (Ko and Khan, 2014), whereas the softplus function requires approximations , e.g. " </li>  </ul>   <div  style="margin-top: -2px">  <h5 class="pub-type-and-title">  <span class="publication-type">Article:</span>    <a class="js-publication-title-link js-go-to-publication ga-publication-item" href="publication/286094850_Expectation_Propagation_for_Rectified_Linear_Poisson_Regression"> <span class="publication-title js-publication-title">Expectation Propagation for Rectified Linear Poisson Regression</span> </a>     </h5>  </div>    <div class="authors">     <a href="researcher/80788842_Young_Jun_Ko" class="authors js-author-name ga-publications-authors">Young Jun Ko</a> &middot;     <a href="researcher/2009110960_Matthias_Seeger" class="authors js-author-name ga-publications-authors">Matthias Seeger</a>      </div>        <div class="abstract"> <span class="shorten"> <a href="javascript:" class="js-toggle-abstract">[Show abstract]</a> </span> <span class="full"> <a href="javascript:" class="js-toggle-abstract">[Hide abstract]</a><br/>  <strong>ABSTRACT:</strong> The Poisson likelihood with rectified linear function as non-linearity is a physically plausible model to discribe the stochastic arrival process of photons or other particles at a detector. At low emission rates the discrete nature of this process leads to measurement noise that behaves very differently from additive white Gaussian noise. To address the intractable inference problem for such models, we present a novel efficient and robust Expectation Propagation algorithm entirely based on analytically tractable computations operating re- liably in regimes where quadrature based implementations can fail. Full posterior inference therefore becomes an attractive alternative in areas generally dominated by methods of point estimation. Moreover, we discuss the rectified linear function in the context of other common non-linearities and identify situations where it can serve as a robust alternative. </span> </div>    <div class="publication-meta publication-meta">  <span class="ico-publication-preview reset-background"></span> Preview    &middot; Article &middot; Jan 2015  </div>        <div class="publication-actions"> <div class="btn-group">  <a class="btn btn-plain action-request-external  " href="javascript:;" data-context="pubCit">  <span class="js-btn-label">Request full-text</span> </a>    </div> </div>      </li>  <li class="c-list-item li-publication   includes-citation-list"  id="rgw34_56ab1dd57cd9f" >  <div class="indent-left">  <div id="rgw35_56ab1dd57cd9f" class="js-publication-item-fulltext fulltext-thumb">    <a class="publication-preview ga-publication-viewer js-publication-item-fulltext-content" href="publication/270222737_Gaussian_Process_Pseudo-Likelihood_Models_for_Sequence_Labeling">       </a>   <div class="preview-source-info"> <a class="details js-show-source ga-source-url" href="profile/P_Balamurugan" >Source</a>  <div class="tooltip-content" style="display: none"> Available from: P. Balamurugan </div> </div>   </div>  </div>  <div class="indent-right">      </div>  <ul class="citation-contexts" id="rgw36_56ab1dd57cd9f">  <li class="citation-context-item"> "Variational Gaussian approaches can be slow because of the requirement to estimate the covariance matrix. Fortunately, recent advances in VG inference approaches (Opper and Archambeau, 2009) enable one to compute the covariance matrix using O(N L) variational parameters. In fact, we use the VG approach for GPs (Khan et al., 2012) which requires computation of only O(N L) variational parameters, but at the same time uses a concave variational lower bound. " </li>  </ul>   <div  style="margin-top: -2px">  <h5 class="pub-type-and-title">  <span class="publication-type">Article:</span>    <a class="js-publication-title-link js-go-to-publication ga-publication-item" href="publication/270222737_Gaussian_Process_Pseudo-Likelihood_Models_for_Sequence_Labeling"> <span class="publication-title js-publication-title">Gaussian Process Pseudo-Likelihood Models for Sequence Labeling</span> </a>     </h5>  </div>    <div class="authors">     <a href="researcher/2047892358_P_K_Srijith" class="authors js-author-name ga-publications-authors">P. K. Srijith</a> &middot;     <a href="researcher/2059997535_P_Balamurugan" class="authors js-author-name ga-publications-authors">P. Balamurugan</a> &middot;     <a href="researcher/35397864_Shirish_Shevade" class="authors js-author-name ga-publications-authors">Shirish Shevade</a>      </div>        <div class="abstract"> <span class="shorten"> <a href="javascript:" class="js-toggle-abstract">[Show abstract]</a> </span> <span class="full"> <a href="javascript:" class="js-toggle-abstract">[Hide abstract]</a><br/>  <strong>ABSTRACT:</strong> Several machine learning problems arising in natural language processing can
be modeled as a sequence labeling problem. We provide Gaussian process models
based on pseudo-likelihood approximation to perform sequence labeling. Gaussian
processes (GPs) provide a Bayesian approach to learning in a kernel based
framework. The pseudo-likelihood model enables one to capture long range
dependencies among the output components of the sequence without becoming
computationally intractable. We use an efficient variational Gaussian
approximation method to perform inference in the proposed model. We also
provide an iterative algorithm which can effectively make use of the
information from the neighboring labels to perform prediction. The ability to
capture long range dependencies makes the proposed approach useful for a wide
range of sequence labeling problems. Numerical experiments on some sequence
labeling data sets demonstrate the usefulness of the proposed approach. </span> </div>    <div class="publication-meta publication-meta">   <span class="ico-publication-fulltext reset-background"></span> Full-text   &middot; Article &middot; Dec 2014  </div>        <div class="publication-actions"> <div class="btn-group">  <a class="btn btn-plain action-download primary  open-viewer" href="profile/P_Balamurugan/publication/270222737_Gaussian_Process_Pseudo-Likelihood_Models_for_Sequence_Labeling/links/55f9a40608aeba1d9f1f3b0e.pdf?origin=publication_list">  <span class="js-btn-label">Download</span> </a>    </div> </div>      </li>  <li class="c-list-item li-publication   includes-citation-list"  id="rgw37_56ab1dd57cd9f" >  <div class="indent-left">  <div id="rgw38_56ab1dd57cd9f" class="js-publication-item-fulltext fulltext-thumb">    <a class="publication-preview ga-publication-viewer js-publication-item-fulltext-content" href="publication/260289417_Integrated_Non-Factorized_Variational_Inference">       </a>   <div class="preview-source-info"> <a class="details js-show-source ga-source-url" href="profile/Shaobo_Han" >Source</a>  <div class="tooltip-content" style="display: none"> Available from: Shaobo Han </div> </div>   </div>  </div>  <div class="indent-right">      </div>  <ul class="citation-contexts" id="rgw39_56ab1dd57cd9f">  <li class="citation-context-item"> "Based on the Laplace approximation [3], INLA seeks a Gaussian distribution q G (x|y, θ k ) = N (x; x * (θ k ), H(x * (θ k )) −1 ), ∀θ k ∈ G that captures most of the probabilistic mass locally, where x * (θ k ) = argmax x p(x|y, θ k ) is the posterior mode, and H(x * (θ k )) is the Hessian matrix of the log posterior evaluated at the mode. By contrast, INF-VB with the Gaussian parametric constraint on q (x|y, θ k ) provides a global variational Gaussian approximation q V G (x|y, θ k ) in the sense that the conditions of the Laplace approximation hold on average [17]. As we will see next, the averaging operator plays a crucial role in handling the non-differentiable 1 norm arising from the double-exponential priors. " </li>  </ul>   <div  style="margin-top: -2px">  <h5 class="pub-type-and-title">  <span class="publication-type">Conference Paper:</span>    <a class="js-publication-title-link js-go-to-publication ga-publication-item" href="publication/260289417_Integrated_Non-Factorized_Variational_Inference"> <span class="publication-title js-publication-title">Integrated Non-Factorized Variational Inference</span> </a>     </h5>  </div>    <div class="authors">     <a href="researcher/2044132067_Shaobo_Han" class="authors js-author-name ga-publications-authors">Shaobo Han</a> &middot;     <a href="researcher/2006243672_Xuejun_Liao" class="authors js-author-name ga-publications-authors">Xuejun Liao</a> &middot;     <a href="researcher/10135830_Lawrence_Carin" class="authors js-author-name ga-publications-authors">Lawrence Carin</a>      </div>        <div class="abstract"> <span class="shorten"> <a href="javascript:" class="js-toggle-abstract">[Show abstract]</a> </span> <span class="full"> <a href="javascript:" class="js-toggle-abstract">[Hide abstract]</a><br/>  <strong>ABSTRACT:</strong> We present a non-factorized variational method for full posterior inference in Bayesian hierarchical models, with the goal of capturing the posterior variable de-pendencies via efficient and possibly parallel computation. Our approach unifies the integrated nested Laplace approximation (INLA) under the variational frame-work. The proposed method is applicable in more challenging scenarios than typ-ically assumed by INLA, such as Bayesian Lasso, which is characterized by the non-differentiability of the 1 norm arising from independent Laplace priors. We derive an upper bound for the Kullback-Leibler divergence, which yields a fast closed-form solution via decoupled optimization. Our method is a reliable ana-lytic alternative to Markov chain Monte Carlo (MCMC), and it results in a tighter evidence lower bound than that of mean-field variational Bayes (VB) method. </span> </div>    <div class="publication-meta publication-meta">   <span class="ico-publication-fulltext reset-background"></span> Full-text   &middot; Conference Paper &middot; Dec 2013  </div>        <div class="publication-actions"> <div class="btn-group">  <a class="btn btn-plain action-download primary  open-viewer" href="profile/Shaobo_Han/publication/260289417_Integrated_Non-Factorized_Variational_Inference/links/0a85e5308f8849bfe7000000.pdf?origin=publication_list">  <span class="js-btn-label">Download</span> </a>    </div> </div>      </li>  </ul>    <a class="show-more-rebranded js-show-more rf text-gray-lighter">Show more</a> <span class="ajax-loading-small list-loading" style="display: none"></span>  <div class="clearfix"></div>  <div class="publication-detail-sidebar-legal">Note: This list is based on the publications in our database and might not be exhaustive.</div> <div class="clearfix"></div>  </div> </div> </div> </div> </div> </div> <div class="clearfix">     <div id="rgw24_56ab1dd57cd9f" class="c-box pub-resource-container js-toggle" style="display: none;"> <h4 class="lf js-expand-list"><small><a href="javascript:" class="lf">View other sources <span class="ico-expand-list"></span></a></small></h4> <h4 class="lf js-collapse-list hidden"><small><a href="javascript:" class="lf">Hide other sources <span class="ico-collapse-list"></span></a></small></h4> <div class="clear"></div> <div class="scroll-wrapper hidden"> <ul class="files-list c-list" id="rgw25_56ab1dd57cd9f">  </ul> </div> </div>   <div id="rgw15_56ab1dd57cd9f" class="similar-publications"> <h2>Similar Publications</h2> <ul class="list-bordered">  <li class="c-list-item li-publication-teaser" id="rgw16_56ab1dd57cd9f"> <div> <h5> <a href="publication/290431543_Histogram-Based_Discrimination_of_Intravenous_Contrast_in_Abdominopelvic_Computed_Tomography" class="color-inherit ga-similar-publication-title"><span class="publication-title">Histogram-Based Discrimination of Intravenous Contrast in Abdominopelvic Computed Tomography</span></a>  </h5>  <div class="authors"> <a href="researcher/2093895522_Phillip_M_Cheng" class="authors ga-similar-publication-author">Phillip M Cheng</a>  </div>  </div> <div class="clear"></div> </li>  <li class="c-list-item li-publication-teaser" id="rgw17_56ab1dd57cd9f"> <div> <h5> <a href="publication/289587204_State_Space_representation_of_non-stationary_Gaussian_Processes" class="color-inherit ga-similar-publication-title"><span class="publication-title">State Space representation of non-stationary Gaussian Processes</span></a>  </h5>  <div class="authors"> <a href="researcher/33382619_Alessio_Benavoli" class="authors ga-similar-publication-author">Alessio Benavoli</a>, <a href="researcher/10654903_Marco_Zaffalon" class="authors ga-similar-publication-author">Marco Zaffalon</a>  </div>  </div> <div class="clear"></div> </li>  <li class="c-list-item li-publication-teaser" id="rgw18_56ab1dd57cd9f"> <div> <h5> <a href="publication/287249271_Probabilistic_Programming_with_Gaussian_Process_Memoization" class="color-inherit ga-similar-publication-title"><span class="publication-title">Probabilistic Programming with Gaussian Process Memoization</span></a>  </h5>  <div class="authors"> <a href="researcher/2034167984_Ulrich_Schaechtle" class="authors ga-similar-publication-author">Ulrich Schaechtle</a>, <a href="researcher/2089456342_Ben_Zinberg" class="authors ga-similar-publication-author">Ben Zinberg</a>, <a href="researcher/2089399536_Alexey_Radul" class="authors ga-similar-publication-author">Alexey Radul</a>, <a href="researcher/8074903_Kostas_Stathis" class="authors ga-similar-publication-author">Kostas Stathis</a>, <a href="researcher/2089392273_Vikash_K_Mansinghka" class="authors ga-similar-publication-author">Vikash K. Mansinghka</a>  </div>  </div> <div class="clear"></div> </li>  </ul> </div> </div> </div> </div> </div></div></div>
<div class="clear"></div><div id="rgw49_56ab1dd57cd9f" class="default-footer"> <div id="footer" class="clearfix"> <span class="footer-left"> &copy; 2008&dash;2016 researchgate.net. All rights reserved. </span> <span class="footer-right"> <a href="https://www.researchgate.net/about">About us</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="https://www.researchgate.net/contact">Contact us</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="careers">Careers</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="developers">Developers</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="blog" target="_blank">News</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="application.PrivacyPolicy.html">Privacy</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="application.TermsAndConditions.html">Terms</a> <span class="footer-link-separator" style="padding: 0 5px;">&nbsp;|&nbsp;</span> <a href="advertising?_ref=ft">Advertising</a> <span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="recruiters?_ref=ft">Recruiting</a> </span> </div>  </div></div>
<div id="rgw50_56ab1dd57cd9f">  <div class="header-wrapper-logged-out"> <div id="header"> <div class="header-content"> <a href="" class="g-l-logo"> <svg width="149" height="19"> <image xlink:href="https://c5.rgstatic.net/m/235107188705592/images/template/brand-header-logo.svg" src="https://c5.rgstatic.net/m/238113351022438/images/template/brand-header-logo.png" width="149" height="19"/> </svg> </a> <a href="" class="g-l-logo-ico"> <svg width="127" height="17" viewbox="0 0 127 22"> <image xlink:href="https://c5.rgstatic.net/m/235107188705592/images/template/brand-header-logo.svg" src="https://c5.rgstatic.net/m/238113351022438/images/template/brand-header-logo.png" width="127" height="17"/> </svg> </a> <div id="rgw51_56ab1dd57cd9f" class="header-login-wrapper js-header-login"> <div class="dropdown-right-align"> <div class="login-signup-container lf"> <a href="https://www.researchgate.net/signup.SignUp.html?ev=su_chnl_index&amp;hdrsu=1&amp;_sg=FLgAj8w-GQQd78l5KB8-Ea2syiuqwelGFAmG3lrpYlYTbO5LnJ_EhC0fHwKqV9XW" class="dropdown-toggle lf">Join for free</a> </div> <div class="dropdown lf" style="height: 20px;"> <a href="https://www.researchgate.net/application.Login.html" class="js-login-url dropdown-toggle lf">Log in <span class="caret"></span></a> <div class="dropdown-menu"> <div class="header-login-form-wrapper"> <!--[if IE 6]><p class="box-warning" style="margin-bottom: 0;">Sorry, ResearchGate no longer supports the version of Internet Explorer you are using. <a href="http://whatbrowser.org/" rel="nofollow" target="_blank">Update your web browser</a> and then log in. </p><![endif]--> <form method="post" action="https://www.researchgate.net/application.Login.html" class="form-big header-login-form js-login-form" name="loginForm" id="headerLoginForm"> <input type="hidden" name="request_token" value="y7lUdnCpewh8r+qXSjRwhOrAdcggKTmjxqk7FlKDvFXaeFWBLFFpz70WZ8WkVXMoEcMoPAFW+xKt+3rqryNp6JMJS0NehoFL+pvhHeamJaTxVoYqgBE0TSJTGT1EGzm4KutvFN2xLCBVKBZKUH3DPl0eLBZtA2HaQWOsCgFXmDgK01I/uF+hhwdd4rRUf+hi1EWh8qTvKn8lq2gHk5NnejCBlZ6aWq+dlybcnAtbRLb6jInAyI8rLuhw8qtOUoJyxxXpoDiU5xxmQ23LKT/dApWBN/Jbw03tPv6f48aqStg="/> <input type="hidden" name="urlAfterLogin" value="publication/23252767_The_Variational_Gaussian_Approximation_Revisited"/> <input type="hidden" name="invalidPasswordCount" value="0"/> <input type="hidden" name="headerLogin" value="yes"/> <label for="input-header-login">Email</label> <div class="login-input"> <div class="info-tip-wrapper"> <span class="ico-info js-info"></span> </div> <input type="email" value="" name="login" class="login js-login-input text" id="input-header-login" tabindex="1"/> </div> <div class="clear"></div> <label class="lf" for="input-header-password"> Password </label> <a class="rf forgot-password js-forgot-password" href="application.LostPassword.html">Forgot password?</a> <div class="clear"></div> <input type="password" value="" name="password" class="password js-password-input text" id="input-header-password" tabindex="2"/> <div class="clear"></div> <label class="remember-me" for="headerLoginCookie"> <input type="checkbox" checked="checked" value="yes" name="setLoginCookie" class="lf checkbox" id="headerLoginCookie" tabindex="3"/> Keep me logged in </label> <div class="clear"></div> <input value="Log in" name="loginSubmit" class="btn btn-promote btn-fullwidth btn-large allow-leave js-submit-button" type="submit" tabindex="4"/> </form> <div class="connectors"> <div class="text">or log in with</div> <div class="connector-actions"> <a href="connector/linkedin/" class="li-connect js-li-connect" data-redirect-url="cHVibGljYXRpb24vMjMyNTI3NjdfVGhlX1ZhcmlhdGlvbmFsX0dhdXNzaWFuX0FwcHJveGltYXRpb25fUmV2aXNpdGVk"> <span class="icon ico-linkedin-round-grey"></span> <span class="icon ico-linkedin-round"></span> </a> <a href="connector/facebook/" class="fb-connect middle js-fb-connect" data-redirect-url="cHVibGljYXRpb24vMjMyNTI3NjdfVGhlX1ZhcmlhdGlvbmFsX0dhdXNzaWFuX0FwcHJveGltYXRpb25fUmV2aXNpdGVk"> <span class="icon ico-facebook-round-grey"></span> <span class="icon ico-facebook-round"></span> </a> <a href="connector/google/" class="g-connect js-g-connect" data-redirect-url="cHVibGljYXRpb24vMjMyNTI3NjdfVGhlX1ZhcmlhdGlvbmFsX0dhdXNzaWFuX0FwcHJveGltYXRpb25fUmV2aXNpdGVk"> <span class="icon ico-google-round-grey"></span> <span class="icon ico-google-round"></span> </a> </div> </div> </div> </div> </div> </div> </div> </div> </div> <script type="application/ld+json">
{ "@context" : "http://schema.org",
  "@type" : "Organization",
  "name" : "ResearchGate",
  "url" : "http://www.researchgate.net",
  "logo" : "http://www.researchgate.net/images/template/rg_logo_square_brand.png",
  "sameAs" : [ "https://www.facebook.com/ResearchGate",
    "https://twitter.com/ResearchGate",
    "https://plus.google.com/+researchgate",
    "https://www.linkedin.com/company/researchgate"] 
}
</script> </div> </div><div class="c-signup-bar" id="rgw52_56ab1dd57cd9f"> <div class="banner-contents">   <span class="message">ResearchGate is the professional network for scientists and researchers.</span> <a href="signup.SignUp.html?ev=su_banner" class="btn btn-large btn-promote">Join for free</a>  </div> </div></div>
<script>
rgConfig.backendTime = 880;
</script>
<script src="//c5.rgstatic.net/m/2277196935388619/javascript/lib/yui3/yui/yui-min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/2448732603281275/javascript/yuiLoaderConfig-min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/23178613132105398/javascript/vendor/babel-core/browser-polyfill.min.js" type="text/javascript"></script>
<script>
(function (){
if (typeof YRG === "undefined") {
var xmlHttpRequest = new XMLHttpRequest();
xmlHttpRequest.open("post", "go.Error.html");
xmlHttpRequest.setRequestHeader("Content-Type", "application/json");
xmlHttpRequest.setRequestHeader("Accept", "application/json"); var loadedScripts = "";
if (window.performance && window.performance.getEntriesByType) {
    var result = [];
    var resources = performance.getEntriesByType("resource");
    for (var i in resources) {
        if (resources.hasOwnProperty(i)) {
            result.push({
                name: resources[i].name,
                duration: resources[i].duration
            });
        }
    }
    loadedScripts += "&loadedScripts=" + encodeURIComponent(JSON.stringify(result));
}
if (typeof YUI === "undefined") {
    loadedScripts += "&yuiLoaded=false";
} else {
    loadedScripts += "&yuiLoaded=true";
}
xmlHttpRequest.send("Type=InformationException&message=" + encodeURIComponent("Error loading YUI") + loadedScripts);
}
})();
</script>
<script>if (typeof YRG !== 'undefined') { YRG.use('rg-base',function(Y){Y.applyConfig({ignore: ["css-rg","css-rg2","css-ie","css-modules-publicprofile","css-pow-publicliterature-FollowPublicationPromo","css-pow-application-PdfJsReader","css-pow-publicliterature-PublicationInlineReader"]});Y.use(["rg.core.pagespeed.Monitoring"],function(Y){(function(){Y.rg.createInitialWidget({"data":{"content":{"data":{"profileSmallHeader":{"data":{"profileBadge":{"data":{"fullname":"Manfred Opper","imageUrl":"https:\/\/i1.rgstatic.net\/ii\/profile.image\/AS%3A272782856552477%401442047909729_m","profileStats":[],"profileFollowButton":null,"profileReputationScoreNumber":null,"profileUrl":"profile\/Manfred_Opper","institution":"Technische Universit\u00e4t Berlin","institutionUrl":false,"widgetId":"rgw4_56ab1dd57cd9f"},"id":"rgw4_56ab1dd57cd9f","partials":[],"templateName":"publicprofile\/stubs\/ProfileBadge.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicprofile.ProfileBadge.html?accountId=3175935","viewClass":null,"yuiModules":["css-modules-publicprofile"],"stylesheets":["modules\/publicprofile.css"],"_isYUI":true},"widgetId":"rgw3_56ab1dd57cd9f"},"id":"rgw3_56ab1dd57cd9f","partials":[],"templateName":"publicprofile\/stubs\/ProfileSmallHeader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicprofile.ProfileSmallHeader.html?publicationUid=23252767","viewClass":null,"yuiModules":["css-modules-publicprofile"],"stylesheets":["modules\/publicprofile.css"],"_isYUI":true},"publication":{"data":{"publicationUid":23252767,"title":"The Variational Gaussian Approximation Revisited","journalTitle":"Neural Computation","journalDetailsTooltip":{"data":{"journalTitle":"Neural Computation","journalAbbrev":"NEURAL COMPUT","publisher":"Massachusetts Institute of Technology Press (MIT Press)","issn":"0899-7667","impactFactor":"2.21","fiveYearImpactFactor":"2.20","citedHalfLife":">10.0","immediacyIndex":"0.57","eigenFactor":"0.01","articleInfluence":"0.96","widgetId":"rgw6_56ab1dd57cd9f"},"id":"rgw6_56ab1dd57cd9f","partials":[],"templateName":"publicliterature\/stubs\/JournalInfo.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.JournalInfo.html?issn=0899-7667","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"affiliation":"Department of Computer Science, Technical University Berlin, D-10587 Berlin, Germany. ","type":"Article","details":{"doi":"10.1162\/neco.2008.08-07-592","journalInfos":{"journal":"","publicationDate":"10\/2008;","publicationDateRobot":"2008-10","article":"21(3):786-92.","journalTitle":"Neural Computation","journalUrl":"journal\/0899-7667_Neural_Computation","impactFactor":2.21}},"source":{"sourceUrl":"http:\/\/www.ncbi.nlm.nih.gov\/pubmed\/18785854","sourceName":"PubMed"},"publicationActions":null,"publicationCoins":{"data":{"tags":[{"key":"ctx_ver","value":"Z39.88-2004"},{"key":"rft_val_fmt","value":"info:ofi\/fmt:kev:mtx:journal"},{"key":"rfr_id","value":"info:sid\/researchgate.net:researchgate"},{"key":"rft_id","value":"info:doi\/10.1162\/neco.2008.08-07-592"},{"key":"rft.atitle","value":"The Variational Gaussian Approximation Revisited"},{"key":"rft.title","value":"Neural computation"},{"key":"rft.jtitle","value":"Neural computation"},{"key":"rft.volume","value":"21"},{"key":"rft.issue","value":"3"},{"key":"rft.date","value":"2008"},{"key":"rft.pages","value":"786-92"},{"key":"rft.issn","value":"0899-7667"},{"key":"rft.au","value":"Manfred Opper,C\u00e9dric Archambeau"},{"key":"rft.genre","value":"article"}],"widgetId":"rgw7_56ab1dd57cd9f"},"id":"rgw7_56ab1dd57cd9f","partials":[],"templateName":"publicliterature\/stubs\/PublicationCoins.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationCoins.html?publicationUid=23252767","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationAuthors":{"data":{"publicationUid":23252767,"peopleItems":[{"data":{"authorNameOnPublication":"Manfred Opper","accountUrl":"profile\/Manfred_Opper","accountKey":"Manfred_Opper","imageUrl":"https:\/\/i1.rgstatic.net\/ii\/profile.image\/AS%3A272782856552477%401442047909729_m","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Manfred Opper","profile":{"professionalInstitution":{"professionalInstitutionName":"Technische Universit\u00e4t Berlin","professionalInstitutionUrl":"institution\/Technische_Universitaet_Berlin"}},"professionalInstitutionName":"Technische Universit\u00e4t Berlin","professionalInstitutionUrl":"institution\/Technische_Universitaet_Berlin","url":"profile\/Manfred_Opper","imageUrl":"https:\/\/i1.rgstatic.net\/ii\/profile.image\/AS%3A272782856552477%401442047909729_l","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":false,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":true,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"accountKey":"Manfred_Opper","hasInfoPopup":false,"hasTeaserPopup":true,"showContactAuthorButton":true,"widgetId":"rgw10_56ab1dd57cd9f"},"id":"rgw10_56ab1dd57cd9f","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAccountItem.html?entityId=3175935&enableUnfollow=0&imageSize=l&enableFollowButton=0&showContactAuthorButton=1","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"accountInstitution":"Technische Universit\u00e4t Berlin","score":null,"largeTooltip":false,"useRebrandedImageStyle":null,"authorCount":2,"accountCount":2,"publicationUid":23252767,"widgetId":"rgw9_56ab1dd57cd9f"},"id":"rgw9_56ab1dd57cd9f","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAccountItem.html","templateExtensions":[],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAccountItem.html?accountId=3175935&context=pubdetail_authors_xflw&showContactAuthorButton=1&authorCount=2&accountCount=2&publicationUid=23252767","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true},{"data":{"authorNameOnPublication":"Cedric Archambeau","accountUrl":"profile\/Cedric_Archambeau","accountKey":"Cedric_Archambeau","imageUrl":"https:\/\/i1.rgstatic.net\/ii\/profile.image\/AS%3A272180487389207%401441904293508_m","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Cedric Archambeau","profile":{"professionalInstitution":{"professionalInstitutionName":"Amazon","professionalInstitutionUrl":false}},"professionalInstitutionName":"Amazon","professionalInstitutionUrl":false,"url":"profile\/Cedric_Archambeau","imageUrl":"https:\/\/i1.rgstatic.net\/ii\/profile.image\/AS%3A272180487389207%401441904293508_l","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":false,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":true,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"accountKey":"Cedric_Archambeau","hasInfoPopup":false,"hasTeaserPopup":true,"showContactAuthorButton":true,"widgetId":"rgw12_56ab1dd57cd9f"},"id":"rgw12_56ab1dd57cd9f","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAccountItem.html?entityId=274152&enableUnfollow=0&imageSize=l&enableFollowButton=0&showContactAuthorButton=1","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"accountInstitution":"Amazon","score":null,"largeTooltip":false,"useRebrandedImageStyle":null,"authorCount":2,"accountCount":2,"publicationUid":23252767,"widgetId":"rgw11_56ab1dd57cd9f"},"id":"rgw11_56ab1dd57cd9f","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAccountItem.html","templateExtensions":[],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAccountItem.html?accountId=274152&context=pubdetail_authors_xflw&showContactAuthorButton=1&authorCount=2&accountCount=2&publicationUid=23252767","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true}],"hasMore":false,"nextOffset":6,"useRebrandedImageStyle":null,"widgetId":"rgw8_56ab1dd57cd9f"},"id":"rgw8_56ab1dd57cd9f","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorList.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorList.html?publicationUid=23252767&context=pubdetail_authors_xflw&showContactAuthorButton=1","viewClass":"views.publicliterature.PublicationDetailAuthorListView","yuiModules":["rg.views.publicliterature.PublicationDetailAuthorListView"],"stylesheets":[],"_isYUI":true},"publicationAbstract":{"data":{"publicationUid":23252767,"abstract":"<noscript><\/noscript><div>The variational approximation of posterior distributions by multivariate gaussians has been much less popular in the machine learning community compared to the corresponding approximation by factorizing distributions. This is for a good reason: the gaussian approximation is in general plagued by an Omicron(N)(2) number of variational parameters to be optimized, N being the number of random variables. In this letter, we discuss the relationship between the Laplace and the variational approximation, and we show that for models with gaussian priors and factorizing likelihoods, the number of variational parameters is actually Omicron(N). The approach is applied to gaussian process regression with nongaussian likelihoods.<\/div>","canEdit":false,"isAdmin":false,"isArtifact":false,"showFullAbstract":true,"widgetId":"rgw13_56ab1dd57cd9f"},"id":"rgw13_56ab1dd57cd9f","partials":[],"templateName":"publicliterature\/stubs\/PublicationAbstract.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationAbstract.html?publicationUid=23252767","viewClass":"views.publicliterature.PublicationAbstractView","yuiModules":["rg.views.publicliterature.PublicationAbstractView"],"stylesheets":[],"_isYUI":true},"publicationKeywords":null,"publicationState":null,"isGuest":true,"isAdminEditingAllowed":false,"isArtifact":false,"figureListWidget":null,"previewImage":"https:\/\/i1.rgstatic.net\/publication\/23252767_The_Variational_Gaussian_Approximation_Revisited\/links\/0912f50aca8ae75c77000000\/smallpreview.png","nativeAdDisclosure":null,"showFollowPublicationButton":false,"followPublicationPromo":{"data":{"widgetId":"rgw14_56ab1dd57cd9f"},"id":"rgw14_56ab1dd57cd9f","partials":[],"templateName":"publicliterature\/stubs\/FollowPublicationPromo.html","templateExtensions":[],"attrs":{"context":null,"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.FollowPublicationPromo.html","viewClass":null,"yuiModules":["css-pow-publicliterature-FollowPublicationPromo"],"stylesheets":["pow\/publicliterature\/FollowPublicationPromo.css"],"_isYUI":true},"widgetId":"rgw5_56ab1dd57cd9f"},"id":"rgw5_56ab1dd57cd9f","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailItem.html","templateExtensions":["generalHelpers"],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailItem.html?publicationUid=23252767&showActionBar=0&showContactAuthorButton=1&showRequestFulltextExperience=0&showNoRgAuthorsRequestFulltextExperience=0&showFollowPublicationPromo=1","viewClass":"views.publicliterature.PublicationDetailItemView","yuiModules":["rg.views.publicliterature.PublicationDetailItemView"],"stylesheets":[],"_isYUI":true},"similarPublications":{"data":{"publicationListItems":[{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore","clickThrough":"experimentMilestoneClickedToPublicationFromReferenceWithNoFulltext","clickThroughWithContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":2093895522,"url":"researcher\/2093895522_Phillip_M_Cheng","fullname":"Phillip M Cheng","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Jan 2016","journal":"Journal of computer assisted tomography","showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/290431543_Histogram-Based_Discrimination_of_Intravenous_Contrast_in_Abdominopelvic_Computed_Tomography","usePlainButton":true,"publicationUid":290431543,"feedStubs":null,"hasFeedStubs":false,"impactPoints":"1.41","url":"publication\/290431543_Histogram-Based_Discrimination_of_Intravenous_Contrast_in_Abdominopelvic_Computed_Tomography","title":"Histogram-Based Discrimination of Intravenous Contrast in Abdominopelvic Computed Tomography","displayTitleAsLink":true,"authors":[{"id":2093895522,"url":"researcher\/2093895522_Phillip_M_Cheng","fullname":"Phillip M Cheng","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["Journal of computer assisted tomography 01\/2016;  DOI:10.1097\/RCT.0000000000000361"],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/290431543_Histogram-Based_Discrimination_of_Intravenous_Contrast_in_Abdominopelvic_Computed_Tomography","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/290431543_Histogram-Based_Discrimination_of_Intravenous_Contrast_in_Abdominopelvic_Computed_Tomography\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw16_56ab1dd57cd9f"},"id":"rgw16_56ab1dd57cd9f","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=290431543","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore","clickThrough":"experimentMilestoneClickedToPublicationFromReferenceWithNoFulltext","clickThroughWithContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":33382619,"url":"researcher\/33382619_Alessio_Benavoli","fullname":"Alessio Benavoli","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":10654903,"url":"researcher\/10654903_Marco_Zaffalon","fullname":"Marco Zaffalon","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Jan 2016","journal":null,"showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/289587204_State_Space_representation_of_non-stationary_Gaussian_Processes","usePlainButton":true,"publicationUid":289587204,"feedStubs":null,"hasFeedStubs":false,"impactPoints":false,"url":"publication\/289587204_State_Space_representation_of_non-stationary_Gaussian_Processes","title":"State Space representation of non-stationary Gaussian Processes","displayTitleAsLink":true,"authors":[{"id":33382619,"url":"researcher\/33382619_Alessio_Benavoli","fullname":"Alessio Benavoli","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":10654903,"url":"researcher\/10654903_Marco_Zaffalon","fullname":"Marco Zaffalon","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":[],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/289587204_State_Space_representation_of_non-stationary_Gaussian_Processes","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/289587204_State_Space_representation_of_non-stationary_Gaussian_Processes\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw17_56ab1dd57cd9f"},"id":"rgw17_56ab1dd57cd9f","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=289587204","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore","clickThrough":"experimentMilestoneClickedToPublicationFromReferenceWithNoFulltext","clickThroughWithContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":2034167984,"url":"researcher\/2034167984_Ulrich_Schaechtle","fullname":"Ulrich Schaechtle","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2089456342,"url":"researcher\/2089456342_Ben_Zinberg","fullname":"Ben Zinberg","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2089399536,"url":"researcher\/2089399536_Alexey_Radul","fullname":"Alexey Radul","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":{"id":8074903,"url":"researcher\/8074903_Kostas_Stathis","fullname":"Kostas Stathis","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},"surplusAuthors":1,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Dec 2015","journal":null,"showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/287249271_Probabilistic_Programming_with_Gaussian_Process_Memoization","usePlainButton":true,"publicationUid":287249271,"feedStubs":null,"hasFeedStubs":false,"impactPoints":false,"url":"publication\/287249271_Probabilistic_Programming_with_Gaussian_Process_Memoization","title":"Probabilistic Programming with Gaussian Process Memoization","displayTitleAsLink":true,"authors":[{"id":2034167984,"url":"researcher\/2034167984_Ulrich_Schaechtle","fullname":"Ulrich Schaechtle","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2089456342,"url":"researcher\/2089456342_Ben_Zinberg","fullname":"Ben Zinberg","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2089399536,"url":"researcher\/2089399536_Alexey_Radul","fullname":"Alexey Radul","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":8074903,"url":"researcher\/8074903_Kostas_Stathis","fullname":"Kostas Stathis","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2089392273,"url":"researcher\/2089392273_Vikash_K_Mansinghka","fullname":"Vikash K. Mansinghka","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":[],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/287249271_Probabilistic_Programming_with_Gaussian_Process_Memoization","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/287249271_Probabilistic_Programming_with_Gaussian_Process_Memoization\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw18_56ab1dd57cd9f"},"id":"rgw18_56ab1dd57cd9f","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=287249271","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"viewClass":"sidebar","widgetId":"rgw15_56ab1dd57cd9f"},"id":"rgw15_56ab1dd57cd9f","partials":[],"templateName":"publicliterature\/stubs\/SimilarPublications.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.SimilarPublications.html?referencePublicationId=23252767&view=sidebar","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationFulltextPreview":null,"publicationResourcesFulltext":{"data":{"publicationUid":23252767,"publicationResourceList":{"data":{"publicationResourceItems":[{"data":{"publicationUid":23252767,"publicationType":"article","linkId":"0912f50aca8ae75c77000000","fileName":"download.pdf","fileUrl":"profile\/Cedric_Archambeau\/publication\/23252767_The_Variational_Gaussian_Approximation_Revisited\/links\/0912f50aca8ae75c77000000.pdf","name":"Cedric Archambeau","nameUrl":"profile\/Cedric_Archambeau","canRemove":false,"fileIcon":"ico-pub","canPreview":true,"hasPublisherLink":null,"hasMetaData":true,"hide":false,"fulltext":"ico-pub","origin":"publication_list","isLastLink":false,"isUserLink":true,"uploadDate":"Jan 20, 2016","fileSize":"153.11 KB","widgetId":"rgw21_56ab1dd57cd9f"},"id":"rgw21_56ab1dd57cd9f","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceItem.html","templateExtensions":["generalHelpers"],"attrs":{"fileRequiredPublicationTypes":["code","coverPage","experimentFindings","method","negativeResults","presentation","rawData","researchProposal","workingPaper","artifact","dataset"]},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceItem.html?publicationUid=23252767&linkId=0912f50aca8ae75c77000000&hide=0&disableJavascript=disableJavascript&useAlternativeTemplate=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"publicationUid":23252767,"publicationType":"article","linkId":"0e6039c3f0c46d4f0aa21f10","fileName":"The Variational Gaussian Approximation Revisited","fileUrl":"http:\/\/citeseerx.ist.psu.edu\/viewdoc\/download?doi=10.1.1.154.9381&amp;rep=rep1&amp;type=pdf","name":"psu.edu","nameUrl":"http:\/\/citeseerx.ist.psu.edu\/viewdoc\/download?doi=10.1.1.154.9381&amp;rep=rep1&amp;type=pdf","canRemove":false,"fileIcon":"ico-pub","canPreview":true,"hasPublisherLink":null,"hasMetaData":true,"hide":false,"fulltext":"ico-pub","origin":"publication_list","isLastLink":false,"isUserLink":false,"widgetId":"rgw22_56ab1dd57cd9f"},"id":"rgw22_56ab1dd57cd9f","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceItem.html","templateExtensions":["generalHelpers"],"attrs":{"fileRequiredPublicationTypes":["code","coverPage","experimentFindings","method","negativeResults","presentation","rawData","researchProposal","workingPaper","artifact","dataset"]},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceItem.html?publicationUid=23252767&linkId=0e6039c3f0c46d4f0aa21f10&hide=0&disableJavascript=disableJavascript&useAlternativeTemplate=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"widgetId":"rgw20_56ab1dd57cd9f"},"id":"rgw20_56ab1dd57cd9f","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceList.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceList.html?publicationUid=23252767&limit=3&disableJavascript=disableJavascript&type=fulltextFile","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"resourceCount":2,"hidden":false,"showMore":false,"fulltext":true,"publicationDownloadCount":{"data":{"value":473,"valueFormatted":"473","widgetId":"rgw23_56ab1dd57cd9f"},"id":"rgw23_56ab1dd57cd9f","partials":[],"templateName":"publicliterature\/stubs\/PublicationDownloadCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDownloadCount.html?publicationUid=23252767","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw19_56ab1dd57cd9f"},"id":"rgw19_56ab1dd57cd9f","partials":[],"templateName":"publicliterature\/stubs\/PublicationResources.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResources.html?publicationUid=23252767&type=fulltextFile&disableJavascript=1","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationResourcesAttachments":{"data":{"publicationUid":23252767,"publicationResourceList":{"data":{"publicationResourceItems":[],"widgetId":"rgw25_56ab1dd57cd9f"},"id":"rgw25_56ab1dd57cd9f","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceList.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceList.html?publicationUid=23252767&limit=3&disableJavascript=disableJavascript&type=attachmentFile","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"resourceCount":0,"hidden":true,"showMore":false,"fulltext":false,"publicationDownloadCount":{"data":{"value":473,"valueFormatted":"473","widgetId":"rgw26_56ab1dd57cd9f"},"id":"rgw26_56ab1dd57cd9f","partials":[],"templateName":"publicliterature\/stubs\/PublicationDownloadCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDownloadCount.html?publicationUid=23252767","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw24_56ab1dd57cd9f"},"id":"rgw24_56ab1dd57cd9f","partials":[],"templateName":"publicliterature\/stubs\/PublicationResources.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResources.html?publicationUid=23252767&type=attachmentFile","viewClass":"views.publicliterature.PublicationResourcesView","yuiModules":["rg.views.publicliterature.PublicationResourcesView"],"stylesheets":[],"_isYUI":true},"publicationText":{"data":{"hide":false,"pages":[{"page":1,"text":"The Variational Gaussian Approximation\nRevisited\nManfred Opper\u2217\nC\u00b4 edric Archambeau\u2020\nMarch 16, 2009\nAbstract\nThe variational approximation of posterior distributions by\nmultivariate Gaussians has been much less popular in the Ma-\nchine Learning community compared to the corresponding ap-\nproximation by factorising distributions. This is for a good rea-\nson: the Gaussian approximation is in general plagued by an\nO(N2) number of variational parameters to be optimised, N be-\ning the number of random variables. In this work, we discuss\nthe relationship between the Laplace and the variational approx-\nimation and we show that for models with Gaussian priors and\nfactorising likelihoods, the number of variational parameters is\nactually O(N). The approach is applied to Gaussian process re-\ngression with non-Gaussian likelihoods.\n1Introduction\nThe variational approximation is among the most important techniques for\ntreating intractable probabilistic models in the field of Machine Learning.\n\u2217Department of Computer, Technical University Berlin, Franklinstr. 28\/29, D-10587\nBerlin, Germany. opperm@cs.tu-berlin.de\n\u2020Centre for Computational Statistics and Machine Learning, University College Lon-\ndon, Gower Street, London WC1E 6BT. c.archambeau@cs.ucl.ac.uk\n1"},{"page":2,"text":"An intractable probability distribution (usually the Bayesian posterior) is ap-\nproximated by the closest distribution within a tractable family, where close-\nness is defined by the Kullback-Leibler divergence (Kullback & Leibler, 1951).\nIn most applications, the tractable families contain distributions which fac-\ntorize in all or in tractable subgroups of random variables (Beal, 2003; Winn,\n2003). Hence, the method neglects correlations between variables which may\nbe crucial in the learning of the hyperparameters.\nIf the random variables are continuous and unconstrained, the family of\nmultivariate Gaussian densities suggests itself as a natural alternative to fac-\ntorizing densities, allowing incorporation of correlations. Nevertheless, such\na variational Gaussian approximation has been applied, to our knowledge,\nonly a few times to problems in Machine Learning (e.g., Barber and Bishop\n(1998), Seeger (2000), Honkela and Valpola (2005)). One possible expla-\nnation is that the covariance matrix of the Gaussian requires a number of\nvariational parameters to be optimised, which scales quadratically with the\nnumber of latent variables in the model.\nHowever, we show that this prejudice against the variational Gaussian ap-\nproximation is not always justified. We derive the exact fixed point conditions\nfor the optimal setting of the variational parameters and find that for certain\nclasses of probabilistic models, related to Gaussian processes (O\u2019Hagan, 1978;\nRasmussen & Williams, 2006), the number of free variational parameters will\nbe only 2N. While this fact seems to be known, at least in some parts of\nthe Machine Learning community (Seeger, 1999, p. 119), several discussions\nhave shown that many researchers were not aware of this result. We will\ndemonstrate the method only on toy regression problems. Our results have\nalso motivated the inclusion of the variational Gaussian approach within a\nlarger study of different methods for classification with Gaussian processes\n(Nickisch & Rasmussen, 2008). In this complementary work a variety of\ncomparisons can be found.\n2 The variational Gaussian approximation\nWe consider probabilistic models for a set of observations y = (y1,...,yM)?\nand a set of latent, unobserved random variables x = (x1,...,xN)?defined\nby a joint probability distribution p(y,x|\u03b8), where \u03b8 denotes a set of hyper-\nparameters. We aim to approximate the posterior density p(x|y,\u03b8) =\nby a density q(x), which belongs to a family of tractable densities. The op-\np(y,x|\u03b8)\np(y|\u03b8)\n2"},{"page":3,"text":"timal q(x) is chosen to minimise the variational free energy\nF(q,\u03b8) = \u2212lnp(y|\u03b8) + KL[q?p], (1)\nwhere KL[q?p] =?q(x)ln\nof the observations and can be used to estimate hyperparameters by a vari-\national EM algorithm (Dempster et al., 1977; Neal & Hinton, 1998).\nIf we restrict the approximate posterior q(x) to be a multivariate Gaussian\nwith mean \u00b5 and covariance \u03a3, i.e.\nq(x)\np(x|y,\u03b8)dx is the Kullback-Leibler (KL) divergence.\nThe free energy is an upper bound to the negative log-marginal probability\nq(x) = (2\u03c0)\u2212N\/2|\u03a3|\u22121\n2e\u22121\n2(x\u2212\u00b5)?\u03a3\u22121(x\u2212\u00b5),(2)\nwe get\nF(q,\u03b8) = \u2212 ?lnp(x,y|\u03b8)?q\u2212N\n2ln2\u03c0e \u22121\n2ln|\u03a3|.(3)\nHence, setting the derivatives of F(q,\u03b8) with respect to the variational pa-\nrameters equal to zero leads to\n0 = \u2207\u00b5?lnp(x,y|\u03b8)?q\nIn general, this will require the computation of N(N + 3)\/2 free variational\nparameters, which is much larger than the typically O(N) number of param-\neters often required for factorising variational distributions.\nand\u03a3\u22121= \u22122\u2207\u03a3?lnp(x,y|\u03b8)?q.(4)\nGeneral properties\nThe variational Gaussian approach can be compared to the well-known Laplace\napproximation, where the mean of a Gaussian density is fitted locally at a\npoint x which maximises the posterior p(x|y,\u03b8). The covariance is then built\nfrom the curvature of the log-posterior at the maximum. Hence, we have\n0 = \u2207xlnp(x,y|\u03b8)\nBy contrast, (4) can be rewritten in two different ways using (18) and (19)\nand\u03a3\u22121= \u2212\u2207x\u2207xlnp(x,y|\u03b8). (5)\n0 = \u2207\u00b5?lnp(x,y|\u03b8)?q= ?\u2207xlnp(x,y|\u03b8)?q,\n\u03a3\u22121= \u2212\u2207\u00b5\u2207\u00b5?lnp(x,y|\u03b8)?q= \u2212?\u2207x\u2207xlnp(x,y|\u03b8)?q.\n(6)\n(7)\n3"},{"page":4,"text":"The second set of equalities on both lines shows that we have a global ap-\nproximation: the conditions of the Laplace approximation hold on average.\nAnother interpretation comes from the first set of equalities. Here we see that\nthe variational Gaussian method is equivalent to applying Laplace\u2019s method\nto a new (implicitly defined) probability density \u02dc q(\u00b5) \u221d e?lnp(x,y|\u03b8)?q, which\nis defined over the space of parameters \u00b5.\n3 Gaussian prior models\nWe will now specialise to a class of models which are of the following form:\np(x,y|\u03b8) =\n1\nZ0e\u2212P\nnVn\u22121\n2x?K\u22121x,(8)\nwhere K is a positive definite matrix, Vnis a shorthand notation for V (yn,xn)\nand Z0is the normalization constant (including the factor |K|1\/2). A typical\napplication is inference with Gaussian process (GP) models (O\u2019Hagan, 1978;\nRasmussen & Williams, 2006), where x = (x(s1),...,x(sN))?denotes the\nvalues of a latent function x(s) at inputs s1,...,sN, K is the kernel matrix\nand Vn= \u2212lnp(yn|xn) denotes the negative log-likelihood.\nFrom (8), we get\nF(q,\u03b8) =\n?\n+ lnZ0\u2212N\nn\n?Vn?qn+1\n2tr{K\u22121\u03a3} +1\n2\u00b5?K\u22121\u00b5 \u22121\n2ln|\u03a3|\n2ln2\u03c0e, (9)\nwhere ? \u00b7 ?qnindicates that the expectation is taken with respect to the\nmarginal q(xn), the univariate Gaussian with mean \u00b5nand variance \u03a3nn.\nEach term ?Vn?qndepends only on the mean \u00b5nand the diagonal element\n\u03a3nnof the full covariance \u03a3. As a result, the second equation in (4) shows\nthat the nondiagonal elements of \u03a3\u22121are simply equal to those of K\u22121and\nthat the optimal covariance will be of the form\n\u03a3 =?K\u22121+ \u039b?\u22121,\nwhere \u039b is a diagonal matrix with \u03bb \u2261 ( ... \u03bbn ... )?on its diagonal.\nHence, we can use the N elements \u03bbnas new parameters. We found it also\nuseful to represent the mean parameters in the form \u00b5 = K\u03bd with a vector\n(10)\n4"},{"page":5,"text":"\u03bd of N new effective parameters. Inserting these definitions into the free\nenergy, a short calculation shows that the gradients of the free energy with\nrespect to the new 2N parameters are given by\ng\u03bd\u2261 \u2207\u03bdF(q,\u03b8) = K(\u03bd \u2212 \u00af \u03bd),\ng\u03bb\u2261 \u2207\u03bbF(q,\u03b8) =1\n(11)\n2(\u03a3 \u25e6 \u03a3)(\u03bb \u2212\u00af\u03bb),(12)\nwhere \u25e6 denotes the Hadamard product. \u00af \u03bd \u2261 ( ... \u2212 \u2202 ?Vn?qn\/\u2202\u00b5n ... )?\nand where\u00af\u03bb \u2261 ( ... 2\u2202 ?Vn?qn\/\u2202\u03a3nn ... )?. We use these gradients within\na nonlinear conjugate gradient method with back-tracking (Hager & Zhang,\n2005) to optimise the parameters.\nOne could generalize this approach to models where only a few of the\nlikelihood terms depend on more than a single variable. In this case as well,\na relatively small number of variational parameters would have to be be\noptimised.\nDerivatives of the Gaussian expectations\nThe computation of the gradients requires explicit expressions for ?Vn?qn\nfor which there is often no analytical solution. However, one can circum-\nvent this problem by using the Gaussian identities (18) and (19), along with\n?\n\u2212\u00af \u03bdn=\u2202 ?Vn?qn\n\u2202\u00b5n\n\u2202xn\nqn\n\u00af\u03bbn\n2\u2202\u03a3nn\n2 \u2202x2\nn\nqn\n\u2202Vn\n\u2202xn\n?\n\u03a3nn= ?(xn\u2212 \u00b5n)Vn?:\n=\n?\u2202Vn\n=1\n?\n=?(xn\u2212 \u00b5n)Vn?qn\n\u03a3nn\n?\n,(13)\n=\u2202 ?Vn?qn\n?\u22022Vn\n=?(xn\u2212 \u00b5n)2Vn?qn\u2212 \u03a3nn?Vn?qn\n2\u03a32\nnn\n. (14)\nAs a consequence, the evaluation of these expectations does not require to\ncompute the first and second order derivatives of Vn explicitly. They can\neither be naively estimated by sample averages, the samples being generated\nfrom the univariate Gaussian marginals qn, or by more elaborate techniques\nsuch as Gauss-Hermite quadrature (Liu & Pierce, 1994), provided Vnsatisfies\nsome smoothness properties.\n5"},{"page":6,"text":"4 Application to robust Gaussian process re-\ngression\nWe test our approach on the Boston housing regression data. The aim is to\npredict the median value of a home. The input data is 13-dimensional. More\ninformation on this data set can be found at http:\/\/lib.stat.cmu.edu\/datasets\/.\nWe investigate two noise models, Laplace and Cauchy noise, which have heav-\nier tails compared to a simple Gaussian and are thus expected to be less\nsensitive to outliers. The likelihoods are respectively given by\np(y|x,\u03b7) =\u03b7\n2e\u2212\u03b7|y\u2212x|\nandp(y|f,\u03b3) =\n1\n\u03c0\u03b3\n?\n1 +(y \u2212 x)2\n\u03b32\n?\u22121\n, (15)\nwhere \u03b7 > 0 and \u03b3 > 0 are the noise parameters. In order to estimate the\nkernel parameters, which we denote by \u03b8 = {\u03b8i}i, and the noise parameters,\nwe resort to gradient descent algorithms (Nocedal & Wright, 2000). The\ngradient of the variational free energy w.r.t. \u03b8iis given by\n??\u00af \u03bd\u00af \u03bd?\u2212\u00afB\u22121?\u2202K\nwhere\u00af\u039b is a diagonal matrix with\u00af\u03bb on its diagonal. When computing this\ngradient, we have kept the variational parameters fixed, that is \u03bd = \u00af \u03bd and\n\u039b =\u00af\u039b. The reason is that the implicit derivatives vanish at \u00af \u03bd and\u00af\u039b,\nwhich are stationary points of the free energy F(q,\u03b8). The overall training\nalgorithm requires thus to perform an inner and an outer optimization loop.\nAfter each gradient step (16), one needs to recompute \u00af \u03bd and\u00af\u039b using (11)\nand (12). To compute approximate predictions for x(s\u2217) at inputs s\u2217which\nare not in the training set using the approximate Gaussian on x, we follow\nRasmussen and Williams (2006, p. 44).\nTable 1 shows the average test mean squared error (MSE) and the 1-\nstandard deviation of the MSE for the standard GP, the variational Gaus-\nsian approximation assuming Laplace noise and the variational Gaussian\napproximation assuming Cauchy noise. All models use a squared exponen-\ntial kernel function with common length scale and common multiplicative\nconstant. The standard GP assumes additive Gaussian noise with variance\n\u03c32. All hyperparameters are optimised by gradient techniques. We use 5-fold\ncross-validation to estimate the MSE. It can be observed from Table 1 that\ng\u03b8i= \u22121\n2tr\u2202\u03b8i\n?\n,\n\u00afB = K +\u00af\u039b\u22121,(16)\n6"},{"page":7,"text":"Table 1: Average test mean squared error (MSE) and 1-standard deviation\nof the MSE for the Boston housing data. See text for details.\nlikelihood\nboston\nCauchy\n47.92 \u00b1 16.13\nLaplace\n42.35 \u00b1 13.65\nGaussian\n53.75 \u00b1 22.02\nboth variational Gaussian approximations outperform the standard GP. As-\nsuming Laplace distributed noise seems to be advantageous over the Cauchy\nnoise, suggesting that there are no strong outliers in the data.\n5Conclusion\nIn this paper, we have reconsidered the variational Gaussian approximation.\nWe have clarified its relation to the Laplace approximation. We have shown\nthat it is a tractable approach at least for models with Gaussian priors and\nfactorising likelihoods, which naturally occur within the Gaussian process\nframework. We have also discussed several ways to compute the Gaussian\nexpectations. The variational Gaussian approximation may also be natu-\nrally combined with variational sparse Gaussian approximations in order to\nspeed up the inference for large datasets. We will give such extensions and\ncomparisons of the method with other techniques in a forthcoming paper.\nA Appendix\nDerivatives of multivariate Gaussian expectations with respect to the mean \u00b5\nand the covariance \u03a3 are most conveniently computed using the characteristic\nfunction G(k) = ?eik?x?q= e\u22121\nstandard Fourier analysis, we can express expectations of any function V (x)\nas\n?\n=\n(2\u03c0)n\n2k?\u03a3k+ik?\u00b5of the Gaussian measure q. Using\n?V (x)?q=\n1\n(2\u03c0)n\n1\nG(k)e\u2212ik?yV (y) dy dk\n?\ne\u22121\n2k?\u03a3k+ik?(\u00b5\u2212y)V (y) dy dk. (17)\n7"},{"page":8,"text":"This shows that any derivative with respect to \u00b5 is equivalent to (\u2212) the\nderivative of the exponential under the integral with respect to y. This in\nturn, using integrations by parts with respect to y, yields\n\u2207\u00b5?V (x)?q= ?\u2207xV (x)?q\n\u2207\u03a3?V (x)?q=1\n(18)\n2?\u2207x\u2207xV (x)?q=1\n2\u2207\u00b5\u2207\u00b5?V (x)?q. (19)\nwhere the second equality in the last line follows from the first line.\nReferences\nBarber, D., & Bishop, C. M. (1998). Ensemble learning for Multi-Layer\nNetworks. Advances in Neural Information Processing Systems 10 (NIPS).\nThe MIT Press.\nBeal, M. J. (2003). Variational algorithms for approximate Bayesian in-\nference. Doctoral dissertation, Gatsby Computational Neuroscience Unit,\nUniversity College London, United Kingdom.\nDempster, A. P., Laird, N. M., & Rubin, D. B. (1977). Maximum likelihood\nfrom incomplete data via EM algorithm. Journal of the Royal Statistical\nSociety B, 39, 1\u201338.\nHager, W. W., & Zhang, H. (2005).\nwith guaranteed descent and an efficient line search. SIAM Journal on\nOptimization, 16, 170\u2013192.\nA new conjugate gradient method\nHonkela, A., & Valpola, H. (2005). Unsupervised variational Bayesian learn-\ning of nonlinear models. Advances in Neural Information Processing Sys-\ntems 17 (NIPS) (pp. 593 \u2013 600). The MIT Press.\nKullback, S., & Leibler, R. A. (1951). On information and sufficiency. Annals\nof Mathematical Statistics, 22, 79\u201386.\nLiu, Q., & Pierce, D. A. (1994).\nBiometrika, 81, 624\u2013629.\nA note on Gauss-Hermite quadrature.\nNeal, R. M., & Hinton, G. E. (1998). A view of the EM algorithm that\njustifies incremental, sparse, and other variants. In M. I. Jordan (Ed.),\nLearning in graphical models, 355\u2013368. The MIT press.\n8"},{"page":9,"text":"Nickisch, H., & Rasmussen, C. E. (2008). Approximations for binary Gaus-\nsian process classification. Journal of Machine Learning Research. Sub-\nmitted.\nNocedal, J., & Wright, S. J. (2000). Numerical optimization. Springer.\nO\u2019Hagan, A. (1978). Curve fitting and optimal design for prediction. Journal\nof the Royal Statistical Society B, 40, 1\u201342.\nRasmussen, C. E., & Williams, C. K. I. (2006).\nmachine learning. Cambridge, Massachusetts: The MIT Press.\nGaussian processes for\nSeeger, M. (1999). Bayesian methods for support vector machines and Gaus-\nsian processes. Master\u2019s thesis, University of Karlsruhe, Germany.\nSeeger, M. (2000). Bayesian model selection for support vector machines,\nGaussian processes and other kernel classifiers. Advances in Neural Infor-\nmation Processing Systems 12 (NIPS) (pp. 603\u2013609). The MIT Press.\nWinn, J. (2003). Variational message passing and its applications. Doc-\ntoral dissertation, Department of Physics, University of Cambridge, United\nKingdom.\n9"}],"fullTextUrl":"https:\/\/www.researchgate.net\/profile\/Cedric_Archambeau\/publication\/23252767_The_Variational_Gaussian_Approximation_Revisited\/links\/0912f50aca8ae75c77000000.pdf","widgetId":"rgw27_56ab1dd57cd9f"},"id":"rgw27_56ab1dd57cd9f","partials":[],"templateName":"publicliterature\/stubs\/PublicationText.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationText.html?publicationUid=23252767&hide=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationDetailAd":{"data":{"googleDfpSlot":null,"widgetId":"rgw28_56ab1dd57cd9f"},"id":"rgw28_56ab1dd57cd9f","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAd.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAd.html?publicationUid=23252767&slotId=336x280_Publications_ATF_Right&collapseSlotMode=never&fallbackContainerEnabled=1","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationRelations":null,"publicationRelationsReverse":null,"publicationUid":23252767,"showSignUpDialog":false,"selectNewSignUpDialog":false,"publicationQuestions":null,"publicationCitations":{"data":{"publicationUid":23252767,"publicationCitationsList":{"data":{"citationItems":[{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore","clickThrough":"experimentMilestoneClickedToPublicationFromCitationWithSlurp","clickThroughWithContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextSlurp","nextPublicationViewId":null,"authorsPartOne":[{"id":80788842,"url":"researcher\/80788842_Young_Jun_Ko","fullname":"Young Jun Ko","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2009110960,"url":"researcher\/2009110960_Matthias_Seeger","fullname":"Matthias Seeger","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":[["includes-citation-list"]],"isFulltext":false,"isSlurp":true,"isNoText":false,"publicationType":"Article","publicationDate":"Jan 2015","journal":null,"showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/286094850_Expectation_Propagation_for_Rectified_Linear_Poisson_Regression","usePlainButton":true,"publicationUid":286094850,"feedStubs":null,"hasFeedStubs":false,"impactPoints":false,"url":"publication\/286094850_Expectation_Propagation_for_Rectified_Linear_Poisson_Regression","title":"Expectation Propagation for Rectified Linear Poisson Regression","displayTitleAsLink":true,"authors":[{"id":80788842,"url":"researcher\/80788842_Young_Jun_Ko","fullname":"Young Jun Ko","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2009110960,"url":"researcher\/2009110960_Matthias_Seeger","fullname":"Matthias Seeger","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":[],"abstract":"The Poisson likelihood with rectified linear function as non-linearity is a physically plausible model to discribe the stochastic arrival process of photons or other particles at a detector. At low emission rates the discrete nature of this process leads to measurement noise that behaves very differently from additive white Gaussian noise. To address the intractable inference problem for such models, we present a novel efficient and robust Expectation Propagation algorithm entirely based on analytically tractable computations operating re- liably in regimes where quadrature based implementations can fail. Full posterior inference therefore becomes an attractive alternative in areas generally dominated by methods of point estimation. Moreover, we discuss the rectified linear function in the context of other common non-linearities and identify situations where it can serve as a robust alternative.","description":false,"swapJournalAndAuthorPositions":false,"showAbstract":true,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/286094850_Expectation_Propagation_for_Rectified_Linear_Poisson_Regression","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":false,"actions":[{"type":"request-external","text":"Request full-text","url":"javascript:;","active":false,"primary":false,"extraClass":null,"icon":null,"data":[{"key":"context","value":"pubCit"}]}],"actionWidgets":[],"publicationItemFulltext":{"data":{"isDataset":false,"isResearch":false,"isFulltext":true,"source":{"isPreview":true,"sourceUrl":"deref\/http%3A%2F%2Finfoscience.epfl.ch%2Frecord%2F214372%2Ffiles%2FKo49.pdf","sourceName":"infoscience.epfl.ch","hasSourceUrl":true},"publicationUid":286094850,"publicationUrl":"publication\/286094850_Expectation_Propagation_for_Rectified_Linear_Poisson_Regression","eventCode":"","citationCount":0,"additionalContentWidgets":[],"disableViewer":true,"showLoggedOutRequestButton":false,"context":null,"previewUrl":"https:\/\/i1.rgstatic.net\/publication\/286094850_Expectation_Propagation_for_Rectified_Linear_Poisson_Regression\/links\/569e748208ae2c638eb56191\/smallpreview.png","linkId":"569e748208ae2c638eb56191","origin":"publication_list","showRequestCount":false,"publish":false,"request":false,"showAction":false,"displayAsLink":true,"documentViewerUrl":"publicliterature.PublicLiteratureDocumentViewer.html?publicationId=286094850&reference=569e748208ae2c638eb56191&eventCode=&origin=publication_list","widgetId":"rgw32_56ab1dd57cd9f"},"id":"rgw32_56ab1dd57cd9f","partials":[],"templateName":"publicliterature\/stubs\/PublicationItemFulltext.html","templateExtensions":["generalHelpers"],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItemFulltext.html?publicationUid=286094850&showAction=1&eventCode=&hideSource=0&displayAsLink=1&showPublishAsSelectFile=0","viewClass":"views.publicliterature.PublicationItemFulltextView","yuiModules":["rg.views.publicliterature.PublicationItemFulltextView"],"stylesheets":[],"_isYUI":true},"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":true,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":23252767,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/286094850_Expectation_Propagation_for_Rectified_Linear_Poisson_Regression\/review","additionalRightSideTopWidgets":[{"data":{"citationContexts":["While Laplace's method is the preferred method in the GP setting (Park and Pillow, 2013; Diggle et al., 2013; Park et al., 2014), it cannot be applied to SLMs, because by design we expect many transform coefficients to be zero, where the Laplace potential is not differentiable. Another popular variational Bayesian (VB) technique is referred to as Variational Gaussian approximation (Opper and Archambeau, 2009) or KL method (Nickisch and Rasmussen, 2008; Challis and Barber, 2013). It is analytically tractable for the exponential function (Ko and Khan, 2014), whereas the softplus function requires approximations , e.g. "],"widgetId":"rgw33_56ab1dd57cd9f"},"id":"rgw33_56ab1dd57cd9f","partials":[],"templateName":"publicliterature\/stubs\/PublicationItemCitationContexts.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItemCitationContexts.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":true,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw31_56ab1dd57cd9f"},"id":"rgw31_56ab1dd57cd9f","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":true,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItem.html?showEnrichedPublicationItem=0&showRequestButton=1&publicationUid=286094850&additionalCssClasses%5B0%5D=includes-citation-list&citationContextItemVersion=old&isIncomingCitation=1","viewClass":"views.publicliterature.PublicationItemView","yuiModules":["rg.views.publicliterature.PublicationItemView"],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore","clickThrough":"experimentMilestoneClickedToPublicationFromCitationWithFulltext","clickThroughWithContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextSlurp","nextPublicationViewId":null,"authorsPartOne":[{"id":2047892358,"url":"researcher\/2047892358_P_K_Srijith","fullname":"P. K. Srijith","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2059997535,"url":"researcher\/2059997535_P_Balamurugan","fullname":"P. Balamurugan","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":35397864,"url":"researcher\/35397864_Shirish_Shevade","fullname":"Shirish Shevade","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":[["includes-citation-list"]],"isFulltext":true,"isSlurp":false,"isNoText":false,"publicationType":"Article","publicationDate":"Dec 2014","journal":null,"showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/270222737_Gaussian_Process_Pseudo-Likelihood_Models_for_Sequence_Labeling","usePlainButton":true,"publicationUid":270222737,"feedStubs":null,"hasFeedStubs":false,"impactPoints":false,"url":"publication\/270222737_Gaussian_Process_Pseudo-Likelihood_Models_for_Sequence_Labeling","title":"Gaussian Process Pseudo-Likelihood Models for Sequence Labeling","displayTitleAsLink":true,"authors":[{"id":2047892358,"url":"researcher\/2047892358_P_K_Srijith","fullname":"P. K. Srijith","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2059997535,"url":"researcher\/2059997535_P_Balamurugan","fullname":"P. Balamurugan","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":35397864,"url":"researcher\/35397864_Shirish_Shevade","fullname":"Shirish Shevade","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":[],"abstract":"Several machine learning problems arising in natural language processing can\nbe modeled as a sequence labeling problem. We provide Gaussian process models\nbased on pseudo-likelihood approximation to perform sequence labeling. Gaussian\nprocesses (GPs) provide a Bayesian approach to learning in a kernel based\nframework. The pseudo-likelihood model enables one to capture long range\ndependencies among the output components of the sequence without becoming\ncomputationally intractable. We use an efficient variational Gaussian\napproximation method to perform inference in the proposed model. We also\nprovide an iterative algorithm which can effectively make use of the\ninformation from the neighboring labels to perform prediction. The ability to\ncapture long range dependencies makes the proposed approach useful for a wide\nrange of sequence labeling problems. Numerical experiments on some sequence\nlabeling data sets demonstrate the usefulness of the proposed approach.","description":false,"swapJournalAndAuthorPositions":false,"showAbstract":true,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/270222737_Gaussian_Process_Pseudo-Likelihood_Models_for_Sequence_Labeling","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":true,"actions":[{"type":"download","text":"Download","url":"profile\/P_Balamurugan\/publication\/270222737_Gaussian_Process_Pseudo-Likelihood_Models_for_Sequence_Labeling\/links\/55f9a40608aeba1d9f1f3b0e.pdf?origin=publication_list","active":false,"primary":true,"extraClass":"open-viewer","icon":null,"data":[]}],"actionWidgets":[],"publicationItemFulltext":{"data":{"isDataset":false,"isResearch":false,"isFulltext":true,"source":{"isPreview":false,"sourceUrl":"profile\/P_Balamurugan","sourceName":"P. Balamurugan","hasSourceUrl":true},"publicationUid":270222737,"publicationUrl":"publication\/270222737_Gaussian_Process_Pseudo-Likelihood_Models_for_Sequence_Labeling","eventCode":"","citationCount":0,"additionalContentWidgets":[],"disableViewer":true,"showLoggedOutRequestButton":false,"context":null,"previewUrl":"https:\/\/i1.rgstatic.net\/publication\/270222737_Gaussian_Process_Pseudo-Likelihood_Models_for_Sequence_Labeling\/links\/55f9a40608aeba1d9f1f3b0e\/smallpreview.png","linkId":"55f9a40608aeba1d9f1f3b0e","origin":"publication_list","showRequestCount":false,"publish":false,"request":false,"showAction":false,"displayAsLink":true,"documentViewerUrl":"publicliterature.PublicLiteratureDocumentViewer.html?publicationId=270222737&reference=55f9a40608aeba1d9f1f3b0e&eventCode=&origin=publication_list","widgetId":"rgw35_56ab1dd57cd9f"},"id":"rgw35_56ab1dd57cd9f","partials":[],"templateName":"publicliterature\/stubs\/PublicationItemFulltext.html","templateExtensions":["generalHelpers"],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItemFulltext.html?publicationUid=270222737&showAction=1&eventCode=&hideSource=0&displayAsLink=1&showPublishAsSelectFile=0","viewClass":"views.publicliterature.PublicationItemFulltextView","yuiModules":["rg.views.publicliterature.PublicationItemFulltextView"],"stylesheets":[],"_isYUI":true},"linkId":"55f9a40608aeba1d9f1f3b0e","context":null,"contextId":null,"eventCode":"","isCitation":true,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":23252767,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/270222737_Gaussian_Process_Pseudo-Likelihood_Models_for_Sequence_Labeling\/review","additionalRightSideTopWidgets":[{"data":{"citationContexts":["Variational Gaussian approaches can be slow because of the requirement to estimate the covariance matrix. Fortunately, recent advances in VG inference approaches (Opper and Archambeau, 2009) enable one to compute the covariance matrix using O(N L) variational parameters. In fact, we use the VG approach for GPs (Khan et al., 2012) which requires computation of only O(N L) variational parameters, but at the same time uses a concave variational lower bound. "],"widgetId":"rgw36_56ab1dd57cd9f"},"id":"rgw36_56ab1dd57cd9f","partials":[],"templateName":"publicliterature\/stubs\/PublicationItemCitationContexts.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItemCitationContexts.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":true,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read full-text","widgetId":"rgw34_56ab1dd57cd9f"},"id":"rgw34_56ab1dd57cd9f","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":true,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItem.html?showEnrichedPublicationItem=0&showRequestButton=1&publicationUid=270222737&additionalCssClasses%5B0%5D=includes-citation-list&citationContextItemVersion=old&isIncomingCitation=1","viewClass":"views.publicliterature.PublicationItemView","yuiModules":["rg.views.publicliterature.PublicationItemView"],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore","clickThrough":"experimentMilestoneClickedToPublicationFromCitationWithFulltext","clickThroughWithContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":2044132067,"url":"researcher\/2044132067_Shaobo_Han","fullname":"Shaobo Han","last":false,"imageUrl":"https:\/\/i1.rgstatic.net\/ii\/profile.image\/AS%3A273720048615424%401442271353189_m"},{"id":2006243672,"url":"researcher\/2006243672_Xuejun_Liao","fullname":"Xuejun Liao","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":10135830,"url":"researcher\/10135830_Lawrence_Carin","fullname":"Lawrence Carin","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":[["includes-citation-list"]],"isFulltext":true,"isSlurp":false,"isNoText":false,"publicationType":"Conference Paper","publicationDate":"Dec 2013","journal":null,"showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/260289417_Integrated_Non-Factorized_Variational_Inference","usePlainButton":true,"publicationUid":260289417,"feedStubs":null,"hasFeedStubs":false,"impactPoints":false,"url":"publication\/260289417_Integrated_Non-Factorized_Variational_Inference","title":"Integrated Non-Factorized Variational Inference","displayTitleAsLink":true,"authors":[{"id":2044132067,"url":"researcher\/2044132067_Shaobo_Han","fullname":"Shaobo Han","last":false,"imageUrl":"https:\/\/i1.rgstatic.net\/ii\/profile.image\/AS%3A273720048615424%401442271353189_m"},{"id":2006243672,"url":"researcher\/2006243672_Xuejun_Liao","fullname":"Xuejun Liao","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":10135830,"url":"researcher\/10135830_Lawrence_Carin","fullname":"Lawrence Carin","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["Advances in Neural Information Processing Systems; 12\/2013"],"abstract":"We present a non-factorized variational method for full posterior inference in Bayesian hierarchical models, with the goal of capturing the posterior variable de-pendencies via efficient and possibly parallel computation. Our approach unifies the integrated nested Laplace approximation (INLA) under the variational frame-work. The proposed method is applicable in more challenging scenarios than typ-ically assumed by INLA, such as Bayesian Lasso, which is characterized by the non-differentiability of the 1 norm arising from independent Laplace priors. We derive an upper bound for the Kullback-Leibler divergence, which yields a fast closed-form solution via decoupled optimization. Our method is a reliable ana-lytic alternative to Markov chain Monte Carlo (MCMC), and it results in a tighter evidence lower bound than that of mean-field variational Bayes (VB) method.","description":false,"swapJournalAndAuthorPositions":false,"showAbstract":true,"type":"Conference Paper","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/260289417_Integrated_Non-Factorized_Variational_Inference","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":true,"actions":[{"type":"download","text":"Download","url":"profile\/Shaobo_Han\/publication\/260289417_Integrated_Non-Factorized_Variational_Inference\/links\/0a85e5308f8849bfe7000000.pdf?origin=publication_list","active":false,"primary":true,"extraClass":"open-viewer","icon":null,"data":[]}],"actionWidgets":[],"publicationItemFulltext":{"data":{"isDataset":false,"isResearch":false,"isFulltext":true,"source":{"isPreview":false,"sourceUrl":"profile\/Shaobo_Han","sourceName":"Shaobo Han","hasSourceUrl":true},"publicationUid":260289417,"publicationUrl":"publication\/260289417_Integrated_Non-Factorized_Variational_Inference","eventCode":"","citationCount":0,"additionalContentWidgets":[],"disableViewer":true,"showLoggedOutRequestButton":false,"context":null,"previewUrl":"https:\/\/i1.rgstatic.net\/publication\/260289417_Integrated_Non-Factorized_Variational_Inference\/links\/0a85e5308f8849bfe7000000\/smallpreview.png","linkId":"0a85e5308f8849bfe7000000","origin":"publication_list","showRequestCount":false,"publish":false,"request":false,"showAction":false,"displayAsLink":true,"documentViewerUrl":"publicliterature.PublicLiteratureDocumentViewer.html?publicationId=260289417&reference=0a85e5308f8849bfe7000000&eventCode=&origin=publication_list","widgetId":"rgw38_56ab1dd57cd9f"},"id":"rgw38_56ab1dd57cd9f","partials":[],"templateName":"publicliterature\/stubs\/PublicationItemFulltext.html","templateExtensions":["generalHelpers"],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItemFulltext.html?publicationUid=260289417&showAction=1&eventCode=&hideSource=0&displayAsLink=1&showPublishAsSelectFile=0","viewClass":"views.publicliterature.PublicationItemFulltextView","yuiModules":["rg.views.publicliterature.PublicationItemFulltextView"],"stylesheets":[],"_isYUI":true},"linkId":"0a85e5308f8849bfe7000000","context":null,"contextId":null,"eventCode":"","isCitation":true,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":23252767,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/260289417_Integrated_Non-Factorized_Variational_Inference\/review","additionalRightSideTopWidgets":[{"data":{"citationContexts":["Based on the Laplace approximation [3], INLA seeks a Gaussian distribution q G (x|y, \u03b8 k ) = N (x; x * (\u03b8 k ), H(x * (\u03b8 k )) \u22121 ), \u2200\u03b8 k \u2208 G that captures most of the probabilistic mass locally, where x * (\u03b8 k ) = argmax x p(x|y, \u03b8 k ) is the posterior mode, and H(x * (\u03b8 k )) is the Hessian matrix of the log posterior evaluated at the mode. By contrast, INF-VB with the Gaussian parametric constraint on q (x|y, \u03b8 k ) provides a global variational Gaussian approximation q V G (x|y, \u03b8 k ) in the sense that the conditions of the Laplace approximation hold on average [17]. As we will see next, the averaging operator plays a crucial role in handling the non-differentiable 1 norm arising from the double-exponential priors. "],"widgetId":"rgw39_56ab1dd57cd9f"},"id":"rgw39_56ab1dd57cd9f","partials":[],"templateName":"publicliterature\/stubs\/PublicationItemCitationContexts.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItemCitationContexts.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":true,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read full-text","widgetId":"rgw37_56ab1dd57cd9f"},"id":"rgw37_56ab1dd57cd9f","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":true,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItem.html?showEnrichedPublicationItem=0&showRequestButton=1&publicationUid=260289417&additionalCssClasses%5B0%5D=includes-citation-list&citationContextItemVersion=old&isIncomingCitation=1","viewClass":"views.publicliterature.PublicationItemView","yuiModules":["rg.views.publicliterature.PublicationItemView"],"stylesheets":[],"_isYUI":true}],"hasCitations":true,"isPublicationAuthor":false,"isPublicationVisitor":false,"publicationUid":23252767,"publicationLink":"publication\/23252767_The_Variational_Gaussian_Approximation_Revisited","hasShowMore":true,"newOffset":3,"pageSize":10,"widgetId":"rgw30_56ab1dd57cd9f"},"id":"rgw30_56ab1dd57cd9f","partials":[],"templateName":"publicliterature\/stubs\/PublicationIncomingCitationsList.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationIncomingCitationsList.html?publicationUid=23252767&citedInPage=1&swapJournalAndAuthorPositions=0&showAbstract=1&showType=1&showPublicationPreview=1&totalCount=39","viewClass":"views.publicliterature.PublicationIncomingCitationsListView","yuiModules":["rg.views.publicliterature.PublicationIncomingCitationsListView"],"stylesheets":[],"_isYUI":true},"hasCitations":false,"citationsCount":0,"hasIncomingCitations":true,"incomingCitationsCount":39,"showCitationsSorter":true,"showAbstract":true,"showType":true,"showPublicationPreview":true,"swapJournalAndAuthorPositions":false,"sort":"","sortOriginal":false,"citationList":"incoming","showsIncoming":true,"showSorting":false,"usePlainButton":null,"useEnrichedContext":null,"widgetId":"rgw29_56ab1dd57cd9f"},"id":"rgw29_56ab1dd57cd9f","partials":[],"templateName":"publicliterature\/stubs\/PublicationCitations.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationCitations.html?publicationUid=23252767&citationList=&citedInPage=1&sort=","viewClass":"views.publicliterature.PublicationCitationsView","yuiModules":["rg.views.publicliterature.PublicationCitationsView"],"stylesheets":[],"_isYUI":true},"publicationReviewPromo":null,"publicationUsedInReviews":null,"publicationPdfJsReader":{"data":{"isPreview":false,"licenseUrl":null,"licenseInfo":null,"defaultLinkData":{"linkId":"0912f50aca8ae75c77000000","name":"Cedric Archambeau","date":null,"nameLink":"profile\/Cedric_Archambeau","filename":"download.pdf","downloadLink":"https:\/\/www.researchgate.net\/profile\/Cedric_Archambeau\/publication\/23252767_The_Variational_Gaussian_Approximation_Revisited\/links\/0912f50aca8ae75c77000000.pdf?inViewer=0&pdfJsDownload=0&origin=publication_detail","viewerUrl":"https:\/\/www.researchgate.net\/profile\/Cedric_Archambeau\/publication\/23252767_The_Variational_Gaussian_Approximation_Revisited\/links\/0912f50aca8ae75c77000000.pdf?inViewer=1&pdfJsDownload=1&origin=publication_detail","downloadHash":"15e43c969e06ca7ff6eb7f85eef9781e","showFileSizeNote":false,"fileSize":"153.11 KB","noFollow":false,"isDefault":true,"doi":null},"displayableLinks":[{"linkId":"0912f50aca8ae75c77000000","name":"Cedric Archambeau","date":null,"nameLink":"profile\/Cedric_Archambeau","filename":"download.pdf","downloadLink":"https:\/\/www.researchgate.net\/profile\/Cedric_Archambeau\/publication\/23252767_The_Variational_Gaussian_Approximation_Revisited\/links\/0912f50aca8ae75c77000000.pdf?inViewer=0&pdfJsDownload=0&origin=publication_detail","viewerUrl":"https:\/\/www.researchgate.net\/profile\/Cedric_Archambeau\/publication\/23252767_The_Variational_Gaussian_Approximation_Revisited\/links\/0912f50aca8ae75c77000000.pdf?inViewer=1&pdfJsDownload=1&origin=publication_detail","downloadHash":"15e43c969e06ca7ff6eb7f85eef9781e","showFileSizeNote":false,"fileSize":"153.11 KB","noFollow":false,"isDefault":true,"doi":null}],"hasDisplayableLinks":false,"reader":{"data":{"pdfCommentsActive":false,"publicationType":"Article","onlyRenderFirstPage":false,"readMoreExperimentGoal":"goalPublicationPdfClicksReadMore","readMoreExperimentViewId":null,"comments":null,"figures":[],"figureAssetIds":[],"figureOverlayUrls":{"clickOnOverlay":"publication.PublicationFigures.html?_sg=TSUSWkJZUREauWC8YCdAaWc4ytGhyqLlDALV4q0NFhxA3cd3MbPIcZ2K9T80hHZa7NWCGmRZ2RKzvvE9aLNkNA.Rtqu2_a2fRj62qLOqtnnL_sg5ROFJ1xjXRN2PkXCZppB7C3ylYL32OvBoRArTdt4HaWYEZGWdSAt4CLbzefanA","clickOnPill":"publication.PublicationFigures.html?_sg=4bcJMD-XsF1YOHv1REcMBAOQ7bUGJBTFcCOlWkc5qfsuC1bGid3nuaWn83KmJC1n4Juw35wFQ9JerWTmmYxQcA.4vdd3bqhdSwwx-V7jMEc8aizb-YcMR-5UWoCzcpbssph-ht5E_mcKAnRHV8ZPrrAd72wJiIrV8cBYNOG6ySrEg"},"canSelect":false,"javascriptPath":"https:\/\/www.researchgate.net\/c\/o1o9o3\/","downloadUrl":"https%3A%2F%2Fwww.researchgate.net%2Fprofile%2FCedric_Archambeau%2Fpublication%2F23252767_The_Variational_Gaussian_Approximation_Revisited%2Flinks%2F0912f50aca8ae75c77000000.pdf%3FinViewer%3D1%26pdfJsDownload%3D1%26origin%3Dpublication_detail","viewerUrl":"https:\/\/www.researchgate.net\/c\/o1o9o3\/javascript\/lib\/pdfjs\/web\/viewer.html","commentEndpoint":"https:\/\/www.researchgate.net\/rgformat\/api\/comment","experimentEndpoint":"https:\/\/www.researchgate.net\/rgformat\/api\/experiment?key=Y1vdNA63IbJ1xmBjq6YD7sizRI2emaeW-cIs22nGg72Hr-m7lHc3-mBlyi4aFe_J6sAfvcY50wPuKo6b6fEIAQ","urlHash":"6f8cd24060407a2e5012ed09fa2dae79","downloadTrackUrl":"application.PdfJsReader.ajaxTrackDownload.html?msrp=5ovE9kXpR2jxkOrYlQ82xbWogYQHHZ0sxEumJPxwWnH7RiLPubSVg0GWJ0q0nHq5HiD8v4wRG0yMcw_bDmfPaXVZK2n6u8CsqZpYk-wP6Sg._RSxOLBVWXtHoVqULJMzx55TnVtyzo1NiSae5HDFPkDLFdMkrMS3Lsjsue1bCWJG1-TUpTop37iRK_1OaK0TBQ.LkxJZWW8n213tSUOwpMj6JOPxCIsBdK7IS9irNV8XFwtlwFpzgFlJsjqTxdSGT9CaJt9VenczxVayQx4jEW-fQ","viewportMilestoneTrackUrl":"application.PdfJsReader.ajaxTrackViewportMilestone.html","linkId":"0912f50aca8ae75c77000000","trackedDownloads":{"0912f50aca8ae75c77000000":{"v":false,"d":false}},"assetId":"AS:98587723698182@1400516553573","readerDocId":null,"assetType":"fulltext","interactionType":{"comment":"comment","highlight":"highlight"},"publicationUid":23252767,"commentCursorPromo":null,"widgetId":"rgw41_56ab1dd57cd9f"},"id":"rgw41_56ab1dd57cd9f","partials":[],"templateName":"application\/stubs\/PdfJsReader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PdfJsReader.html?fileHref=https%3A%2F%2Fwww.researchgate.net%2Fprofile%2FCedric_Archambeau%2Fpublication%2F23252767_The_Variational_Gaussian_Approximation_Revisited%2Flinks%2F0912f50aca8ae75c77000000.pdf%3FinViewer%3D1%26pdfJsDownload%3D1%26origin%3Dpublication_detail&assetId=AS%3A98587723698182%401400516553573&publicationUid=23252767&linkId=0912f50aca8ae75c77000000&onlyShowFirstPage=0","viewClass":null,"yuiModules":["css-pow-application-PdfJsReader"],"stylesheets":["pow\/application\/PdfJsReader.css"],"_isYUI":true},"showHeader":true,"title":"The Variational Gaussian Approximation Revisited","publicationType":"Article","downloadTrackUrl":"publicliterature.PublicationInlineReader.ajaxTrackDownload.html?msrp=SblIvHIhVKBE-7At6XYxlq178KNDFTbtRNb6O-6Pr_Pv2iHQHrP7bQQKjs3L7ioUFgOb0ko05vNjI3sImQAYjzCzcR3T8kr8tqjpg6No8d0.eHF_4D544GHyNOlACk-brtMekg5fy3jZxDwqWsFhWTu8UhgCgh1j0uu0to3FVipWFuAhlXK98XTW4YUlzdfZpw.PbtojXGtRbM6JF-Z3mPnsdZgawknj6jZykE6NzIoV1otyfP6Xf-1-iC2J6eVuonEYEorFcZhFOMzib3DRsw4vQ","publicationUid":23252767,"trackedDownloads":{"0912f50aca8ae75c77000000":{"v":false,"d":false}},"inlinePdf":false,"publicationComments":null,"showDownloadButton":true,"socialShare":{"data":{"shareItems":[{"data":{"name":"Facebook","url":"http:\/\/www.facebook.com\/share.php?u={{url}}{{#title}}&t={{title}}{{\/title}}","width":600,"height":350,"useUtmTags":true,"utmSource":"facebook","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareFacebook.ajaxTrackSocialShare.html","widgetId":"rgw43_56ab1dd57cd9f"},"id":"rgw43_56ab1dd57cd9f","partials":{"shareIcon":"application\/stubs\/partials\/shareFacebookBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareFacebook.html?provider=Facebook&shareIcon=shareIconBlog&utmSource=facebook&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"Twitter","url":"http:\/\/twitter.com\/intent\/tweet?text={{#title}}{{title}}: {{\/title}}{{url}}&via=researchgate","width":600,"height":350,"useUtmTags":true,"utmSource":"twitter","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareTwitter.ajaxTrackSocialShare.html","widgetId":"rgw44_56ab1dd57cd9f"},"id":"rgw44_56ab1dd57cd9f","partials":{"shareIcon":"application\/stubs\/partials\/shareTwitterBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareTwitter.html?provider=Twitter&shareIcon=shareIconBlog&utmSource=twitter&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"Google+","url":"https:\/\/plus.google.com\/share?url={{url}}","width":600,"height":600,"useUtmTags":true,"utmSource":"googleplus","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareGooglePlus.ajaxTrackSocialShare.html","widgetId":"rgw45_56ab1dd57cd9f"},"id":"rgw45_56ab1dd57cd9f","partials":{"shareIcon":"application\/stubs\/partials\/shareGooglePlusBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareGooglePlus.html?provider=Google%2B&shareIcon=shareIconBlog&utmSource=googleplus&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"LinkedIn","url":"http:\/\/www.linkedin.com\/shareArticle?mini=true&url={{url}}{{#title}}&title={{title}}{{\/title}}&source=ResearchGate","width":520,"height":570,"useUtmTags":true,"utmSource":"linkedin","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareLinkedIn.ajaxTrackSocialShare.html","widgetId":"rgw46_56ab1dd57cd9f"},"id":"rgw46_56ab1dd57cd9f","partials":{"shareIcon":"application\/stubs\/partials\/shareLinkedInBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareLinkedIn.html?provider=LinkedIn&shareIcon=shareIconBlog&utmSource=linkedin&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"Reddit","url":"https:\/\/www.reddit.com\/submit?url={{url}}{{#title}}&title={{title}}{{\/title}}","width":600,"height":600,"useUtmTags":true,"utmSource":"reddit","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareReddit.ajaxTrackSocialShare.html","widgetId":"rgw47_56ab1dd57cd9f"},"id":"rgw47_56ab1dd57cd9f","partials":{"shareIcon":"application\/stubs\/partials\/shareRedditBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareReddit.html?provider=Reddit&shareIcon=shareIconBlog&utmSource=reddit&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true}],"widgetId":"rgw42_56ab1dd57cd9f"},"id":"rgw42_56ab1dd57cd9f","partials":[],"templateName":"application\/stubs\/SocialShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.SocialShare.html?campaign=shareFullTextPublication&trackClick=1&shareIcon=shareIconBlog","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw40_56ab1dd57cd9f"},"id":"rgw40_56ab1dd57cd9f","partials":[],"templateName":"publicliterature\/stubs\/PublicationInlineReader.html","templateExtensions":["generalHelpers"],"attrs":{"showFulltextDownloadedSignupDialog":true,"preSignUpDialogContext":null,"requestFulltext":false},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationInlineReader.html","viewClass":"views.publicliterature.PublicationInlineReaderView","yuiModules":["rg.views.publicliterature.PublicationInlineReaderView","css-pow-publicliterature-PublicationInlineReader"],"stylesheets":["pow\/publicliterature\/PublicationInlineReader.css"],"_isYUI":true},"useFulltextOptimizedLayout":false,"publicationActions":null,"requestFulltextPromo":null,"currentUrl":"publication\/23252767_The_Variational_Gaussian_Approximation_Revisited","isLeaderboardAd":false,"enableStickyBox":null,"googleDfpSlotMobileBottom":null,"fullTextExitPopup":null,"showExitPopupDialog":false,"widgetId":"rgw2_56ab1dd57cd9f"},"id":"rgw2_56ab1dd57cd9f","partials":{"romeo_legal_notice":"publicliterature\/stubs\/partials\/romeo_legal_notice.html"},"templateName":"publicliterature\/stubs\/PublicPublicationDetails_NewLayout.html","templateExtensions":["generalHelpers"],"attrs":{"publicationUid":23252767},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicPublicationDetailsOld.html?publicationUid=23252767&isTestOldDesign=0","viewClass":"views.publicliterature.PublicPublicationDetailsOldView","yuiModules":["rg.views.publicliterature.PublicPublicationDetailsOldView"],"stylesheets":[],"_isYUI":true},"widgetId":"rgw1_56ab1dd57cd9f"},"id":"rgw1_56ab1dd57cd9f","partials":[],"templateName":"publicliterature\/stubs\/PublicPublicationDetails.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicPublicationDetails.html","viewClass":"views.publicliterature.PublicPublicationDetailsView","yuiModules":["rg.views.publicliterature.PublicPublicationDetailsView"],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"uaClass":"","headPrefix":[],"rootUrl":"https:\/\/www.researchgate.net\/","requestToken":"qvloLcsc42W2J8RIrg8ioEuOfGKPZ69Xtln8OhJa33yDoA6GzB7sCd8zZ4ZH5+mjkApDwDmr\/YsKQd5VrDvVNrG5rbzXN6ADlSqpxcWAfQVkAcLhgLq38DNE1aamM3Mp5roP\/RcgpBwCV\/W2BgzMtEdjwwp+NgWqG4Hqk++RYCeuqLsh+Ev4EuZns6WtW08OH8JZpm5bigZsfqHc3WQVVIDzPusTwDw63twEyqbwLWZe0FUuMPS5qo6zwnzM6nBudavST8J69tSFL3hJZxQ4SjDhCryFXBFux58\/9MVISH8=","faviconCdnUrl":"https:\/\/c5.rgstatic.net\/m\/2390829798215018\/images\/favicon.ico","headerOutput":"<noscript><\/noscript><link rel=\"canonical\" href=\"https:\/\/www.researchgate.net\/publication\/23252767_The_Variational_Gaussian_Approximation_Revisited\" \/>\n<link rel=\"dns-prefetch\" href=\"\/\/c5.rgstatic.net\" \/>\n<link rel=\"dns-prefetch\" href=\"\/\/i1.rgstatic.net\" \/>\n<meta property=\"twitter:card\" content=\"summary\" \/>\n<meta property=\"twitter:site\" content=\"@ResearchGate\" \/>\n<meta property=\"og:title\" content=\"The Variational Gaussian Approximation Revisited\" \/>\n<meta property=\"og:description\" content=\"The variational approximation of posterior distributions by multivariate gaussians has been much less popular in the machine learning community compared to the corresponding approximation by...\" \/>\n<meta property=\"og:site_name\" content=\"ResearchGate\" \/>\n<meta property=\"og:image\" content=\"https:\/\/i1.rgstatic.net\/publication\/23252767_The_Variational_Gaussian_Approximation_Revisited\/links\/0912f50aca8ae75c77000000\/smallpreview.png\" \/>\n<meta property=\"og:url\" content=\"https:\/\/www.researchgate.net\/publication\/23252767_The_Variational_Gaussian_Approximation_Revisited\" \/>\n<meta property=\"rg:id\" content=\"PB:23252767\" \/>\n<meta name=\"DC.identifier\" scheme=\"DCTERMS.URI\" content=\"http:\/\/dx.doi.org\/10.1162\/neco.2008.08-07-592\" \/>\n<meta name=\"gs_meta_revision\" content=\"1.1\" \/>\n<meta name=\"citation_title\" content=\"The Variational Gaussian Approximation Revisited\" \/>\n<meta name=\"citation_author\" content=\"Manfred Opper\" \/>\n<meta name=\"citation_author\" content=\"C\u00e9dric Archambeau\" \/>\n<meta name=\"citation_pmid\" content=\"18785854\" \/>\n<meta name=\"citation_publication_date\" content=\"2008\/10\/01\" \/>\n<meta name=\"citation_journal_title\" content=\"Neural Computation\" \/>\n<meta name=\"citation_issn\" content=\"0899-7667\" \/>\n<meta name=\"citation_volume\" content=\"21\" \/>\n<meta name=\"citation_issue\" content=\"3\" \/>\n<meta name=\"citation_firstpage\" content=\"786\" \/>\n<meta name=\"citation_lastpage\" content=\"92\" \/>\n<meta name=\"citation_doi\" content=\"10.1162\/neco.2008.08-07-592\" \/>\n<meta name=\"citation_pdf_url\" content=\"https:\/\/www.researchgate.net\/profile\/Cedric_Archambeau\/publication\/23252767_The_Variational_Gaussian_Approximation_Revisited\/links\/0912f50aca8ae75c77000000.pdf\" \/>\n<meta name=\"citation_abstract_html_url\" content=\"https:\/\/www.researchgate.net\/publication\/23252767_The_Variational_Gaussian_Approximation_Revisited\" \/>\n<meta name=\"citation_fulltext_html_url\" content=\"https:\/\/www.researchgate.net\/publication\/23252767_The_Variational_Gaussian_Approximation_Revisited\" \/>\n<meta name=\"viewport\" content=\"width=device-width,initial-scale=1\" \/>\n<link href=\"\/\/c5.rgstatic.net\/m\/22664197317151888\/styles\/rg.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/21004998181197492\/styles\/rg2.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<!--[if lt IE 9]><link href=\"\/\/c5.rgstatic.net\/m\/238176252723686\/styles\/ie.css\" type=\"text\/css\" rel=\"stylesheet\"\/><![endif]-->\n<link href=\"\/\/c5.rgstatic.net\/m\/217752362214895\/styles\/modules\/publicprofile.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/21993347442549\/styles\/pow\/publicliterature\/FollowPublicationPromo.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/282514599719602\/styles\/pow\/application\/PdfJsReader.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/23819663151220\/styles\/pow\/publicliterature\/PublicationInlineReader.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<script src=\"\/\/c5.rgstatic.net\/m\/2321000301012716\/javascript\/vendor\/webfontloader\/webfontloader.js\" type=\"text\/javascript\"><\/script>\n <script>(function(i,s,o,g,r,a,m){i[\"GoogleAnalyticsObject\"]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,\"script\",\"\/\/www.google-analytics.com\/analytics.js\",\"ga\");\n ga(\"create\",\"UA-58591210-1\");ga(\"set\",\"anonymizeIp\",true);ga('set', 'dimension1', 'publication full-text');ga('set', 'dimension2', 'Article');ga('set', 'dimension3', 'Logged out');ga('set', 'dimension4', 'https');ga(\"send\",\"pageview\");<\/script>\n","webfont":"<noscript><\/noscript><script> WebFontConfig = { custom: { families: ['source_sans_pro_italic', 'source_sans_pro_bold', 'source_sans_pro', 'martel'], urls : ['\/\/c5.rgstatic.net\/m\/231392577336386\/styles\/fonts.css'] } }; WebFont.load(WebFontConfig); <\/script>\n","correlationId":"rgreq-55d4f05f-678c-4ba0-bca4-9b36c6227fbb","accountId":null,"module":"publicliterature","action":"publicliterature.PublicPublicationDetails","page":"publicationDetail","product":"publications","backendTime":861,"continent":"Asia","stylesHome":"\/\/c5.rgstatic.net\/m\/","staticHost":"c5.rgstatic.net","useEarlyFlush":false,"longRunningRequestIdentifier":"LongRunningRequest.publicliterature.PublicPublicationDetails","longRunningRequestFp":"e9e5bbe1366c7ee8c8e41d02f793c884ac9be19b","widgetId":"rgw48_56ab1dd57cd9f"},"id":"rgw48_56ab1dd57cd9f","partials":[],"templateName":"application\/stubs\/StaticHeader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.StaticHeader.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){
            Y.rg.core.pagespeed.Monitoring.monitorPage("\/\/glassmoni.researchgate.net", "publicliterature.PublicPublicationDetails.run.html.loggedOut.get", "59de9668d07aeb77ab4de5f24d382b5d199d2437", "rgreq-55d4f05f-678c-4ba0-bca4-9b36c6227fbb", "adf68f25a03af40cf33c15137c631ece7cbccec1");
        
            Y.rg.core.pagespeed.Monitoring.monitorPage("\/\/glassmoni.researchgate.net", "publicationDetail.loggedOut", "ed1993d9e20f6cefa83edacaa24401a18c071aea", "rgreq-55d4f05f-678c-4ba0-bca4-9b36c6227fbb", "adf68f25a03af40cf33c15137c631ece7cbccec1");
        })();
(function(){Y.rg.createInitialWidget({"data":{"year":"2016","inlinePromo":null,"isAdmin":false,"contactUrl":"https:\/\/www.researchgate.net\/contact","aboutUsUrl":"https:\/\/www.researchgate.net\/about","widgetId":"rgw49_56ab1dd57cd9f"},"id":"rgw49_56ab1dd57cd9f","partials":[],"templateName":"application\/stubs\/DefaultFooter.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.DefaultFooter.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"headerLogin":{"data":{"urlAfterLogin":"publication\/23252767_The_Variational_Gaussian_Approximation_Revisited","requestToken":"y7lUdnCpewh8r+qXSjRwhOrAdcggKTmjxqk7FlKDvFXaeFWBLFFpz70WZ8WkVXMoEcMoPAFW+xKt+3rqryNp6JMJS0NehoFL+pvhHeamJaTxVoYqgBE0TSJTGT1EGzm4KutvFN2xLCBVKBZKUH3DPl0eLBZtA2HaQWOsCgFXmDgK01I\/uF+hhwdd4rRUf+hi1EWh8qTvKn8lq2gHk5NnejCBlZ6aWq+dlybcnAtbRLb6jInAyI8rLuhw8qtOUoJyxxXpoDiU5xxmQ23LKT\/dApWBN\/Jbw03tPv6f48aqStg=","loginUrl":"https:\/\/www.researchgate.net\/application.Login.html","signupUrl":"https:\/\/www.researchgate.net\/signup.SignUp.html?ev=su_chnl_index&hdrsu=1&_sg=FLgAj8w-GQQd78l5KB8-Ea2syiuqwelGFAmG3lrpYlYTbO5LnJ_EhC0fHwKqV9XW","encodedUrlAfterLogin":"cHVibGljYXRpb24vMjMyNTI3NjdfVGhlX1ZhcmlhdGlvbmFsX0dhdXNzaWFuX0FwcHJveGltYXRpb25fUmV2aXNpdGVk","signupCallToAction":"Join for free","widgetId":"rgw51_56ab1dd57cd9f"},"id":"rgw51_56ab1dd57cd9f","partials":{"partial":"application\/stubs\/partials\/headerLoginDefault.html"},"templateName":"application\/stubs\/HeaderLogin.html","templateExtensions":[],"attrs":{"goal":"milestoneHeaderLoginSeen"},"widgetUrl":"https:\/\/www.researchgate.net\/application.HeaderLogin.html","viewClass":"views.application.HeaderLoginView","yuiModules":["rg.views.application.HeaderLoginView"],"stylesheets":[],"_isYUI":true},"cookieConsent":null,"logoSvgSrc":"https:\/\/c5.rgstatic.net\/m\/235107188705592\/images\/template\/brand-header-logo.svg","logoFallbackSrc":"https:\/\/c5.rgstatic.net\/m\/238113351022438\/images\/template\/brand-header-logo.png","widgetId":"rgw50_56ab1dd57cd9f"},"id":"rgw50_56ab1dd57cd9f","partials":{"schemaSocialProfiles":"application\/stubs\/partials\/schemaSocialProfiles.html"},"templateName":"application\/stubs\/HeaderLoggedOut.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.HeaderLoggedOut.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"logEvent":"su_banner","specialCopy":false,"widgetId":"rgw52_56ab1dd57cd9f"},"id":"rgw52_56ab1dd57cd9f","partials":[],"templateName":"application\/stubs\/LoggedOutBanner.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.LoggedOutBanner.html","viewClass":"views.application.LoggedOutBannerView","yuiModules":["rg.views.application.LoggedOutBannerView"],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.core.util.ParameterFilter.filter(["ev","cp","ch","ref","dbw","pli","loginT","uid","claimChannel","enrichId","enrichSource","utm_source","utm_medium","utm_campaign","el","ci"]);})();
});}); } else { throw 'YRG was not loaded when attaching widgets'; }</script><script> dataLayer = [{"pageCategory":"publication full-text","publicationType":"Article","eventCategory":"Publication page"}]; </script> <noscript><iframe src="//www.googletagmanager.com/ns.html?id=GTM-MKVKH7" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-MKVKH7');</script><script>(function(e){function n(n,t,o,a){"use strict";var i=e.document.createElement("link"),r=t||e.document.getElementsByTagName("script")[0],d=e.document.styleSheets;return i.rel="stylesheet",i.href=n,i.media="only x",a&&(i.onload=a),r.parentNode.insertBefore(i,r),i.onloadcssdefined=function(e){for(var t,o=0;d.length>o;o++)d[o].href&&d[o].href.indexOf(n)>-1&&(t=!0);t?e():setTimeout(function(){i.onloadcssdefined(e)})},i.onloadcssdefined(function(){i.media=o||"all"}),i}function t(e,n){e.onload=function(){e.onload=null,n&&n.call(e)},"isApplicationInstalled"in navigator&&"onloadcssdefined"in e&&e.onloadcssdefined(n)}var o=function(a,i){"use strict";if(a&&3===a.length){var r=e.Image,d=!(!document.createElementNS||!document.createElementNS("http://www.w3.org/2000/svg","svg").createSVGRect||!document.implementation.hasFeature("http://www.w3.org/TR/SVG11/feature#Image","1.1")||e.opera&&-1===navigator.userAgent.indexOf("Chrome")||-1!==navigator.userAgent.indexOf("Series40")),c=new r;c.onerror=function(){o.method="png",o.href=a[2],n(a[2])},c.onload=function(){var e=1===c.width&&1===c.height,r=a[e&&d?0:e?1:2];o.method=e&&d?"svg":e?"datapng":"png",o.href=r,t(n(r),i)},c.src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///ywAAAAAAQABAAACAUwAOw==",document.documentElement.className+=" grunticon"}};o.loadCSS=n,o.onloadCSS=t,e.grunticon=o})(this);grunticon(["https://c5.rgstatic.net/c/o1o9o3/styles/icons/_header-ico.svg.css", "https://c5.rgstatic.net/c/o1o9o3/styles/icons/_header-ico.png.css", "https://c5.rgstatic.net/c/o1o9o3/styles/icons/_header-ico.fallback.scss"]);grunticon(["https://c5.rgstatic.net/c/o1o9o3/styles/icons/_admin-ico.svg.css", "https://c5.rgstatic.net/c/o1o9o3/styles/icons/_admin-ico.png.css", "https://c5.rgstatic.net/c/o1o9o3/styles/icons/_admin-ico.fallback.scss"]);grunticon(["https://c5.rgstatic.net/c/o1o9o3/styles/icons/_ico.svg.css", "https://c5.rgstatic.net/c/o1o9o3/styles/icons/_ico.png.css", "https://c5.rgstatic.net/c/o1o9o3/styles/icons/_ico.fallback.scss"]);</script></body>
</html>
