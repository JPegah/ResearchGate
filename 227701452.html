<!DOCTYPE html> <html lang="en" class="" id="rgw39_56ab9fc7d28b9"> <head > <meta charset="utf-8"/> <meta http-equiv="content-type" content="text/html; charset=UTF-8"/> <meta name="Rg-Request-Token" id="Rg-Request-Token" content="ANadGBl3+Lzt6KNN4DRbYevOzinqdHlDvCXEhE6AGeZFOTbSufDJ9Q4wTLbHCuBPuNZ4C1mBxNuoe6KJWbu1x9cByNlqSjxCcmP73vCPbLDjVpWMu3zc0K1nxsPtAyIs1RN5VlRXxLAq6GQ6Z67fPHZOs0UUGHHfUs/PjxQcgJu/LuuG6J3QGdSUwjG5pxueXBdsJMfQEGB16Q59L+k16BxlMKPp4FtjHwpYkh6FS703fwpGBRlme584ohRma50Z1vVGHozosXq9DNOowmf1p+52YCd/RdRfs06kzGxS/nY="/> <meta http-equiv="expires" content="0"/> <link rel="apple-touch-icon" sizes="57x57" href="https://www.researchgate.net/apple-touch-icon-57x57.png"> <link rel="apple-touch-icon" sizes="60x60" href="https://www.researchgate.net/apple-touch-icon-60x60.png"> <link rel="apple-touch-icon" sizes="72x72" href="https://www.researchgate.net/apple-touch-icon-72x72.png"> <link rel="apple-touch-icon" sizes="76x76" href="https://www.researchgate.net/apple-touch-icon-76x76.png"> <link rel="apple-touch-icon" sizes="114x114" href="https://www.researchgate.net/apple-touch-icon-114x114.png"> <link rel="apple-touch-icon" sizes="120x120" href="https://www.researchgate.net/apple-touch-icon-120x120.png"> <link rel="apple-touch-icon" sizes="144x144" href="https://www.researchgate.net/apple-touch-icon-144x144.png"> <link rel="apple-touch-icon" sizes="152x152" href="https://www.researchgate.net/apple-touch-icon-152x152.png"> <link rel="apple-touch-icon" sizes="180x180" href="https://www.researchgate.net/apple-touch-icon-180x180.png"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-32x32.png" sizes="32x32"> <link rel="icon" type="image/png" href="https://www.researchgate.net/android-chrome-192x192.png" sizes="192x192"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-96x96.png" sizes="96x96"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-16x16.png" sizes="16x16"> <link rel="shortcut icon" type="image/x-icon" href="https://c5.rgstatic.net/m/2390829798215018/images/favicon.ico"/> <link rel="manifest" href="https://www.researchgate.net/manifest.json"> <meta name="msapplication-TileColor" content="#da532c"> <meta name="msapplication-TileImage" content="https://www.researchgate.net/mstile-144x144.png"> <meta name="theme-color" content="#444444"> <link rel="search" type="application/opensearchdescription+xml" title="ResearchGate search" href="https://www.researchgate.net/application.DownloadOpenSearchPlugin.html"/> <link rel="meta" type="application/rdf+xml" title="ICRA labels" href="https://www.researchgate.net/application.DownloadLabels.html"/> <link rel="http://oexchange.org/spec/0.8/rel/related-target" type="application/xrd+xml" href="https://www.researchgate.net/application.DownloadOExchange.html"/> <base href="https://www.researchgate.net/"/> <script>
    var rgConfig = {
        correlationId: "rgreq-255ecbd5-1344-437a-a0df-0235699bfd6d",
        accountId: "",
        module: "publicliterature",
        action: "publicliterature.PublicPublicationDetails",
        page: "publicationDetail",
        product: "publications",
        continent: "Asia",
        stylesHome: "//c5.rgstatic.net/m/",
        staticHost: "c5.rgstatic.net",
        longRunningRequestIdentifier: "LongRunningRequest.publicliterature.PublicPublicationDetails",
        longRunningRequestFp: "e9e5bbe1366c7ee8c8e41d02f793c884ac9be19b"
    };
    window.rootUrl = "https://www.researchgate.net/";
</script> <link rel="canonical" href="https://www.researchgate.net/publication/227701452_Log_Gaussian_Cox_Processes" />
<link rel="dns-prefetch" href="//c5.rgstatic.net" />
<link rel="dns-prefetch" href="//i1.rgstatic.net" />
<meta property="twitter:card" content="summary" />
<meta property="twitter:site" content="@ResearchGate" />
<meta property="og:title" content="Log Gaussian Cox Processes" />
<meta property="og:description" content="Planar Cox processes directed by a log Gaussian intensity process are investigated in the univariate and multivariate cases. The appealing properties of such models are demonstrated theoretically..." />
<meta property="og:site_name" content="ResearchGate" />
<meta property="og:image" content="https://i1.rgstatic.net/publication/227701452_Log_Gaussian_Cox_Processes/links/02e7e51a6f17c691d3000000/smallpreview.png" />
<meta property="og:url" content="https://www.researchgate.net/publication/227701452_Log_Gaussian_Cox_Processes" />
<meta property="rg:id" content="PB:227701452" />
<meta name="DC.identifier" scheme="DCTERMS.URI" content="http://dx.doi.org/10.1111/1467-9469.00115" />
<meta name="gs_meta_revision" content="1.1" />
<meta name="citation_title" content="Log Gaussian Cox Processes" />
<meta name="citation_author" content="Jesper MÃ¸ller" />
<meta name="citation_author" content="Anne Randi Syversveen" />
<meta name="citation_author" content="Rasmus Plenge Waagepetersen" />
<meta name="citation_publication_date" content="1998/08/31" />
<meta name="citation_journal_title" content="Scandinavian Journal of Statistics" />
<meta name="citation_issn" content="1467-9469" />
<meta name="citation_volume" content="25" />
<meta name="citation_issue" content="3" />
<meta name="citation_firstpage" content="451" />
<meta name="citation_lastpage" content="482" />
<meta name="citation_doi" content="10.1111/1467-9469.00115" />
<meta name="citation_pdf_url" content="https://www.researchgate.net/profile/Anne_Syversveen/publication/227701452_Log_Gaussian_Cox_Processes/links/02e7e51a6f17c691d3000000.pdf" />
<meta name="citation_abstract_html_url" content="https://www.researchgate.net/publication/227701452_Log_Gaussian_Cox_Processes" />
<meta name="citation_fulltext_html_url" content="https://www.researchgate.net/publication/227701452_Log_Gaussian_Cox_Processes" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<link href="//c5.rgstatic.net/m/22664197317151888/styles/rg.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/21004998181197492/styles/rg2.css" type="text/css" rel="stylesheet"/>
<!--[if lt IE 9]><link href="//c5.rgstatic.net/m/238176252723686/styles/ie.css" type="text/css" rel="stylesheet"/><![endif]-->
<link href="//c5.rgstatic.net/m/217752362214895/styles/modules/publicprofile.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/21993347442549/styles/pow/publicliterature/FollowPublicationPromo.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/282514599719602/styles/pow/application/PdfJsReader.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/23819663151220/styles/pow/publicliterature/PublicationInlineReader.css" type="text/css" rel="stylesheet"/>
<script src="//c5.rgstatic.net/m/2321000301012716/javascript/vendor/webfontloader/webfontloader.js" type="text/javascript"></script>
 <script>(function(i,s,o,g,r,a,m){i["GoogleAnalyticsObject"]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,"script","//www.google-analytics.com/analytics.js","ga");
 ga("create","UA-58591210-1");ga("set","anonymizeIp",true);ga('set', 'dimension1', 'publication full-text');ga('set', 'dimension2', 'Article');ga('set', 'dimension3', 'Logged out');ga('set', 'dimension4', 'https');ga("send","pageview");</script>
  <script> WebFontConfig = { custom: { families: ['source_sans_pro_italic', 'source_sans_pro_bold', 'source_sans_pro', 'martel'], urls : ['//c5.rgstatic.net/m/231392577336386/styles/fonts.css'] } }; WebFont.load(WebFontConfig); </script><noscript></noscript>

<title>Log Gaussian Cox Processes (PDF Download Available)</title>
<meta name="description" content="Official Full-Text Publication: Log Gaussian Cox Processes on ResearchGate, the professional network for scientists."/>
<meta name="keywords" content="scientific network, scientific platform, scientific community, research partner, research collaboration, journal articles, international collaboration, find researcher, lifescience researcher, interdisciplinary research, research collaboration"/>
</head>
<body class="use-svg-icons logged-out">
<div id="page-container">
<script type="text/javascript">var googletag = googletag || {}; googletag.cmd = googletag.cmd || [];
(function() { var gads = document.createElement("script"); gads.async = true; gads.type = "text/javascript"; var useSSL = "https:" == document.location.protocol; gads.src = (useSSL ? "https:" : "http:") + "//www.googletagservices.com/tag/js/gpt.js"; var node =document.getElementsByTagName("script")[0]; node.parentNode.insertBefore(gads, node); })();</script><div id="main" class="logged-out-header-support">
<div id="content" class="">

<noscript>
<div class="c-box-warning full-width-element" style="text-align: center; ">
    <div style="margin: auto; padding:10px;" class="container">
        <b>For full functionality of ResearchGate it is necessary to enable JavaScript.
            Here are the <a href="http://www.enable-javascript.com/" rel="nofollow" target="_blank">
                instructions how to enable JavaScript in your web browser</a>.</b>
    </div>
</div>
</noscript>

<div id="rgw1_56ab9fc7d28b9" itemscope itemtype="http://schema.org/ScholarlyArticle"><div class="publication-wrapper publication-wrapper-onecol" id="rgw2_56ab9fc7d28b9" itemscope itemtype="http://schema.org/ScholarlyArticle"> <div class="c-col-content"> <div class="c-content"> <div class="clearfix">  <div class="publication-header"> <div id="rgw5_56ab9fc7d28b9">  <div class="type-label"> Article   </div> <span class="Z3988" title="ctx_ver=Z39.88-2004&rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&rfr_id=info%3Asid%2Fresearchgate.net%3Aresearchgate&rft_id=info%3Adoi%2F10.1111%2F1467-9469.00115&rft.atitle=Log%20Gaussian%20Cox%20Processes&rft.title=Scandinavian%20Journal%20of%20Statistics&rft.jtitle=Scandinavian%20Journal%20of%20Statistics&rft.volume=25&rft.issue=3&rft.date=1998&rft.pages=451%20-%20482&rft.issn=1467-9469&rft.au=Jesper%20M%C3%B8ller%2CAnne%20Randi%20Syversveen%2CRasmus%20Plenge%20Waagepetersen&rft.genre=article"></span> <h1 class="pub-title" itemprop="name">Log Gaussian Cox Processes</h1> <meta itemprop="headline" content="Log Gaussian Cox Processes">  <meta itemprop="image" content="https://i1.rgstatic.net/publication/227701452_Log_Gaussian_Cox_Processes/links/02e7e51a6f17c691d3000000/smallpreview.png">  <div id="rgw8_56ab9fc7d28b9" class="publication-detail-author-list"> <div> <ul class="clearfix js-people-list">  <li id="rgw9_56ab9fc7d28b9"> <a href="researcher/2040135095_Jesper_Moller" class="pub-detail-item author-item" itemprop="author" itemscope itemtype="http://schema.org/Person"> <div class="indent-left"> <div class="people-img">  <img src="https://c5.rgstatic.net/m/2951093203564/images/template/default/profile/profile_default_s.jpg" title="Jesper MÃ¸ller" alt="Jesper MÃ¸ller" height="20px" width="20px" style="height: 20px;"/>  </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Jesper MÃ¸ller</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item   not-claimed " id="rgw10_56ab9fc7d28b9">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="researcher/2040135095_Jesper_Moller"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="Jesper MÃ¸ller" alt="Jesper MÃ¸ller" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">       </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="researcher/2040135095_Jesper_Moller" class="display-name">Jesper MÃ¸ller</a>    </h5> <div class="truncate-single-line meta">   </div>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>  <li id="rgw11_56ab9fc7d28b9" itemprop="author" itemscope itemtype="http://schema.org/Person"> <a itemprop="sameAs" href="profile/Anne_Syversveen" class="pub-detail-item account-item"> <div class="indent-left"> <div class="people-img"> <img  src="https://c5.rgstatic.net/m/2671872220764/images/template/default/profile/profile_default_m.jpg" title="Anne Randi Syversveen" alt="Anne Randi Syversveen" height="20px" width="20px" style="height: 20px;"/> </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Anne Randi Syversveen</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item  remove-action-indent   " id="rgw12_56ab9fc7d28b9" data-account-key="Anne_Syversveen">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="profile/Anne_Syversveen"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="Anne Randi Syversveen" alt="Anne Randi Syversveen" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">     </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="profile/Anne_Syversveen" class="display-name">Anne Randi Syversveen</a>    </h5> <div class="truncate-single-line meta">   <a class="meta ga-top-coauthor-institution" href="institution/Norwegian_Computing_Center" title="Norwegian Computing Center">Norwegian Computing Center</a>     </div>  <a href="javascript:" class="btn btn-promote btn-large people-item-contact-author js-contact-author">Message author</a>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>  <li id="rgw13_56ab9fc7d28b9"> <a href="researcher/38142003_Rasmus_Plenge_Waagepetersen" class="pub-detail-item author-item" itemprop="author" itemscope itemtype="http://schema.org/Person"> <div class="indent-left"> <div class="people-img">  <img src="https://c5.rgstatic.net/m/2951093203564/images/template/default/profile/profile_default_s.jpg" title="Rasmus Plenge Waagepetersen" alt="Rasmus Plenge Waagepetersen" height="20px" width="20px" style="height: 20px;"/>  </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Rasmus Plenge Waagepetersen</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item   not-claimed " id="rgw14_56ab9fc7d28b9">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="researcher/38142003_Rasmus_Plenge_Waagepetersen"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="Rasmus Plenge Waagepetersen" alt="Rasmus Plenge Waagepetersen" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">       </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="researcher/38142003_Rasmus_Plenge_Waagepetersen" class="display-name">Rasmus Plenge Waagepetersen</a>    </h5> <div class="truncate-single-line meta">   </div>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>   </ul> <div class="js-loading"></div>  </div> </div> <div class="pub-details js-pub-details">  <div> Aalborg University, Ãlborg, North Denmark, Denmark </div>      <span itemprop="isPartOf" itemscope itemtype="http://schema.org/Periodical"> <a itemprop="sameAs" href="journal/1467-9469_Scandinavian_Journal_of_Statistics"><span itemprop="name">Scandinavian Journal of Statistics</span></a> </span>    (Impact Factor: 0.87).     <meta itemprop="datePublished" content="1998-08">  08/1998;  25(3):451 - 482.    DOI:&nbsp;10.1111/1467-9469.00115           </div> <div id="rgw15_56ab9fc7d28b9" class="pub-abstract">  <div class="clearfix">   <div style="max-height: 54px;" class="js-expander-container js-expander-collapsed">  <p itemprop="description"> <strong>ABSTRACT</strong> <div>Planar Cox processes directed by a log Gaussian intensity process are investigated in the univariate and multivariate cases. The appealing properties of such models are demonstrated theoretically as well as through data examples and simulations. In particular, the first, second and third-order properties are studied and utilized in the statistical analysis of clustered point patterns. Also empirical Bayesian inference for the underlying intensity surface is considered.</div> </p>  </div>  </div>   </div>      <div class="action-container"> <div id="rgw16_56ab9fc7d28b9" class="follow-publication-promo"> <table> <tr> <td class="follow-publication-promo-text-cell"> <p>Get notified about updates to this publication</p> <a class="btn btn-large btn-promote js-follow-publication ga-follow-publication-new-promo">Follow publication</a> </td> <td> <div class="follow-publication-publication-image"></div> </td> </tr> </table> </div>  <div class="clear"></div> <div class="share-dialog-container" style="display: none;">  </div> </div> </div> <div style="margin-left: -20px; margin-right: -20px;">  </div> </div>  <div class="publication-detail-dfp-container rf"> <div id="rgw30_56ab9fc7d28b9">  </div> </div>  </div>  <div class="clearfix"> <div class="pdf-js-container clearfix " id="rgw31_56ab9fc7d28b9">  <div class="pdf-js-header js-sticky-header clear">  <a class="blue-link js-download rf btn btn-promote" href="https://www.researchgate.net/profile/Anne_Syversveen/publication/227701452_Log_Gaussian_Cox_Processes/links/02e7e51a6f17c691d3000000.pdf?inViewer=0&amp;pdfJsDownload=0&amp;origin=publication_detail">Download full-text</a>  <h3>Full-text</h3> <span class="publication-info">  <span class="js-doi-container" style="display: none;"> DOI: <span class="js-doi"></span> &middot; </span> Available from: <a class="js-name" href="profile/Anne_Syversveen">Anne Randi Syversveen</a>   </span>  </div>  <div class="social-share-container"><div id="rgw33_56ab9fc7d28b9" class="social-share js-social-share"> <div class="social-share-heading">Share</div>  <a id="rgw34_56ab9fc7d28b9" href="javascript:" title="Share on Facebook" class="link-nostyle js-share-item share-icon "  data-url="http://www.facebook.com/share.php?u={{url}}{{#title}}&amp;t={{title}}{{/title}}" data-width="600" data-height="350" data-name="Facebook"> <span class="share-icon ico-share-facebook-round reset-background ga-share-blog-facebook"></span> </a>  <a id="rgw35_56ab9fc7d28b9" href="javascript:" title="Share on Twitter" class="link-nostyle js-share-item share-icon "  data-url="http://twitter.com/intent/tweet?text={{#title}}{{title}}: {{/title}}{{url}}&amp;via=researchgate" data-width="600" data-height="350" data-name="Twitter"> <span class="share-icon ico-share-twitter-round reset-background ga-share-blog-twitter"></span> </a>  <a id="rgw36_56ab9fc7d28b9" href="javascript:" title="Share on Google+" class="link-nostyle js-share-item share-icon "  data-url="https://plus.google.com/share?url={{url}}" data-width="600" data-height="600" data-name="Google+"> <span class="share-icon ico-share-gplus-round reset-background ga-share-blog-gplus"></span> </a>  <a id="rgw37_56ab9fc7d28b9" href="javascript:" title="Share on LinkedIn" class="link-nostyle js-share-item share-icon "  data-url="http://www.linkedin.com/shareArticle?mini=true&amp;url={{url}}{{#title}}&amp;title={{title}}{{/title}}&amp;source=ResearchGate" data-width="520" data-height="570" data-name="LinkedIn"> <span class="share-icon ico-share-linkedin-round reset-background ga-share-blog-linkedin"></span> </a>  <a id="rgw38_56ab9fc7d28b9" href="javascript:" title="Share on Reddit" class="link-nostyle js-share-item share-icon "  data-url="https://www.reddit.com/submit?url={{url}}{{#title}}&amp;title={{title}}{{/title}}" data-width="600" data-height="600" data-name="Reddit"> <span class="share-icon ico-share-reddit reset-background ga-share-blog-reddit"></span> </a>  </div></div>    <iframe id="rgw32_56ab9fc7d28b9" src="https://www.researchgate.net/c/o1q2er/javascript/lib/pdfjs/web/viewer.html?file=https%3A%2F%2Fwww.researchgate.net%2Fprofile%2FAnne_Syversveen%2Fpublication%2F227701452_Log_Gaussian_Cox_Processes%2Flinks%2F02e7e51a6f17c691d3000000.pdf%3FinViewer%3D1%26pdfJsDownload%3D1%26origin%3Dpublication_detail" allowfullscreen frameborder="0" style="width: 100%; height: 100%; box-sizing: border-box;"></iframe>    </div> <noscript> <div id="rgw29_56ab9fc7d28b9"  itemprop="articleBody">  <p>Page 1</p> <p>Log Gaussian Cox processes<br />by<br />Jesper MÃ¸ller,<br />Anne Randi Syversveen,<br />and Rasmus Plenge Waagepetersen.</p>  <p>Page 2</p> <p></p>  <p>Page 3</p> <p>Log Gaussian Cox processes<br />JESPER MÃLLER<br />Aalborg University<br />ANNE RANDI SYVERSVEEN<br />The Norwegian University of Science and Technology<br />RASMUS PLENGE WAAGEPETERSEN<br />University of Aarhus<br />ABSTRACT. Planar Cox processes directed by a log Gaussian intensity process<br />are investigated in the univariate and multivariate cases. The appealing properties<br />of such models are demonstrated theoretically as well as through data examples<br />and simulations. In particular, the first, second and third-order properties are<br />studied and utilized in the statistical analysis of clustered point patterns. Also<br />empirical Bayesian inference for the underlying intensity surface is considered.<br />Key words: empirical Bayesian inference; ergodicity; Markov chain Monte Carlo;<br />Metropolis-adjusted Langevin algorithm; multivariate Cox processes; Neyman-Scott<br />processes; pair correlation function; parameter estimation; spatial point processes; third-<br />order properties.<br />AMS 1991 subject classification: Primary 60G55, 62M30. Secondary 60D05.<br />1 Introduction<br />Cox processes provide useful and frequently applied models for aggregated spatial<br />point patterns where the aggregation is due to a stochastic environmental heterogeneity,<br />see e.g. Diggle (1983), Cressie (1993), Stoyan et al. (1995), and the references therein.<br />A Cox process is âdoubly stochasticâ as it arises as an inhomogeneous Poisson process<br />with a random intensity measure. The random intensity measure is often specified by a<br />random intensity function or as we prefer to call it an intensity process or surface.<br />There may indeed be other sources of aggregation in a spatial point pattern than<br />spatial heterogeneity. Cluster processes is a well-known class of models where clusters<br />are generated by an unseen point process, cf. the references mentioned above. The class<br />of nearest-neighbour Markov point processes (Baddeley and MÃ¸ller, 1989) include many<br />specific models of cluster processes (Baddeley et al., 1996) as well as other types of<br />processes with clustering modelled by âinteraction functionsâ (MÃ¸ller, 1994) such as the<br />penetrable sphere model (Widom and Rowlinson, 1970; Baddeley and Van Lieshout,<br />1995) and the continuum random cluster model (MÃ¸ller, 1994; HÂ¨ aggstrÂ¨ om et al., 1996).<br />In this paper we consider log Gaussian Cox processes, i.e. Cox processes where<br />the logarithm of the intensity surface is a Gaussian process. We show that the class of<br />1</p>  <p>Page 4</p> <p>stationary log Gaussian Cox processes possesses various appealing properties: (i) The<br />distribution is completely characterized by the intensity and the pair correlation function<br />of the Cox process. This makes parametric models easy to interpret and simple methods<br />are available for parameter estimation and model checking. (ii) Theoretical properties<br />are easily derived. Higher-order properties are for instance simply expressed by the<br />intensity and the pair correlation function of the log Gaussian Cox process. Thereby<br />summary statistics based on e.g. the third-order properties can be constructed and<br />estimated. (iii) The underlying Gaussian process and intensity surface can be predicted<br />from a realization of a log Gaussian Cox process observed within a bounded window<br />using Bayesian methods. (vi) There is no problem with edge effects as the distribution<br />of a log Gaussian Cox process restricted to a bounded subset is known.<br />The properties (i)-(vi) are rather characteristic for Log Gaussian Cox processes. We<br />shall further note that log Gaussian Cox processes are flexible models for clustering,<br />easy to simulate, and that the definition of univariate log Gaussian Cox processes can<br />be extended in a natural way to multivariate log Gaussian Cox processes.<br />Other transformations than the exponential of the Gaussian process may be con-<br />sidered as well, and in particular ??Cox processes (as defined in Section 3) may be<br />of interest.<br />During the final preparation of this paper we realized that a definition of Log<br />Gaussian Cox processes has previously been given in Rathbun and Cressie (1994), but<br />they restrict attention to the case where the intensity is constant within square quadrats<br />and modelled by a conditional autoregression (Besag, 1974). The advantage of these<br />discretized models is mainly that they can easily be explored using Gibbs sampling, but<br />as noticed by Rathbun and Cressie (1994) such models does not converge to anything<br />reasonable as the sides of the quadrats tend to zero. Consequently, it is difficult to<br />investigate the correlation structure of these Gaussian random field models through<br />those summary statistics which are usually estimated for a point pattern such as the<br />pair correlation function. The log Gaussian Cox processes studied in the present paper<br />are in contrast to this specified by such characteristics, and discretized versions of our<br />log Gaussian Cox processes can be simulated exactly without any problem with edge<br />effects. Also the Metropolis-adjusted Langevin algorithm (Besag, 1994; Roberts and<br />Tweedie, 1997) for simulating from the posterior of the intensity surface as studied in<br />Section 8 is both easy to specify and implement. In contrast and even if we ignore the<br />problem with edge effects, Gibbs sampling from the posterior becomes straightforward<br />only if one uses conditional autoregression priors.<br />The paper is organized as follows. In Section 2 we give a formal definition<br />of univariate log Gaussian Cox processes and inspect some of their properties by<br />simulations. Theoretical results are established in Section 3. In Section 4 we compare<br />log Gaussian Cox processes with the class of Neyman-Scott processes with a Poisson<br />distributed number of offspring. Extensions of log Gaussian Cox processes to the<br />multivariate case are studied in Section 5. In Section 6 we describe different simulation<br />procedures. Section 7 is concerned with parameter estimation and model checking of<br />parametric models for log Gaussian Cox processes. We illustrate this by considering<br />2</p>  <p>Page 5</p> <p>some data sets of univariate and bivariate point patterns. Finally, in Section 8 we<br />discuss how empirical Bayesian methods may be used for the purpose of predicting the<br />unobserved Gaussian process and intensity surface.<br />2 Univariate log Gaussian Cox processes<br />For specificity and since all the examples presented later on are planar we specify<br />the model in<br />Briefly, by a planar spatial point process we shall understand a locally finite random<br />subset ? of the plane<br />process ? ? ????? ? ? ?<br />process with intensity function ????, i.e. when for bounded Borel sets ? ?<br />conditional on ? that ?????? ??? is Poisson distributed with a mean?<br />hence ? is stationary and sometimes also isotropic, i.e. when the distribution of ? is<br />invariant under translations and possibly also rotations in<br />?, but our model can be completely similar defined in<br />?, ? ? ???????.<br />?. This is said to be a Cox process directed by a random intensity<br />?? if the conditional distribution of ? given ? is a Poisson<br />?we have<br />??????? which<br />is assumed to be nonnegative and finite. We restrict attention to the case where ? and<br />?. The intensity<br />? ? ?????<br />is henceforth assumed to be strictly positive and finite.<br />Throughout this paper we model the intensity process by a log Gaussian process:<br />???? ? ????? ????<br />?? is a real-valued Gaussian process (i.e., the joint distribution<br />of any finite vector ?? ?????????? ????? is Gaussian). It is necessary to impose conditions<br />on ? so that the random mean measure ? given by ???? ??<br />sets ? ?<br />of ? are integrable almost surely. But further conditions are required in order that ? is<br />uniquely determined by the distribution of ? . Here we impose the natural condition that<br />? is given in terms of a continuous modification of ? . Then ? is uniquely determined,<br />since all the continuous modifications are indistinguishable (i.e. their realizations are<br />identical with probability one), and it also follows that ???? ? ? for bounded ?.<br />By stationarity, the distribution of ? and hence ? is specified by the mean<br />? ? ?? ???, the variance ??? ? ???? ????, and the correlation function ????? ??? ?<br />????? ?????? ????????of ? . The model is only well-defined for positive semi-definite<br />correlation functions, i.e. when<br />??????????<br />best be answered through a spectral analysis, see e.g. Christakos (1984), Wackernagel<br />(1995), and the references therein. Furthermore, if there exist ? ? ? and ? ? ? such<br />that ? ? ???? ? ???????????????for all ? with ??? ? ?, then the existence of an<br />almost surely continuous modification is quaranteed (Adler, 1981, page 60). A stronger<br />condition, which in our experience is easier to check, is given by that ?????? ???????<br />for some?? ? ? and ? ? ?.<br />(1)<br />where ? ? ?? ??? ? ? ?<br />?<br />?????? for bounded Borel<br />?, becomes well-defined. First it is of course required that the realizations<br />?<br />???????????? ??? ? ? for all ????????? ?<br />?, ? ? ???????. Whether a given function is positive semi-definite may<br />,<br />3</p>  <p>Page 6</p> <p>The parameters ??? ? and ? ? ? have a clear interpretation as a scale and<br />shape parameter, respectively, since we can write ????<br />stationary Gaussian process with mean ?, variance ??, and correlation function ????.<br />The homogeneous Poisson process may be considered as the limit of a log Gaussian<br />Cox process as ? tends to 0. Another extreme case is ???? ? ?, whereby we obtain<br />a mixed Poisson process with a randomized intensity ???? ? ? which is log Gaussian<br />distributed.<br />If the distribution of ? is invariant under rotations, ???? ? ???????? depends only<br />on ? through its length ?????, so the correlation function is invariant under reflections<br />too. Consequently, invariance under translations and rotations implies that the joint<br />distribution of ???? ? is invariant under rigid motions ? in<br />???? ??<br />Examples of isotropic correlation models are listed in Table 1. The condition for<br />existence of an almost surely continuous modification holds for all of these correlation<br />functions which furthermore all tend to 0 at infinity. Notice that the correlation models<br />are parametrized by a scale parameter ? so that the three types of processes (Gaussian,<br />intensity, and Cox) are all parametrized by ??????? ??????????????????????.<br />The âscaleâ of the parameter ? is with respect to locations: with obvious notation,<br />??????<br />The first four models in Table 1 represent well the correlation structures which can<br />be achieved by using the correlation models in this table, so we have restricted attention<br />to these four models in the following Fig.âs 1â3. In Theorem 1, Section 3, it is shown<br />that the corresponding pair correlation functions are given by the exponential to the<br />covariance function ??????. These pair correlation functions are plotted in Fig. 1 a)-d)<br />for various values of ? when ? ? ?. If one âstandardizesâ the pair correlation function<br />???? to ???? ? ? or equivalently takes ? ? ?, plots of corresponding pair correlation<br />and covariance functions look very similar, cf. Fig. 1, a)-b) and g)-h).<br />Simulated realizations of Gaussian processes on the unit square with correlation<br />structure given by the four different types of correlation functions are shown in Fig.<br />2. Fig. 3 shows simulations of the corresponding log Gaussian Cox processes. The<br />parameters in the first row in Fig. 3 are the same as in Fig. 2. In order to facilitate<br />comparison of the four different Cox processes the ?-values in Fig. 3 are chosen so<br />that the mean and variance of the number of points are equal for all Cox processes<br />in the same row. By Theorem 1, Section 3, the mean is ? ? ????? ? ????? and the<br />variance is given by<br />?? ????<br />???, where ?????? is a<br />?: ??????? ???????<br />??<br />??<br />???????????????? ? ?<br />??.<br />? ??<br />?<br />????<br />?<br />? ? ????????<br />? ? ? ??<br />?<br />?<br />?<br />?<br />??????<br />?<br />??????<br />????????????? ? ?<br />?<br />??<br />?<br />The variance thus increases when ? and hence the correlation increases. It is difficult to<br />compare unconditional simulations when the variance of the number of points is large<br />and the simulations in Fig.âs 2 and 3 are therefore performed conditional on that the<br />number ? of points equals the mean number of points (? ? ? ? ???).<br />4</p>  <p>Page 7</p> <p>In the upper row in Fig. 3 a moderate value of ? but large values of ? give rise<br />to large but not dense clusters of points. In the lower row moderate values of ? but a<br />higher value of ? lead to many but small clusters. In the middle row a high value of ?<br />and intermediate values of ? are used, and compared to the lowest row fewer but larger<br />clusters appear. The realizations of the âGaussianâ and âcardinal sineâ log Gaussian Cox<br />processes are visually quite similar. The âstableâ log Gaussian Cox process is in general<br />less clustered than the other processes. This is not surprising because the Gaussian<br />random field with the stable correlation function is not very peaked except at the small<br />scale, c.f. Fig. 2.<br />Finally, it should be noted that Cox processes may be extended to models on<br />bounded regions ? ?<br />?? ? ????? ? ? ? ?? is of a Gibbsian type. For instance, consider a conditional<br />distribution of ?? given ?? ? ?? with density<br />??<br />???<br />?, where the conditional distribution of ??? ? ? ? given<br />???????? ? ?????<br />?<br />?????<br />??<br />?<br />?<br />?<br />???????<br />??????? ?????<br />?<br />?<br />?<br />with respect to a unit rate Poisson point process and for ?? ? ??????????? ? ?,<br />where e.g. ?? models the large scale properties and the function ???? ? ? specifies<br />pairwise interactions terms at the small scale. Although the marginal distribution of ?<br />restricted to ? becomes analytically intractable, such models may at least be simulated<br />and statistical inference may be performed by Markov chain Monte Carlo methods.<br />3 Theoretical results<br />Theoretical properties of Cox processes have been extensively studied, see e.g.<br />Grandell (1976), Daley and Vere-Jones (1988), and Karr (1991). In this section we<br />establish further results for log Gaussian Cox processes. In particular, we discuss the<br />first, second and third-order properties of a univariate log Gaussian Cox process. As<br />in the previous section we consider the planar case, but many of the presented results<br />hold as well in<br />The most useful characteristics for our purpose are the nth order product densities<br />????? ? ? ???????, for the reduced moment measures of the Cox process ?. These are<br />given by the moments of the intensity process as<br />?, ? ? ?????? (with obvious modifications in a few places).<br />??????????????? ? ?<br />?<br />?<br />?<br />?????<br />for pairwise different ??????????<br />is the probability that ? has a point in each of ? infinitesimally small disjoint regions<br />of volumes ???????????.<br />?. Intuitively speaking ????????????????????????<br />5</p>  <p>Page 8</p> <p>Theorem 1. A log Gaussian Cox process ? is stationary if and only if the corresponding<br />Gaussian field ? is stationary. For a stationary log Gaussian Cox process we have<br />?<br />??????????????? ? ???<br />?<br />??? ? ??<br />?<br />?<br />??<br />??<br />?<br />???????<br />????? ???<br />?<br />?<br />?<br />?<br />?<br />? ??<br />???????<br />????? ???<br />(2)<br />where<br />? ? ??????? ? ????? ? ?????<br />????? ??? ? ??????????????? ??????????? ????<br />are the intensity and the pair correlation function of the process, respectively.<br />(3)<br />and<br />(4)<br />Proof.<br />tribution ?????? with mean ? and variance ?.<br />??<br />Hence, by (1), ??????????????? ? ???????<br />?????????????????????????????? are in particular given by ??????? ? ???????? ? ??????<br />and ???????? ? ???????????????????????? whereby (2)-(4) follow when ? is stationary.<br />If ? is stationary then ??????? ? ?? and we can write ???????? ? ????? ???.<br />By letting ?? ? ?? it follows that ????? ? ??? ???? is constant, and further that<br />???? ? ? ? ?????? ? ???? and ???????? ? ????? ??? ? ????????? ???????, whereby<br />? is stationary. Finally, by definition of a log Gaussian Cox process, stationarity of ?<br />implies stationarity of ?.<br />Let ???? ? ????? ? ?????? be the Laplace transform of the normal dis-<br />Let ? ?<br />??<br />?? ???? ? ??????.<br />?????? and ? ?<br />??? ????, ?????<br />??????? ? ??<br />????????????????????????? where ????<br />? ???? ????? and ?????? is the correlation function of ? . Then??<br />first order product density ??????? and the pair correlation function ???????? ?<br />??<br />?? ????? ? ????? ? ????.The<br />Theorem 1 reflects the fact that the distribution of a log Gaussian Cox process is<br />completely determined by ?????????? or equivalently by ???????? (since ???? ? ?). It<br />follows from (4) and the definition of a log Gaussian Cox process that it is isotropic if and<br />only if the underlying Gaussian process is isotropic or equivalently when ???? ? ????????.<br />Especially, when ???? ? ? is a log Gaussian random variable we have a mixed Poisson<br />process with ???? ? ? and ???? ? ???? ?, whilst for a homogeneous Poisson process<br />???? ? ? and ???? ? ?.<br />Similar results may be established for other intensity processes being a function of<br />a Gaussian process. Suppose e.g. for the moment that ? ? ? and ???? ? ? ????is<br />????-distributed with ? degrees of freedom. Then the intensity of the â??Cox processâ<br />is ??? ? ??and the pair correlation function becomes<br />?????? ? ? ? ???????<br />6</p>  <p>Page 9</p> <p>Hence there is not a one-to-one correspondence between ????????? and ????????????<br />unless the sign of the correlation function is known.<br />In the statistical analysis of point processes mostly first and second-order properties<br />are investigated (see Section 7), but we shall also explore the following correspondence<br />between the second and third-order properties: For any stationary simple point process<br />? with finite intensity ? ? ? and well-defined pair correlation function ???????? ?<br />????? ??? ? ? and third-order density ?????????????? ? ???????? ?????? ??? define<br />?<br />????<br />???????<br />This has an interpretation as a third-order summary statistic, since<br />???? ?<br />?<br />?<br />???????<br />?????????<br />????????????? ? ??????? ? ? ??<br />(5)<br />?????????? ? ??<br />?<br />??<br />?<br />?????????????????????<br />?????????????? ? ???<br />where ?? means that the summation is over pairwise distinct points, and where the<br />expectation is with respect to the reduced Palm distribution at the origin (heuristically<br />this means that we have conditioned on that there is a point at the origin and ? denotes<br />the collection of the remaining points, cf. e.g. Stoyan et al., 1995). By Theorem 1,<br />???? ? ? ? ? ? ?? for a log Gaussian Cox process. (6)<br />This can be used to check our model assumptions as demonstrated in Section 7.<br />In the case of rotation invariance we propose an unbiased estimator which uses all<br />triplets of observed points and which takes care of edge effects as follows. For a given<br />âwindowâ ? ?<br />?????????? ?? ? ?????????? ???????????? ? ??<br />??? ??????? ? ???????? ? ??? ? ??<br />and define the âedge correctionâ<br />?????????? ?????????? ?? ?????????<br />taking ???? ? ?. Then for given ??? ?? ? and ?, ???????????is the proportion of<br />triangles which can be observed within ? with vertices ???????? ? ? such that<br />????? ???? ? ?, ????? ???? ? ?, and ? is the angle (anticlockwise) between the vectors<br />??? ?? and ??? ??.<br />?and ??? ?, ? ? ?, ? ? ?, ? ? ? ? ??, let<br />?<br />Theorem 2. Let ??????????? denote the angle (anticlockwise) between ??? ??and<br />?????. For any stationary simple point process ? as considered above, assuming that<br />the distribution of ? is invariant under rotations about the origin,<br />?<br />?<br />??????<br />??<br />?<br />?????????????????<br />???????????? ???????????<br />???????????????????????????????????<br />??????? ???????????? ???????????? ?????<br />(7)<br />7</p>  <p>Page 10</p> <p>is an unbiased estimator of ?????????????? for all ? ? ??, where ???? is the area<br />of ? and<br />?<br />?<br />Proof. Note that factor ? in (7) appears because the second summation is over unordered<br />pairs of distinct points. Then ???????? ?????? ??? ? ????<br />because of the rotation invariance. Moreover, ????? ???? ? ???????? is a function of<br />??????? ? ????????????????????????????????? only. Hence, using that the correction<br />factor ? is the same for ?????????? as for ?????????? together with the fact that<br />??? ???<br />?<br />?<br />?<br />? ? ??<br />?<br />????<br />?<br />???????<br />?<br />???????<br />?<br />????????<br />???????????? ???????????? ?<br />?<br />?<br />?<br />?<br />?<br />?<br />???????? for a function ????<br />?<br />?<br />??<br />?<br />??????????<br />??????????? ?<br />? ? ?<br />??????????????????????????????????<br />for nonnegative measurable functions ?, we find that the mean of (7) equals<br />?<br />??<br />?<br />????????????????????????? ???????????<br />?<br />???<br />?<br />????<br />?<br />????<br />?<br />???????<br />where we have used that ? ? ??to obtain the third equality. This combined with (5)<br />gives the result.<br />???????????????????????????????????<br />??????? ???????????? ???????????? ?????<br />?<br />??<br />????<br />?????????????????<br />?????????????????????? ? ? ? ??? ? ? ? ???????????<br />?<br />?<br />?<br />???????<br />?<br />?<br />?<br />???????<br />?<br />?<br />????????<br />?<br />???????????<br />?<br />????????<br />?????????<br />??????????? ? ??????<br />????<br />?????????????????<br />????????????????????????????????<br />?<br />??????????????????????<br />????<br />????????<br />????????????????????????????????<br />? ????<br />???????<br />The estimator (7) is of the same spirit as Ripleyâs (1977) estimator for the second<br />order reduced moment measure. In fact ?????????agrees with Ripleyâs edge correction<br />factor when ? ? ? and ? ? ?. Our edge correction factor is of course also applicable<br />for other third order summary statistics than ?.<br />Applications of ? and its estimator are discussed at the end of Section 4 and in<br />Section 7, Example 1. In most applications ? will be convex in which case ??? ????,<br />the radius of the maximal inner ball contained in ?. We have also considered a naive<br />8</p>  <p>Page 11</p> <p>estimator based on âminus samplingâ and which do not presume rotation invariance,<br />viz. the unbiased estimator of ???????????????? given by<br />??<br />?<br />??????????? ??????? ???? ???<br />?????? ???????? ???????? ??????<br />with<br />?????? ? ? ? ?? ?<br />?? ????? ? ? ? ? ? ? ? ???<br />Compared to (7) the variation of this estimator can be very large since not all triplets<br />of points in ? ?? are used. Another problem may be caused by a clustering of points<br />so that no points are observed within ???for even moderate values of ?.<br />Finally, we establish some simple results about ergodicity. Ergodicity may for<br />instance become useful for establishing consistency of nonparametric estimators of ?<br />and ????. The log Gaussian Cox processes corresponding to the correlation models in<br />Table 1 are all ergodic as shown in part (b) of Theorem 3 below.<br />Theorem 3.<br />process, let ? ?<br />?<br />intensity function ???????? ? ? ?<br />that the realizations of ? are continuous with probability one and that ? is strictly<br />monotone, ergodicity of the Cox process implies that ? is ergodic.<br />(b) If ? is a stationary Gaussian process where the correlations decay to zero, i.e.<br />when<br />???? ? ? ?? ????? ? ?<br />then the corresponding log Gaussian Cox process is ergodic. Especially, a stationary<br />log Gaussian Cox process is ergodic if<br />(a) Let ? ? ????? ? ? ?<br />? ????? be measurable, and suppose that with probability one<br />????????? ? ? for bounded Borel sets ? ?<br />?? is ergodic if ? is ergodic. Conversely, assuming<br />?? be a stationary real-valued stochastic<br />?<br />?. Then a Cox process with random<br />(8)<br />???? ? ? ?? ????? ? ??<br />(9)<br />Proof. We first need some measure theoretical details. Let ? ?<br />of functions ? ?<br />equipped with the ?-field ?? generated by the projections<br />??? ? ?<br />of locally finite measures defined on the Borel ?-field ??in<br />is generated by the projections ? ?? ? ? ?<br />Furthermore, let ? ? ? ? ? be defined by<br />?<br />?<br />?denote the space<br />??<br />?? where ????? ? ????. Further, let ????? be the measure space<br />? ? ?<br />?where the ?-field ?<br />, ? ? ??, given by ? ????? ? ????.<br />??????? ?<br />?????????? ? ? ???<br />It is not difficult to show that for any fixed ? ? ??, the function ??? ? ?<br />by ????? ? ? ???????? is measurable. Hence ? is measurable and so ? ? ???? is<br />a random measure.<br />given<br />9</p>  <p>Page 12</p> <p>Now, consider a stationary Cox process as in (a). This is ergodic if and only if the<br />random measure ? is ergodic, cf. e.g. Proposition 10.3.VII in Daley and Vere-Jones<br />(1988). Ergodicity of ? means that ??? ? ?? ? ????? for all events ? ? ? which<br />are invariant under translations in the plane (? is invariant if ? ? ? ???? ? for all<br />? ?<br />??? ? ?? ? ????? for all events ? ? ?? which are invariant under translations in the<br />plane (i.e. ? is invariant if ? ? ? ???? ? for all ? ?<br />Using these definitions it is straightforward to show the first implication in (a).<br />Assuming that ? is strictly monotone, then ? restricted to ?? ? ?? ? ? ?<br />? continuous? becomes injective. Assume further that ? ? ?? is invariant and ?<br />is ergodic. Then it follows that ???? is invariant so that ??? ? ?????????? ? ?????.<br />Under the additional assumption that realizations of ? are continuous a.s., it is no<br />restriction to assume that ? ? ??. Then, since ? is injective on ??, ??????????? ?<br />? ? ??whereby ??? ? ?? ? ?????, and the second implication in (a) is proved.<br />According to (a) a stationary log Gaussian Cox process is ergodic if the underlying<br />Gaussian process is ergodic. But ergodicity of the Gaussian process is in fact implied<br />by (8), cf. Theorem 6.5.4 in Adler (1981). Using (4) we get the equivalence between<br />(8) and (9). This completes the proof.<br />?where ????? ? ???? ? ? ? ? ? ???). Similarly, ergodicity of ? means that<br />?where ????? ? ??? ? ??).<br />Conditions for continuity of random fields may be found in Adler (1981) or Ledoux<br />&amp; Talagrand (1991). Notice that (8) and (9) are equivalent and that (9) implies ergodicity<br />also for a ??Cox process.<br />4 Comparison with Neyman-Scott processes<br />We shall now compare our log Gaussian Cox processes with a popular and frequently<br />used class of models which are simultaneously Poisson cluster and Cox processes,<br />namely those Neyman-Scott processes where the number of points per cluster is Poisson<br />distributed (see e.g. Bartlett, 1964; Diggle, 1983; Stoyan and Stoyan, 1994; Stoyan et<br />al., 1995).<br />Imagine a point process ?????<br />neous Poisson point process of intensity ? ? ?, and which generate clusters of offspring<br />???<br />? ? ? and the relative positions ??? of offspring are iid with density ?. Further, the<br />????, ????, and ????? are mutually independent. The Poisson cluster process of offspring<br />?????<br />?<br />The product densities of such Neyman-Scott processes are known: We have that<br />? ? ??,<br />?<br />?of (unobserved) parents which form a homoge-<br />??????? ????. The counts ??are assumed to be iid Poisson distributed with mean<br />??????????? is then stochastic equivalent to a Cox process with intensity process<br />???? ? ?<br />?<br />??? ? ????<br />(10)<br />???? ? ? ??<br />?<br />??????? ? ????<br />10</p>  <p>Page 13</p> <p>?????????????? ? ????? ??? ? ????? ??? ? ????? ??? ? ?<br />?<br />and with similar but longer expressions for ????? ? ? ?. The higher-order product<br />densities of a log Gaussian Cox process as given by Theorem 1 are in general of a<br />different and much simpler form than for Neyman-Scott processes.<br />In the following we consider some particular but widely used models of Neyman-<br />Scott processes, viz. a MatÂ´ ern (1960) cluster process and a (modified) Thomas (1949)<br />process (Bartlett, 1964). For the Thomas process, ? is the density of a radially symmetric<br />Normal distribution with variance ? ? ?, and the pair correlation function becomes<br />?<br />?<br />??<br />??? ? ?????? ? ?????? ? ?????<br />????? ? ? ?<br />?<br />???????<br />?<br />???<br />??<br />?<br />? ? ? ??<br />For the MatÂ´ ern cluster process, ? is the density for a uniform distribution on a disc with<br />radius ? ? ? centered at ?, and the pair correlation function becomes<br />?<br />?<br />????? ?<br />? ?<br />?<br />?????<br />?<br />??????<br />?<br />???<br />?<br />??<br />?<br />? ?<br />??<br />???<br />?<br />? ? ? ? ? ??<br />? ? ? ???<br />In Fig. 1 we have included plots of the pair correlation functions for Thomas and<br />MatÂ´ ern cluster processes. For comparison we have taken ????? ? ????? ? ?. Then for<br />the Thomas process ? ? ???????????? is determined by the value of ?, whilst for the<br />MatÂ´ ern cluster process ? is determined by the value of ?. At least for certain values<br />of ? and ? the Gaussian pair correlation function and ????? appear to be very similar,<br />whereas ????? looks different from the other pair correlation functions in Fig. 1. For<br />instance, by taking ? ? ???? and minimizing????<br />the logarithm of these pair correlation functions for the Thomas and the log Gaussian<br />Cox process with Gaussian correlation function are nearly identical.<br />This may suggest that ????? ? ???????? could be considered as a covariance function.<br />One way to check this is through the Hankel transform of ????? given by<br />?<br />?<br />?<br />?<br />????? ? ????????? with respect to ?,<br />where ??????? ? ????????????, we get ? ? ???????. The left plot in Fig. 4 shows that<br />????? ?<br />?<br />??<br />??????????????<br />where<br />????? ?<br />?<br />?<br />???<br />?????<br />???<br />????????<br />is the Bessel function of first kind and order zero. Then ????? is positive semi-definite if<br />and only if ????? ? ? for all ? ? ?, cf. e.g. Christakos (1984). The Hankel transforms<br />??and ??for the Thomas and MatÂ´ ern cluster processes given in Fig. 4 show that<br />11</p>  <p>Page 14</p> <p>neither of the two Neyman-Scott processes can be considered as log Gaussian Cox<br />processes. But the close agreement with respect to the pair correlation functions and<br />the remarks below and at the end of this section suggest that certain Thomas processes<br />may in practice be difficult to distinguish from log Gaussian Cox processes with a<br />Gaussian correlation function.<br />Fig. 5 shows simulated distribution functions ? and ? for the distance to the nearest<br />point of a point process ? with respect to ? and a typical point of ?, respectively<br />(see e.g.Diggle, 1983).Here we consider two kinds of point processes: a log<br />Gaussian Cox process (the solid lines in Fig. 5) with a Gaussian correlation function<br />and ? ? ?????? ? ? ?, i.e. ? ? ??, and correspondingly a Thomas process with<br />? ? ??????? ? ???? and ? ? ??? (dotted lines); as before ? ? ???? and ? ? ???????.<br />For each model we simulated 100 realizations and calculated the average and the<br />upper and lower envelopes for nonparametric estimates of ? and ?. (The upper and<br />lower envelopes for ?, ? or any another summary statistic depending only on the<br />distance are here and elsewhere in the following given by the maximum and minimum<br />values obtained from the simulations at each distance; see e.g. Diggle, 1983.) The<br />averages are then estimates of the theoretical ? and ? functions. Further simulations<br />confirmed that the envelopes of ? for the Thomas process lie beneath those for the log<br />Gaussian Cox process, while the opposite statement holds for the envelopes of ?. We<br />recognized further that the ? function distinguishes better between the two processes<br />than the ? function, but also that none of these summary statistics are really useful<br />for discriminating between the two models. Another experiment confirmed that it may<br />also be difficult to distinguish between the two models by means of the third-order<br />characteristic ? in (5).<br />In Section 7 plots of ?, ?, and ? raise doubt of the appropiateness of the MatÂ´ ern<br />cluster process as a model for the data in Example 1, but give no reason to question<br />the use of a log Gaussian Cox process with an exponential correlation function.<br />5 Multivariate log Gaussian Cox processes<br />Our model can immediately be extended to the case of multivariate Cox processes<br />as follows.<br />Let us for simplicity just consider the bivariate case of a Cox process ? ?<br />??????? directed by random intensity processes ?? ? ?????? ? ?????????? ? ? ?<br />??? ? ? ???, where ? ? ?????????????? ? ? ?<br />and possibly isotropic Gaussian process with mean ??????? and covariance functions<br />?????? ? ?????????????????? for ? ? ????? ????? ??? ? ??? (in the isotropic case we<br />have that ?????? ? ??????). Then conditional on ? , ??and ??are independent Poisson<br />processes with intensity functions ?? and ??, respectively. The covariance function<br />matrix of the multivariate Gaussian process must be positive semi-definite. Restricting<br />attention to absolutely integrable and isotropic covariance functions, this is equivalent<br />to that<br />?? is a bivariate stationary<br />?????? ? ?? ?????? ? ?? and ?????????? ???????????? ? ? ? ?<br />(11)<br />12</p>  <p>Page 15</p> <p>where<br />?????? ?<br />?<br />??<br />?<br />?<br />?<br />???????????????<br />is the spectral density or Hankel transform of ??? (Yaglom, 1986; Christakos, 1992;<br />Wackernagel, 1995). Moreover, many of the results presented in Section 3 may easily<br />be extended to the multivariate case. For example, by Theorem 1 the intensity and pair<br />correlation function of ?? become<br />??? ??????? ????????? ? ?????? ? ???????????<br />and the mixed pair correlation function is given by<br />(12)<br />?????? ? ?????????????????????? ? ??????????? ? ? ? ????? ?????<br />Especially, if we consider affine transformations ????? ? ??<br />independent one-dimensional Gaussian processes ??? ?????? ? ? ?<br />each with mean 0, variance 1, and a positive semi-definite correlation function ??, then<br />of course ? is well-defined and<br />(13)<br />????????? ? ?? of ?<br />??? ? ? ???????,<br />?????? ?<br />?<br />?<br />???<br />??<br />??????? ? ? ? ??? ? ?????? ?<br />?<br />?<br />???<br />??????????? ? ? ?<br />?<br />(14)<br />(in this case ?????? ? ?????? no matter if isotropy is required or not). For example,<br />if ?? ? ??? ? ??? ? ? ???, where ? is a stationary Gaussian process with mean 0,<br />variance 1, and correlation function ????, then the sign of ???????? determines whether<br />there is a positive or negative dependence structure between the two types of patterns<br />??and ??. In the special case ??? ??we have a linked Cox process (Diggle and<br />Milne, 1983) as ??????? ? ???????. Fig. 6 shows realizations on the square under the<br />exponential model ???? ? ????????? with ??? ??? ??? and for each of ??? ??? ?<br />and ??? ??? ? ?. The different dependence structures are clearly expressed in the<br />simulations.<br />6 Simulation algorithms<br />Some properties of Cox processes are hard to evaluate analytically. Fortunately,<br />log Gaussian Cox processes are easy to simulate so that Monte Carlo methods can be<br />applied. An advantage of log Gaussian Cox processes is that there are no boundary<br />effects since all marginal distributions of a Gaussian field are known.<br />In practice we represent the finite domain of simulation by a grid and approximate<br />the Gaussian process by the values of the corresponding finite dimensional Gaussian<br />distribution on the grid. If we for example wish to simulate a log Gaussian Cox process<br />on the unit square, we approximate the Gaussian process<br />???? ??????????????????????????????????????? by its value????? ? ??????? at<br />the center ????? of ???where ????? ? ? ? ??????????? ?????????????? ????? ?<br />?? ????<br />????????on each cell<br />13</p>  <p>Page 16</p> <p>????????? and ? is a suitable value for the discretization. Thus, simulations of the<br />field?? ? ?????????????are required. For ease of presentation we shall here mainly focus<br />on univariate log Gaussian Cox processes where the discretization is given by a square<br />lattice ?; at the end of Subsection 6.1 we consider briefly the case of a multivariate log<br />Gaussian Cox process and a rectangular lattice.<br />If the Cox process is moderately clustered and the intensity moderate, the very fine<br />scale properties of the Gaussian field are probably not so important and a rather coarse<br />discretization can be used. The choice of discretization also depends on the smoothness<br />of the realizations of the Gaussian field, see Fig. 2. The error due to discretization is e.g.<br />likely to be small when the Gaussian correlation function is used. For the simulations<br />presented in this paper we found it sufficient to use either ?? ? ?? or ??? ? ??? grids.<br />Simulation of a log Gaussian Cox process involves two steps. First the Gaussian<br />field is simulated and secondly, given the Gaussian field?? ? ?? ???????????, the inhomoge-<br />neous Poisson process can be simulated: either within each cell ???where the Poisson<br />process is homogeneous with intensity????? ????? ????, or by thinning a homogeneous<br />Poisson process with intensity?????? ?????????so that a Poisson point situated in the<br />??th cell is retained with probability??????????.<br />There are several methods available for simulation of a Gaussian random field, see<br />e.g. LantuÂ´ ejoul (1994). The simulation method based on Cholesky decomposition of<br />the covariance matrix is too slow even for moderate grid sizes. We used another method<br />based on decomposition of the covariance matrix (see Subsection 6.1) or alternatively the<br />turning bands method (Matheron, 1973). In Subsection 6.2 we describe how simulations<br />conditional on the number of points can be obtained. Finally, in Subsection 6.3 we<br />briefly discuss how the Thomas and MatÂ´ ern cluster processes studied in Section 4 are<br />simulated.<br />6.1 Simulation using diagonalization by the two-dimensional discrete Fourier<br />transform:<br />A detailed description of this method in the univariate case and any lattice<br />dimension ? ? ??????? assuming only stationarity can be found in Wood and Chan<br />(1994). Below we summarize this for the two-dimensional case (the notation and the<br />results are also used in Sections 7 and 8). For simplicity we assume isotropy.<br />Suppose that an isotropic covariance function ? ?<br />wish to simulate a Gaussian field?? ? ?????????????with covariance matrix ? ?<br />?????????????????????? ?????????????????????????????????(here we use a lexicographic ordering<br />of the indices ??). Note that ? is block Toeplitz and block symmetric. Extend the lattice<br />? to ????? ????????????????????????????????????????????wrapped on a<br />torus. Let ???? ?????????????????????????, ????? ? ????? and let ?????????????? ?<br />?<br />symmetric matrix ? ? ????????????????????????defined by ?????? ? ????????????????? is<br />block circulant with ??? ? ?? circulant blocks of dimension ??? ? ?? ? ??? ? ??.<br />Hence, by Theorem 5.8.1 in Davis (1979),<br />? ???????????????????<br />14<br />??<br />is given and we<br />??<br />??? ??<br />??denote the shortest distance on the torus between ????? and ?????. The<br />??????????? ???????<br />?<br />(15)</p>  <p>Page 17</p> <p>where ???????? ???????is unitary and ? ? ????????? ????? ? ????? is a diagonal<br />matrix of the eigenvalues for ?. Here ???????? ????? ? ????????????????? ?<br />â?â denotes complex conjugate, and ? is the Kronecker product.<br />Now, suppose that ? is positive semi-definite (i.e. ? has nonnegative eigenvalues).<br />Then we can extend?? to a Gaussian field?????? ????????????????with covariance matrix<br />?. Using the above decomposition of ? we find that<br />???????????????is the (normalized) ????????????? discrete Fourier transform matrix,<br />?????<br />?? ????????????????????????<br />?<br />where ? ? ??????? follows a ?-dimensional standard normal distribution with ? equal<br />to the rank of ?, ? is a diagonal matrix given by the non-zero eigenvalues of ?, and<br />? is a certain ? ? ???? ? ????complex matrix of rank ?. If ? ? ? is a power of two<br />(or three or five), the calculation of?????is only a ?????? ? ????????????? ? ??????<br />operation as the two-dimensional fast Fourier transform (see e.g. Press et al., 1988) can<br />be applied. Thereby a fast simulation algorithm is obtained.<br />Notice that the extension of the lattice ????????????????????????? ????? ?<br />????????to ??????????? ? ??????????????? ? ?? ? ???? ? ????????is the<br />minimal extension which gives a block circulant matrix ?. If ? turns out not to be<br />positive semi-definite, it may help to use a larger extension (see Wood and Chan, 1994).<br />Also, if ? ?? is not a power of two (or three or five), a larger extension can be applied<br />in order to use the two-dimensional fast Fourier transform.<br />The algorithm can straightforwardly be generalized to the case of a multivariate<br />Gaussian field?? ? ????????????????????????, where ? is a ? ? ? rectangular lattice<br />and ? ? ?. In this case ? becomes a ??? ? ???? ? ??? ? ??? ? ???? ? ??? block<br />circulant matrix given by ??? ? ?? blocks, which in turn are block circulants and of<br />dimension ??? ? ??? ? ??? ? ???. By combining (5.6.3), Theorem 5.6.4, and (3.2.2)<br />in Davis (1979) one obtains that<br />? ???????????????????????<br />where ? is a block diagonal matrix with ??? ? ???? ? ?? blocks of dimension<br />? ? ?. In the bivariate case, simulation of?? thus amounts to a linear transformation<br />of ??? ? ???? ? ?? independent two dimensional Gaussian vectors.<br />The method is fast and practically applicable. Problems with nonpositive semi-<br />definiteness of ? occurred very seldom, and were then due to slowly decaying corre-<br />lation functions like the stable correlation function (see Figure 1).<br />??????????? ???????? ??<br />?<br />6.2 Conditional simulation:<br />distribution of ? ? ??????given that ???? ? ?????? ? ??????? ? ? for ? ?<br />we need first to simulate a realization ? ? from?? ????? ? ? and secondly simulate<br />from ?????? ? ???? ? ? ?. The last step is performed by distributing ? independent<br />points in the ??grid cells, where a cell ???is chosen with a probability proportional<br />to????? ????? ????? ????? ? ?, and the point subsequently placed at a uniformly sampled<br />It may sometimes be desired to simulate the conditional<br />. Then<br />15</p>  <p>Page 18</p> <p>location in the chosen cell. Rejection sampling (see e.g. Ripley, 1987) is used for<br />the simulation of?? ????? ? ? as follows. For the conditional density of?? given<br />???? ? ? we have that<br />??? ? ? ?? ? ??? ? ? ????? ?? ???<br />???????? ???<br />The rejection sampling can thus be performed by generating realizations of?? until a<br />realization ? ? is accepted with probability????????????, where?? ?<br />Considered?? as a random variable, the mean of?? approximates the intensity ? of<br />?. Thus the acceptance rates are reasonably high if ? is close to ? and the variance<br />of?? moderate.<br />????<br />???<br />????<br />???<br />???????.<br />6.3 Simulation of the Thomas and MatÂ´ ern cluster processes:<br />ulation of the Thomas and MatÂ´ ern cluster processes on a bounded region ? follow<br />straightforwardly from the definitions of these processes as Poisson cluster processes,<br />see Section 4. In order to avoid boundary effects the parent process is simulated on an<br />extended area ? containing ?. The area ? is chosen so that offspring from a parent<br />outside ? falls into ? with a negligible probability. An approximate procedure for sim-<br />ulation conditional on the number of points can be obtained by using that the Thomas<br />and MatÂ´ ern processes are Cox processes with intensity surface given by (10) and then<br />proceed as described in Subsection 6.2 above.<br />Procedures for sim-<br />7 Parameter estimation and model checking<br />For simplicity we first restrict attention to the univariate case, but our methods for<br />estimation and model checking can also be used in the multivariate case, see Example<br />2 at the end of this section.<br />Suppose we have observed a point pattern ? ? ??????????? within a bounded<br />planar window ? of area ????. Under a homogeneous log Gaussian Cox model with<br />a correlation function ????? the density of ??? ? ? ? with respect to a planar unit<br />Poisson process is<br />?<br />?<br />Except for very special models this likelihood is analytically intractable.<br />Considering this as a âmissing data problemâ the likelihood can be approximated by<br />discretizing ? as described in Section 6 and making importance sampling as follows:<br />The density of the Gaussian field?? is proportional to<br />?<br />???????? ? ??????<br />????<br />?<br />?<br />?<br />?<br />?? ? ????? ???????<br />?<br />?<br />?<br />?<br />?<br />?<br />????? ?????<br />?<br />??<br />???? ?? ? ???<br />?<br />?<br />????? ? ? ? ?????????? ? ? ? ???<br />?<br />16</p>  <p>Page 19</p> <p>where ? ? ???????, ???? is the correlation matrix (here assumed to be positive definite),<br />and ? denotes transposition. For a given fixed parameter ??? ?????????? suppose that<br />? ????????? ? ????is a sample from the distribution of?? and ? ???????????? ? ??????? is a<br />sample from the conditional distribution of?? given ??? ? (Section 8 describes how<br />the latter sample can be generated). Since the conditional distribution of ??given??<br />does not depend on ?, it is easily seen from the results in Gelfand and Carlin (1991)<br />and Geyer (1994) that the Monte Carlo approximation of the log likelihood is<br />?<br />???<br />???? ? ????? ? ????<br />?<br />?<br />?<br />???<br />??<br />? ???????<br />?? ???????? ? ????<br />?<br />?<br />?<br />?<br />???<br />??<br />?<br />? ?????<br />???<br />?? ????? ?<br />Actually we may replace?? with the extended Gaussian field?????(see Section 6.1) for<br />which it is easier to invert the correlation matrix. We have no experience about how this<br />would work in practice, but we expect that multimodality of the likelihood may cause<br />problems for finding the (approximate) maximum likelihood estimate. Since only the<br />Gaussian density (up to scale) appears in the approximation of the log likelihood, there<br />may be some analog here to Ripleyâs (1988) discussion on the difficulties associated<br />with likelihood analysis for spatial Gaussian processes.<br />Pseudo-likelihood (Besag 1977; Jensen and MÃ¸ller, 1991) is not useful since a<br />closed expression of the density is not known even not up to multiplication with a<br />positive constant (so a closed expression of the socalled Papangelou conditional intensity<br />is not known). For the same reason we also doubt the usefulness of the more general<br />method of Takacs-Fiksel estimation (see e.g. Ripley, 1988, and the references therein).<br />Since the distribution of a log Gaussian Cox process is completely determined<br />by its first and second order properties we suggest instead to base the inference on<br />corresponding summary statistics as described in the following.<br />As a natural estimate of the intensity we shall use<br />? ? ? ???????<br />(16)<br />This estimator is unbiased. If ????? ? ? as ? ? ?, then the ergodicity implies that<br />? ? ? ? almost surely as ? extends to<br />The parameters ??? ? and ? ? ? are estimated by a minimum contrast method:<br />Assume henceforth that the correlation function is isotropic. Let ? ???? denote a nonpara-<br />metric estimate of the covariance function. Then ? ??and?? are chosen to minimize<br />?, cf. Theorem 3.<br />??<br />?<br />?<br />?<br />? ????????????????????<br />(17)<br />where ? ? ? ? ??and ? ? ? are user specified parameters; in Examples 1 and 2 we<br />take ? ? ???<br />These parameters must of course be chosen so that the terms in (17) are well-defined.<br />????????? ????, while ??and ? are determined by the form of ? ???? and ?????.<br />17</p>  <p>Page 20</p> <p>For fixed ? the minimum of (17) is obtained at<br />? ??<br />?? ??????????????with ???? ?<br />??<br />?<br />?<br />?? ????????????? ? ???? ?<br />??<br />?<br />?<br />?????????<br />provided ???? ? ?; otherwise there exists no minimum. Inserting this into (17) and<br />using that ? ? ????? ? ????? give the estimates<br />?? ? ???????????????? ? ? ??? ? ??<br />??? ? ? ? ????? ?? ? ? ?????<br />(18)<br />Diggle (1983) describes a similar estimation procedure using the ?-function<br />???? ? ??<br />? ?<br />?<br />??????? ? ? ? ?<br />instead of the covariance function, but for the data considered later on we found that<br />there may be many local minima, and it may be difficult to find a global minimum.<br />The procedure in (18) is computationally much simpler; we need only to maximize<br />with respect to ?, whereas Diggleâs procedure involves ??as well. In our examples<br />the function ?????????? turned out to be unimodal.<br />As the nonparametric estimate of the covariance function we have used ? ???? ?<br />???? ???? with<br />?<br />???? ??????<br />?<br />????<br />? ???? ?<br />?<br />?<br />???? ? ????? ????????? ? ? ??<br />(19)<br />where ????? is the Epanecnikov kernel<br />????? ?<br />?<br />??<br />?? ? ?????????? ? ? ? ??<br />with bandwidth ? ? ?, ???is the proportion of the circumference of the circle with center<br />??and radius ????????? lying within ?, and ??is the circumradius of ?. The estimator<br />(19) and other estimators of the pair correlation function are discussed in Stoyan and<br />Stoyan (1994); in particular they discuss how to choose the bandwidth of the kernel.<br />To study how well our estimation procedure works we performed 20 simulations<br />from the model with an exponential covariance function where ??? ??? and ? ? ???.<br />A scatter plot of the estimated values of ? and ??together with the true values is<br />shown in Fig. 7. There is a large variation in the estimate of ?, but the mean values<br />of the 20 estimates are?? ? ????? and ? ??? ????, not far from the true values. The<br />other plot in Fig. 7 shows the mean covariance function ? ? (solid line) and upper and<br />lower envelopes for the empirically estimated covariance functions obtained from the 20<br />simulations. The values of ? ? are close to the exponential covariance function, especially<br />at small distances. Estimating the parameters from ? ? gives???? ????? and?? ? ?????,<br />which indicates that a good estimate of the covariance function gives good parameter<br />estimates.<br />18</p>  <p>Page 21</p> <p>Having estimated the parameters we may check our model assumptions by compar-<br />ing nonparametric estimators of various summary statistics with those obtained under<br />the estimated log Gaussian Cox model. We have considered the distribution functions<br />? and ? of the distance to the nearest point in ? from a fixed point in the plane and<br />a âtypical pointâ in ?, respectively. Under the log Gaussian Cox model ? ? ???????<br />and ? ? ???????are given by<br />?????????? ? ? ? ??????????<br />?<br />?<br />?<br />?<br />?<br />?<br />?<br />???????<br />?? ?????<br />?<br />?<br />?<br />?<br />?<br />and<br />?????????? ? ? ? ???????????????<br />?<br />?<br />??? ??????<br />?<br />?<br />?<br />?<br />?<br />?<br />?<br />???????<br />?? ?????<br />?<br />?<br />?<br />?<br />???? based<br />?<br />?<br />?<br />?<br />where the mean values may be approximated by Monte Carlo.<br />As in Diggle (1983), Stoyan and Stoyan (1994), and Stoyan et al. (1995) we have<br />in Examples 1 and 2 compared nonparametric estimates of ?? ?? ? ?<br />on the data with those obtained by simulations under the estimated log Gaussian Cox<br />model. For short we call such nonparametric estimates for empirical ?, ?, and ?-<br />functions. Moreover, we have obtained a nonparametric estimate of the third-order<br />characteristic ? in (5) by combining (7) with (16) and (19), and considered whether this<br />summary statistic varies around 1 in accordance with the result (6) for log Gaussian<br />Cox processes.<br />Example 1:<br />square plot of 10 ?10 ??. The pine forest has grown naturally in the Eastern Finland<br />and the data have previously been analyzed by Penttinen et al. (1992) and Stoyan and<br />Stoyan (1994), who both fitted a MatÂ´ ern cluster process using the ?-function both for<br />parameter estimation and model checking. The estimation in Penttinen et al. (1992)<br />was carried out by trial-and-error, while Stoyan and Stoyan (1994) used a minimum<br />contrast method. The fit in both cases seems quite good, see Fig. 11 in Penttinen et al.<br />(1992) and Fig. 131 in Stoyan and Stoyan (1994), but one may object to that the same<br />summary statistics have been used for both estimation and model checking.<br />Fig. 8 shows several characteristics for the pine data: The data normalized to a<br />unit square are shown in a). The logarithm of the estimated pair correlation function<br />is plotted in b) (solid line), and the shape of the curve suggests to use the exponential<br />covariance function. We estimated the parameters by minimizing (17) with ??? ???<br />and ? ? ???, which are chosen to give more weight to values of ? close to zero. The<br />estimates are?? ? ???? and ? ??? ????. The dotted line in b) shows the covariance<br />function for the estimated model. The plot in c) shows the empirical ?-function for<br />the data (solid line) and upper and lower envelopes of the ?-function for the fitted<br />model based on 19 simulations. This is the same as Stoyan and Stoyan (1994), Fig.<br />The first data set consists of the locations of 126 Scots pine saplings in a<br />19</p>  <p>Page 22</p> <p>131, and our model shows a better fit with respect to the ?-function than the MatÂ´ ern<br />cluster model. The empirical ?-function falls within the envelopes from the simulations<br />except for very small values of ?. The plots in d) and e) show the nonparametric<br />estimates?? and?? based on the data against the mean of these estimates obtained from<br />99 simulations under the estimated model. The plots show a reasonable good fit to the<br />chosen model and?? and?? fall within the upper and lower envelopes based on the 99<br />simulations. For the MatÂ´ ern cluster model fitted by Stoyan and Stoyan (1994) we have<br />also created plots similar to d) and e) which indicate that our model fits the data better.<br />Finally, f) shows a realization under the estimated log Gaussian Cox process.<br />We also used the third-order characteristic ? to check our model assumptions. The<br />left plot in Fig. 9 shows the estimated ? for the data and two sets of envelopes based<br />on 20 unconditional simulations of the estimated log Gaussian Cox process and 20<br />simulations where we condition on the observed number of points. The plot gives<br />no reason to doubt the model no matter whether the âunconditionalâ or âconditionalâ<br />envelopes are considered. The two sets of envelopes are not very different in this<br />situation where ? is rather small and the correlation therefore not very strong. To check<br />the discriminatory power of ? we similarly calculated envelopes for the MatÂ´ ern cluster<br />process estimated by Stoyan and Stoyan (1994), see the right plot in Fig. 9. The<br />estimated ?-function based on the data crosses the envelopes in an interval of ?-values<br />and even though the large variability of the estimator for small ? makes it difficult to<br />make definitive conclusions, the plot raises serious doubt concerning the appropiateness<br />of the MatÂ´ ern cluster process as a model for the data.<br />Example 2:<br />trees, 219 spruces and 114 birches in a square plot of 50 ?50 ??. The data has been<br />collected by Kari Leinonen and Markku Nygren as a part of a larger data set where<br />also a very few pines were present and marks consisting of tree length and diameter<br />were included. These data has earlier been studied by Kuuluvainen et al. (1996). They<br />found that small trees are clustered, while larger trees are regularly distributed.<br />Fig. 10 a) shows the data normalized to unit area. The plot indicates clustering<br />and a positive dependence between the two types of trees. In Fig. 10 b) the empirical<br />covariance functions ? ???, ? ???and ? ???are plotted (solid line, from top to bottom) using<br />the equations (12) and (13) to obtain ? ???? ??? ???. Here ? ?????? is the estimate (19) based<br />on the point pattern ??? ?????????????? of type ? trees. Further,<br />????<br />????????<br />??? ??<br />???<br />??<br />?<br />with the correction factor ???similarly defined as in (19), and where we have combined<br />kernel estimation with the way Lotwick and Silverman (1982) and Diggle (1983)<br />recommend to estimate ?????? ? ????<br />20<br />In this example we study a bivariate data set consisting of two types of<br />? ?????? ?<br />??<br />??<br />?<br />??<br />?<br />??<br />?<br />???<br />???? ? ?????? ??????????<br />??<br />??? ??<br />??????<br />???? ? ?????? ??????????<br />??????????? ? ? ?.</p>  <p>Page 23</p> <p>Based on the plot of the empirical covariance functions we specify a model for<br />a bivariate log Gaussian Cox process with exponential covariance functions ?????? ?<br />??<br />Estimating the parameters from the empirical covariance functions by minimizing (17)<br />gives ? ??<br />The estimated covariance functions are shown as dotted lines in Fig. 10 b). This<br />indicates a good fit to the empirical covariance functions. We have moreover checked<br />that the condition (11) is fulfilled under the estimated model so that we have a valid<br />covariance matrix function.<br />However, plots of the function ? for each of the two types of trees show a poor<br />fit of the estimated model to the data as there seems to be more âempty spaceâ in<br />realizations of the estimated model than in the pattern a). As an example Fig. 10<br />c) shows the nonparametric estimate of ??? based on birch data plotted against the<br />mean of the estimate obtained from 99 simulations under the estimated model. We<br />have also tried to fit models with covariance functions as in (14) with ? ? ? terms<br />and various combinations of Gaussian, exponential and stable correlation functions, but<br />again there was too much empty space under the fitted models. This may be caused<br />by the regularity in the pattern of the larger trees, so one suggestion may be to include<br />ârepulsiveâ pairwise interaction terms into the model as discussed at the end of Section<br />2. Another possibility is to include a thinning operation, cf. Diggle and Milne (1983)<br />and Diggle (1983).<br />????????????? and corresponding spectral density ?????? ? ??<br />????????????? ???<br />???????.<br />??? ????? ??????? ????? ? ??<br />??? ????? ??????? ????? ? ??<br />??? ????? ??????? ???.<br />8 Prediction and Bayesian inference<br />We conclude this paper by considering prediction of the unobserved Gaussian<br />process and intensity process under a given model for a univariate log Gaussian Cox<br />process when this is observed within a bounded window. We use an empirical Bayesian<br />approach, where the a posteriori distribution of the intensity process is obtained by<br />considering the Gaussian distribution as a prior which smoothes the intensity surface,<br />and where the prior may be estimated as described in Section 7. The posterior is not<br />analytically tractable so we use a Markov chain Monte Carlo algorithm to simulate the<br />posterior distribution whereby various posterior characteristics can be estimated. The<br />results are applied on the data set in Example 1 and we compare various Bayesian<br />estimators of the intensity process with a parametric kernel estimator studied in Diggle<br />(1985), Berman and Diggle (1989), and Cressie (1993). Ogata and Katsura (1988)<br />developed another objective Bayesian method for estimating the intensity function of<br />a marked inhomogeneous Poisson point process using spline functions. Other related<br />research but for Poisson (and more general) cluster processes include Lawson (1993),<br />Baddeley and Van Lieshout (1993), and Granville and Smith (1995), who consider<br />Bayesian estimation of cluster centres and cluster membership. Simultaneously with<br />the development of the material of this section, Heikkinen and Arjas (1996) have<br />been working with nonparametric Bayesian estimation of the intensity function of<br />inhomogeneous planar Poisson processes generalizing the method of Arjas and Gasbarra<br />(1994).<br />21</p>  <p>Page 24</p> <p>Suppose that a realization ? of a log Gaussian Cox process is observed within a<br />bounded window ????and we wish to predict the Gaussian process and the intensity<br />surface on the bounded set ? ? ????.<br />of generality assume that ? is the unit square and consider a finite subdivision of<br />????and ????? ? ? ????into cells ??? of area ??? ? ?? ????? ? ?, where<br />? ? ??????????? ? ????????????? ? ???? ? ????????. Define the sublattices,<br />????? ??????? ? ? ???. Further, we approximate the Gaussian field ? restricted to ?<br />by a Gaussian field?? ? ?????????????with mean vector ? ? ? ??????????and a covariance<br />matrix ? given by the covariance function of ? . As noticed in Subsection 6.1 we<br />can extend?? to??????<br />??????????<br />??????????????????????? ?????????, ? given by (15) is assumed to be positive<br />semi-definite and of rank ?, ? ? ???????, ? is a certain ? ? ???? ? ????real matrix<br />of rank ?, and ? ????? ?????????????. We shall later on explain why it (apart from ease<br />of exposition) may be preferred to use ? instead of?????.<br />Now, if ?????? denotes the density of the conditional distribution of ? given that<br />? ? ????? ?,<br />????????? ? ???????? ??<br />As in Section 6 we shall without loss<br />?????<br />?<br />?? ?? ? ? ????, where ????? ??????????? ?<br />????????<br />?<br />??????????<br />?? ??????? ?? ??????<br />?<br />(20)<br />where ??? ? ?????? ? ???? is the number of points of ? contained in the ??th cell<br />if ????? ? ????, and we set ??? ? ??? ? ? if ????? ? ? ????. Though this conditional<br />distribution is not defined in accordance to the covariance structure of the Gaussian<br />process outside ?, we shall refer to this as the a posteriori distribution of ? given ?;<br />the important point is that the marginal distribution of?? under this posterior agrees with<br />the conditional distribution of?? given ? ? ????? ?. In the following the gradient<br />of the posterior<br />???? ?? ? ???????????? ? ?? ?????? ?? ??????<br />plays a keyrole. It is easily seen that ?????????is strictly negative definite. Thus the<br />posterior is strictly log-concave.<br />For simulation of the posterior we use a Metropolis-adjusted Langevin algorithm<br />(MALA) as suggested by Besag (1994) in the discussion of Grenander and Miller (1994)<br />and further studied in Roberts and Tweedie (1997). This is a Metropolis-Hastings type<br />Markov chain Monte Carlo (MCMC) method inspired by the definition of a Langevin<br />diffusion through a stochastic differential equation which in the present context is<br />?<br />????????????<br />????? ? ?????????????? ?<br />?<br />??????<br />where ???? is standard Brownian motion and ? ? ? is a user specified parameter (see<br />Example 1 below); the posterior ??? is a stationary distribution of this Markov process<br />????.<br />The MALA is given by two steps: First, if ????is the current state of the chain,<br />a âproposalâ ??????is generated from a multivariate normal distribution with mean<br />22</p>  <p>Page 25</p> <p>??????? ? ????? ???????????? and independent coordinates with common variance<br />?. In general, the use of gradient information in the proposal kernel may lead to<br />much faster convergence than for e.g. a random walk Metropolis chain (Roberts and<br />Rosenthal, 1995). Secondly, with probability<br />?<br />????????????<br />the next state becomes ??????? ??????; otherwise ??????? ????. This gives an<br />irreducible and aperiodic Markov chain with the posterior as the stationary distribution,<br />but it is not geometrically ergodic as the posterior has lighter tails than the Gaussian<br />distribution (this can formally be verified using Theorem 4.2 in Roberts and Tweedie,<br />1996b).<br />Briefly, the problem with the light tails is that the Markov chain may leave the<br />center of the posterior for a very long time, since ???????? may become extremely large<br />if ? is far away from the mode of the posterior. As suggested in Roberts and Tweedie<br />(1996b) more robust geometric ergodicity properties may be obtained by truncating the<br />gradient in the mean of the proposal kernel: In the Appendix we show that if ????<br />is replaced by<br />?????????? ?? ???????? ? ?? ???????<br />for some constant ? ? ?, then the âtruncated MALAâ becomes geometrically ergodic<br />when ? ? ? ? ?. However, if a sensible value of ? is chosen, the undesirable properties<br />of the (untruncated) MALA may not be a problem. In our examples the chain behaved<br />very nicely and a truncation of the gradient (for a suitably large ?) would not have<br />made a difference.<br />Note that ? and ? do not need to be strictly positive definite. This is one reason for<br />using ? instead of?? when the posterior is considered. In the case where ? is strictly<br />positive definite we have compared MALAâs for simulating the conditional distribution<br />of ? respective?? given ?, where the gradient in the latter case is given by<br />??? ????? ? ??? ????? ? ?????????????? ?? ??????<br />For the data in Example 1 considered below we found that in the former case the algo-<br />rithm mixes much faster (Fig. 11), so this is another reason to prefer the âparametriza-<br />tionâ given by ?.<br />By simulating the posterior we can obtain MCMC estimates of the posterior mean,<br />credibility intervals, etc. for the Gaussian process and intensity surface. Conditional<br />simulations of the unobserved part ? ?????of the point process given ? ? ????? ?<br />can also be obtained. To do this one generates first a realization from the posterior<br />distribution of the intensity surface and given this realization, ? ? ????is simulated<br />along the same lines as described in the beginning of Section 6.<br />? ?<br />?<br />?<br />????????<br />?<br />???<br />?<br />???<br />???????? ?<br />?<br />??????????<br />???<br />??????<br />?<br />?<br />???????????? ?????????????????<br />?<br />?<br />????????????<br />(21)<br />?<br />???????????<br />23</p>  <p>Page 26</p> <p>Maximum a posteriori (MAP) estimation is also possible. Since ?????? is strictly<br />log-concave and its tails tend to zero at infinity, the MAP-estimate ????is the unique<br />solution to ???? ? ?. Because of the linear relationship between????? and ?, the<br />MAP-estimate of?????is simply given by ????<br />???<br />estimate ????of?? agrees with ????<br />???<br />restricted to ?. It can be shown that ????<br />restricted to ????is the same as the predictor of??????<br />?<br />The conditional density of the intensity surface????? ? ?????????????????????(with<br />respect to ?-dimensional Hausdorff measure with carrier space of dimension ???? ?<br />????) is not log-concave and ?????????<br />??<br />?????????is clearly not the MAP-estimate of<br />the intensity surface. If ? is strictly positive definite, then using an obvious notation,<br />???????? ??????? is strictly log-concave, and so<br />? ??????? ????. Note that the MAP-<br />??????<br />???<br />??<br />?<br />??????????obtained from<br />âdataâ??????<br />? ????<br />??<br />?<br />??????????using kriging (see e.g. Cressie, 1993).<br />??? ????? ? ????????????? ?????????????????? ? ???????? ????????<br />?<br />??????????<br />? ???<br />is strictly log-concave. Consequently, in this case the MAP-estimate ????of the<br />intensity surface on ? is the same as ????<br />???<br />where ? ? is the unique solution to ??? ????? ? ?????????. Note here that since the log<br />Gaussian distribution is heavy tailed and skewed, ????is not necessarily a sensible<br />estimator of the intensity surface (see also the discussion in Example 1 below).<br />We have used a discrete gradient ascent algorithm for finding ????, since this<br />algorithm involves only the calculation of the gradient: Given an initial value ????the<br />iteration is given by ??????? ???????<br />specified parameter. The algorithm for finding ? ? is similar, except that in each iteration<br />we replace ? by ? ? ?????????. A too high value of ? may cause the algorithm to<br />diverge â we used in Example 1 the modest value ? ? ??.<br />? ?????? ???????????????restricted to ?,<br />?<br />?????<br />? ? ? ??????? , where ? ? ? is a user<br />Example 1 (continued):<br />intensity surface on a grid ? ? ???????????under the log Gaussian Cox process which<br />was estimated in Example 1, Section 7. In this example ? ? ????? ??????.<br />After some preliminary runs of the MALA the parameter ? was adjusted to be ???<br />in order to obtain an acceptance rate close to the optimal rate ???? given in Roberts and<br />Rosenthal (1995) (they formally prove their results for target distributions with i.i.d.<br />components, but notice that various generalizations are possible and the optimal rate<br />appear to be quite robust over changes in the model). Then a sample of length ???????<br />was generated by the MALA and we used a subsample of this (with spacing equal to<br />??) for obtaining Monte Carlo estimates of the various characteristics of the posterior.<br />These estimates are reported below.<br />To study the convergence properties and to compare the different implementations of<br />the MALA we have considered various plots of timeseries and estimated autocorrelations<br />for selected cells on the initial as well as the extended lattice. It appears from these<br />We now consider estimation of the Gaussian process and the<br />24</p>  <p>Page 27</p> <p>plots that the potential problem related to geometrical ergodicity of the MALA is rather<br />hypothetical. As an illustration Fig. 11 shows timeseries and estimated autocorrelations<br />for a subsample of???????when the invariant distribution of the MALA is either ??? or<br />???????. In the former case the autocorrelations die out much faster.<br />Monte Carlo posterior means of the Gaussian process and the intensity surface are<br />shown in Fig. 12. For comparison we have also included Diggleâs (1985) nonparametric<br />kernel estimate of the intensity surface. For the uniform kernel given by the uniform<br />density on a disc, the band width of the kernel can be chosen by minimization of an<br />estimate of the mean square error (see Diggle, 1985, and Berman and Diggle, 1989).<br />Instead of the uniform kernel we actually used a planar Epanecnikov kernel since the<br />estimate obtained with this kernel has a more suitable smooth appearance. The band<br />width ????? for the planar Epanecnikov kernel was obtained by calibration of the chosen<br />band width for the uniform kernel as suggested in Diggle (1985). The posterior mean of<br />the intensity surface is quite peaked since the minimum and maximum values are ?????<br />and ???????. This is not surprising recalling the heavytailedness of the log Gaussian<br />distribution. The kernel estimate is less peaked with a range ?-??????. Integration of<br />the Monte Carlo posterior mean of the intensity surface and the kernel estimate over the<br />unit square yields ?????? and ??????, respectively, so the expected number of points<br />for the inhomogeneous Poisson processes with intensity surfaces given by the posterior<br />mean respective the kernel estimate are practically equal and very near to the observed<br />number of points (???). We have also in Fig. 12 included a plot of the logarithm to the<br />Monte Carlo posterior mean of the intensity surface as this gives a better impression of<br />the variability for intermediate values of the posterior mean.<br />The application of MCMC also facilitates assessment of posterior uncertainty. The<br />estimated posterior variance of the Gaussian process, ? ??????????? ????? ? ?, is shown<br />in the left plot in Fig. 13. The largest variance is ???? whilst the smallest is ???. By<br />comparing this plot with the Monte Carlo posterior mean of the intensity surface in Fig.<br />12, we see that the posterior variance is smallest where the posterior mean is largest<br />and vice versa. For the posterior distribution of the intensity surface we have further<br />for selected cells ???estimated the ??% and ??% quantiles. These credibility intervals<br />are shown in Table 2 when ????? are given by ?????????? ??? ? ???????, and ???????.<br />The credibility interval for ??????is largest as this cell is situated in a peak of ?????????.<br />As an illustration of the simulation method on the extended lattice and the effect<br />of wrapping the extended Gaussian field on a torus, the right plot in Fig. 13 shows<br />the Monte Carlo posterior mean of?????. Notice that outside the original field and<br />away from the boundaries the estimated posterior mean is constant and equal to the<br />unconditional mean.<br />Finally, we have considered MAP-estimation of the Gaussian process and the<br />intensity process. The extended matrix ? was strictly positive definite, and ????<br />and ????<br />???<br />were obtained by iterating the discrete gradient ascent algorithm until the<br />gradient was practically zero (i.e.until its coordinates were numerically less than<br />????). The minimum and maximum values of ????are ???? and ????, while the<br />corresponding values of the estimated posterior means ??????????? ????? ? ?, are ????<br />???<br />25</p>  <p>Page 28</p> <p>and ????. Actually, ????is very similar to these posterior means, so we have omitted<br />the plot of ????. Since ???<br />??<br />? ?????the MAP-estimate is clearly a totally<br />unreasonable estimate of the intensity surface. This may as noted before be due to the<br />skewness and heavytailedness of the log Gaussian distribution combined with the fact<br />that the intensity surface is a random field of correlated log Gaussian random variates.<br />In Example 1 the posterior mean and the nonparametric kernel estimate gave very<br />different estimates of the intensity surface. To study these estimators under known<br />conditions we simulated a point pattern on the unit square from the log Gaussian Cox<br />process with exponential correlation function and parameters ? ? ?? ??? ?? ? ? ??.<br />Using the same procedure as in Example 1, Section 7, the estimates of ?? ??? ? are<br />????? ????? ????, and the procedure for choosing the bandwidth yields ????. Plots of<br />the true intensity surface, the Monte Carlo posterior mean of the intensity surface under<br />the estimated model, and the kernel estimate are shown in Fig. 14. In this case the two<br />estimates look much more similar than in Example 1. The large difference between the<br />intensity surface estimates in Example 1 may be explained by the considerably larger<br />bandwidth which was used in the kernel estimate in Example 1, and which yielded an<br />oversmoothed estimate of the intensity surface. In Fig. 14 the range of the true intensity<br />surface, the Monte Carlo posterior mean, and the kernel estimate are ???-???????, ?????-<br />???????, and ?-???????, respectively. Integration of the estimates give ?????? for the<br />posterior mean and ?????? for the kernel estimate, while the integral of the true surface<br />is ??????, and the true and estimated intensity are ? ? ?????? and ? ? ? ???.<br />In conclusion, at least for the particular cases of Example 1 and the simulation<br />study, the posterior mean seems to be the better estimate.<br />???????????<br />Acknowledgments<br />This research will be a part of the second and third authors Ph.D. Dissertations. It has<br />been funded by the Danish Informatics Network in the Agricultural Sciences, the Danish<br />Natural Science Research Council, NORFA and the Research Council of Norway. Antti<br />Penttinen kindly provided the data studied in Examples 1 and 2. We thank Anders Brix,<br />Poul Svante Eriksen, Peter Green, JÃ¸rgen Hoffmann-JÃ¸rgensen, Steffen L. Lauritzen,<br />Antti Penttinen, Gareth Roberts, Mats Rudemo, Dietrich Stoyan, the editor and two<br />anonymous referees for helpful comments.<br />Appendix: Geometrical ergodicity of the truncated MALA<br />Below we prove that the truncated MALA discussed in Section 8 is geometrically<br />ergodic when ? ? ? ? ?. For simplicity and without loss of generality we shall assume<br />that ? ? ?. Letting ? ? ? ??, then by (20) the logarithm of the posterior density is<br />????????? ? ???????? ??<br />???????? ?? ???<br />?<br />??????????<br />?? ??????<br />where ? ? ???????????????, and by (21) the truncated gradient is<br />?????????? ?? ? ?? ? ??? ?????<br />26</p>  <p>Page 29</p> <p>where<br />??? ?? ???? ? ?? ???????<br />?<br />???????????<br />In the following ? will denote a measurable function mapping<br />concerning geometrical ergodicity are the following:<br />?into<br />. The results<br />Theorem 4.<br />????? ? ????????? and any ? ? ?, i.e, there exist ? ? ?? ? ? and ? ? ?? ? ?<br />such that for any ? ?<br />??????<br />measure ?, ?????? ?????????????? ?????? ???.<br />Corollary. Suppose that ?????? ? ???????????? ? ?<br />from the truncated MALA where ? ? ? ? ? and the initial distribution of ??is arbitrary.<br />Define the Monte Carlo approximation??? ?<br />When ? ? ? ? ? the truncated MALA is ??-uniformly ergodic for<br />?,<br />??????<br />????????? ?<br />?<br />?<br />??? ?????? ?<br />?????? ????????<br />? ?????????<br />?? ? ? ??<br />Here ????denotes the ?-step transition kernel of the truncated MALA and for a signed<br />?, and that ???????is generated<br />? ?<br />?<br />??????? of the mean ? ? ??????<br />calculated for the stationary chain. Assuming first that the density of ??is ??????, then<br />????? ??????<br />Moreover, if ??<br />distribution of ??:<br />????? ???<br />Proof. Let ???? ? ? ? ??????????????and let ?????? be the density of ????????????.<br />Then (36) in Roberts and Tweedie (1996b) holds since ? ? ??? ????is bounded. Since<br />the proof of Theorem 4.1 in Roberts and Tweedie (1996b) is also applicable in our<br />situation, the geometrical ergodicity then follows if we can show that the truncated<br />MALA âconverges inwardsâ. More precisely let as in Roberts and Tweedie (1996b),<br />???? ? ?? ? ? ?? ?? ? ???? and ???? ? ?? ? ? ?????????? ? ?? ? ??? ??????? ?????? Then we<br />need to show that<br />?<br />Here ? denotes symmetric difference, i.e. ??? ? ?? ? ?? ? ?? ? ??.<br />Note that for any ? ? ? we can choose ??such that<br />??<br />??? ???<br />?? ? ????????? ? ?<br />?<br />?<br />???<br />???????????????? ? ??<br />?? ?, we have a central limit theorem independently of the chosen initial<br />?<br />??<br />???<br />?<br />? ?????? ?? ? ? ??<br />?????????<br />???? ? ???? ? ? ? ?? ??? ? ??<br />?<br />???????<br />???? ? ???? ? ? ? where<br />????? ? ?? ? ? ?? ? ? ????? ? ???. Thus<br />?<br />?????????<br />???? ? ???? ? ?<br />?<br />?????????????????<br />???? ? ???? ? ? ??<br />27</p>  <p>Page 30</p> <p>Since<br />? ? ? ????? ? ?? ?? ? ?? ? ? ????? ? ?????? ? ?? ? ??????? ? ??? ????????<br />we have for ??? sufficiently large that ????? ? ???? so that ??????????? ? ????? ?<br />????? ? ???? . It is therefore enough to show that when ??? is sufficiently large then<br />? ? ? ????? implies that ? ? ? ????.<br />It is straightforwardly seen that the inequality which defines the set ???? is<br />equivalent to ??? ??? ??? ??? ??? ? where<br />?<br />???<br />??????????<br />??? ?????<br />? ? ?<br />??? ?????<br />??????? ??? ?????<br />?<br />? ??? ?????<br />?<br />??? ?<br />?<br />? ???<br />???? ? ??? ?????????<br />?<br />??? ?<br />???<br />???<br />?<br />? ? ?<br />??? ?<br />??? ?<br />??<br />????????<br />??<br />?<br />???<br />?? ???? ??? ????<br />?<br />? ? ??? ?<br />? ? ??? ? ??? ?????<br />??<br />??? ?? ? ?<br />??????<br />???<br />and?? ? ? ? ??. If ? ? ? ????? and ??? is sufficiently large, then ??? ??? ? since ??is<br />bounded and ? ? ? ? ?. We therefore just need to show that ??? ??? ??? ? for<br />? ? ? ????? and ??? sufficiently large.<br />If ??? ? ? then also ?? ?? ? ? because ? is of full rank. Furthermore, if<br />? ? ? ?????, then?? ???? ?? ? ????? ???? ???? ?????? where ??? ?? is a uniformly bounded<br />vector. Since ? ? ? ? ?, we have therefore that ? ??? ? ? implies that?? ???? ?,<br />while ? ??? ? ?? implies that?? ???? ??, where in both cases ?? ???? ? ? at a rate<br />faster than ??? ????, since ? ?????? ???is of the order ?????? ??? asymptotically. Let now<br />? ? ?????? ? ????? ?? ???? ?? ??. Then ??? ??? ??can be written as<br />?<br />??????? ????<br />??? ? ???????? ???<br />????? ?????? ?????? ? ?? ??????? ? ?<br />where ????? ???? ?? is a finite sum of bounded terms. Since for each ????? ? ?????? the<br />corresponding term ????? in the sum converges to ? when ?? ?? ? ?, the proof of the<br />theorem is completed. The corollary is a direct consequence of Theorem 4.1 in Roberts<br />and Tweedie (1996a).<br />????????????<br />????<br />?<br />?? ???? ??? ????<br />?<br />?<br />?<br />? ?????? ???<br />?<br />?<br />??????? ?????? ? ?? ?????<br />???? ??????? ????<br />?<br />?<br />? ???<br />? ? ??? ???<br />?<br />? ? ??? ???<br />?<br />??<br />?<br />?? ? ???? ?<br />References<br />Adler, R. (1981). The Geometry of Random Fields. Wiley, New York.<br />Arjas, E. and Gasbarra, D. (1994).<br />censored survival data, using the Gibbs sampler. Statistica Sinica 4, 505â524.<br />Nonparametric Bayesian inference from right<br />28</p>  <p>Page 31</p> <p>Baddeley, A.J. and Van Lieshout, M.N.M. (1993). Stochastic geometry models in high-<br />level vision. In K. Mardia and G.K. Kanji (eds.) Statistics and images, Advances<br />in Applied Statistics, a supplement to J. Appl. Statist. 20, 231â256.<br />Baddeley, A.J. and Van Lieshout, M.N.M. (1995). Area-interaction point processes.<br />Ann. Inst. Statist. Math. 47, 601â619.<br />Baddeley, A.J., Van Lieshout, M.N.M. and MÃ¸ller, J. (1996). Markov properties of<br />cluster processes. Adv. Appl. Prob. (SGSA) 28, 346â355.<br />Baddeley, A. J. and MÃ¸ller, J. (1989). Nearest-neighbour Markov point processes and<br />random sets. Int. Statist. Rev. 57, 89â121.<br />Bartlett, M.S. (1964). Spectral analysis of two-dimensional point processes. Biometrika<br />44, 299â311.<br />Berman, M. and Diggle, P.J. (1989). Estimating weighted integrals of the second-order<br />intensity of a spatial point process. J. R. Statist. Soc. B 51, 81â92.<br />Besag, J.E. (1974). Spatial interaction and the statistical analysis of lattice systems. J.<br />Roy. Statist. Soc. B 36, 192â225.<br />Besag, J.E. (1977). Some methods of statistical analysis for spatial data. Bull. Internat.<br />Statist. Inst. 47, 77â92.<br />Besag, J.E. (1994). Discussion of the paper by Grenander and Miller. J. R. Statist.<br />Soc. B 56, 591â592.<br />Christakos, G. (1984). On the problem of permissible covariance and covariogram<br />models. Water Resources Research 20, 251â265.<br />Christakos, G. (1992). Random Field Models in Earth Sciences. Academic Press, San<br />Diego.<br />Cressie, N. (1991). Statistics for Spatial Data. Wiley, New York.<br />Daley, D.J. and Vere-Jones, D. (1988). An Introduction to the Theory of Point Processes.<br />Springer-Verlag, New York.<br />Davis, P.J. (1979). Circulant Matrices. Wiley, New York.<br />Diggle, P.J. (1983). Statistical Analysis of Spatial Point Patterns. Academic Press,<br />London.<br />Diggle, P.J. (1985). A kernel method for smoothing point process data. Appl. Statist.<br />34, 138â147.<br />Diggle, P.J. and Milne, R.K. (1983).<br />bivariate spatial point processes. J. R. Statist. Soc. B 45, 11â21.<br />Bivariate Cox processes: Some models for<br />29</p>  <p>Page 32</p> <p>Gelfand, A.E. and Carlin, B.P. (1991). Maximum likelihood estimation for constrained<br />or missing data models. Research Report 91â002, Division of Biostatistics,<br />University of Minnesota.<br />Georgii, H.-O. (1988). Gibbs Measures and Phase Transitions. Walter de Gruyter,<br />Berlin.<br />Geyer, C.J. (1994). On the convergence of Monte Carlo maximum likelihood calcula-<br />tions. J. R. Statist. Soc. B 56, 261â274.<br />Grandell, J. (1976). Doubly Stochastic Poisson Processes. Lecture Notes in Mathemat-<br />ics, 529. Springer-Verlag, Berlin.<br />Granville, V. and Smith, R.L. (1995). Clustering and Neyman-Scott process parameter<br />simulation via Gibbs sampling. (Manuscript.) Statistical Laboratory, University<br />of Cambridge.<br />Grenander, U. and Miller, M.I. (1994).<br />systems (with discussion). J. R. Statist. Soc. B 56, 549â603.<br />Representations of knowledge in complex<br />HÂ¨ aggstrÂ¨ om, O., Van Lieshout, M.N.M. and MÃ¸ller, J. (1996). Characterisation results<br />and Markov chain Monte Carlo algorithms including exact simulation for some<br />spatial point processes. Research Report R-96â2040, Department of Mathematics,<br />Aalborg University. (Submitted for publication.)<br />Heikkinen, J. and Arjas, E. (1996). Nonparametric Bayesian estimation of a spatial<br />Poisson intensity. Preprint 20, Department of Statistics, University of Jyvaskyla.<br />(Submitted for publication.)<br />Jensen, J.L. and MÃ¸ller, J. (1991). Pseudolikelihood for exponential family models of<br />spatial point processes. Annals of Applied Probability 1, 445â461.<br />Karr, A.F. (1991). Point Processes and Their Statistical Inference. (2nd ed.) Marcel<br />Dekker, New York.<br />Kuuluvainen, T., Penttinen, A., Leinonen, K, and Nygren, M. (1996).<br />opportunities for comparing stand structural heterogeneity in managed and primeval<br />forests: an example from boreal spruce forest in southern Finland. Silvia Fennica<br />30, 315â328<br />Statistical<br />LantuÂ´ ejoul, C. (1994). Nonconditional simulation of stationary isotropic multigaussian<br />random functions. In Geostatistical Simulations, (eds. M. Armstrong and P. Dowd)<br />Kluwer Academic Publishers, Dordrecht.<br />Lawson, A.B. (1993). Discussion contribution to the The Gibbs sampler and other<br />Markov chain Monte Carlo methods. J. R. Statist. Soc. B 55, 61â62.<br />30</p>  <p>Page 33</p> <p>Ledoux, M. and Talagrand, M. (1991). Probability in Banach spaces. Springer-Verlag,<br />Berlin.<br />Lotwick, H.W. and Silverman, B.W. (1982). Methods for analysing spatial processes<br />of several types of points. J. R. Statist. Soc. B 44, 406-413.<br />Mantouglou, A. and Wilson, J. L. (1982). The turning bands method for simulation<br />of random fields using line generation by a spectral method. Water Resources<br />Research 18 (5), 1379â1394.<br />MatÂ´ ern, B. (1960). Spatial Variation. Meddelanden frË an Statens Skogsforskningsinstitut,<br />Vol. 49 (5). Statens Skogsforskningsinstitut, Stockholm.<br />Matheron, G. (1973). The intrinsic random functions and their applications. Adv. Appl.<br />Prob. 5, 439â468.<br />MÃ¸ller, J. (1994). Markov chain Monte Carlo and spatial point processes. Research<br />Report 293, Department of Theoretical Statistics, University of Aarhus. To appear<br />in O.E. Barndorff-Nielsen et al. (eds.): Proc. Seminaire EuropÂ´ een Statistique<br />Toulouse 1996 âCurrent trends in stochastic geometry with applicationsâ, Chapman<br />and Hall.<br />Ogata, Y. and Katsura, K. (1988). Likelihood analysis of spatial inhomogeneity for<br />marked point patterns. J. Am. Statist. Ass. 40, 29â39.<br />Penttinen, A., Stoyan, D. and Henttonen H.M (1992). Marked point processes in forest<br />statistics. Forest Science 38 (4), 806â824.<br />Preston, C. (1976). Random Fields. Lecture Notes in Mathematics, 534. Springer-<br />Verlag, Berlin.<br />Rathbun, S.L. and Cressie, N. (1994). A space-time survival point process for a longleaf<br />pine forest in Southern Georgia. J. Am. Statist. Ass. 89, 1164â1174.<br />Ripley, B.D. (1977). Modelling spatial patterns (with discussion). J. R. Statist. Soc.<br />B 39, 172â212.<br />Ripley, B.D. (1987). Stochastic Simulation. Wiley, New York.<br />Ripley, B.D. (1988). Statistical Inference for Spatial Processes. Cambridge University<br />Press, Cambridge.<br />Roberts, G.O. and Rosenthal, J.S. (1995). Optimal scaling of discrete approximations to<br />Langevin diffusions. Research Report no 95â11, Statistical Laboratory, Cambridge<br />University.<br />31</p>  <p>Page 34</p> <p>Roberts, G.O. and Tweedie, R.L. (1996a). Geometric convergence and central limit<br />theorems for multidimensional Hastings and Metropolis algorithms. Biometrika<br />83, 95-110.<br />Roberts, G.O. and Tweedie, R.L. (1996b).<br />diffusions and their discrete approximations. Bernoulli 2, 341â363.<br />Exponential convergence of Langevin<br />Stoyan, D., Kendall, W.S. and Mecke, J. (1995). Stochastic Geometry and Its Applica-<br />tions. 2nd ed. Wiley, Chichester.<br />Stoyan, D. and Stoyan, H. (1994). Fractals, Random Shapes and Point Fields. Wiley,<br />Chichester.<br />Thomas, M. (1949). A generalization of Poissonâs binomial limit for use in ecology.<br />Biometrika 36, 18â25.<br />Wackernagel, H. (1995). Multivariate Geostatistics. Springer-Verlag, Berlin.<br />Widom, B. and Rowlinson, J.S. (1970). New models for the study of liquid-vapor phase<br />transitions. J. Chem. Physics 52, 1670â1684.<br />Wood, A.T.A. and Chan, G. (1994). Simulation of stationary Gaussian processes in<br />??????. J. Computational and Graphical Statistics 3, 409â432.<br />Yaglom, A.M. (1986). Correlation Theory of Stationary and Related Random Functions<br />I. Springer, Berlin.<br />Jesper MÃ¸ller, Department of Mathematics, Aalborg University, Fredrik Bajers Vej<br />7E, DK- 9220 Aalborg Ã, Denmark. Email: jm@math.auc.dk<br />Anne Randi Syversveen, Department of Mathematical Sciences, The Norwegian Uni-<br />versity of Science and Technology, N-7034 Trondheim, Norway. Email:<br />annerand@math.ntnu.no<br />Rasmus Plenge Waagepetersen, Department of Theoretical Statistics and Operations Re-<br />search, Departments of Mathematical Sciences, University of Aarhus, DK-8000 ËArhus<br />C, Denmark. Email: rasmus@mi.aau.dk<br />32</p>  <p>Page 35</p> <p>1. Gaussian:<br />????????????<br />?????????<br />??????????????<br />??????????<br />5. Hyperbolic:<br />?? ? ??????<br />????????????????? ??<br />????? ? ?? ? ??????????<br />? ? ??????????<br />2. Exponential:<br />6. Bessel:<br />3. Cardinal sine: 7. Spherical:<br />4. Stable:<br />Table 1. Correlation functions. ?? is the Bessel function of the first kind of order zero.<br />33</p>  <p>Page 36</p> <p>? ? ??<br />7.0-181.3<br />78.1<br />7.9-207.5<br />89.9<br />6.5-173.3<br />74.3<br />17.2-380.3<br />163.2<br />363.3-3733.3<br />1734.1<br />? ? ??<br />26.6-546.2<br />235.0<br />8.8-218.5<br />95.7<br />11.5-282.0<br />119.2<br />12.9-311.4<br />130.6<br />? ? ??<br />7.4-190.4<br />83.0<br />8.0-215.3<br />93.0<br />11.6-282.9<br />119.8<br />10.5-248.4<br />105.2<br />? ? ??<br />28.6-541.3<br />234.5<br />8.0-207.3<br />89.0<br />6.7-170.4<br />73.2<br />5.0-138.2<br />60.7<br />? ? ??<br />? ? ??<br />? ? ??<br />? ? ??<br />????? ?<br />???????<br />Table 2. Example 1. Estimated 80%-credibility intervals and posterior means of the intensity surface at selected<br />cells ??? organized in accordance with Figure 11, where ????? ? ?????? ??????? ?????????????? correspond to the<br />lower left, upper left, lower right, and upper right cells.<br />34</p>  <p>Page 37</p> <p>0.00.10.20.3 0.4 0.5<br />1.0<br />1.5<br />2.0<br />2.5<br />a) Gaussian<br />0.00.10.2 0.3 0.40.5<br />1.0<br />1.5<br />2.0<br />2.5<br />b) Exponential<br /> <br /> <br />0.00.10.2 0.30.40.5<br />1.0<br />1.5<br />2.0<br />2.5<br />c) Cardinal sine<br />0.00.10.20.3 0.40.5<br />1.0<br />1.5<br />2.0<br />2.5<br />3.0<br />d) Stable<br /> <br /> <br />0.00.10.20.30.40.5<br />1.0<br />1.5<br />2.0<br />2.5<br />e) Modified Thomas<br /> <br /> <br />0.00.10.20.30.40.5<br />1.0<br />1.5<br />2.0<br />2.5<br />f) Matern cluster<br /> <br /> <br />0.00.10.20.30.40.5<br />0.0<br />0.2<br />0.4<br />0.6<br />0.8<br />1.0<br />g) Gaussian<br />0.00.10.20.30.40.5<br />0.0<br />0.2<br />0.4<br />0.6<br />0.8<br />1.0<br />h) Exponential<br />Fig. 1. Upper row, a)-d): Various pair correlation functions with varying values of ? (solid line = smallest value<br />of ?) when ? ? ?. Lower row: e), f) pair correlation functions for the Thomas and MatÂ´ ern cluster processes. g),<br />h) Gaussian and exponential correlation functions with ? as in the upper row.<br />35</p>  <p>Page 38</p> <p>Fig. 2. Simulated realizations of Gaussian random fields with ? ? ?. Left to right: Gaussian ? ? ?????, exponential<br />? ? ?????, cardinal sine ? ? ?????, stable ? ? ?????.<br />36</p>  <p>Page 39</p> <p>â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢ â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢â¢<br />â¢<br />â¢<br />â¢ â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢â¢<br />â¢ â¢<br />â¢<br />â¢â¢ â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢ â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢ â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢ â¢â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢â¢<br />â¢ â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢ â¢<br />â¢â¢<br />â¢<br />â¢â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢ â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢ â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢ â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />Fig. 3. Simulations of log Gaussian Cox processes conditional on that the number of points is 148. First column:<br />Gaussian correlation function. Second column: Exponential. Third column: Cardinal sine. Fourth column: Stable.<br />First row: Same values of parameters as in Figure 2, i.e. ??? ? and ? ? ?????? ?????? ?????? ????? (left to right).<br />Second row: ??? ???, ? ? ?????? ?????? ?????? ?????. Third row: ??? ???, ? ? ?????? ?????? ?????? ?????.<br />Mean and variance of the number of points are equal in each row.<br />37</p>  <p>Page 40</p> <p>0.00.20.40.60.81.0<br />0.0<br />0.2<br />0.4<br />0.6<br />0.8<br />1.0<br />050100150200250300<br />0.0<br />0.01<br />0.02<br />0.03<br />050100150200250300<br />0.0<br />0.01<br />0.02<br />0.03<br />0.04<br />0.05<br />Fig. 4. Left: Plot of Gaussian correlation function (solid) and ??????? (dotted line) for ? ? ?????. Middle: Hankel<br />transform of ??????? for ? ? ?????. Right: Hankel transform of ??????? for ? ? ???.<br />38</p>  <p>Page 41</p> <p>r<br />F(r)<br />0.00.050.10 0.150.20<br />0.0<br />0.2<br />0.4<br />0.6<br />0.8<br />1.0<br />r<br />G(r)<br />0.00.050.100.150.20<br />0.0<br />0.2<br />0.4<br />0.6<br />0.8<br />1.0<br />Fig. 5. Left: Dotted lines: Average and envelopes for the nonparametric estimator of ? based on 100 simulations of<br />the Thomas process. Solid lines: The same but for the log Gaussian Cox process with Gaussian correlation function.<br />Right: The same as the left plot but with ? substituted by ?.<br />39</p>  <p>Page 42</p> <p>â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢â¢<br />â¢<br />â¢ â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />Fig.<br />bivariate log Gaussian Cox process, ?? ? ?? ? ???, ?? ? ?? ? ?. Right: Bivariate log Gaussian Cox process,<br />?? ? ?? ? ???, ?? ? ??? ? ?.<br />6. Left: Gaussian random field with exponential correlation function, ??? ? and ? ? ???.Middle:<br />40</p>  <p>Page 43</p> <p>â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />beta<br />sigma^2<br />0.040.060.080.100.12<br />1.5<br />2.0<br />2.5<br />3.0<br />t<br />c(t)<br />0.00.10.20.30.4 0.5<br />-0.5<br />0.0<br />0.5<br />1.0<br />1.5<br />Fig.<br />exponential covariance function ???? ? ????????????. The true parameter value is marked with a square. Right:<br />The true covariance function (dotted line), the mean and upper and lower envelopes for the estimated covariance<br />functions (solid lines).<br />7. Left: Estimated parameters ? and ??from 20 simulations under the log Gaussian Cox process with<br />41</p>  <p>Page 44</p> <p>.<br />.<br />.<br />.<br />.<br />. . ..<br />.<br />.<br />.<br />. .<br />....<br />.<br />.<br />..<br />.<br />.<br />.<br />..<br />.<br />.<br />.. .. .<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />..<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />..<br />.<br />.<br />. . ..<br />..<br />..<br />.....<br />.<br />.<br />. .<br />..... ...<br />.<br />..<br />. .<br />.<br />.<br />.<br />.<br />.<br />.<br />. .<br />.<br />. .<br />..<br />..<br />. . . .<br />.<br />.<br />.<br />.<br />. ..<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />0.00.2 0.40.60.81.0<br />0.0<br />0.2<br />0.4<br />0.6<br />0.8<br />1.0<br />a)  <br />t<br />c(t)<br />0.0 0.10.20.30.40.5<br />-0.5<br />0.0<br />0.5<br />1.0<br />1.5<br />2.0<br />2.5<br />3.0<br />b)  <br />t<br />L^(t)<br />0.00.10.20.30.40.5<br />0.0<br />0.1<br />0.2<br />0.3<br />0.4<br />0.5<br />c)  <br />F(t)<br />F^(t)<br />0.00.20.40.60.8 1.0<br />0.0<br />0.2<br />0.4<br />0.6<br />0.8<br />1.0<br />d)  <br />G(t)<br />G^(t)<br />0.00.20.40.60.81.0<br />0.0<br />0.2<br />0.4<br />0.6<br />0.8<br />1.0<br />e)  <br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />..<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />.<br />0.00.20.40.60.81.0<br />0.0<br />0.2<br />0.4<br />0.6<br />0.8<br />1.0<br />f)  <br />Fig. 8. Example 1. Several characteristics for the pine data (see the text for explanations).<br />42</p>  <p>Page 45</p> <p>t<br />z(t)<br />0.00.1 0.20.30.4<br />0.0<br />0.5<br />1.0<br />1.5<br />2.0<br />2.5<br />3.0<br />t<br />z(t)<br />0.00.10.20.3 0.4<br />0.0<br />0.5<br />1.0<br />1.5<br />2.0<br />2.5<br />3.0<br />Fig. 9. Example 1. Estimate of z based on the data (solid line) and âconditionalâ envelopes (â â â ) and<br />âunconditionalâ envelopes (- - - - -) based on 20 simulations. Left: Log Gaussian Cox process. Right: MatÂ´ ern<br />cluster process.<br />43</p>  <p>Page 46</p> <p>â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />x<br />â¢<br />â¢<br />â¢â¢<br />x x<br />â¢<br />â¢<br />â¢ â¢<br />â¢â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢â¢<br />x<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />x<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢â¢<br />â¢â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />x<br />â¢â¢<br />â¢<br />â¢<br />â¢<br />x<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢â¢<br />â¢<br />â¢â¢<br />â¢<br />xx<br />x<br />â¢<br />â¢<br />â¢<br />x<br />â¢<br />â¢<br />â¢<br />â¢<br />x<br />x<br />â¢<br />â¢<br />x<br />â¢<br />x<br />x<br />â¢<br />â¢<br />x x<br />â¢<br />â¢<br />â¢<br />x<br />x<br />x<br />â¢<br />â¢â¢â¢ â¢<br />x<br />â¢<br />â¢ â¢â¢â¢â¢<br />â¢<br />â¢<br />x<br />â¢<br />â¢â¢â¢<br />x<br />â¢<br />â¢<br />xxx<br />â¢â¢â¢<br />â¢<br />â¢ â¢â¢â¢â¢<br />â¢<br />x<br />xx<br />â¢<br />â¢<br />â¢<br />x<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢â¢<br />â¢â¢â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢ â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢â¢<br />â¢â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />x<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢â¢<br />â¢â¢<br />x<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />â¢<br />0.00.20.40.60.81.0<br />0.0<br />0.2<br />0.4<br />0.6<br />0.8<br />1.0<br />a) <br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />xx<br />x<br />x<br />x<br />xx<br />x x<br />xxx<br />x<br />x<br />xx<br />xx<br />x<br />x<br />x<br />xxxx x<br />x<br />xx<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />xx<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />xx<br />x<br />x<br />x<br />x x<br />x<br />x<br />x x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x x<br />x<br />x<br />x<br />x<br />0.00.10.20.30.40.5<br />-0.5<br />0.0<br />0.5<br />1.0<br />1.5<br />2.0<br />2.5<br />3.0<br />3.5<br />b) <br />0.00.20.40.60.81.0<br />0.0<br />0.2<br />0.4<br />0.6<br />0.8<br />1.0<br />c) <br />Fig. 10. Example 2. a) Plot of data, spruces marked with â?â and birches marked with âxâ. b) Empirical covariance<br />functions (solid line), from top ? ???, ? ???, ? ???, and covariance functions for the fitted model (dotted line). c) Empirical<br />???? (solid line) together with lower and upper envelopes (dotted line) plotted against the mean of 99 simulations<br />from the fitted model.<br />44</p>  <p>Page 47</p> <p>time<br />0100002000030000<br />-2<br />0<br />2<br />4<br />6<br />8<br />         lag<br />01020 3040<br />0.0 0.2 0.4 0.6 0.8 1.0<br />time<br />0100002000030000<br />0<br />2<br />4<br />6<br />8<br />         lag<br />010 203040<br />0.0 0.2 0.4 0.6 0.8 1.0<br />Fig. 11. Example 1. Upper plots: Timeseries (left) and estimated autocorrelations (right) for????????? obtained by<br />transforming a subsample of ???????? (spacing = 10) generated by MALA. Lower row: Same as upper row but no<br />transformation is used, i.e. ????????? is generated directly by MALA.<br />45</p>  <p>Page 48</p> <p>Fig. 12. Example 1. Upper left plot: Monte Carlo posterior mean of the Gaussian field. Upper right plot: Monte<br />Carlo posterior mean of the intensity surface. Lower left plot: Logarithm to the upper right plot. Lower right plot:<br />Diggleâs nonparametric kernel estimate of the intensity surface.<br />46</p>  <p>Page 49</p> <p>Fig. 13. Example 1. Left: Monte Carlo posterior variance of the Gaussian field on the original lattice. Right:<br />Monte Carlo posterior mean of the Gaussian field on the extended lattice.<br />47</p>  <p>Page 50</p> <p>Fig. 14. Simulation study. Upper left plot: True Gaussian surface. Upper right plot: True intensity surface. Lower<br />left plot: Monte Carlo posterior mean of the intensity surface. Lower right plot: Diggleâs nonparametric kernel<br />estimate.<br />48</p>  <a href="https://www.researchgate.net/profile/Anne_Syversveen/publication/227701452_Log_Gaussian_Cox_Processes/links/02e7e51a6f17c691d3000000.pdf">Download full-text</a> </div> <div id="rgw21_56ab9fc7d28b9" class="c-box pub-resource-container js-toggle" style=""> <h4 class="lf js-expand-list"><small><a href="javascript:" class="lf">View other sources <span class="ico-expand-list"></span></a></small></h4> <h4 class="lf js-collapse-list hidden"><small><a href="javascript:" class="lf">Hide other sources <span class="ico-collapse-list"></span></a></small></h4> <div class="clear"></div> <div class="scroll-wrapper hidden"> <ul class="files-list c-list" id="rgw22_56ab9fc7d28b9">  <li class="c-list-item pub-resource-item"  data-type="fulltext" id="rgw23_56ab9fc7d28b9"> <span class="ico-pub"></span> <div class="file-content"> <div class="download"> <a href="profile/Anne_Syversveen/publication/227701452_Log_Gaussian_Cox_Processes/links/02e7e51a6f17c691d3000000.pdf" class="publication-viewer" title="02e7e51a6f17c691d3000000.pdf">02e7e51a6f17c691d3000000.pdf</a> </div>  <div class="details">  <span> Available from <a href="profile/Anne_Syversveen">Anne Randi Syversveen</a> &middot; Jan 21, 2016 </span>   </div>    </div> </li>  <li class="c-list-item pub-resource-item"  data-type="fulltext" id="rgw24_56ab9fc7d28b9"> <span class="ico-pub"></span> <div class="file-content"> <div class="download"> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.71.6732&amp;amp;rep=rep1&amp;amp;type=pdf" target="_blank" rel="nofollow" class="publication-viewer" title="Log Gaussian Cox Processes">Log Gaussian Cox Processes</a> </div>  <div class="details">   Available from <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.71.6732&amp;amp;rep=rep1&amp;amp;type=pdf" target="_blank" rel="nofollow">psu.edu</a>  </div>    </div> </li>  </ul> </div> </div> </noscript> <div class="clearfix"> <div class="action-container">  </div> <div class="pub-legal"> Data provided are for informational purposes only. Although carefully collected, accuracy cannot be guaranteed. The impact factor represents a rough estimation of the journal's impact factor and does not reflect the actual current impact factor. Publisher conditions are provided by RoMEO. Differing provisions from the publisher's actual policy or licence agreement may be applicable. </div>   </div> </div> <div class="clearfix">     <div id="rgw26_56ab9fc7d28b9" class="c-box pub-resource-container js-toggle" style="display: none;"> <h4 class="lf js-expand-list"><small><a href="javascript:" class="lf">View other sources <span class="ico-expand-list"></span></a></small></h4> <h4 class="lf js-collapse-list hidden"><small><a href="javascript:" class="lf">Hide other sources <span class="ico-collapse-list"></span></a></small></h4> <div class="clear"></div> <div class="scroll-wrapper hidden"> <ul class="files-list c-list" id="rgw27_56ab9fc7d28b9">  </ul> </div> </div>   <div id="rgw17_56ab9fc7d28b9" class="similar-publications"> <h2>Similar Publications</h2> <ul class="list-bordered">  <li class="c-list-item li-publication-teaser" id="rgw18_56ab9fc7d28b9"> <div> <h5> <a href="publication/281145921_Exact_Bayesian_Inference_for_Animal_Movement_in_Continuous_Time" class="color-inherit ga-similar-publication-title"><span class="publication-title">Exact Bayesian Inference for Animal Movement in Continuous Time</span></a>  </h5>  <div class="authors"> <a href="researcher/2044185198_Paul_G_Blackwell" class="authors ga-similar-publication-author">Paul G. Blackwell</a>, <a href="researcher/2031228179_Mu_Niu" class="authors ga-similar-publication-author">Mu Niu</a>, <a href="researcher/2079834072_Mark_S_Lambert" class="authors ga-similar-publication-author">Mark S. Lambert</a>, <a href="researcher/60023792_Scott_D_LaPoint" class="authors ga-similar-publication-author">Scott D. LaPoint</a>  </div>  </div> <div class="clear"></div> </li>  <li class="c-list-item li-publication-teaser" id="rgw19_56ab9fc7d28b9"> <div> <h5> <a href="publication/280243600_Modeling_and_Predicting_Surface_Roughness_in_Hard_Turning_Using_a_Bayesian_Inference-Based_HMM-SVM_Model" class="color-inherit ga-similar-publication-title"><span class="publication-title">Modeling and Predicting Surface Roughness in Hard Turning Using a Bayesian Inference-Based HMM-SVM Model</span></a>  </h5>  <div class="authors"> <a href="researcher/2066632629_Kang_He" class="authors ga-similar-publication-author">Kang He</a>, <a href="researcher/11832150_Qingsong_Xu" class="authors ga-similar-publication-author">Qingsong Xu</a>, <a href="researcher/31575251_Minping_Jia" class="authors ga-similar-publication-author">Minping Jia</a>  </div>  </div> <div class="clear"></div> </li>  <li class="c-list-item li-publication-teaser" id="rgw20_56ab9fc7d28b9"> <div> <h5> <a href="publication/275668438_A_Bayesian_mixture_of_semiparametric_mixed-effects_joint_models_for_skewed-longitudinal_and_time-to-event_data" class="color-inherit ga-similar-publication-title"><span class="publication-title">A Bayesian mixture of semiparametric mixed-effects joint models for skewed-longitudinal and time-to-event data</span></a>  </h5>  <div class="authors"> <a href="researcher/2051640749_Jiaqing_Chen" class="authors ga-similar-publication-author">Jiaqing Chen</a>, <a href="researcher/38930418_Yangxin_Huang" class="authors ga-similar-publication-author">Yangxin Huang</a>  </div>  </div> <div class="clear"></div> </li>  </ul> </div> </div> </div> </div> </div></div></div>
<div class="clear"></div><div id="rgw40_56ab9fc7d28b9" class="default-footer"> <div id="footer" class="clearfix"> <span class="footer-left"> &copy; 2008&dash;2016 researchgate.net. All rights reserved. </span> <span class="footer-right"> <a href="https://www.researchgate.net/about">About us</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="https://www.researchgate.net/contact">Contact us</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="careers">Careers</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="developers">Developers</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="blog" target="_blank">News</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="application.PrivacyPolicy.html">Privacy</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="application.TermsAndConditions.html">Terms</a> <span class="footer-link-separator" style="padding: 0 5px;">&nbsp;|&nbsp;</span> <a href="advertising?_ref=ft">Advertising</a> <span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="recruiters?_ref=ft">Recruiting</a> </span> </div>  </div></div>
<div id="rgw41_56ab9fc7d28b9">  <div class="header-wrapper-logged-out"> <div id="header"> <div class="header-content"> <a href="" class="g-l-logo"> <svg width="149" height="19"> <image xlink:href="https://c5.rgstatic.net/m/235107188705592/images/template/brand-header-logo.svg" src="https://c5.rgstatic.net/m/238113351022438/images/template/brand-header-logo.png" width="149" height="19"/> </svg> </a> <a href="" class="g-l-logo-ico"> <svg width="127" height="17" viewbox="0 0 127 22"> <image xlink:href="https://c5.rgstatic.net/m/235107188705592/images/template/brand-header-logo.svg" src="https://c5.rgstatic.net/m/238113351022438/images/template/brand-header-logo.png" width="127" height="17"/> </svg> </a> <div id="rgw42_56ab9fc7d28b9" class="header-login-wrapper js-header-login"> <div class="dropdown-right-align"> <div class="login-signup-container lf"> <a href="https://www.researchgate.net/signup.SignUp.html?ev=su_chnl_index&amp;hdrsu=1&amp;_sg=iUUAT81hSrElMWS3QQO9y8r9jmWApPCW1f0B-dA08NQntApIAaUe9UVrspRku2Gs" class="dropdown-toggle lf">Join for free</a> </div> <div class="dropdown lf" style="height: 20px;"> <a href="https://www.researchgate.net/application.Login.html" class="js-login-url dropdown-toggle lf">Log in <span class="caret"></span></a> <div class="dropdown-menu"> <div class="header-login-form-wrapper"> <!--[if IE 6]><p class="box-warning" style="margin-bottom: 0;">Sorry, ResearchGate no longer supports the version of Internet Explorer you are using. <a href="http://whatbrowser.org/" rel="nofollow" target="_blank">Update your web browser</a> and then log in. </p><![endif]--> <form method="post" action="https://www.researchgate.net/application.Login.html" class="form-big header-login-form js-login-form" name="loginForm" id="headerLoginForm"> <input type="hidden" name="request_token" value="5IF7jMp6tCxim7No3cR/OneeBRs8GExt7mH4dR07T1iDCpQNp3CZ41MXM9GeT2POziwvkn2v29axZbqNlcLiOoYy3S7Wr8SrZfWc8mnzLrts1nRKEJ5R3fvUDPavjaROPAt7UIFa1/Qyg5bNIbPf/tgHSGpGYGLFKzCyACptBHde85YB9MhP5hXewpZFUAgc6kAmjXeZUboUM8F60NMT7al4Y0k3sMFEBz6DfMyxxAOkTwvnmsGUIoBhiakLh/V5LvAvn1M+5bMxyDfYCwK65sDzELz6W8V5oTZ5dtLC+q8="/> <input type="hidden" name="urlAfterLogin" value="publication/227701452_Log_Gaussian_Cox_Processes"/> <input type="hidden" name="invalidPasswordCount" value="0"/> <input type="hidden" name="headerLogin" value="yes"/> <label for="input-header-login">Email</label> <div class="login-input"> <div class="info-tip-wrapper"> <span class="ico-info js-info"></span> </div> <input type="email" value="" name="login" class="login js-login-input text" id="input-header-login" tabindex="1"/> </div> <div class="clear"></div> <label class="lf" for="input-header-password"> Password </label> <a class="rf forgot-password js-forgot-password" href="application.LostPassword.html">Forgot password?</a> <div class="clear"></div> <input type="password" value="" name="password" class="password js-password-input text" id="input-header-password" tabindex="2"/> <div class="clear"></div> <label class="remember-me" for="headerLoginCookie"> <input type="checkbox" checked="checked" value="yes" name="setLoginCookie" class="lf checkbox" id="headerLoginCookie" tabindex="3"/> Keep me logged in </label> <div class="clear"></div> <input value="Log in" name="loginSubmit" class="btn btn-promote btn-fullwidth btn-large allow-leave js-submit-button" type="submit" tabindex="4"/> </form> <div class="connectors"> <div class="text">or log in with</div> <div class="connector-actions"> <a href="connector/linkedin/" class="li-connect js-li-connect" data-redirect-url="cHVibGljYXRpb24vMjI3NzAxNDUyX0xvZ19HYXVzc2lhbl9Db3hfUHJvY2Vzc2Vz"> <span class="icon ico-linkedin-round-grey"></span> <span class="icon ico-linkedin-round"></span> </a> <a href="connector/facebook/" class="fb-connect middle js-fb-connect" data-redirect-url="cHVibGljYXRpb24vMjI3NzAxNDUyX0xvZ19HYXVzc2lhbl9Db3hfUHJvY2Vzc2Vz"> <span class="icon ico-facebook-round-grey"></span> <span class="icon ico-facebook-round"></span> </a> <a href="connector/google/" class="g-connect js-g-connect" data-redirect-url="cHVibGljYXRpb24vMjI3NzAxNDUyX0xvZ19HYXVzc2lhbl9Db3hfUHJvY2Vzc2Vz"> <span class="icon ico-google-round-grey"></span> <span class="icon ico-google-round"></span> </a> </div> </div> </div> </div> </div> </div> </div> </div> </div> <script type="application/ld+json">
{ "@context" : "http://schema.org",
  "@type" : "Organization",
  "name" : "ResearchGate",
  "url" : "http://www.researchgate.net",
  "logo" : "http://www.researchgate.net/images/template/rg_logo_square_brand.png",
  "sameAs" : [ "https://www.facebook.com/ResearchGate",
    "https://twitter.com/ResearchGate",
    "https://plus.google.com/+researchgate",
    "https://www.linkedin.com/company/researchgate"] 
}
</script> </div> </div><div class="c-signup-bar" id="rgw43_56ab9fc7d28b9"> <div class="banner-contents">   <span class="message">ResearchGate is the professional network for scientists and researchers.</span> <a href="signup.SignUp.html?ev=su_banner" class="btn btn-large btn-promote">Join for free</a>  </div> </div></div>
<script>
rgConfig.backendTime = 496;
</script>
<script src="//c5.rgstatic.net/m/2277196935388619/javascript/lib/yui3/yui/yui-min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/21832295316281274/javascript/yuiLoaderConfig-min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/23178613132105398/javascript/vendor/babel-core/browser-polyfill.min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/2198378204065/javascript/min/lib/error_logging.js" type="text/javascript"></script>
<script>
(function (){
if (typeof YRG === "undefined") {
var xmlHttpRequest = new XMLHttpRequest();
xmlHttpRequest.open("post", "go.Error.html");
xmlHttpRequest.setRequestHeader("Content-Type", "application/json");
xmlHttpRequest.setRequestHeader("Accept", "application/json"); var loadedScripts = "";
if (window.performance && window.performance.getEntriesByType) {
    var result = [];
    var resources = performance.getEntriesByType("resource");
    for (var i in resources) {
        if (resources.hasOwnProperty(i)) {
            result.push({
                name: resources[i].name,
                duration: resources[i].duration
            });
        }
    }
    loadedScripts += "&loadedScripts=" + encodeURIComponent(JSON.stringify(result));
}
if (typeof YUI === "undefined") {
    loadedScripts += "&yuiLoaded=false";
} else {
    loadedScripts += "&yuiLoaded=true";
}
xmlHttpRequest.send("Type=InformationException&message=" + encodeURIComponent("Error loading YUI") + loadedScripts);
}
})();
</script>
<script>if (typeof YRG !== 'undefined') { YRG.use('rg-base',function(Y){Y.applyConfig({ignore: ["css-rg","css-rg2","css-ie","css-modules-publicprofile","css-pow-publicliterature-FollowPublicationPromo","css-pow-application-PdfJsReader","css-pow-publicliterature-PublicationInlineReader"]});Y.use(["rg.core.pagespeed.Monitoring"],function(Y){(function(){Y.rg.createInitialWidget({"data":{"content":{"data":{"profileSmallHeader":{"data":{"profileBadge":{"data":{"fullname":"Anne Randi Syversveen","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2671872220764\/images\/template\/default\/profile\/profile_default_m.jpg","profileStats":[],"profileFollowButton":null,"profileReputationScoreNumber":null,"profileUrl":"profile\/Anne_Syversveen","institution":"Norwegian Computing Center","institutionUrl":false,"widgetId":"rgw4_56ab9fc7d28b9"},"id":"rgw4_56ab9fc7d28b9","partials":[],"templateName":"publicprofile\/stubs\/ProfileBadge.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicprofile.ProfileBadge.html?accountId=1997243","viewClass":null,"yuiModules":["css-modules-publicprofile"],"stylesheets":["modules\/publicprofile.css"],"_isYUI":true},"widgetId":"rgw3_56ab9fc7d28b9"},"id":"rgw3_56ab9fc7d28b9","partials":[],"templateName":"publicprofile\/stubs\/ProfileSmallHeader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicprofile.ProfileSmallHeader.html?publicationUid=227701452","viewClass":null,"yuiModules":["css-modules-publicprofile"],"stylesheets":["modules\/publicprofile.css"],"_isYUI":true},"publication":{"data":{"publicationUid":227701452,"title":"Log Gaussian Cox Processes","journalTitle":"Scandinavian Journal of Statistics","journalDetailsTooltip":{"data":{"journalTitle":"Scandinavian Journal of Statistics","journalAbbrev":"Scand J Stat","publisher":"Dansk Selskab for Teoretisk Statistik, Wiley","issn":"1467-9469","impactFactor":"0.87","fiveYearImpactFactor":"1.15","citedHalfLife":">10.0","immediacyIndex":"0.19","eigenFactor":"0.00","articleInfluence":"1.35","widgetId":"rgw6_56ab9fc7d28b9"},"id":"rgw6_56ab9fc7d28b9","partials":[],"templateName":"publicliterature\/stubs\/JournalInfo.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.JournalInfo.html?issn=1467-9469","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"affiliation":"Aalborg University, \u00c5lborg, North Denmark, Denmark","type":"Article","details":{"doi":"10.1111\/1467-9469.00115","journalInfos":{"journal":"","publicationDate":"08\/1998;","publicationDateRobot":"1998-08","article":"25(3):451 - 482.","journalTitle":"Scandinavian Journal of Statistics","journalUrl":"journal\/1467-9469_Scandinavian_Journal_of_Statistics","impactFactor":0.87}},"source":false,"publicationActions":null,"publicationCoins":{"data":{"tags":[{"key":"ctx_ver","value":"Z39.88-2004"},{"key":"rft_val_fmt","value":"info:ofi\/fmt:kev:mtx:journal"},{"key":"rfr_id","value":"info:sid\/researchgate.net:researchgate"},{"key":"rft_id","value":"info:doi\/10.1111\/1467-9469.00115"},{"key":"rft.atitle","value":"Log Gaussian Cox Processes"},{"key":"rft.title","value":"Scandinavian Journal of Statistics"},{"key":"rft.jtitle","value":"Scandinavian Journal of Statistics"},{"key":"rft.volume","value":"25"},{"key":"rft.issue","value":"3"},{"key":"rft.date","value":"1998"},{"key":"rft.pages","value":"451 - 482"},{"key":"rft.issn","value":"1467-9469"},{"key":"rft.au","value":"Jesper M\u00f8ller,Anne Randi Syversveen,Rasmus Plenge Waagepetersen"},{"key":"rft.genre","value":"article"}],"widgetId":"rgw7_56ab9fc7d28b9"},"id":"rgw7_56ab9fc7d28b9","partials":[],"templateName":"publicliterature\/stubs\/PublicationCoins.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationCoins.html?publicationUid=227701452","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationAuthors":{"data":{"publicationUid":227701452,"peopleItems":[{"data":{"authorUrl":"researcher\/2040135095_Jesper_Moller","authorNameOnPublication":"Jesper M\u00f8ller","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg","imageSize":"s","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Jesper M\u00f8ller","profile":{"professionalInstitution":{"professionalInstitutionName":false,"professionalInstitutionUrl":null}},"professionalInstitutionName":false,"professionalInstitutionUrl":null,"url":"researcher\/2040135095_Jesper_Moller","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":true,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":false,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"widgetId":"rgw10_56ab9fc7d28b9"},"id":"rgw10_56ab9fc7d28b9","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAuthorItem.html?entityId=2040135095&imageSize=l&enableAuthorInviteButton=0","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"largeTooltip":false,"useRebrandedImageStyle":null,"widgetId":"rgw9_56ab9fc7d28b9"},"id":"rgw9_56ab9fc7d28b9","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorItem.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorItem.html?authorUid=2040135095&authorNameOnPublication=Jesper%20M%C3%B8ller","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true},{"data":{"authorNameOnPublication":"Anne Randi Syversveen","accountUrl":"profile\/Anne_Syversveen","accountKey":"Anne_Syversveen","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2671872220764\/images\/template\/default\/profile\/profile_default_m.jpg","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Anne Randi Syversveen","profile":{"professionalInstitution":{"professionalInstitutionName":"Norwegian Computing Center","professionalInstitutionUrl":"institution\/Norwegian_Computing_Center"}},"professionalInstitutionName":"Norwegian Computing Center","professionalInstitutionUrl":"institution\/Norwegian_Computing_Center","url":"profile\/Anne_Syversveen","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":false,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":true,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"accountKey":"Anne_Syversveen","hasInfoPopup":false,"hasTeaserPopup":true,"showContactAuthorButton":true,"widgetId":"rgw12_56ab9fc7d28b9"},"id":"rgw12_56ab9fc7d28b9","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAccountItem.html?entityId=1997243&enableUnfollow=0&imageSize=l&enableFollowButton=0&showContactAuthorButton=1","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"accountInstitution":"Norwegian Computing Center","score":null,"largeTooltip":false,"useRebrandedImageStyle":null,"authorCount":3,"accountCount":1,"publicationUid":227701452,"widgetId":"rgw11_56ab9fc7d28b9"},"id":"rgw11_56ab9fc7d28b9","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAccountItem.html","templateExtensions":[],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAccountItem.html?accountId=1997243&context=pubdetail_authors_xflw&showContactAuthorButton=1&authorCount=3&accountCount=1&publicationUid=227701452","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true},{"data":{"authorUrl":"researcher\/38142003_Rasmus_Plenge_Waagepetersen","authorNameOnPublication":"Rasmus Plenge Waagepetersen","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg","imageSize":"s","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Rasmus Plenge Waagepetersen","profile":{"professionalInstitution":{"professionalInstitutionName":false,"professionalInstitutionUrl":null}},"professionalInstitutionName":false,"professionalInstitutionUrl":null,"url":"researcher\/38142003_Rasmus_Plenge_Waagepetersen","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":true,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":false,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"widgetId":"rgw14_56ab9fc7d28b9"},"id":"rgw14_56ab9fc7d28b9","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAuthorItem.html?entityId=38142003&imageSize=l&enableAuthorInviteButton=0","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"largeTooltip":false,"useRebrandedImageStyle":null,"widgetId":"rgw13_56ab9fc7d28b9"},"id":"rgw13_56ab9fc7d28b9","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorItem.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorItem.html?authorUid=38142003&authorNameOnPublication=Rasmus%20Plenge%20Waagepetersen","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true}],"hasMore":false,"nextOffset":6,"useRebrandedImageStyle":null,"widgetId":"rgw8_56ab9fc7d28b9"},"id":"rgw8_56ab9fc7d28b9","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorList.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorList.html?publicationUid=227701452&context=pubdetail_authors_xflw&showContactAuthorButton=1","viewClass":"views.publicliterature.PublicationDetailAuthorListView","yuiModules":["rg.views.publicliterature.PublicationDetailAuthorListView"],"stylesheets":[],"_isYUI":true},"publicationAbstract":{"data":{"publicationUid":227701452,"abstract":"<noscript><\/noscript><div>Planar Cox processes directed by a log Gaussian intensity process are investigated in the univariate and multivariate cases. The appealing properties of such models are demonstrated theoretically as well as through data examples and simulations. In particular, the first, second and third-order properties are studied and utilized in the statistical analysis of clustered point patterns. Also empirical Bayesian inference for the underlying intensity surface is considered.<\/div>","canEdit":false,"isAdmin":false,"isArtifact":false,"showFullAbstract":false,"widgetId":"rgw15_56ab9fc7d28b9"},"id":"rgw15_56ab9fc7d28b9","partials":[],"templateName":"publicliterature\/stubs\/PublicationAbstract.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationAbstract.html?publicationUid=227701452","viewClass":"views.publicliterature.PublicationAbstractView","yuiModules":["rg.views.publicliterature.PublicationAbstractView"],"stylesheets":[],"_isYUI":true},"publicationKeywords":null,"publicationState":null,"isGuest":true,"isAdminEditingAllowed":false,"isArtifact":false,"figureListWidget":null,"previewImage":"https:\/\/i1.rgstatic.net\/publication\/227701452_Log_Gaussian_Cox_Processes\/links\/02e7e51a6f17c691d3000000\/smallpreview.png","nativeAdDisclosure":null,"showFollowPublicationButton":false,"followPublicationPromo":{"data":{"widgetId":"rgw16_56ab9fc7d28b9"},"id":"rgw16_56ab9fc7d28b9","partials":[],"templateName":"publicliterature\/stubs\/FollowPublicationPromo.html","templateExtensions":[],"attrs":{"context":null,"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.FollowPublicationPromo.html","viewClass":null,"yuiModules":["css-pow-publicliterature-FollowPublicationPromo"],"stylesheets":["pow\/publicliterature\/FollowPublicationPromo.css"],"_isYUI":true},"widgetId":"rgw5_56ab9fc7d28b9"},"id":"rgw5_56ab9fc7d28b9","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailItem.html","templateExtensions":["generalHelpers"],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailItem.html?publicationUid=227701452&showActionBar=0&showContactAuthorButton=1&showRequestFulltextExperience=0&showNoRgAuthorsRequestFulltextExperience=0&showFollowPublicationPromo=1","viewClass":"views.publicliterature.PublicationDetailItemView","yuiModules":["rg.views.publicliterature.PublicationDetailItemView"],"stylesheets":[],"_isYUI":true},"similarPublications":{"data":{"publicationListItems":[{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":2044185198,"url":"researcher\/2044185198_Paul_G_Blackwell","fullname":"Paul G. Blackwell","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2031228179,"url":"researcher\/2031228179_Mu_Niu","fullname":"Mu Niu","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2079834072,"url":"researcher\/2079834072_Mark_S_Lambert","fullname":"Mark S. Lambert","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":60023792,"url":"researcher\/60023792_Scott_D_LaPoint","fullname":"Scott D. LaPoint","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Aug 2015","journal":"Methods in Ecology and Evolution","showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/281145921_Exact_Bayesian_Inference_for_Animal_Movement_in_Continuous_Time","usePlainButton":true,"publicationUid":281145921,"feedStubs":null,"hasFeedStubs":false,"impactPoints":"6.55","url":"publication\/281145921_Exact_Bayesian_Inference_for_Animal_Movement_in_Continuous_Time","title":"Exact Bayesian Inference for Animal Movement in Continuous Time","displayTitleAsLink":true,"authors":[{"id":2044185198,"url":"researcher\/2044185198_Paul_G_Blackwell","fullname":"Paul G. Blackwell","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2031228179,"url":"researcher\/2031228179_Mu_Niu","fullname":"Mu Niu","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2079834072,"url":"researcher\/2079834072_Mark_S_Lambert","fullname":"Mark S. Lambert","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":60023792,"url":"researcher\/60023792_Scott_D_LaPoint","fullname":"Scott D. LaPoint","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["Methods in Ecology and Evolution 08\/2015;  DOI:10.1111\/2041-210X.12460"],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/281145921_Exact_Bayesian_Inference_for_Animal_Movement_in_Continuous_Time","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/281145921_Exact_Bayesian_Inference_for_Animal_Movement_in_Continuous_Time\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw18_56ab9fc7d28b9"},"id":"rgw18_56ab9fc7d28b9","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=281145921","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":2066632629,"url":"researcher\/2066632629_Kang_He","fullname":"Kang He","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":11832150,"url":"researcher\/11832150_Qingsong_Xu","fullname":"Qingsong Xu","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":31575251,"url":"researcher\/31575251_Minping_Jia","fullname":"Minping Jia","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Jul 2015","journal":"IEEE Transactions on Automation Science and Engineering","showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/280243600_Modeling_and_Predicting_Surface_Roughness_in_Hard_Turning_Using_a_Bayesian_Inference-Based_HMM-SVM_Model","usePlainButton":true,"publicationUid":280243600,"feedStubs":null,"hasFeedStubs":false,"impactPoints":"2.43","url":"publication\/280243600_Modeling_and_Predicting_Surface_Roughness_in_Hard_Turning_Using_a_Bayesian_Inference-Based_HMM-SVM_Model","title":"Modeling and Predicting Surface Roughness in Hard Turning Using a Bayesian Inference-Based HMM-SVM Model","displayTitleAsLink":true,"authors":[{"id":2066632629,"url":"researcher\/2066632629_Kang_He","fullname":"Kang He","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":11832150,"url":"researcher\/11832150_Qingsong_Xu","fullname":"Qingsong Xu","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":31575251,"url":"researcher\/31575251_Minping_Jia","fullname":"Minping Jia","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["IEEE Transactions on Automation Science and Engineering 07\/2015; 12(3):1092-1103. DOI:10.1109\/TASE.2014.2369478"],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/280243600_Modeling_and_Predicting_Surface_Roughness_in_Hard_Turning_Using_a_Bayesian_Inference-Based_HMM-SVM_Model","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/280243600_Modeling_and_Predicting_Surface_Roughness_in_Hard_Turning_Using_a_Bayesian_Inference-Based_HMM-SVM_Model\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw19_56ab9fc7d28b9"},"id":"rgw19_56ab9fc7d28b9","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=280243600","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":2051640749,"url":"researcher\/2051640749_Jiaqing_Chen","fullname":"Jiaqing Chen","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":38930418,"url":"researcher\/38930418_Yangxin_Huang","fullname":"Yangxin Huang","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Apr 2015","journal":"Statistics in Medicine","showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/275668438_A_Bayesian_mixture_of_semiparametric_mixed-effects_joint_models_for_skewed-longitudinal_and_time-to-event_data","usePlainButton":true,"publicationUid":275668438,"feedStubs":null,"hasFeedStubs":false,"impactPoints":"1.83","url":"publication\/275668438_A_Bayesian_mixture_of_semiparametric_mixed-effects_joint_models_for_skewed-longitudinal_and_time-to-event_data","title":"A Bayesian mixture of semiparametric mixed-effects joint models for skewed-longitudinal and time-to-event data","displayTitleAsLink":true,"authors":[{"id":2051640749,"url":"researcher\/2051640749_Jiaqing_Chen","fullname":"Jiaqing Chen","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":38930418,"url":"researcher\/38930418_Yangxin_Huang","fullname":"Yangxin Huang","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["Statistics in Medicine 04\/2015; 34(20). DOI:10.1002\/sim.6517"],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/275668438_A_Bayesian_mixture_of_semiparametric_mixed-effects_joint_models_for_skewed-longitudinal_and_time-to-event_data","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/275668438_A_Bayesian_mixture_of_semiparametric_mixed-effects_joint_models_for_skewed-longitudinal_and_time-to-event_data\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw20_56ab9fc7d28b9"},"id":"rgw20_56ab9fc7d28b9","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=275668438","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"viewClass":"sidebar","widgetId":"rgw17_56ab9fc7d28b9"},"id":"rgw17_56ab9fc7d28b9","partials":[],"templateName":"publicliterature\/stubs\/SimilarPublications.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.SimilarPublications.html?referencePublicationId=227701452&view=sidebar","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationFulltextPreview":null,"publicationResourcesFulltext":{"data":{"publicationUid":227701452,"publicationResourceList":{"data":{"publicationResourceItems":[{"data":{"publicationUid":227701452,"publicationType":"article","linkId":"02e7e51a6f17c691d3000000","fileName":"02e7e51a6f17c691d3000000.pdf","fileUrl":"profile\/Anne_Syversveen\/publication\/227701452_Log_Gaussian_Cox_Processes\/links\/02e7e51a6f17c691d3000000.pdf","name":"Anne Randi Syversveen","nameUrl":"profile\/Anne_Syversveen","canRemove":false,"fileIcon":"ico-pub","canPreview":true,"hasPublisherLink":null,"hasMetaData":true,"hide":false,"fulltext":"ico-pub","origin":"publication_list","isLastLink":false,"isUserLink":true,"uploadDate":"Jan 21, 2016","fileSize":"1.88 MB","widgetId":"rgw23_56ab9fc7d28b9"},"id":"rgw23_56ab9fc7d28b9","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceItem.html","templateExtensions":["generalHelpers"],"attrs":{"fileRequiredPublicationTypes":["code","coverPage","experimentFindings","method","negativeResults","presentation","rawData","researchProposal","workingPaper","artifact","dataset"]},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceItem.html?publicationUid=227701452&linkId=02e7e51a6f17c691d3000000&hide=0&disableJavascript=disableJavascript&useAlternativeTemplate=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"publicationUid":227701452,"publicationType":"article","linkId":"00048c1e0cf2ed98fb43c836","fileName":"Log Gaussian Cox Processes","fileUrl":"http:\/\/citeseerx.ist.psu.edu\/viewdoc\/download?doi=10.1.1.71.6732&amp;rep=rep1&amp;type=pdf","name":"psu.edu","nameUrl":"http:\/\/citeseerx.ist.psu.edu\/viewdoc\/download?doi=10.1.1.71.6732&amp;rep=rep1&amp;type=pdf","canRemove":false,"fileIcon":"ico-pub","canPreview":true,"hasPublisherLink":null,"hasMetaData":true,"hide":false,"fulltext":"ico-pub","origin":"publication_list","isLastLink":false,"isUserLink":false,"widgetId":"rgw24_56ab9fc7d28b9"},"id":"rgw24_56ab9fc7d28b9","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceItem.html","templateExtensions":["generalHelpers"],"attrs":{"fileRequiredPublicationTypes":["code","coverPage","experimentFindings","method","negativeResults","presentation","rawData","researchProposal","workingPaper","artifact","dataset"]},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceItem.html?publicationUid=227701452&linkId=00048c1e0cf2ed98fb43c836&hide=0&disableJavascript=disableJavascript&useAlternativeTemplate=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"widgetId":"rgw22_56ab9fc7d28b9"},"id":"rgw22_56ab9fc7d28b9","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceList.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceList.html?publicationUid=227701452&limit=3&disableJavascript=disableJavascript&type=fulltextFile","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"resourceCount":2,"hidden":false,"showMore":false,"fulltext":true,"publicationDownloadCount":{"data":{"value":341,"valueFormatted":"341","widgetId":"rgw25_56ab9fc7d28b9"},"id":"rgw25_56ab9fc7d28b9","partials":[],"templateName":"publicliterature\/stubs\/PublicationDownloadCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDownloadCount.html?publicationUid=227701452","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw21_56ab9fc7d28b9"},"id":"rgw21_56ab9fc7d28b9","partials":[],"templateName":"publicliterature\/stubs\/PublicationResources.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResources.html?publicationUid=227701452&type=fulltextFile&disableJavascript=1","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationResourcesAttachments":{"data":{"publicationUid":227701452,"publicationResourceList":{"data":{"publicationResourceItems":[],"widgetId":"rgw27_56ab9fc7d28b9"},"id":"rgw27_56ab9fc7d28b9","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceList.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceList.html?publicationUid=227701452&limit=3&disableJavascript=disableJavascript&type=attachmentFile","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"resourceCount":0,"hidden":true,"showMore":false,"fulltext":false,"publicationDownloadCount":{"data":{"value":341,"valueFormatted":"341","widgetId":"rgw28_56ab9fc7d28b9"},"id":"rgw28_56ab9fc7d28b9","partials":[],"templateName":"publicliterature\/stubs\/PublicationDownloadCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDownloadCount.html?publicationUid=227701452","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw26_56ab9fc7d28b9"},"id":"rgw26_56ab9fc7d28b9","partials":[],"templateName":"publicliterature\/stubs\/PublicationResources.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResources.html?publicationUid=227701452&type=attachmentFile","viewClass":"views.publicliterature.PublicationResourcesView","yuiModules":["rg.views.publicliterature.PublicationResourcesView"],"stylesheets":[],"_isYUI":true},"publicationText":{"data":{"hide":false,"pages":[{"page":1,"text":"Log Gaussian Cox processes\nby\nJesper M\u00f8ller,\nAnne Randi Syversveen,\nand Rasmus Plenge Waagepetersen."},{"page":2,"text":""},{"page":3,"text":"Log Gaussian Cox processes\nJESPER M\u00d8LLER\nAalborg University\nANNE RANDI SYVERSVEEN\nThe Norwegian University of Science and Technology\nRASMUS PLENGE WAAGEPETERSEN\nUniversity of Aarhus\nABSTRACT. Planar Cox processes directed by a log Gaussian intensity process\nare investigated in the univariate and multivariate cases. The appealing properties\nof such models are demonstrated theoretically as well as through data examples\nand simulations. In particular, the first, second and third-order properties are\nstudied and utilized in the statistical analysis of clustered point patterns. Also\nempirical Bayesian inference for the underlying intensity surface is considered.\nKey words: empirical Bayesian inference; ergodicity; Markov chain Monte Carlo;\nMetropolis-adjusted Langevin algorithm; multivariate Cox processes; Neyman-Scott\nprocesses; pair correlation function; parameter estimation; spatial point processes; third-\norder properties.\nAMS 1991 subject classification: Primary 60G55, 62M30. Secondary 60D05.\n1 Introduction\nCox processes provide useful and frequently applied models for aggregated spatial\npoint patterns where the aggregation is due to a stochastic environmental heterogeneity,\nsee e.g. Diggle (1983), Cressie (1993), Stoyan et al. (1995), and the references therein.\nA Cox process is \u2019doubly stochastic\u2019 as it arises as an inhomogeneous Poisson process\nwith a random intensity measure. The random intensity measure is often specified by a\nrandom intensity function or as we prefer to call it an intensity process or surface.\nThere may indeed be other sources of aggregation in a spatial point pattern than\nspatial heterogeneity. Cluster processes is a well-known class of models where clusters\nare generated by an unseen point process, cf. the references mentioned above. The class\nof nearest-neighbour Markov point processes (Baddeley and M\u00f8ller, 1989) include many\nspecific models of cluster processes (Baddeley et al., 1996) as well as other types of\nprocesses with clustering modelled by \u2018interaction functions\u2019 (M\u00f8ller, 1994) such as the\npenetrable sphere model (Widom and Rowlinson, 1970; Baddeley and Van Lieshout,\n1995) and the continuum random cluster model (M\u00f8ller, 1994; H\u00a8 aggstr\u00a8 om et al., 1996).\nIn this paper we consider log Gaussian Cox processes, i.e. Cox processes where\nthe logarithm of the intensity surface is a Gaussian process. We show that the class of\n1"},{"page":4,"text":"stationary log Gaussian Cox processes possesses various appealing properties: (i) The\ndistribution is completely characterized by the intensity and the pair correlation function\nof the Cox process. This makes parametric models easy to interpret and simple methods\nare available for parameter estimation and model checking. (ii) Theoretical properties\nare easily derived. Higher-order properties are for instance simply expressed by the\nintensity and the pair correlation function of the log Gaussian Cox process. Thereby\nsummary statistics based on e.g. the third-order properties can be constructed and\nestimated. (iii) The underlying Gaussian process and intensity surface can be predicted\nfrom a realization of a log Gaussian Cox process observed within a bounded window\nusing Bayesian methods. (vi) There is no problem with edge effects as the distribution\nof a log Gaussian Cox process restricted to a bounded subset is known.\nThe properties (i)-(vi) are rather characteristic for Log Gaussian Cox processes. We\nshall further note that log Gaussian Cox processes are flexible models for clustering,\neasy to simulate, and that the definition of univariate log Gaussian Cox processes can\nbe extended in a natural way to multivariate log Gaussian Cox processes.\nOther transformations than the exponential of the Gaussian process may be con-\nsidered as well, and in particular ??Cox processes (as defined in Section 3) may be\nof interest.\nDuring the final preparation of this paper we realized that a definition of Log\nGaussian Cox processes has previously been given in Rathbun and Cressie (1994), but\nthey restrict attention to the case where the intensity is constant within square quadrats\nand modelled by a conditional autoregression (Besag, 1974). The advantage of these\ndiscretized models is mainly that they can easily be explored using Gibbs sampling, but\nas noticed by Rathbun and Cressie (1994) such models does not converge to anything\nreasonable as the sides of the quadrats tend to zero. Consequently, it is difficult to\ninvestigate the correlation structure of these Gaussian random field models through\nthose summary statistics which are usually estimated for a point pattern such as the\npair correlation function. The log Gaussian Cox processes studied in the present paper\nare in contrast to this specified by such characteristics, and discretized versions of our\nlog Gaussian Cox processes can be simulated exactly without any problem with edge\neffects. Also the Metropolis-adjusted Langevin algorithm (Besag, 1994; Roberts and\nTweedie, 1997) for simulating from the posterior of the intensity surface as studied in\nSection 8 is both easy to specify and implement. In contrast and even if we ignore the\nproblem with edge effects, Gibbs sampling from the posterior becomes straightforward\nonly if one uses conditional autoregression priors.\nThe paper is organized as follows. In Section 2 we give a formal definition\nof univariate log Gaussian Cox processes and inspect some of their properties by\nsimulations. Theoretical results are established in Section 3. In Section 4 we compare\nlog Gaussian Cox processes with the class of Neyman-Scott processes with a Poisson\ndistributed number of offspring. Extensions of log Gaussian Cox processes to the\nmultivariate case are studied in Section 5. In Section 6 we describe different simulation\nprocedures. Section 7 is concerned with parameter estimation and model checking of\nparametric models for log Gaussian Cox processes. We illustrate this by considering\n2"},{"page":5,"text":"some data sets of univariate and bivariate point patterns. Finally, in Section 8 we\ndiscuss how empirical Bayesian methods may be used for the purpose of predicting the\nunobserved Gaussian process and intensity surface.\n2 Univariate log Gaussian Cox processes\nFor specificity and since all the examples presented later on are planar we specify\nthe model in\nBriefly, by a planar spatial point process we shall understand a locally finite random\nsubset ? of the plane\nprocess ? ? ????? ? ? ?\nprocess with intensity function ????, i.e. when for bounded Borel sets ? ?\nconditional on ? that ?????? ??? is Poisson distributed with a mean?\nhence ? is stationary and sometimes also isotropic, i.e. when the distribution of ? is\ninvariant under translations and possibly also rotations in\n?, but our model can be completely similar defined in\n?, ? ? ???????.\n?. This is said to be a Cox process directed by a random intensity\n?? if the conditional distribution of ? given ? is a Poisson\n?we have\n??????? which\nis assumed to be nonnegative and finite. We restrict attention to the case where ? and\n?. The intensity\n? ? ?????\nis henceforth assumed to be strictly positive and finite.\nThroughout this paper we model the intensity process by a log Gaussian process:\n???? ? ????? ????\n?? is a real-valued Gaussian process (i.e., the joint distribution\nof any finite vector ?? ?????????? ????? is Gaussian). It is necessary to impose conditions\non ? so that the random mean measure ? given by ???? ??\nsets ? ?\nof ? are integrable almost surely. But further conditions are required in order that ? is\nuniquely determined by the distribution of ? . Here we impose the natural condition that\n? is given in terms of a continuous modification of ? . Then ? is uniquely determined,\nsince all the continuous modifications are indistinguishable (i.e. their realizations are\nidentical with probability one), and it also follows that ???? ? ? for bounded ?.\nBy stationarity, the distribution of ? and hence ? is specified by the mean\n? ? ?? ???, the variance ??? ? ???? ????, and the correlation function ????? ??? ?\n????? ?????? ????????of ? . The model is only well-defined for positive semi-definite\ncorrelation functions, i.e. when\n??????????\nbest be answered through a spectral analysis, see e.g. Christakos (1984), Wackernagel\n(1995), and the references therein. Furthermore, if there exist ? ? ? and ? ? ? such\nthat ? ? ???? ? ???????????????for all ? with ??? ? ?, then the existence of an\nalmost surely continuous modification is quaranteed (Adler, 1981, page 60). A stronger\ncondition, which in our experience is easier to check, is given by that ?????? ???????\nfor some?? ? ? and ? ? ?.\n(1)\nwhere ? ? ?? ??? ? ? ?\n?\n?????? for bounded Borel\n?, becomes well-defined. First it is of course required that the realizations\n?\n???????????? ??? ? ? for all ????????? ?\n?, ? ? ???????. Whether a given function is positive semi-definite may\n,\n3"},{"page":6,"text":"The parameters ??? ? and ? ? ? have a clear interpretation as a scale and\nshape parameter, respectively, since we can write ????\nstationary Gaussian process with mean ?, variance ??, and correlation function ????.\nThe homogeneous Poisson process may be considered as the limit of a log Gaussian\nCox process as ? tends to 0. Another extreme case is ???? ? ?, whereby we obtain\na mixed Poisson process with a randomized intensity ???? ? ? which is log Gaussian\ndistributed.\nIf the distribution of ? is invariant under rotations, ???? ? ???????? depends only\non ? through its length ?????, so the correlation function is invariant under reflections\ntoo. Consequently, invariance under translations and rotations implies that the joint\ndistribution of ???? ? is invariant under rigid motions ? in\n???? ??\nExamples of isotropic correlation models are listed in Table 1. The condition for\nexistence of an almost surely continuous modification holds for all of these correlation\nfunctions which furthermore all tend to 0 at infinity. Notice that the correlation models\nare parametrized by a scale parameter ? so that the three types of processes (Gaussian,\nintensity, and Cox) are all parametrized by ??????? ??????????????????????.\nThe \u201cscale\u201d of the parameter ? is with respect to locations: with obvious notation,\n??????\nThe first four models in Table 1 represent well the correlation structures which can\nbe achieved by using the correlation models in this table, so we have restricted attention\nto these four models in the following Fig.\u2019s 1\u20133. In Theorem 1, Section 3, it is shown\nthat the corresponding pair correlation functions are given by the exponential to the\ncovariance function ??????. These pair correlation functions are plotted in Fig. 1 a)-d)\nfor various values of ? when ? ? ?. If one \u2019standardizes\u2019 the pair correlation function\n???? to ???? ? ? or equivalently takes ? ? ?, plots of corresponding pair correlation\nand covariance functions look very similar, cf. Fig. 1, a)-b) and g)-h).\nSimulated realizations of Gaussian processes on the unit square with correlation\nstructure given by the four different types of correlation functions are shown in Fig.\n2. Fig. 3 shows simulations of the corresponding log Gaussian Cox processes. The\nparameters in the first row in Fig. 3 are the same as in Fig. 2. In order to facilitate\ncomparison of the four different Cox processes the ?-values in Fig. 3 are chosen so\nthat the mean and variance of the number of points are equal for all Cox processes\nin the same row. By Theorem 1, Section 3, the mean is ? ? ????? ? ????? and the\nvariance is given by\n?? ????\n???, where ?????? is a\n?: ??????? ???????\n??\n??\n???????????????? ? ?\n??.\n? ??\n?\n????\n?\n? ? ????????\n? ? ? ??\n?\n?\n?\n?\n??????\n?\n??????\n????????????? ? ?\n?\n??\n?\nThe variance thus increases when ? and hence the correlation increases. It is difficult to\ncompare unconditional simulations when the variance of the number of points is large\nand the simulations in Fig.\u2019s 2 and 3 are therefore performed conditional on that the\nnumber ? of points equals the mean number of points (? ? ? ? ???).\n4"},{"page":7,"text":"In the upper row in Fig. 3 a moderate value of ? but large values of ? give rise\nto large but not dense clusters of points. In the lower row moderate values of ? but a\nhigher value of ? lead to many but small clusters. In the middle row a high value of ?\nand intermediate values of ? are used, and compared to the lowest row fewer but larger\nclusters appear. The realizations of the \u2018Gaussian\u2019 and \u2018cardinal sine\u2019 log Gaussian Cox\nprocesses are visually quite similar. The \u2018stable\u2019 log Gaussian Cox process is in general\nless clustered than the other processes. This is not surprising because the Gaussian\nrandom field with the stable correlation function is not very peaked except at the small\nscale, c.f. Fig. 2.\nFinally, it should be noted that Cox processes may be extended to models on\nbounded regions ? ?\n?? ? ????? ? ? ? ?? is of a Gibbsian type. For instance, consider a conditional\ndistribution of ?? given ?? ? ?? with density\n??\n???\n?, where the conditional distribution of ??? ? ? ? given\n???????? ? ?????\n?\n?????\n??\n?\n?\n?\n???????\n??????? ?????\n?\n?\n?\nwith respect to a unit rate Poisson point process and for ?? ? ??????????? ? ?,\nwhere e.g. ?? models the large scale properties and the function ???? ? ? specifies\npairwise interactions terms at the small scale. Although the marginal distribution of ?\nrestricted to ? becomes analytically intractable, such models may at least be simulated\nand statistical inference may be performed by Markov chain Monte Carlo methods.\n3 Theoretical results\nTheoretical properties of Cox processes have been extensively studied, see e.g.\nGrandell (1976), Daley and Vere-Jones (1988), and Karr (1991). In this section we\nestablish further results for log Gaussian Cox processes. In particular, we discuss the\nfirst, second and third-order properties of a univariate log Gaussian Cox process. As\nin the previous section we consider the planar case, but many of the presented results\nhold as well in\nThe most useful characteristics for our purpose are the nth order product densities\n????? ? ? ???????, for the reduced moment measures of the Cox process ?. These are\ngiven by the moments of the intensity process as\n?, ? ? ?????? (with obvious modifications in a few places).\n??????????????? ? ?\n?\n?\n?\n?????\nfor pairwise different ??????????\nis the probability that ? has a point in each of ? infinitesimally small disjoint regions\nof volumes ???????????.\n?. Intuitively speaking ????????????????????????\n5"},{"page":8,"text":"Theorem 1. A log Gaussian Cox process ? is stationary if and only if the corresponding\nGaussian field ? is stationary. For a stationary log Gaussian Cox process we have\n?\n??????????????? ? ???\n?\n??? ? ??\n?\n?\n??\n??\n?\n???????\n????? ???\n?\n?\n?\n?\n?\n? ??\n???????\n????? ???\n(2)\nwhere\n? ? ??????? ? ????? ? ?????\n????? ??? ? ??????????????? ??????????? ????\nare the intensity and the pair correlation function of the process, respectively.\n(3)\nand\n(4)\nProof.\ntribution ?????? with mean ? and variance ?.\n??\nHence, by (1), ??????????????? ? ???????\n?????????????????????????????? are in particular given by ??????? ? ???????? ? ??????\nand ???????? ? ???????????????????????? whereby (2)-(4) follow when ? is stationary.\nIf ? is stationary then ??????? ? ?? and we can write ???????? ? ????? ???.\nBy letting ?? ? ?? it follows that ????? ? ??? ???? is constant, and further that\n???? ? ? ? ?????? ? ???? and ???????? ? ????? ??? ? ????????? ???????, whereby\n? is stationary. Finally, by definition of a log Gaussian Cox process, stationarity of ?\nimplies stationarity of ?.\nLet ???? ? ????? ? ?????? be the Laplace transform of the normal dis-\nLet ? ?\n??\n?? ???? ? ??????.\n?????? and ? ?\n??? ????, ?????\n??????? ? ??\n????????????????????????? where ????\n? ???? ????? and ?????? is the correlation function of ? . Then??\nfirst order product density ??????? and the pair correlation function ???????? ?\n??\n?? ????? ? ????? ? ????.The\nTheorem 1 reflects the fact that the distribution of a log Gaussian Cox process is\ncompletely determined by ?????????? or equivalently by ???????? (since ???? ? ?). It\nfollows from (4) and the definition of a log Gaussian Cox process that it is isotropic if and\nonly if the underlying Gaussian process is isotropic or equivalently when ???? ? ????????.\nEspecially, when ???? ? ? is a log Gaussian random variable we have a mixed Poisson\nprocess with ???? ? ? and ???? ? ???? ?, whilst for a homogeneous Poisson process\n???? ? ? and ???? ? ?.\nSimilar results may be established for other intensity processes being a function of\na Gaussian process. Suppose e.g. for the moment that ? ? ? and ???? ? ? ????is\n????-distributed with ? degrees of freedom. Then the intensity of the \u2019??Cox process\u2019\nis ??? ? ??and the pair correlation function becomes\n?????? ? ? ? ???????\n6"},{"page":9,"text":"Hence there is not a one-to-one correspondence between ????????? and ????????????\nunless the sign of the correlation function is known.\nIn the statistical analysis of point processes mostly first and second-order properties\nare investigated (see Section 7), but we shall also explore the following correspondence\nbetween the second and third-order properties: For any stationary simple point process\n? with finite intensity ? ? ? and well-defined pair correlation function ???????? ?\n????? ??? ? ? and third-order density ?????????????? ? ???????? ?????? ??? define\n?\n????\n???????\nThis has an interpretation as a third-order summary statistic, since\n???? ?\n?\n?\n???????\n?????????\n????????????? ? ??????? ? ? ??\n(5)\n?????????? ? ??\n?\n??\n?\n?????????????????????\n?????????????? ? ???\nwhere ?? means that the summation is over pairwise distinct points, and where the\nexpectation is with respect to the reduced Palm distribution at the origin (heuristically\nthis means that we have conditioned on that there is a point at the origin and ? denotes\nthe collection of the remaining points, cf. e.g. Stoyan et al., 1995). By Theorem 1,\n???? ? ? ? ? ? ?? for a log Gaussian Cox process. (6)\nThis can be used to check our model assumptions as demonstrated in Section 7.\nIn the case of rotation invariance we propose an unbiased estimator which uses all\ntriplets of observed points and which takes care of edge effects as follows. For a given\n\u2019window\u2019 ? ?\n?????????? ?? ? ?????????? ???????????? ? ??\n??? ??????? ? ???????? ? ??? ? ??\nand define the \u2019edge correction\u2019\n?????????? ?????????? ?? ?????????\ntaking ???? ? ?. Then for given ??? ?? ? and ?, ???????????is the proportion of\ntriangles which can be observed within ? with vertices ???????? ? ? such that\n????? ???? ? ?, ????? ???? ? ?, and ? is the angle (anticlockwise) between the vectors\n??? ?? and ??? ??.\n?and ??? ?, ? ? ?, ? ? ?, ? ? ? ? ??, let\n?\nTheorem 2. Let ??????????? denote the angle (anticlockwise) between ??? ??and\n?????. For any stationary simple point process ? as considered above, assuming that\nthe distribution of ? is invariant under rotations about the origin,\n?\n?\n??????\n??\n?\n?????????????????\n???????????? ???????????\n???????????????????????????????????\n??????? ???????????? ???????????? ?????\n(7)\n7"},{"page":10,"text":"is an unbiased estimator of ?????????????? for all ? ? ??, where ???? is the area\nof ? and\n?\n?\nProof. Note that factor ? in (7) appears because the second summation is over unordered\npairs of distinct points. Then ???????? ?????? ??? ? ????\nbecause of the rotation invariance. Moreover, ????? ???? ? ???????? is a function of\n??????? ? ????????????????????????????????? only. Hence, using that the correction\nfactor ? is the same for ?????????? as for ?????????? together with the fact that\n??? ???\n?\n?\n?\n? ? ??\n?\n????\n?\n???????\n?\n???????\n?\n????????\n???????????? ???????????? ?\n?\n?\n?\n?\n?\n?\n???????? for a function ????\n?\n?\n??\n?\n??????????\n??????????? ?\n? ? ?\n??????????????????????????????????\nfor nonnegative measurable functions ?, we find that the mean of (7) equals\n?\n??\n?\n????????????????????????? ???????????\n?\n???\n?\n????\n?\n????\n?\n???????\nwhere we have used that ? ? ??to obtain the third equality. This combined with (5)\ngives the result.\n???????????????????????????????????\n??????? ???????????? ???????????? ?????\n?\n??\n????\n?????????????????\n?????????????????????? ? ? ? ??? ? ? ? ???????????\n?\n?\n?\n???????\n?\n?\n?\n???????\n?\n?\n????????\n?\n???????????\n?\n????????\n?????????\n??????????? ? ??????\n????\n?????????????????\n????????????????????????????????\n?\n??????????????????????\n????\n????????\n????????????????????????????????\n? ????\n???????\nThe estimator (7) is of the same spirit as Ripley\u2019s (1977) estimator for the second\norder reduced moment measure. In fact ?????????agrees with Ripley\u2019s edge correction\nfactor when ? ? ? and ? ? ?. Our edge correction factor is of course also applicable\nfor other third order summary statistics than ?.\nApplications of ? and its estimator are discussed at the end of Section 4 and in\nSection 7, Example 1. In most applications ? will be convex in which case ??? ????,\nthe radius of the maximal inner ball contained in ?. We have also considered a naive\n8"},{"page":11,"text":"estimator based on \u2019minus sampling\u2019 and which do not presume rotation invariance,\nviz. the unbiased estimator of ???????????????? given by\n??\n?\n??????????? ??????? ???? ???\n?????? ???????? ???????? ??????\nwith\n?????? ? ? ? ?? ?\n?? ????? ? ? ? ? ? ? ? ???\nCompared to (7) the variation of this estimator can be very large since not all triplets\nof points in ? ?? are used. Another problem may be caused by a clustering of points\nso that no points are observed within ???for even moderate values of ?.\nFinally, we establish some simple results about ergodicity. Ergodicity may for\ninstance become useful for establishing consistency of nonparametric estimators of ?\nand ????. The log Gaussian Cox processes corresponding to the correlation models in\nTable 1 are all ergodic as shown in part (b) of Theorem 3 below.\nTheorem 3.\nprocess, let ? ?\n?\nintensity function ???????? ? ? ?\nthat the realizations of ? are continuous with probability one and that ? is strictly\nmonotone, ergodicity of the Cox process implies that ? is ergodic.\n(b) If ? is a stationary Gaussian process where the correlations decay to zero, i.e.\nwhen\n???? ? ? ?? ????? ? ?\nthen the corresponding log Gaussian Cox process is ergodic. Especially, a stationary\nlog Gaussian Cox process is ergodic if\n(a) Let ? ? ????? ? ? ?\n? ????? be measurable, and suppose that with probability one\n????????? ? ? for bounded Borel sets ? ?\n?? is ergodic if ? is ergodic. Conversely, assuming\n?? be a stationary real-valued stochastic\n?\n?. Then a Cox process with random\n(8)\n???? ? ? ?? ????? ? ??\n(9)\nProof. We first need some measure theoretical details. Let ? ?\nof functions ? ?\nequipped with the ?-field ?? generated by the projections\n??? ? ?\nof locally finite measures defined on the Borel ?-field ??in\nis generated by the projections ? ?? ? ? ?\nFurthermore, let ? ? ? ? ? be defined by\n?\n?\n?denote the space\n??\n?? where ????? ? ????. Further, let ????? be the measure space\n? ? ?\n?where the ?-field ?\n, ? ? ??, given by ? ????? ? ????.\n??????? ?\n?????????? ? ? ???\nIt is not difficult to show that for any fixed ? ? ??, the function ??? ? ?\nby ????? ? ? ???????? is measurable. Hence ? is measurable and so ? ? ???? is\na random measure.\ngiven\n9"},{"page":12,"text":"Now, consider a stationary Cox process as in (a). This is ergodic if and only if the\nrandom measure ? is ergodic, cf. e.g. Proposition 10.3.VII in Daley and Vere-Jones\n(1988). Ergodicity of ? means that ??? ? ?? ? ????? for all events ? ? ? which\nare invariant under translations in the plane (? is invariant if ? ? ? ???? ? for all\n? ?\n??? ? ?? ? ????? for all events ? ? ?? which are invariant under translations in the\nplane (i.e. ? is invariant if ? ? ? ???? ? for all ? ?\nUsing these definitions it is straightforward to show the first implication in (a).\nAssuming that ? is strictly monotone, then ? restricted to ?? ? ?? ? ? ?\n? continuous? becomes injective. Assume further that ? ? ?? is invariant and ?\nis ergodic. Then it follows that ???? is invariant so that ??? ? ?????????? ? ?????.\nUnder the additional assumption that realizations of ? are continuous a.s., it is no\nrestriction to assume that ? ? ??. Then, since ? is injective on ??, ??????????? ?\n? ? ??whereby ??? ? ?? ? ?????, and the second implication in (a) is proved.\nAccording to (a) a stationary log Gaussian Cox process is ergodic if the underlying\nGaussian process is ergodic. But ergodicity of the Gaussian process is in fact implied\nby (8), cf. Theorem 6.5.4 in Adler (1981). Using (4) we get the equivalence between\n(8) and (9). This completes the proof.\n?where ????? ? ???? ? ? ? ? ? ???). Similarly, ergodicity of ? means that\n?where ????? ? ??? ? ??).\nConditions for continuity of random fields may be found in Adler (1981) or Ledoux\n& Talagrand (1991). Notice that (8) and (9) are equivalent and that (9) implies ergodicity\nalso for a ??Cox process.\n4 Comparison with Neyman-Scott processes\nWe shall now compare our log Gaussian Cox processes with a popular and frequently\nused class of models which are simultaneously Poisson cluster and Cox processes,\nnamely those Neyman-Scott processes where the number of points per cluster is Poisson\ndistributed (see e.g. Bartlett, 1964; Diggle, 1983; Stoyan and Stoyan, 1994; Stoyan et\nal., 1995).\nImagine a point process ?????\nneous Poisson point process of intensity ? ? ?, and which generate clusters of offspring\n???\n? ? ? and the relative positions ??? of offspring are iid with density ?. Further, the\n????, ????, and ????? are mutually independent. The Poisson cluster process of offspring\n?????\n?\nThe product densities of such Neyman-Scott processes are known: We have that\n? ? ??,\n?\n?of (unobserved) parents which form a homoge-\n??????? ????. The counts ??are assumed to be iid Poisson distributed with mean\n??????????? is then stochastic equivalent to a Cox process with intensity process\n???? ? ?\n?\n??? ? ????\n(10)\n???? ? ? ??\n?\n??????? ? ????\n10"},{"page":13,"text":"?????????????? ? ????? ??? ? ????? ??? ? ????? ??? ? ?\n?\nand with similar but longer expressions for ????? ? ? ?. The higher-order product\ndensities of a log Gaussian Cox process as given by Theorem 1 are in general of a\ndifferent and much simpler form than for Neyman-Scott processes.\nIn the following we consider some particular but widely used models of Neyman-\nScott processes, viz. a Mat\u00b4 ern (1960) cluster process and a (modified) Thomas (1949)\nprocess (Bartlett, 1964). For the Thomas process, ? is the density of a radially symmetric\nNormal distribution with variance ? ? ?, and the pair correlation function becomes\n?\n?\n??\n??? ? ?????? ? ?????? ? ?????\n????? ? ? ?\n?\n???????\n?\n???\n??\n?\n? ? ? ??\nFor the Mat\u00b4 ern cluster process, ? is the density for a uniform distribution on a disc with\nradius ? ? ? centered at ?, and the pair correlation function becomes\n?\n?\n????? ?\n? ?\n?\n?????\n?\n??????\n?\n???\n?\n??\n?\n? ?\n??\n???\n?\n? ? ? ? ? ??\n? ? ? ???\nIn Fig. 1 we have included plots of the pair correlation functions for Thomas and\nMat\u00b4 ern cluster processes. For comparison we have taken ????? ? ????? ? ?. Then for\nthe Thomas process ? ? ???????????? is determined by the value of ?, whilst for the\nMat\u00b4 ern cluster process ? is determined by the value of ?. At least for certain values\nof ? and ? the Gaussian pair correlation function and ????? appear to be very similar,\nwhereas ????? looks different from the other pair correlation functions in Fig. 1. For\ninstance, by taking ? ? ???? and minimizing????\nthe logarithm of these pair correlation functions for the Thomas and the log Gaussian\nCox process with Gaussian correlation function are nearly identical.\nThis may suggest that ????? ? ???????? could be considered as a covariance function.\nOne way to check this is through the Hankel transform of ????? given by\n?\n?\n?\n?\n????? ? ????????? with respect to ?,\nwhere ??????? ? ????????????, we get ? ? ???????. The left plot in Fig. 4 shows that\n????? ?\n?\n??\n??????????????\nwhere\n????? ?\n?\n?\n???\n?????\n???\n????????\nis the Bessel function of first kind and order zero. Then ????? is positive semi-definite if\nand only if ????? ? ? for all ? ? ?, cf. e.g. Christakos (1984). The Hankel transforms\n??and ??for the Thomas and Mat\u00b4 ern cluster processes given in Fig. 4 show that\n11"},{"page":14,"text":"neither of the two Neyman-Scott processes can be considered as log Gaussian Cox\nprocesses. But the close agreement with respect to the pair correlation functions and\nthe remarks below and at the end of this section suggest that certain Thomas processes\nmay in practice be difficult to distinguish from log Gaussian Cox processes with a\nGaussian correlation function.\nFig. 5 shows simulated distribution functions ? and ? for the distance to the nearest\npoint of a point process ? with respect to ? and a typical point of ?, respectively\n(see e.g.Diggle, 1983).Here we consider two kinds of point processes: a log\nGaussian Cox process (the solid lines in Fig. 5) with a Gaussian correlation function\nand ? ? ?????? ? ? ?, i.e. ? ? ??, and correspondingly a Thomas process with\n? ? ??????? ? ???? and ? ? ??? (dotted lines); as before ? ? ???? and ? ? ???????.\nFor each model we simulated 100 realizations and calculated the average and the\nupper and lower envelopes for nonparametric estimates of ? and ?. (The upper and\nlower envelopes for ?, ? or any another summary statistic depending only on the\ndistance are here and elsewhere in the following given by the maximum and minimum\nvalues obtained from the simulations at each distance; see e.g. Diggle, 1983.) The\naverages are then estimates of the theoretical ? and ? functions. Further simulations\nconfirmed that the envelopes of ? for the Thomas process lie beneath those for the log\nGaussian Cox process, while the opposite statement holds for the envelopes of ?. We\nrecognized further that the ? function distinguishes better between the two processes\nthan the ? function, but also that none of these summary statistics are really useful\nfor discriminating between the two models. Another experiment confirmed that it may\nalso be difficult to distinguish between the two models by means of the third-order\ncharacteristic ? in (5).\nIn Section 7 plots of ?, ?, and ? raise doubt of the appropiateness of the Mat\u00b4 ern\ncluster process as a model for the data in Example 1, but give no reason to question\nthe use of a log Gaussian Cox process with an exponential correlation function.\n5 Multivariate log Gaussian Cox processes\nOur model can immediately be extended to the case of multivariate Cox processes\nas follows.\nLet us for simplicity just consider the bivariate case of a Cox process ? ?\n??????? directed by random intensity processes ?? ? ?????? ? ?????????? ? ? ?\n??? ? ? ???, where ? ? ?????????????? ? ? ?\nand possibly isotropic Gaussian process with mean ??????? and covariance functions\n?????? ? ?????????????????? for ? ? ????? ????? ??? ? ??? (in the isotropic case we\nhave that ?????? ? ??????). Then conditional on ? , ??and ??are independent Poisson\nprocesses with intensity functions ?? and ??, respectively. The covariance function\nmatrix of the multivariate Gaussian process must be positive semi-definite. Restricting\nattention to absolutely integrable and isotropic covariance functions, this is equivalent\nto that\n?? is a bivariate stationary\n?????? ? ?? ?????? ? ?? and ?????????? ???????????? ? ? ? ?\n(11)\n12"},{"page":15,"text":"where\n?????? ?\n?\n??\n?\n?\n?\n???????????????\nis the spectral density or Hankel transform of ??? (Yaglom, 1986; Christakos, 1992;\nWackernagel, 1995). Moreover, many of the results presented in Section 3 may easily\nbe extended to the multivariate case. For example, by Theorem 1 the intensity and pair\ncorrelation function of ?? become\n??? ??????? ????????? ? ?????? ? ???????????\nand the mixed pair correlation function is given by\n(12)\n?????? ? ?????????????????????? ? ??????????? ? ? ? ????? ?????\nEspecially, if we consider affine transformations ????? ? ??\nindependent one-dimensional Gaussian processes ??? ?????? ? ? ?\neach with mean 0, variance 1, and a positive semi-definite correlation function ??, then\nof course ? is well-defined and\n(13)\n????????? ? ?? of ?\n??? ? ? ???????,\n?????? ?\n?\n?\n???\n??\n??????? ? ? ? ??? ? ?????? ?\n?\n?\n???\n??????????? ? ? ?\n?\n(14)\n(in this case ?????? ? ?????? no matter if isotropy is required or not). For example,\nif ?? ? ??? ? ??? ? ? ???, where ? is a stationary Gaussian process with mean 0,\nvariance 1, and correlation function ????, then the sign of ???????? determines whether\nthere is a positive or negative dependence structure between the two types of patterns\n??and ??. In the special case ??? ??we have a linked Cox process (Diggle and\nMilne, 1983) as ??????? ? ???????. Fig. 6 shows realizations on the square under the\nexponential model ???? ? ????????? with ??? ??? ??? and for each of ??? ??? ?\nand ??? ??? ? ?. The different dependence structures are clearly expressed in the\nsimulations.\n6 Simulation algorithms\nSome properties of Cox processes are hard to evaluate analytically. Fortunately,\nlog Gaussian Cox processes are easy to simulate so that Monte Carlo methods can be\napplied. An advantage of log Gaussian Cox processes is that there are no boundary\neffects since all marginal distributions of a Gaussian field are known.\nIn practice we represent the finite domain of simulation by a grid and approximate\nthe Gaussian process by the values of the corresponding finite dimensional Gaussian\ndistribution on the grid. If we for example wish to simulate a log Gaussian Cox process\non the unit square, we approximate the Gaussian process\n???? ??????????????????????????????????????? by its value????? ? ??????? at\nthe center ????? of ???where ????? ? ? ? ??????????? ?????????????? ????? ?\n?? ????\n????????on each cell\n13"},{"page":16,"text":"????????? and ? is a suitable value for the discretization. Thus, simulations of the\nfield?? ? ?????????????are required. For ease of presentation we shall here mainly focus\non univariate log Gaussian Cox processes where the discretization is given by a square\nlattice ?; at the end of Subsection 6.1 we consider briefly the case of a multivariate log\nGaussian Cox process and a rectangular lattice.\nIf the Cox process is moderately clustered and the intensity moderate, the very fine\nscale properties of the Gaussian field are probably not so important and a rather coarse\ndiscretization can be used. The choice of discretization also depends on the smoothness\nof the realizations of the Gaussian field, see Fig. 2. The error due to discretization is e.g.\nlikely to be small when the Gaussian correlation function is used. For the simulations\npresented in this paper we found it sufficient to use either ?? ? ?? or ??? ? ??? grids.\nSimulation of a log Gaussian Cox process involves two steps. First the Gaussian\nfield is simulated and secondly, given the Gaussian field?? ? ?? ???????????, the inhomoge-\nneous Poisson process can be simulated: either within each cell ???where the Poisson\nprocess is homogeneous with intensity????? ????? ????, or by thinning a homogeneous\nPoisson process with intensity?????? ?????????so that a Poisson point situated in the\n??th cell is retained with probability??????????.\nThere are several methods available for simulation of a Gaussian random field, see\ne.g. Lantu\u00b4 ejoul (1994). The simulation method based on Cholesky decomposition of\nthe covariance matrix is too slow even for moderate grid sizes. We used another method\nbased on decomposition of the covariance matrix (see Subsection 6.1) or alternatively the\nturning bands method (Matheron, 1973). In Subsection 6.2 we describe how simulations\nconditional on the number of points can be obtained. Finally, in Subsection 6.3 we\nbriefly discuss how the Thomas and Mat\u00b4 ern cluster processes studied in Section 4 are\nsimulated.\n6.1 Simulation using diagonalization by the two-dimensional discrete Fourier\ntransform:\nA detailed description of this method in the univariate case and any lattice\ndimension ? ? ??????? assuming only stationarity can be found in Wood and Chan\n(1994). Below we summarize this for the two-dimensional case (the notation and the\nresults are also used in Sections 7 and 8). For simplicity we assume isotropy.\nSuppose that an isotropic covariance function ? ?\nwish to simulate a Gaussian field?? ? ?????????????with covariance matrix ? ?\n?????????????????????? ?????????????????????????????????(here we use a lexicographic ordering\nof the indices ??). Note that ? is block Toeplitz and block symmetric. Extend the lattice\n? to ????? ????????????????????????????????????????????wrapped on a\ntorus. Let ???? ?????????????????????????, ????? ? ????? and let ?????????????? ?\n?\nsymmetric matrix ? ? ????????????????????????defined by ?????? ? ????????????????? is\nblock circulant with ??? ? ?? circulant blocks of dimension ??? ? ?? ? ??? ? ??.\nHence, by Theorem 5.8.1 in Davis (1979),\n? ???????????????????\n14\n??\nis given and we\n??\n??? ??\n??denote the shortest distance on the torus between ????? and ?????. The\n??????????? ???????\n?\n(15)"},{"page":17,"text":"where ???????? ???????is unitary and ? ? ????????? ????? ? ????? is a diagonal\nmatrix of the eigenvalues for ?. Here ???????? ????? ? ????????????????? ?\n\u2018?\u2019 denotes complex conjugate, and ? is the Kronecker product.\nNow, suppose that ? is positive semi-definite (i.e. ? has nonnegative eigenvalues).\nThen we can extend?? to a Gaussian field?????? ????????????????with covariance matrix\n?. Using the above decomposition of ? we find that\n???????????????is the (normalized) ????????????? discrete Fourier transform matrix,\n?????\n?? ????????????????????????\n?\nwhere ? ? ??????? follows a ?-dimensional standard normal distribution with ? equal\nto the rank of ?, ? is a diagonal matrix given by the non-zero eigenvalues of ?, and\n? is a certain ? ? ???? ? ????complex matrix of rank ?. If ? ? ? is a power of two\n(or three or five), the calculation of?????is only a ?????? ? ????????????? ? ??????\noperation as the two-dimensional fast Fourier transform (see e.g. Press et al., 1988) can\nbe applied. Thereby a fast simulation algorithm is obtained.\nNotice that the extension of the lattice ????????????????????????? ????? ?\n????????to ??????????? ? ??????????????? ? ?? ? ???? ? ????????is the\nminimal extension which gives a block circulant matrix ?. If ? turns out not to be\npositive semi-definite, it may help to use a larger extension (see Wood and Chan, 1994).\nAlso, if ? ?? is not a power of two (or three or five), a larger extension can be applied\nin order to use the two-dimensional fast Fourier transform.\nThe algorithm can straightforwardly be generalized to the case of a multivariate\nGaussian field?? ? ????????????????????????, where ? is a ? ? ? rectangular lattice\nand ? ? ?. In this case ? becomes a ??? ? ???? ? ??? ? ??? ? ???? ? ??? block\ncirculant matrix given by ??? ? ?? blocks, which in turn are block circulants and of\ndimension ??? ? ??? ? ??? ? ???. By combining (5.6.3), Theorem 5.6.4, and (3.2.2)\nin Davis (1979) one obtains that\n? ???????????????????????\nwhere ? is a block diagonal matrix with ??? ? ???? ? ?? blocks of dimension\n? ? ?. In the bivariate case, simulation of?? thus amounts to a linear transformation\nof ??? ? ???? ? ?? independent two dimensional Gaussian vectors.\nThe method is fast and practically applicable. Problems with nonpositive semi-\ndefiniteness of ? occurred very seldom, and were then due to slowly decaying corre-\nlation functions like the stable correlation function (see Figure 1).\n??????????? ???????? ??\n?\n6.2 Conditional simulation:\ndistribution of ? ? ??????given that ???? ? ?????? ? ??????? ? ? for ? ?\nwe need first to simulate a realization ? ? from?? ????? ? ? and secondly simulate\nfrom ?????? ? ???? ? ? ?. The last step is performed by distributing ? independent\npoints in the ??grid cells, where a cell ???is chosen with a probability proportional\nto????? ????? ????? ????? ? ?, and the point subsequently placed at a uniformly sampled\nIt may sometimes be desired to simulate the conditional\n. Then\n15"},{"page":18,"text":"location in the chosen cell. Rejection sampling (see e.g. Ripley, 1987) is used for\nthe simulation of?? ????? ? ? as follows. For the conditional density of?? given\n???? ? ? we have that\n??? ? ? ?? ? ??? ? ? ????? ?? ???\n???????? ???\nThe rejection sampling can thus be performed by generating realizations of?? until a\nrealization ? ? is accepted with probability????????????, where?? ?\nConsidered?? as a random variable, the mean of?? approximates the intensity ? of\n?. Thus the acceptance rates are reasonably high if ? is close to ? and the variance\nof?? moderate.\n????\n???\n????\n???\n???????.\n6.3 Simulation of the Thomas and Mat\u00b4 ern cluster processes:\nulation of the Thomas and Mat\u00b4 ern cluster processes on a bounded region ? follow\nstraightforwardly from the definitions of these processes as Poisson cluster processes,\nsee Section 4. In order to avoid boundary effects the parent process is simulated on an\nextended area ? containing ?. The area ? is chosen so that offspring from a parent\noutside ? falls into ? with a negligible probability. An approximate procedure for sim-\nulation conditional on the number of points can be obtained by using that the Thomas\nand Mat\u00b4 ern processes are Cox processes with intensity surface given by (10) and then\nproceed as described in Subsection 6.2 above.\nProcedures for sim-\n7 Parameter estimation and model checking\nFor simplicity we first restrict attention to the univariate case, but our methods for\nestimation and model checking can also be used in the multivariate case, see Example\n2 at the end of this section.\nSuppose we have observed a point pattern ? ? ??????????? within a bounded\nplanar window ? of area ????. Under a homogeneous log Gaussian Cox model with\na correlation function ????? the density of ??? ? ? ? with respect to a planar unit\nPoisson process is\n?\n?\nExcept for very special models this likelihood is analytically intractable.\nConsidering this as a \u2018missing data problem\u2019 the likelihood can be approximated by\ndiscretizing ? as described in Section 6 and making importance sampling as follows:\nThe density of the Gaussian field?? is proportional to\n?\n???????? ? ??????\n????\n?\n?\n?\n?\n?? ? ????? ???????\n?\n?\n?\n?\n?\n?\n????? ?????\n?\n??\n???? ?? ? ???\n?\n?\n????? ? ? ? ?????????? ? ? ? ???\n?\n16"},{"page":19,"text":"where ? ? ???????, ???? is the correlation matrix (here assumed to be positive definite),\nand ? denotes transposition. For a given fixed parameter ??? ?????????? suppose that\n? ????????? ? ????is a sample from the distribution of?? and ? ???????????? ? ??????? is a\nsample from the conditional distribution of?? given ??? ? (Section 8 describes how\nthe latter sample can be generated). Since the conditional distribution of ??given??\ndoes not depend on ?, it is easily seen from the results in Gelfand and Carlin (1991)\nand Geyer (1994) that the Monte Carlo approximation of the log likelihood is\n?\n???\n???? ? ????? ? ????\n?\n?\n?\n???\n??\n? ???????\n?? ???????? ? ????\n?\n?\n?\n?\n???\n??\n?\n? ?????\n???\n?? ????? ?\nActually we may replace?? with the extended Gaussian field?????(see Section 6.1) for\nwhich it is easier to invert the correlation matrix. We have no experience about how this\nwould work in practice, but we expect that multimodality of the likelihood may cause\nproblems for finding the (approximate) maximum likelihood estimate. Since only the\nGaussian density (up to scale) appears in the approximation of the log likelihood, there\nmay be some analog here to Ripley\u2019s (1988) discussion on the difficulties associated\nwith likelihood analysis for spatial Gaussian processes.\nPseudo-likelihood (Besag 1977; Jensen and M\u00f8ller, 1991) is not useful since a\nclosed expression of the density is not known even not up to multiplication with a\npositive constant (so a closed expression of the socalled Papangelou conditional intensity\nis not known). For the same reason we also doubt the usefulness of the more general\nmethod of Takacs-Fiksel estimation (see e.g. Ripley, 1988, and the references therein).\nSince the distribution of a log Gaussian Cox process is completely determined\nby its first and second order properties we suggest instead to base the inference on\ncorresponding summary statistics as described in the following.\nAs a natural estimate of the intensity we shall use\n? ? ? ???????\n(16)\nThis estimator is unbiased. If ????? ? ? as ? ? ?, then the ergodicity implies that\n? ? ? ? almost surely as ? extends to\nThe parameters ??? ? and ? ? ? are estimated by a minimum contrast method:\nAssume henceforth that the correlation function is isotropic. Let ? ???? denote a nonpara-\nmetric estimate of the covariance function. Then ? ??and?? are chosen to minimize\n?, cf. Theorem 3.\n??\n?\n?\n?\n? ????????????????????\n(17)\nwhere ? ? ? ? ??and ? ? ? are user specified parameters; in Examples 1 and 2 we\ntake ? ? ???\nThese parameters must of course be chosen so that the terms in (17) are well-defined.\n????????? ????, while ??and ? are determined by the form of ? ???? and ?????.\n17"},{"page":20,"text":"For fixed ? the minimum of (17) is obtained at\n? ??\n?? ??????????????with ???? ?\n??\n?\n?\n?? ????????????? ? ???? ?\n??\n?\n?\n?????????\nprovided ???? ? ?; otherwise there exists no minimum. Inserting this into (17) and\nusing that ? ? ????? ? ????? give the estimates\n?? ? ???????????????? ? ? ??? ? ??\n??? ? ? ? ????? ?? ? ? ?????\n(18)\nDiggle (1983) describes a similar estimation procedure using the ?-function\n???? ? ??\n? ?\n?\n??????? ? ? ? ?\ninstead of the covariance function, but for the data considered later on we found that\nthere may be many local minima, and it may be difficult to find a global minimum.\nThe procedure in (18) is computationally much simpler; we need only to maximize\nwith respect to ?, whereas Diggle\u2019s procedure involves ??as well. In our examples\nthe function ?????????? turned out to be unimodal.\nAs the nonparametric estimate of the covariance function we have used ? ???? ?\n???? ???? with\n?\n???? ??????\n?\n????\n? ???? ?\n?\n?\n???? ? ????? ????????? ? ? ??\n(19)\nwhere ????? is the Epanecnikov kernel\n????? ?\n?\n??\n?? ? ?????????? ? ? ? ??\nwith bandwidth ? ? ?, ???is the proportion of the circumference of the circle with center\n??and radius ????????? lying within ?, and ??is the circumradius of ?. The estimator\n(19) and other estimators of the pair correlation function are discussed in Stoyan and\nStoyan (1994); in particular they discuss how to choose the bandwidth of the kernel.\nTo study how well our estimation procedure works we performed 20 simulations\nfrom the model with an exponential covariance function where ??? ??? and ? ? ???.\nA scatter plot of the estimated values of ? and ??together with the true values is\nshown in Fig. 7. There is a large variation in the estimate of ?, but the mean values\nof the 20 estimates are?? ? ????? and ? ??? ????, not far from the true values. The\nother plot in Fig. 7 shows the mean covariance function ? ? (solid line) and upper and\nlower envelopes for the empirically estimated covariance functions obtained from the 20\nsimulations. The values of ? ? are close to the exponential covariance function, especially\nat small distances. Estimating the parameters from ? ? gives???? ????? and?? ? ?????,\nwhich indicates that a good estimate of the covariance function gives good parameter\nestimates.\n18"},{"page":21,"text":"Having estimated the parameters we may check our model assumptions by compar-\ning nonparametric estimators of various summary statistics with those obtained under\nthe estimated log Gaussian Cox model. We have considered the distribution functions\n? and ? of the distance to the nearest point in ? from a fixed point in the plane and\na \u2019typical point\u2019 in ?, respectively. Under the log Gaussian Cox model ? ? ???????\nand ? ? ???????are given by\n?????????? ? ? ? ??????????\n?\n?\n?\n?\n?\n?\n?\n???????\n?? ?????\n?\n?\n?\n?\n?\nand\n?????????? ? ? ? ???????????????\n?\n?\n??? ??????\n?\n?\n?\n?\n?\n?\n?\n???????\n?? ?????\n?\n?\n?\n?\n???? based\n?\n?\n?\n?\nwhere the mean values may be approximated by Monte Carlo.\nAs in Diggle (1983), Stoyan and Stoyan (1994), and Stoyan et al. (1995) we have\nin Examples 1 and 2 compared nonparametric estimates of ?? ?? ? ?\non the data with those obtained by simulations under the estimated log Gaussian Cox\nmodel. For short we call such nonparametric estimates for empirical ?, ?, and ?-\nfunctions. Moreover, we have obtained a nonparametric estimate of the third-order\ncharacteristic ? in (5) by combining (7) with (16) and (19), and considered whether this\nsummary statistic varies around 1 in accordance with the result (6) for log Gaussian\nCox processes.\nExample 1:\nsquare plot of 10 ?10 ??. The pine forest has grown naturally in the Eastern Finland\nand the data have previously been analyzed by Penttinen et al. (1992) and Stoyan and\nStoyan (1994), who both fitted a Mat\u00b4 ern cluster process using the ?-function both for\nparameter estimation and model checking. The estimation in Penttinen et al. (1992)\nwas carried out by trial-and-error, while Stoyan and Stoyan (1994) used a minimum\ncontrast method. The fit in both cases seems quite good, see Fig. 11 in Penttinen et al.\n(1992) and Fig. 131 in Stoyan and Stoyan (1994), but one may object to that the same\nsummary statistics have been used for both estimation and model checking.\nFig. 8 shows several characteristics for the pine data: The data normalized to a\nunit square are shown in a). The logarithm of the estimated pair correlation function\nis plotted in b) (solid line), and the shape of the curve suggests to use the exponential\ncovariance function. We estimated the parameters by minimizing (17) with ??? ???\nand ? ? ???, which are chosen to give more weight to values of ? close to zero. The\nestimates are?? ? ???? and ? ??? ????. The dotted line in b) shows the covariance\nfunction for the estimated model. The plot in c) shows the empirical ?-function for\nthe data (solid line) and upper and lower envelopes of the ?-function for the fitted\nmodel based on 19 simulations. This is the same as Stoyan and Stoyan (1994), Fig.\nThe first data set consists of the locations of 126 Scots pine saplings in a\n19"},{"page":22,"text":"131, and our model shows a better fit with respect to the ?-function than the Mat\u00b4 ern\ncluster model. The empirical ?-function falls within the envelopes from the simulations\nexcept for very small values of ?. The plots in d) and e) show the nonparametric\nestimates?? and?? based on the data against the mean of these estimates obtained from\n99 simulations under the estimated model. The plots show a reasonable good fit to the\nchosen model and?? and?? fall within the upper and lower envelopes based on the 99\nsimulations. For the Mat\u00b4 ern cluster model fitted by Stoyan and Stoyan (1994) we have\nalso created plots similar to d) and e) which indicate that our model fits the data better.\nFinally, f) shows a realization under the estimated log Gaussian Cox process.\nWe also used the third-order characteristic ? to check our model assumptions. The\nleft plot in Fig. 9 shows the estimated ? for the data and two sets of envelopes based\non 20 unconditional simulations of the estimated log Gaussian Cox process and 20\nsimulations where we condition on the observed number of points. The plot gives\nno reason to doubt the model no matter whether the \u2018unconditional\u2019 or \u2018conditional\u2019\nenvelopes are considered. The two sets of envelopes are not very different in this\nsituation where ? is rather small and the correlation therefore not very strong. To check\nthe discriminatory power of ? we similarly calculated envelopes for the Mat\u00b4 ern cluster\nprocess estimated by Stoyan and Stoyan (1994), see the right plot in Fig. 9. The\nestimated ?-function based on the data crosses the envelopes in an interval of ?-values\nand even though the large variability of the estimator for small ? makes it difficult to\nmake definitive conclusions, the plot raises serious doubt concerning the appropiateness\nof the Mat\u00b4 ern cluster process as a model for the data.\nExample 2:\ntrees, 219 spruces and 114 birches in a square plot of 50 ?50 ??. The data has been\ncollected by Kari Leinonen and Markku Nygren as a part of a larger data set where\nalso a very few pines were present and marks consisting of tree length and diameter\nwere included. These data has earlier been studied by Kuuluvainen et al. (1996). They\nfound that small trees are clustered, while larger trees are regularly distributed.\nFig. 10 a) shows the data normalized to unit area. The plot indicates clustering\nand a positive dependence between the two types of trees. In Fig. 10 b) the empirical\ncovariance functions ? ???, ? ???and ? ???are plotted (solid line, from top to bottom) using\nthe equations (12) and (13) to obtain ? ???? ??? ???. Here ? ?????? is the estimate (19) based\non the point pattern ??? ?????????????? of type ? trees. Further,\n????\n????????\n??? ??\n???\n??\n?\nwith the correction factor ???similarly defined as in (19), and where we have combined\nkernel estimation with the way Lotwick and Silverman (1982) and Diggle (1983)\nrecommend to estimate ?????? ? ????\n20\nIn this example we study a bivariate data set consisting of two types of\n? ?????? ?\n??\n??\n?\n??\n?\n??\n?\n???\n???? ? ?????? ??????????\n??\n??? ??\n??????\n???? ? ?????? ??????????\n??????????? ? ? ?."},{"page":23,"text":"Based on the plot of the empirical covariance functions we specify a model for\na bivariate log Gaussian Cox process with exponential covariance functions ?????? ?\n??\nEstimating the parameters from the empirical covariance functions by minimizing (17)\ngives ? ??\nThe estimated covariance functions are shown as dotted lines in Fig. 10 b). This\nindicates a good fit to the empirical covariance functions. We have moreover checked\nthat the condition (11) is fulfilled under the estimated model so that we have a valid\ncovariance matrix function.\nHowever, plots of the function ? for each of the two types of trees show a poor\nfit of the estimated model to the data as there seems to be more \u2018empty space\u2019 in\nrealizations of the estimated model than in the pattern a). As an example Fig. 10\nc) shows the nonparametric estimate of ??? based on birch data plotted against the\nmean of the estimate obtained from 99 simulations under the estimated model. We\nhave also tried to fit models with covariance functions as in (14) with ? ? ? terms\nand various combinations of Gaussian, exponential and stable correlation functions, but\nagain there was too much empty space under the fitted models. This may be caused\nby the regularity in the pattern of the larger trees, so one suggestion may be to include\n\u2018repulsive\u2019 pairwise interaction terms into the model as discussed at the end of Section\n2. Another possibility is to include a thinning operation, cf. Diggle and Milne (1983)\nand Diggle (1983).\n????????????? and corresponding spectral density ?????? ? ??\n????????????? ???\n???????.\n??? ????? ??????? ????? ? ??\n??? ????? ??????? ????? ? ??\n??? ????? ??????? ???.\n8 Prediction and Bayesian inference\nWe conclude this paper by considering prediction of the unobserved Gaussian\nprocess and intensity process under a given model for a univariate log Gaussian Cox\nprocess when this is observed within a bounded window. We use an empirical Bayesian\napproach, where the a posteriori distribution of the intensity process is obtained by\nconsidering the Gaussian distribution as a prior which smoothes the intensity surface,\nand where the prior may be estimated as described in Section 7. The posterior is not\nanalytically tractable so we use a Markov chain Monte Carlo algorithm to simulate the\nposterior distribution whereby various posterior characteristics can be estimated. The\nresults are applied on the data set in Example 1 and we compare various Bayesian\nestimators of the intensity process with a parametric kernel estimator studied in Diggle\n(1985), Berman and Diggle (1989), and Cressie (1993). Ogata and Katsura (1988)\ndeveloped another objective Bayesian method for estimating the intensity function of\na marked inhomogeneous Poisson point process using spline functions. Other related\nresearch but for Poisson (and more general) cluster processes include Lawson (1993),\nBaddeley and Van Lieshout (1993), and Granville and Smith (1995), who consider\nBayesian estimation of cluster centres and cluster membership. Simultaneously with\nthe development of the material of this section, Heikkinen and Arjas (1996) have\nbeen working with nonparametric Bayesian estimation of the intensity function of\ninhomogeneous planar Poisson processes generalizing the method of Arjas and Gasbarra\n(1994).\n21"},{"page":24,"text":"Suppose that a realization ? of a log Gaussian Cox process is observed within a\nbounded window ????and we wish to predict the Gaussian process and the intensity\nsurface on the bounded set ? ? ????.\nof generality assume that ? is the unit square and consider a finite subdivision of\n????and ????? ? ? ????into cells ??? of area ??? ? ?? ????? ? ?, where\n? ? ??????????? ? ????????????? ? ???? ? ????????. Define the sublattices,\n????? ??????? ? ? ???. Further, we approximate the Gaussian field ? restricted to ?\nby a Gaussian field?? ? ?????????????with mean vector ? ? ? ??????????and a covariance\nmatrix ? given by the covariance function of ? . As noticed in Subsection 6.1 we\ncan extend?? to??????\n??????????\n??????????????????????? ?????????, ? given by (15) is assumed to be positive\nsemi-definite and of rank ?, ? ? ???????, ? is a certain ? ? ???? ? ????real matrix\nof rank ?, and ? ????? ?????????????. We shall later on explain why it (apart from ease\nof exposition) may be preferred to use ? instead of?????.\nNow, if ?????? denotes the density of the conditional distribution of ? given that\n? ? ????? ?,\n????????? ? ???????? ??\nAs in Section 6 we shall without loss\n?????\n?\n?? ?? ? ? ????, where ????? ??????????? ?\n????????\n?\n??????????\n?? ??????? ?? ??????\n?\n(20)\nwhere ??? ? ?????? ? ???? is the number of points of ? contained in the ??th cell\nif ????? ? ????, and we set ??? ? ??? ? ? if ????? ? ? ????. Though this conditional\ndistribution is not defined in accordance to the covariance structure of the Gaussian\nprocess outside ?, we shall refer to this as the a posteriori distribution of ? given ?;\nthe important point is that the marginal distribution of?? under this posterior agrees with\nthe conditional distribution of?? given ? ? ????? ?. In the following the gradient\nof the posterior\n???? ?? ? ???????????? ? ?? ?????? ?? ??????\nplays a keyrole. It is easily seen that ?????????is strictly negative definite. Thus the\nposterior is strictly log-concave.\nFor simulation of the posterior we use a Metropolis-adjusted Langevin algorithm\n(MALA) as suggested by Besag (1994) in the discussion of Grenander and Miller (1994)\nand further studied in Roberts and Tweedie (1997). This is a Metropolis-Hastings type\nMarkov chain Monte Carlo (MCMC) method inspired by the definition of a Langevin\ndiffusion through a stochastic differential equation which in the present context is\n?\n????????????\n????? ? ?????????????? ?\n?\n??????\nwhere ???? is standard Brownian motion and ? ? ? is a user specified parameter (see\nExample 1 below); the posterior ??? is a stationary distribution of this Markov process\n????.\nThe MALA is given by two steps: First, if ????is the current state of the chain,\na \u2018proposal\u2019 ??????is generated from a multivariate normal distribution with mean\n22"},{"page":25,"text":"??????? ? ????? ???????????? and independent coordinates with common variance\n?. In general, the use of gradient information in the proposal kernel may lead to\nmuch faster convergence than for e.g. a random walk Metropolis chain (Roberts and\nRosenthal, 1995). Secondly, with probability\n?\n????????????\nthe next state becomes ??????? ??????; otherwise ??????? ????. This gives an\nirreducible and aperiodic Markov chain with the posterior as the stationary distribution,\nbut it is not geometrically ergodic as the posterior has lighter tails than the Gaussian\ndistribution (this can formally be verified using Theorem 4.2 in Roberts and Tweedie,\n1996b).\nBriefly, the problem with the light tails is that the Markov chain may leave the\ncenter of the posterior for a very long time, since ???????? may become extremely large\nif ? is far away from the mode of the posterior. As suggested in Roberts and Tweedie\n(1996b) more robust geometric ergodicity properties may be obtained by truncating the\ngradient in the mean of the proposal kernel: In the Appendix we show that if ????\nis replaced by\n?????????? ?? ???????? ? ?? ???????\nfor some constant ? ? ?, then the \u2018truncated MALA\u2019 becomes geometrically ergodic\nwhen ? ? ? ? ?. However, if a sensible value of ? is chosen, the undesirable properties\nof the (untruncated) MALA may not be a problem. In our examples the chain behaved\nvery nicely and a truncation of the gradient (for a suitably large ?) would not have\nmade a difference.\nNote that ? and ? do not need to be strictly positive definite. This is one reason for\nusing ? instead of?? when the posterior is considered. In the case where ? is strictly\npositive definite we have compared MALA\u2019s for simulating the conditional distribution\nof ? respective?? given ?, where the gradient in the latter case is given by\n??? ????? ? ??? ????? ? ?????????????? ?? ??????\nFor the data in Example 1 considered below we found that in the former case the algo-\nrithm mixes much faster (Fig. 11), so this is another reason to prefer the \u2018parametriza-\ntion\u2019 given by ?.\nBy simulating the posterior we can obtain MCMC estimates of the posterior mean,\ncredibility intervals, etc. for the Gaussian process and intensity surface. Conditional\nsimulations of the unobserved part ? ?????of the point process given ? ? ????? ?\ncan also be obtained. To do this one generates first a realization from the posterior\ndistribution of the intensity surface and given this realization, ? ? ????is simulated\nalong the same lines as described in the beginning of Section 6.\n? ?\n?\n?\n????????\n?\n???\n?\n???\n???????? ?\n?\n??????????\n???\n??????\n?\n?\n???????????? ?????????????????\n?\n?\n????????????\n(21)\n?\n???????????\n23"},{"page":26,"text":"Maximum a posteriori (MAP) estimation is also possible. Since ?????? is strictly\nlog-concave and its tails tend to zero at infinity, the MAP-estimate ????is the unique\nsolution to ???? ? ?. Because of the linear relationship between????? and ?, the\nMAP-estimate of?????is simply given by ????\n???\nestimate ????of?? agrees with ????\n???\nrestricted to ?. It can be shown that ????\nrestricted to ????is the same as the predictor of??????\n?\nThe conditional density of the intensity surface????? ? ?????????????????????(with\nrespect to ?-dimensional Hausdorff measure with carrier space of dimension ???? ?\n????) is not log-concave and ?????????\n??\n?????????is clearly not the MAP-estimate of\nthe intensity surface. If ? is strictly positive definite, then using an obvious notation,\n???????? ??????? is strictly log-concave, and so\n? ??????? ????. Note that the MAP-\n??????\n???\n??\n?\n??????????obtained from\n\u2018data\u2019??????\n? ????\n??\n?\n??????????using kriging (see e.g. Cressie, 1993).\n??? ????? ? ????????????? ?????????????????? ? ???????? ????????\n?\n??????????\n? ???\nis strictly log-concave. Consequently, in this case the MAP-estimate ????of the\nintensity surface on ? is the same as ????\n???\nwhere ? ? is the unique solution to ??? ????? ? ?????????. Note here that since the log\nGaussian distribution is heavy tailed and skewed, ????is not necessarily a sensible\nestimator of the intensity surface (see also the discussion in Example 1 below).\nWe have used a discrete gradient ascent algorithm for finding ????, since this\nalgorithm involves only the calculation of the gradient: Given an initial value ????the\niteration is given by ??????? ???????\nspecified parameter. The algorithm for finding ? ? is similar, except that in each iteration\nwe replace ? by ? ? ?????????. A too high value of ? may cause the algorithm to\ndiverge \u2013 we used in Example 1 the modest value ? ? ??.\n? ?????? ???????????????restricted to ?,\n?\n?????\n? ? ? ??????? , where ? ? ? is a user\nExample 1 (continued):\nintensity surface on a grid ? ? ???????????under the log Gaussian Cox process which\nwas estimated in Example 1, Section 7. In this example ? ? ????? ??????.\nAfter some preliminary runs of the MALA the parameter ? was adjusted to be ???\nin order to obtain an acceptance rate close to the optimal rate ???? given in Roberts and\nRosenthal (1995) (they formally prove their results for target distributions with i.i.d.\ncomponents, but notice that various generalizations are possible and the optimal rate\nappear to be quite robust over changes in the model). Then a sample of length ???????\nwas generated by the MALA and we used a subsample of this (with spacing equal to\n??) for obtaining Monte Carlo estimates of the various characteristics of the posterior.\nThese estimates are reported below.\nTo study the convergence properties and to compare the different implementations of\nthe MALA we have considered various plots of timeseries and estimated autocorrelations\nfor selected cells on the initial as well as the extended lattice. It appears from these\nWe now consider estimation of the Gaussian process and the\n24"},{"page":27,"text":"plots that the potential problem related to geometrical ergodicity of the MALA is rather\nhypothetical. As an illustration Fig. 11 shows timeseries and estimated autocorrelations\nfor a subsample of???????when the invariant distribution of the MALA is either ??? or\n???????. In the former case the autocorrelations die out much faster.\nMonte Carlo posterior means of the Gaussian process and the intensity surface are\nshown in Fig. 12. For comparison we have also included Diggle\u2019s (1985) nonparametric\nkernel estimate of the intensity surface. For the uniform kernel given by the uniform\ndensity on a disc, the band width of the kernel can be chosen by minimization of an\nestimate of the mean square error (see Diggle, 1985, and Berman and Diggle, 1989).\nInstead of the uniform kernel we actually used a planar Epanecnikov kernel since the\nestimate obtained with this kernel has a more suitable smooth appearance. The band\nwidth ????? for the planar Epanecnikov kernel was obtained by calibration of the chosen\nband width for the uniform kernel as suggested in Diggle (1985). The posterior mean of\nthe intensity surface is quite peaked since the minimum and maximum values are ?????\nand ???????. This is not surprising recalling the heavytailedness of the log Gaussian\ndistribution. The kernel estimate is less peaked with a range ?-??????. Integration of\nthe Monte Carlo posterior mean of the intensity surface and the kernel estimate over the\nunit square yields ?????? and ??????, respectively, so the expected number of points\nfor the inhomogeneous Poisson processes with intensity surfaces given by the posterior\nmean respective the kernel estimate are practically equal and very near to the observed\nnumber of points (???). We have also in Fig. 12 included a plot of the logarithm to the\nMonte Carlo posterior mean of the intensity surface as this gives a better impression of\nthe variability for intermediate values of the posterior mean.\nThe application of MCMC also facilitates assessment of posterior uncertainty. The\nestimated posterior variance of the Gaussian process, ? ??????????? ????? ? ?, is shown\nin the left plot in Fig. 13. The largest variance is ???? whilst the smallest is ???. By\ncomparing this plot with the Monte Carlo posterior mean of the intensity surface in Fig.\n12, we see that the posterior variance is smallest where the posterior mean is largest\nand vice versa. For the posterior distribution of the intensity surface we have further\nfor selected cells ???estimated the ??% and ??% quantiles. These credibility intervals\nare shown in Table 2 when ????? are given by ?????????? ??? ? ???????, and ???????.\nThe credibility interval for ??????is largest as this cell is situated in a peak of ?????????.\nAs an illustration of the simulation method on the extended lattice and the effect\nof wrapping the extended Gaussian field on a torus, the right plot in Fig. 13 shows\nthe Monte Carlo posterior mean of?????. Notice that outside the original field and\naway from the boundaries the estimated posterior mean is constant and equal to the\nunconditional mean.\nFinally, we have considered MAP-estimation of the Gaussian process and the\nintensity process. The extended matrix ? was strictly positive definite, and ????\nand ????\n???\nwere obtained by iterating the discrete gradient ascent algorithm until the\ngradient was practically zero (i.e.until its coordinates were numerically less than\n????). The minimum and maximum values of ????are ???? and ????, while the\ncorresponding values of the estimated posterior means ??????????? ????? ? ?, are ????\n???\n25"},{"page":28,"text":"and ????. Actually, ????is very similar to these posterior means, so we have omitted\nthe plot of ????. Since ???\n??\n? ?????the MAP-estimate is clearly a totally\nunreasonable estimate of the intensity surface. This may as noted before be due to the\nskewness and heavytailedness of the log Gaussian distribution combined with the fact\nthat the intensity surface is a random field of correlated log Gaussian random variates.\nIn Example 1 the posterior mean and the nonparametric kernel estimate gave very\ndifferent estimates of the intensity surface. To study these estimators under known\nconditions we simulated a point pattern on the unit square from the log Gaussian Cox\nprocess with exponential correlation function and parameters ? ? ?? ??? ?? ? ? ??.\nUsing the same procedure as in Example 1, Section 7, the estimates of ?? ??? ? are\n????? ????? ????, and the procedure for choosing the bandwidth yields ????. Plots of\nthe true intensity surface, the Monte Carlo posterior mean of the intensity surface under\nthe estimated model, and the kernel estimate are shown in Fig. 14. In this case the two\nestimates look much more similar than in Example 1. The large difference between the\nintensity surface estimates in Example 1 may be explained by the considerably larger\nbandwidth which was used in the kernel estimate in Example 1, and which yielded an\noversmoothed estimate of the intensity surface. In Fig. 14 the range of the true intensity\nsurface, the Monte Carlo posterior mean, and the kernel estimate are ???-???????, ?????-\n???????, and ?-???????, respectively. Integration of the estimates give ?????? for the\nposterior mean and ?????? for the kernel estimate, while the integral of the true surface\nis ??????, and the true and estimated intensity are ? ? ?????? and ? ? ? ???.\nIn conclusion, at least for the particular cases of Example 1 and the simulation\nstudy, the posterior mean seems to be the better estimate.\n???????????\nAcknowledgments\nThis research will be a part of the second and third authors Ph.D. Dissertations. It has\nbeen funded by the Danish Informatics Network in the Agricultural Sciences, the Danish\nNatural Science Research Council, NORFA and the Research Council of Norway. Antti\nPenttinen kindly provided the data studied in Examples 1 and 2. We thank Anders Brix,\nPoul Svante Eriksen, Peter Green, J\u00f8rgen Hoffmann-J\u00f8rgensen, Steffen L. Lauritzen,\nAntti Penttinen, Gareth Roberts, Mats Rudemo, Dietrich Stoyan, the editor and two\nanonymous referees for helpful comments.\nAppendix: Geometrical ergodicity of the truncated MALA\nBelow we prove that the truncated MALA discussed in Section 8 is geometrically\nergodic when ? ? ? ? ?. For simplicity and without loss of generality we shall assume\nthat ? ? ?. Letting ? ? ? ??, then by (20) the logarithm of the posterior density is\n????????? ? ???????? ??\n???????? ?? ???\n?\n??????????\n?? ??????\nwhere ? ? ???????????????, and by (21) the truncated gradient is\n?????????? ?? ? ?? ? ??? ?????\n26"},{"page":29,"text":"where\n??? ?? ???? ? ?? ???????\n?\n???????????\nIn the following ? will denote a measurable function mapping\nconcerning geometrical ergodicity are the following:\n?into\n. The results\nTheorem 4.\n????? ? ????????? and any ? ? ?, i.e, there exist ? ? ?? ? ? and ? ? ?? ? ?\nsuch that for any ? ?\n??????\nmeasure ?, ?????? ?????????????? ?????? ???.\nCorollary. Suppose that ?????? ? ???????????? ? ?\nfrom the truncated MALA where ? ? ? ? ? and the initial distribution of ??is arbitrary.\nDefine the Monte Carlo approximation??? ?\nWhen ? ? ? ? ? the truncated MALA is ??-uniformly ergodic for\n?,\n??????\n????????? ?\n?\n?\n??? ?????? ?\n?????? ????????\n? ?????????\n?? ? ? ??\nHere ????denotes the ?-step transition kernel of the truncated MALA and for a signed\n?, and that ???????is generated\n? ?\n?\n??????? of the mean ? ? ??????\ncalculated for the stationary chain. Assuming first that the density of ??is ??????, then\n????? ??????\nMoreover, if ??\ndistribution of ??:\n????? ???\nProof. Let ???? ? ? ? ??????????????and let ?????? be the density of ????????????.\nThen (36) in Roberts and Tweedie (1996b) holds since ? ? ??? ????is bounded. Since\nthe proof of Theorem 4.1 in Roberts and Tweedie (1996b) is also applicable in our\nsituation, the geometrical ergodicity then follows if we can show that the truncated\nMALA \u2018converges inwards\u2019. More precisely let as in Roberts and Tweedie (1996b),\n???? ? ?? ? ? ?? ?? ? ???? and ???? ? ?? ? ? ?????????? ? ?? ? ??? ??????? ?????? Then we\nneed to show that\n?\nHere ? denotes symmetric difference, i.e. ??? ? ?? ? ?? ? ?? ? ??.\nNote that for any ? ? ? we can choose ??such that\n??\n??? ???\n?? ? ????????? ? ?\n?\n?\n???\n???????????????? ? ??\n?? ?, we have a central limit theorem independently of the chosen initial\n?\n??\n???\n?\n? ?????? ?? ? ? ??\n?????????\n???? ? ???? ? ? ? ?? ??? ? ??\n?\n???????\n???? ? ???? ? ? ? where\n????? ? ?? ? ? ?? ? ? ????? ? ???. Thus\n?\n?????????\n???? ? ???? ? ?\n?\n?????????????????\n???? ? ???? ? ? ??\n27"},{"page":30,"text":"Since\n? ? ? ????? ? ?? ?? ? ?? ? ? ????? ? ?????? ? ?? ? ??????? ? ??? ????????\nwe have for ??? sufficiently large that ????? ? ???? so that ??????????? ? ????? ?\n????? ? ???? . It is therefore enough to show that when ??? is sufficiently large then\n? ? ? ????? implies that ? ? ? ????.\nIt is straightforwardly seen that the inequality which defines the set ???? is\nequivalent to ??? ??? ??? ??? ??? ? where\n?\n???\n??????????\n??? ?????\n? ? ?\n??? ?????\n??????? ??? ?????\n?\n? ??? ?????\n?\n??? ?\n?\n? ???\n???? ? ??? ?????????\n?\n??? ?\n???\n???\n?\n? ? ?\n??? ?\n??? ?\n??\n????????\n??\n?\n???\n?? ???? ??? ????\n?\n? ? ??? ?\n? ? ??? ? ??? ?????\n??\n??? ?? ? ?\n??????\n???\nand?? ? ? ? ??. If ? ? ? ????? and ??? is sufficiently large, then ??? ??? ? since ??is\nbounded and ? ? ? ? ?. We therefore just need to show that ??? ??? ??? ? for\n? ? ? ????? and ??? sufficiently large.\nIf ??? ? ? then also ?? ?? ? ? because ? is of full rank. Furthermore, if\n? ? ? ?????, then?? ???? ?? ? ????? ???? ???? ?????? where ??? ?? is a uniformly bounded\nvector. Since ? ? ? ? ?, we have therefore that ? ??? ? ? implies that?? ???? ?,\nwhile ? ??? ? ?? implies that?? ???? ??, where in both cases ?? ???? ? ? at a rate\nfaster than ??? ????, since ? ?????? ???is of the order ?????? ??? asymptotically. Let now\n? ? ?????? ? ????? ?? ???? ?? ??. Then ??? ??? ??can be written as\n?\n??????? ????\n??? ? ???????? ???\n????? ?????? ?????? ? ?? ??????? ? ?\nwhere ????? ???? ?? is a finite sum of bounded terms. Since for each ????? ? ?????? the\ncorresponding term ????? in the sum converges to ? when ?? ?? ? ?, the proof of the\ntheorem is completed. The corollary is a direct consequence of Theorem 4.1 in Roberts\nand Tweedie (1996a).\n????????????\n????\n?\n?? ???? ??? ????\n?\n?\n?\n? ?????? ???\n?\n?\n??????? ?????? ? ?? ?????\n???? ??????? ????\n?\n?\n? ???\n? ? ??? ???\n?\n? ? ??? ???\n?\n??\n?\n?? ? ???? ?\nReferences\nAdler, R. (1981). The Geometry of Random Fields. Wiley, New York.\nArjas, E. and Gasbarra, D. (1994).\ncensored survival data, using the Gibbs sampler. Statistica Sinica 4, 505\u2013524.\nNonparametric Bayesian inference from right\n28"},{"page":31,"text":"Baddeley, A.J. and Van Lieshout, M.N.M. (1993). Stochastic geometry models in high-\nlevel vision. In K. Mardia and G.K. Kanji (eds.) Statistics and images, Advances\nin Applied Statistics, a supplement to J. Appl. Statist. 20, 231\u2013256.\nBaddeley, A.J. and Van Lieshout, M.N.M. (1995). Area-interaction point processes.\nAnn. Inst. Statist. Math. 47, 601\u2013619.\nBaddeley, A.J., Van Lieshout, M.N.M. and M\u00f8ller, J. (1996). Markov properties of\ncluster processes. Adv. Appl. Prob. (SGSA) 28, 346\u2013355.\nBaddeley, A. J. and M\u00f8ller, J. (1989). Nearest-neighbour Markov point processes and\nrandom sets. Int. Statist. Rev. 57, 89\u2013121.\nBartlett, M.S. (1964). Spectral analysis of two-dimensional point processes. Biometrika\n44, 299\u2013311.\nBerman, M. and Diggle, P.J. (1989). Estimating weighted integrals of the second-order\nintensity of a spatial point process. J. R. Statist. Soc. B 51, 81\u201392.\nBesag, J.E. (1974). Spatial interaction and the statistical analysis of lattice systems. J.\nRoy. Statist. Soc. B 36, 192\u2013225.\nBesag, J.E. (1977). Some methods of statistical analysis for spatial data. Bull. Internat.\nStatist. Inst. 47, 77\u201392.\nBesag, J.E. (1994). Discussion of the paper by Grenander and Miller. J. R. Statist.\nSoc. B 56, 591\u2013592.\nChristakos, G. (1984). On the problem of permissible covariance and covariogram\nmodels. Water Resources Research 20, 251\u2013265.\nChristakos, G. (1992). Random Field Models in Earth Sciences. Academic Press, San\nDiego.\nCressie, N. (1991). Statistics for Spatial Data. Wiley, New York.\nDaley, D.J. and Vere-Jones, D. (1988). An Introduction to the Theory of Point Processes.\nSpringer-Verlag, New York.\nDavis, P.J. (1979). Circulant Matrices. Wiley, New York.\nDiggle, P.J. (1983). Statistical Analysis of Spatial Point Patterns. Academic Press,\nLondon.\nDiggle, P.J. (1985). A kernel method for smoothing point process data. Appl. Statist.\n34, 138\u2013147.\nDiggle, P.J. and Milne, R.K. (1983).\nbivariate spatial point processes. J. R. Statist. Soc. B 45, 11\u201321.\nBivariate Cox processes: Some models for\n29"},{"page":32,"text":"Gelfand, A.E. and Carlin, B.P. (1991). Maximum likelihood estimation for constrained\nor missing data models. Research Report 91\u2013002, Division of Biostatistics,\nUniversity of Minnesota.\nGeorgii, H.-O. (1988). Gibbs Measures and Phase Transitions. Walter de Gruyter,\nBerlin.\nGeyer, C.J. (1994). On the convergence of Monte Carlo maximum likelihood calcula-\ntions. J. R. Statist. Soc. B 56, 261\u2013274.\nGrandell, J. (1976). Doubly Stochastic Poisson Processes. Lecture Notes in Mathemat-\nics, 529. Springer-Verlag, Berlin.\nGranville, V. and Smith, R.L. (1995). Clustering and Neyman-Scott process parameter\nsimulation via Gibbs sampling. (Manuscript.) Statistical Laboratory, University\nof Cambridge.\nGrenander, U. and Miller, M.I. (1994).\nsystems (with discussion). J. R. Statist. Soc. B 56, 549\u2013603.\nRepresentations of knowledge in complex\nH\u00a8 aggstr\u00a8 om, O., Van Lieshout, M.N.M. and M\u00f8ller, J. (1996). Characterisation results\nand Markov chain Monte Carlo algorithms including exact simulation for some\nspatial point processes. Research Report R-96\u20132040, Department of Mathematics,\nAalborg University. (Submitted for publication.)\nHeikkinen, J. and Arjas, E. (1996). Nonparametric Bayesian estimation of a spatial\nPoisson intensity. Preprint 20, Department of Statistics, University of Jyvaskyla.\n(Submitted for publication.)\nJensen, J.L. and M\u00f8ller, J. (1991). Pseudolikelihood for exponential family models of\nspatial point processes. Annals of Applied Probability 1, 445\u2013461.\nKarr, A.F. (1991). Point Processes and Their Statistical Inference. (2nd ed.) Marcel\nDekker, New York.\nKuuluvainen, T., Penttinen, A., Leinonen, K, and Nygren, M. (1996).\nopportunities for comparing stand structural heterogeneity in managed and primeval\nforests: an example from boreal spruce forest in southern Finland. Silvia Fennica\n30, 315\u2013328\nStatistical\nLantu\u00b4 ejoul, C. (1994). Nonconditional simulation of stationary isotropic multigaussian\nrandom functions. In Geostatistical Simulations, (eds. M. Armstrong and P. Dowd)\nKluwer Academic Publishers, Dordrecht.\nLawson, A.B. (1993). Discussion contribution to the The Gibbs sampler and other\nMarkov chain Monte Carlo methods. J. R. Statist. Soc. B 55, 61\u201362.\n30"},{"page":33,"text":"Ledoux, M. and Talagrand, M. (1991). Probability in Banach spaces. Springer-Verlag,\nBerlin.\nLotwick, H.W. and Silverman, B.W. (1982). Methods for analysing spatial processes\nof several types of points. J. R. Statist. Soc. B 44, 406-413.\nMantouglou, A. and Wilson, J. L. (1982). The turning bands method for simulation\nof random fields using line generation by a spectral method. Water Resources\nResearch 18 (5), 1379\u20131394.\nMat\u00b4 ern, B. (1960). Spatial Variation. Meddelanden fr\u02da an Statens Skogsforskningsinstitut,\nVol. 49 (5). Statens Skogsforskningsinstitut, Stockholm.\nMatheron, G. (1973). The intrinsic random functions and their applications. Adv. Appl.\nProb. 5, 439\u2013468.\nM\u00f8ller, J. (1994). Markov chain Monte Carlo and spatial point processes. Research\nReport 293, Department of Theoretical Statistics, University of Aarhus. To appear\nin O.E. Barndorff-Nielsen et al. (eds.): Proc. Seminaire Europ\u00b4 een Statistique\nToulouse 1996 \u201cCurrent trends in stochastic geometry with applications\u201d, Chapman\nand Hall.\nOgata, Y. and Katsura, K. (1988). Likelihood analysis of spatial inhomogeneity for\nmarked point patterns. J. Am. Statist. Ass. 40, 29\u201339.\nPenttinen, A., Stoyan, D. and Henttonen H.M (1992). Marked point processes in forest\nstatistics. Forest Science 38 (4), 806\u2013824.\nPreston, C. (1976). Random Fields. Lecture Notes in Mathematics, 534. Springer-\nVerlag, Berlin.\nRathbun, S.L. and Cressie, N. (1994). A space-time survival point process for a longleaf\npine forest in Southern Georgia. J. Am. Statist. Ass. 89, 1164\u20131174.\nRipley, B.D. (1977). Modelling spatial patterns (with discussion). J. R. Statist. Soc.\nB 39, 172\u2013212.\nRipley, B.D. (1987). Stochastic Simulation. Wiley, New York.\nRipley, B.D. (1988). Statistical Inference for Spatial Processes. Cambridge University\nPress, Cambridge.\nRoberts, G.O. and Rosenthal, J.S. (1995). Optimal scaling of discrete approximations to\nLangevin diffusions. Research Report no 95\u201311, Statistical Laboratory, Cambridge\nUniversity.\n31"},{"page":34,"text":"Roberts, G.O. and Tweedie, R.L. (1996a). Geometric convergence and central limit\ntheorems for multidimensional Hastings and Metropolis algorithms. Biometrika\n83, 95-110.\nRoberts, G.O. and Tweedie, R.L. (1996b).\ndiffusions and their discrete approximations. Bernoulli 2, 341\u2013363.\nExponential convergence of Langevin\nStoyan, D., Kendall, W.S. and Mecke, J. (1995). Stochastic Geometry and Its Applica-\ntions. 2nd ed. Wiley, Chichester.\nStoyan, D. and Stoyan, H. (1994). Fractals, Random Shapes and Point Fields. Wiley,\nChichester.\nThomas, M. (1949). A generalization of Poisson\u2019s binomial limit for use in ecology.\nBiometrika 36, 18\u201325.\nWackernagel, H. (1995). Multivariate Geostatistics. Springer-Verlag, Berlin.\nWidom, B. and Rowlinson, J.S. (1970). New models for the study of liquid-vapor phase\ntransitions. J. Chem. Physics 52, 1670\u20131684.\nWood, A.T.A. and Chan, G. (1994). Simulation of stationary Gaussian processes in\n??????. J. Computational and Graphical Statistics 3, 409\u2013432.\nYaglom, A.M. (1986). Correlation Theory of Stationary and Related Random Functions\nI. Springer, Berlin.\nJesper M\u00f8ller, Department of Mathematics, Aalborg University, Fredrik Bajers Vej\n7E, DK- 9220 Aalborg \u00d8, Denmark. Email: jm@math.auc.dk\nAnne Randi Syversveen, Department of Mathematical Sciences, The Norwegian Uni-\nversity of Science and Technology, N-7034 Trondheim, Norway. Email:\nannerand@math.ntnu.no\nRasmus Plenge Waagepetersen, Department of Theoretical Statistics and Operations Re-\nsearch, Departments of Mathematical Sciences, University of Aarhus, DK-8000 \u02daArhus\nC, Denmark. Email: rasmus@mi.aau.dk\n32"},{"page":35,"text":"1. Gaussian:\n????????????\n?????????\n??????????????\n??????????\n5. Hyperbolic:\n?? ? ??????\n????????????????? ??\n????? ? ?? ? ??????????\n? ? ??????????\n2. Exponential:\n6. Bessel:\n3. Cardinal sine: 7. Spherical:\n4. Stable:\nTable 1. Correlation functions. ?? is the Bessel function of the first kind of order zero.\n33"},{"page":36,"text":"? ? ??\n7.0-181.3\n78.1\n7.9-207.5\n89.9\n6.5-173.3\n74.3\n17.2-380.3\n163.2\n363.3-3733.3\n1734.1\n? ? ??\n26.6-546.2\n235.0\n8.8-218.5\n95.7\n11.5-282.0\n119.2\n12.9-311.4\n130.6\n? ? ??\n7.4-190.4\n83.0\n8.0-215.3\n93.0\n11.6-282.9\n119.8\n10.5-248.4\n105.2\n? ? ??\n28.6-541.3\n234.5\n8.0-207.3\n89.0\n6.7-170.4\n73.2\n5.0-138.2\n60.7\n? ? ??\n? ? ??\n? ? ??\n? ? ??\n????? ?\n???????\nTable 2. Example 1. Estimated 80%-credibility intervals and posterior means of the intensity surface at selected\ncells ??? organized in accordance with Figure 11, where ????? ? ?????? ??????? ?????????????? correspond to the\nlower left, upper left, lower right, and upper right cells.\n34"},{"page":37,"text":"0.00.10.20.3 0.4 0.5\n1.0\n1.5\n2.0\n2.5\na) Gaussian\n0.00.10.2 0.3 0.40.5\n1.0\n1.5\n2.0\n2.5\nb) Exponential\n \n \n0.00.10.2 0.30.40.5\n1.0\n1.5\n2.0\n2.5\nc) Cardinal sine\n0.00.10.20.3 0.40.5\n1.0\n1.5\n2.0\n2.5\n3.0\nd) Stable\n \n \n0.00.10.20.30.40.5\n1.0\n1.5\n2.0\n2.5\ne) Modified Thomas\n \n \n0.00.10.20.30.40.5\n1.0\n1.5\n2.0\n2.5\nf) Matern cluster\n \n \n0.00.10.20.30.40.5\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\ng) Gaussian\n0.00.10.20.30.40.5\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nh) Exponential\nFig. 1. Upper row, a)-d): Various pair correlation functions with varying values of ? (solid line = smallest value\nof ?) when ? ? ?. Lower row: e), f) pair correlation functions for the Thomas and Mat\u00b4 ern cluster processes. g),\nh) Gaussian and exponential correlation functions with ? as in the upper row.\n35"},{"page":38,"text":"Fig. 2. Simulated realizations of Gaussian random fields with ? ? ?. Left to right: Gaussian ? ? ?????, exponential\n? ? ?????, cardinal sine ? ? ?????, stable ? ? ?????.\n36"},{"page":39,"text":"\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022 \u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\u2022\n\u2022\n\u2022\n\u2022 \u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\u2022\n\u2022 \u2022\n\u2022\n\u2022\u2022 \u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022 \u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022 \u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022 \u2022\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\u2022\n\u2022 \u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022 \u2022\n\u2022\u2022\n\u2022\n\u2022\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022 \u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022 \u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022 \u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\nFig. 3. Simulations of log Gaussian Cox processes conditional on that the number of points is 148. First column:\nGaussian correlation function. Second column: Exponential. Third column: Cardinal sine. Fourth column: Stable.\nFirst row: Same values of parameters as in Figure 2, i.e. ??? ? and ? ? ?????? ?????? ?????? ????? (left to right).\nSecond row: ??? ???, ? ? ?????? ?????? ?????? ?????. Third row: ??? ???, ? ? ?????? ?????? ?????? ?????.\nMean and variance of the number of points are equal in each row.\n37"},{"page":40,"text":"0.00.20.40.60.81.0\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\n050100150200250300\n0.0\n0.01\n0.02\n0.03\n050100150200250300\n0.0\n0.01\n0.02\n0.03\n0.04\n0.05\nFig. 4. Left: Plot of Gaussian correlation function (solid) and ??????? (dotted line) for ? ? ?????. Middle: Hankel\ntransform of ??????? for ? ? ?????. Right: Hankel transform of ??????? for ? ? ???.\n38"},{"page":41,"text":"r\nF(r)\n0.00.050.10 0.150.20\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nr\nG(r)\n0.00.050.100.150.20\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nFig. 5. Left: Dotted lines: Average and envelopes for the nonparametric estimator of ? based on 100 simulations of\nthe Thomas process. Solid lines: The same but for the log Gaussian Cox process with Gaussian correlation function.\nRight: The same as the left plot but with ? substituted by ?.\n39"},{"page":42,"text":"\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\u2022\n\u2022\n\u2022 \u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\nFig.\nbivariate log Gaussian Cox process, ?? ? ?? ? ???, ?? ? ?? ? ?. Right: Bivariate log Gaussian Cox process,\n?? ? ?? ? ???, ?? ? ??? ? ?.\n6. Left: Gaussian random field with exponential correlation function, ??? ? and ? ? ???.Middle:\n40"},{"page":43,"text":"\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\nbeta\nsigma^2\n0.040.060.080.100.12\n1.5\n2.0\n2.5\n3.0\nt\nc(t)\n0.00.10.20.30.4 0.5\n-0.5\n0.0\n0.5\n1.0\n1.5\nFig.\nexponential covariance function ???? ? ????????????. The true parameter value is marked with a square. Right:\nThe true covariance function (dotted line), the mean and upper and lower envelopes for the estimated covariance\nfunctions (solid lines).\n7. Left: Estimated parameters ? and ??from 20 simulations under the log Gaussian Cox process with\n41"},{"page":44,"text":".\n.\n.\n.\n.\n. . ..\n.\n.\n.\n. .\n....\n.\n.\n..\n.\n.\n.\n..\n.\n.\n.. .. .\n.\n.\n.\n.\n.\n.\n.\n.\n..\n.\n.\n.\n.\n.\n.\n.\n.\n..\n.\n.\n. . ..\n..\n..\n.....\n.\n.\n. .\n..... ...\n.\n..\n. .\n.\n.\n.\n.\n.\n.\n. .\n.\n. .\n..\n..\n. . . .\n.\n.\n.\n.\n. ..\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n0.00.2 0.40.60.81.0\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\na)  \nt\nc(t)\n0.0 0.10.20.30.40.5\n-0.5\n0.0\n0.5\n1.0\n1.5\n2.0\n2.5\n3.0\nb)  \nt\nL^(t)\n0.00.10.20.30.40.5\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\nc)  \nF(t)\nF^(t)\n0.00.20.40.60.8 1.0\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nd)  \nG(t)\nG^(t)\n0.00.20.40.60.81.0\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\ne)  \n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n..\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n0.00.20.40.60.81.0\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nf)  \nFig. 8. Example 1. Several characteristics for the pine data (see the text for explanations).\n42"},{"page":45,"text":"t\nz(t)\n0.00.1 0.20.30.4\n0.0\n0.5\n1.0\n1.5\n2.0\n2.5\n3.0\nt\nz(t)\n0.00.10.20.3 0.4\n0.0\n0.5\n1.0\n1.5\n2.0\n2.5\n3.0\nFig. 9. Example 1. Estimate of z based on the data (solid line) and \u2018conditional\u2019 envelopes (\u2014 \u2014 \u2014 ) and\n\u2018unconditional\u2019 envelopes (- - - - -) based on 20 simulations. Left: Log Gaussian Cox process. Right: Mat\u00b4 ern\ncluster process.\n43"},{"page":46,"text":"\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\nx\n\u2022\n\u2022\n\u2022\u2022\nx x\n\u2022\n\u2022\n\u2022 \u2022\n\u2022\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\u2022\nx\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\nx\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\u2022\n\u2022\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\nx\n\u2022\u2022\n\u2022\n\u2022\n\u2022\nx\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\u2022\n\u2022\n\u2022\u2022\n\u2022\nxx\nx\n\u2022\n\u2022\n\u2022\nx\n\u2022\n\u2022\n\u2022\n\u2022\nx\nx\n\u2022\n\u2022\nx\n\u2022\nx\nx\n\u2022\n\u2022\nx x\n\u2022\n\u2022\n\u2022\nx\nx\nx\n\u2022\n\u2022\u2022\u2022 \u2022\nx\n\u2022\n\u2022 \u2022\u2022\u2022\u2022\n\u2022\n\u2022\nx\n\u2022\n\u2022\u2022\u2022\nx\n\u2022\n\u2022\nxxx\n\u2022\u2022\u2022\n\u2022\n\u2022 \u2022\u2022\u2022\u2022\n\u2022\nx\nxx\n\u2022\n\u2022\n\u2022\nx\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\u2022\n\u2022\u2022\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022 \u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\u2022\n\u2022\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\nx\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\u2022\n\u2022\u2022\nx\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n0.00.20.40.60.81.0\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\na) \nx\nx\nx\nx\nx\nx\nx\nx\nxx\nx\nx\nx\nxx\nx x\nxxx\nx\nx\nxx\nxx\nx\nx\nx\nxxxx x\nx\nxx\nx\nx\nx\nx\nx\nx\nx\nxx\nx\nx\nx\nx\nx\nx\nx\nxx\nx\nx\nx\nx x\nx\nx\nx x\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx x\nx\nx\nx\nx\n0.00.10.20.30.40.5\n-0.5\n0.0\n0.5\n1.0\n1.5\n2.0\n2.5\n3.0\n3.5\nb) \n0.00.20.40.60.81.0\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nc) \nFig. 10. Example 2. a) Plot of data, spruces marked with \u2018?\u2019 and birches marked with \u2018x\u2019. b) Empirical covariance\nfunctions (solid line), from top ? ???, ? ???, ? ???, and covariance functions for the fitted model (dotted line). c) Empirical\n???? (solid line) together with lower and upper envelopes (dotted line) plotted against the mean of 99 simulations\nfrom the fitted model.\n44"},{"page":47,"text":"time\n0100002000030000\n-2\n0\n2\n4\n6\n8\n         lag\n01020 3040\n0.0 0.2 0.4 0.6 0.8 1.0\ntime\n0100002000030000\n0\n2\n4\n6\n8\n         lag\n010 203040\n0.0 0.2 0.4 0.6 0.8 1.0\nFig. 11. Example 1. Upper plots: Timeseries (left) and estimated autocorrelations (right) for????????? obtained by\ntransforming a subsample of ???????? (spacing = 10) generated by MALA. Lower row: Same as upper row but no\ntransformation is used, i.e. ????????? is generated directly by MALA.\n45"},{"page":48,"text":"Fig. 12. Example 1. Upper left plot: Monte Carlo posterior mean of the Gaussian field. Upper right plot: Monte\nCarlo posterior mean of the intensity surface. Lower left plot: Logarithm to the upper right plot. Lower right plot:\nDiggle\u2019s nonparametric kernel estimate of the intensity surface.\n46"},{"page":49,"text":"Fig. 13. Example 1. Left: Monte Carlo posterior variance of the Gaussian field on the original lattice. Right:\nMonte Carlo posterior mean of the Gaussian field on the extended lattice.\n47"},{"page":50,"text":"Fig. 14. Simulation study. Upper left plot: True Gaussian surface. Upper right plot: True intensity surface. Lower\nleft plot: Monte Carlo posterior mean of the intensity surface. Lower right plot: Diggle\u2019s nonparametric kernel\nestimate.\n48"}],"fullTextUrl":"https:\/\/www.researchgate.net\/profile\/Anne_Syversveen\/publication\/227701452_Log_Gaussian_Cox_Processes\/links\/02e7e51a6f17c691d3000000.pdf","widgetId":"rgw29_56ab9fc7d28b9"},"id":"rgw29_56ab9fc7d28b9","partials":[],"templateName":"publicliterature\/stubs\/PublicationText.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationText.html?publicationUid=227701452&hide=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationDetailAd":{"data":{"googleDfpSlot":null,"widgetId":"rgw30_56ab9fc7d28b9"},"id":"rgw30_56ab9fc7d28b9","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAd.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAd.html?publicationUid=227701452&slotId=336x280_Publications_ATF_Right&collapseSlotMode=never&fallbackContainerEnabled=1","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationRelations":null,"publicationRelationsReverse":null,"publicationUid":227701452,"showSignUpDialog":false,"selectNewSignUpDialog":false,"publicationQuestions":null,"publicationCitations":null,"publicationReviewPromo":null,"publicationUsedInReviews":null,"publicationPdfJsReader":{"data":{"isPreview":false,"licenseUrl":null,"licenseInfo":null,"defaultLinkData":{"linkId":"02e7e51a6f17c691d3000000","name":"Anne Randi Syversveen","date":null,"nameLink":"profile\/Anne_Syversveen","filename":"","downloadLink":"https:\/\/www.researchgate.net\/profile\/Anne_Syversveen\/publication\/227701452_Log_Gaussian_Cox_Processes\/links\/02e7e51a6f17c691d3000000.pdf?inViewer=0&pdfJsDownload=0&origin=publication_detail","viewerUrl":"https:\/\/www.researchgate.net\/profile\/Anne_Syversveen\/publication\/227701452_Log_Gaussian_Cox_Processes\/links\/02e7e51a6f17c691d3000000.pdf?inViewer=1&pdfJsDownload=1&origin=publication_detail","downloadHash":"8b0e072305d2f0b0bd72c39ef38935f4","showFileSizeNote":false,"fileSize":"1.88 MB","noFollow":false,"isDefault":true,"doi":null},"displayableLinks":[{"linkId":"02e7e51a6f17c691d3000000","name":"Anne Randi Syversveen","date":null,"nameLink":"profile\/Anne_Syversveen","filename":"","downloadLink":"https:\/\/www.researchgate.net\/profile\/Anne_Syversveen\/publication\/227701452_Log_Gaussian_Cox_Processes\/links\/02e7e51a6f17c691d3000000.pdf?inViewer=0&pdfJsDownload=0&origin=publication_detail","viewerUrl":"https:\/\/www.researchgate.net\/profile\/Anne_Syversveen\/publication\/227701452_Log_Gaussian_Cox_Processes\/links\/02e7e51a6f17c691d3000000.pdf?inViewer=1&pdfJsDownload=1&origin=publication_detail","downloadHash":"8b0e072305d2f0b0bd72c39ef38935f4","showFileSizeNote":false,"fileSize":"1.88 MB","noFollow":false,"isDefault":true,"doi":null}],"hasDisplayableLinks":false,"reader":{"data":{"pdfCommentsActive":false,"publicationType":"Article","onlyRenderFirstPage":false,"readMoreExperimentGoal":"goalPublicationPdfClicksReadMore","readMoreExperimentViewId":null,"comments":null,"figures":[],"figureAssetIds":[],"figureOverlayUrls":{"clickOnOverlay":"publication.PublicationFigures.html?_sg=3e-xDrdVzyAf5EGksod3hQ09X4TzN5WetDMghrGp1LX1NjGLCYgJX1C0-bPYw38COaGwGjwOayPISl80mjI0sw.BpY6f4RIm5-7snJtlbYRIy9fXXet7LQo8hoJoerKuD6WUifBtF5-KwnzsIzc2kIXffUO1LRsxBWfJq_q8024LA","clickOnPill":"publication.PublicationFigures.html?_sg=OFs9ljXq3XoxuS0sdISiLTNvB-yDKb7xbVVzXDnHj6lNl2CvqDKUjwhGYLHvo8y_7zp0eOf8Dg60NJFctCZwtw.EvHi44vnLE4du1ty2CBwzjIPU6Vd1ki-9c-W-QegWr3tQgWrxTK4ZOvVteiHGKoHDRCVw6fLFpwOun1biT4k0Q"},"canSelect":false,"javascriptPath":"https:\/\/www.researchgate.net\/c\/o1q2er\/","downloadUrl":"https%3A%2F%2Fwww.researchgate.net%2Fprofile%2FAnne_Syversveen%2Fpublication%2F227701452_Log_Gaussian_Cox_Processes%2Flinks%2F02e7e51a6f17c691d3000000.pdf%3FinViewer%3D1%26pdfJsDownload%3D1%26origin%3Dpublication_detail","viewerUrl":"https:\/\/www.researchgate.net\/c\/o1q2er\/javascript\/lib\/pdfjs\/web\/viewer.html","commentEndpoint":"https:\/\/www.researchgate.net\/rgformat\/api\/comment","experimentEndpoint":"https:\/\/www.researchgate.net\/rgformat\/api\/experiment?key=oVspfn05zG6Bd55gV7kfsfMEb-403PpcBlx33I8FJAdRZI4r_EyxX51P9afB68o1Pdvxw0yhlLqCzx39Mb4v8Q","urlHash":"a833df041d796df6d0d39a7181d20686","downloadTrackUrl":"application.PdfJsReader.ajaxTrackDownload.html?msrp=mw5C6AiqrYglZeuFqDgSO49tqP3JzD2FoK3LxKJPc6zOKUkwwVk-2ubOB4cfKLFjlWCjDg_ex1_ypHqibNJL0gkOdScAWl_PlmkrUw7899w.4lmvp7ZTfTjVRGpmwvLHYZzYpE795UdAL3v92VyTBVSJ4owwu4cVkF9oJK6VknLET6cWKmv7KD3ecAJMqc2GNw.vSUfW4kQGZ8HbvF-SIySwawzbR2JJz_4ck2gCTSV31dELHCGc4Eezs2ooRrqphG3XndMPpsT8aQl-Z4jeO-fWw","viewportMilestoneTrackUrl":"application.PdfJsReader.ajaxTrackViewportMilestone.html","linkId":"02e7e51a6f17c691d3000000","trackedDownloads":{"02e7e51a6f17c691d3000000":{"v":false,"d":false}},"assetId":"AS:97028780593154@1400144872558","readerDocId":null,"assetType":"fulltext","interactionType":{"comment":"comment","highlight":"highlight"},"publicationUid":227701452,"commentCursorPromo":null,"widgetId":"rgw32_56ab9fc7d28b9"},"id":"rgw32_56ab9fc7d28b9","partials":[],"templateName":"application\/stubs\/PdfJsReader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PdfJsReader.html?fileHref=https%3A%2F%2Fwww.researchgate.net%2Fprofile%2FAnne_Syversveen%2Fpublication%2F227701452_Log_Gaussian_Cox_Processes%2Flinks%2F02e7e51a6f17c691d3000000.pdf%3FinViewer%3D1%26pdfJsDownload%3D1%26origin%3Dpublication_detail&assetId=AS%3A97028780593154%401400144872558&publicationUid=227701452&linkId=02e7e51a6f17c691d3000000&onlyShowFirstPage=0","viewClass":null,"yuiModules":["css-pow-application-PdfJsReader"],"stylesheets":["pow\/application\/PdfJsReader.css"],"_isYUI":true},"showHeader":true,"title":"Log Gaussian Cox Processes","publicationType":"Article","downloadTrackUrl":"publicliterature.PublicationInlineReader.ajaxTrackDownload.html?msrp=L0ZLII22qNdS63dG7T7mamqBYat4a5YaUuRQHpFjw9Qqg1SrA4qMFfJKTl3vZuhEH2XYlXj-bpvvjyH98XcyG9KL244-SiRP1_xhs-plYUk.JlK4urkjTARFp4lGH6d1Jwp4mB0gisyAK66N56x9oAkac3E5Hcj5EHbbTMq3gBQT6yf7S4EppvaTcGWE6L_F_g.Zfm3Pcpw8arhOwEJ5xSQoCE3c91IlgKHG9bvOgHBFWmU5_QSKDzEi9gOOXTVJmdBIKeLQKf_IFA5kIOPLPdRmA","publicationUid":227701452,"trackedDownloads":{"02e7e51a6f17c691d3000000":{"v":false,"d":false}},"inlinePdf":false,"publicationComments":null,"showDownloadButton":true,"socialShare":{"data":{"shareItems":[{"data":{"name":"Facebook","url":"http:\/\/www.facebook.com\/share.php?u={{url}}{{#title}}&t={{title}}{{\/title}}","width":600,"height":350,"useUtmTags":true,"utmSource":"facebook","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareFacebook.ajaxTrackSocialShare.html","widgetId":"rgw34_56ab9fc7d28b9"},"id":"rgw34_56ab9fc7d28b9","partials":{"shareIcon":"application\/stubs\/partials\/shareFacebookBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareFacebook.html?provider=Facebook&shareIcon=shareIconBlog&utmSource=facebook&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"Twitter","url":"http:\/\/twitter.com\/intent\/tweet?text={{#title}}{{title}}: {{\/title}}{{url}}&via=researchgate","width":600,"height":350,"useUtmTags":true,"utmSource":"twitter","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareTwitter.ajaxTrackSocialShare.html","widgetId":"rgw35_56ab9fc7d28b9"},"id":"rgw35_56ab9fc7d28b9","partials":{"shareIcon":"application\/stubs\/partials\/shareTwitterBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareTwitter.html?provider=Twitter&shareIcon=shareIconBlog&utmSource=twitter&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"Google+","url":"https:\/\/plus.google.com\/share?url={{url}}","width":600,"height":600,"useUtmTags":true,"utmSource":"googleplus","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareGooglePlus.ajaxTrackSocialShare.html","widgetId":"rgw36_56ab9fc7d28b9"},"id":"rgw36_56ab9fc7d28b9","partials":{"shareIcon":"application\/stubs\/partials\/shareGooglePlusBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareGooglePlus.html?provider=Google%2B&shareIcon=shareIconBlog&utmSource=googleplus&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"LinkedIn","url":"http:\/\/www.linkedin.com\/shareArticle?mini=true&url={{url}}{{#title}}&title={{title}}{{\/title}}&source=ResearchGate","width":520,"height":570,"useUtmTags":true,"utmSource":"linkedin","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareLinkedIn.ajaxTrackSocialShare.html","widgetId":"rgw37_56ab9fc7d28b9"},"id":"rgw37_56ab9fc7d28b9","partials":{"shareIcon":"application\/stubs\/partials\/shareLinkedInBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareLinkedIn.html?provider=LinkedIn&shareIcon=shareIconBlog&utmSource=linkedin&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"Reddit","url":"https:\/\/www.reddit.com\/submit?url={{url}}{{#title}}&title={{title}}{{\/title}}","width":600,"height":600,"useUtmTags":true,"utmSource":"reddit","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareReddit.ajaxTrackSocialShare.html","widgetId":"rgw38_56ab9fc7d28b9"},"id":"rgw38_56ab9fc7d28b9","partials":{"shareIcon":"application\/stubs\/partials\/shareRedditBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareReddit.html?provider=Reddit&shareIcon=shareIconBlog&utmSource=reddit&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true}],"widgetId":"rgw33_56ab9fc7d28b9"},"id":"rgw33_56ab9fc7d28b9","partials":[],"templateName":"application\/stubs\/SocialShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.SocialShare.html?campaign=shareFullTextPublication&trackClick=1&shareIcon=shareIconBlog","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw31_56ab9fc7d28b9"},"id":"rgw31_56ab9fc7d28b9","partials":[],"templateName":"publicliterature\/stubs\/PublicationInlineReader.html","templateExtensions":["generalHelpers"],"attrs":{"showFulltextDownloadedSignupDialog":true,"preSignUpDialogContext":null,"requestFulltext":false},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationInlineReader.html","viewClass":"views.publicliterature.PublicationInlineReaderView","yuiModules":["rg.views.publicliterature.PublicationInlineReaderView","css-pow-publicliterature-PublicationInlineReader"],"stylesheets":["pow\/publicliterature\/PublicationInlineReader.css"],"_isYUI":true},"useFulltextOptimizedLayout":false,"publicationActions":null,"requestFulltextPromo":null,"currentUrl":"publication\/227701452_Log_Gaussian_Cox_Processes","isLeaderboardAd":false,"enableStickyBox":null,"googleDfpSlotMobileBottom":null,"fullTextExitPopup":null,"showExitPopupDialog":false,"widgetId":"rgw2_56ab9fc7d28b9"},"id":"rgw2_56ab9fc7d28b9","partials":{"romeo_legal_notice":"publicliterature\/stubs\/partials\/romeo_legal_notice.html"},"templateName":"publicliterature\/stubs\/PublicPublicationDetails_NewLayout.html","templateExtensions":["generalHelpers"],"attrs":{"publicationUid":227701452},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicPublicationDetailsOld.html?publicationUid=227701452&isTestOldDesign=0","viewClass":"views.publicliterature.PublicPublicationDetailsOldView","yuiModules":["rg.views.publicliterature.PublicPublicationDetailsOldView"],"stylesheets":[],"_isYUI":true},"widgetId":"rgw1_56ab9fc7d28b9"},"id":"rgw1_56ab9fc7d28b9","partials":[],"templateName":"publicliterature\/stubs\/PublicPublicationDetails.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicPublicationDetails.html","viewClass":"views.publicliterature.PublicPublicationDetailsView","yuiModules":["rg.views.publicliterature.PublicPublicationDetailsView"],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"uaClass":"","headPrefix":[],"rootUrl":"https:\/\/www.researchgate.net\/","requestToken":"ANadGBl3+Lzt6KNN4DRbYevOzinqdHlDvCXEhE6AGeZFOTbSufDJ9Q4wTLbHCuBPuNZ4C1mBxNuoe6KJWbu1x9cByNlqSjxCcmP73vCPbLDjVpWMu3zc0K1nxsPtAyIs1RN5VlRXxLAq6GQ6Z67fPHZOs0UUGHHfUs\/PjxQcgJu\/LuuG6J3QGdSUwjG5pxueXBdsJMfQEGB16Q59L+k16BxlMKPp4FtjHwpYkh6FS703fwpGBRlme584ohRma50Z1vVGHozosXq9DNOowmf1p+52YCd\/RdRfs06kzGxS\/nY=","faviconCdnUrl":"https:\/\/c5.rgstatic.net\/m\/2390829798215018\/images\/favicon.ico","headerOutput":"<noscript><\/noscript><link rel=\"canonical\" href=\"https:\/\/www.researchgate.net\/publication\/227701452_Log_Gaussian_Cox_Processes\" \/>\n<link rel=\"dns-prefetch\" href=\"\/\/c5.rgstatic.net\" \/>\n<link rel=\"dns-prefetch\" href=\"\/\/i1.rgstatic.net\" \/>\n<meta property=\"twitter:card\" content=\"summary\" \/>\n<meta property=\"twitter:site\" content=\"@ResearchGate\" \/>\n<meta property=\"og:title\" content=\"Log Gaussian Cox Processes\" \/>\n<meta property=\"og:description\" content=\"Planar Cox processes directed by a log Gaussian intensity process are investigated in the univariate and multivariate cases. The appealing properties of such models are demonstrated theoretically...\" \/>\n<meta property=\"og:site_name\" content=\"ResearchGate\" \/>\n<meta property=\"og:image\" content=\"https:\/\/i1.rgstatic.net\/publication\/227701452_Log_Gaussian_Cox_Processes\/links\/02e7e51a6f17c691d3000000\/smallpreview.png\" \/>\n<meta property=\"og:url\" content=\"https:\/\/www.researchgate.net\/publication\/227701452_Log_Gaussian_Cox_Processes\" \/>\n<meta property=\"rg:id\" content=\"PB:227701452\" \/>\n<meta name=\"DC.identifier\" scheme=\"DCTERMS.URI\" content=\"http:\/\/dx.doi.org\/10.1111\/1467-9469.00115\" \/>\n<meta name=\"gs_meta_revision\" content=\"1.1\" \/>\n<meta name=\"citation_title\" content=\"Log Gaussian Cox Processes\" \/>\n<meta name=\"citation_author\" content=\"Jesper M\u00f8ller\" \/>\n<meta name=\"citation_author\" content=\"Anne Randi Syversveen\" \/>\n<meta name=\"citation_author\" content=\"Rasmus Plenge Waagepetersen\" \/>\n<meta name=\"citation_publication_date\" content=\"1998\/08\/31\" \/>\n<meta name=\"citation_journal_title\" content=\"Scandinavian Journal of Statistics\" \/>\n<meta name=\"citation_issn\" content=\"1467-9469\" \/>\n<meta name=\"citation_volume\" content=\"25\" \/>\n<meta name=\"citation_issue\" content=\"3\" \/>\n<meta name=\"citation_firstpage\" content=\"451\" \/>\n<meta name=\"citation_lastpage\" content=\"482\" \/>\n<meta name=\"citation_doi\" content=\"10.1111\/1467-9469.00115\" \/>\n<meta name=\"citation_pdf_url\" content=\"https:\/\/www.researchgate.net\/profile\/Anne_Syversveen\/publication\/227701452_Log_Gaussian_Cox_Processes\/links\/02e7e51a6f17c691d3000000.pdf\" \/>\n<meta name=\"citation_abstract_html_url\" content=\"https:\/\/www.researchgate.net\/publication\/227701452_Log_Gaussian_Cox_Processes\" \/>\n<meta name=\"citation_fulltext_html_url\" content=\"https:\/\/www.researchgate.net\/publication\/227701452_Log_Gaussian_Cox_Processes\" \/>\n<meta name=\"viewport\" content=\"width=device-width,initial-scale=1\" \/>\n<link href=\"\/\/c5.rgstatic.net\/m\/22664197317151888\/styles\/rg.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/21004998181197492\/styles\/rg2.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<!--[if lt IE 9]><link href=\"\/\/c5.rgstatic.net\/m\/238176252723686\/styles\/ie.css\" type=\"text\/css\" rel=\"stylesheet\"\/><![endif]-->\n<link href=\"\/\/c5.rgstatic.net\/m\/217752362214895\/styles\/modules\/publicprofile.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/21993347442549\/styles\/pow\/publicliterature\/FollowPublicationPromo.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/282514599719602\/styles\/pow\/application\/PdfJsReader.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/23819663151220\/styles\/pow\/publicliterature\/PublicationInlineReader.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<script src=\"\/\/c5.rgstatic.net\/m\/2321000301012716\/javascript\/vendor\/webfontloader\/webfontloader.js\" type=\"text\/javascript\"><\/script>\n <script>(function(i,s,o,g,r,a,m){i[\"GoogleAnalyticsObject\"]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,\"script\",\"\/\/www.google-analytics.com\/analytics.js\",\"ga\");\n ga(\"create\",\"UA-58591210-1\");ga(\"set\",\"anonymizeIp\",true);ga('set', 'dimension1', 'publication full-text');ga('set', 'dimension2', 'Article');ga('set', 'dimension3', 'Logged out');ga('set', 'dimension4', 'https');ga(\"send\",\"pageview\");<\/script>\n","webfont":"<noscript><\/noscript><script> WebFontConfig = { custom: { families: ['source_sans_pro_italic', 'source_sans_pro_bold', 'source_sans_pro', 'martel'], urls : ['\/\/c5.rgstatic.net\/m\/231392577336386\/styles\/fonts.css'] } }; WebFont.load(WebFontConfig); <\/script>\n","correlationId":"rgreq-255ecbd5-1344-437a-a0df-0235699bfd6d","accountId":null,"module":"publicliterature","action":"publicliterature.PublicPublicationDetails","page":"publicationDetail","product":"publications","backendTime":480,"continent":"Asia","stylesHome":"\/\/c5.rgstatic.net\/m\/","staticHost":"c5.rgstatic.net","useEarlyFlush":false,"longRunningRequestIdentifier":"LongRunningRequest.publicliterature.PublicPublicationDetails","longRunningRequestFp":"e9e5bbe1366c7ee8c8e41d02f793c884ac9be19b","widgetId":"rgw39_56ab9fc7d28b9"},"id":"rgw39_56ab9fc7d28b9","partials":[],"templateName":"application\/stubs\/StaticHeader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.StaticHeader.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){
            Y.rg.core.pagespeed.Monitoring.monitorPage("\/\/glassmoni.researchgate.net", "publicliterature.PublicPublicationDetails.run.html.loggedOut.get", "59de9668d07aeb77ab4de5f24d382b5d199d2437", "rgreq-255ecbd5-1344-437a-a0df-0235699bfd6d", "e13429372b4deec629fc206504a35b5cf0e8340a");
        
            Y.rg.core.pagespeed.Monitoring.monitorPage("\/\/glassmoni.researchgate.net", "publicationDetail.loggedOut", "ed1993d9e20f6cefa83edacaa24401a18c071aea", "rgreq-255ecbd5-1344-437a-a0df-0235699bfd6d", "e13429372b4deec629fc206504a35b5cf0e8340a");
        })();
(function(){Y.rg.createInitialWidget({"data":{"year":"2016","inlinePromo":null,"isAdmin":false,"contactUrl":"https:\/\/www.researchgate.net\/contact","aboutUsUrl":"https:\/\/www.researchgate.net\/about","widgetId":"rgw40_56ab9fc7d28b9"},"id":"rgw40_56ab9fc7d28b9","partials":[],"templateName":"application\/stubs\/DefaultFooter.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.DefaultFooter.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"headerLogin":{"data":{"urlAfterLogin":"publication\/227701452_Log_Gaussian_Cox_Processes","requestToken":"5IF7jMp6tCxim7No3cR\/OneeBRs8GExt7mH4dR07T1iDCpQNp3CZ41MXM9GeT2POziwvkn2v29axZbqNlcLiOoYy3S7Wr8SrZfWc8mnzLrts1nRKEJ5R3fvUDPavjaROPAt7UIFa1\/Qyg5bNIbPf\/tgHSGpGYGLFKzCyACptBHde85YB9MhP5hXewpZFUAgc6kAmjXeZUboUM8F60NMT7al4Y0k3sMFEBz6DfMyxxAOkTwvnmsGUIoBhiakLh\/V5LvAvn1M+5bMxyDfYCwK65sDzELz6W8V5oTZ5dtLC+q8=","loginUrl":"https:\/\/www.researchgate.net\/application.Login.html","signupUrl":"https:\/\/www.researchgate.net\/signup.SignUp.html?ev=su_chnl_index&hdrsu=1&_sg=iUUAT81hSrElMWS3QQO9y8r9jmWApPCW1f0B-dA08NQntApIAaUe9UVrspRku2Gs","encodedUrlAfterLogin":"cHVibGljYXRpb24vMjI3NzAxNDUyX0xvZ19HYXVzc2lhbl9Db3hfUHJvY2Vzc2Vz","signupCallToAction":"Join for free","widgetId":"rgw42_56ab9fc7d28b9"},"id":"rgw42_56ab9fc7d28b9","partials":{"partial":"application\/stubs\/partials\/headerLoginDefault.html"},"templateName":"application\/stubs\/HeaderLogin.html","templateExtensions":[],"attrs":{"goal":"milestoneHeaderLoginSeen"},"widgetUrl":"https:\/\/www.researchgate.net\/application.HeaderLogin.html","viewClass":"views.application.HeaderLoginView","yuiModules":["rg.views.application.HeaderLoginView"],"stylesheets":[],"_isYUI":true},"cookieConsent":null,"logoSvgSrc":"https:\/\/c5.rgstatic.net\/m\/235107188705592\/images\/template\/brand-header-logo.svg","logoFallbackSrc":"https:\/\/c5.rgstatic.net\/m\/238113351022438\/images\/template\/brand-header-logo.png","widgetId":"rgw41_56ab9fc7d28b9"},"id":"rgw41_56ab9fc7d28b9","partials":{"schemaSocialProfiles":"application\/stubs\/partials\/schemaSocialProfiles.html"},"templateName":"application\/stubs\/HeaderLoggedOut.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.HeaderLoggedOut.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"logEvent":"su_banner","specialCopy":false,"widgetId":"rgw43_56ab9fc7d28b9"},"id":"rgw43_56ab9fc7d28b9","partials":[],"templateName":"application\/stubs\/LoggedOutBanner.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.LoggedOutBanner.html","viewClass":"views.application.LoggedOutBannerView","yuiModules":["rg.views.application.LoggedOutBannerView"],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.core.util.ParameterFilter.filter(["ev","cp","ch","ref","dbw","pli","loginT","uid","claimChannel","enrichId","enrichSource","utm_source","utm_medium","utm_campaign","el","ci"]);})();
});}); } else { throw 'YRG was not loaded when attaching widgets'; }</script><script> dataLayer = [{"pageCategory":"publication full-text","publicationType":"Article","eventCategory":"Publication page"}]; </script> <noscript><iframe src="//www.googletagmanager.com/ns.html?id=GTM-MKVKH7" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-MKVKH7');</script><script>(function(e){function n(n,t,o,a){"use strict";var i=e.document.createElement("link"),r=t||e.document.getElementsByTagName("script")[0],d=e.document.styleSheets;return i.rel="stylesheet",i.href=n,i.media="only x",a&&(i.onload=a),r.parentNode.insertBefore(i,r),i.onloadcssdefined=function(e){for(var t,o=0;d.length>o;o++)d[o].href&&d[o].href.indexOf(n)>-1&&(t=!0);t?e():setTimeout(function(){i.onloadcssdefined(e)})},i.onloadcssdefined(function(){i.media=o||"all"}),i}function t(e,n){e.onload=function(){e.onload=null,n&&n.call(e)},"isApplicationInstalled"in navigator&&"onloadcssdefined"in e&&e.onloadcssdefined(n)}var o=function(a,i){"use strict";if(a&&3===a.length){var r=e.Image,d=!(!document.createElementNS||!document.createElementNS("http://www.w3.org/2000/svg","svg").createSVGRect||!document.implementation.hasFeature("http://www.w3.org/TR/SVG11/feature#Image","1.1")||e.opera&&-1===navigator.userAgent.indexOf("Chrome")||-1!==navigator.userAgent.indexOf("Series40")),c=new r;c.onerror=function(){o.method="png",o.href=a[2],n(a[2])},c.onload=function(){var e=1===c.width&&1===c.height,r=a[e&&d?0:e?1:2];o.method=e&&d?"svg":e?"datapng":"png",o.href=r,t(n(r),i)},c.src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///ywAAAAAAQABAAACAUwAOw==",document.documentElement.className+=" grunticon"}};o.loadCSS=n,o.onloadCSS=t,e.grunticon=o})(this);grunticon(["https://c5.rgstatic.net/c/o1q2er/styles/icons/_header-ico.svg.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_header-ico.png.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_header-ico.fallback.scss"]);grunticon(["https://c5.rgstatic.net/c/o1q2er/styles/icons/_admin-ico.svg.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_admin-ico.png.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_admin-ico.fallback.scss"]);grunticon(["https://c5.rgstatic.net/c/o1q2er/styles/icons/_ico.svg.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_ico.png.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_ico.fallback.scss"]);</script></body>
</html>
