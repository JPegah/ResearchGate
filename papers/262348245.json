{"abstract":"Gaussian process prior with an appropriate likelihood function is a flexible non-parametric model for a variety of learning tasks. One important and standard task is multi-class classification, which is the categorization of an item into one of several fixed classes. A usual likelihood function for this is the multinomial logistic likelihood function. However, exact inference with this model has proved to be difficult because high-dimensional integrations are required. In this paper, we propose a variational approximation to this model, and we describe the optimization of the variational parameters. Experiments have shown our approximation to be tight. In addition, we provide data-independent bounds on the marginal likelihood of the model, one of which is shown to be much tighter than the existing variational mean-field bound in the experiments. We also derive a proper lower bound on the predictive likelihood that involves the Kullback-Leibler divergence between the approximating and the true posterior. We combine our approach with a recently proposed sparse approximation to give a variational sparse approximation to the Gaussian process multi-class model. We also derive criteria which can be used to select the inducing set, and we show the effectiveness of these criteria over random selection in an experiment.","authors":["Kian Ming A. Chai"],"title":"Variational Multinomial Logit Gaussian Process","_id":262348245,"citee":[3192933,5608645,2306327,6690142,238625098,221345826,262401611,220320940,220074019,220343611,2525851,265368623,260161252,224178838,222400397,220654786,220320048,228618014],"citedBy":[275588150,270222737,229156453,262286080,272195669,278332447],"URL":"https:\/\/www.researchgate.net\/publication\/262348245_Variational_Multinomial_Logit_Gaussian_Process"}