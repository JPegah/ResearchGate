{"abstract":"We present a hybrid algorithm for Bayesian topic models that combines the efficiency of sparse Gibbs sampling with the scalability of online stochastic inference. We used our algorithm to analyze a corpus of 1.2 million books (33 billion words) with thousands of topics. Our approach reduces the bias of variational inference and generalizes to many Bayesian hidden-variable models.","authors":["Matt Hoffman","David Blei"],"title":"Sparse Stochastic Inference for Latent Dirichlet allocation","pub_id":228095627,"citee":[],"citedBy":[],"URL":"https:\/\/www.researchgate.net\/publication\/228095627_Sparse_Stochastic_Inference_for_Latent_Dirichlet_allocation"}