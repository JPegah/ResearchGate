{"abstract":"Inference in topic models typically involves a sampling step to associate latent variables with observations. Unfortunately the generative model loses sparsity as the amount of data increases, requiring O(k) operations per word for k topics. In this paper we propose an algorithm which scales linearly with the number of actually instantiated topics kd in the document. For large document collections and in structured hierarchical models kd ll k. This yields an order of magnitude speedup. Our method applies to a wide variety of statistical models such as PDP [16,4] and HDP [19]. At its core is the idea that dense, slowly changing distributions can be approximated efficiently by the combination of a Metropolis-Hastings step, use of sparsity, and amortized constant time sampling via Walker's alias method.","authors":["Amr Ahmed"],"title":"Reducing the sampling complexity of topic models","_id":266660385,"citee":[238727925,271076887,229100346,2826951,221653500,220320763,222646955,228059007,220699346,273171262,228092206,228654366,5142858,220492510,220270139,5948829,229100911,221653450,220538800],"citedBy":[284476547,283471250,283334510,283118017,279633530,273471480,269722321,269116869,288219754,268747974,276297134,281144924,283117882],"URL":"https:\/\/www.researchgate.net\/publication\/266660385_Reducing_the_sampling_complexity_of_topic_models"}