<!DOCTYPE html> <html lang="en" class="" id="rgw37_56ab9eee9ebe9"> <head > <meta charset="utf-8"/> <meta http-equiv="content-type" content="text/html; charset=UTF-8"/> <meta name="Rg-Request-Token" id="Rg-Request-Token" content="mUXJuJiCvW+btnynApBwxqH7B4l7FDkfhOtQpvoLMOA/IQVzfq+6wjMmD3hwr6O1D8vGCAm/65BCSiQPeNQCLXWlJ95XHOct/fMkXLfMweRKruwi+Ain1W6FosyMy0qATV7XoYjYQaKgXZ+fyGePdm6Nst3yyA7nU1TZirPbl+sqvO+T8DVC9nZERd2pMkhqVnJif0SJ+XBBnOdaO6O5dwkx1YD7zLpayLUMH4ekWovNnhxvNplOt/DwivDyMPdNYIwwXIrYcyJ/cYruGX/aly9JW+6pGUfNpt9R5DP8cqs="/> <meta http-equiv="expires" content="0"/> <link rel="apple-touch-icon" sizes="57x57" href="https://www.researchgate.net/apple-touch-icon-57x57.png"> <link rel="apple-touch-icon" sizes="60x60" href="https://www.researchgate.net/apple-touch-icon-60x60.png"> <link rel="apple-touch-icon" sizes="72x72" href="https://www.researchgate.net/apple-touch-icon-72x72.png"> <link rel="apple-touch-icon" sizes="76x76" href="https://www.researchgate.net/apple-touch-icon-76x76.png"> <link rel="apple-touch-icon" sizes="114x114" href="https://www.researchgate.net/apple-touch-icon-114x114.png"> <link rel="apple-touch-icon" sizes="120x120" href="https://www.researchgate.net/apple-touch-icon-120x120.png"> <link rel="apple-touch-icon" sizes="144x144" href="https://www.researchgate.net/apple-touch-icon-144x144.png"> <link rel="apple-touch-icon" sizes="152x152" href="https://www.researchgate.net/apple-touch-icon-152x152.png"> <link rel="apple-touch-icon" sizes="180x180" href="https://www.researchgate.net/apple-touch-icon-180x180.png"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-32x32.png" sizes="32x32"> <link rel="icon" type="image/png" href="https://www.researchgate.net/android-chrome-192x192.png" sizes="192x192"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-96x96.png" sizes="96x96"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-16x16.png" sizes="16x16"> <link rel="shortcut icon" type="image/x-icon" href="https://c5.rgstatic.net/m/2390829798215018/images/favicon.ico"/> <link rel="manifest" href="https://www.researchgate.net/manifest.json"> <meta name="msapplication-TileColor" content="#da532c"> <meta name="msapplication-TileImage" content="https://www.researchgate.net/mstile-144x144.png"> <meta name="theme-color" content="#444444"> <link rel="search" type="application/opensearchdescription+xml" title="ResearchGate search" href="https://www.researchgate.net/application.DownloadOpenSearchPlugin.html"/> <link rel="meta" type="application/rdf+xml" title="ICRA labels" href="https://www.researchgate.net/application.DownloadLabels.html"/> <link rel="http://oexchange.org/spec/0.8/rel/related-target" type="application/xrd+xml" href="https://www.researchgate.net/application.DownloadOExchange.html"/> <base href="https://www.researchgate.net/"/> <script>
    var rgConfig = {
        correlationId: "rgreq-c5481979-0cab-4c2f-bd9e-84a725ad17bb",
        accountId: "",
        module: "publicliterature",
        action: "publicliterature.PublicPublicationDetails",
        page: "publicationDetail",
        product: "publications",
        continent: "Asia",
        stylesHome: "//c5.rgstatic.net/m/",
        staticHost: "c5.rgstatic.net",
        longRunningRequestIdentifier: "LongRunningRequest.publicliterature.PublicPublicationDetails",
        longRunningRequestFp: "e9e5bbe1366c7ee8c8e41d02f793c884ac9be19b"
    };
    window.rootUrl = "https://www.researchgate.net/";
</script> <link rel="canonical" href="https://www.researchgate.net/publication/228083473_Fixed-Form_Variational_Posterior_Approximation_through_Stochastic_Linear_Regression" />
<link rel="dns-prefetch" href="//c5.rgstatic.net" />
<link rel="dns-prefetch" href="//i1.rgstatic.net" />
<meta property="twitter:card" content="summary" />
<meta property="twitter:site" content="@ResearchGate" />
<meta property="og:title" content="Fixed-Form Variational Posterior Approximation through Stochastic Linear Regression" />
<meta property="og:description" content="We propose a general algorithm for approximating nonstandard Bayesian
posterior distributions. The algorithm minimizes the Kullback-Leibler
divergence of an approximating distribution to the..." />
<meta property="og:site_name" content="ResearchGate" />
<meta property="og:image" content="https://i1.rgstatic.net/publication/228083473_Fixed-Form_Variational_Posterior_Approximation_through_Stochastic_Linear_Regression/links/5486e7290cf268d28f062892/smallpreview.png" />
<meta property="og:url" content="https://www.researchgate.net/publication/228083473_Fixed-Form_Variational_Posterior_Approximation_through_Stochastic_Linear_Regression" />
<meta property="rg:id" content="PB:228083473" />
<meta name="DC.identifier" scheme="DCTERMS.URI" content="http://dx.doi.org/10.1214/13-BA858" />
<meta name="gs_meta_revision" content="1.1" />
<meta name="citation_title" content="Fixed-Form Variational Posterior Approximation through Stochastic Linear Regression" />
<meta name="citation_author" content="Tim Salimans" />
<meta name="citation_author" content="David A. Knowles" />
<meta name="citation_publication_date" content="2012/06/28" />
<meta name="citation_issn" content="1936-0975" />
<meta name="citation_volume" content="8" />
<meta name="citation_issue" content="4" />
<meta name="citation_doi" content="10.1214/13-BA858" />
<meta name="citation_pdf_url" content="https://www.researchgate.net/profile/Tim_Salimans/publication/228083473_Fixed-Form_Variational_Posterior_Approximation_through_Stochastic_Linear_Regression/links/5486e7290cf268d28f062892.pdf" />
<meta name="citation_abstract_html_url" content="https://www.researchgate.net/publication/228083473_Fixed-Form_Variational_Posterior_Approximation_through_Stochastic_Linear_Regression" />
<meta name="citation_fulltext_html_url" content="https://www.researchgate.net/publication/228083473_Fixed-Form_Variational_Posterior_Approximation_through_Stochastic_Linear_Regression" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<link href="//c5.rgstatic.net/m/22664197317151888/styles/rg.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/21004998181197492/styles/rg2.css" type="text/css" rel="stylesheet"/>
<!--[if lt IE 9]><link href="//c5.rgstatic.net/m/238176252723686/styles/ie.css" type="text/css" rel="stylesheet"/><![endif]-->
<link href="//c5.rgstatic.net/m/217752362214895/styles/modules/publicprofile.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/21993347442549/styles/pow/publicliterature/FollowPublicationPromo.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/282514599719602/styles/pow/application/PdfJsReader.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/23819663151220/styles/pow/publicliterature/PublicationInlineReader.css" type="text/css" rel="stylesheet"/>
<script src="//c5.rgstatic.net/m/2321000301012716/javascript/vendor/webfontloader/webfontloader.js" type="text/javascript"></script>
 <script>(function(i,s,o,g,r,a,m){i["GoogleAnalyticsObject"]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,"script","//www.google-analytics.com/analytics.js","ga");
 ga("create","UA-58591210-1");ga("set","anonymizeIp",true);ga('set', 'dimension1', 'publication full-text');ga('set', 'dimension2', 'Article');ga('set', 'dimension3', 'Logged out');ga('set', 'dimension4', 'https');ga("send","pageview");</script>
  <script> WebFontConfig = { custom: { families: ['source_sans_pro_italic', 'source_sans_pro_bold', 'source_sans_pro', 'martel'], urls : ['//c5.rgstatic.net/m/231392577336386/styles/fonts.css'] } }; WebFont.load(WebFontConfig); </script><noscript></noscript>

<title>Fixed-Form Variational Posterior Approximation through Stochastic Linear Regression (PDF Download Available)</title>
<meta name="description" content="Official Full-Text Publication: Fixed-Form Variational Posterior Approximation through Stochastic Linear Regression on ResearchGate, the professional network for scientists."/>
<meta name="keywords" content="scientific network, scientific platform, scientific community, research partner, research collaboration, journal articles, international collaboration, find researcher, lifescience researcher, interdisciplinary research, research collaboration"/>
</head>
<body class="use-svg-icons logged-out">
<div id="page-container">
<script type="text/javascript">var googletag = googletag || {}; googletag.cmd = googletag.cmd || [];
(function() { var gads = document.createElement("script"); gads.async = true; gads.type = "text/javascript"; var useSSL = "https:" == document.location.protocol; gads.src = (useSSL ? "https:" : "http:") + "//www.googletagservices.com/tag/js/gpt.js"; var node =document.getElementsByTagName("script")[0]; node.parentNode.insertBefore(gads, node); })();</script><div id="main" class="logged-out-header-support">
<div id="content" class="">

<noscript>
<div class="c-box-warning full-width-element" style="text-align: center; ">
    <div style="margin: auto; padding:10px;" class="container">
        <b>For full functionality of ResearchGate it is necessary to enable JavaScript.
            Here are the <a href="http://www.enable-javascript.com/" rel="nofollow" target="_blank">
                instructions how to enable JavaScript in your web browser</a>.</b>
    </div>
</div>
</noscript>

<div id="rgw1_56ab9eee9ebe9" itemscope itemtype="http://schema.org/ScholarlyArticle"><div class="publication-wrapper publication-wrapper-onecol" id="rgw2_56ab9eee9ebe9" itemscope itemtype="http://schema.org/ScholarlyArticle"> <div class="c-col-content"> <div class="c-content"> <div class="clearfix">  <div class="publication-header"> <div id="rgw5_56ab9eee9ebe9">  <div class="type-label"> Article   </div> <span class="Z3988" title="ctx_ver=Z39.88-2004&rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&rfr_id=info%3Asid%2Fresearchgate.net%3Aresearchgate&rft_id=info%3Adoi%2F10.1214%2F13-BA858&rft.atitle=Fixed-Form%20Variational%20Posterior%20Approximation%20through%20Stochastic%20Linear%20Regression&rft.title=Bayesian%20Analysis&rft.jtitle=Bayesian%20Analysis&rft.volume=8&rft.issue=4&rft.date=2012&rft.issn=1936-0975&rft.au=Tim%20Salimans%2CDavid%20A.%20Knowles&rft.genre=article"></span> <h1 class="pub-title" itemprop="name">Fixed-Form Variational Posterior Approximation through Stochastic Linear Regression</h1> <meta itemprop="headline" content="Fixed-Form Variational Posterior Approximation through Stochastic Linear Regression">  <meta itemprop="image" content="https://i1.rgstatic.net/publication/228083473_Fixed-Form_Variational_Posterior_Approximation_through_Stochastic_Linear_Regression/links/5486e7290cf268d28f062892/smallpreview.png">  <div id="rgw7_56ab9eee9ebe9" class="publication-detail-author-list"> <div> <ul class="clearfix js-people-list">  <li id="rgw8_56ab9eee9ebe9" itemprop="author" itemscope itemtype="http://schema.org/Person"> <a itemprop="sameAs" href="profile/Tim_Salimans" class="pub-detail-item account-item"> <div class="indent-left"> <div class="people-img"> <img  src="https://i1.rgstatic.net/ii/profile.image/AS%3A278933837762578%401443514417931_m" title="Tim Salimans" alt="Tim Salimans" height="20px" width="20px" style="height: 20px;"/> </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Tim Salimans</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item  remove-action-indent   " id="rgw9_56ab9eee9ebe9" data-account-key="Tim_Salimans">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="profile/Tim_Salimans"> <img class="lazyload" data-src="https://i1.rgstatic.net/ii/profile.image/AS%3A278933837762578%401443514417931_l" title="Tim Salimans" alt="Tim Salimans" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">     </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="profile/Tim_Salimans" class="display-name">Tim Salimans</a>    </h5> <div class="truncate-single-line meta">    <span class="meta">Algoritmica</span>    </div>  <a href="javascript:" class="btn btn-promote btn-large people-item-contact-author js-contact-author">Message author</a>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>  <li id="rgw10_56ab9eee9ebe9" itemprop="author" itemscope itemtype="http://schema.org/Person"> <a itemprop="sameAs" href="profile/David_Knowles2" class="pub-detail-item account-item"> <div class="indent-left"> <div class="people-img"> <img  src="https://c5.rgstatic.net/m/2671872220764/images/template/default/profile/profile_default_m.jpg" title="David A. Knowles" alt="David A. Knowles" height="20px" width="20px" style="height: 20px;"/> </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">David A. Knowles</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item  remove-action-indent   " id="rgw11_56ab9eee9ebe9" data-account-key="David_Knowles2">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="profile/David_Knowles2"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="David A. Knowles" alt="David A. Knowles" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">     </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="profile/David_Knowles2" class="display-name">David A. Knowles</a>    </h5> <div class="truncate-single-line meta">   <a class="meta ga-top-coauthor-institution" href="institution/Stanford_University" title="Stanford University">Stanford University</a>     </div>  <a href="javascript:" class="btn btn-promote btn-large people-item-contact-author js-contact-author">Message author</a>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>   </ul> <div class="js-loading"></div>  </div> </div> <div class="pub-details js-pub-details">     Bayesian Analysis   <meta itemprop="datePublished" content="2012-06">  06/2012;  8(4).    DOI:&nbsp;10.1214/13-BA858           <div class="pub-source"> Source: <a href="http://arxiv.org/abs/1206.6679" rel="nofollow">arXiv</a> </div>  </div> <div id="rgw12_56ab9eee9ebe9" class="pub-abstract">  <div class="clearfix">   <p itemprop="description"> <strong>ABSTRACT</strong> <div>We propose a general algorithm for approximating nonstandard Bayesian<br />
posterior distributions. The algorithm minimizes the Kullback-Leibler<br />
divergence of an approximating distribution to the intractable posterior<br />
distribution. Our method can be used to approximate any posterior distribution,<br />
provided that it is given in closed form up to the proportionality constant.<br />
The approximation can be any distribution in the exponential family or any<br />
mixture of such distributions, which means that it can be made arbitrarily<br />
precise. Several examples illustrate the speed and accuracy of our<br />
approximation method in practice.</div> </p>  </div>   </div>      <div class="action-container"> <div id="rgw13_56ab9eee9ebe9" class="follow-publication-promo"> <table> <tr> <td class="follow-publication-promo-text-cell"> <p>Get notified about updates to this publication</p> <a class="btn btn-large btn-promote js-follow-publication ga-follow-publication-new-promo">Follow publication</a> </td> <td> <div class="follow-publication-publication-image"></div> </td> </tr> </table> </div>  <div class="clear"></div> <div class="share-dialog-container" style="display: none;">  </div> </div> </div> <div style="margin-left: -20px; margin-right: -20px;">  </div> </div>  <div class="publication-detail-dfp-container rf"> <div id="rgw28_56ab9eee9ebe9">  </div> </div>  </div>  <div class="clearfix"> <div class="pdf-js-container clearfix " id="rgw29_56ab9eee9ebe9">  <div class="pdf-js-header js-sticky-header clear">  <a class="blue-link js-download rf btn btn-promote" href="https://www.researchgate.net/profile/Tim_Salimans/publication/228083473_Fixed-Form_Variational_Posterior_Approximation_through_Stochastic_Linear_Regression/links/5486e7290cf268d28f062892.pdf?inViewer=0&amp;pdfJsDownload=0&amp;origin=publication_detail">Download full-text</a>  <h3>Full-text</h3> <span class="publication-info">  <span class="js-doi-container" style="display: none;"> DOI: <span class="js-doi"></span> &middot; </span> Available from: <a class="js-name" href="profile/Tim_Salimans">Tim Salimans</a>, <span class="js-publication-date"> Dec 09, 2014 </span>   </span>  <select class="publication-version-select rf js-publication-version-select" data-placeholder="View other sources"> <option> </option>  <optgroup label="Tim Salimans"> <option value="https://www.researchgate.net/profile/Tim_Salimans/publication/228083473_Fixed-Form_Variational_Posterior_Approximation_through_Stochastic_Linear_Regression/links/5486e7290cf268d28f062892.pdf?inViewer=0&amp;pdfJsDownload=0&amp;origin=publication_detail"  data-date="Dec 09, 2014 " data-name="Tim Salimans" data-hash="de0c096904c4b25d8294e4eaead550a5" data-viewer-url="https://www.researchgate.net/profile/Tim_Salimans/publication/228083473_Fixed-Form_Variational_Posterior_Approximation_through_Stochastic_Linear_Regression/links/5486e7290cf268d28f062892.pdf?inViewer=1&amp;pdfJsDownload=1&amp;origin=publication_detail" data-name-link="profile/Tim_Salimans" data-link-id="5486e7290cf268d28f062892"> euclid.ba.1386166315.pdf (585.68 KB) </option> </optgroup>  <optgroup label="Tim Salimans"> <option value="https://www.researchgate.net/profile/Tim_Salimans/publication/228083473_Fixed-Form_Variational_Posterior_Approximation_through_Stochastic_Linear_Regression/links/544f7c230cf26dda089103c3.pdf?inViewer=0&amp;pdfJsDownload=0&amp;origin=publication_detail"  data-date="Oct 28, 2014 " data-name="Tim Salimans" data-hash="04724e639aa5175343ffb84936975ea9" data-viewer-url="https://www.researchgate.net/profile/Tim_Salimans/publication/228083473_Fixed-Form_Variational_Posterior_Approximation_through_Stochastic_Linear_Regression/links/544f7c230cf26dda089103c3.pdf?inViewer=1&amp;pdfJsDownload=1&amp;origin=publication_detail" data-name-link="profile/Tim_Salimans" data-link-id="544f7c230cf26dda089103c3">  (585.84 KB) </option> </optgroup>  </select>  </div>  <div class="social-share-container"><div id="rgw31_56ab9eee9ebe9" class="social-share js-social-share"> <div class="social-share-heading">Share</div>  <a id="rgw32_56ab9eee9ebe9" href="javascript:" title="Share on Facebook" class="link-nostyle js-share-item share-icon "  data-url="http://www.facebook.com/share.php?u={{url}}{{#title}}&amp;t={{title}}{{/title}}" data-width="600" data-height="350" data-name="Facebook"> <span class="share-icon ico-share-facebook-round reset-background ga-share-blog-facebook"></span> </a>  <a id="rgw33_56ab9eee9ebe9" href="javascript:" title="Share on Twitter" class="link-nostyle js-share-item share-icon "  data-url="http://twitter.com/intent/tweet?text={{#title}}{{title}}: {{/title}}{{url}}&amp;via=researchgate" data-width="600" data-height="350" data-name="Twitter"> <span class="share-icon ico-share-twitter-round reset-background ga-share-blog-twitter"></span> </a>  <a id="rgw34_56ab9eee9ebe9" href="javascript:" title="Share on Google+" class="link-nostyle js-share-item share-icon "  data-url="https://plus.google.com/share?url={{url}}" data-width="600" data-height="600" data-name="Google+"> <span class="share-icon ico-share-gplus-round reset-background ga-share-blog-gplus"></span> </a>  <a id="rgw35_56ab9eee9ebe9" href="javascript:" title="Share on LinkedIn" class="link-nostyle js-share-item share-icon "  data-url="http://www.linkedin.com/shareArticle?mini=true&amp;url={{url}}{{#title}}&amp;title={{title}}{{/title}}&amp;source=ResearchGate" data-width="520" data-height="570" data-name="LinkedIn"> <span class="share-icon ico-share-linkedin-round reset-background ga-share-blog-linkedin"></span> </a>  <a id="rgw36_56ab9eee9ebe9" href="javascript:" title="Share on Reddit" class="link-nostyle js-share-item share-icon "  data-url="https://www.reddit.com/submit?url={{url}}{{#title}}&amp;title={{title}}{{/title}}" data-width="600" data-height="600" data-name="Reddit"> <span class="share-icon ico-share-reddit reset-background ga-share-blog-reddit"></span> </a>  </div></div>    <iframe id="rgw30_56ab9eee9ebe9" src="https://www.researchgate.net/c/o1q2er/javascript/lib/pdfjs/web/viewer.html?file=https%3A%2F%2Fwww.researchgate.net%2Fprofile%2FTim_Salimans%2Fpublication%2F228083473_Fixed-Form_Variational_Posterior_Approximation_through_Stochastic_Linear_Regression%2Flinks%2F5486e7290cf268d28f062892.pdf%3FinViewer%3D1%26pdfJsDownload%3D1%26origin%3Dpublication_detail" allowfullscreen frameborder="0" style="width: 100%; height: 100%; box-sizing: border-box;"></iframe>    </div> <noscript> <div id="rgw27_56ab9eee9ebe9"  itemprop="articleBody">  <p>Page 1</p> <p>Bayesian Analysis (2013)8, Number 4, pp. 837–882<br />Fixed-Form Variational Posterior Approximation<br />through Stochastic Linear Regression<br />Tim Salimans∗and David A. Knowles†<br />Abstract.<br />Bayesian posterior distributions. The algorithm minimizes the Kullback-Leibler<br />divergence of an approximating distribution to the intractable posterior distribu-<br />tion. Our method can be used to approximate any posterior distribution, provided<br />that it is given in closed form up to the proportionality constant. The approxi-<br />mation can be any distribution in the exponential family or any mixture of such<br />distributions, which means that it can be made arbitrarily precise. Several exam-<br />ples illustrate the speed and accuracy of our approximation method in practice.<br />We propose a general algorithm for approximating nonstandard<br />Keywords: variational Bayes, approximate inference, stochastic approximation<br />1 Introduction<br />In Bayesian analysis the form of the posterior distribution is often not analytically<br />tractable. To obtain quantities of interest under such a distribution, such as moments<br />or marginal distributions, we typically need to use Monte Carlo methods or approxi-<br />mate the posterior with a more convenient distribution. A popular method of obtaining<br />such an approximation is structured or fixed-form Variational Bayes, which works by<br />numerically minimizing the Kullback-Leibler divergence of an approximating distribu-<br />tion in the exponential family to the intractable target distribution (Attias 2000; Beal<br />and Ghahramani 2006; Jordan et al. 1999; Wainwright and Jordan 2008). For certain<br />problems, algorithms exist that can solve this optimization problem in much less time<br />than it would take to approximate the posterior using Monte Carlo methods (see e.g.<br />Honkela et al. 2010). However, these methods usually rely on analytic solutions to<br />certain integrals and need conditional conjugacy in the model specification, i.e. the<br />distribution of each variable conditional on its Markov blanket must be an analytically<br />tractable member of the exponential family for these methods to be applicable. As a<br />result this class of methods is limited in the type of approximations and posteriors they<br />can handle.<br />We show that solving the optimization problem of fixed-form Variational Bayes is equiv-<br />alent to performing a linear regression with the sufficient statistics of the approximation<br />as explanatory variables and the (unnormalized) log posterior density as the dependent<br />variable. Inspired by this result, we present an efficient stochastic approximation algo-<br />rithm for solving this optimization problem. In contrast to earlier work, our approach<br />does not require any analytic calculation of integrals, which allows us to extend the<br />∗Erasmus University Rotterdam salimanstim@gmail.com<br />†Stanford University<br />© 2013 International Society for Bayesian AnalysisDOI:10.1214/13-BA858</p>  <p>Page 2</p> <p>838 VB through Stochastic Regression<br />fixed-form Variational Bayes approach to problems where it was previously not applica-<br />ble. Our method can be used to approximate any posterior distribution, provided that<br />it is given in closed form up to the proportionality constant. The type of approximating<br />distribution can be any distribution in the exponential family or any mixture of such<br />distributions, which means that our approximations can in principle be made arbitrarily<br />precise. While our method somewhat resembles performing stochastic gradient descent<br />on the variational objective function in parameter space (Paisley et al. 2012; Nott et al.<br />2012), the linear regression view gives insights which allow a more computationally<br />efficient approach.<br />Section 2 introduces fixed-form variational posterior approximation, the optimization<br />problem to be solved, and the notation used in the remainder of the paper. In Sec-<br />tion 3 we provide a new way of looking at variational posterior approximation by re-<br />interpreting the underlying optimization as a linear regression problem. We propose a<br />stochastic approximation algorithm to perform the optimization in Section 4. In Sec-<br />tion 5 we discuss how to assess the quality of our posterior approximations and how to<br />use the proposed methods to approximate the marginal likelihood of a model. These<br />sections represent the core ideas of the paper.<br />To make our approach more generally applicable and computationally efficient we pro-<br />vide a number of extensions in two separate sections. Section 6 discusses modifications<br />of our stochastic approximation algorithm to improve efficiency. Section 7 relaxes the<br />assumption that our posterior approximation is in the exponential family, allowing in-<br />stead mixtures of exponential family distributions. Sections 4, 6, and 7 also contain<br />multiple examples of using our method in practice, and show that despite its generality,<br />the efficiency of our algorithm is highly competitive with more specialized approaches.<br />Code for these examples is available at github.com/TimSalimans/LinRegVB. Finally,<br />Section 8 concludes.<br />2 Fixed-form Variational Bayes<br />Let x be a vector of unknown parameters and/or latent random effects for which we<br />have specified a prior distribution p(x), and let p(y|x) be the likelihood of observing a<br />given set of data, y. Upon observing y we can use Bayes’ rule to obtain our updated<br />state of belief, the posterior distribution<br />p(x|y) =p(x,y)<br />p(y)<br />=<br />p(y|x)p(x)<br />?p(y|x)p(x)dx.<br /><br />(1)<br />An equivalent definition of the posterior distribution is<br />p(x|y) = argmin<br />q(x)Eq(x)<br />„<br />log<br />q(x)<br />p(x,y)<br />= argmin<br />q(x)D[q(x)|p(x|y)], (2)<br />where the optimization is over all proper probability distributions q(x), and where<br />D[q(x)|p(x|y)] denotes the Kullback-Leibler divergence between q(x) and p(x|y). The</p>  <p>Page 3</p> <p>T. Salimans and D. A. Knowles 839<br />KL-divergence is always non-negative and has a unique minimizing solution q(x) =<br />p(x|y) almost everywhere, at which point the KL-divergence is zero. The solution of (2)<br />does not depend on the normalizing constant p(y) of the posterior distribution.<br />The posterior distribution given in (1) is the exact solution of the variational optimiza-<br />tion problem in (2), but except for certain special cases it is not very useful by itself<br />because it does not have an analytically tractable form. This means that we do not<br />have analytic expressions for the posterior moments of x, or for the marginals p(xi|y)<br />of the multivariate posterior distribution, nor can we determine the normalizing con-<br />stant p(y). One method of solving this problem is to approximate these quantities using<br />Monte Carlo simulation. A different approach, which we will pursue here, is to restrict<br />the optimization problem in (2) to a reduced set of more convenient distributions Q.<br />If p(x,y) is of conjugate exponential form, choosing Q to be the set of factorized dis-<br />tributions q(x) = q(x1)q(x2)...q(xk) often leads to a tractable optimization problem<br />that can be solved efficiently using an algorithm called Variational Bayes Expectation<br />Maximization (VBEM, Beal and Ghahramani 2002). Such a factorized solution is at-<br />tractive because it makes the variational optimization problem easy to solve, but it is<br />also very restrictive: it requires a conjugate exponential model and prior specification<br />and it assumes posterior independence between the different blocks of parameters xi.<br />This means that this factorized approach can be used with few models, and that the<br />solution q(x) may be a poor approximation to the exact posterior (see e.g. Turner et al.<br />2008).<br />An alternative choice for Q is the set of distributions of a certain parametric form qη(x),<br />where η denotes the vector of parameters governing the shape of the posterior approxi-<br />mation. This approach is known as structured or fixed-form Variational Bayes (Honkela<br />et al. 2010; Storkey 2000; Saul and Jordan 1996). Usually, the posterior approximation<br />is chosen to be a specific member of the exponential family of distributions:<br />qη(x) = exp[T(x)η − U(η)]ν(x), (3)<br />where T(x) is a 1 × k vector of sufficient statistics, U(η) takes care of normalization,<br />and ν(x) is a base measure. The k ×1 vector η is often called the set of natural param-<br />eters of the exponential family distribution qη(x). Using this approach, the variational<br />optimization problem in (2) reduces to a parametric optimization problem in η:<br />ˆ η = argmin<br />η<br />Eqη(x)[logqη(x) − logp(x,y)].(4)<br />If our posterior approximation is of an analytically tractable form, the negative entropy<br />term Eq(x)[logq(x)] in (4) can often be evaluated analytically. If we can then also deter-<br />mine Eq(x)[logp(x,y)] and its derivatives with respect to η, the optimization problem<br />can be solved using gradient-based optimization or fixed-point algorithms. Posterior<br />approximations of this type are often much more accurate than a factorized approxima-<br />tion, but the requirement of being able to evaluate Eq(x)[logq(x)] and Eq(x)[logp(x,y)]<br />analytically is very restrictive. In addition, approximations of this type generally do not</p>  <p>Page 4</p> <p>840VB through Stochastic Regression<br />allow us to use the fast EM type optimization algorithms often used with factorized ap-<br />proximations (see Bishop 2006, Ch. 10). In the next section, we draw a parallel between<br />the optimization problem of variational Bayes and linear regression, which allows us to<br />develop a new optimization algorithm that pushes back these limitations significantly.<br />3 Variational Bayes as linear regression<br />For notational convenience we will write our posterior approximation in the adjusted<br />form,<br />˜ q˜ η(x) = exp[˜T(x)˜ η]ν(x), (5)<br />where we have removed the normalizer U(η), and we have replaced it by adding a<br />constant to the vector of sufficient statistics, i.e.˜T(x) = (1,T(x)) and ˜ η = (η0,η?)?. If<br />η0is equal to −U(η), (5) describes the same family of (normalized) distribution functions<br />as (3). If η0is different from −U(η) then (5) describes a rescaled (unnormalized) version<br />of this distribution function.<br />To work with ˜ q˜ η(x), we use the unnormalized version of the KL-divergence, which is<br />given by<br />?<br />= exp[˜T(x)˜ η][˜T(x)˜ η − logp(x,y)]dν(x) −<br />D[˜ q˜ η(x)|p(x,y)] =˜ q˜ η(x)log<br />˜ q˜ η(x)<br />p(x,y)dν(x) −<br />?<br />˜ q˜ η(x)dν(x) (6)<br />??<br />exp[˜T(x)˜ η]dν(x).<br />At the minimum this gives η0= Eq[logp(x,y) − logq(x)] − U(η) as shown in Appendix<br />A. The other parameters η have the same minimum as in the normalized case.<br />Taking the gradient of (6) with respect to the natural parameters ˜ η we have<br />?<br />Setting this expression to zero in order to find the minimum gives<br />„?<br />or in its normalized form<br />∇˜ ηD[˜ q˜ η(x)|p(x,y)] =˜ q˜ η(x)[˜T(x)?˜T(x)˜ η −˜T(x)?logp(x,y)]dν(x). (7)<br />˜ η =˜ q˜ η(x)˜T(x)?˜T(x)dν(x)<br />−1„?<br />˜ q˜ η(x)˜T(x)?logp(x,y)dν(x)<br /><br />, (8)<br />˜ η = Eq[˜T(x)?˜T(x)]−1Eq[˜T(x)?logp(x,y)].(9)<br />We have implicitly assumed that the Fisher information matrix, Eq[˜T(x)?˜T(x)] is non-<br />singular, which will be the case for any identifiable approximating exponential family<br />distribution q. Our key insight is to notice the similarity between (9) and the maximum<br />likelihood estimator for linear regression. Recall that in classical linear regression we</p>  <p>Page 5</p> <p>T. Salimans and D. A. Knowles 841<br />have that the dependent variable {yn∈ R : n = 1,..,N} is distributed as N(Y |Xβ,σ2I)<br />where X is the N ×D design matrix, β is the D×1 vector of regression coefficients and<br />σ2is the noise variance. The maximum likelihood estimator for β is then<br />ˆβ = (X?X)−1X?Y. (10)<br />To see the relation between (9) and (10), associate the design matrix X with the<br />sufficient statistics˜T, the dependent variable Y with the unnormalized log posterior<br />logp(x,y), and the regression coefficients β with the vector of natural parameters ˜ η. If<br />we then consider Monte Carlo estimates of the expectations in (9) the analogy is very<br />fitting indeed. A similar analogy is used by Richard and Zhang (2007) in the context<br />of importance sampling. Appendix C discusses the connection between their work and<br />ours.<br />In (9), unlike (10), the right-hand side depends on the unknown parameters, η. This<br />means that (9) in itself does not constitute a solution to our variational optimiza-<br />tion problem. In the next section, we introduce a stochastic approximation algorithm<br />to perform this optimization, without requiring the expectations Eq[˜T(x)?˜T(x)] and<br />Eq[˜T(x)?logp(x,y)] to be computable analytically. This allows us to extend the fixed-<br />form Variational Bayes approach to situations in which it was previously not applicable.<br />The only requirements we impose on logp(x,y) is that it is given in closed form. The<br />main requirement on qη(x) is that we can sample from it. For simplicity, Sections 4, 5<br />and 6 will also assume that qη(x) is in the exponential family. Section 7 will then show<br />how we can extend this to include mixtures of exponential family distributions. By<br />using these mixtures and choosing qη(x) to be of a rich enough type, we can in principle<br />make our approximation arbitrarily precise.<br />4 A stochastic approximation algorithm<br />The link between variational Bayes and linear regression in itself is interesting, but it<br />does not yet provide us with a solution to the variational optimization problem of (4).<br />We propose solving this optimization problem by viewing (9) as a fixed point update. Let<br />C = Eq[˜T(x)?˜T(x)] and g = Eq[˜T(x)?logp(x,y)] so that (9) can be written ˜ η = C−1g.<br />We iteratively approximate C and g by weighted Monte Carlo, drawing a single sample<br />x∗<br />update equations<br />tfrom the current posterior approximation qηt(x) at each iteration t, and using the<br />gt+1= (1 − w)gt+ wˆ gt<br />Ct+1= (1 − w)Ct+ wˆCt<br />(11)<br />for some w ∈ [0,1] where ˆ gt=˜T(x∗<br />downweights earlier iterations when q was less accurate. The parameters are updated as<br />˜ ηt+1= C−1<br />Pseudocode is shown in Algorithm 1.<br />t)?logp(x∗<br />t,y) andˆCt=˜T(x∗<br />t)?˜T(x∗<br />t). Equation 11<br />t+1gt+1. w is chosen to be small enough to ensure convergence of the algorithm.</p>  <p>Page 6</p> <p>842VB through Stochastic Regression<br />Algorithm 1 Stochastic Optimization for Fixed-Form Variational Bayes<br />Require: An unnormalized posterior distribution p(x,y)<br />Require: A type of approximating posterior qη(x)<br />Require: The total number of iterations N<br />Initialize ˜ η1to a first guess, for example by matching the prior p(x)<br />Initialize C1= Eqη1[˜T(x)?˜T(x)], or a diagonal approximation of this matrix<br />Initialize g1= C1˜ η1<br />Initialize¯C = 0<br />Initialize ¯ g = 0<br />Set step-size w = 1/?N<br />for t = 1 : N do<br />Simulate a draw x∗<br />Set ˆ gt=˜T(x∗<br />SetˆCt=˜T(x∗<br />Set gt+1= (1 − w)gt+ wˆ gt<br />Set Ct+1= (1 − w)Ct+ wˆCt<br />Set ˜ ηt+1= C−1<br />if t &gt; N/2 then<br />Set ¯ g = ¯ g + ˆ gt<br />Set¯C =¯C +ˆCt<br />end if<br />end for<br />return ˆ η =¯C−1¯ g<br />tfrom the current approximation qηt(x)<br />t)?logp(x∗<br />t)?˜T(x∗<br />t,y), or another unbiased estimate of Eqηt[˜T(x)?logp(x,y)]<br />t), or another unbiased estimate of Eqηt[˜T(x)?˜T(x)]<br />t+1gt+1<br />Algorithm 1 is inspired by a long line of research on stochastic approximation, starting<br />with the seminal work of Robbins and Monro (1951).<br />considered a relatively standard stochastic gradient descent algorithm. At each iteration<br />we have ˜ ηt= C−1<br />Up to first order it can be<br />t gt, which we then update to<br />˜ ηt+1= C−1<br />t+1gt+1= [(1 − w)Ct+ wˆCt]−1[(1 − w)gt+ wˆ gt] = [Ct+ λˆCt]−1[gt+ λˆ gt],<br />where ˆ gtandˆCtare the stochastic estimates generated during iteration t, w is the step-<br />size in our algorithm, and λ = w/(1−w) is the effective step-size as it is usually defined<br />in the stochastic approximation literature. To characterize this update for small values<br />of λ we perform a first order Taylor expansion of ˜ ηt+1around λ = 0, which gives<br />˜ ηt+1= ˜ ηt− λC−1<br />t (ˆCt˜ ηt− ˆ gt) + O(λ2). (12)<br />Comparison with (7) shows that the stochastic term in this expression (ˆCt˜ ηt− ˆ gt) is<br />an unbiased estimate of the gradient of the KL-divergence D[qηt(x)|p(x,y)]. Up to first<br />order, the update equation in (12) thus represents a stochastic gradient descent step,<br />pre-conditioned with the C−1<br />t<br />matrix. Since this pre-conditioner is independent of the<br />stochastic gradient approximation at iteration t, this gives a valid adaptive stochastic<br />gradient descent algorithm, to which all the usual convergence results apply (see e.g.<br />Amari 1997).</p>  <p>Page 7</p> <p>T. Salimans and D. A. Knowles843<br />If we take small steps, the pre-conditioner C−1<br />metric EqtˆCt = Eqt[˜T(x)?˜T(x)] used in natural gradient descent algorithms like that<br />of Honkela et al. (2010) and Hoffman et al. (2012). For certain exponential family<br />distributions this metric can be calculated analytically, which would suggest performing<br />stochastic natural gradient descent optimization with updates of the form<br />´<br />where the Eqt[˜T(x)?logp(x,y)] term is approximated using Monte Carlo, but the pre-<br />conditioner Eqt[˜T(x)?˜T(x)] is calculated analytically. At first glance, our approach of<br />approximating Eqt[˜T(x)?˜T(x)] using Monte Carlo only seems to add to the randomness<br />of the gradient estimate, and using the same random numbers to approximate both<br />Eqt[˜T(x)?logp(x,y)] and Eqt[˜T(x)?˜T(x)] leads to biased pre-conditioned gradient ap-<br />proximations at that (although that bias disappears as λ → 0). However, it turns out<br />that approximating both terms using the same random draws increases the efficiency of<br />our algorithm dramatically. The reason for this is analogous to the reason for why the<br />optimal estimator in linear regression is given by (X?X)−1X?y and not E[X?X]−1X?y:<br />by using the same randomness for both the X?X and X?y terms, a large part of the<br />noise in their product cancels out.<br />t<br />in (12) will be close to the Riemannian<br />˜ ηt+1= ˜ ηt− λ˜ ηt− Eqt[˜T(x)?˜T(x)]−1[˜T(x∗)?logp(x∗,y)]<br />¯<br />,<br />A particularly interesting example of this is when the true posterior distribution is<br />of the same functional form as its approximation, say p(x,y) = exp[˜T(x)ξ], in which<br />case Algorithm 1 will recover the true posterior exactly in 2(k + 1) iterations, with<br />k the number of sufficient statistics in q and p.<br />x∗<br />surely for continuous distributions q), we have<br />˜2k+2<br />t=k+2<br />˜2k+2<br />t=k+2<br />Assuming the last k + 1 samples<br />t,t = k + 2,...,2k + 2 generated by our algorithm are unique (which holds almost<br />ˆ η=<br />?<br />?<br />˜T(x∗<br />t)?˜T(x∗<br />t)<br />¸−12k+2<br />t=k+2<br />¸−12k+2<br />t=k+2<br />?<br />?<br />˜T(x∗<br />t)?log[p(x∗<br />t,y)]<br />=<br />˜T(x∗<br />t)?˜T(x∗<br />t)<br />˜T(x∗<br />t)?˜T(x∗<br />t)ξ = ξ.(13)<br />If the algorithm is run for additional iterations after the true posterior is recovered, the<br />approximation will not change. This is to be contrasted with other stochastic gradient<br />descent algorithms which have non-vanishing variance for a finite number of samples,<br />and is due to the fact that our regression in itself is noise free: only its support points are<br />stochastic. This exact convergence will not hold for cases of actual interest, where p and<br />q will not be of the exact same functional form, but we generally still observe a dramatic<br />improvement when using Algorithm 1 instead of more conventional stochastic gradient<br />descent algorithms. A deeper analysis of the variance of our stochastic approximation<br />is given in Appendix D.<br />Contrary to most applications in the literature, Algorithm 1 uses a fixed step size<br />w = 1/?N rather than a declining one in updating our statistics. The analyses of</p>  <p>Page 8</p> <p>844VB through Stochastic Regression<br />Robbins and Monro (1951) and Amari (1997) show that a sequence of learning rates<br />wt = ct−1is asymptotically efficient in stochastic gradient descent as the number of<br />iterations N goes to infinity, but this conclusion rests on strong assumptions on the<br />functional form of the objective function (e.g. strong convexity) that are not satisfied<br />for the problems we are interested in. Moreover, with a finite number of iterations, the<br />effectiveness of a sequence of learning rates that decays this fast is highly dependent on<br />the proportionality constant c. If we choose c either too low or too high, it may take a<br />very long time to reach the efficient asymptotic regime of this learning rate sequence.<br />Nemirovski et al. (2009) show that a more robust approach is to use a constant learning<br />rate w = 1/?N and that this is optimal for finite N without putting stringent require-<br />ments on the objective function. In order to reduce the variance of the last iterate with<br />this non-vanishing learning rate, they propose to use an average of the last L iterates<br />as the final output of the optimization algorithm. The value of L should grow with<br />the total number of iterations, and is usually chosen to be equal to N/2. Remarkably,<br />they show that such an averaging procedure can match the asymptotic efficiency of the<br />optimal learning sequence wt= ct−1.<br />For our particular optimization problem we have observed excellent results using con-<br />stant learning rate w = 1/?N, and averaging starting half-way into the optimization.<br />We perform this averaging on the statistics g and C, rather than on the parameters<br />˜ η = C−1g, which is necessary to remove the bias caused by forming g and C using<br />the same random numbers. As previously described, using this set-up gt and Ct are<br />actually weighted MC estimates where the weight of the j-th MC sample during the t-th<br />iteration (j ≤ t) is given by w(1 − w)t−j. Since w ∈ (0,1), this means that the weight<br />of earlier MC samples declines as the algorithm advances, which is desirable since we<br />expect q to be closer to optimal later in the algorithm’s progression.<br />If the initial guess for ˜ η is very far from the optimal value, or if the number of steps<br />N is very small, it can sometimes occur that the algorithm proposes a new value for ˜ η<br />that does not define a proper distribution, for example because the proposed ˜ η value<br />corresponds to a negative variance. This is a sign that the number of iterations should<br />be increased: since our algorithm becomes a pre-conditioned gradient descent algorithm<br />as the number of steps goes to infinity, the algorithm is guaranteed to converge if the<br />step size is small enough. In addition, the exact convergence result presented in (13)<br />suggests that divergence is very unlikely if qη(x) and p(x,y) are close in functional form:<br />choosing a good approximation will thus also help to ensure fast convergence. Picking a<br />good first guess for ˜ η also helps the algorithm to converge more quickly. For very difficult<br />cases it might therefore be worthwhile to base this guess on a first rough approximation<br />of the posterior, for example by choosing ˜ η to match the curvature of logp(x,y) at its<br />mode. For all our applications we found that a simple first guess for ˜ η and a large<br />enough number of iterations was sufficient to guarantee a stable algorithm. Our default<br />implementation of Algorithm 1 is therefore to initialize ˜ η to (an approximation of) the<br />prior, and to increase the number of iterations until the algorithm is sufficiently stable.</p>  <p>Page 9</p> <p>T. Salimans and D. A. Knowles845<br />Like other optimization algorithms for Variational Bayes, Algorithm 1 will only find a<br />local minimum of the KL-divergence. This is generally not a problem when approxi-<br />mating unimodal posterior distributions, such as with the examples in this paper, since<br />the optimization problem then often only has a single optimum (depending on the type<br />of approximation, see Bishop 2006, Ch. 10). If the true posterior distribution is multi-<br />modal and the approximation is unimodal, however, the variational approximation will<br />tend to pick one of the posterior modes and ignore the others (Minka 2005). Although<br />this is often desirable (see e.g. Stern et al. 2009), there is no guarantee that the recovered<br />local minimum of the KL-divergence is then also a global minimum.<br />Example: Fitting an exponential distribution<br />It is instructive to consider a toy example: approximating an exponential distribution<br />p(x) = λe−λxwith a variational approximation of the same functional form. We assume<br />that we are unaware that p happens to be normalized. Our variational approximation<br />has˜T = [1,x] and rate η, i.e. q(x) = ηe−ηx. Since the functional form of the variational<br />posterior matches the true posterior, (13) holds and Algorithm 1 will recover η to<br />machine precision in just 2(k+1) = 4 iterations. We contrast this with the performance<br />if two different strategies are used to estimate ˆ gtandˆCtin Algorithm 1: i) a different<br />random draw x∗is used for ˆ gtandˆCt, ii)ˆCtis calculated analytically using<br />„<br />These seemingly similar alternatives perform dramatically worse than Algorithm 1. We<br />set the true λ := 2, and initialize η := 1 and C := I2, the identity matrix. Figure 1 shows<br />the mean and variance of the estimates of log(η) across 100 repeat runs of each method<br />with varying number of iterations N. We see it takes option i (“different randomness”)<br />and ii (“analytic”) well over 1000 iterations to give a reasonable answer, and even with<br />N = 104samples, option i) estimates ˆ η = 2.04 ± 0.15 and option ii) 2.01 ± 0.11.<br />Eq[˜T(x)?˜T(x)] =<br />1<br />−η−1<br />η−2<br />−η−1<br /><br />. (14)<br />10<br />1<br />10<br />2<br />10<br />3<br />10<br />4<br />−2<br />−1<br />0<br />1<br />2<br />3<br />4<br />iterations, N<br />log(eta)<br /> <br /> <br />analytic<br />different<br />same randomness<br />Figure 1:<br />methods for estimating ˆ gt andˆCt<br />in Algorithm 1 on a toy example:<br />approximating an exponential pos-<br />terior with an approximation of the<br />same functional form. Solid lines<br />show the means of the recovered<br />parameters over 100 repeat runs,<br />and dashed lines show ± one stan-<br />dard deviation.<br />random draw to estimate ˆ gtandˆCt<br />(our proposed method) gives exact<br />convergence in N = 4 iterations<br />Comparing alternative<br />Using the same</p>  <p>Page 10</p> <p>846VB through Stochastic Regression<br />5 Marginal likelihood and approximation quality<br />The stochastic approximation algorithm presented in the last section serves to minimize<br />the Kullback-Leibler divergence between qη(x) and p(x|y), given by<br />„<br />D(qη|p) = Eqη<br />logqη(x)<br />p(x|y)<br /><br />= Eqη<br />„<br />logqη(x)<br />p(x,y)<br /><br />+ logp(y).<br />As discussed before, we do not need to know p(y) (the marginal likelihood) in order to<br />minimize D(qη|p) as p(y) does not depend on η, but we do need to know it if we want to<br />determine the quality of the approximation, as measured by the final Kullback-Leibler<br />divergence. In addition, the constant p(y) is also essential for performing Bayesian model<br />comparison or model averaging. This section presents a method for approximating the<br />marginal likelihood and final Kullback-Leibler divergence.<br />When our algorithm has converged, we have the following identity<br />logp(x,y) = ˆ η0+ T(x)η + r(x) = ˆ η0+ U(η) + logqη(x) + r(x), (15)<br />where r(x) is the ‘residual’ or ‘error term’ in the linear regression of logp(x,y) on the<br />sufficient statistics of qη(x), and where U(η) is the normalizer of qη(x). The intercept<br />of the regression is<br />ˆ η0= Eqηrlogp(x,y) − logqη(x)s − U(η),<br />where Eqηrlogp(x,y) − logqη(x)s = ˆ η0+U(η) may be recognized as the usual VB lower<br />bound on the log marginal likelihood. Exponentiating (15) yields<br />p(x,y) = exp[ˆ η0+ U(η)]qη(x)exp(r(x)),<br />which we need to integrate with respect to x in order to find the marginal likelihood<br />p(y). Doing so gives<br />p(y) = exp[ˆ η0+ U(η)]Eqη[exp(r(x))]. (16)<br />At convergence we have that Eqη[r(x)] = 0. Jensen’s inequality then tells us that<br />Eqη[exp(r(x))] ≥ 1,<br />so that ˆ η0+U(η) is indeed a lower bound on the log marginal likelihood. If our approx-<br />imation is perfect, the KL-divergence is zero and r(x) is zero almost everywhere. In<br />that case the residual term vanishes and the lower bound will be tight, otherwise it will<br />underestimate the true marginal likelihood. The lower bound ˆ η0+ U(η) is often used<br />in model comparison, which works well if the KL-divergence between the approximate<br />and true posterior distribution is of approximately the same size for all models that<br />are being compared. However, if we compare two very different models this will often<br />not be the case, and the model comparison will be biased as a result. In addition, as<br />opposed to the exact marginal likelihood, the lower bound gives us no information on</p>  <p>Page 11</p> <p>T. Salimans and D. A. Knowles 847<br />the quality of our posterior approximation. It would therefore be useful to obtain a<br />better estimate of the marginal likelihood.<br />One approach to doing this would be to evaluate the expectation in (16) using Monte<br />Carlo sampling. Some analysis shows that this corresponds to approximating p(y)<br />using importance sampling, with qη(x) as the candidate distribution. It is well known<br />that this estimator of the marginal likelihood may have infinite variance, unless r(x) is<br />bounded from above (see e.g. Geweke 2005, p. 114). In general, we cannot guarantee the<br />boundedness of r(x) for our approach, so we will instead approximate the expectation<br />in (16) using something that is easier to calculate.<br />At convergence, we know that the mean of r(x) is zero when sampling from qη(x). The<br />variance of r(x) can be estimated using the mean squared error of the regressions we<br />perform during the optimization, with relatively low variance. We denote our estimate<br />of this variance by s2. The assumption we will then make in order to approximate<br />logp(y) is that r(x) is approximately distributed as a normal random variable with<br />these two moments. This leads to the following simple estimate of the log marginal<br />likelihood<br />logp(y) ≈ ˆ η0+ U(η) +1<br />That is, our estimate of the marginal likelihood is equal to its lower bound plus a<br />correction term that captures the error in our posterior approximation qη(x). Similarly,<br />we can approximate the KL-divergence of our posterior approximation as<br />2s2. (17)<br />D(qη|p) ≈1<br />2s2.<br />The KL-divergence is approximately equal to half the mean squared error in the re-<br />gression of logp(x,y) on the sufficient statistics of the approximation. This relationship<br />should not come as a surprise: this mean squared error is exactly what we minimize<br />when we perform linear regression.<br />The scale of the KL-divergence is highly dependent on the amount of curvature in<br />logp(x|y) and is therefore not easily comparable across different problems. If we scale<br />the approximate KL-divergence to account for this curvature, this naturally leads to<br />the R-squared measure of fit for regression modeling:<br />R2= 1 −<br />s2<br />Varq[logp(x,y)].<br />The R-squared measure corrects for the amount of curvature in the posterior distribution<br />and is therefore comparable across different models and data sets. In addition it is a<br />well-known measure and easily interpretable. We therefore propose to use the R-squared<br />as the measure of approximation quality for our variational posterior approximations.<br />Although we find the R-squared to be a useful measure for the majority of applications,<br />it is important to realize that it mostly contains information about the mass of the</p>  <p>Page 12</p> <p>848VB through Stochastic Regression<br />posterior distribution and its approximation, and not directly about their moments.<br />It is therefore possible to construct pathological examples in which the R-squared is<br />relatively high, yet the (higher) moments of the posterior and its approximation are<br />quite different. This may for example occur if the posterior distribution has very fat<br />tails.<br />Section 7.2 provides an application of the methods developed here. In that section,<br />Figure 6 shows that the approximation of the KL-divergence is quite accurate, especially<br />when the approximation qη(x) is reasonably good. The same figure also shows that the<br />approximation of the marginal likelihood proposed here (17) is much more accurate than<br />the usual lower bound. In Sections 6 and 7, we also calculate the R-squared measure<br />of approximation quality for a number of different posterior approximations, and we<br />conclude that it corresponds well to visual assessments of the approximation accuracy.<br />The discussion up to this point represents the core ideas of this paper. To make our<br />approach more general and computationally efficient we now provide a number of ex-<br />tensions in two separate sections. Section 6 discusses modifications of our stochastic<br />approximation algorithm to improve efficiency, and Section 7 generalizes the exponen-<br />tial family approximations q(x) used so far to include mixtures of exponential family<br />distributions. Examples are given throughout. Finally, Section 8 concludes.<br />6 Extensions I: Improving algorithmic efficiency<br />Algorithm 1 approximates the expectations Eqη[˜T(x)?logp(x,y)] and Eqη[˜T(x)?˜T(x)] by<br />simply drawing a sample x∗<br />tfrom qηt(x) and using this sample to calculate<br />ˆ gt<br />ˆCt<br />=<br />˜T(x∗<br />˜T(x∗<br />t)?logp(x∗<br />t)?˜T(x∗<br />t,y)<br />=<br />t).<br />This works remarkably well because, as Section 4 explains, using the same random<br />draw x∗<br />However, it is certainly not the only method of obtaining unbiased approximations of<br />the required expectations, and in this section we present alternatives that often work<br />even better. In addition, we also present alternative methods of parameterizing our<br />problem, and we discuss ways of speeding up the regression step of our algorithm.<br />tto form both estimates, part of the random variation in ˜ η = C−1g cancels out.<br />Example: Binary probit regression<br />To illustrate the different versions of our posterior approximation algorithm, we will<br />use binary probit regression as a running example. Binary probit regression is a classic<br />model in statistics, also referred to as binary classification in the machine learning<br />literature. Here we take a Bayesian approach to probit regression to demonstrate the<br />performance of our methodology relative to existing variational approaches. We have<br />N observed data pairs (yi∈ {0,1},vi∈ RM), and we model yi|vias P(yi= 1|vi,x) =</p>  <p>Page 13</p> <p>T. Salimans and D. A. Knowles 849<br />φ(x?vi) where φ(.) is the standard Gaussian cdf and x ∈ RMis a vector of regression<br />coefficients, for which we assume an elementwise Gaussian prior N(0,1). This is a model<br />for which existing approaches are straightforward so it is interesting to compare their<br />performance to our method. Of course the major benefit of our approach is that it<br />can be applied in a much wider class of models. For all versions of our method the<br />variational approximation used is a full covariance multivariate normal distribution.<br />We use data simulated from the model, with N = 100 and M = 5, to be able to<br />show the performance averaged over 500 datasets and many different settings of the<br />algorithm. We compare our algorithm to the VBEM algorithm of Ormerod and Wand<br />(2010) which makes use of the fact that the expectations required for this model can<br />be calculated analytically. We choose not to do this for our method to investigate how<br />effective our MC estimation strategy can be. For completeness we also compare to<br />variational message passing (VMP, Winn and Bishop 2006), a message passing imple-<br />mentation of VBEM, and expectation propagation (EP, Minka 2001), which is known to<br />have excellent performance on binary classification problems (Nickisch and Rasmussen<br />2008). These last two alternatives are both implemented in Infer.NET (Minka et al.<br />2010) a library for probabilistic inference in graphical models, whereas we implement<br />VBEM and our approximation algorithm ourselves in MATLAB. VMP and VBEM use<br />a different variational approximation to our methods, introducing auxiliary variables<br />zi∼ N(x?vi,1), with ziconstrained to be positive if yi= 1 and negative otherwise. A<br />factorized variational posterior q(x)?<br />iq(zi) is used, where q(x) is multivariate normal<br />and each q(zi) can be thought of as a truncated univariate Gaussian.<br />For all implementations of our algorithm, we initialize the posterior approximation to<br />the prior. All algorithms then use a single random draw to update the parameters dur-<br />ing each iteration. This is often not the best implementation in terms of computational<br />efficiency, since the contributions of multiple draws can often be calculated in parallel<br />at little extra cost, and using antithetic sampling (i.e. sampling of negatively corre-<br />lated draws) can reduce the variance of our approximations. By using the most basic<br />implementation, however, we can more clearly compare the different stochastic approxi-<br />mations proposed in this section. Since the time required to run the different algorithms<br />is strongly dependent on their precise implementation (e.g. the chosen programming<br />language), we choose to perform this comparison by looking at statistical efficiency, as<br />measured by the accuracy as a function of the number of likelihood evaluations, rather<br />than the running time of the algorithms.<br />Since this experiment is on synthetic data we are able to assess performance in terms of<br />the method’s ability to recover the known regression coefficients x, which we quantify<br />as the root mean squared error (RMSE) between the variational mean and the true<br />regression weights, and the “log score”: the log density of the true weights under the<br />approximate variational posterior. The log score is useful because it rewards a method<br />for finding good estimates of the posterior variance as well as the mean, which should<br />of course be central to any approximate Bayesian method.</p>  <p>Page 14</p> <p>850VB through Stochastic Regression<br />Figure 2 shows the performance of the different versions of our algorithm as presented in<br />the following discussion, as well as the performance of the VBEM algorithm of Ormerod<br />and Wand (2010). As can be seen from this graph, our approximation method achieves<br />a lower RMSE than the VBEM algorithm. This is because of the extra factorization<br />assumptions made by VBEM when introducing the zivariables. Where the improvement<br />in the RMSE is noticeable, the difference in log score is dramatic: 0.193 versus −4.46<br />(not shown), indicating that our approximation gives significantly better estimates of the<br />variance than VBEM. The average R-squared obtained by our variational approximation<br />was 0.97, indicating a close fit to the exact posterior distribution. In terms of accuracy,<br />our results are very similar to those of EP, which obtained an RMSE and log score<br />identical to those of our approximation (up to 3 significant digits). As expected, VMP<br />gave consistent results with VBEM: an RMSE of 0.265 and a log score of −4.56.<br />10<br />0<br />10<br />1<br />10<br />2<br />10<br />3<br />0.255<br />0.26<br />0.265<br />0.27<br />0.275<br />number of likelihood evaluations<br />RMSE approximate posterior mean<br /> <br /> <br />Basic algorithm<br />Factorized<br />VBEM<br />Factor+Gradient<br />Hessian<br />Minibatch<br />Figure 2: RMSE approximate posterior mean as a function of the number of likelihood<br />evaluations for the different implementations of our algorithm and VBEM. Green: our<br />basic algorithm (Section 4). Cyan: using factor structure (Section 6.1). Black: the<br />standard VBEM algorithm. Blue: using both factor structure and the gradient of the<br />log posterior (Section 6.2). Red: using the Hessian of the log posterior with linear<br />transformation for efficiency (Sections 6.3 and 6.4). Magenta: using the Hessian, linear<br />transformation and minibatches of data (Section 6.5).<br />As can be seen from Figure 2, our basic algorithm is considerably slower than VBEM in<br />terms of the number of likelihood evaluations that are required to achieve convergence.<br />In terms of wall clock time, our basic algorithm ran about an order of magnitude slower<br />than VBEM, although it could easily be sped up by using multiple random draws in<br />parallel. The basic algorithm was about as fast as EP and VMP, needing about 15<br />milliseconds to converge on this small data set, but note that the system set ups were</p>  <p>Page 15</p> <p>T. Salimans and D. A. Knowles 851<br />not completely comparable: EP and VMP were run on a laptop rather than a desktop,<br />and Infer.NET is implemented in C# rather than MATLAB.<br />The remainder of this section introduces the other implementations of our variational<br />approximation, presented in Figure 2, some of which are much faster and more compu-<br />tationally efficient than both our basic algorithm and VBEM.<br />6.1 Making use of factor structure<br />For most statistical problems, including our probit regression model, the log posterior<br />can be decomposed into a number of additive factors, i.e. logp(x,y) =?N<br />N<br />?<br />This means that rather than performing one single linear regression we can equivalently<br />perform N separate regressions.<br />j=1logφj(x,y).<br />The optimality condition in (9) can then also be written as a sum:<br />˜ η =<br />j=1<br />Eq[˜T(x)?˜T(x)]−1Eq[˜T(x)?logφj(x,y)].<br />ˆ η=<br />N<br />?<br />Eq[˜T(x)?˜T(x)]−1Eq[˜T(x)?logφj(x,y)].<br />j=1<br />ˆ ηj<br />(18)<br />ˆ ηj<br />= (19)<br />One benefit of this is that some of the factors φj(x,y) may be conjugate to the posterior<br />approximation, such as the prior p(x) in our probit regression example. The regression<br />coefficients ˆ ηjfor these conjugate factors are known analytically and do not need to be<br />approximated.<br />More importantly, the separate coefficients ˆ ηjin (18) can often be calculated using re-<br />gressions of much lower dimension than the full vector of natural parameters since the<br />factors φj(x,y) often only depend on a few of the sufficient statistics of our approxi-<br />mation. This occurs when the factors are functions of low dimensional projections or<br />subsets of x. For example, we might have φj(x,y) = φj(xR,y), where xR contains a<br />subset of the variables in x. In that case, it follows from the properties of the expo-<br />nential family that logφj(x,y) will have zero partial correlation with all the sufficient<br />statistics in˜T(x), after controlling for the sufficient statistics of the marginal q(xR) (see<br />Wainwright and Jordan 2008, Section 5.5). In other words, we have<br />logφj(x,y) =˜TR(x)ˆ ηj<br />R+ r(x), with Eq[˜T(x)?r(x)] = 0,<br />where˜TR(x) is that subset of the statistics in˜T(x) that is sufficient for q(xR), and ˆ ηj<br />is the corresponding subset of the parameters in ˆ ηj. The ‘residual’ r(x) is orthogonal to<br />the remaining sufficient statistics, i.e. the factor logφj(x,y) has zero partial correlation<br />to the sufficient statistics that are not in the subset˜TR(x), which means that the<br />R</p>  <p>Page 16</p> <p>852VB through Stochastic Regression<br />coefficients of those statistics will be zero. Statistics that are known to have a zero<br />coefficient can of course be omitted from the regression, leading to the low dimensional<br />regression<br />ˆ ηj<br />R= Eq[˜TR(x)?˜TR(x)]−1Eq[˜TR(x)?logφj(x,y)].<br />By performing these lower dimensional regressions we can reduce the variance of the<br />stochastic approximation algorithm, as well as reduce the overhead needed to store and<br />invert C = Eq[˜T(x)?˜T(x)].<br />Our probit regression model provides a straightforward example, for which the log joint<br />density of x and y has the following factor structure<br />logp(x,y) = logp(x) +<br />N<br />?<br />i=1<br />logp(yi|vi,x).<br />Here, each likelihood factor p(yi|vi,x) depends on all the parameters x, but only through<br />the univariate product fi= x?vi. We can emphasize this by writing our model as<br />logp(x,y) = logp(x) +<br />N<br />?<br />i=1<br />logp(yi|fi),<br />where the new variables fi are linked to the parameters x through the relationship<br />fi = x?vi. When we sample x from its multivariate normal approximate posterior,<br />the resulting fi’s will have univariate normal distributions qη(fi) = N[µi,σ2<br />µi= v?<br />zero partial correlation to the statistics˜T(x) after controlling for the sufficient statistics<br />of the marginals qη(fi), being fiand −0.5f2<br />Gaussian is thus equivalent to approximating the likelihood factors p(yi|fi) by univariate<br />Gaussian likelihood terms in fi. Using this, we can write our unnormalized approximate<br />posterior ˜ q˜ η(x) as<br />i], with<br />iEq[x] and σ2<br />i= v?<br />iVarq[x]vi. This means that the factors logp(yi|fi) will have<br />i. Approximating p(x|y) by a multivariate<br />log ˜ q˜ η(x)= logp(x) +<br />N<br />?<br />N<br />?<br />i=1<br />“˜ ηi,0+ ˜ ηi,1fi− 0.5˜ ηi,2f2<br />“˜ ηi,0+ ˜ ηi,1x?vi− 0.5˜ ηi,2(x?vi)2‰<br />i<br />‰<br />(20)<br />= logp(x) +<br />i=1<br />where ˜ ηi,0, ˜ ηi,1, and ˜ ηi,2are the natural parameters of the univariate Gaussian approx-<br />imation of the likelihood term p(yi|fi). These parameters can now be optimized by<br />performing a separate regression for each likelihood factor, using the statistics<br />»<br />−0.5f2<br />˜T(fi)?=<br />–<br />1<br />fi<br />i<br />fi<br />fl=<br />»<br />–<br />1<br />ixv?<br />−0.5(v?<br />ix)2<br />fi<br />fl,</p>  <p>Page 17</p> <p>T. Salimans and D. A. Knowles 853<br />and regressing these against the likelihood factors logp(yi|vi,xi). At each iteration of<br />Algorithm 1, we can then update the natural parameters of each approximate likelihood<br />term using<br />ˆ gt,i<br />ˆCt,i<br />=<br />˜T(v?<br />˜T(v?<br />(1 − w)gt,i+ wˆ gt,i<br />(1 − w)Ct,i+ wˆCt,i<br />C−1<br />t+1,igt+1,i.<br />ix∗<br />ix∗<br />t)?log[p(yi|vi,x∗<br />t)?˜T(v?<br />t)] (21)<br />=<br />ix∗<br />t)<br />gt+1,i<br />=<br />Ct+1,i<br />˜ ηt+1,i<br />=<br />=<br />Rather than performing a single regression of dimension 1+M(M +3)/2, we may thus<br />equivalently perform N regressions of dimension 3. Performing these lower dimensional<br />regressions is computationally more efficient as long as N is not very large, and it is also<br />statistically more efficient. Figure 2 shows that this factorized regression implementation<br />of our approximation indeed needs far fewer random draws to achieve convergence.<br />All N regressions can be performed in parallel, which offers further opportunities for<br />computational gain on multicore machines or computer clusters.<br />So far, we have assumed that we sample x∗and then form the fiby multiplying with<br />the vi, but note that we can equivalently sample the fi directly and separately from<br />their univariate Gaussian approximate posteriors qη(fi) = N[µi(η,vi),σ2<br />the current example we find that both implementations are about equally efficient.<br />i(η,vi)]. For<br />6.2Using the gradient of the log posterior<br />Using the Frisch-Waugh-Lovell theorem (Lovell 2008), we can remove the constant from<br />the sufficient statistics˜T(x) and rewrite the optimality condition (9) in its normalized<br />form (this is shown for our particular application in Appendix A):<br />ˆ η = Covq[T(x),T(x)]−1Covq[T(x),logp(x,y)]. (22)<br />Furthermore, using the properties of the exponential family of distributions, we know<br />that<br />Covq[T(x),T(x)] = ∇ηEqη[T(x)],<br />which we take to denote the transposed Jacobian matrix of Eqη[T(x)], and<br />(23)<br />Covq[T(x),logp(x,y)] = ∇ηEqη[logp(x,y)],(24)<br />which denotes the column vector gradient of Eqη[logp(x,y)] (since p(x,y) is a scalar<br />valued function).<br />Both Eqη[T(x)] and Eqη[logp(x,y)] can be approximated without bias using Monte<br />Carlo. By differentiating these Monte Carlo approximations we can then obtain unbi-<br />ased estimates of their derivatives. This is easy to do as long as the pseudo-random</p>  <p>Page 18</p> <p>854 VB through Stochastic Regression<br />draw x∗from qη(x) is a differentiable function of the parameters η, given our random<br />number seed z∗:<br />x∗<br />ˆ g<br />ˆC<br />=s(η,z∗), with s() and z∗such that x∗∼ qη(x)<br />∇ηlogp(s(η,z∗),y) = ∇ηs(η,z∗)∇xlogp(x∗,y)<br />∇ηT(s(η,z∗)) = ∇ηs(η,z∗)∇xT(x∗).<br />(25)<br />=<br />=<br />By using the same random number seed z∗in both Monte Carlo approximations we<br />once again get the beneficial variance reduction effect described in Section 4.<br />Performing a single iteration using (25) provides about the same information as doing<br />2×dim(x) iterations with the basic algorithm, making it more computationally efficient<br />if the gradients can be obtained analytically.<br />We can also do updates of this form while still making use of the factor structure of the<br />posterior distribution, as proposed above for the probit regression example. Using this<br />example, and assuming we sample the fiseparately (see last paragraph of Section 6.1),<br />this gives the following regression statistics for each of the N low dimensional regressions:<br />f∗<br />i= si(η,z∗<br />«<br />«<br />«<br />„<br />i) = µi(η,vi) + σi(η,vi)z∗<br />∂si(η,z∗<br />i)<br />∂ηi,1<br />∂si(η,z∗<br />∂ηi,2<br />∂ log p(yi|f∗<br />∂fi<br />(−µiσ2<br />∂si(η,z∗<br />i)<br />∂ηi,1<br />∂si(η,z∗<br />i)<br />∂ηi,2<br />σ2<br />i<br />−µiσ2<br />i, with z∗<br />i∼ N(0,1)(26)<br />ˆ gi=<br />i)<br />ff<br />∂ logp(y|f∗)<br />∂fi<br />=<br />σ2<br />i<br />i)<br />i− 0.5σ3<br />ff”<br />iz∗<br />i)∂ log p(yi|f∗<br />i)<br />∂fi<br />ff<br />ˆCi=<br />∂Ti,1(f∗<br />∂f∗<br />i)<br />i<br />∂Ti,2(f∗<br />∂f∗<br />i)<br />i<br />ı<br />=<br />−σ2<br />i+ 0.5σ3<br />if∗<br />i<br />i− 0.5σ3<br />iz∗<br />i<br />(µiσ2<br />iz∗<br />i)f∗<br />i<br /><br />.<br />Figure 2 shows the performance of this approximation on our probit example, showing<br />again a large gain in efficiency with respect to the approximations introduced earlier.<br />Empirically, we find that using gradients also leads to more efficient stochastic op-<br />timization algorithms for many other applications. For some problems the posterior<br />distribution will not be differentiable in some of the elements of x, for example when x<br />is discrete. In that case the stochastic approximations presented here may be combined<br />with the basic approximation of Section 4.<br />In addition, for many samplers ∇ηs(η,z∗) may be not defined, e.g. rejection samplers.<br />However, for the gradient approximations it does not matter what type of sampler is<br />actually used to draw x∗, only that it is from the correct distribution. A correct strategy<br />is therefore to draw x∗using any desired sampling algorithm, and then proceeding as if<br />we had used a different sampling algorithm for which ∇ηs(η,z∗) is defined. For example,</p>  <p>Page 19</p> <p>T. Salimans and D. A. Knowles 855<br />we might use a nondifferentiable rejection sampler to draw a univariate x∗, and then<br />calculate (25) as if we had used an inverse-transform sampler, for which we have<br />∂<br />∂ηis(η,z∗) = −<br />∂<br />∂ηiQη(x∗)<br />qη(x∗)<br />, (27)<br />for all natural parameters ηi, with Qη(x) the cdf and qη(x) the pdf of x. Similarly, it<br />does not matter for the probit example whether we sample the fijointly by sampling x,<br />or whether we sample them directly and independently. After sampling the fi, we can<br />use si(η,z∗<br />(27), or something else entirely. Finding the most efficient strategy we mostly leave<br />for future work, although Sections 6.3 and 6.4 offer some further insights into what is<br />possible.<br />i) = µi+ σiz∗<br />ias proposed above, but we might equivalently proceed using<br />6.3 Using the Hessian of the log posterior<br />When we have both first and second order gradient information for logp(x,y) and if we<br />choose our approximation to be multivariate Gaussian, i.e. qη(x) = N(m(η),V (η)), we<br />have a third option for approximating the statistics used in the regression. For Gaussian<br />q(x) and twice differentiable logp(x,y), Minka (2001) and Opper and Archambeau<br />(2009) show that<br />∇mEq[logp(x,y)] = Eq[∇xlogp(x,y)],<br />and<br />∇VEq[logp(x,y)] =1<br />where ∇x∇xlogp(x,y) denotes the Hessian matrix of logp(x,y) in x.<br />(28)<br />2Eq[∇x∇xlogp(x,y)], (29)<br />For the multivariate Gaussian distribution we know that the natural parameters are<br />given as η1 = V−1m and η2 = V−1. Using this relationship, we can derive Monte<br />Carlo estimators ˆ g andˆC using the identities (23, 24). We find that these stochastic<br />approximations are often even more efficient than the ones in Section 6.2, provided that<br />the Hessian matrix of logp(x,y) can be calculated cheaply. This type of approximation<br />is especially powerful when combined with the extension presented in the next section.<br />6.4 Linear transformations of the regression problem<br />It is well known that classical linear least squares regression is invariant to invertible<br />linear transformations of the explanatory variables. We can use the same principle in<br />our stochastic approximation algorithm to allow us to work with alternative parame-<br />terizations of the approximate posterior q(x). These alternative forms can be easier to<br />implement or lead to more efficient algorithms, as we show in this section.<br />In classical linear least squares regression, we have an N × D matrix of explanatory<br />variables X, and an N × 1 vector of dependent variables Y . Instead of doing a linear</p>  <p>Page 20</p> <p>856 VB through Stochastic Regression<br />regression with these variables directly, we may equivalently perform the linear regres-<br />sion using a transformed set of explanatory variables˜ X = XK?, with K any invertible<br />matrix of size D×D. The least squares estimator˜β = (˜ X? ˜ X)−1 ˜ X?Y of the transformed<br />problem can then be used to give the least squares estimator of the original problem as<br />ˆβ = K?˜β:<br />ˆβ = K?(KX?XK?)−1KX?Y = (KX?X)−1KX?Y = (X?X)−1X?Y.<br />Using the same principle, we can rewrite the optimality condition of (9) as<br />˜ η = Eqη[K(η)˜T(x)?˜T(x)]−1Eqη[K(η)˜T(x)?logp(x,y)], (30)<br />for any invertible matrix K, which may depend on the variational parameters η. Instead<br />of solving our original least squares regression problem, we may thus equivalently solve<br />this transformed version. When we perform the linear regression in (30) for a fixed set of<br />parameters η, the result will be identical to that of the original regression with K(η) = I,<br />as long as we use the same random numbers for both regressions. However, when<br />the Monte Carlo samples (‘data points’ in our regression) are generated using different<br />values of η, as is the case with the proposed stochastic approximation algorithm, the two<br />regressions will not necessarily give the same solution for a finite number of samples.<br />If the true posterior p(x|y) is of the same functional form as the approximation qη,<br />the exact convergence result of Section 4 holds for any invertible K(η), so it is not<br />immediately obvious which K(η) is best for general applications.<br />We hypothesize that certain choices of K(η) may lead to statistically more efficient<br />stochastic approximation algorithms for certain specific problems, but we will not pursue<br />this idea here. What we will discuss is the observation that the stochastic approximation<br />algorithm may be easier to implement for some choices of K(η) than for others, and that<br />the computational costs are not identical for all K(η). In particular, the transformation<br />K(η) allows us to use different parameterizations of the variational approximation. Let<br />qφ be such a reparameterization of the approximation, let the new parameter vector<br />φ(η) be an invertible and differentiable transformation of the original parameters η, and<br />set K(η) equal to the inverse transposed Jacobian of this transformation, i.e. K(η) =<br />[∇ηφ(η)]−1. Using the properties of the exponential family of distributions, we can then<br />show that<br />K(η)Covqφ[T(x),h(x)] = ∇φEqφ[h(x)],<br />for any differentiable function h(x). Using this result, the stochastic approximations of<br />Section 6.2 for the transformed regression problem are<br />(31)<br />x∗<br />ˆ g<br />ˆC<br />=s(φ,z∗), with s() and z∗such that x∗∼ qφ(x)<br />∇φlogp(s(φ,z∗),y)<br />∇φT(s(φ,z∗)).<br />(32)<br />= (33)<br />= (34)<br />These new expressions for ˆ g andˆC may be easier to calculate than the original ones (25),<br />and the resultingˆC may have a structure making it easier to invert in some cases. An</p>  <p>Page 21</p> <p>T. Salimans and D. A. Knowles 857<br />example of this occurs when we use a Gaussian approximation in combination with the<br />stochastic approximations of Section 6.3, using the gradient and Hessian of logp(x,y).<br />In this case we may work in the usual natural parameterization, but doing so gives a<br />dense matrixˆC with dimensions proportional to M2, where M is the dimension of x.<br />For large M, such a stochastic approximation is expensive to store and invert. However,<br />using the stochastic approximations above, we may alternatively parameterize our ap-<br />proximation in terms of the mean m and variance V . Working in this parameterization,<br />we can express the update equations for the natural parameters in terms of the gradi-<br />ent and Hessian of logp(x,y) and the average sampled x value, instead of the (higher<br />dimensional) g and C statistics. The resulting algorithm, as derived in Appendix B, is<br />therefore more efficient in terms of both computation and storage. Pseudocode for the<br />new algorithm is given below.<br />Algorithm 2 Stochastic Approximation for Gaussian Variational Approximation<br />Require: An unnormalized, twice differentiable posterior distribution p(x,y)<br />Require: The total number of iterations N<br />Initialize the mean and variance of the approximation (m1,V1) to a first guess, for<br />example by matching the prior p(x)<br />Initialize z1= m1, P1= V−1<br />1<br />and a1= 0<br />Initialize ¯ z = 0,¯P = 0 and ¯ a = 0<br />Set step-size w = 1/?N<br />for t = 1 : N do<br />Generate a draw x∗<br />Calculate the gradient gtand Hessian Htof logp(x,y) at x∗<br />Set at+1= (1 − w)at+ wgt<br />Set Pt+1= (1 − w)Pt− wHt<br />Set zt+1= (1 − w)zt+ wx∗<br />Set Vt+1= P−1<br />if t &gt; N/2 then<br />Set ¯ a = ¯ a +<br />Ngt<br />Set¯P =¯P −<br />Set ¯ z = ¯ z +<br />t<br />end if<br />end for<br />Set V =¯P−1and m = V ¯ a + ¯ z<br />return m,V<br />tfrom N(mt,Vt)<br />t<br />t<br />t+1and mt+1= Vt+1at+1+ zt+1<br />2<br />2<br />NHt<br />2<br />Nx∗<br />Instead of storing and inverting the full C matrix, this algorithm uses the sparsity<br />induced by the transformation K(η) to work with the precision matrix P instead. The<br />dimensions of this matrix are equal to the dimension of x, rather than its square,<br />providing great savings. Moreover, while the C matrix in the original parameterization<br />is always dense, P will have the same sparsity pattern as the Hessian of logp(x,y), which<br />may reduce the costs of storing and inverting it even further for many applications.</p>  <p>Page 22</p> <p>858 VB through Stochastic Regression<br />Figure 2 shows the performance of Algorithm 2 as applied to our probit regression<br />example. As is typical for this version of the algorithm, it performs even better than<br />the algorithm using only the gradient and factor structure of the posterior distribution.<br />Since this type of approximation is also very easy to implement efficiently in a matrix<br />programming language like MATLAB, it also runs significantly faster than the VBEM<br />algorithm for this example. Moreover, the algorithm is now again completely general<br />and does not make any assumptions as to the structure of the posterior distribution<br />(other than it being twice differentiable). This means it can easily be used for Gaussian<br />variational approximation of almost any posterior distribution.<br />6.5 Subsampling the data: double stochastic approximation<br />The stochastic approximations derived above are all linear functions of logp(x,y) and<br />its first and second derivatives. This means that these estimates are still unbiased even if<br />we take logp(x,y) to be a noisy unbiased estimate of the true log posterior, rather than<br />the exact log posterior. For most statistical applications logp(x,y) itself is a separable<br />additive function of a number of independent factors, i.e. logp(x,y) =?N<br />approximation of logp(x,y) as<br />j=1logφj(x,y)<br />as explained in Section 6.1. Using this fact we can construct an unbiased stochastic<br />log ˜ p(x,y) =N<br />K<br />K<br />?<br />j=1<br />logφj(x,y), (35)<br />where the K factors logφj(x,y) are randomly selected from the total N factors. This<br />approach was previously proposed for online learning of topic models by Hoffman et al.<br />(2010). Since log ˜ p(x,y) has logp(x,y) as its expectation, performing stochastic approx-<br />imation based on ˜ p(x,y) converges to the same solution as when using p(x,y), provided<br />we resample the factors in log ˜ p(x,y) at every iteration. By subsampling the K ? N<br />factors in the model, the individual steps of the optimization procedure become more<br />noisy, but since we can calculate ˜ p(x,y) faster than we can p(x,y), we can perform a<br />larger number of steps in the same amount of time. In practice this tradeoff often favors<br />using subsampling, and this principle has been used in many successful applications of<br />stochastic gradient descent, see e.g. Bottou (2010).<br />For our probit regression example we implement subsampling by dividing the sample<br />into 10 equally sized ‘minibatches’ of data. During each iteration of the algorithm, these<br />minibatches are processed in random order, using Algorithm 2 combined with (35) to<br />update the variational parameters after each minibatch. As can be seen in Figure 2 this<br />approach allows us to get a good approximation to the posterior very quickly: reaching<br />the accuracy of converged VBEM now only requires three passes over the training data,<br />although final convergence is not much faster than when using the full sample.</p>  <p>Page 23</p> <p>T. Salimans and D. A. Knowles859<br />7 Extensions II: Using mixtures of exponential family dis-<br />tributions<br />So far, we have assumed that the approximating distribution qη(x) is a member of the<br />exponential family. Here we will relax that assumption. If we choose a non-standard<br />approximation, certain moments or marginals of qη(x) are typically no longer available<br />analytically, which should be taken into account when choosing the type of approxima-<br />tion. However, if we can at least sample directly from qη(x), it is often still much cheaper<br />to approximate these moments using Monte Carlo than it would be to approximate the<br />corresponding moments of the posterior using MCMC or other indirect sampling meth-<br />ods. We have identified two general strategies for constructing useful non-standard<br />posterior approximations which are discussed in the following two sections.<br />7.1 Hierarchical approximations<br />If we split our vector of unknown parameters x into p non-overlapping blocks, our<br />approximating posterior may be decomposed as<br />q(x) = q(x1)q(x2|x1)q(x3|x1,x2)...q(xp|x1,...,xp−1).<br />If we then choose every conditional posterior q(xi|x1,...,xi−1) to be an analytically<br />tractable member of the exponential family, we can easily sample from the joint q(x),<br />while still having much more freedom in capturing the dependence between the different<br />blocks of x. In practice, such a conditionally tractable approximation can be achieved<br />by specifying the sufficient statistics of each exponential family block q(xi|x1,...,xi−1)<br />to be a function of the preceding elements x1,x2,...,xi−1. This leads to a natural type<br />of approximation for hierarchical Bayesian models, where the hierarchical structure of<br />the prior often suggests a good hierarchical structure for the posterior approximation.<br />If every conditional q(xi|x1,...,xi−1) is in the exponential family, the joint may not<br />be if the normalizing constant of any of those conditionals is a non-separable function<br />of the preceding elements x1,x2,...,xi−1 and the variational parameters. However,<br />because the conditionals are still in the exponential family, our optimality condition<br />still holds separately for the variational parameters of each conditional with only slight<br />modification. Taking again the derivative of the KL-divergence and setting it to zero<br />yields:<br />ηi<br />Ci<br />gi<br />=C−1<br />i<br />Eq(x1,...,xi−1){Varq(xi|x1,...,xi−1)[Ti(xi)]}<br />Eq(x1,...,xi−1){Covq(xi,...,xp|x1,...,xi−1)[Ti(xi),r−i(x)]},<br />logp(x,y) − logqη(x1,...,xi−1) − logqη(xi+1,...,xp|x1,...,xi)<br />logp(x,y) − logqη(x) + logqη(xi|x1,...,xi−1),<br />where Ti(xi) and ηidenote the sufficient statistics and corresponding natural parame-<br />ters of the i-th conditional approximation q(xi|x1,...,xi−1), and where r−i(x) can be<br />gi<br />(36)<br />=<br />=<br />r−i(x)=<br />=</p>  <p>Page 24</p> <p>860VB through Stochastic Regression<br />seen as the residual of the approximation with the i-th block left out. Note that we<br />cannot rewrite this expression as a linear regression any further, like we did in Sec-<br />tion 2, since the intercept of such a regression is related to the normalizing constant of<br />q(xi|x1,...,xi−1) which may now vary in x1,...,xi−1. However, Ciand gican still be<br />approximated straightforwardly using Monte Carlo, and Algorithm 1 can still be used<br />with these approximations, performing separate ‘regressions’ for all conditionals during<br />each iteration like we proposed for factorized p(x,y) in Section 6.1. Alternatively, Al-<br />gorithm 2 or any of the extensions in Section 6 may be used to fit the different blocks<br />of qη(x).<br />Using this type of approximation, the marginals q(xi) will generally be mixtures of<br />exponential family distributions, which is where the added flexibility of this method<br />comes from. By allowing the marginals q(xi) to be mixtures with dependency on the<br />preceding elements of x, we can achieve much better approximation quality than by<br />forcing them to be a single exponential family distribution. A similar idea was used in<br />the context of importance sampling by Hoogerheide et al. (2012). A practical example<br />of this is given below.<br />Example: A stochastic volatility model<br />Stochastic volatility models for signals with time varying variances are considered ex-<br />tremely important in finance. Here we apply our methodology to the model and prior<br />specified in Girolami and Calderhead (2011). The data we will use, from Kim et al.<br />(1998), is the percentage change ytin GB Pound vs. US Dollar exchange rate, modeled<br />as:<br />yt= ?tβ exp(vt/2).<br />The relative volatilities, vtare governed by the autoregressive AR(1) process<br />vt+1= φvt+ ξt+1, with v1∼ N[0,σ2/(1 − φ2)].<br />The distributions of the error terms are given by ?t∼ N(0,1) and ξt∼ N(0,σ2). The<br />prior specification is as in Girolami and Calderhead (2011):<br />p(β) ∝ β−1,(φ + 1)/2 ∼ Beta(20,1.5),σ2∼ Inv-Gamma(5,0.25).<br />Following the strategy outlined above, we use the hierarchical structure of the prior to<br />suggest a hierarchical structure for the approximate posterior:<br />qη(φ,σ2,β,v) = qη(φ)qη(σ2|φ)qη(β,v|φ,σ2).<br />The prior of φ is in the exponential family, so we choose the posterior approximation<br />qη(φ) to be of the same form:<br />qη[(φ + 1)/2] = Beta(η1,η2).</p>  <p>Page 25</p> <p>T. Salimans and D. A. Knowles861<br />The prior for σ2is inverse-Gamma, which is also in the exponential family. We again<br />choose the same functional form for the posterior approximation, but with a slight<br />modification in order to capture the posterior dependency between φ and σ2:<br />qη(σ2|φ) ∼ Inv-Gamma(η3,η4+ η5φ2),<br />where the extra term η5φ2was chosen by examining the functional form of the exact<br />full conditional p(σ2|φ,v).<br />Using the notation f = (log(β),v?)?, the conditional prior p(f|φ,σ2) can be seen as the<br />diffuse limit of a multivariate normal distribution. We therefore also use a multivariate<br />normal conditional approximate posterior:<br />qη(f|φ,σ2) =p(f|φ,σ2)qη(y|f)<br />qη(y|φ,σ2)<br />,<br />with p(f|φ,σ2) the Gaussian prior, qη(y|f) a Gaussian approximate likelihood of the<br />form<br />qη(y|f) = (2π)−T/2a<br />with η6a T × T positive-definite matrix and η7a T × 1 vector, and where<br />qη(y|φ,σ2) =<br />f<br />|η6|exp“η?<br />?<br />7η−1<br />6η7<br />‰exp<br />„<br />η?<br />7f −1<br />2f?η6f<br /><br />,<br />p(f|φ,σ2)qη(y|f)df<br />is the normalizing constant of our posterior approximation qη(f|φ,σ2).<br />Now that we have defined the functional form of the approximate posterior, we can fit<br />its parameters by applying (36) to each of the blocks qη(φ), qη(σ2|φ), and qη(f|φ,σ2).<br />We approximate the statistics of the first two blocks using gradients as proposed in<br />Section 6.2. The last (multivariate Gaussian) block is updated using both the gradient<br />and the Hessian of p(y|f) via the optimized expressions of Algorithm 2.<br />For the first block qη(φ) this gives us the following stochastic approximations:<br />φ∗<br />σ2∗<br />ˆC1<br />ˆ g1<br />=s1(η,z∗<br />s2(η,z∗<br />∇η[s1(η,z∗<br />∇η[s1(η,z∗<br />+∇φ[s2(η,z∗<br />∇η[s1(η,z∗<br />+Eq(f|φ∗,σ2∗)(logp(y|f) − logqη(y|f))]<br />+∇φ[s2(η,z∗<br />+Eq(f|φ∗,σ2∗)(logp(y|f) − logqη(y|f))]}<br />∇η[s1(η,z∗<br />1), with s1() and z∗<br />2,φ∗), with s2() and z∗<br />1)]∇φ[T1(φ∗)]<br />1)]{∇φEq(f|φ∗,σ2∗)[logp(φ∗,σ2∗,f,y) − logqη(σ2∗,f|φ∗)]<br />2,φ∗)]∇σ2Eq(f|φ∗,σ2∗)[logp(φ∗,σ2∗,f,y) − logqη(σ2∗,f|φ∗)]}<br />1)]{∇φ[logp(φ∗) + logqη(y|φ∗,σ2∗) − logqη(σ2∗|φ∗)<br />1such that φ∗∼ qη(φ)<br />2such that σ2∗∼ qη(σ2|φ∗)<br />(37)<br />=(38)<br />=(39)<br />=(40)<br />= (41)<br />2,φ∗)]∇σ2[logp(σ2∗) + logqη(y|φ∗,σ2∗) − logqη(σ2∗|φ∗)<br />≈<br />1)]{∇φ[logp(φ∗) + logqη(y|φ∗,σ2∗) − logqη(σ2∗|φ∗)],(42)</p>  <p>Page 26</p> <p>862 VB through Stochastic Regression<br />where T1(φ∗) are the sufficient statistics of qη(φ), and where we make use of the fact<br />that<br />p(φ,σ2,β,f) = p(φ)p(σ2)p(f|φ,σ2)p(y|f)<br />and<br />qη(σ2,f|φ)=qη(σ2|φ)qη(f|φ,σ2)<br />qη(σ2|φ)p(f|φ,σ2)qη(y|f)/qη(y|φ,σ2).=<br />Cancelling the prior term p(f|φ,σ2) in p() and q() then allows us to go from (40) to (41).<br />The approximate marginal likelihood qη(y|φ,σ2) and the expectations with respect to<br />qη(f|φ,σ2) can be evaluated analytically using the Kalman filter and smoother (e.g.<br />Durbin and Koopman 2001), which means we do not have to sample f for this problem.<br />Note that (41) includes both the direct effect of φ, as well as its indirect effects through<br />qη(σ2|φ) and qη(f|φ,σ2). If the functional form of q() is close to that of p(), the relative<br />importance of these indirect effects is low. In most cases we can therefore ignore these<br />indirect effects with little to no loss of accuracy. For the current application we find<br />that using (42) instead of (41) gives virtually identical results.<br />The stochastic approximations for the second block qη(σ2|φ) are given by<br />ˆC2<br />=<br />∇η[s2(η,z∗<br />ˆ g2<br />=<br />∇η[s2(η,z∗<br />+Eq(f|φ∗,σ2∗)(logp(y|f) − logqη(y|f))]<br />≈<br />where T2(σ2∗) are the sufficient statistics of qη(σ2|φ).<br />2,φ∗)]∇σ2[T2(σ2∗)]<br />2,φ∗)]∇σ2[logp(σ2∗) + logqη(y|φ∗,σ2∗)<br />(43)<br />∇η[s2(η,z∗<br />2,φ∗)]∇σ2[logp(σ2∗) + logqη(y|φ∗,σ2∗)],<br />Finally, the updates for the likelihood approximation (using Algorithm 2) are given by<br />at+1<br />zt+1<br />η6,t+1<br />η7,t+1<br />= (1 − w)at+ wEqη(f|φ∗,σ2∗)[∇flogp(y|f)]<br />(1 − w)zt+ wEqη(f|φ∗,σ2∗)[f]<br />(1 − w)η6,t− wEqη(f|φ∗,σ2∗)[∇f∇flogp(y|f)]<br />at+1+ η6,t+1zt+1.<br />=<br />=<br />=<br />Here again, the expectations with respect to the approximate posterior qη(f|φ,σ2) can<br />be calculated analytically using the Kalman filter/smoother and do not have to be<br />approximated by sampling. Furthermore we know that the Hessian of the log likelihood<br />is sparse, which means that only a relatively small number of the parameters in η6will be<br />non-zero: all elements on the diagonal and all elements in the column and row belonging<br />to log(β). This sparsity is also what makes fitting this posterior approximation feasible,<br />since inverting a dense T ×T precision matrix would be much too expensive. Even with<br />this sparsity, our optimization problem is still fairly high dimensional with about 2000<br />free parameters. Nevertheless, we find that our approximation converges very quickly<br />using 250 iterations of our algorithm, with a single (φ,σ2) sample per iteration, which</p>  <p>Page 27</p> <p>T. Salimans and D. A. Knowles 863<br />takes our single-threaded MATLAB implementation half a second to complete on a<br />3GHz processor. This is more than two orders of magnitude faster than the running<br />time required by advanced MCMC algorithms for this problem.<br />We compare the results of our posterior approximation against the “true” posterior,<br />provided by a very long run of the MCMC algorithm of Girolami and Calderhead<br />(2011). As can be seen from Figures 3, 4 and 5, the posterior approximations for<br />the model parameters are nearly exact. Similarly, the posterior approximations for the<br />latent volatilities v (not shown) are also indistinguishable from the exact posterior.<br />0.4 0.50.60.7 0.80.9<br />beta<br />1 1.11.2 1.31.4<br />0<br />1<br />2<br />3<br />4<br />5<br />6<br />7<br />8<br />posterior density<br /> <br /> <br />Monte Carlo<br />Variational Approximation<br />Figure 3: Exact and approximate posterior for the stochastic volatility model - β pa-<br />rameter<br />Our approach to doing inference in the stochastic volatility model shares some char-<br />acteristics with the approach of Liesenfeld and Richard (2008). They fit a Gaussian<br />approximation to the posterior of the volatilities for given φ,σ2,β parameters, using<br />the importance sampling algorithm of Richard and Zhang (2007), which is based on<br />auxiliary regressions somewhat similar to those in Algorithm 1. They then infer the<br />model parameters using MCMC methods. The advantage of our method is that we are<br />able to leverage the information in the gradient and Hessian of the posterior, and that<br />our stochastic approximation algorithm allows us to fit the posterior approximation very<br />quickly for all volatilities simultaneously, while their approach requires optimizing the<br />approximation one volatility at a time. Unique to our approach is also the ability to<br />concurrently fit a posterior approximation for the model parameters φ,σ2,β and have<br />the approximate posterior of the volatilities depend on these parameters, while Liesen-<br />feld and Richard (2008) need to re-construct their approximation every time a new set<br />of model parameters is considered. As a result, our approach is significantly faster for<br />this problem.</p>  <p>Page 28</p> <p>864VB through Stochastic Regression<br />0.75 0.80.850.90.951<br />0<br />5<br />10<br />15<br />20<br />25<br />30<br />phi<br />posterior density<br /> <br /> <br />Monte Carlo<br />Variational Approximation<br />Figure 4: Exact and approximate posterior for the stochastic volatility model - φ pa-<br />rameter<br />00.05 0.10.150.20.25<br />0<br />5<br />10<br />15<br />20<br />25<br />30<br />35<br />variance<br />posterior density<br /> <br /> <br />Monte Carlo<br />Variational Approximation<br />Figure 5: Exact and approximate posterior for the stochastic volatility model - σ2<br />parameter</p>  <p>Page 29</p> <p>T. Salimans and D. A. Knowles 865<br />7.2Using auxiliary variables<br />Another approach to constructing flexible posterior approximations is using the con-<br />ditional exponential family approximation of Section 7.1, but letting the first block of<br />variables be a vector of auxiliary variables u, that are not part of the original set of<br />model parameters and latent variables, x. The posterior approximation then has the<br />form<br />q(x,u) = q(u)q(x|u).<br />The factors q(u) and q(x|u) should both be analytically tractable members of the expo-<br />nential family, which allows the marginal approximation q(x) to be a general mixture<br />of exponential family distributions, like a mixture of normals for example. If we use<br />enough mixture components, the approximation q(x) could then in principle be made<br />arbitrarily close to p(x|y). Note, however, that if p(x|y) is multimodal our optimization<br />problem might suffer from multiple local minima, which means that we are generally<br />not guaranteed to find the optimal approximation.<br />The mixture approximation q(x) can be fitted by performing the standard KL-divergence<br />minimization:<br />Eqη[logqη(x) − logp(x,y)].ˆ η = argmin<br />η<br />(44)<br />From (44) it becomes clear that an additional requirement of this type of approximation<br />is that we can integrate out the auxiliary variables u from the joint q(x,u) in order to<br />evaluate the marginal density q(x) at a given point x. Fortunately this is easy to do for<br />many interesting approximations, such as discrete mixtures of normals or continuous<br />mixtures like Student’s t distributions. Also apparent from (44) is that we cannot use<br />this approximation directly with the stochastic approximation algorithms proposed in<br />the last sections since q(x) is itself not part of the exponential family of distributions.<br />However, we can rewrite (44) as<br />ˆ η = argmin<br />η<br />Eqη[logqη(x,u) − log ˜ p(x,y,u)],(45)<br />with ˜ p(x,y,u) = p(x,y)qη(u|x), and<br />qη(u|x) =<br />qη(x|u)qη(u)<br />?qη(x|u)qη(u)du=qη(x|u)qη(u)<br />qη(x)<br />.<br />Equation 45 now once again has the usual form of a KL-divergence minimization where<br />the approximation, qη(x,u), consists of exponential family blocks qη(u) and qη(x|u). By<br />including the auxiliary variables u in the ‘true’ posterior density, we can thus once again<br />make use of our efficient stochastic optimization algorithms. Including u in the posterior<br />does not change the marginal posterior p(x|y) which is what we are interested in. We<br />now describe a practical example of this approach using an approximation consisting of<br />a mixture of normals.</p>  <p>Page 30</p> <p>866VB through Stochastic Regression<br />Example: A beta-binomial model for overdispersion<br />Albert (2009, Section 5.4) considers the problem of estimating the rates of death from<br />stomach cancer for the largest cities in Missouri. This cancer mortality data is available<br />from the R package LearnBayes, and consists of 20 pairs (nj,yj) where njcontains the<br />number of individuals that were at risk in city j, and yjis the number of cancer deaths<br />that occurred in that city. The counts yjare overdispersed compared to what one could<br />expect under a binomial model with constant probability, so Albert (2009) assumes the<br />following beta-binomial model with mean m and precision K:<br />P(yj|m,K) =<br />ˆnj<br />yj<br />˙B(Km + yj,K(1 − m) + nj− yj)<br />B(Km,K(1 − m))<br />,<br />where B(·,·) denotes the Beta-function. The parameters m and K are given the follow-<br />ing improper prior:<br />p(m,K) ∝<br />1<br />m(1 − m)<br />1<br />(1 + K)2.<br />The resulting posterior distribution is non-standard and extremely skewed. To amelio-<br />rate this, Albert (2009) proposes the reparameterization<br />x1= logit(m), and x2= log(K).<br />The form of the posterior distribution p(x|y) still does not resemble any standard dis-<br />tribution, so we will approximate it using a finite mixture of L bivariate Gaussians.<br />In order to do this, we first introduce an auxiliary variable u, to which we assign a<br />categorical approximate posterior distribution with L possible outcomes:<br />qη(u) = exprδ(u = 1)η1+ δ(u = 2)η2+ ··· + δ(u = L)ηL− U(η)s,<br />where δ(.) is the indicator function and U(η) is the normalizer.<br />Conditional on u, we assign x a Gaussian approximate posterior<br />qη(x|u = i) = N(µi,Σi).<br />By adapting the true posterior to include u as described above, we can fit this ap-<br />proximate posterior to p(x|y). Here, the auxiliary variable u is discrete, and hence our<br />posterior approximation is not differentiable with respect to this variable. We must<br />therefore use the basic stochastic approximation of Section 4 to fit qη(u). In order to re-<br />duce the variance of the resulting stochastic approximations, we Rao-Blackwellize them<br />by taking expectations with respect to qη(u|x). If we then also take advantage of the<br />sparsity in the covariance matrix of the sufficient statistics, this leads to the following</p>  <p>Page 31</p> <p>T. Salimans and D. A. Knowles867<br />update equations:<br />x∗<br />t<br />∼<br />=<br />qηt(x)<br />Eqηt(u|x∗<br />ˆCt,i[logp(x∗<br />ˆCt,i[logp(x∗<br />−logqηt(x∗<br />ˆCt,i[logp(x∗<br />(1 − w)Ct,i+ wˆCt,i<br />(1 − w)gt,i+ wˆ gt,i<br />gt+1,i<br />Ct+1,i,<br />ˆCt,i<br />t)[δ(u = i)] = qη(u = i|x∗<br />t,y) + logqη(u = i|x∗<br />t,y) + logqηt(x∗<br />t) − logqηt(x∗<br />t,y) − logqηt(x∗<br />t)<br />ˆ gt,i<br />=<br />t) − logqηt(x∗<br />t|u = i) + logqηt(u = i)<br />t|u = i)]<br />t) + ηt,i− U(ηt)]<br />t|u = i)]<br />=<br />=<br />Ct+1,i<br />gt+1,i<br />=<br />=<br />ηt+1,i<br />=<br />for each mixture component i.<br />Conditional on u, the approximate posterior for x is Gaussian, and we can therefore<br />once again use the optimized expressions from Algorithm 2 to update qη(x|u):<br />x∗<br />t<br />∼<br />ˆCt,i<br />=<br />Eqηt(u|x∗<br />Ct+1,i<br />=(1 − w)Ct,i+ wˆCt,i<br />at+1,i<br />=(1 − w)at,i+ wˆCt,i∇x[logp(x∗,y) + logqηt(u = i|x∗)]<br />Ht+1,i<br />=(1 − w)Ht,i+ wˆCt,i∇x∇x[logp(x∗,y) + logqηt(u = i|x∗)]<br />zt+1,i<br />=(1 − w)zt,i+ wˆCt,ix∗<br />Σt+1,i<br />=<br />−Ct+1,iH−1<br />µt+1,i<br />=<br />−H−1<br />qηt(x)<br />t)[δ(u = i)] = qηt(u = i|x∗<br />t)<br />t<br />t+1,i<br />t+1,iat+1+<br />zt+1<br />Ct+1,i,<br />for each mixture component i. Here we have once again Rao-Blackwellized the stochas-<br />tic approximations with respect to qη(u|x), which introduced the extra variableˆCt,i<br />compared to Algorithm 2. Also note the presence of the logqηt(u = i|x∗) term, which<br />enters our equations as a result of expanding the posterior to include u. This term has<br />the effect of pushing apart the different mixture components of the approximation.<br />We fit the approximation qη(x) using a varying number of mixture components and<br />examine the resulting KL-divergence to the true posterior density. Since this is a low<br />dimensional problem, we can obtain this divergence very precisely using quadrature<br />methods. Figures 6 and 7 show that we can indeed approximate this skewed and heavy-<br />tailed density very well using a large enough number of Gaussians. The R-squared of<br />the mixture approximation with 8 components is 0.997.</p>  <p>Page 32</p> <p>868VB through Stochastic Regression<br />Also apparent is the inadequacy of an approximation consisting of a single Gaussian for<br />this problem, with an R-squared of only 0.82. This clearly illustrates the advantages of<br />our approach which allows us to use much richer approximations than was previously<br />possible. Furthermore, Figure 6 shows that the KL-divergence of the approximation to<br />the true posterior can be approximated quite accurately using the measure developed<br />in Section 5, especially if the posterior approximation is reasonably good.<br />The variational optimization problem for this approximation has multiple solutions,<br />since all Gaussian mixture components are interchangeable. Since p(x|y) is unimodal,<br />however, we find that all local optima (that we find) are equally good, and are presum-<br />ably also global optima. In this case, we find that we can therefore indeed approximate<br />p(x|y) arbitrarily well by using a large enough number of mixture components.<br />12345678<br />0<br />0.02<br />0.04<br />0.06<br />0.08<br />0.1<br />0.12<br />0.14<br />number of mixture components<br />KL divergence D(q|p)<br /> <br /> <br />exact<br />approximate<br />Figure 6: KL-divergence between the variational approximation and the exact posterior<br />density for an increasing number of mixture components. The exact divergence is given<br />by the solid blue line, while the approximation from Section 5 is given by the dashed red<br />line. Note that the log marginal likelihood is given by logp(y) = ˆ η0+U(η)+D(qη|p), with<br />ˆ η0+U(η) = Eq[logp(x,y)−logq(x)] its usual lower bound. This means that the height<br />of the solid blue line can also be interpreted as the approximation error of this bound for<br />approximating the log marginal likelihood. The corresponding approximation error for<br />the newly proposed marginal likelihood approximation (Section 5, Equation 17) is then<br />given by the difference between the solid and dashed lines: The new approximation for<br />the marginal likelihood is thus much more accurate than the usual lower bound.</p>  <p>Page 33</p> <p>T. Salimans and D. A. Knowles869<br />logit m<br />log K<br />exact<br />−7.5 −7 −6.5 −6<br />5<br />10<br />logit m<br />4<br />log K<br />1<br />−7.5 −7 −6.5 −6<br />5<br />10<br />logit m<br />5<br />log K<br />2<br />−7.5 −7 −6.5 −6<br />5<br />10<br />logit m<br />6<br />log K<br />3<br />−7.5 −7 −6.5 −6<br />5<br />10<br />logit m<br />7<br />log K<br />−7.5 −7 −6.5 −6<br />5<br />10<br />logit m<br />8<br />log K<br />−7.5 −7 −6.5 −6<br />5<br />10<br />logit m<br />log K<br />−7.5 −7 −6.5 −6<br />5<br />10<br />logit m<br />log K<br />−7.5 −7 −6.5 −6<br />5<br />10<br />logit m<br />log K<br />−7.5 −7 −6.5 −6<br />5<br />10<br />Figure 7: Contour plots of posterior approximations using 1-8 mixture components,<br />with the exact posterior at the bottom-right. With seven or eight mixture components<br />the approximation is visually indistinguishable from the true posterior.<br />8Conclusion and future work<br />We have introduced a stochastic optimization scheme for variational inference inspired<br />by a novel interpretation of fixed-form variational approximation as linear regression of<br />the target log density against the sufficient statistics of the approximating family. Our<br />scheme allows very generic implementation for a wide class of models since in its most<br />basic form only the unnormalized density of the target distribution is required, although<br />we have shown how gradient or even Hessian information can be used if available. The<br />generic nature of our methodology would lend itself naturally to a software package for<br />Bayesian inference along the lines of Infer.NET (Minka et al. 2010) or WinBUGS (Gilks<br />et al. 1994), and would allow inference in a considerably wider range of models. Incorpo-<br />rating automatic differentiation in such a package could clearly be beneficial. Automatic<br />selection of the approximating family would be very appealing from a user perspective,<br />but could be challenging in general.<br />Despite its general applicability, the performance of our approach was demonstrated<br />to be very competitive for problems where we can either decompose the posterior dis-<br />tribution into low dimensional factors (Section 6.1), or where we can make use of the<br />gradient and Hessian of the log posterior (Section 6.3). For those rare cases where this</p>  <p>Page 34</p> <p>870VB through Stochastic Regression<br />is not the case (e.g. high dimensional discrete distributions without factor structure) we<br />cannot presently recommend the optimization algorithm presented in this paper. The<br />extension of our approach to this class of problems is an important direction for future<br />work.<br />We have shown it is straightforward to extend our methodology to use hierarchical<br />structured approximations and more flexible approximating families such as mixtures.<br />This closes the gap considerably relative to MCMC methods.<br />selling point of MCMC methods is that they are asymptotically exact: in practice<br />this means simply running the MCMC chain for longer can give greater accuracy, an<br />option not available to a researcher using variational methods. However, if we use<br />a mixture approximating family then we can tune the computation time vs. accuracy<br />trade off simply by varying the number of mixture components used. Another interesting<br />direction of research along this line would be to use low rank approximating families<br />such as factor analysis models.<br />Perhaps the biggest<br />Variational inference usually requires that we use conditionally conjugate models: since<br />our method removes this restriction several possible avenues of research are opened. For<br />example, for MCMC methods collapsed versions of models (i.e. with certain parameters<br />or latent variables integrated out) sometimes permit much more efficient inference (Por-<br />teous et al. 2008) but adapting variational methods to work with collapsed models is<br />complex and requires custom per model methodology (Teh et al. 2006). However, our<br />method is indifferent to whether the model is collapsed or not, so it would be straight-<br />forward to experiment with different representations of the same model.<br />It is also possible to mix our method with VBEM, for example using our method for<br />any non-conjugate parts of the model and VBEM for variables that happen to be con-<br />ditionally conjugate. This is closely related to the non-conjugate variational message<br />passing (NCVMP) algorithm of Knowles and Minka (2011) implemented in Infer.NET,<br />which aims to fit non-conjugate models while maintaining the convenient message pass-<br />ing formalism. NCVMP only specifies how to perform the variational optimization, not<br />how to approximate required integrals: in Infer.NET where analytic expectations are<br />not available quadrature or secondary variational bounds are used, unlike the Monte<br />Carlo approach proposed here. It is still an open question how these different methods<br />could best be combined into a joint framework.<br />Acknowledgments<br />Tim Salimans wishes to acknowledge his advisors Richard Paap and Dennis Fok, as well as<br />the anonymous referees, for their substantial help in improving the paper. He thanks the<br />Netherlands Organization for Scientific Research (NWO) for financially supporting this project.<br />DAK thanks Wolfson College, Cambridge, Microsoft Research Cambridge, and the Center for<br />Cancer Systems Biology for funding.</p>  <p>Page 35</p> <p>T. Salimans and D. A. Knowles 871<br />References<br />Albert, J. (2009). Bayesian Computation with R. Springer Science, New York. Second<br />edition. 866<br />Amari, S. (1997). “Neural Learning in Structured Parameter Spaces - Natural Rieman-<br />nian Gradient.” In Advances in Neural Information Processing Systems, 127–133.<br />MIT Press. 842, 844<br />Attias, H. (2000). “A variational Bayesian framework for graphical models.” In Ad-<br />vances in Neural Information Processing Systems (NIPS) 12, 209–215. 837<br />Beal, M. J. and Ghahramani, Z. (2002). “The variational Bayesian EM algorithm for<br />incomplete data: with application to scoring graphical model structures.” In Bayesian<br />Statistics 7: Proceedings of the 7th Valencia International Meeting, 453–463. 839<br />— (2006). “Variational Bayesian learning of directed graphical models with hidden<br />variables.” Bayesian Analysis, 1(4): 793–832. 837<br />Bishop, C. M. (2006). Pattern recognition and machine learning, volume 1. Springer<br />New York. 840, 845<br />Bottou, L. (2010). “Large-Scale Machine Learning with Stochastic Gradient Descent.”<br />In Proceedings of the 19th International Conference on Computational Statistics<br />(COMPSTAT’2010), 177–187. Springer. 858<br />de Freitas, N., Højen-Sørensen, P., Jordan, M. I., and Russell, S. (2001). “Variational<br />MCMC.” In Proceedings of the Seventeenth Conference on Uncertainty in Artificial<br />Intelligence, UAI’01, 120–127. San Francisco, CA, USA: Morgan Kaufmann Publish-<br />ers Inc.<br />URL http://dl.acm.org/citation.cfm?id=2074022.2074038 876<br />Durbin, J. and Koopman, S. (2001). Time Series Analysis by State Space Methods.<br />Oxford University Press. 862<br />Geweke, J. (2005).<br />Interscience. 847<br />Contemporary Bayesian Econometrics and Statistics.Wiley-<br />Gilks, W., Thomas, A., and Spiegelhalter, D. (1994). “A language and program for<br />complex Bayesian modelling.” The Statistician, 169–177. 869<br />Girolami, M. and Calderhead, B. (2011). “Riemann manifold Langevin and Hamiltonian<br />Monte Carlo methods.” Journal of the Royal Statistical Society: Series B (Statistical<br />Methodology), 73(2): 123–214. 860, 863<br />Hoffman, M., Blei, D., and Bach, F. (2010). “Online learning for latent Dirichlet allo-<br />cation.” Advances in Neural Information Processing Systems, 23. 858<br />Hoffman, M., Blei, D., Wang, C., and Paisley, J. (2012). “Stochastic Variational Infer-<br />ence.” arXiv preprint arXiv:1206.7051. 843</p>  <p>Page 36</p> <p>872VB through Stochastic Regression<br />Honkela, A., Raiko, T., Kuusela, M., Tornio, M., and Karhunen, J. (2010). “Approxi-<br />mate Riemannian Conjugate Gradient Learning for Fixed-Form Variational Bayes.”<br />Journal of Machine Learning Research, 3235–3268. 837, 839, 843, 876<br />Hoogerheide, L., Opschoor, A., and van Dijk, H. K. (2012).<br />importance sampling weighted {EM} algorithms for efficient and robust posterior<br />and predictive simulation.” Journal of Econometrics, 171(2): 101 – 120.<br />URL<br />http://www.sciencedirect.com/science/article/pii/<br />S0304407612001583 860<br />“A class of adaptive<br />Jordan, M., Ghahramani, Z., Jaakkola, T., and Saul, L. (1999). “An introduction to<br />variational methods for graphical models.” Machine learning, 37(2): 183–233. 837<br />Kim, S., Shephard, N., and Chib, S. (1998). “Stochastic Volatility: Likelihood Inference<br />and Comparison with ARCH Models.” The Review of Economic Studies, 65(3): pp.<br />361–393. 860<br />Knowles, D. A. and Minka, T. P. (2011). “Non-conjugate Variational Message Pass-<br />ing for Multinomial and Binary Regression.” In Advances in Neural Information<br />Processing Systems (NIPS), 25. 870, 876<br />Liesenfeld, R. and Richard, J.-F. (2008). “Improving MCMC, using efficient importance<br />sampling.” Computational Statistics and Data Analysis, 53(2): 272 – 288. 863<br />Lovell, M. (2008). “A Simple Proof of the FWL Theorem.” The Journal of Economic<br />Education, 39(1): 88–91. 853<br />Minka, T. (2005). “Divergence measures and message passing.” Technical Report MSR-<br />TR-2005-173, Microsoft Research. 845, 876<br />Minka, T. P. (2001). “A family of algorithms for approximate Bayesian inference.”<br />Ph.D. thesis, MIT. 849, 855<br />Minka, T. P., Winn, J. M., Guiver, J. P., and Knowles, D. A. (2010). “Infer.NET 2.4.”<br />849, 869<br />Nemirovski, A., Juditsky, A., Lan, G., and Shapiro, A. (2009). “Robust Stochastic Ap-<br />proximation Approach to Stochastic Programming.” SIAM Journal on Optimization,<br />19(4): 1574–1609. 844<br />Nickisch, H. and Rasmussen, C. E. (2008). “Approximations for Binary Gaussian Pro-<br />cess Classification.” Journal of Machine Learning Research, 9: 2035–2078. 849, 876<br />Nott, D., Tan, S., Villani, M., and Kohn, R. (2012). “Regression density estimation<br />with variational methods and stochastic approximation.” Journal of Computational<br />and Graphical Statistics, 21(3): 797–820. 838<br />Opper, M. and Archambeau, C. (2009). “The Variational Gaussian Approximation<br />Revisited.” Neural Computation, 21(3): 786–792. 855</p>  <p>Page 37</p> <p>T. Salimans and D. A. Knowles 873<br />Ormerod, J. T. and Wand, M. P. (2010). “Explaining Variational Approximations.”<br />The American Statistician, 64(2): 140–153. 849, 850<br />Paisley, J., Blei, D., and Jordan, M. (2012).<br />Stochastic Search.” In International Conference on Machine Learning 2012. 838<br />“Variational Bayesian Inference with<br />Porteous, I., Newman, D., Ihler, A., Asuncion, A., Smyth, P., and Welling, M. (2008).<br />“Fast collapsed Gibbs sampling for latent Dirichlet allocation.” In Proceedings of<br />the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data<br />Mining, 569–577. 870<br />Richard, J.-F. and Zhang, W. (2007). “Efficient high-dimensional importance sampling.”<br />Journal of Econometrics, 141(2): 1385 – 1411. 841, 863, 875, 876<br />Robbins, H. and Monro, S. (1951). “A Stochastic Approximation Method.” The Annals<br />of Mathematical Statistics, 22(3): 400–407. 842, 844<br />Saul, L. and Jordan, M. (1996).<br />networks.” Advances in Neural Information Processing Systems, 486–492. 839<br />“Exploiting tractable substructures in intractable<br />Stern, D. H., Herbrich, R., and Graepel, T. (2009). “Matchbox: large scale online<br />Bayesian recommendations.” In Proceedings of the 18th International Conference on<br />World Wide Web, 111–120. 845<br />Storkey, A. J. (2000). “Dynamic Trees: A Structured Variational Method Giving Ef-<br />ficient Propagation Rules.” In Conference on Uncertainty in Artificial Intelligence<br />(UAI). 839<br />Teh, Y., Newman, D., and Welling, M. (2006). “A collapsed variational Bayesian in-<br />ference algorithm for latent Dirichlet allocation.” Advances in Neural Information<br />Processing Systems, 19: 1353–1360. 870, 876<br />Turner, R. E., Berkes, P., and Sahani, M. (2008). “Two problems with variational<br />expectation maximisation for time-series models.” In Proceedings of the Workshop<br />on Inference and Estimation in Probabilistic Time-Series Models, 107–115. 839, 876<br />Wainwright, M. J. and Jordan, M. I. (2008). “Graphical models, exponential families,<br />and variational inference.” Foundations and Trends® in Machine Learning, 1(1-2):<br />1–305. 837, 851<br />Winn, J. and Bishop, C. M. (2006). “Variational message passing.” Journal of Machine<br />Learning Research, 6(1): 661. 849</p>  <p>Page 38</p> <p>874VB through Stochastic Regression<br />Appendix A: Unnormalized to normalized optimality con-<br />dition<br />The unnormalized optimality condition in (8) is<br />˜ η =<br />„?<br />˜ q˜ η(x)˜T(x)?˜T(x)dν(x)<br />−1„?<br />˜ q˜ η(x)˜T(x)?logp(x,y)dν(x)<br /><br />.(46)<br />Clearly we can replace ˜ q(x) by its normalized version q(x) = ˜ q(x)/exp[U(η)] since the<br />normalizing terms will cancel. Recalling˜T(x) = (1,T(x)) and ˜ η = (η0,η?)?we then have<br />„<br />where Y := logp(x,y). Rearranging gives<br />ˆ<br />Solving for η0easily gives<br />1<br />E[T]<br />E[T?T]<br />E[T?]<br />−1ˆ<br />E[Y ]<br />E[T?Y ]<br />˙<br />=<br />ˆ<br />η0<br />η<br />˙<br />,(47)<br />E[Y ]<br />E[T?Y ]<br />˙<br />=<br />„<br />1<br />E[T]<br />E[T?T]<br />E[T?]<br />ˆ<br />η0<br />η<br />˙<br />.(48)<br />η0= E[Y ] − E[T]η = E[logp(x,y) − logq(x)] − U(η)<br />η = pE[T?T] − E[T?]E[T]q−1(E[T?Y ] − E[T?]E[Y ])<br />= Cov(T,T)−1Cov(T,Y ).<br />(49)<br />(50)<br />(51)<br />Appendix B: Derivation of Gaussian variational approxima-<br />tion<br />For notational simplicity we will derive our stochastic approximation algorithm for<br />Gaussian variational approximation (Algorithm 2) under the assumption that x is uni-<br />variate. The extension to multivariate x is conceptually straightforward but much more<br />tedious in terms of notation.<br />Let p(x,y) be the unnormalized posterior distribution of a univariate random variable<br />x, and let q(x) = N(m,V ) be its Gaussian approximation with sufficient statistics,<br />T(x) = (x,−0.5x2). In order to find the mean m and variance V that minimize the<br />KL-divergence between q(x) and p(x|y) we solve the transformed regression problem<br />defined in (30), i.e.<br />η =“K(η)Covqη(T(x),T(x))‰−1“K(η)Covqη(T(x),logp(x,y))‰<br />= C−1g<br />where<br />K(η) = [∇ηφ(η)]−1,</p>  <p>Page 39</p> <p>T. Salimans and D. A. Knowles 875<br />with φ = (φ1,φ2) = (m,V ) the usual mean-variance parameterization and where the<br />natural parameters are given by η = (V−1m,V−1). Recall identity (28) which states<br />that<br />∇φ1Eqφ[h(x)] = Eqφ[∇xh(x)],<br />with φ1= m the first element of the parameter vector φ, and g(x) any differentiable<br />function. Similarly, identity (29) reads<br />∇φ2Eqφ[h(x)] = −1<br />2Eqφ[∇x∇xh(x)],<br />with φ2= V the second element of the parameter vector. Using these identities we find<br />that the regression statistics for this optimization problem are given by<br />C := K(η)Covqφ[T(x),T(x)] = ∇φEqφ[T(x)]<br />= Eqφ[∇xT(x)] = Eqφ<br />„1<br />−x<br />1<br />2<br />0<br /><br />=<br />„1<br />−Eqφ[x]<br />1<br />2<br />0<br /><br />,<br />and<br />g := K(η)Covqφ[T(x),logp(x,y)]<br />= ∇φEqφ[logp(x,y)]<br /><br />⇒<br />„g1<br />g2<br />=<br />„<br />Eq[∇xlogp(x,y)]<br />2Eq[∇x∇xlogp(x,y)]<br />−1<br /><br />.<br />Now since η = C−1g we have<br />„Pm<br />⇒ η2= P = 2g2= −Eq[∇x∇xlogp(x,y)]<br />η1= Pm = g1+ P−1Eq[x] = Eq[∇xlogp(x,y)] + P−1Eq[x]<br />where Pm and P = V−1are the natural parameters (mean times precision and preci-<br />sion) of the approximation. Thus the quantities we need to stochastically approximate<br />are<br />P<br /><br />:=<br />„η1<br />η2<br /><br />=<br />„1<br />−Eqφ[x]<br />1<br />2<br />0<br />−1„g1<br />g2<br /><br />a := Eq[∇xlogp(x,y)]<br />H := Eq[∇x∇xlogp(x,y)]<br />z := Eq[x]<br />so we have P = −H and m = P−1a + z.<br />Appendix C: Connection to Efficient Importance Sampling<br />It is worth pointing out the connection between fixed-form variational Bayes and Richard<br />and Zhang’s (2007) Efficient Importance Sampling (EIS) algorithm. Although these</p>  <p>Page 40</p> <p>876VB through Stochastic Regression<br />authors take a different perspective (that of importance sampling) their goal of ap-<br />proximating the intractable posterior distribution with a more convenient distribution<br />is shared with variational Bayes. Specifically, Richard and Zhang (2007) choose their<br />posterior approximation to minimize the variance of the log-weights of the resulting im-<br />portance sampler. This leads to an optimization problem obeying a similar fixed-point<br />condition as in (9), but with the expectation taken over p(x|y) instead of q(x). Since<br />sampling from p(x|y) directly is not possible, they evaluate this expectation by sampling<br />from q(x) and weighting the samples using importance sampling. In practice however,<br />these ‘weights’ are often kept fixed to one during the optimization process in order to<br />improve the stability of the algorithm. When all weights are fixed to one, Richard and<br />Zhang’s (2007) fixed-point condition becomes identical to that of (9) and the algorithm<br />is in fact fitting a variational posterior approximation.<br />The connection between EIS and variational Bayes seems to have gone unnoticed until<br />now, but it has some important consequences. It is for example well known (e.g. Minka<br />2005; Nickisch and Rasmussen 2008; Turner et al. 2008) that the tails of variational<br />posterior approximations tend to be thinner than those of the actual posterior unless<br />the approximation is extremely close, which means that using EIS with the importance-<br />weights fixed to one is not to be recommended for general applications: In the case that<br />the posterior approximation is nearly exact, one might as well use it directly instead of<br />using it to form another approximation using importance sampling. In cases where the<br />approximation is not very close, the resulting importance sampling algorithm is likely to<br />suffer from infinite variance problems. The literature on variational Bayes offers some<br />help with these problems. Specifically, de Freitas et al. (2001) propose a number of ways<br />in which variational approximations can be combined with Monte Carlo methods, while<br />guarding for the aforementioned problems.<br />Much of the recent literature (e.g. Teh et al. 2006; Honkela et al. 2010) has focused<br />on the computational and algorithmic aspects of fitting variational posterior approx-<br />imations, and this work might also be useful in the context of importance sampling.<br />Algorithmically, the ‘sequential EIS’ approach of Richard and Zhang (2007) is most<br />similar to the non-conjugate VMP algorithm of Knowles and Minka (2011). As these<br />authors discuss, such an algorithm is not guaranteed to converge, and they present some<br />tricks that might be used to improve convergence in some difficult cases.<br />The algorithm presented in this paper for fitting variational approximations is provably<br />convergent, as discussed in Section 4. Furthermore, Sections 5 and 6 present multi-<br />ple new strategies for variance reduction and computational speed-up that might also<br />be useful for importance sampling. In this paper we will not pursue the application<br />of importance sampling any further, but exploring these connections more fully is a<br />promising direction for future work.</p>  <p>Page 41</p> <p>T. Salimans and D. A. Knowles877<br />Appendix D: Choosing an estimator<br />As discussed in Section 4, the particular estimator used in our stochastic approximation<br />is not the most obvious choice, but it seems to provide a lower variance approxima-<br />tion than other choices. In this section we consider three different MC estimators for<br />approximating (9) to see why this might be the case.<br />The first separately approximates the two integrals and then calculates the ratio:<br />˜<br />S<br />r<br />S<br />s<br />ˆ η1=<br />1<br />?<br />˜T(xr)?˜T(xr)<br />¸−1<br />1<br />?<br />˜T(xs)?logp(xs,y),xr,xs∼iidq(x),(52)<br />with S the number of Monte Carlo samples. The second approximates both integrals<br />using the same samples from q:<br />˜<br />S<br />s<br />S<br />s<br />ˆ η2=<br />1<br />?<br />˜T(xs)?˜T(xs)<br />¸−1<br />1<br />?<br />˜T(xs)?logp(xs,y),xs∼iidq(x).(53)<br />Only this estimator is directly analogous to the linear regression estimator. The third<br />estimator is available only when the first expectation is available analytically:<br />”˜T(x)?˜T(x)<br />We wish to understand the bias/variance tradeoff inherent in each of these estimators.<br />To keep notation manageable consider the case with only k = 1 sufficient statistic1and<br />let<br />ˆ ηa= Eq<br />ı−11<br />S<br />?<br />s<br />˜T(xs)?logp(xs,y),xs∼iidq(x).(54)<br />a(x) =˜T(x)?˜T(x) =˜T(x)2<br />b(x) =˜T(x)logp(x,y).<br />(55)<br />(56)<br />We can now write the three estimators of η more concisely as<br />?<br />S<br />1<br />S<br />1<br />S<br />1<br />S<br />E[a]<br />ˆ η1=<br />1<br />S<br />1<br />rb(xr)<br />sa(xs),<br />?<br />?<br />?<br />?<br />xr,xs∼iidq(x) (57)<br />ˆ η2=<br />sb(xs)<br />sa(xs),xs∼iidq(x) (58)<br />ˆ ηa=<br />sb(xs)<br />,xs∼iidq(x).(59)<br />Using a simple Taylor series argument it is straightforward to approximate the bias<br />and variance of these estimators. We first consider the bias. Consider the multivariate<br />Taylor expansion of f : RK→ R around the point ¯ y ∈ RK:<br />f(y) ≈ f(¯ y) + (y − ¯ y)?f?(¯ y) +1<br />2tr((y − ¯ y)(y − ¯ y)?∇2f(¯ y)).(60)<br />1These results extend in a straightforward manner to the case where k &gt; 1.</p>  <p>Page 42</p> <p>878VB through Stochastic Regression<br />From this we can derive expressions for the expectation of f(y):<br />E[f] ≈ f(¯ y) +1<br />2tr(Cov(y)f??(¯ y))(61)<br />where we have chosen to perform the Taylor expansion around the mean ¯ y = E[y]. For<br />the first estimator let y =1<br />S<br />»<br />S<br />s<br />ˆ<br />= η +Var(a)E[b]<br />SE[a]3<br />?<br />sa(xs) and f(y) = 1/y, then we find<br />˜<br />E[ˆ η1] = E<br />–<br />E[a]+Var(a)<br />1<br />?<br />a(xs)<br />¸−1fi<br />˙<br />flE[b]<br />E[b]<br />(62)<br />≈<br />1<br />SE[a]3<br />(63)<br />(64)<br />since Var(y) = Var(a)/S. We see that the bias term depends on the ratio Var(a)/E[a]2,<br />i.e. the spread of the distribution of a relative to its magnitude.<br />Now for the second estimator let<br />y =<br />„<br />1<br />S<br />1<br />S<br />?<br />sa(xs)<br />?<br />SCov([a,b]?) and<br />sb(xs)<br /><br />(65)<br />so that η2= f(y) =y2<br />y1. Note that Cov(y) =1<br />∇2f(y) =<br />«<br />2y2<br />y3<br />−1<br />1<br />−1<br />0<br />y2<br />1<br />y2<br />1<br />ff<br />.(66)<br />Putting everything together we have<br />E[ˆ η2] ≈ η +Var(a)Eb<br />SE[a]3<br />−Cov(a,b)<br />SE[a]2. (67)<br />Note that we recover the expression for Eˆ η1if Cov(a,b) = 0, which makes sense because<br />if we use different randomness for calculating E[a] and E[b] then a,b have 0 covariance<br />in our MC estimate. Finally the analytic estimator is unbiased:<br />Eˆ ηa= η. (68)<br />We now turn to the variances. The analytic estimator is a standard MC estimator with<br />variance<br />Var(ˆ ηa) =Var(b)<br />SE[a]2. (69)<br />Consider only the linear terms of the Taylor expansion:<br />f(y) ≈ f(¯ y) + (y − ¯ y)?f?(¯ y).(70)</p>  <p>Page 43</p> <p>T. Salimans and D. A. Knowles879<br />Substituting this into the formula for variance gives<br />Var[f(y)] = E[(f(y) − E[f(y)])(f(y) − E[f(y)])?]<br />≈ E[f?(¯ y)?(y − ¯ y)(y − ¯ y)?f?(¯ y)]<br />= f?(¯ y)?Var(y)f?(¯ y).<br />(71)<br />(72)<br />(73)<br />We will calculate the variance of the second estimator and derive the variance of the<br />first estimator from this. Again let y be as in (65). Note that Var(y) = Cov(a,b)/S.<br />We find<br />ˆE[b]2Vara<br />The final term is equal to that for the analytic estimator. The second term is not present<br />in the variance of the first estimator, since then a and b have no covariance under the<br />sampling distribution, i.e.<br />ˆE[b]2Vara<br />The first term is always positive, suggesting that ˆ η1is dominated by the analytic esti-<br />mator.<br />Var ˆ η2≈1<br />S<br />E[a]4<br />− 2E[b]Cov(a,b)<br />E[a]3<br />+Varb<br />E[a]2<br />˙<br />.(74)<br />Var ˆ η1≈1<br />S<br />E[a]4<br />+Varb<br />E[a]2<br />˙<br />.(75)<br />Summarizing these derivations, we have<br />bias(ˆ η1)<br />≈<br />Var(a)E[b]<br />SE[a]3<br />Var(a)E[b]<br />SE[a]3<br />bias(ˆ η2)<br />≈−Cov(a,b)<br />SE[a]2.(76)<br />Note that the first term is shared, but the first estimator does not have the covariance<br />term as a result of the independent sampling in approximating the numerator and<br />denominator. In contrast ˆ ηais unbiased. Now consider the variances<br />ˆE[b]2Var(a)<br />Var(ˆ η2) ≈1<br />S<br />E[a]4<br />Var(ˆ ηa) =Var(b)<br />SE[a]2.<br />Var(ˆ η1) ≈1<br />S<br />E[a]4<br />+Var(b)<br />E[a]2<br />− 2E[b]Cov(a,b)<br />E[a]3<br />˙<br />(77)<br />ˆE[b]2Var(a)<br />+Var(b)<br />E[a]2<br />˙<br />(78)<br />(79)<br />All three estimators have the same final term (the variance of the “analytic” estimator).<br />Again the second estimator has an additional term resulting from the covariance between<br />a and b which we find is typically beneficial in that it results in the variance of ˆ η being<br />significantly smaller. It is worth recalling that the mean squared error (MSE) of an<br />estimator is given by<br />E[(η − ˆ η)2] = Var(ˆ η) + bias(ˆ η)2.(80)</p>  <p>Page 44</p> <p>880VB through Stochastic Regression<br />Since both the variance and bias are O(1/S), the variance contribution to the MSE is<br />O(1/S) whereas the bias contribution is O(1/S2), so the variance is actually a greater<br />problem than the bias. From these expressions it is still not immediately obvious which<br />estimator we should use. However, consider the case when the target distribution p is<br />in the same exponential family as q, i.e. when logp(x,y) =˜T(x)λ. It is then straight-<br />forward to show that<br />bias(ˆ η1) ≈λVar(˜T2)<br />SE[˜T2]2,Var(ˆ η1) ≈ 2λ2Var(˜T2)<br />SE[˜T2]2<br />Var(ˆ η2) ≈ 0<br />(81)<br />bias(ˆ η2) ≈ 0,(82)<br />bias(ˆ ηa) = 0,Var(ˆ ηa) =λ2Var(˜T2)<br />SE[˜T2]2<br />.(83)<br />We see that in this case for ˆ η2the positive and negative contributions to both the bias<br />and variance cancel. While this result will not hold exactly for cases of interest, it<br />suggests that for exponential families which are capable of approximating p reasonably<br />well, ˆ η2should perform significantly better than ˆ η1or even ˆ ηa. If q and p are of the<br />same exponential family, it is actually possible to see that ˆ η2will in fact give the exact<br />solution in k + 1 samples (with k the number of sufficient statistics), while the other<br />estimators have non-vanishing variance for a finite number of samples. This means that<br />the approximate equality in (82) can be replaced by exact equality. Using k+1 samples<br />xi,i = 1,...,k + 1, assumed to be unique (which holds almost surely for continuous<br />distributions q), we have<br />ˆ η2=<br />˜k+1<br />i=1<br />?<br />˜T(xi)?˜T(xi)<br />¸−1k+1<br />?<br />i=1<br />˜T(xi)?˜T(xi)λ = λ.(84)<br />That is, the algorithm has recovered p(x,y) exactly with probability one. If we assume<br />we know how to normalize q, this means we also have p(x|y) exactly in this case.<br />Note that we recover the exact answer here because the p(x,y) function evaluations<br />are in themselves noise free, so the regression analogy really corresponds to a noise free<br />regression.<br />We test the three estimators in (52), (53) and (54) on the trivial exponential example<br />of Section 4 when the true exponential rate is λ = 1.5, and sampling from the optimal<br />q distribution with η = 1.5. The results confirm that ˆ η2finds the exact rate using just<br />S = 2 MC samples, as predicted by (84). We would expect ˆ ηato be unbiased, and this<br />is borne out by the results shown in Figure 8. The estimator ˆ η1 has both poor bias<br />and such large variance that it often gives an invalid negative rate if fewer than 10 MC<br />samples are used. While this is clearly a very simple example it hopefully emphasizes<br />the potential benefit to be gained from using estimators related to ˆ η2.</p>  <p>Page 45</p> <p>T. Salimans and D. A. Knowles881<br />10<br />0<br />10<br />1<br />10<br />2<br />10<br />3<br />10<br />4<br />10<br />−4<br />10<br />−2<br />10<br />0<br />10<br />2<br />10<br />4<br />10<br />6<br />10<br />8<br /># samples<br />estimate<br /> <br /> <br />eta 1<br />eta 2<br />eta analytic<br />Figure 8: Comparison of three estimators for fitting a variational posterior q to a simple<br />exponential distribution p. 50 repeats were used to estimate the mean and variance of<br />the estimator: the thick line shows the mean and the thin lines show ± one standard<br />deviation. The x-axis indicates the number of MC samples, S, used. As expected in<br />this case ˆ η2gives the correct solution of 1.5 using S ≥ 2 samples.</p>  <p>Page 46</p> <p>882VB through Stochastic Regression</p>  <a href="https://www.researchgate.net/profile/Tim_Salimans/publication/228083473_Fixed-Form_Variational_Posterior_Approximation_through_Stochastic_Linear_Regression/links/5486e7290cf268d28f062892.pdf">Download full-text</a> </div> <div id="rgw18_56ab9eee9ebe9" class="c-box pub-resource-container js-toggle" style=""> <h4 class="lf js-expand-list"><small><a href="javascript:" class="lf">View other sources <span class="ico-expand-list"></span></a></small></h4> <h4 class="lf js-collapse-list hidden"><small><a href="javascript:" class="lf">Hide other sources <span class="ico-collapse-list"></span></a></small></h4> <div class="clear"></div> <div class="scroll-wrapper hidden"> <ul class="files-list c-list" id="rgw19_56ab9eee9ebe9">  <li class="c-list-item pub-resource-item"  data-type="fulltext" id="rgw20_56ab9eee9ebe9"> <span class="ico-pub"></span> <div class="file-content"> <div class="download"> <a href="profile/Tim_Salimans/publication/228083473_Fixed-Form_Variational_Posterior_Approximation_through_Stochastic_Linear_Regression/links/5486e7290cf268d28f062892.pdf" class="publication-viewer" title="euclid.ba.1386166315.pdf">euclid.ba.1386166315.pdf</a> </div>  <div class="details">  <span> Available from <a href="profile/Tim_Salimans">Tim Salimans</a> &middot; Dec 9, 2014 </span>   </div>   <div class="details"> Available from <a href="http://projecteuclid.org/download/pdfview_1/euclid.ba/1386166315" target="_blank" rel="nofollow">projecteuclid.org</a> </div>   </div> </li>  <li class="c-list-item pub-resource-item"  data-type="fulltext" id="rgw21_56ab9eee9ebe9"> <span class="ico-pub"></span> <div class="file-content"> <div class="download"> <a href="profile/Tim_Salimans/publication/228083473_Fixed-Form_Variational_Posterior_Approximation_through_Stochastic_Linear_Regression/links/544f7c230cf26dda089103c3.pdf" class="publication-viewer" title="544f7c230cf26dda089103c3.pdf">544f7c230cf26dda089103c3.pdf</a> </div>  <div class="details">  <span> Available from <a href="profile/Tim_Salimans">Tim Salimans</a> &middot; Oct 28, 2014 </span>   </div>    </div> </li>  <li class="c-list-item pub-resource-item"  data-type="fulltext" id="rgw22_56ab9eee9ebe9"> <span class="ico-pub"></span> <div class="file-content"> <div class="download"> <a href="http://arxiv.org/pdf/1206.6679" target="_blank" rel="nofollow" class="publication-viewer" title="Fixed-Form Variational Posterior Approximation through Stochastic Linear Regression">Fixed-Form Variational Posterior Approximation thr...</a> </div>  <div class="details">   Available from <a href="http://arxiv.org/pdf/1206.6679" target="_blank" rel="nofollow">arxiv.org</a>  </div>    </div> </li>  </ul> </div> </div> </noscript> <div class="clearfix"> <div class="action-container">  </div> <div class="pub-legal"> Data provided are for informational purposes only. Although carefully collected, accuracy cannot be guaranteed. The impact factor represents a rough estimation of the journal's impact factor and does not reflect the actual current impact factor. Publisher conditions are provided by RoMEO. Differing provisions from the publisher's actual policy or licence agreement may be applicable. </div>   </div> </div> <div class="clearfix">     <div id="rgw24_56ab9eee9ebe9" class="c-box pub-resource-container js-toggle" style="display: none;"> <h4 class="lf js-expand-list"><small><a href="javascript:" class="lf">View other sources <span class="ico-expand-list"></span></a></small></h4> <h4 class="lf js-collapse-list hidden"><small><a href="javascript:" class="lf">Hide other sources <span class="ico-collapse-list"></span></a></small></h4> <div class="clear"></div> <div class="scroll-wrapper hidden"> <ul class="files-list c-list" id="rgw25_56ab9eee9ebe9">  </ul> </div> </div>   <div id="rgw14_56ab9eee9ebe9" class="similar-publications"> <h2>Similar Publications</h2> <ul class="list-bordered">  <li class="c-list-item li-publication-teaser" id="rgw15_56ab9eee9ebe9"> <div> <h5> <a href="publication/259625316_Implementing_and_Automating_Fixed-Form_Variational_Posterior_Approximation_through_Stochastic_Linear_Regression" class="color-inherit ga-similar-publication-title"><span class="publication-title">Implementing and Automating Fixed-Form Variational Posterior Approximation through Stochastic Linear Regression</span></a>  </h5>  <div class="authors"> <a href="researcher/2014625660_Tim_Salimans" class="authors ga-similar-publication-author">Tim Salimans</a>  </div>  </div> <div class="clear"></div> </li>  <li class="c-list-item li-publication-teaser" id="rgw16_56ab9eee9ebe9"> <div> <h5> <a href="publication/259578079_On_Using_Control_Variates_with_Stochastic_Approximation_for_Variational_Bayes_and_its_Connection_to_Stochastic_Linear_Regression" class="color-inherit ga-similar-publication-title"><span class="publication-title">On Using Control Variates with Stochastic Approximation for Variational Bayes and its Connection to Stochastic Linear Regression</span></a>  </h5>  <div class="authors"> <a href="researcher/2014625660_Tim_Salimans" class="authors ga-similar-publication-author">Tim Salimans</a>  </div>  </div> <div class="clear"></div> </li>  <li class="c-list-item li-publication-teaser" id="rgw17_56ab9eee9ebe9"> <div> <h5> <a href="publication/233328970_SEQUENTIAL_FIXED-PRECISION_ESTIMATION_IN_STOCHASTIC_LINEAR_REGRESSION_MODELS" class="color-inherit ga-similar-publication-title"><span class="publication-title">SEQUENTIAL FIXED-PRECISION ESTIMATION IN STOCHASTIC LINEAR REGRESSION MODELS</span></a>  </h5>  <div class="authors"> <a href="researcher/2002884186_Sujay_Datta" class="authors ga-similar-publication-author">Sujay Datta</a>  </div>  </div> <div class="clear"></div> </li>  </ul> </div> </div> </div> </div> </div></div></div>
<div class="clear"></div><div id="rgw38_56ab9eee9ebe9" class="default-footer"> <div id="footer" class="clearfix"> <span class="footer-left"> &copy; 2008&dash;2016 researchgate.net. All rights reserved. </span> <span class="footer-right"> <a href="https://www.researchgate.net/about">About us</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="https://www.researchgate.net/contact">Contact us</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="careers">Careers</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="developers">Developers</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="blog" target="_blank">News</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="application.PrivacyPolicy.html">Privacy</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="application.TermsAndConditions.html">Terms</a> <span class="footer-link-separator" style="padding: 0 5px;">&nbsp;|&nbsp;</span> <a href="advertising?_ref=ft">Advertising</a> <span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="recruiters?_ref=ft">Recruiting</a> </span> </div>  </div></div>
<div id="rgw39_56ab9eee9ebe9">  <div class="header-wrapper-logged-out"> <div id="header"> <div class="header-content"> <a href="" class="g-l-logo"> <svg width="149" height="19"> <image xlink:href="https://c5.rgstatic.net/m/235107188705592/images/template/brand-header-logo.svg" src="https://c5.rgstatic.net/m/238113351022438/images/template/brand-header-logo.png" width="149" height="19"/> </svg> </a> <a href="" class="g-l-logo-ico"> <svg width="127" height="17" viewbox="0 0 127 22"> <image xlink:href="https://c5.rgstatic.net/m/235107188705592/images/template/brand-header-logo.svg" src="https://c5.rgstatic.net/m/238113351022438/images/template/brand-header-logo.png" width="127" height="17"/> </svg> </a> <div id="rgw40_56ab9eee9ebe9" class="header-login-wrapper js-header-login"> <div class="dropdown-right-align"> <div class="login-signup-container lf"> <a href="https://www.researchgate.net/signup.SignUp.html?ev=su_chnl_index&amp;hdrsu=1&amp;_sg=UCKT13aG8DtCq_sF7zncbtz-l9rRY_dd9_p5A1q1SjOQFGS5nRu6HDMQmd2CZJc2" class="dropdown-toggle lf">Join for free</a> </div> <div class="dropdown lf" style="height: 20px;"> <a href="https://www.researchgate.net/application.Login.html" class="js-login-url dropdown-toggle lf">Log in <span class="caret"></span></a> <div class="dropdown-menu"> <div class="header-login-form-wrapper"> <!--[if IE 6]><p class="box-warning" style="margin-bottom: 0;">Sorry, ResearchGate no longer supports the version of Internet Explorer you are using. <a href="http://whatbrowser.org/" rel="nofollow" target="_blank">Update your web browser</a> and then log in. </p><![endif]--> <form method="post" action="https://www.researchgate.net/application.Login.html" class="form-big header-login-form js-login-form" name="loginForm" id="headerLoginForm"> <input type="hidden" name="request_token" value="ljrYRD4+/XOEZfDF9FQPeKsM5jpERD48usEogaKilFHcc11t+OhHVGt0ZnH5G84fx+6WRrwEwY/YDd2VPMSDmTcBRLuDYh72Wn4Sgn4rJZW/7g4JtGpmhX0a4tJavYDpdg9gIqNKCXXui2u/Ryf0PD3yV7yQlopeYmEBmeFGl8Fo+65ZNqNUYb1IVIqHchyw0FJnmDJGOkIcuSbI6Cm+XlQJcUh7Gr3zOXpevFhrnbJMQ9nitN9D1zWzp0HRU6UIILO0Li0nORGr2Z31QbFGQkeB4rzAJg3x5NE7w72APyQ="/> <input type="hidden" name="urlAfterLogin" value="publication/228083473_Fixed-Form_Variational_Posterior_Approximation_through_Stochastic_Linear_Regression"/> <input type="hidden" name="invalidPasswordCount" value="0"/> <input type="hidden" name="headerLogin" value="yes"/> <label for="input-header-login">Email</label> <div class="login-input"> <div class="info-tip-wrapper"> <span class="ico-info js-info"></span> </div> <input type="email" value="" name="login" class="login js-login-input text" id="input-header-login" tabindex="1"/> </div> <div class="clear"></div> <label class="lf" for="input-header-password"> Password </label> <a class="rf forgot-password js-forgot-password" href="application.LostPassword.html">Forgot password?</a> <div class="clear"></div> <input type="password" value="" name="password" class="password js-password-input text" id="input-header-password" tabindex="2"/> <div class="clear"></div> <label class="remember-me" for="headerLoginCookie"> <input type="checkbox" checked="checked" value="yes" name="setLoginCookie" class="lf checkbox" id="headerLoginCookie" tabindex="3"/> Keep me logged in </label> <div class="clear"></div> <input value="Log in" name="loginSubmit" class="btn btn-promote btn-fullwidth btn-large allow-leave js-submit-button" type="submit" tabindex="4"/> </form> <div class="connectors"> <div class="text">or log in with</div> <div class="connector-actions"> <a href="connector/linkedin/" class="li-connect js-li-connect" data-redirect-url="cHVibGljYXRpb24vMjI4MDgzNDczX0ZpeGVkLUZvcm1fVmFyaWF0aW9uYWxfUG9zdGVyaW9yX0FwcHJveGltYXRpb25fdGhyb3VnaF9TdG9jaGFzdGljX0xpbmVhcl9SZWdyZXNzaW9u"> <span class="icon ico-linkedin-round-grey"></span> <span class="icon ico-linkedin-round"></span> </a> <a href="connector/facebook/" class="fb-connect middle js-fb-connect" data-redirect-url="cHVibGljYXRpb24vMjI4MDgzNDczX0ZpeGVkLUZvcm1fVmFyaWF0aW9uYWxfUG9zdGVyaW9yX0FwcHJveGltYXRpb25fdGhyb3VnaF9TdG9jaGFzdGljX0xpbmVhcl9SZWdyZXNzaW9u"> <span class="icon ico-facebook-round-grey"></span> <span class="icon ico-facebook-round"></span> </a> <a href="connector/google/" class="g-connect js-g-connect" data-redirect-url="cHVibGljYXRpb24vMjI4MDgzNDczX0ZpeGVkLUZvcm1fVmFyaWF0aW9uYWxfUG9zdGVyaW9yX0FwcHJveGltYXRpb25fdGhyb3VnaF9TdG9jaGFzdGljX0xpbmVhcl9SZWdyZXNzaW9u"> <span class="icon ico-google-round-grey"></span> <span class="icon ico-google-round"></span> </a> </div> </div> </div> </div> </div> </div> </div> </div> </div> <script type="application/ld+json">
{ "@context" : "http://schema.org",
  "@type" : "Organization",
  "name" : "ResearchGate",
  "url" : "http://www.researchgate.net",
  "logo" : "http://www.researchgate.net/images/template/rg_logo_square_brand.png",
  "sameAs" : [ "https://www.facebook.com/ResearchGate",
    "https://twitter.com/ResearchGate",
    "https://plus.google.com/+researchgate",
    "https://www.linkedin.com/company/researchgate"] 
}
</script> </div> </div><div class="c-signup-bar" id="rgw41_56ab9eee9ebe9"> <div class="banner-contents">   <span class="message">ResearchGate is the professional network for scientists and researchers.</span> <a href="signup.SignUp.html?ev=su_banner" class="btn btn-large btn-promote">Join for free</a>  </div> </div></div>
<script>
rgConfig.backendTime = 1289;
</script>
<script src="//c5.rgstatic.net/m/2277196935388619/javascript/lib/yui3/yui/yui-min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/21832295316281274/javascript/yuiLoaderConfig-min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/23178613132105398/javascript/vendor/babel-core/browser-polyfill.min.js" type="text/javascript"></script>
<script>
(function (){
if (typeof YRG === "undefined") {
var xmlHttpRequest = new XMLHttpRequest();
xmlHttpRequest.open("post", "go.Error.html");
xmlHttpRequest.setRequestHeader("Content-Type", "application/json");
xmlHttpRequest.setRequestHeader("Accept", "application/json"); var loadedScripts = "";
if (window.performance && window.performance.getEntriesByType) {
    var result = [];
    var resources = performance.getEntriesByType("resource");
    for (var i in resources) {
        if (resources.hasOwnProperty(i)) {
            result.push({
                name: resources[i].name,
                duration: resources[i].duration
            });
        }
    }
    loadedScripts += "&loadedScripts=" + encodeURIComponent(JSON.stringify(result));
}
if (typeof YUI === "undefined") {
    loadedScripts += "&yuiLoaded=false";
} else {
    loadedScripts += "&yuiLoaded=true";
}
xmlHttpRequest.send("Type=InformationException&message=" + encodeURIComponent("Error loading YUI") + loadedScripts);
}
})();
</script>
<script>if (typeof YRG !== 'undefined') { YRG.use('rg-base',function(Y){Y.applyConfig({ignore: ["css-rg","css-rg2","css-ie","css-modules-publicprofile","css-pow-publicliterature-FollowPublicationPromo","css-pow-application-PdfJsReader","css-pow-publicliterature-PublicationInlineReader"]});Y.use(["rg.core.pagespeed.Monitoring"],function(Y){(function(){Y.rg.createInitialWidget({"data":{"content":{"data":{"profileSmallHeader":{"data":{"profileBadge":{"data":{"fullname":"Tim Salimans","imageUrl":"https:\/\/i1.rgstatic.net\/ii\/profile.image\/AS%3A278933837762578%401443514417931_m","profileStats":[],"profileFollowButton":null,"profileReputationScoreNumber":null,"profileUrl":"profile\/Tim_Salimans","institution":"Algoritmica","institutionUrl":false,"widgetId":"rgw4_56ab9eee9ebe9"},"id":"rgw4_56ab9eee9ebe9","partials":[],"templateName":"publicprofile\/stubs\/ProfileBadge.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicprofile.ProfileBadge.html?accountId=6029690","viewClass":null,"yuiModules":["css-modules-publicprofile"],"stylesheets":["modules\/publicprofile.css"],"_isYUI":true},"widgetId":"rgw3_56ab9eee9ebe9"},"id":"rgw3_56ab9eee9ebe9","partials":[],"templateName":"publicprofile\/stubs\/ProfileSmallHeader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicprofile.ProfileSmallHeader.html?publicationUid=228083473","viewClass":null,"yuiModules":["css-modules-publicprofile"],"stylesheets":["modules\/publicprofile.css"],"_isYUI":true},"publication":{"data":{"publicationUid":228083473,"title":"Fixed-Form Variational Posterior Approximation through Stochastic Linear Regression","journalTitle":false,"journalDetailsTooltip":false,"affiliation":false,"type":"Article","details":{"doi":"10.1214\/13-BA858","journalInfos":{"journal":"Bayesian Analysis","publicationDate":"06\/2012;","publicationDateRobot":"2012-06","article":"8(4)."}},"source":{"sourceUrl":"http:\/\/arxiv.org\/abs\/1206.6679","sourceName":"arXiv"},"publicationActions":null,"publicationCoins":{"data":{"tags":[{"key":"ctx_ver","value":"Z39.88-2004"},{"key":"rft_val_fmt","value":"info:ofi\/fmt:kev:mtx:journal"},{"key":"rfr_id","value":"info:sid\/researchgate.net:researchgate"},{"key":"rft_id","value":"info:doi\/10.1214\/13-BA858"},{"key":"rft.atitle","value":"Fixed-Form Variational Posterior Approximation through Stochastic Linear Regression"},{"key":"rft.title","value":"Bayesian Analysis"},{"key":"rft.jtitle","value":"Bayesian Analysis"},{"key":"rft.volume","value":"8"},{"key":"rft.issue","value":"4"},{"key":"rft.date","value":"2012"},{"key":"rft.issn","value":"1936-0975"},{"key":"rft.au","value":"Tim Salimans,David A. Knowles"},{"key":"rft.genre","value":"article"}],"widgetId":"rgw6_56ab9eee9ebe9"},"id":"rgw6_56ab9eee9ebe9","partials":[],"templateName":"publicliterature\/stubs\/PublicationCoins.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationCoins.html?publicationUid=228083473","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationAuthors":{"data":{"publicationUid":228083473,"peopleItems":[{"data":{"authorNameOnPublication":"Tim Salimans","accountUrl":"profile\/Tim_Salimans","accountKey":"Tim_Salimans","imageUrl":"https:\/\/i1.rgstatic.net\/ii\/profile.image\/AS%3A278933837762578%401443514417931_m","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Tim Salimans","profile":{"professionalInstitution":{"professionalInstitutionName":"Algoritmica","professionalInstitutionUrl":false}},"professionalInstitutionName":"Algoritmica","professionalInstitutionUrl":false,"url":"profile\/Tim_Salimans","imageUrl":"https:\/\/i1.rgstatic.net\/ii\/profile.image\/AS%3A278933837762578%401443514417931_l","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":false,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":true,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"accountKey":"Tim_Salimans","hasInfoPopup":false,"hasTeaserPopup":true,"showContactAuthorButton":true,"widgetId":"rgw9_56ab9eee9ebe9"},"id":"rgw9_56ab9eee9ebe9","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAccountItem.html?entityId=6029690&enableUnfollow=0&imageSize=l&enableFollowButton=0&showContactAuthorButton=1","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"accountInstitution":"Algoritmica","score":null,"largeTooltip":false,"useRebrandedImageStyle":null,"authorCount":2,"accountCount":2,"publicationUid":228083473,"widgetId":"rgw8_56ab9eee9ebe9"},"id":"rgw8_56ab9eee9ebe9","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAccountItem.html","templateExtensions":[],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAccountItem.html?accountId=6029690&context=pubdetail_authors_xflw&showContactAuthorButton=1&authorCount=2&accountCount=2&publicationUid=228083473","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true},{"data":{"authorNameOnPublication":"David A. Knowles","accountUrl":"profile\/David_Knowles2","accountKey":"David_Knowles2","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2671872220764\/images\/template\/default\/profile\/profile_default_m.jpg","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"David A. Knowles","profile":{"professionalInstitution":{"professionalInstitutionName":"Stanford University","professionalInstitutionUrl":"institution\/Stanford_University"}},"professionalInstitutionName":"Stanford University","professionalInstitutionUrl":"institution\/Stanford_University","url":"profile\/David_Knowles2","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":false,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":true,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"accountKey":"David_Knowles2","hasInfoPopup":false,"hasTeaserPopup":true,"showContactAuthorButton":true,"widgetId":"rgw11_56ab9eee9ebe9"},"id":"rgw11_56ab9eee9ebe9","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAccountItem.html?entityId=7693199&enableUnfollow=0&imageSize=l&enableFollowButton=0&showContactAuthorButton=1","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"accountInstitution":"Stanford University","score":null,"largeTooltip":false,"useRebrandedImageStyle":null,"authorCount":2,"accountCount":2,"publicationUid":228083473,"widgetId":"rgw10_56ab9eee9ebe9"},"id":"rgw10_56ab9eee9ebe9","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAccountItem.html","templateExtensions":[],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAccountItem.html?accountId=7693199&context=pubdetail_authors_xflw&showContactAuthorButton=1&authorCount=2&accountCount=2&publicationUid=228083473","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true}],"hasMore":false,"nextOffset":6,"useRebrandedImageStyle":null,"widgetId":"rgw7_56ab9eee9ebe9"},"id":"rgw7_56ab9eee9ebe9","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorList.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorList.html?publicationUid=228083473&context=pubdetail_authors_xflw&showContactAuthorButton=1","viewClass":"views.publicliterature.PublicationDetailAuthorListView","yuiModules":["rg.views.publicliterature.PublicationDetailAuthorListView"],"stylesheets":[],"_isYUI":true},"publicationAbstract":{"data":{"publicationUid":228083473,"abstract":"<noscript><\/noscript><div>We propose a general algorithm for approximating nonstandard Bayesian<br \/>\nposterior distributions. The algorithm minimizes the Kullback-Leibler<br \/>\ndivergence of an approximating distribution to the intractable posterior<br \/>\ndistribution. Our method can be used to approximate any posterior distribution,<br \/>\nprovided that it is given in closed form up to the proportionality constant.<br \/>\nThe approximation can be any distribution in the exponential family or any<br \/>\nmixture of such distributions, which means that it can be made arbitrarily<br \/>\nprecise. Several examples illustrate the speed and accuracy of our<br \/>\napproximation method in practice.<\/div>","canEdit":false,"isAdmin":false,"isArtifact":false,"showFullAbstract":true,"widgetId":"rgw12_56ab9eee9ebe9"},"id":"rgw12_56ab9eee9ebe9","partials":[],"templateName":"publicliterature\/stubs\/PublicationAbstract.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationAbstract.html?publicationUid=228083473","viewClass":"views.publicliterature.PublicationAbstractView","yuiModules":["rg.views.publicliterature.PublicationAbstractView"],"stylesheets":[],"_isYUI":true},"publicationKeywords":null,"publicationState":null,"isGuest":true,"isAdminEditingAllowed":false,"isArtifact":false,"figureListWidget":null,"previewImage":"https:\/\/i1.rgstatic.net\/publication\/228083473_Fixed-Form_Variational_Posterior_Approximation_through_Stochastic_Linear_Regression\/links\/5486e7290cf268d28f062892\/smallpreview.png","nativeAdDisclosure":null,"showFollowPublicationButton":false,"followPublicationPromo":{"data":{"widgetId":"rgw13_56ab9eee9ebe9"},"id":"rgw13_56ab9eee9ebe9","partials":[],"templateName":"publicliterature\/stubs\/FollowPublicationPromo.html","templateExtensions":[],"attrs":{"context":null,"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.FollowPublicationPromo.html","viewClass":null,"yuiModules":["css-pow-publicliterature-FollowPublicationPromo"],"stylesheets":["pow\/publicliterature\/FollowPublicationPromo.css"],"_isYUI":true},"widgetId":"rgw5_56ab9eee9ebe9"},"id":"rgw5_56ab9eee9ebe9","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailItem.html","templateExtensions":["generalHelpers"],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailItem.html?publicationUid=228083473&showActionBar=0&showContactAuthorButton=1&showRequestFulltextExperience=0&showNoRgAuthorsRequestFulltextExperience=0&showFollowPublicationPromo=1","viewClass":"views.publicliterature.PublicationDetailItemView","yuiModules":["rg.views.publicliterature.PublicationDetailItemView"],"stylesheets":[],"_isYUI":true},"similarPublications":{"data":{"publicationListItems":[{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":2014625660,"url":"researcher\/2014625660_Tim_Salimans","fullname":"Tim Salimans","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Jan 2014","journal":null,"showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/259625316_Implementing_and_Automating_Fixed-Form_Variational_Posterior_Approximation_through_Stochastic_Linear_Regression","usePlainButton":true,"publicationUid":259625316,"feedStubs":null,"hasFeedStubs":false,"impactPoints":false,"url":"publication\/259625316_Implementing_and_Automating_Fixed-Form_Variational_Posterior_Approximation_through_Stochastic_Linear_Regression","title":"Implementing and Automating Fixed-Form Variational Posterior Approximation through Stochastic Linear Regression","displayTitleAsLink":true,"authors":[{"id":2014625660,"url":"researcher\/2014625660_Tim_Salimans","fullname":"Tim Salimans","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":[],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/259625316_Implementing_and_Automating_Fixed-Form_Variational_Posterior_Approximation_through_Stochastic_Linear_Regression","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/259625316_Implementing_and_Automating_Fixed-Form_Variational_Posterior_Approximation_through_Stochastic_Linear_Regression\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw15_56ab9eee9ebe9"},"id":"rgw15_56ab9eee9ebe9","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=259625316","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":2014625660,"url":"researcher\/2014625660_Tim_Salimans","fullname":"Tim Salimans","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Jan 2014","journal":null,"showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/259578079_On_Using_Control_Variates_with_Stochastic_Approximation_for_Variational_Bayes_and_its_Connection_to_Stochastic_Linear_Regression","usePlainButton":true,"publicationUid":259578079,"feedStubs":null,"hasFeedStubs":false,"impactPoints":false,"url":"publication\/259578079_On_Using_Control_Variates_with_Stochastic_Approximation_for_Variational_Bayes_and_its_Connection_to_Stochastic_Linear_Regression","title":"On Using Control Variates with Stochastic Approximation for Variational Bayes and its Connection to Stochastic Linear Regression","displayTitleAsLink":true,"authors":[{"id":2014625660,"url":"researcher\/2014625660_Tim_Salimans","fullname":"Tim Salimans","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":[],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/259578079_On_Using_Control_Variates_with_Stochastic_Approximation_for_Variational_Bayes_and_its_Connection_to_Stochastic_Linear_Regression","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/259578079_On_Using_Control_Variates_with_Stochastic_Approximation_for_Variational_Bayes_and_its_Connection_to_Stochastic_Linear_Regression\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw16_56ab9eee9ebe9"},"id":"rgw16_56ab9eee9ebe9","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=259578079","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":2002884186,"url":"researcher\/2002884186_Sujay_Datta","fullname":"Sujay Datta","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Aug 2002","journal":"Sequential Analysis","showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/233328970_SEQUENTIAL_FIXED-PRECISION_ESTIMATION_IN_STOCHASTIC_LINEAR_REGRESSION_MODELS","usePlainButton":true,"publicationUid":233328970,"feedStubs":null,"hasFeedStubs":false,"impactPoints":"0.50","url":"publication\/233328970_SEQUENTIAL_FIXED-PRECISION_ESTIMATION_IN_STOCHASTIC_LINEAR_REGRESSION_MODELS","title":"SEQUENTIAL FIXED-PRECISION ESTIMATION IN STOCHASTIC LINEAR REGRESSION MODELS","displayTitleAsLink":true,"authors":[{"id":2002884186,"url":"researcher\/2002884186_Sujay_Datta","fullname":"Sujay Datta","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["Sequential Analysis 08\/2002; No. 3(pp. 161\u2013190):161-190. DOI:10.1081\/SQA-120014362"],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/233328970_SEQUENTIAL_FIXED-PRECISION_ESTIMATION_IN_STOCHASTIC_LINEAR_REGRESSION_MODELS","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/233328970_SEQUENTIAL_FIXED-PRECISION_ESTIMATION_IN_STOCHASTIC_LINEAR_REGRESSION_MODELS\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw17_56ab9eee9ebe9"},"id":"rgw17_56ab9eee9ebe9","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=233328970","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"viewClass":"sidebar","widgetId":"rgw14_56ab9eee9ebe9"},"id":"rgw14_56ab9eee9ebe9","partials":[],"templateName":"publicliterature\/stubs\/SimilarPublications.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.SimilarPublications.html?referencePublicationId=228083473&view=sidebar","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationFulltextPreview":null,"publicationResourcesFulltext":{"data":{"publicationUid":228083473,"publicationResourceList":{"data":{"publicationResourceItems":[{"data":{"publicationUid":228083473,"publicationType":"article","linkId":"5486e7290cf268d28f062892","fileName":"euclid.ba.1386166315.pdf","fileUrl":"profile\/Tim_Salimans\/publication\/228083473_Fixed-Form_Variational_Posterior_Approximation_through_Stochastic_Linear_Regression\/links\/5486e7290cf268d28f062892.pdf","name":"Tim Salimans","nameUrl":"profile\/Tim_Salimans","canRemove":false,"fileIcon":"ico-pub","canPreview":true,"hasPublisherLink":"http:\/\/projecteuclid.org\/download\/pdfview_1\/euclid.ba\/1386166315","hasMetaData":true,"hide":false,"fulltext":"ico-pub","origin":"publication_list","isLastLink":false,"publisherLink":"http:\/\/projecteuclid.org\/download\/pdfview_1\/euclid.ba\/1386166315","publisherLinkDisplay":"projecteuclid.org","isUserLink":true,"uploadDate":"Dec 9, 2014","fileSize":"585.68 KB","widgetId":"rgw20_56ab9eee9ebe9"},"id":"rgw20_56ab9eee9ebe9","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceItem.html","templateExtensions":["generalHelpers"],"attrs":{"fileRequiredPublicationTypes":["code","coverPage","experimentFindings","method","negativeResults","presentation","rawData","researchProposal","workingPaper","artifact","dataset"]},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceItem.html?publicationUid=228083473&linkId=5486e7290cf268d28f062892&hide=0&disableJavascript=disableJavascript&useAlternativeTemplate=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"publicationUid":228083473,"publicationType":"article","linkId":"544f7c230cf26dda089103c3","fileName":"544f7c230cf26dda089103c3.pdf","fileUrl":"profile\/Tim_Salimans\/publication\/228083473_Fixed-Form_Variational_Posterior_Approximation_through_Stochastic_Linear_Regression\/links\/544f7c230cf26dda089103c3.pdf","name":"Tim Salimans","nameUrl":"profile\/Tim_Salimans","canRemove":false,"fileIcon":"ico-pub","canPreview":true,"hasPublisherLink":null,"hasMetaData":true,"hide":false,"fulltext":"ico-pub","origin":"publication_list","isLastLink":false,"isUserLink":true,"uploadDate":"Oct 28, 2014","fileSize":"585.84 KB","widgetId":"rgw21_56ab9eee9ebe9"},"id":"rgw21_56ab9eee9ebe9","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceItem.html","templateExtensions":["generalHelpers"],"attrs":{"fileRequiredPublicationTypes":["code","coverPage","experimentFindings","method","negativeResults","presentation","rawData","researchProposal","workingPaper","artifact","dataset"]},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceItem.html?publicationUid=228083473&linkId=544f7c230cf26dda089103c3&hide=0&disableJavascript=disableJavascript&useAlternativeTemplate=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"publicationUid":228083473,"publicationType":"article","linkId":"02b044d40cf27908e9dda293","fileName":"Fixed-Form Variational Posterior Approximation through Stochastic Linear Regression","fileUrl":"http:\/\/arxiv.org\/pdf\/1206.6679","name":"arxiv.org","nameUrl":"http:\/\/arxiv.org\/pdf\/1206.6679","canRemove":false,"fileIcon":"ico-pub","canPreview":true,"hasPublisherLink":null,"hasMetaData":true,"hide":false,"fulltext":"ico-pub","origin":"publication_list","isLastLink":false,"isUserLink":false,"widgetId":"rgw22_56ab9eee9ebe9"},"id":"rgw22_56ab9eee9ebe9","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceItem.html","templateExtensions":["generalHelpers"],"attrs":{"fileRequiredPublicationTypes":["code","coverPage","experimentFindings","method","negativeResults","presentation","rawData","researchProposal","workingPaper","artifact","dataset"]},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceItem.html?publicationUid=228083473&linkId=02b044d40cf27908e9dda293&hide=0&disableJavascript=disableJavascript&useAlternativeTemplate=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"widgetId":"rgw19_56ab9eee9ebe9"},"id":"rgw19_56ab9eee9ebe9","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceList.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceList.html?publicationUid=228083473&limit=3&disableJavascript=disableJavascript&type=fulltextFile","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"resourceCount":3,"hidden":false,"showMore":false,"fulltext":true,"publicationDownloadCount":{"data":{"value":51,"valueFormatted":"51","widgetId":"rgw23_56ab9eee9ebe9"},"id":"rgw23_56ab9eee9ebe9","partials":[],"templateName":"publicliterature\/stubs\/PublicationDownloadCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDownloadCount.html?publicationUid=228083473","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw18_56ab9eee9ebe9"},"id":"rgw18_56ab9eee9ebe9","partials":[],"templateName":"publicliterature\/stubs\/PublicationResources.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResources.html?publicationUid=228083473&type=fulltextFile&disableJavascript=1","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationResourcesAttachments":{"data":{"publicationUid":228083473,"publicationResourceList":{"data":{"publicationResourceItems":[],"widgetId":"rgw25_56ab9eee9ebe9"},"id":"rgw25_56ab9eee9ebe9","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceList.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceList.html?publicationUid=228083473&limit=3&disableJavascript=disableJavascript&type=attachmentFile","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"resourceCount":0,"hidden":true,"showMore":false,"fulltext":false,"publicationDownloadCount":{"data":{"value":51,"valueFormatted":"51","widgetId":"rgw26_56ab9eee9ebe9"},"id":"rgw26_56ab9eee9ebe9","partials":[],"templateName":"publicliterature\/stubs\/PublicationDownloadCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDownloadCount.html?publicationUid=228083473","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw24_56ab9eee9ebe9"},"id":"rgw24_56ab9eee9ebe9","partials":[],"templateName":"publicliterature\/stubs\/PublicationResources.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResources.html?publicationUid=228083473&type=attachmentFile","viewClass":"views.publicliterature.PublicationResourcesView","yuiModules":["rg.views.publicliterature.PublicationResourcesView"],"stylesheets":[],"_isYUI":true},"publicationText":{"data":{"hide":false,"pages":[{"page":1,"text":"Bayesian Analysis (2013)8, Number 4, pp. 837\u2013882\nFixed-Form Variational Posterior Approximation\nthrough Stochastic Linear Regression\nTim Salimans\u2217and David A. Knowles\u2020\nAbstract.\nBayesian posterior distributions. The algorithm minimizes the Kullback-Leibler\ndivergence of an approximating distribution to the intractable posterior distribu-\ntion. Our method can be used to approximate any posterior distribution, provided\nthat it is given in closed form up to the proportionality constant. The approxi-\nmation can be any distribution in the exponential family or any mixture of such\ndistributions, which means that it can be made arbitrarily precise. Several exam-\nples illustrate the speed and accuracy of our approximation method in practice.\nWe propose a general algorithm for approximating nonstandard\nKeywords: variational Bayes, approximate inference, stochastic approximation\n1 Introduction\nIn Bayesian analysis the form of the posterior distribution is often not analytically\ntractable. To obtain quantities of interest under such a distribution, such as moments\nor marginal distributions, we typically need to use Monte Carlo methods or approxi-\nmate the posterior with a more convenient distribution. A popular method of obtaining\nsuch an approximation is structured or fixed-form Variational Bayes, which works by\nnumerically minimizing the Kullback-Leibler divergence of an approximating distribu-\ntion in the exponential family to the intractable target distribution (Attias 2000; Beal\nand Ghahramani 2006; Jordan et al. 1999; Wainwright and Jordan 2008). For certain\nproblems, algorithms exist that can solve this optimization problem in much less time\nthan it would take to approximate the posterior using Monte Carlo methods (see e.g.\nHonkela et al. 2010). However, these methods usually rely on analytic solutions to\ncertain integrals and need conditional conjugacy in the model specification, i.e. the\ndistribution of each variable conditional on its Markov blanket must be an analytically\ntractable member of the exponential family for these methods to be applicable. As a\nresult this class of methods is limited in the type of approximations and posteriors they\ncan handle.\nWe show that solving the optimization problem of fixed-form Variational Bayes is equiv-\nalent to performing a linear regression with the sufficient statistics of the approximation\nas explanatory variables and the (unnormalized) log posterior density as the dependent\nvariable. Inspired by this result, we present an efficient stochastic approximation algo-\nrithm for solving this optimization problem. In contrast to earlier work, our approach\ndoes not require any analytic calculation of integrals, which allows us to extend the\n\u2217Erasmus University Rotterdam salimanstim@gmail.com\n\u2020Stanford University\n\u00a9 2013 International Society for Bayesian AnalysisDOI:10.1214\/13-BA858"},{"page":2,"text":"838 VB through Stochastic Regression\nfixed-form Variational Bayes approach to problems where it was previously not applica-\nble. Our method can be used to approximate any posterior distribution, provided that\nit is given in closed form up to the proportionality constant. The type of approximating\ndistribution can be any distribution in the exponential family or any mixture of such\ndistributions, which means that our approximations can in principle be made arbitrarily\nprecise. While our method somewhat resembles performing stochastic gradient descent\non the variational objective function in parameter space (Paisley et al. 2012; Nott et al.\n2012), the linear regression view gives insights which allow a more computationally\nefficient approach.\nSection 2 introduces fixed-form variational posterior approximation, the optimization\nproblem to be solved, and the notation used in the remainder of the paper. In Sec-\ntion 3 we provide a new way of looking at variational posterior approximation by re-\ninterpreting the underlying optimization as a linear regression problem. We propose a\nstochastic approximation algorithm to perform the optimization in Section 4. In Sec-\ntion 5 we discuss how to assess the quality of our posterior approximations and how to\nuse the proposed methods to approximate the marginal likelihood of a model. These\nsections represent the core ideas of the paper.\nTo make our approach more generally applicable and computationally efficient we pro-\nvide a number of extensions in two separate sections. Section 6 discusses modifications\nof our stochastic approximation algorithm to improve efficiency. Section 7 relaxes the\nassumption that our posterior approximation is in the exponential family, allowing in-\nstead mixtures of exponential family distributions. Sections 4, 6, and 7 also contain\nmultiple examples of using our method in practice, and show that despite its generality,\nthe efficiency of our algorithm is highly competitive with more specialized approaches.\nCode for these examples is available at github.com\/TimSalimans\/LinRegVB. Finally,\nSection 8 concludes.\n2 Fixed-form Variational Bayes\nLet x be a vector of unknown parameters and\/or latent random effects for which we\nhave specified a prior distribution p(x), and let p(y|x) be the likelihood of observing a\ngiven set of data, y. Upon observing y we can use Bayes\u2019 rule to obtain our updated\nstate of belief, the posterior distribution\np(x|y) =p(x,y)\np(y)\n=\np(y|x)p(x)\n?p(y|x)p(x)dx.\n\uf6be\n(1)\nAn equivalent definition of the posterior distribution is\np(x|y) = argmin\nq(x)Eq(x)\n\u201e\nlog\nq(x)\np(x,y)\n= argmin\nq(x)D[q(x)|p(x|y)], (2)\nwhere the optimization is over all proper probability distributions q(x), and where\nD[q(x)|p(x|y)] denotes the Kullback-Leibler divergence between q(x) and p(x|y). The"},{"page":3,"text":"T. Salimans and D. A. Knowles 839\nKL-divergence is always non-negative and has a unique minimizing solution q(x) =\np(x|y) almost everywhere, at which point the KL-divergence is zero. The solution of (2)\ndoes not depend on the normalizing constant p(y) of the posterior distribution.\nThe posterior distribution given in (1) is the exact solution of the variational optimiza-\ntion problem in (2), but except for certain special cases it is not very useful by itself\nbecause it does not have an analytically tractable form. This means that we do not\nhave analytic expressions for the posterior moments of x, or for the marginals p(xi|y)\nof the multivariate posterior distribution, nor can we determine the normalizing con-\nstant p(y). One method of solving this problem is to approximate these quantities using\nMonte Carlo simulation. A different approach, which we will pursue here, is to restrict\nthe optimization problem in (2) to a reduced set of more convenient distributions Q.\nIf p(x,y) is of conjugate exponential form, choosing Q to be the set of factorized dis-\ntributions q(x) = q(x1)q(x2)...q(xk) often leads to a tractable optimization problem\nthat can be solved efficiently using an algorithm called Variational Bayes Expectation\nMaximization (VBEM, Beal and Ghahramani 2002). Such a factorized solution is at-\ntractive because it makes the variational optimization problem easy to solve, but it is\nalso very restrictive: it requires a conjugate exponential model and prior specification\nand it assumes posterior independence between the different blocks of parameters xi.\nThis means that this factorized approach can be used with few models, and that the\nsolution q(x) may be a poor approximation to the exact posterior (see e.g. Turner et al.\n2008).\nAn alternative choice for Q is the set of distributions of a certain parametric form q\u03b7(x),\nwhere \u03b7 denotes the vector of parameters governing the shape of the posterior approxi-\nmation. This approach is known as structured or fixed-form Variational Bayes (Honkela\net al. 2010; Storkey 2000; Saul and Jordan 1996). Usually, the posterior approximation\nis chosen to be a specific member of the exponential family of distributions:\nq\u03b7(x) = exp[T(x)\u03b7 \u2212 U(\u03b7)]\u03bd(x), (3)\nwhere T(x) is a 1 \u00d7 k vector of sufficient statistics, U(\u03b7) takes care of normalization,\nand \u03bd(x) is a base measure. The k \u00d71 vector \u03b7 is often called the set of natural param-\neters of the exponential family distribution q\u03b7(x). Using this approach, the variational\noptimization problem in (2) reduces to a parametric optimization problem in \u03b7:\n\u02c6 \u03b7 = argmin\n\u03b7\nEq\u03b7(x)[logq\u03b7(x) \u2212 logp(x,y)].(4)\nIf our posterior approximation is of an analytically tractable form, the negative entropy\nterm Eq(x)[logq(x)] in (4) can often be evaluated analytically. If we can then also deter-\nmine Eq(x)[logp(x,y)] and its derivatives with respect to \u03b7, the optimization problem\ncan be solved using gradient-based optimization or fixed-point algorithms. Posterior\napproximations of this type are often much more accurate than a factorized approxima-\ntion, but the requirement of being able to evaluate Eq(x)[logq(x)] and Eq(x)[logp(x,y)]\nanalytically is very restrictive. In addition, approximations of this type generally do not"},{"page":4,"text":"840VB through Stochastic Regression\nallow us to use the fast EM type optimization algorithms often used with factorized ap-\nproximations (see Bishop 2006, Ch. 10). In the next section, we draw a parallel between\nthe optimization problem of variational Bayes and linear regression, which allows us to\ndevelop a new optimization algorithm that pushes back these limitations significantly.\n3 Variational Bayes as linear regression\nFor notational convenience we will write our posterior approximation in the adjusted\nform,\n\u02dc q\u02dc \u03b7(x) = exp[\u02dcT(x)\u02dc \u03b7]\u03bd(x), (5)\nwhere we have removed the normalizer U(\u03b7), and we have replaced it by adding a\nconstant to the vector of sufficient statistics, i.e.\u02dcT(x) = (1,T(x)) and \u02dc \u03b7 = (\u03b70,\u03b7?)?. If\n\u03b70is equal to \u2212U(\u03b7), (5) describes the same family of (normalized) distribution functions\nas (3). If \u03b70is different from \u2212U(\u03b7) then (5) describes a rescaled (unnormalized) version\nof this distribution function.\nTo work with \u02dc q\u02dc \u03b7(x), we use the unnormalized version of the KL-divergence, which is\ngiven by\n?\n= exp[\u02dcT(x)\u02dc \u03b7][\u02dcT(x)\u02dc \u03b7 \u2212 logp(x,y)]d\u03bd(x) \u2212\nD[\u02dc q\u02dc \u03b7(x)|p(x,y)] =\u02dc q\u02dc \u03b7(x)log\n\u02dc q\u02dc \u03b7(x)\np(x,y)d\u03bd(x) \u2212\n?\n\u02dc q\u02dc \u03b7(x)d\u03bd(x) (6)\n??\nexp[\u02dcT(x)\u02dc \u03b7]d\u03bd(x).\nAt the minimum this gives \u03b70= Eq[logp(x,y) \u2212 logq(x)] \u2212 U(\u03b7) as shown in Appendix\nA. The other parameters \u03b7 have the same minimum as in the normalized case.\nTaking the gradient of (6) with respect to the natural parameters \u02dc \u03b7 we have\n?\nSetting this expression to zero in order to find the minimum gives\n\u201e?\nor in its normalized form\n\u2207\u02dc \u03b7D[\u02dc q\u02dc \u03b7(x)|p(x,y)] =\u02dc q\u02dc \u03b7(x)[\u02dcT(x)?\u02dcT(x)\u02dc \u03b7 \u2212\u02dcT(x)?logp(x,y)]d\u03bd(x). (7)\n\u02dc \u03b7 =\u02dc q\u02dc \u03b7(x)\u02dcT(x)?\u02dcT(x)d\u03bd(x)\n\uf6be\u22121\u201e?\n\u02dc q\u02dc \u03b7(x)\u02dcT(x)?logp(x,y)d\u03bd(x)\n\uf6be\n, (8)\n\u02dc \u03b7 = Eq[\u02dcT(x)?\u02dcT(x)]\u22121Eq[\u02dcT(x)?logp(x,y)].(9)\nWe have implicitly assumed that the Fisher information matrix, Eq[\u02dcT(x)?\u02dcT(x)] is non-\nsingular, which will be the case for any identifiable approximating exponential family\ndistribution q. Our key insight is to notice the similarity between (9) and the maximum\nlikelihood estimator for linear regression. Recall that in classical linear regression we"},{"page":5,"text":"T. Salimans and D. A. Knowles 841\nhave that the dependent variable {yn\u2208 R : n = 1,..,N} is distributed as N(Y |X\u03b2,\u03c32I)\nwhere X is the N \u00d7D design matrix, \u03b2 is the D\u00d71 vector of regression coefficients and\n\u03c32is the noise variance. The maximum likelihood estimator for \u03b2 is then\n\u02c6\u03b2 = (X?X)\u22121X?Y. (10)\nTo see the relation between (9) and (10), associate the design matrix X with the\nsufficient statistics\u02dcT, the dependent variable Y with the unnormalized log posterior\nlogp(x,y), and the regression coefficients \u03b2 with the vector of natural parameters \u02dc \u03b7. If\nwe then consider Monte Carlo estimates of the expectations in (9) the analogy is very\nfitting indeed. A similar analogy is used by Richard and Zhang (2007) in the context\nof importance sampling. Appendix C discusses the connection between their work and\nours.\nIn (9), unlike (10), the right-hand side depends on the unknown parameters, \u03b7. This\nmeans that (9) in itself does not constitute a solution to our variational optimiza-\ntion problem. In the next section, we introduce a stochastic approximation algorithm\nto perform this optimization, without requiring the expectations Eq[\u02dcT(x)?\u02dcT(x)] and\nEq[\u02dcT(x)?logp(x,y)] to be computable analytically. This allows us to extend the fixed-\nform Variational Bayes approach to situations in which it was previously not applicable.\nThe only requirements we impose on logp(x,y) is that it is given in closed form. The\nmain requirement on q\u03b7(x) is that we can sample from it. For simplicity, Sections 4, 5\nand 6 will also assume that q\u03b7(x) is in the exponential family. Section 7 will then show\nhow we can extend this to include mixtures of exponential family distributions. By\nusing these mixtures and choosing q\u03b7(x) to be of a rich enough type, we can in principle\nmake our approximation arbitrarily precise.\n4 A stochastic approximation algorithm\nThe link between variational Bayes and linear regression in itself is interesting, but it\ndoes not yet provide us with a solution to the variational optimization problem of (4).\nWe propose solving this optimization problem by viewing (9) as a fixed point update. Let\nC = Eq[\u02dcT(x)?\u02dcT(x)] and g = Eq[\u02dcT(x)?logp(x,y)] so that (9) can be written \u02dc \u03b7 = C\u22121g.\nWe iteratively approximate C and g by weighted Monte Carlo, drawing a single sample\nx\u2217\nupdate equations\ntfrom the current posterior approximation q\u03b7t(x) at each iteration t, and using the\ngt+1= (1 \u2212 w)gt+ w\u02c6 gt\nCt+1= (1 \u2212 w)Ct+ w\u02c6Ct\n(11)\nfor some w \u2208 [0,1] where \u02c6 gt=\u02dcT(x\u2217\ndownweights earlier iterations when q was less accurate. The parameters are updated as\n\u02dc \u03b7t+1= C\u22121\nPseudocode is shown in Algorithm 1.\nt)?logp(x\u2217\nt,y) and\u02c6Ct=\u02dcT(x\u2217\nt)?\u02dcT(x\u2217\nt). Equation 11\nt+1gt+1. w is chosen to be small enough to ensure convergence of the algorithm."},{"page":6,"text":"842VB through Stochastic Regression\nAlgorithm 1 Stochastic Optimization for Fixed-Form Variational Bayes\nRequire: An unnormalized posterior distribution p(x,y)\nRequire: A type of approximating posterior q\u03b7(x)\nRequire: The total number of iterations N\nInitialize \u02dc \u03b71to a first guess, for example by matching the prior p(x)\nInitialize C1= Eq\u03b71[\u02dcT(x)?\u02dcT(x)], or a diagonal approximation of this matrix\nInitialize g1= C1\u02dc \u03b71\nInitialize\u00afC = 0\nInitialize \u00af g = 0\nSet step-size w = 1\/?N\nfor t = 1 : N do\nSimulate a draw x\u2217\nSet \u02c6 gt=\u02dcT(x\u2217\nSet\u02c6Ct=\u02dcT(x\u2217\nSet gt+1= (1 \u2212 w)gt+ w\u02c6 gt\nSet Ct+1= (1 \u2212 w)Ct+ w\u02c6Ct\nSet \u02dc \u03b7t+1= C\u22121\nif t > N\/2 then\nSet \u00af g = \u00af g + \u02c6 gt\nSet\u00afC =\u00afC +\u02c6Ct\nend if\nend for\nreturn \u02c6 \u03b7 =\u00afC\u22121\u00af g\ntfrom the current approximation q\u03b7t(x)\nt)?logp(x\u2217\nt)?\u02dcT(x\u2217\nt,y), or another unbiased estimate of Eq\u03b7t[\u02dcT(x)?logp(x,y)]\nt), or another unbiased estimate of Eq\u03b7t[\u02dcT(x)?\u02dcT(x)]\nt+1gt+1\nAlgorithm 1 is inspired by a long line of research on stochastic approximation, starting\nwith the seminal work of Robbins and Monro (1951).\nconsidered a relatively standard stochastic gradient descent algorithm. At each iteration\nwe have \u02dc \u03b7t= C\u22121\nUp to first order it can be\nt gt, which we then update to\n\u02dc \u03b7t+1= C\u22121\nt+1gt+1= [(1 \u2212 w)Ct+ w\u02c6Ct]\u22121[(1 \u2212 w)gt+ w\u02c6 gt] = [Ct+ \u03bb\u02c6Ct]\u22121[gt+ \u03bb\u02c6 gt],\nwhere \u02c6 gtand\u02c6Ctare the stochastic estimates generated during iteration t, w is the step-\nsize in our algorithm, and \u03bb = w\/(1\u2212w) is the effective step-size as it is usually defined\nin the stochastic approximation literature. To characterize this update for small values\nof \u03bb we perform a first order Taylor expansion of \u02dc \u03b7t+1around \u03bb = 0, which gives\n\u02dc \u03b7t+1= \u02dc \u03b7t\u2212 \u03bbC\u22121\nt (\u02c6Ct\u02dc \u03b7t\u2212 \u02c6 gt) + O(\u03bb2). (12)\nComparison with (7) shows that the stochastic term in this expression (\u02c6Ct\u02dc \u03b7t\u2212 \u02c6 gt) is\nan unbiased estimate of the gradient of the KL-divergence D[q\u03b7t(x)|p(x,y)]. Up to first\norder, the update equation in (12) thus represents a stochastic gradient descent step,\npre-conditioned with the C\u22121\nt\nmatrix. Since this pre-conditioner is independent of the\nstochastic gradient approximation at iteration t, this gives a valid adaptive stochastic\ngradient descent algorithm, to which all the usual convergence results apply (see e.g.\nAmari 1997)."},{"page":7,"text":"T. Salimans and D. A. Knowles843\nIf we take small steps, the pre-conditioner C\u22121\nmetric Eqt\u02c6Ct = Eqt[\u02dcT(x)?\u02dcT(x)] used in natural gradient descent algorithms like that\nof Honkela et al. (2010) and Hoffman et al. (2012). For certain exponential family\ndistributions this metric can be calculated analytically, which would suggest performing\nstochastic natural gradient descent optimization with updates of the form\n\u00b4\nwhere the Eqt[\u02dcT(x)?logp(x,y)] term is approximated using Monte Carlo, but the pre-\nconditioner Eqt[\u02dcT(x)?\u02dcT(x)] is calculated analytically. At first glance, our approach of\napproximating Eqt[\u02dcT(x)?\u02dcT(x)] using Monte Carlo only seems to add to the randomness\nof the gradient estimate, and using the same random numbers to approximate both\nEqt[\u02dcT(x)?logp(x,y)] and Eqt[\u02dcT(x)?\u02dcT(x)] leads to biased pre-conditioned gradient ap-\nproximations at that (although that bias disappears as \u03bb \u2192 0). However, it turns out\nthat approximating both terms using the same random draws increases the efficiency of\nour algorithm dramatically. The reason for this is analogous to the reason for why the\noptimal estimator in linear regression is given by (X?X)\u22121X?y and not E[X?X]\u22121X?y:\nby using the same randomness for both the X?X and X?y terms, a large part of the\nnoise in their product cancels out.\nt\nin (12) will be close to the Riemannian\n\u02dc \u03b7t+1= \u02dc \u03b7t\u2212 \u03bb\u02dc \u03b7t\u2212 Eqt[\u02dcT(x)?\u02dcT(x)]\u22121[\u02dcT(x\u2217)?logp(x\u2217,y)]\n\u00af\n,\nA particularly interesting example of this is when the true posterior distribution is\nof the same functional form as its approximation, say p(x,y) = exp[\u02dcT(x)\u03be], in which\ncase Algorithm 1 will recover the true posterior exactly in 2(k + 1) iterations, with\nk the number of sufficient statistics in q and p.\nx\u2217\nsurely for continuous distributions q), we have\n\u02dc2k+2\nt=k+2\n\u02dc2k+2\nt=k+2\nAssuming the last k + 1 samples\nt,t = k + 2,...,2k + 2 generated by our algorithm are unique (which holds almost\n\u02c6 \u03b7=\n?\n?\n\u02dcT(x\u2217\nt)?\u02dcT(x\u2217\nt)\n\u00b8\u221212k+2\nt=k+2\n\u00b8\u221212k+2\nt=k+2\n?\n?\n\u02dcT(x\u2217\nt)?log[p(x\u2217\nt,y)]\n=\n\u02dcT(x\u2217\nt)?\u02dcT(x\u2217\nt)\n\u02dcT(x\u2217\nt)?\u02dcT(x\u2217\nt)\u03be = \u03be.(13)\nIf the algorithm is run for additional iterations after the true posterior is recovered, the\napproximation will not change. This is to be contrasted with other stochastic gradient\ndescent algorithms which have non-vanishing variance for a finite number of samples,\nand is due to the fact that our regression in itself is noise free: only its support points are\nstochastic. This exact convergence will not hold for cases of actual interest, where p and\nq will not be of the exact same functional form, but we generally still observe a dramatic\nimprovement when using Algorithm 1 instead of more conventional stochastic gradient\ndescent algorithms. A deeper analysis of the variance of our stochastic approximation\nis given in Appendix D.\nContrary to most applications in the literature, Algorithm 1 uses a fixed step size\nw = 1\/?N rather than a declining one in updating our statistics. The analyses of"},{"page":8,"text":"844VB through Stochastic Regression\nRobbins and Monro (1951) and Amari (1997) show that a sequence of learning rates\nwt = ct\u22121is asymptotically efficient in stochastic gradient descent as the number of\niterations N goes to infinity, but this conclusion rests on strong assumptions on the\nfunctional form of the objective function (e.g. strong convexity) that are not satisfied\nfor the problems we are interested in. Moreover, with a finite number of iterations, the\neffectiveness of a sequence of learning rates that decays this fast is highly dependent on\nthe proportionality constant c. If we choose c either too low or too high, it may take a\nvery long time to reach the efficient asymptotic regime of this learning rate sequence.\nNemirovski et al. (2009) show that a more robust approach is to use a constant learning\nrate w = 1\/?N and that this is optimal for finite N without putting stringent require-\nments on the objective function. In order to reduce the variance of the last iterate with\nthis non-vanishing learning rate, they propose to use an average of the last L iterates\nas the final output of the optimization algorithm. The value of L should grow with\nthe total number of iterations, and is usually chosen to be equal to N\/2. Remarkably,\nthey show that such an averaging procedure can match the asymptotic efficiency of the\noptimal learning sequence wt= ct\u22121.\nFor our particular optimization problem we have observed excellent results using con-\nstant learning rate w = 1\/?N, and averaging starting half-way into the optimization.\nWe perform this averaging on the statistics g and C, rather than on the parameters\n\u02dc \u03b7 = C\u22121g, which is necessary to remove the bias caused by forming g and C using\nthe same random numbers. As previously described, using this set-up gt and Ct are\nactually weighted MC estimates where the weight of the j-th MC sample during the t-th\niteration (j \u2264 t) is given by w(1 \u2212 w)t\u2212j. Since w \u2208 (0,1), this means that the weight\nof earlier MC samples declines as the algorithm advances, which is desirable since we\nexpect q to be closer to optimal later in the algorithm\u2019s progression.\nIf the initial guess for \u02dc \u03b7 is very far from the optimal value, or if the number of steps\nN is very small, it can sometimes occur that the algorithm proposes a new value for \u02dc \u03b7\nthat does not define a proper distribution, for example because the proposed \u02dc \u03b7 value\ncorresponds to a negative variance. This is a sign that the number of iterations should\nbe increased: since our algorithm becomes a pre-conditioned gradient descent algorithm\nas the number of steps goes to infinity, the algorithm is guaranteed to converge if the\nstep size is small enough. In addition, the exact convergence result presented in (13)\nsuggests that divergence is very unlikely if q\u03b7(x) and p(x,y) are close in functional form:\nchoosing a good approximation will thus also help to ensure fast convergence. Picking a\ngood first guess for \u02dc \u03b7 also helps the algorithm to converge more quickly. For very difficult\ncases it might therefore be worthwhile to base this guess on a first rough approximation\nof the posterior, for example by choosing \u02dc \u03b7 to match the curvature of logp(x,y) at its\nmode. For all our applications we found that a simple first guess for \u02dc \u03b7 and a large\nenough number of iterations was sufficient to guarantee a stable algorithm. Our default\nimplementation of Algorithm 1 is therefore to initialize \u02dc \u03b7 to (an approximation of) the\nprior, and to increase the number of iterations until the algorithm is sufficiently stable."},{"page":9,"text":"T. Salimans and D. A. Knowles845\nLike other optimization algorithms for Variational Bayes, Algorithm 1 will only find a\nlocal minimum of the KL-divergence. This is generally not a problem when approxi-\nmating unimodal posterior distributions, such as with the examples in this paper, since\nthe optimization problem then often only has a single optimum (depending on the type\nof approximation, see Bishop 2006, Ch. 10). If the true posterior distribution is multi-\nmodal and the approximation is unimodal, however, the variational approximation will\ntend to pick one of the posterior modes and ignore the others (Minka 2005). Although\nthis is often desirable (see e.g. Stern et al. 2009), there is no guarantee that the recovered\nlocal minimum of the KL-divergence is then also a global minimum.\nExample: Fitting an exponential distribution\nIt is instructive to consider a toy example: approximating an exponential distribution\np(x) = \u03bbe\u2212\u03bbxwith a variational approximation of the same functional form. We assume\nthat we are unaware that p happens to be normalized. Our variational approximation\nhas\u02dcT = [1,x] and rate \u03b7, i.e. q(x) = \u03b7e\u2212\u03b7x. Since the functional form of the variational\nposterior matches the true posterior, (13) holds and Algorithm 1 will recover \u03b7 to\nmachine precision in just 2(k+1) = 4 iterations. We contrast this with the performance\nif two different strategies are used to estimate \u02c6 gtand\u02c6Ctin Algorithm 1: i) a different\nrandom draw x\u2217is used for \u02c6 gtand\u02c6Ct, ii)\u02c6Ctis calculated analytically using\n\u201e\nThese seemingly similar alternatives perform dramatically worse than Algorithm 1. We\nset the true \u03bb := 2, and initialize \u03b7 := 1 and C := I2, the identity matrix. Figure 1 shows\nthe mean and variance of the estimates of log(\u03b7) across 100 repeat runs of each method\nwith varying number of iterations N. We see it takes option i (\u201cdifferent randomness\u201d)\nand ii (\u201canalytic\u201d) well over 1000 iterations to give a reasonable answer, and even with\nN = 104samples, option i) estimates \u02c6 \u03b7 = 2.04 \u00b1 0.15 and option ii) 2.01 \u00b1 0.11.\nEq[\u02dcT(x)?\u02dcT(x)] =\n1\n\u2212\u03b7\u22121\n\u03b7\u22122\n\u2212\u03b7\u22121\n\uf6be\n. (14)\n10\n1\n10\n2\n10\n3\n10\n4\n\u22122\n\u22121\n0\n1\n2\n3\n4\niterations, N\nlog(eta)\n \n \nanalytic\ndifferent\nsame randomness\nFigure 1:\nmethods for estimating \u02c6 gt and\u02c6Ct\nin Algorithm 1 on a toy example:\napproximating an exponential pos-\nterior with an approximation of the\nsame functional form. Solid lines\nshow the means of the recovered\nparameters over 100 repeat runs,\nand dashed lines show \u00b1 one stan-\ndard deviation.\nrandom draw to estimate \u02c6 gtand\u02c6Ct\n(our proposed method) gives exact\nconvergence in N = 4 iterations\nComparing alternative\nUsing the same"},{"page":10,"text":"846VB through Stochastic Regression\n5 Marginal likelihood and approximation quality\nThe stochastic approximation algorithm presented in the last section serves to minimize\nthe Kullback-Leibler divergence between q\u03b7(x) and p(x|y), given by\n\u201e\nD(q\u03b7|p) = Eq\u03b7\nlogq\u03b7(x)\np(x|y)\n\uf6be\n= Eq\u03b7\n\u201e\nlogq\u03b7(x)\np(x,y)\n\uf6be\n+ logp(y).\nAs discussed before, we do not need to know p(y) (the marginal likelihood) in order to\nminimize D(q\u03b7|p) as p(y) does not depend on \u03b7, but we do need to know it if we want to\ndetermine the quality of the approximation, as measured by the final Kullback-Leibler\ndivergence. In addition, the constant p(y) is also essential for performing Bayesian model\ncomparison or model averaging. This section presents a method for approximating the\nmarginal likelihood and final Kullback-Leibler divergence.\nWhen our algorithm has converged, we have the following identity\nlogp(x,y) = \u02c6 \u03b70+ T(x)\u03b7 + r(x) = \u02c6 \u03b70+ U(\u03b7) + logq\u03b7(x) + r(x), (15)\nwhere r(x) is the \u2018residual\u2019 or \u2018error term\u2019 in the linear regression of logp(x,y) on the\nsufficient statistics of q\u03b7(x), and where U(\u03b7) is the normalizer of q\u03b7(x). The intercept\nof the regression is\n\u02c6 \u03b70= Eq\u03b7rlogp(x,y) \u2212 logq\u03b7(x)s \u2212 U(\u03b7),\nwhere Eq\u03b7rlogp(x,y) \u2212 logq\u03b7(x)s = \u02c6 \u03b70+U(\u03b7) may be recognized as the usual VB lower\nbound on the log marginal likelihood. Exponentiating (15) yields\np(x,y) = exp[\u02c6 \u03b70+ U(\u03b7)]q\u03b7(x)exp(r(x)),\nwhich we need to integrate with respect to x in order to find the marginal likelihood\np(y). Doing so gives\np(y) = exp[\u02c6 \u03b70+ U(\u03b7)]Eq\u03b7[exp(r(x))]. (16)\nAt convergence we have that Eq\u03b7[r(x)] = 0. Jensen\u2019s inequality then tells us that\nEq\u03b7[exp(r(x))] \u2265 1,\nso that \u02c6 \u03b70+U(\u03b7) is indeed a lower bound on the log marginal likelihood. If our approx-\nimation is perfect, the KL-divergence is zero and r(x) is zero almost everywhere. In\nthat case the residual term vanishes and the lower bound will be tight, otherwise it will\nunderestimate the true marginal likelihood. The lower bound \u02c6 \u03b70+ U(\u03b7) is often used\nin model comparison, which works well if the KL-divergence between the approximate\nand true posterior distribution is of approximately the same size for all models that\nare being compared. However, if we compare two very different models this will often\nnot be the case, and the model comparison will be biased as a result. In addition, as\nopposed to the exact marginal likelihood, the lower bound gives us no information on"},{"page":11,"text":"T. Salimans and D. A. Knowles 847\nthe quality of our posterior approximation. It would therefore be useful to obtain a\nbetter estimate of the marginal likelihood.\nOne approach to doing this would be to evaluate the expectation in (16) using Monte\nCarlo sampling. Some analysis shows that this corresponds to approximating p(y)\nusing importance sampling, with q\u03b7(x) as the candidate distribution. It is well known\nthat this estimator of the marginal likelihood may have infinite variance, unless r(x) is\nbounded from above (see e.g. Geweke 2005, p. 114). In general, we cannot guarantee the\nboundedness of r(x) for our approach, so we will instead approximate the expectation\nin (16) using something that is easier to calculate.\nAt convergence, we know that the mean of r(x) is zero when sampling from q\u03b7(x). The\nvariance of r(x) can be estimated using the mean squared error of the regressions we\nperform during the optimization, with relatively low variance. We denote our estimate\nof this variance by s2. The assumption we will then make in order to approximate\nlogp(y) is that r(x) is approximately distributed as a normal random variable with\nthese two moments. This leads to the following simple estimate of the log marginal\nlikelihood\nlogp(y) \u2248 \u02c6 \u03b70+ U(\u03b7) +1\nThat is, our estimate of the marginal likelihood is equal to its lower bound plus a\ncorrection term that captures the error in our posterior approximation q\u03b7(x). Similarly,\nwe can approximate the KL-divergence of our posterior approximation as\n2s2. (17)\nD(q\u03b7|p) \u22481\n2s2.\nThe KL-divergence is approximately equal to half the mean squared error in the re-\ngression of logp(x,y) on the sufficient statistics of the approximation. This relationship\nshould not come as a surprise: this mean squared error is exactly what we minimize\nwhen we perform linear regression.\nThe scale of the KL-divergence is highly dependent on the amount of curvature in\nlogp(x|y) and is therefore not easily comparable across different problems. If we scale\nthe approximate KL-divergence to account for this curvature, this naturally leads to\nthe R-squared measure of fit for regression modeling:\nR2= 1 \u2212\ns2\nVarq[logp(x,y)].\nThe R-squared measure corrects for the amount of curvature in the posterior distribution\nand is therefore comparable across different models and data sets. In addition it is a\nwell-known measure and easily interpretable. We therefore propose to use the R-squared\nas the measure of approximation quality for our variational posterior approximations.\nAlthough we find the R-squared to be a useful measure for the majority of applications,\nit is important to realize that it mostly contains information about the mass of the"},{"page":12,"text":"848VB through Stochastic Regression\nposterior distribution and its approximation, and not directly about their moments.\nIt is therefore possible to construct pathological examples in which the R-squared is\nrelatively high, yet the (higher) moments of the posterior and its approximation are\nquite different. This may for example occur if the posterior distribution has very fat\ntails.\nSection 7.2 provides an application of the methods developed here. In that section,\nFigure 6 shows that the approximation of the KL-divergence is quite accurate, especially\nwhen the approximation q\u03b7(x) is reasonably good. The same figure also shows that the\napproximation of the marginal likelihood proposed here (17) is much more accurate than\nthe usual lower bound. In Sections 6 and 7, we also calculate the R-squared measure\nof approximation quality for a number of different posterior approximations, and we\nconclude that it corresponds well to visual assessments of the approximation accuracy.\nThe discussion up to this point represents the core ideas of this paper. To make our\napproach more general and computationally efficient we now provide a number of ex-\ntensions in two separate sections. Section 6 discusses modifications of our stochastic\napproximation algorithm to improve efficiency, and Section 7 generalizes the exponen-\ntial family approximations q(x) used so far to include mixtures of exponential family\ndistributions. Examples are given throughout. Finally, Section 8 concludes.\n6 Extensions I: Improving algorithmic efficiency\nAlgorithm 1 approximates the expectations Eq\u03b7[\u02dcT(x)?logp(x,y)] and Eq\u03b7[\u02dcT(x)?\u02dcT(x)] by\nsimply drawing a sample x\u2217\ntfrom q\u03b7t(x) and using this sample to calculate\n\u02c6 gt\n\u02c6Ct\n=\n\u02dcT(x\u2217\n\u02dcT(x\u2217\nt)?logp(x\u2217\nt)?\u02dcT(x\u2217\nt,y)\n=\nt).\nThis works remarkably well because, as Section 4 explains, using the same random\ndraw x\u2217\nHowever, it is certainly not the only method of obtaining unbiased approximations of\nthe required expectations, and in this section we present alternatives that often work\neven better. In addition, we also present alternative methods of parameterizing our\nproblem, and we discuss ways of speeding up the regression step of our algorithm.\ntto form both estimates, part of the random variation in \u02dc \u03b7 = C\u22121g cancels out.\nExample: Binary probit regression\nTo illustrate the different versions of our posterior approximation algorithm, we will\nuse binary probit regression as a running example. Binary probit regression is a classic\nmodel in statistics, also referred to as binary classification in the machine learning\nliterature. Here we take a Bayesian approach to probit regression to demonstrate the\nperformance of our methodology relative to existing variational approaches. We have\nN observed data pairs (yi\u2208 {0,1},vi\u2208 RM), and we model yi|vias P(yi= 1|vi,x) ="},{"page":13,"text":"T. Salimans and D. A. Knowles 849\n\u03c6(x?vi) where \u03c6(.) is the standard Gaussian cdf and x \u2208 RMis a vector of regression\ncoefficients, for which we assume an elementwise Gaussian prior N(0,1). This is a model\nfor which existing approaches are straightforward so it is interesting to compare their\nperformance to our method. Of course the major benefit of our approach is that it\ncan be applied in a much wider class of models. For all versions of our method the\nvariational approximation used is a full covariance multivariate normal distribution.\nWe use data simulated from the model, with N = 100 and M = 5, to be able to\nshow the performance averaged over 500 datasets and many different settings of the\nalgorithm. We compare our algorithm to the VBEM algorithm of Ormerod and Wand\n(2010) which makes use of the fact that the expectations required for this model can\nbe calculated analytically. We choose not to do this for our method to investigate how\neffective our MC estimation strategy can be. For completeness we also compare to\nvariational message passing (VMP, Winn and Bishop 2006), a message passing imple-\nmentation of VBEM, and expectation propagation (EP, Minka 2001), which is known to\nhave excellent performance on binary classification problems (Nickisch and Rasmussen\n2008). These last two alternatives are both implemented in Infer.NET (Minka et al.\n2010) a library for probabilistic inference in graphical models, whereas we implement\nVBEM and our approximation algorithm ourselves in MATLAB. VMP and VBEM use\na different variational approximation to our methods, introducing auxiliary variables\nzi\u223c N(x?vi,1), with ziconstrained to be positive if yi= 1 and negative otherwise. A\nfactorized variational posterior q(x)?\niq(zi) is used, where q(x) is multivariate normal\nand each q(zi) can be thought of as a truncated univariate Gaussian.\nFor all implementations of our algorithm, we initialize the posterior approximation to\nthe prior. All algorithms then use a single random draw to update the parameters dur-\ning each iteration. This is often not the best implementation in terms of computational\nefficiency, since the contributions of multiple draws can often be calculated in parallel\nat little extra cost, and using antithetic sampling (i.e. sampling of negatively corre-\nlated draws) can reduce the variance of our approximations. By using the most basic\nimplementation, however, we can more clearly compare the different stochastic approxi-\nmations proposed in this section. Since the time required to run the different algorithms\nis strongly dependent on their precise implementation (e.g. the chosen programming\nlanguage), we choose to perform this comparison by looking at statistical efficiency, as\nmeasured by the accuracy as a function of the number of likelihood evaluations, rather\nthan the running time of the algorithms.\nSince this experiment is on synthetic data we are able to assess performance in terms of\nthe method\u2019s ability to recover the known regression coefficients x, which we quantify\nas the root mean squared error (RMSE) between the variational mean and the true\nregression weights, and the \u201clog score\u201d: the log density of the true weights under the\napproximate variational posterior. The log score is useful because it rewards a method\nfor finding good estimates of the posterior variance as well as the mean, which should\nof course be central to any approximate Bayesian method."},{"page":14,"text":"850VB through Stochastic Regression\nFigure 2 shows the performance of the different versions of our algorithm as presented in\nthe following discussion, as well as the performance of the VBEM algorithm of Ormerod\nand Wand (2010). As can be seen from this graph, our approximation method achieves\na lower RMSE than the VBEM algorithm. This is because of the extra factorization\nassumptions made by VBEM when introducing the zivariables. Where the improvement\nin the RMSE is noticeable, the difference in log score is dramatic: 0.193 versus \u22124.46\n(not shown), indicating that our approximation gives significantly better estimates of the\nvariance than VBEM. The average R-squared obtained by our variational approximation\nwas 0.97, indicating a close fit to the exact posterior distribution. In terms of accuracy,\nour results are very similar to those of EP, which obtained an RMSE and log score\nidentical to those of our approximation (up to 3 significant digits). As expected, VMP\ngave consistent results with VBEM: an RMSE of 0.265 and a log score of \u22124.56.\n10\n0\n10\n1\n10\n2\n10\n3\n0.255\n0.26\n0.265\n0.27\n0.275\nnumber of likelihood evaluations\nRMSE approximate posterior mean\n \n \nBasic algorithm\nFactorized\nVBEM\nFactor+Gradient\nHessian\nMinibatch\nFigure 2: RMSE approximate posterior mean as a function of the number of likelihood\nevaluations for the different implementations of our algorithm and VBEM. Green: our\nbasic algorithm (Section 4). Cyan: using factor structure (Section 6.1). Black: the\nstandard VBEM algorithm. Blue: using both factor structure and the gradient of the\nlog posterior (Section 6.2). Red: using the Hessian of the log posterior with linear\ntransformation for efficiency (Sections 6.3 and 6.4). Magenta: using the Hessian, linear\ntransformation and minibatches of data (Section 6.5).\nAs can be seen from Figure 2, our basic algorithm is considerably slower than VBEM in\nterms of the number of likelihood evaluations that are required to achieve convergence.\nIn terms of wall clock time, our basic algorithm ran about an order of magnitude slower\nthan VBEM, although it could easily be sped up by using multiple random draws in\nparallel. The basic algorithm was about as fast as EP and VMP, needing about 15\nmilliseconds to converge on this small data set, but note that the system set ups were"},{"page":15,"text":"T. Salimans and D. A. Knowles 851\nnot completely comparable: EP and VMP were run on a laptop rather than a desktop,\nand Infer.NET is implemented in C# rather than MATLAB.\nThe remainder of this section introduces the other implementations of our variational\napproximation, presented in Figure 2, some of which are much faster and more compu-\ntationally efficient than both our basic algorithm and VBEM.\n6.1 Making use of factor structure\nFor most statistical problems, including our probit regression model, the log posterior\ncan be decomposed into a number of additive factors, i.e. logp(x,y) =?N\nN\n?\nThis means that rather than performing one single linear regression we can equivalently\nperform N separate regressions.\nj=1log\u03c6j(x,y).\nThe optimality condition in (9) can then also be written as a sum:\n\u02dc \u03b7 =\nj=1\nEq[\u02dcT(x)?\u02dcT(x)]\u22121Eq[\u02dcT(x)?log\u03c6j(x,y)].\n\u02c6 \u03b7=\nN\n?\nEq[\u02dcT(x)?\u02dcT(x)]\u22121Eq[\u02dcT(x)?log\u03c6j(x,y)].\nj=1\n\u02c6 \u03b7j\n(18)\n\u02c6 \u03b7j\n= (19)\nOne benefit of this is that some of the factors \u03c6j(x,y) may be conjugate to the posterior\napproximation, such as the prior p(x) in our probit regression example. The regression\ncoefficients \u02c6 \u03b7jfor these conjugate factors are known analytically and do not need to be\napproximated.\nMore importantly, the separate coefficients \u02c6 \u03b7jin (18) can often be calculated using re-\ngressions of much lower dimension than the full vector of natural parameters since the\nfactors \u03c6j(x,y) often only depend on a few of the sufficient statistics of our approxi-\nmation. This occurs when the factors are functions of low dimensional projections or\nsubsets of x. For example, we might have \u03c6j(x,y) = \u03c6j(xR,y), where xR contains a\nsubset of the variables in x. In that case, it follows from the properties of the expo-\nnential family that log\u03c6j(x,y) will have zero partial correlation with all the sufficient\nstatistics in\u02dcT(x), after controlling for the sufficient statistics of the marginal q(xR) (see\nWainwright and Jordan 2008, Section 5.5). In other words, we have\nlog\u03c6j(x,y) =\u02dcTR(x)\u02c6 \u03b7j\nR+ r(x), with Eq[\u02dcT(x)?r(x)] = 0,\nwhere\u02dcTR(x) is that subset of the statistics in\u02dcT(x) that is sufficient for q(xR), and \u02c6 \u03b7j\nis the corresponding subset of the parameters in \u02c6 \u03b7j. The \u2018residual\u2019 r(x) is orthogonal to\nthe remaining sufficient statistics, i.e. the factor log\u03c6j(x,y) has zero partial correlation\nto the sufficient statistics that are not in the subset\u02dcTR(x), which means that the\nR"},{"page":16,"text":"852VB through Stochastic Regression\ncoefficients of those statistics will be zero. Statistics that are known to have a zero\ncoefficient can of course be omitted from the regression, leading to the low dimensional\nregression\n\u02c6 \u03b7j\nR= Eq[\u02dcTR(x)?\u02dcTR(x)]\u22121Eq[\u02dcTR(x)?log\u03c6j(x,y)].\nBy performing these lower dimensional regressions we can reduce the variance of the\nstochastic approximation algorithm, as well as reduce the overhead needed to store and\ninvert C = Eq[\u02dcT(x)?\u02dcT(x)].\nOur probit regression model provides a straightforward example, for which the log joint\ndensity of x and y has the following factor structure\nlogp(x,y) = logp(x) +\nN\n?\ni=1\nlogp(yi|vi,x).\nHere, each likelihood factor p(yi|vi,x) depends on all the parameters x, but only through\nthe univariate product fi= x?vi. We can emphasize this by writing our model as\nlogp(x,y) = logp(x) +\nN\n?\ni=1\nlogp(yi|fi),\nwhere the new variables fi are linked to the parameters x through the relationship\nfi = x?vi. When we sample x from its multivariate normal approximate posterior,\nthe resulting fi\u2019s will have univariate normal distributions q\u03b7(fi) = N[\u00b5i,\u03c32\n\u00b5i= v?\nzero partial correlation to the statistics\u02dcT(x) after controlling for the sufficient statistics\nof the marginals q\u03b7(fi), being fiand \u22120.5f2\nGaussian is thus equivalent to approximating the likelihood factors p(yi|fi) by univariate\nGaussian likelihood terms in fi. Using this, we can write our unnormalized approximate\nposterior \u02dc q\u02dc \u03b7(x) as\ni], with\niEq[x] and \u03c32\ni= v?\niVarq[x]vi. This means that the factors logp(yi|fi) will have\ni. Approximating p(x|y) by a multivariate\nlog \u02dc q\u02dc \u03b7(x)= logp(x) +\nN\n?\nN\n?\ni=1\n\u201c\u02dc \u03b7i,0+ \u02dc \u03b7i,1fi\u2212 0.5\u02dc \u03b7i,2f2\n\u201c\u02dc \u03b7i,0+ \u02dc \u03b7i,1x?vi\u2212 0.5\u02dc \u03b7i,2(x?vi)2\u2030\ni\n\u2030\n(20)\n= logp(x) +\ni=1\nwhere \u02dc \u03b7i,0, \u02dc \u03b7i,1, and \u02dc \u03b7i,2are the natural parameters of the univariate Gaussian approx-\nimation of the likelihood term p(yi|fi). These parameters can now be optimized by\nperforming a separate regression for each likelihood factor, using the statistics\n\u00bb\n\u22120.5f2\n\u02dcT(fi)?=\n\u2013\n1\nfi\ni\nfi\nfl=\n\u00bb\n\u2013\n1\nixv?\n\u22120.5(v?\nix)2\nfi\nfl,"},{"page":17,"text":"T. Salimans and D. A. Knowles 853\nand regressing these against the likelihood factors logp(yi|vi,xi). At each iteration of\nAlgorithm 1, we can then update the natural parameters of each approximate likelihood\nterm using\n\u02c6 gt,i\n\u02c6Ct,i\n=\n\u02dcT(v?\n\u02dcT(v?\n(1 \u2212 w)gt,i+ w\u02c6 gt,i\n(1 \u2212 w)Ct,i+ w\u02c6Ct,i\nC\u22121\nt+1,igt+1,i.\nix\u2217\nix\u2217\nt)?log[p(yi|vi,x\u2217\nt)?\u02dcT(v?\nt)] (21)\n=\nix\u2217\nt)\ngt+1,i\n=\nCt+1,i\n\u02dc \u03b7t+1,i\n=\n=\nRather than performing a single regression of dimension 1+M(M +3)\/2, we may thus\nequivalently perform N regressions of dimension 3. Performing these lower dimensional\nregressions is computationally more efficient as long as N is not very large, and it is also\nstatistically more efficient. Figure 2 shows that this factorized regression implementation\nof our approximation indeed needs far fewer random draws to achieve convergence.\nAll N regressions can be performed in parallel, which offers further opportunities for\ncomputational gain on multicore machines or computer clusters.\nSo far, we have assumed that we sample x\u2217and then form the fiby multiplying with\nthe vi, but note that we can equivalently sample the fi directly and separately from\ntheir univariate Gaussian approximate posteriors q\u03b7(fi) = N[\u00b5i(\u03b7,vi),\u03c32\nthe current example we find that both implementations are about equally efficient.\ni(\u03b7,vi)]. For\n6.2Using the gradient of the log posterior\nUsing the Frisch-Waugh-Lovell theorem (Lovell 2008), we can remove the constant from\nthe sufficient statistics\u02dcT(x) and rewrite the optimality condition (9) in its normalized\nform (this is shown for our particular application in Appendix A):\n\u02c6 \u03b7 = Covq[T(x),T(x)]\u22121Covq[T(x),logp(x,y)]. (22)\nFurthermore, using the properties of the exponential family of distributions, we know\nthat\nCovq[T(x),T(x)] = \u2207\u03b7Eq\u03b7[T(x)],\nwhich we take to denote the transposed Jacobian matrix of Eq\u03b7[T(x)], and\n(23)\nCovq[T(x),logp(x,y)] = \u2207\u03b7Eq\u03b7[logp(x,y)],(24)\nwhich denotes the column vector gradient of Eq\u03b7[logp(x,y)] (since p(x,y) is a scalar\nvalued function).\nBoth Eq\u03b7[T(x)] and Eq\u03b7[logp(x,y)] can be approximated without bias using Monte\nCarlo. By differentiating these Monte Carlo approximations we can then obtain unbi-\nased estimates of their derivatives. This is easy to do as long as the pseudo-random"},{"page":18,"text":"854 VB through Stochastic Regression\ndraw x\u2217from q\u03b7(x) is a differentiable function of the parameters \u03b7, given our random\nnumber seed z\u2217:\nx\u2217\n\u02c6 g\n\u02c6C\n=s(\u03b7,z\u2217), with s() and z\u2217such that x\u2217\u223c q\u03b7(x)\n\u2207\u03b7logp(s(\u03b7,z\u2217),y) = \u2207\u03b7s(\u03b7,z\u2217)\u2207xlogp(x\u2217,y)\n\u2207\u03b7T(s(\u03b7,z\u2217)) = \u2207\u03b7s(\u03b7,z\u2217)\u2207xT(x\u2217).\n(25)\n=\n=\nBy using the same random number seed z\u2217in both Monte Carlo approximations we\nonce again get the beneficial variance reduction effect described in Section 4.\nPerforming a single iteration using (25) provides about the same information as doing\n2\u00d7dim(x) iterations with the basic algorithm, making it more computationally efficient\nif the gradients can be obtained analytically.\nWe can also do updates of this form while still making use of the factor structure of the\nposterior distribution, as proposed above for the probit regression example. Using this\nexample, and assuming we sample the fiseparately (see last paragraph of Section 6.1),\nthis gives the following regression statistics for each of the N low dimensional regressions:\nf\u2217\ni= si(\u03b7,z\u2217\n\u00ab\n\u00ab\n\u00ab\n\u201e\ni) = \u00b5i(\u03b7,vi) + \u03c3i(\u03b7,vi)z\u2217\n\u2202si(\u03b7,z\u2217\ni)\n\u2202\u03b7i,1\n\u2202si(\u03b7,z\u2217\n\u2202\u03b7i,2\n\u2202 log p(yi|f\u2217\n\u2202fi\n(\u2212\u00b5i\u03c32\n\u2202si(\u03b7,z\u2217\ni)\n\u2202\u03b7i,1\n\u2202si(\u03b7,z\u2217\ni)\n\u2202\u03b7i,2\n\u03c32\ni\n\u2212\u00b5i\u03c32\ni, with z\u2217\ni\u223c N(0,1)(26)\n\u02c6 gi=\ni)\nff\n\u2202 logp(y|f\u2217)\n\u2202fi\n=\n\u03c32\ni\ni)\ni\u2212 0.5\u03c33\nff\u201d\niz\u2217\ni)\u2202 log p(yi|f\u2217\ni)\n\u2202fi\nff\n\u02c6Ci=\n\u2202Ti,1(f\u2217\n\u2202f\u2217\ni)\ni\n\u2202Ti,2(f\u2217\n\u2202f\u2217\ni)\ni\n\u0131\n=\n\u2212\u03c32\ni+ 0.5\u03c33\nif\u2217\ni\ni\u2212 0.5\u03c33\niz\u2217\ni\n(\u00b5i\u03c32\niz\u2217\ni)f\u2217\ni\n\uf6be\n.\nFigure 2 shows the performance of this approximation on our probit example, showing\nagain a large gain in efficiency with respect to the approximations introduced earlier.\nEmpirically, we find that using gradients also leads to more efficient stochastic op-\ntimization algorithms for many other applications. For some problems the posterior\ndistribution will not be differentiable in some of the elements of x, for example when x\nis discrete. In that case the stochastic approximations presented here may be combined\nwith the basic approximation of Section 4.\nIn addition, for many samplers \u2207\u03b7s(\u03b7,z\u2217) may be not defined, e.g. rejection samplers.\nHowever, for the gradient approximations it does not matter what type of sampler is\nactually used to draw x\u2217, only that it is from the correct distribution. A correct strategy\nis therefore to draw x\u2217using any desired sampling algorithm, and then proceeding as if\nwe had used a different sampling algorithm for which \u2207\u03b7s(\u03b7,z\u2217) is defined. For example,"},{"page":19,"text":"T. Salimans and D. A. Knowles 855\nwe might use a nondifferentiable rejection sampler to draw a univariate x\u2217, and then\ncalculate (25) as if we had used an inverse-transform sampler, for which we have\n\u2202\n\u2202\u03b7is(\u03b7,z\u2217) = \u2212\n\u2202\n\u2202\u03b7iQ\u03b7(x\u2217)\nq\u03b7(x\u2217)\n, (27)\nfor all natural parameters \u03b7i, with Q\u03b7(x) the cdf and q\u03b7(x) the pdf of x. Similarly, it\ndoes not matter for the probit example whether we sample the fijointly by sampling x,\nor whether we sample them directly and independently. After sampling the fi, we can\nuse si(\u03b7,z\u2217\n(27), or something else entirely. Finding the most efficient strategy we mostly leave\nfor future work, although Sections 6.3 and 6.4 offer some further insights into what is\npossible.\ni) = \u00b5i+ \u03c3iz\u2217\nias proposed above, but we might equivalently proceed using\n6.3 Using the Hessian of the log posterior\nWhen we have both first and second order gradient information for logp(x,y) and if we\nchoose our approximation to be multivariate Gaussian, i.e. q\u03b7(x) = N(m(\u03b7),V (\u03b7)), we\nhave a third option for approximating the statistics used in the regression. For Gaussian\nq(x) and twice differentiable logp(x,y), Minka (2001) and Opper and Archambeau\n(2009) show that\n\u2207mEq[logp(x,y)] = Eq[\u2207xlogp(x,y)],\nand\n\u2207VEq[logp(x,y)] =1\nwhere \u2207x\u2207xlogp(x,y) denotes the Hessian matrix of logp(x,y) in x.\n(28)\n2Eq[\u2207x\u2207xlogp(x,y)], (29)\nFor the multivariate Gaussian distribution we know that the natural parameters are\ngiven as \u03b71 = V\u22121m and \u03b72 = V\u22121. Using this relationship, we can derive Monte\nCarlo estimators \u02c6 g and\u02c6C using the identities (23, 24). We find that these stochastic\napproximations are often even more efficient than the ones in Section 6.2, provided that\nthe Hessian matrix of logp(x,y) can be calculated cheaply. This type of approximation\nis especially powerful when combined with the extension presented in the next section.\n6.4 Linear transformations of the regression problem\nIt is well known that classical linear least squares regression is invariant to invertible\nlinear transformations of the explanatory variables. We can use the same principle in\nour stochastic approximation algorithm to allow us to work with alternative parame-\nterizations of the approximate posterior q(x). These alternative forms can be easier to\nimplement or lead to more efficient algorithms, as we show in this section.\nIn classical linear least squares regression, we have an N \u00d7 D matrix of explanatory\nvariables X, and an N \u00d7 1 vector of dependent variables Y . Instead of doing a linear"},{"page":20,"text":"856 VB through Stochastic Regression\nregression with these variables directly, we may equivalently perform the linear regres-\nsion using a transformed set of explanatory variables\u02dc X = XK?, with K any invertible\nmatrix of size D\u00d7D. The least squares estimator\u02dc\u03b2 = (\u02dc X? \u02dc X)\u22121 \u02dc X?Y of the transformed\nproblem can then be used to give the least squares estimator of the original problem as\n\u02c6\u03b2 = K?\u02dc\u03b2:\n\u02c6\u03b2 = K?(KX?XK?)\u22121KX?Y = (KX?X)\u22121KX?Y = (X?X)\u22121X?Y.\nUsing the same principle, we can rewrite the optimality condition of (9) as\n\u02dc \u03b7 = Eq\u03b7[K(\u03b7)\u02dcT(x)?\u02dcT(x)]\u22121Eq\u03b7[K(\u03b7)\u02dcT(x)?logp(x,y)], (30)\nfor any invertible matrix K, which may depend on the variational parameters \u03b7. Instead\nof solving our original least squares regression problem, we may thus equivalently solve\nthis transformed version. When we perform the linear regression in (30) for a fixed set of\nparameters \u03b7, the result will be identical to that of the original regression with K(\u03b7) = I,\nas long as we use the same random numbers for both regressions. However, when\nthe Monte Carlo samples (\u2018data points\u2019 in our regression) are generated using different\nvalues of \u03b7, as is the case with the proposed stochastic approximation algorithm, the two\nregressions will not necessarily give the same solution for a finite number of samples.\nIf the true posterior p(x|y) is of the same functional form as the approximation q\u03b7,\nthe exact convergence result of Section 4 holds for any invertible K(\u03b7), so it is not\nimmediately obvious which K(\u03b7) is best for general applications.\nWe hypothesize that certain choices of K(\u03b7) may lead to statistically more efficient\nstochastic approximation algorithms for certain specific problems, but we will not pursue\nthis idea here. What we will discuss is the observation that the stochastic approximation\nalgorithm may be easier to implement for some choices of K(\u03b7) than for others, and that\nthe computational costs are not identical for all K(\u03b7). In particular, the transformation\nK(\u03b7) allows us to use different parameterizations of the variational approximation. Let\nq\u03c6 be such a reparameterization of the approximation, let the new parameter vector\n\u03c6(\u03b7) be an invertible and differentiable transformation of the original parameters \u03b7, and\nset K(\u03b7) equal to the inverse transposed Jacobian of this transformation, i.e. K(\u03b7) =\n[\u2207\u03b7\u03c6(\u03b7)]\u22121. Using the properties of the exponential family of distributions, we can then\nshow that\nK(\u03b7)Covq\u03c6[T(x),h(x)] = \u2207\u03c6Eq\u03c6[h(x)],\nfor any differentiable function h(x). Using this result, the stochastic approximations of\nSection 6.2 for the transformed regression problem are\n(31)\nx\u2217\n\u02c6 g\n\u02c6C\n=s(\u03c6,z\u2217), with s() and z\u2217such that x\u2217\u223c q\u03c6(x)\n\u2207\u03c6logp(s(\u03c6,z\u2217),y)\n\u2207\u03c6T(s(\u03c6,z\u2217)).\n(32)\n= (33)\n= (34)\nThese new expressions for \u02c6 g and\u02c6C may be easier to calculate than the original ones (25),\nand the resulting\u02c6C may have a structure making it easier to invert in some cases. An"},{"page":21,"text":"T. Salimans and D. A. Knowles 857\nexample of this occurs when we use a Gaussian approximation in combination with the\nstochastic approximations of Section 6.3, using the gradient and Hessian of logp(x,y).\nIn this case we may work in the usual natural parameterization, but doing so gives a\ndense matrix\u02c6C with dimensions proportional to M2, where M is the dimension of x.\nFor large M, such a stochastic approximation is expensive to store and invert. However,\nusing the stochastic approximations above, we may alternatively parameterize our ap-\nproximation in terms of the mean m and variance V . Working in this parameterization,\nwe can express the update equations for the natural parameters in terms of the gradi-\nent and Hessian of logp(x,y) and the average sampled x value, instead of the (higher\ndimensional) g and C statistics. The resulting algorithm, as derived in Appendix B, is\ntherefore more efficient in terms of both computation and storage. Pseudocode for the\nnew algorithm is given below.\nAlgorithm 2 Stochastic Approximation for Gaussian Variational Approximation\nRequire: An unnormalized, twice differentiable posterior distribution p(x,y)\nRequire: The total number of iterations N\nInitialize the mean and variance of the approximation (m1,V1) to a first guess, for\nexample by matching the prior p(x)\nInitialize z1= m1, P1= V\u22121\n1\nand a1= 0\nInitialize \u00af z = 0,\u00afP = 0 and \u00af a = 0\nSet step-size w = 1\/?N\nfor t = 1 : N do\nGenerate a draw x\u2217\nCalculate the gradient gtand Hessian Htof logp(x,y) at x\u2217\nSet at+1= (1 \u2212 w)at+ wgt\nSet Pt+1= (1 \u2212 w)Pt\u2212 wHt\nSet zt+1= (1 \u2212 w)zt+ wx\u2217\nSet Vt+1= P\u22121\nif t > N\/2 then\nSet \u00af a = \u00af a +\nNgt\nSet\u00afP =\u00afP \u2212\nSet \u00af z = \u00af z +\nt\nend if\nend for\nSet V =\u00afP\u22121and m = V \u00af a + \u00af z\nreturn m,V\ntfrom N(mt,Vt)\nt\nt\nt+1and mt+1= Vt+1at+1+ zt+1\n2\n2\nNHt\n2\nNx\u2217\nInstead of storing and inverting the full C matrix, this algorithm uses the sparsity\ninduced by the transformation K(\u03b7) to work with the precision matrix P instead. The\ndimensions of this matrix are equal to the dimension of x, rather than its square,\nproviding great savings. Moreover, while the C matrix in the original parameterization\nis always dense, P will have the same sparsity pattern as the Hessian of logp(x,y), which\nmay reduce the costs of storing and inverting it even further for many applications."},{"page":22,"text":"858 VB through Stochastic Regression\nFigure 2 shows the performance of Algorithm 2 as applied to our probit regression\nexample. As is typical for this version of the algorithm, it performs even better than\nthe algorithm using only the gradient and factor structure of the posterior distribution.\nSince this type of approximation is also very easy to implement efficiently in a matrix\nprogramming language like MATLAB, it also runs significantly faster than the VBEM\nalgorithm for this example. Moreover, the algorithm is now again completely general\nand does not make any assumptions as to the structure of the posterior distribution\n(other than it being twice differentiable). This means it can easily be used for Gaussian\nvariational approximation of almost any posterior distribution.\n6.5 Subsampling the data: double stochastic approximation\nThe stochastic approximations derived above are all linear functions of logp(x,y) and\nits first and second derivatives. This means that these estimates are still unbiased even if\nwe take logp(x,y) to be a noisy unbiased estimate of the true log posterior, rather than\nthe exact log posterior. For most statistical applications logp(x,y) itself is a separable\nadditive function of a number of independent factors, i.e. logp(x,y) =?N\napproximation of logp(x,y) as\nj=1log\u03c6j(x,y)\nas explained in Section 6.1. Using this fact we can construct an unbiased stochastic\nlog \u02dc p(x,y) =N\nK\nK\n?\nj=1\nlog\u03c6j(x,y), (35)\nwhere the K factors log\u03c6j(x,y) are randomly selected from the total N factors. This\napproach was previously proposed for online learning of topic models by Hoffman et al.\n(2010). Since log \u02dc p(x,y) has logp(x,y) as its expectation, performing stochastic approx-\nimation based on \u02dc p(x,y) converges to the same solution as when using p(x,y), provided\nwe resample the factors in log \u02dc p(x,y) at every iteration. By subsampling the K ? N\nfactors in the model, the individual steps of the optimization procedure become more\nnoisy, but since we can calculate \u02dc p(x,y) faster than we can p(x,y), we can perform a\nlarger number of steps in the same amount of time. In practice this tradeoff often favors\nusing subsampling, and this principle has been used in many successful applications of\nstochastic gradient descent, see e.g. Bottou (2010).\nFor our probit regression example we implement subsampling by dividing the sample\ninto 10 equally sized \u2018minibatches\u2019 of data. During each iteration of the algorithm, these\nminibatches are processed in random order, using Algorithm 2 combined with (35) to\nupdate the variational parameters after each minibatch. As can be seen in Figure 2 this\napproach allows us to get a good approximation to the posterior very quickly: reaching\nthe accuracy of converged VBEM now only requires three passes over the training data,\nalthough final convergence is not much faster than when using the full sample."},{"page":23,"text":"T. Salimans and D. A. Knowles859\n7 Extensions II: Using mixtures of exponential family dis-\ntributions\nSo far, we have assumed that the approximating distribution q\u03b7(x) is a member of the\nexponential family. Here we will relax that assumption. If we choose a non-standard\napproximation, certain moments or marginals of q\u03b7(x) are typically no longer available\nanalytically, which should be taken into account when choosing the type of approxima-\ntion. However, if we can at least sample directly from q\u03b7(x), it is often still much cheaper\nto approximate these moments using Monte Carlo than it would be to approximate the\ncorresponding moments of the posterior using MCMC or other indirect sampling meth-\nods. We have identified two general strategies for constructing useful non-standard\nposterior approximations which are discussed in the following two sections.\n7.1 Hierarchical approximations\nIf we split our vector of unknown parameters x into p non-overlapping blocks, our\napproximating posterior may be decomposed as\nq(x) = q(x1)q(x2|x1)q(x3|x1,x2)...q(xp|x1,...,xp\u22121).\nIf we then choose every conditional posterior q(xi|x1,...,xi\u22121) to be an analytically\ntractable member of the exponential family, we can easily sample from the joint q(x),\nwhile still having much more freedom in capturing the dependence between the different\nblocks of x. In practice, such a conditionally tractable approximation can be achieved\nby specifying the sufficient statistics of each exponential family block q(xi|x1,...,xi\u22121)\nto be a function of the preceding elements x1,x2,...,xi\u22121. This leads to a natural type\nof approximation for hierarchical Bayesian models, where the hierarchical structure of\nthe prior often suggests a good hierarchical structure for the posterior approximation.\nIf every conditional q(xi|x1,...,xi\u22121) is in the exponential family, the joint may not\nbe if the normalizing constant of any of those conditionals is a non-separable function\nof the preceding elements x1,x2,...,xi\u22121 and the variational parameters. However,\nbecause the conditionals are still in the exponential family, our optimality condition\nstill holds separately for the variational parameters of each conditional with only slight\nmodification. Taking again the derivative of the KL-divergence and setting it to zero\nyields:\n\u03b7i\nCi\ngi\n=C\u22121\ni\nEq(x1,...,xi\u22121){Varq(xi|x1,...,xi\u22121)[Ti(xi)]}\nEq(x1,...,xi\u22121){Covq(xi,...,xp|x1,...,xi\u22121)[Ti(xi),r\u2212i(x)]},\nlogp(x,y) \u2212 logq\u03b7(x1,...,xi\u22121) \u2212 logq\u03b7(xi+1,...,xp|x1,...,xi)\nlogp(x,y) \u2212 logq\u03b7(x) + logq\u03b7(xi|x1,...,xi\u22121),\nwhere Ti(xi) and \u03b7idenote the sufficient statistics and corresponding natural parame-\nters of the i-th conditional approximation q(xi|x1,...,xi\u22121), and where r\u2212i(x) can be\ngi\n(36)\n=\n=\nr\u2212i(x)=\n="},{"page":24,"text":"860VB through Stochastic Regression\nseen as the residual of the approximation with the i-th block left out. Note that we\ncannot rewrite this expression as a linear regression any further, like we did in Sec-\ntion 2, since the intercept of such a regression is related to the normalizing constant of\nq(xi|x1,...,xi\u22121) which may now vary in x1,...,xi\u22121. However, Ciand gican still be\napproximated straightforwardly using Monte Carlo, and Algorithm 1 can still be used\nwith these approximations, performing separate \u2018regressions\u2019 for all conditionals during\neach iteration like we proposed for factorized p(x,y) in Section 6.1. Alternatively, Al-\ngorithm 2 or any of the extensions in Section 6 may be used to fit the different blocks\nof q\u03b7(x).\nUsing this type of approximation, the marginals q(xi) will generally be mixtures of\nexponential family distributions, which is where the added flexibility of this method\ncomes from. By allowing the marginals q(xi) to be mixtures with dependency on the\npreceding elements of x, we can achieve much better approximation quality than by\nforcing them to be a single exponential family distribution. A similar idea was used in\nthe context of importance sampling by Hoogerheide et al. (2012). A practical example\nof this is given below.\nExample: A stochastic volatility model\nStochastic volatility models for signals with time varying variances are considered ex-\ntremely important in finance. Here we apply our methodology to the model and prior\nspecified in Girolami and Calderhead (2011). The data we will use, from Kim et al.\n(1998), is the percentage change ytin GB Pound vs. US Dollar exchange rate, modeled\nas:\nyt= ?t\u03b2 exp(vt\/2).\nThe relative volatilities, vtare governed by the autoregressive AR(1) process\nvt+1= \u03c6vt+ \u03bet+1, with v1\u223c N[0,\u03c32\/(1 \u2212 \u03c62)].\nThe distributions of the error terms are given by ?t\u223c N(0,1) and \u03bet\u223c N(0,\u03c32). The\nprior specification is as in Girolami and Calderhead (2011):\np(\u03b2) \u221d \u03b2\u22121,(\u03c6 + 1)\/2 \u223c Beta(20,1.5),\u03c32\u223c Inv-Gamma(5,0.25).\nFollowing the strategy outlined above, we use the hierarchical structure of the prior to\nsuggest a hierarchical structure for the approximate posterior:\nq\u03b7(\u03c6,\u03c32,\u03b2,v) = q\u03b7(\u03c6)q\u03b7(\u03c32|\u03c6)q\u03b7(\u03b2,v|\u03c6,\u03c32).\nThe prior of \u03c6 is in the exponential family, so we choose the posterior approximation\nq\u03b7(\u03c6) to be of the same form:\nq\u03b7[(\u03c6 + 1)\/2] = Beta(\u03b71,\u03b72)."},{"page":25,"text":"T. Salimans and D. A. Knowles861\nThe prior for \u03c32is inverse-Gamma, which is also in the exponential family. We again\nchoose the same functional form for the posterior approximation, but with a slight\nmodification in order to capture the posterior dependency between \u03c6 and \u03c32:\nq\u03b7(\u03c32|\u03c6) \u223c Inv-Gamma(\u03b73,\u03b74+ \u03b75\u03c62),\nwhere the extra term \u03b75\u03c62was chosen by examining the functional form of the exact\nfull conditional p(\u03c32|\u03c6,v).\nUsing the notation f = (log(\u03b2),v?)?, the conditional prior p(f|\u03c6,\u03c32) can be seen as the\ndiffuse limit of a multivariate normal distribution. We therefore also use a multivariate\nnormal conditional approximate posterior:\nq\u03b7(f|\u03c6,\u03c32) =p(f|\u03c6,\u03c32)q\u03b7(y|f)\nq\u03b7(y|\u03c6,\u03c32)\n,\nwith p(f|\u03c6,\u03c32) the Gaussian prior, q\u03b7(y|f) a Gaussian approximate likelihood of the\nform\nq\u03b7(y|f) = (2\u03c0)\u2212T\/2a\nwith \u03b76a T \u00d7 T positive-definite matrix and \u03b77a T \u00d7 1 vector, and where\nq\u03b7(y|\u03c6,\u03c32) =\nf\n|\u03b76|exp\u201c\u03b7?\n?\n7\u03b7\u22121\n6\u03b77\n\u2030exp\n\u201e\n\u03b7?\n7f \u22121\n2f?\u03b76f\n\uf6be\n,\np(f|\u03c6,\u03c32)q\u03b7(y|f)df\nis the normalizing constant of our posterior approximation q\u03b7(f|\u03c6,\u03c32).\nNow that we have defined the functional form of the approximate posterior, we can fit\nits parameters by applying (36) to each of the blocks q\u03b7(\u03c6), q\u03b7(\u03c32|\u03c6), and q\u03b7(f|\u03c6,\u03c32).\nWe approximate the statistics of the first two blocks using gradients as proposed in\nSection 6.2. The last (multivariate Gaussian) block is updated using both the gradient\nand the Hessian of p(y|f) via the optimized expressions of Algorithm 2.\nFor the first block q\u03b7(\u03c6) this gives us the following stochastic approximations:\n\u03c6\u2217\n\u03c32\u2217\n\u02c6C1\n\u02c6 g1\n=s1(\u03b7,z\u2217\ns2(\u03b7,z\u2217\n\u2207\u03b7[s1(\u03b7,z\u2217\n\u2207\u03b7[s1(\u03b7,z\u2217\n+\u2207\u03c6[s2(\u03b7,z\u2217\n\u2207\u03b7[s1(\u03b7,z\u2217\n+Eq(f|\u03c6\u2217,\u03c32\u2217)(logp(y|f) \u2212 logq\u03b7(y|f))]\n+\u2207\u03c6[s2(\u03b7,z\u2217\n+Eq(f|\u03c6\u2217,\u03c32\u2217)(logp(y|f) \u2212 logq\u03b7(y|f))]}\n\u2207\u03b7[s1(\u03b7,z\u2217\n1), with s1() and z\u2217\n2,\u03c6\u2217), with s2() and z\u2217\n1)]\u2207\u03c6[T1(\u03c6\u2217)]\n1)]{\u2207\u03c6Eq(f|\u03c6\u2217,\u03c32\u2217)[logp(\u03c6\u2217,\u03c32\u2217,f,y) \u2212 logq\u03b7(\u03c32\u2217,f|\u03c6\u2217)]\n2,\u03c6\u2217)]\u2207\u03c32Eq(f|\u03c6\u2217,\u03c32\u2217)[logp(\u03c6\u2217,\u03c32\u2217,f,y) \u2212 logq\u03b7(\u03c32\u2217,f|\u03c6\u2217)]}\n1)]{\u2207\u03c6[logp(\u03c6\u2217) + logq\u03b7(y|\u03c6\u2217,\u03c32\u2217) \u2212 logq\u03b7(\u03c32\u2217|\u03c6\u2217)\n1such that \u03c6\u2217\u223c q\u03b7(\u03c6)\n2such that \u03c32\u2217\u223c q\u03b7(\u03c32|\u03c6\u2217)\n(37)\n=(38)\n=(39)\n=(40)\n= (41)\n2,\u03c6\u2217)]\u2207\u03c32[logp(\u03c32\u2217) + logq\u03b7(y|\u03c6\u2217,\u03c32\u2217) \u2212 logq\u03b7(\u03c32\u2217|\u03c6\u2217)\n\u2248\n1)]{\u2207\u03c6[logp(\u03c6\u2217) + logq\u03b7(y|\u03c6\u2217,\u03c32\u2217) \u2212 logq\u03b7(\u03c32\u2217|\u03c6\u2217)],(42)"},{"page":26,"text":"862 VB through Stochastic Regression\nwhere T1(\u03c6\u2217) are the sufficient statistics of q\u03b7(\u03c6), and where we make use of the fact\nthat\np(\u03c6,\u03c32,\u03b2,f) = p(\u03c6)p(\u03c32)p(f|\u03c6,\u03c32)p(y|f)\nand\nq\u03b7(\u03c32,f|\u03c6)=q\u03b7(\u03c32|\u03c6)q\u03b7(f|\u03c6,\u03c32)\nq\u03b7(\u03c32|\u03c6)p(f|\u03c6,\u03c32)q\u03b7(y|f)\/q\u03b7(y|\u03c6,\u03c32).=\nCancelling the prior term p(f|\u03c6,\u03c32) in p() and q() then allows us to go from (40) to (41).\nThe approximate marginal likelihood q\u03b7(y|\u03c6,\u03c32) and the expectations with respect to\nq\u03b7(f|\u03c6,\u03c32) can be evaluated analytically using the Kalman filter and smoother (e.g.\nDurbin and Koopman 2001), which means we do not have to sample f for this problem.\nNote that (41) includes both the direct effect of \u03c6, as well as its indirect effects through\nq\u03b7(\u03c32|\u03c6) and q\u03b7(f|\u03c6,\u03c32). If the functional form of q() is close to that of p(), the relative\nimportance of these indirect effects is low. In most cases we can therefore ignore these\nindirect effects with little to no loss of accuracy. For the current application we find\nthat using (42) instead of (41) gives virtually identical results.\nThe stochastic approximations for the second block q\u03b7(\u03c32|\u03c6) are given by\n\u02c6C2\n=\n\u2207\u03b7[s2(\u03b7,z\u2217\n\u02c6 g2\n=\n\u2207\u03b7[s2(\u03b7,z\u2217\n+Eq(f|\u03c6\u2217,\u03c32\u2217)(logp(y|f) \u2212 logq\u03b7(y|f))]\n\u2248\nwhere T2(\u03c32\u2217) are the sufficient statistics of q\u03b7(\u03c32|\u03c6).\n2,\u03c6\u2217)]\u2207\u03c32[T2(\u03c32\u2217)]\n2,\u03c6\u2217)]\u2207\u03c32[logp(\u03c32\u2217) + logq\u03b7(y|\u03c6\u2217,\u03c32\u2217)\n(43)\n\u2207\u03b7[s2(\u03b7,z\u2217\n2,\u03c6\u2217)]\u2207\u03c32[logp(\u03c32\u2217) + logq\u03b7(y|\u03c6\u2217,\u03c32\u2217)],\nFinally, the updates for the likelihood approximation (using Algorithm 2) are given by\nat+1\nzt+1\n\u03b76,t+1\n\u03b77,t+1\n= (1 \u2212 w)at+ wEq\u03b7(f|\u03c6\u2217,\u03c32\u2217)[\u2207flogp(y|f)]\n(1 \u2212 w)zt+ wEq\u03b7(f|\u03c6\u2217,\u03c32\u2217)[f]\n(1 \u2212 w)\u03b76,t\u2212 wEq\u03b7(f|\u03c6\u2217,\u03c32\u2217)[\u2207f\u2207flogp(y|f)]\nat+1+ \u03b76,t+1zt+1.\n=\n=\n=\nHere again, the expectations with respect to the approximate posterior q\u03b7(f|\u03c6,\u03c32) can\nbe calculated analytically using the Kalman filter\/smoother and do not have to be\napproximated by sampling. Furthermore we know that the Hessian of the log likelihood\nis sparse, which means that only a relatively small number of the parameters in \u03b76will be\nnon-zero: all elements on the diagonal and all elements in the column and row belonging\nto log(\u03b2). This sparsity is also what makes fitting this posterior approximation feasible,\nsince inverting a dense T \u00d7T precision matrix would be much too expensive. Even with\nthis sparsity, our optimization problem is still fairly high dimensional with about 2000\nfree parameters. Nevertheless, we find that our approximation converges very quickly\nusing 250 iterations of our algorithm, with a single (\u03c6,\u03c32) sample per iteration, which"},{"page":27,"text":"T. Salimans and D. A. Knowles 863\ntakes our single-threaded MATLAB implementation half a second to complete on a\n3GHz processor. This is more than two orders of magnitude faster than the running\ntime required by advanced MCMC algorithms for this problem.\nWe compare the results of our posterior approximation against the \u201ctrue\u201d posterior,\nprovided by a very long run of the MCMC algorithm of Girolami and Calderhead\n(2011). As can be seen from Figures 3, 4 and 5, the posterior approximations for\nthe model parameters are nearly exact. Similarly, the posterior approximations for the\nlatent volatilities v (not shown) are also indistinguishable from the exact posterior.\n0.4 0.50.60.7 0.80.9\nbeta\n1 1.11.2 1.31.4\n0\n1\n2\n3\n4\n5\n6\n7\n8\nposterior density\n \n \nMonte Carlo\nVariational Approximation\nFigure 3: Exact and approximate posterior for the stochastic volatility model - \u03b2 pa-\nrameter\nOur approach to doing inference in the stochastic volatility model shares some char-\nacteristics with the approach of Liesenfeld and Richard (2008). They fit a Gaussian\napproximation to the posterior of the volatilities for given \u03c6,\u03c32,\u03b2 parameters, using\nthe importance sampling algorithm of Richard and Zhang (2007), which is based on\nauxiliary regressions somewhat similar to those in Algorithm 1. They then infer the\nmodel parameters using MCMC methods. The advantage of our method is that we are\nable to leverage the information in the gradient and Hessian of the posterior, and that\nour stochastic approximation algorithm allows us to fit the posterior approximation very\nquickly for all volatilities simultaneously, while their approach requires optimizing the\napproximation one volatility at a time. Unique to our approach is also the ability to\nconcurrently fit a posterior approximation for the model parameters \u03c6,\u03c32,\u03b2 and have\nthe approximate posterior of the volatilities depend on these parameters, while Liesen-\nfeld and Richard (2008) need to re-construct their approximation every time a new set\nof model parameters is considered. As a result, our approach is significantly faster for\nthis problem."},{"page":28,"text":"864VB through Stochastic Regression\n0.75 0.80.850.90.951\n0\n5\n10\n15\n20\n25\n30\nphi\nposterior density\n \n \nMonte Carlo\nVariational Approximation\nFigure 4: Exact and approximate posterior for the stochastic volatility model - \u03c6 pa-\nrameter\n00.05 0.10.150.20.25\n0\n5\n10\n15\n20\n25\n30\n35\nvariance\nposterior density\n \n \nMonte Carlo\nVariational Approximation\nFigure 5: Exact and approximate posterior for the stochastic volatility model - \u03c32\nparameter"},{"page":29,"text":"T. Salimans and D. A. Knowles 865\n7.2Using auxiliary variables\nAnother approach to constructing flexible posterior approximations is using the con-\nditional exponential family approximation of Section 7.1, but letting the first block of\nvariables be a vector of auxiliary variables u, that are not part of the original set of\nmodel parameters and latent variables, x. The posterior approximation then has the\nform\nq(x,u) = q(u)q(x|u).\nThe factors q(u) and q(x|u) should both be analytically tractable members of the expo-\nnential family, which allows the marginal approximation q(x) to be a general mixture\nof exponential family distributions, like a mixture of normals for example. If we use\nenough mixture components, the approximation q(x) could then in principle be made\narbitrarily close to p(x|y). Note, however, that if p(x|y) is multimodal our optimization\nproblem might suffer from multiple local minima, which means that we are generally\nnot guaranteed to find the optimal approximation.\nThe mixture approximation q(x) can be fitted by performing the standard KL-divergence\nminimization:\nEq\u03b7[logq\u03b7(x) \u2212 logp(x,y)].\u02c6 \u03b7 = argmin\n\u03b7\n(44)\nFrom (44) it becomes clear that an additional requirement of this type of approximation\nis that we can integrate out the auxiliary variables u from the joint q(x,u) in order to\nevaluate the marginal density q(x) at a given point x. Fortunately this is easy to do for\nmany interesting approximations, such as discrete mixtures of normals or continuous\nmixtures like Student\u2019s t distributions. Also apparent from (44) is that we cannot use\nthis approximation directly with the stochastic approximation algorithms proposed in\nthe last sections since q(x) is itself not part of the exponential family of distributions.\nHowever, we can rewrite (44) as\n\u02c6 \u03b7 = argmin\n\u03b7\nEq\u03b7[logq\u03b7(x,u) \u2212 log \u02dc p(x,y,u)],(45)\nwith \u02dc p(x,y,u) = p(x,y)q\u03b7(u|x), and\nq\u03b7(u|x) =\nq\u03b7(x|u)q\u03b7(u)\n?q\u03b7(x|u)q\u03b7(u)du=q\u03b7(x|u)q\u03b7(u)\nq\u03b7(x)\n.\nEquation 45 now once again has the usual form of a KL-divergence minimization where\nthe approximation, q\u03b7(x,u), consists of exponential family blocks q\u03b7(u) and q\u03b7(x|u). By\nincluding the auxiliary variables u in the \u2018true\u2019 posterior density, we can thus once again\nmake use of our efficient stochastic optimization algorithms. Including u in the posterior\ndoes not change the marginal posterior p(x|y) which is what we are interested in. We\nnow describe a practical example of this approach using an approximation consisting of\na mixture of normals."},{"page":30,"text":"866VB through Stochastic Regression\nExample: A beta-binomial model for overdispersion\nAlbert (2009, Section 5.4) considers the problem of estimating the rates of death from\nstomach cancer for the largest cities in Missouri. This cancer mortality data is available\nfrom the R package LearnBayes, and consists of 20 pairs (nj,yj) where njcontains the\nnumber of individuals that were at risk in city j, and yjis the number of cancer deaths\nthat occurred in that city. The counts yjare overdispersed compared to what one could\nexpect under a binomial model with constant probability, so Albert (2009) assumes the\nfollowing beta-binomial model with mean m and precision K:\nP(yj|m,K) =\n\u02c6nj\nyj\n\u02d9B(Km + yj,K(1 \u2212 m) + nj\u2212 yj)\nB(Km,K(1 \u2212 m))\n,\nwhere B(\u00b7,\u00b7) denotes the Beta-function. The parameters m and K are given the follow-\ning improper prior:\np(m,K) \u221d\n1\nm(1 \u2212 m)\n1\n(1 + K)2.\nThe resulting posterior distribution is non-standard and extremely skewed. To amelio-\nrate this, Albert (2009) proposes the reparameterization\nx1= logit(m), and x2= log(K).\nThe form of the posterior distribution p(x|y) still does not resemble any standard dis-\ntribution, so we will approximate it using a finite mixture of L bivariate Gaussians.\nIn order to do this, we first introduce an auxiliary variable u, to which we assign a\ncategorical approximate posterior distribution with L possible outcomes:\nq\u03b7(u) = expr\u03b4(u = 1)\u03b71+ \u03b4(u = 2)\u03b72+ \u00b7\u00b7\u00b7 + \u03b4(u = L)\u03b7L\u2212 U(\u03b7)s,\nwhere \u03b4(.) is the indicator function and U(\u03b7) is the normalizer.\nConditional on u, we assign x a Gaussian approximate posterior\nq\u03b7(x|u = i) = N(\u00b5i,\u03a3i).\nBy adapting the true posterior to include u as described above, we can fit this ap-\nproximate posterior to p(x|y). Here, the auxiliary variable u is discrete, and hence our\nposterior approximation is not differentiable with respect to this variable. We must\ntherefore use the basic stochastic approximation of Section 4 to fit q\u03b7(u). In order to re-\nduce the variance of the resulting stochastic approximations, we Rao-Blackwellize them\nby taking expectations with respect to q\u03b7(u|x). If we then also take advantage of the\nsparsity in the covariance matrix of the sufficient statistics, this leads to the following"},{"page":31,"text":"T. Salimans and D. A. Knowles867\nupdate equations:\nx\u2217\nt\n\u223c\n=\nq\u03b7t(x)\nEq\u03b7t(u|x\u2217\n\u02c6Ct,i[logp(x\u2217\n\u02c6Ct,i[logp(x\u2217\n\u2212logq\u03b7t(x\u2217\n\u02c6Ct,i[logp(x\u2217\n(1 \u2212 w)Ct,i+ w\u02c6Ct,i\n(1 \u2212 w)gt,i+ w\u02c6 gt,i\ngt+1,i\nCt+1,i,\n\u02c6Ct,i\nt)[\u03b4(u = i)] = q\u03b7(u = i|x\u2217\nt,y) + logq\u03b7(u = i|x\u2217\nt,y) + logq\u03b7t(x\u2217\nt) \u2212 logq\u03b7t(x\u2217\nt,y) \u2212 logq\u03b7t(x\u2217\nt)\n\u02c6 gt,i\n=\nt) \u2212 logq\u03b7t(x\u2217\nt|u = i) + logq\u03b7t(u = i)\nt|u = i)]\nt) + \u03b7t,i\u2212 U(\u03b7t)]\nt|u = i)]\n=\n=\nCt+1,i\ngt+1,i\n=\n=\n\u03b7t+1,i\n=\nfor each mixture component i.\nConditional on u, the approximate posterior for x is Gaussian, and we can therefore\nonce again use the optimized expressions from Algorithm 2 to update q\u03b7(x|u):\nx\u2217\nt\n\u223c\n\u02c6Ct,i\n=\nEq\u03b7t(u|x\u2217\nCt+1,i\n=(1 \u2212 w)Ct,i+ w\u02c6Ct,i\nat+1,i\n=(1 \u2212 w)at,i+ w\u02c6Ct,i\u2207x[logp(x\u2217,y) + logq\u03b7t(u = i|x\u2217)]\nHt+1,i\n=(1 \u2212 w)Ht,i+ w\u02c6Ct,i\u2207x\u2207x[logp(x\u2217,y) + logq\u03b7t(u = i|x\u2217)]\nzt+1,i\n=(1 \u2212 w)zt,i+ w\u02c6Ct,ix\u2217\n\u03a3t+1,i\n=\n\u2212Ct+1,iH\u22121\n\u00b5t+1,i\n=\n\u2212H\u22121\nq\u03b7t(x)\nt)[\u03b4(u = i)] = q\u03b7t(u = i|x\u2217\nt)\nt\nt+1,i\nt+1,iat+1+\nzt+1\nCt+1,i,\nfor each mixture component i. Here we have once again Rao-Blackwellized the stochas-\ntic approximations with respect to q\u03b7(u|x), which introduced the extra variable\u02c6Ct,i\ncompared to Algorithm 2. Also note the presence of the logq\u03b7t(u = i|x\u2217) term, which\nenters our equations as a result of expanding the posterior to include u. This term has\nthe effect of pushing apart the different mixture components of the approximation.\nWe fit the approximation q\u03b7(x) using a varying number of mixture components and\nexamine the resulting KL-divergence to the true posterior density. Since this is a low\ndimensional problem, we can obtain this divergence very precisely using quadrature\nmethods. Figures 6 and 7 show that we can indeed approximate this skewed and heavy-\ntailed density very well using a large enough number of Gaussians. The R-squared of\nthe mixture approximation with 8 components is 0.997."},{"page":32,"text":"868VB through Stochastic Regression\nAlso apparent is the inadequacy of an approximation consisting of a single Gaussian for\nthis problem, with an R-squared of only 0.82. This clearly illustrates the advantages of\nour approach which allows us to use much richer approximations than was previously\npossible. Furthermore, Figure 6 shows that the KL-divergence of the approximation to\nthe true posterior can be approximated quite accurately using the measure developed\nin Section 5, especially if the posterior approximation is reasonably good.\nThe variational optimization problem for this approximation has multiple solutions,\nsince all Gaussian mixture components are interchangeable. Since p(x|y) is unimodal,\nhowever, we find that all local optima (that we find) are equally good, and are presum-\nably also global optima. In this case, we find that we can therefore indeed approximate\np(x|y) arbitrarily well by using a large enough number of mixture components.\n12345678\n0\n0.02\n0.04\n0.06\n0.08\n0.1\n0.12\n0.14\nnumber of mixture components\nKL divergence D(q|p)\n \n \nexact\napproximate\nFigure 6: KL-divergence between the variational approximation and the exact posterior\ndensity for an increasing number of mixture components. The exact divergence is given\nby the solid blue line, while the approximation from Section 5 is given by the dashed red\nline. Note that the log marginal likelihood is given by logp(y) = \u02c6 \u03b70+U(\u03b7)+D(q\u03b7|p), with\n\u02c6 \u03b70+U(\u03b7) = Eq[logp(x,y)\u2212logq(x)] its usual lower bound. This means that the height\nof the solid blue line can also be interpreted as the approximation error of this bound for\napproximating the log marginal likelihood. The corresponding approximation error for\nthe newly proposed marginal likelihood approximation (Section 5, Equation 17) is then\ngiven by the difference between the solid and dashed lines: The new approximation for\nthe marginal likelihood is thus much more accurate than the usual lower bound."},{"page":33,"text":"T. Salimans and D. A. Knowles869\nlogit m\nlog K\nexact\n\u22127.5 \u22127 \u22126.5 \u22126\n5\n10\nlogit m\n4\nlog K\n1\n\u22127.5 \u22127 \u22126.5 \u22126\n5\n10\nlogit m\n5\nlog K\n2\n\u22127.5 \u22127 \u22126.5 \u22126\n5\n10\nlogit m\n6\nlog K\n3\n\u22127.5 \u22127 \u22126.5 \u22126\n5\n10\nlogit m\n7\nlog K\n\u22127.5 \u22127 \u22126.5 \u22126\n5\n10\nlogit m\n8\nlog K\n\u22127.5 \u22127 \u22126.5 \u22126\n5\n10\nlogit m\nlog K\n\u22127.5 \u22127 \u22126.5 \u22126\n5\n10\nlogit m\nlog K\n\u22127.5 \u22127 \u22126.5 \u22126\n5\n10\nlogit m\nlog K\n\u22127.5 \u22127 \u22126.5 \u22126\n5\n10\nFigure 7: Contour plots of posterior approximations using 1-8 mixture components,\nwith the exact posterior at the bottom-right. With seven or eight mixture components\nthe approximation is visually indistinguishable from the true posterior.\n8Conclusion and future work\nWe have introduced a stochastic optimization scheme for variational inference inspired\nby a novel interpretation of fixed-form variational approximation as linear regression of\nthe target log density against the sufficient statistics of the approximating family. Our\nscheme allows very generic implementation for a wide class of models since in its most\nbasic form only the unnormalized density of the target distribution is required, although\nwe have shown how gradient or even Hessian information can be used if available. The\ngeneric nature of our methodology would lend itself naturally to a software package for\nBayesian inference along the lines of Infer.NET (Minka et al. 2010) or WinBUGS (Gilks\net al. 1994), and would allow inference in a considerably wider range of models. Incorpo-\nrating automatic differentiation in such a package could clearly be beneficial. Automatic\nselection of the approximating family would be very appealing from a user perspective,\nbut could be challenging in general.\nDespite its general applicability, the performance of our approach was demonstrated\nto be very competitive for problems where we can either decompose the posterior dis-\ntribution into low dimensional factors (Section 6.1), or where we can make use of the\ngradient and Hessian of the log posterior (Section 6.3). For those rare cases where this"},{"page":34,"text":"870VB through Stochastic Regression\nis not the case (e.g. high dimensional discrete distributions without factor structure) we\ncannot presently recommend the optimization algorithm presented in this paper. The\nextension of our approach to this class of problems is an important direction for future\nwork.\nWe have shown it is straightforward to extend our methodology to use hierarchical\nstructured approximations and more flexible approximating families such as mixtures.\nThis closes the gap considerably relative to MCMC methods.\nselling point of MCMC methods is that they are asymptotically exact: in practice\nthis means simply running the MCMC chain for longer can give greater accuracy, an\noption not available to a researcher using variational methods. However, if we use\na mixture approximating family then we can tune the computation time vs. accuracy\ntrade off simply by varying the number of mixture components used. Another interesting\ndirection of research along this line would be to use low rank approximating families\nsuch as factor analysis models.\nPerhaps the biggest\nVariational inference usually requires that we use conditionally conjugate models: since\nour method removes this restriction several possible avenues of research are opened. For\nexample, for MCMC methods collapsed versions of models (i.e. with certain parameters\nor latent variables integrated out) sometimes permit much more efficient inference (Por-\nteous et al. 2008) but adapting variational methods to work with collapsed models is\ncomplex and requires custom per model methodology (Teh et al. 2006). However, our\nmethod is indifferent to whether the model is collapsed or not, so it would be straight-\nforward to experiment with different representations of the same model.\nIt is also possible to mix our method with VBEM, for example using our method for\nany non-conjugate parts of the model and VBEM for variables that happen to be con-\nditionally conjugate. This is closely related to the non-conjugate variational message\npassing (NCVMP) algorithm of Knowles and Minka (2011) implemented in Infer.NET,\nwhich aims to fit non-conjugate models while maintaining the convenient message pass-\ning formalism. NCVMP only specifies how to perform the variational optimization, not\nhow to approximate required integrals: in Infer.NET where analytic expectations are\nnot available quadrature or secondary variational bounds are used, unlike the Monte\nCarlo approach proposed here. It is still an open question how these different methods\ncould best be combined into a joint framework.\nAcknowledgments\nTim Salimans wishes to acknowledge his advisors Richard Paap and Dennis Fok, as well as\nthe anonymous referees, for their substantial help in improving the paper. He thanks the\nNetherlands Organization for Scientific Research (NWO) for financially supporting this project.\nDAK thanks Wolfson College, Cambridge, Microsoft Research Cambridge, and the Center for\nCancer Systems Biology for funding."},{"page":35,"text":"T. Salimans and D. A. Knowles 871\nReferences\nAlbert, J. (2009). Bayesian Computation with R. Springer Science, New York. Second\nedition. 866\nAmari, S. (1997). \u201cNeural Learning in Structured Parameter Spaces - Natural Rieman-\nnian Gradient.\u201d In Advances in Neural Information Processing Systems, 127\u2013133.\nMIT Press. 842, 844\nAttias, H. (2000). \u201cA variational Bayesian framework for graphical models.\u201d In Ad-\nvances in Neural Information Processing Systems (NIPS) 12, 209\u2013215. 837\nBeal, M. J. and Ghahramani, Z. (2002). \u201cThe variational Bayesian EM algorithm for\nincomplete data: with application to scoring graphical model structures.\u201d In Bayesian\nStatistics 7: Proceedings of the 7th Valencia International Meeting, 453\u2013463. 839\n\u2014 (2006). \u201cVariational Bayesian learning of directed graphical models with hidden\nvariables.\u201d Bayesian Analysis, 1(4): 793\u2013832. 837\nBishop, C. M. (2006). Pattern recognition and machine learning, volume 1. Springer\nNew York. 840, 845\nBottou, L. (2010). \u201cLarge-Scale Machine Learning with Stochastic Gradient Descent.\u201d\nIn Proceedings of the 19th International Conference on Computational Statistics\n(COMPSTAT\u20192010), 177\u2013187. Springer. 858\nde Freitas, N., H\u00f8jen-S\u00f8rensen, P., Jordan, M. I., and Russell, S. (2001). \u201cVariational\nMCMC.\u201d In Proceedings of the Seventeenth Conference on Uncertainty in Artificial\nIntelligence, UAI\u201901, 120\u2013127. San Francisco, CA, USA: Morgan Kaufmann Publish-\ners Inc.\nURL http:\/\/dl.acm.org\/citation.cfm?id=2074022.2074038 876\nDurbin, J. and Koopman, S. (2001). Time Series Analysis by State Space Methods.\nOxford University Press. 862\nGeweke, J. (2005).\nInterscience. 847\nContemporary Bayesian Econometrics and Statistics.Wiley-\nGilks, W., Thomas, A., and Spiegelhalter, D. (1994). \u201cA language and program for\ncomplex Bayesian modelling.\u201d The Statistician, 169\u2013177. 869\nGirolami, M. and Calderhead, B. (2011). \u201cRiemann manifold Langevin and Hamiltonian\nMonte Carlo methods.\u201d Journal of the Royal Statistical Society: Series B (Statistical\nMethodology), 73(2): 123\u2013214. 860, 863\nHoffman, M., Blei, D., and Bach, F. (2010). \u201cOnline learning for latent Dirichlet allo-\ncation.\u201d Advances in Neural Information Processing Systems, 23. 858\nHoffman, M., Blei, D., Wang, C., and Paisley, J. (2012). \u201cStochastic Variational Infer-\nence.\u201d arXiv preprint arXiv:1206.7051. 843"},{"page":36,"text":"872VB through Stochastic Regression\nHonkela, A., Raiko, T., Kuusela, M., Tornio, M., and Karhunen, J. (2010). \u201cApproxi-\nmate Riemannian Conjugate Gradient Learning for Fixed-Form Variational Bayes.\u201d\nJournal of Machine Learning Research, 3235\u20133268. 837, 839, 843, 876\nHoogerheide, L., Opschoor, A., and van Dijk, H. K. (2012).\nimportance sampling weighted {EM} algorithms for efficient and robust posterior\nand predictive simulation.\u201d Journal of Econometrics, 171(2): 101 \u2013 120.\nURL\nhttp:\/\/www.sciencedirect.com\/science\/article\/pii\/\nS0304407612001583 860\n\u201cA class of adaptive\nJordan, M., Ghahramani, Z., Jaakkola, T., and Saul, L. (1999). \u201cAn introduction to\nvariational methods for graphical models.\u201d Machine learning, 37(2): 183\u2013233. 837\nKim, S., Shephard, N., and Chib, S. (1998). \u201cStochastic Volatility: Likelihood Inference\nand Comparison with ARCH Models.\u201d The Review of Economic Studies, 65(3): pp.\n361\u2013393. 860\nKnowles, D. A. and Minka, T. P. (2011). \u201cNon-conjugate Variational Message Pass-\ning for Multinomial and Binary Regression.\u201d In Advances in Neural Information\nProcessing Systems (NIPS), 25. 870, 876\nLiesenfeld, R. and Richard, J.-F. (2008). \u201cImproving MCMC, using efficient importance\nsampling.\u201d Computational Statistics and Data Analysis, 53(2): 272 \u2013 288. 863\nLovell, M. (2008). \u201cA Simple Proof of the FWL Theorem.\u201d The Journal of Economic\nEducation, 39(1): 88\u201391. 853\nMinka, T. (2005). \u201cDivergence measures and message passing.\u201d Technical Report MSR-\nTR-2005-173, Microsoft Research. 845, 876\nMinka, T. P. (2001). \u201cA family of algorithms for approximate Bayesian inference.\u201d\nPh.D. thesis, MIT. 849, 855\nMinka, T. P., Winn, J. M., Guiver, J. P., and Knowles, D. A. (2010). \u201cInfer.NET 2.4.\u201d\n849, 869\nNemirovski, A., Juditsky, A., Lan, G., and Shapiro, A. (2009). \u201cRobust Stochastic Ap-\nproximation Approach to Stochastic Programming.\u201d SIAM Journal on Optimization,\n19(4): 1574\u20131609. 844\nNickisch, H. and Rasmussen, C. E. (2008). \u201cApproximations for Binary Gaussian Pro-\ncess Classification.\u201d Journal of Machine Learning Research, 9: 2035\u20132078. 849, 876\nNott, D., Tan, S., Villani, M., and Kohn, R. (2012). \u201cRegression density estimation\nwith variational methods and stochastic approximation.\u201d Journal of Computational\nand Graphical Statistics, 21(3): 797\u2013820. 838\nOpper, M. and Archambeau, C. (2009). \u201cThe Variational Gaussian Approximation\nRevisited.\u201d Neural Computation, 21(3): 786\u2013792. 855"},{"page":37,"text":"T. Salimans and D. A. Knowles 873\nOrmerod, J. T. and Wand, M. P. (2010). \u201cExplaining Variational Approximations.\u201d\nThe American Statistician, 64(2): 140\u2013153. 849, 850\nPaisley, J., Blei, D., and Jordan, M. (2012).\nStochastic Search.\u201d In International Conference on Machine Learning 2012. 838\n\u201cVariational Bayesian Inference with\nPorteous, I., Newman, D., Ihler, A., Asuncion, A., Smyth, P., and Welling, M. (2008).\n\u201cFast collapsed Gibbs sampling for latent Dirichlet allocation.\u201d In Proceedings of\nthe 14th ACM SIGKDD International Conference on Knowledge Discovery and Data\nMining, 569\u2013577. 870\nRichard, J.-F. and Zhang, W. (2007). \u201cEfficient high-dimensional importance sampling.\u201d\nJournal of Econometrics, 141(2): 1385 \u2013 1411. 841, 863, 875, 876\nRobbins, H. and Monro, S. (1951). \u201cA Stochastic Approximation Method.\u201d The Annals\nof Mathematical Statistics, 22(3): 400\u2013407. 842, 844\nSaul, L. and Jordan, M. (1996).\nnetworks.\u201d Advances in Neural Information Processing Systems, 486\u2013492. 839\n\u201cExploiting tractable substructures in intractable\nStern, D. H., Herbrich, R., and Graepel, T. (2009). \u201cMatchbox: large scale online\nBayesian recommendations.\u201d In Proceedings of the 18th International Conference on\nWorld Wide Web, 111\u2013120. 845\nStorkey, A. J. (2000). \u201cDynamic Trees: A Structured Variational Method Giving Ef-\nficient Propagation Rules.\u201d In Conference on Uncertainty in Artificial Intelligence\n(UAI). 839\nTeh, Y., Newman, D., and Welling, M. (2006). \u201cA collapsed variational Bayesian in-\nference algorithm for latent Dirichlet allocation.\u201d Advances in Neural Information\nProcessing Systems, 19: 1353\u20131360. 870, 876\nTurner, R. E., Berkes, P., and Sahani, M. (2008). \u201cTwo problems with variational\nexpectation maximisation for time-series models.\u201d In Proceedings of the Workshop\non Inference and Estimation in Probabilistic Time-Series Models, 107\u2013115. 839, 876\nWainwright, M. J. and Jordan, M. I. (2008). \u201cGraphical models, exponential families,\nand variational inference.\u201d Foundations and Trends\u00ae in Machine Learning, 1(1-2):\n1\u2013305. 837, 851\nWinn, J. and Bishop, C. M. (2006). \u201cVariational message passing.\u201d Journal of Machine\nLearning Research, 6(1): 661. 849"},{"page":38,"text":"874VB through Stochastic Regression\nAppendix A: Unnormalized to normalized optimality con-\ndition\nThe unnormalized optimality condition in (8) is\n\u02dc \u03b7 =\n\u201e?\n\u02dc q\u02dc \u03b7(x)\u02dcT(x)?\u02dcT(x)d\u03bd(x)\n\uf6be\u22121\u201e?\n\u02dc q\u02dc \u03b7(x)\u02dcT(x)?logp(x,y)d\u03bd(x)\n\uf6be\n.(46)\nClearly we can replace \u02dc q(x) by its normalized version q(x) = \u02dc q(x)\/exp[U(\u03b7)] since the\nnormalizing terms will cancel. Recalling\u02dcT(x) = (1,T(x)) and \u02dc \u03b7 = (\u03b70,\u03b7?)?we then have\n\u201e\nwhere Y := logp(x,y). Rearranging gives\n\u02c6\nSolving for \u03b70easily gives\n1\nE[T]\nE[T?T]\nE[T?]\n\uf6be\u22121\u02c6\nE[Y ]\nE[T?Y ]\n\u02d9\n=\n\u02c6\n\u03b70\n\u03b7\n\u02d9\n,(47)\nE[Y ]\nE[T?Y ]\n\u02d9\n=\n\u201e\n1\nE[T]\nE[T?T]\nE[T?]\n\uf6be\u02c6\n\u03b70\n\u03b7\n\u02d9\n.(48)\n\u03b70= E[Y ] \u2212 E[T]\u03b7 = E[logp(x,y) \u2212 logq(x)] \u2212 U(\u03b7)\n\u03b7 = pE[T?T] \u2212 E[T?]E[T]q\u22121(E[T?Y ] \u2212 E[T?]E[Y ])\n= Cov(T,T)\u22121Cov(T,Y ).\n(49)\n(50)\n(51)\nAppendix B: Derivation of Gaussian variational approxima-\ntion\nFor notational simplicity we will derive our stochastic approximation algorithm for\nGaussian variational approximation (Algorithm 2) under the assumption that x is uni-\nvariate. The extension to multivariate x is conceptually straightforward but much more\ntedious in terms of notation.\nLet p(x,y) be the unnormalized posterior distribution of a univariate random variable\nx, and let q(x) = N(m,V ) be its Gaussian approximation with sufficient statistics,\nT(x) = (x,\u22120.5x2). In order to find the mean m and variance V that minimize the\nKL-divergence between q(x) and p(x|y) we solve the transformed regression problem\ndefined in (30), i.e.\n\u03b7 =\u201cK(\u03b7)Covq\u03b7(T(x),T(x))\u2030\u22121\u201cK(\u03b7)Covq\u03b7(T(x),logp(x,y))\u2030\n= C\u22121g\nwhere\nK(\u03b7) = [\u2207\u03b7\u03c6(\u03b7)]\u22121,"},{"page":39,"text":"T. Salimans and D. A. Knowles 875\nwith \u03c6 = (\u03c61,\u03c62) = (m,V ) the usual mean-variance parameterization and where the\nnatural parameters are given by \u03b7 = (V\u22121m,V\u22121). Recall identity (28) which states\nthat\n\u2207\u03c61Eq\u03c6[h(x)] = Eq\u03c6[\u2207xh(x)],\nwith \u03c61= m the first element of the parameter vector \u03c6, and g(x) any differentiable\nfunction. Similarly, identity (29) reads\n\u2207\u03c62Eq\u03c6[h(x)] = \u22121\n2Eq\u03c6[\u2207x\u2207xh(x)],\nwith \u03c62= V the second element of the parameter vector. Using these identities we find\nthat the regression statistics for this optimization problem are given by\nC := K(\u03b7)Covq\u03c6[T(x),T(x)] = \u2207\u03c6Eq\u03c6[T(x)]\n= Eq\u03c6[\u2207xT(x)] = Eq\u03c6\n\u201e1\n\u2212x\n1\n2\n0\n\uf6be\n=\n\u201e1\n\u2212Eq\u03c6[x]\n1\n2\n0\n\uf6be\n,\nand\ng := K(\u03b7)Covq\u03c6[T(x),logp(x,y)]\n= \u2207\u03c6Eq\u03c6[logp(x,y)]\n\uf6be\n\u21d2\n\u201eg1\ng2\n=\n\u201e\nEq[\u2207xlogp(x,y)]\n2Eq[\u2207x\u2207xlogp(x,y)]\n\u22121\n\uf6be\n.\nNow since \u03b7 = C\u22121g we have\n\u201ePm\n\u21d2 \u03b72= P = 2g2= \u2212Eq[\u2207x\u2207xlogp(x,y)]\n\u03b71= Pm = g1+ P\u22121Eq[x] = Eq[\u2207xlogp(x,y)] + P\u22121Eq[x]\nwhere Pm and P = V\u22121are the natural parameters (mean times precision and preci-\nsion) of the approximation. Thus the quantities we need to stochastically approximate\nare\nP\n\uf6be\n:=\n\u201e\u03b71\n\u03b72\n\uf6be\n=\n\u201e1\n\u2212Eq\u03c6[x]\n1\n2\n0\n\uf6be\u22121\u201eg1\ng2\n\uf6be\na := Eq[\u2207xlogp(x,y)]\nH := Eq[\u2207x\u2207xlogp(x,y)]\nz := Eq[x]\nso we have P = \u2212H and m = P\u22121a + z.\nAppendix C: Connection to Efficient Importance Sampling\nIt is worth pointing out the connection between fixed-form variational Bayes and Richard\nand Zhang\u2019s (2007) Efficient Importance Sampling (EIS) algorithm. Although these"},{"page":40,"text":"876VB through Stochastic Regression\nauthors take a different perspective (that of importance sampling) their goal of ap-\nproximating the intractable posterior distribution with a more convenient distribution\nis shared with variational Bayes. Specifically, Richard and Zhang (2007) choose their\nposterior approximation to minimize the variance of the log-weights of the resulting im-\nportance sampler. This leads to an optimization problem obeying a similar fixed-point\ncondition as in (9), but with the expectation taken over p(x|y) instead of q(x). Since\nsampling from p(x|y) directly is not possible, they evaluate this expectation by sampling\nfrom q(x) and weighting the samples using importance sampling. In practice however,\nthese \u2018weights\u2019 are often kept fixed to one during the optimization process in order to\nimprove the stability of the algorithm. When all weights are fixed to one, Richard and\nZhang\u2019s (2007) fixed-point condition becomes identical to that of (9) and the algorithm\nis in fact fitting a variational posterior approximation.\nThe connection between EIS and variational Bayes seems to have gone unnoticed until\nnow, but it has some important consequences. It is for example well known (e.g. Minka\n2005; Nickisch and Rasmussen 2008; Turner et al. 2008) that the tails of variational\nposterior approximations tend to be thinner than those of the actual posterior unless\nthe approximation is extremely close, which means that using EIS with the importance-\nweights fixed to one is not to be recommended for general applications: In the case that\nthe posterior approximation is nearly exact, one might as well use it directly instead of\nusing it to form another approximation using importance sampling. In cases where the\napproximation is not very close, the resulting importance sampling algorithm is likely to\nsuffer from infinite variance problems. The literature on variational Bayes offers some\nhelp with these problems. Specifically, de Freitas et al. (2001) propose a number of ways\nin which variational approximations can be combined with Monte Carlo methods, while\nguarding for the aforementioned problems.\nMuch of the recent literature (e.g. Teh et al. 2006; Honkela et al. 2010) has focused\non the computational and algorithmic aspects of fitting variational posterior approx-\nimations, and this work might also be useful in the context of importance sampling.\nAlgorithmically, the \u2018sequential EIS\u2019 approach of Richard and Zhang (2007) is most\nsimilar to the non-conjugate VMP algorithm of Knowles and Minka (2011). As these\nauthors discuss, such an algorithm is not guaranteed to converge, and they present some\ntricks that might be used to improve convergence in some difficult cases.\nThe algorithm presented in this paper for fitting variational approximations is provably\nconvergent, as discussed in Section 4. Furthermore, Sections 5 and 6 present multi-\nple new strategies for variance reduction and computational speed-up that might also\nbe useful for importance sampling. In this paper we will not pursue the application\nof importance sampling any further, but exploring these connections more fully is a\npromising direction for future work."},{"page":41,"text":"T. Salimans and D. A. Knowles877\nAppendix D: Choosing an estimator\nAs discussed in Section 4, the particular estimator used in our stochastic approximation\nis not the most obvious choice, but it seems to provide a lower variance approxima-\ntion than other choices. In this section we consider three different MC estimators for\napproximating (9) to see why this might be the case.\nThe first separately approximates the two integrals and then calculates the ratio:\n\u02dc\nS\nr\nS\ns\n\u02c6 \u03b71=\n1\n?\n\u02dcT(xr)?\u02dcT(xr)\n\u00b8\u22121\n1\n?\n\u02dcT(xs)?logp(xs,y),xr,xs\u223ciidq(x),(52)\nwith S the number of Monte Carlo samples. The second approximates both integrals\nusing the same samples from q:\n\u02dc\nS\ns\nS\ns\n\u02c6 \u03b72=\n1\n?\n\u02dcT(xs)?\u02dcT(xs)\n\u00b8\u22121\n1\n?\n\u02dcT(xs)?logp(xs,y),xs\u223ciidq(x).(53)\nOnly this estimator is directly analogous to the linear regression estimator. The third\nestimator is available only when the first expectation is available analytically:\n\u201d\u02dcT(x)?\u02dcT(x)\nWe wish to understand the bias\/variance tradeoff inherent in each of these estimators.\nTo keep notation manageable consider the case with only k = 1 sufficient statistic1and\nlet\n\u02c6 \u03b7a= Eq\n\u0131\u221211\nS\n?\ns\n\u02dcT(xs)?logp(xs,y),xs\u223ciidq(x).(54)\na(x) =\u02dcT(x)?\u02dcT(x) =\u02dcT(x)2\nb(x) =\u02dcT(x)logp(x,y).\n(55)\n(56)\nWe can now write the three estimators of \u03b7 more concisely as\n?\nS\n1\nS\n1\nS\n1\nS\nE[a]\n\u02c6 \u03b71=\n1\nS\n1\nrb(xr)\nsa(xs),\n?\n?\n?\n?\nxr,xs\u223ciidq(x) (57)\n\u02c6 \u03b72=\nsb(xs)\nsa(xs),xs\u223ciidq(x) (58)\n\u02c6 \u03b7a=\nsb(xs)\n,xs\u223ciidq(x).(59)\nUsing a simple Taylor series argument it is straightforward to approximate the bias\nand variance of these estimators. We first consider the bias. Consider the multivariate\nTaylor expansion of f : RK\u2192 R around the point \u00af y \u2208 RK:\nf(y) \u2248 f(\u00af y) + (y \u2212 \u00af y)?f?(\u00af y) +1\n2tr((y \u2212 \u00af y)(y \u2212 \u00af y)?\u22072f(\u00af y)).(60)\n1These results extend in a straightforward manner to the case where k > 1."},{"page":42,"text":"878VB through Stochastic Regression\nFrom this we can derive expressions for the expectation of f(y):\nE[f] \u2248 f(\u00af y) +1\n2tr(Cov(y)f??(\u00af y))(61)\nwhere we have chosen to perform the Taylor expansion around the mean \u00af y = E[y]. For\nthe first estimator let y =1\nS\n\u00bb\nS\ns\n\u02c6\n= \u03b7 +Var(a)E[b]\nSE[a]3\n?\nsa(xs) and f(y) = 1\/y, then we find\n\u02dc\nE[\u02c6 \u03b71] = E\n\u2013\nE[a]+Var(a)\n1\n?\na(xs)\n\u00b8\u22121fi\n\u02d9\nflE[b]\nE[b]\n(62)\n\u2248\n1\nSE[a]3\n(63)\n(64)\nsince Var(y) = Var(a)\/S. We see that the bias term depends on the ratio Var(a)\/E[a]2,\ni.e. the spread of the distribution of a relative to its magnitude.\nNow for the second estimator let\ny =\n\u201e\n1\nS\n1\nS\n?\nsa(xs)\n?\nSCov([a,b]?) and\nsb(xs)\n\uf6be\n(65)\nso that \u03b72= f(y) =y2\ny1. Note that Cov(y) =1\n\u22072f(y) =\n\u00ab\n2y2\ny3\n\u22121\n1\n\u22121\n0\ny2\n1\ny2\n1\nff\n.(66)\nPutting everything together we have\nE[\u02c6 \u03b72] \u2248 \u03b7 +Var(a)Eb\nSE[a]3\n\u2212Cov(a,b)\nSE[a]2. (67)\nNote that we recover the expression for E\u02c6 \u03b71if Cov(a,b) = 0, which makes sense because\nif we use different randomness for calculating E[a] and E[b] then a,b have 0 covariance\nin our MC estimate. Finally the analytic estimator is unbiased:\nE\u02c6 \u03b7a= \u03b7. (68)\nWe now turn to the variances. The analytic estimator is a standard MC estimator with\nvariance\nVar(\u02c6 \u03b7a) =Var(b)\nSE[a]2. (69)\nConsider only the linear terms of the Taylor expansion:\nf(y) \u2248 f(\u00af y) + (y \u2212 \u00af y)?f?(\u00af y).(70)"},{"page":43,"text":"T. Salimans and D. A. Knowles879\nSubstituting this into the formula for variance gives\nVar[f(y)] = E[(f(y) \u2212 E[f(y)])(f(y) \u2212 E[f(y)])?]\n\u2248 E[f?(\u00af y)?(y \u2212 \u00af y)(y \u2212 \u00af y)?f?(\u00af y)]\n= f?(\u00af y)?Var(y)f?(\u00af y).\n(71)\n(72)\n(73)\nWe will calculate the variance of the second estimator and derive the variance of the\nfirst estimator from this. Again let y be as in (65). Note that Var(y) = Cov(a,b)\/S.\nWe find\n\u02c6E[b]2Vara\nThe final term is equal to that for the analytic estimator. The second term is not present\nin the variance of the first estimator, since then a and b have no covariance under the\nsampling distribution, i.e.\n\u02c6E[b]2Vara\nThe first term is always positive, suggesting that \u02c6 \u03b71is dominated by the analytic esti-\nmator.\nVar \u02c6 \u03b72\u22481\nS\nE[a]4\n\u2212 2E[b]Cov(a,b)\nE[a]3\n+Varb\nE[a]2\n\u02d9\n.(74)\nVar \u02c6 \u03b71\u22481\nS\nE[a]4\n+Varb\nE[a]2\n\u02d9\n.(75)\nSummarizing these derivations, we have\nbias(\u02c6 \u03b71)\n\u2248\nVar(a)E[b]\nSE[a]3\nVar(a)E[b]\nSE[a]3\nbias(\u02c6 \u03b72)\n\u2248\u2212Cov(a,b)\nSE[a]2.(76)\nNote that the first term is shared, but the first estimator does not have the covariance\nterm as a result of the independent sampling in approximating the numerator and\ndenominator. In contrast \u02c6 \u03b7ais unbiased. Now consider the variances\n\u02c6E[b]2Var(a)\nVar(\u02c6 \u03b72) \u22481\nS\nE[a]4\nVar(\u02c6 \u03b7a) =Var(b)\nSE[a]2.\nVar(\u02c6 \u03b71) \u22481\nS\nE[a]4\n+Var(b)\nE[a]2\n\u2212 2E[b]Cov(a,b)\nE[a]3\n\u02d9\n(77)\n\u02c6E[b]2Var(a)\n+Var(b)\nE[a]2\n\u02d9\n(78)\n(79)\nAll three estimators have the same final term (the variance of the \u201canalytic\u201d estimator).\nAgain the second estimator has an additional term resulting from the covariance between\na and b which we find is typically beneficial in that it results in the variance of \u02c6 \u03b7 being\nsignificantly smaller. It is worth recalling that the mean squared error (MSE) of an\nestimator is given by\nE[(\u03b7 \u2212 \u02c6 \u03b7)2] = Var(\u02c6 \u03b7) + bias(\u02c6 \u03b7)2.(80)"},{"page":44,"text":"880VB through Stochastic Regression\nSince both the variance and bias are O(1\/S), the variance contribution to the MSE is\nO(1\/S) whereas the bias contribution is O(1\/S2), so the variance is actually a greater\nproblem than the bias. From these expressions it is still not immediately obvious which\nestimator we should use. However, consider the case when the target distribution p is\nin the same exponential family as q, i.e. when logp(x,y) =\u02dcT(x)\u03bb. It is then straight-\nforward to show that\nbias(\u02c6 \u03b71) \u2248\u03bbVar(\u02dcT2)\nSE[\u02dcT2]2,Var(\u02c6 \u03b71) \u2248 2\u03bb2Var(\u02dcT2)\nSE[\u02dcT2]2\nVar(\u02c6 \u03b72) \u2248 0\n(81)\nbias(\u02c6 \u03b72) \u2248 0,(82)\nbias(\u02c6 \u03b7a) = 0,Var(\u02c6 \u03b7a) =\u03bb2Var(\u02dcT2)\nSE[\u02dcT2]2\n.(83)\nWe see that in this case for \u02c6 \u03b72the positive and negative contributions to both the bias\nand variance cancel. While this result will not hold exactly for cases of interest, it\nsuggests that for exponential families which are capable of approximating p reasonably\nwell, \u02c6 \u03b72should perform significantly better than \u02c6 \u03b71or even \u02c6 \u03b7a. If q and p are of the\nsame exponential family, it is actually possible to see that \u02c6 \u03b72will in fact give the exact\nsolution in k + 1 samples (with k the number of sufficient statistics), while the other\nestimators have non-vanishing variance for a finite number of samples. This means that\nthe approximate equality in (82) can be replaced by exact equality. Using k+1 samples\nxi,i = 1,...,k + 1, assumed to be unique (which holds almost surely for continuous\ndistributions q), we have\n\u02c6 \u03b72=\n\u02dck+1\ni=1\n?\n\u02dcT(xi)?\u02dcT(xi)\n\u00b8\u22121k+1\n?\ni=1\n\u02dcT(xi)?\u02dcT(xi)\u03bb = \u03bb.(84)\nThat is, the algorithm has recovered p(x,y) exactly with probability one. If we assume\nwe know how to normalize q, this means we also have p(x|y) exactly in this case.\nNote that we recover the exact answer here because the p(x,y) function evaluations\nare in themselves noise free, so the regression analogy really corresponds to a noise free\nregression.\nWe test the three estimators in (52), (53) and (54) on the trivial exponential example\nof Section 4 when the true exponential rate is \u03bb = 1.5, and sampling from the optimal\nq distribution with \u03b7 = 1.5. The results confirm that \u02c6 \u03b72finds the exact rate using just\nS = 2 MC samples, as predicted by (84). We would expect \u02c6 \u03b7ato be unbiased, and this\nis borne out by the results shown in Figure 8. The estimator \u02c6 \u03b71 has both poor bias\nand such large variance that it often gives an invalid negative rate if fewer than 10 MC\nsamples are used. While this is clearly a very simple example it hopefully emphasizes\nthe potential benefit to be gained from using estimators related to \u02c6 \u03b72."},{"page":45,"text":"T. Salimans and D. A. Knowles881\n10\n0\n10\n1\n10\n2\n10\n3\n10\n4\n10\n\u22124\n10\n\u22122\n10\n0\n10\n2\n10\n4\n10\n6\n10\n8\n# samples\nestimate\n \n \neta 1\neta 2\neta analytic\nFigure 8: Comparison of three estimators for fitting a variational posterior q to a simple\nexponential distribution p. 50 repeats were used to estimate the mean and variance of\nthe estimator: the thick line shows the mean and the thin lines show \u00b1 one standard\ndeviation. The x-axis indicates the number of MC samples, S, used. As expected in\nthis case \u02c6 \u03b72gives the correct solution of 1.5 using S \u2265 2 samples."},{"page":46,"text":"882VB through Stochastic Regression"}],"fullTextUrl":"https:\/\/www.researchgate.net\/profile\/Tim_Salimans\/publication\/228083473_Fixed-Form_Variational_Posterior_Approximation_through_Stochastic_Linear_Regression\/links\/5486e7290cf268d28f062892.pdf","widgetId":"rgw27_56ab9eee9ebe9"},"id":"rgw27_56ab9eee9ebe9","partials":[],"templateName":"publicliterature\/stubs\/PublicationText.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationText.html?publicationUid=228083473&hide=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationDetailAd":{"data":{"googleDfpSlot":null,"widgetId":"rgw28_56ab9eee9ebe9"},"id":"rgw28_56ab9eee9ebe9","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAd.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAd.html?publicationUid=228083473&slotId=336x280_Publications_ATF_Right&collapseSlotMode=never&fallbackContainerEnabled=1","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationRelations":null,"publicationRelationsReverse":null,"publicationUid":228083473,"showSignUpDialog":false,"selectNewSignUpDialog":false,"publicationQuestions":null,"publicationCitations":null,"publicationReviewPromo":null,"publicationUsedInReviews":null,"publicationPdfJsReader":{"data":{"isPreview":false,"licenseUrl":null,"licenseInfo":null,"defaultLinkData":{"linkId":"5486e7290cf268d28f062892","name":"Tim Salimans","date":"Dec 09, 2014 ","nameLink":"profile\/Tim_Salimans","filename":"euclid.ba.1386166315.pdf","downloadLink":"https:\/\/www.researchgate.net\/profile\/Tim_Salimans\/publication\/228083473_Fixed-Form_Variational_Posterior_Approximation_through_Stochastic_Linear_Regression\/links\/5486e7290cf268d28f062892.pdf?inViewer=0&pdfJsDownload=0&origin=publication_detail","viewerUrl":"https:\/\/www.researchgate.net\/profile\/Tim_Salimans\/publication\/228083473_Fixed-Form_Variational_Posterior_Approximation_through_Stochastic_Linear_Regression\/links\/5486e7290cf268d28f062892.pdf?inViewer=1&pdfJsDownload=1&origin=publication_detail","downloadHash":"de0c096904c4b25d8294e4eaead550a5","showFileSizeNote":false,"fileSize":"585.68 KB","noFollow":false,"isDefault":true,"doi":null},"displayableLinks":[{"linkId":"5486e7290cf268d28f062892","name":"Tim Salimans","date":"Dec 09, 2014 ","nameLink":"profile\/Tim_Salimans","filename":"euclid.ba.1386166315.pdf","downloadLink":"https:\/\/www.researchgate.net\/profile\/Tim_Salimans\/publication\/228083473_Fixed-Form_Variational_Posterior_Approximation_through_Stochastic_Linear_Regression\/links\/5486e7290cf268d28f062892.pdf?inViewer=0&pdfJsDownload=0&origin=publication_detail","viewerUrl":"https:\/\/www.researchgate.net\/profile\/Tim_Salimans\/publication\/228083473_Fixed-Form_Variational_Posterior_Approximation_through_Stochastic_Linear_Regression\/links\/5486e7290cf268d28f062892.pdf?inViewer=1&pdfJsDownload=1&origin=publication_detail","downloadHash":"de0c096904c4b25d8294e4eaead550a5","showFileSizeNote":false,"fileSize":"585.68 KB","noFollow":false,"isDefault":true,"doi":null},{"linkId":"544f7c230cf26dda089103c3","name":"Tim Salimans","date":"Oct 28, 2014 ","nameLink":"profile\/Tim_Salimans","filename":"","downloadLink":"https:\/\/www.researchgate.net\/profile\/Tim_Salimans\/publication\/228083473_Fixed-Form_Variational_Posterior_Approximation_through_Stochastic_Linear_Regression\/links\/544f7c230cf26dda089103c3.pdf?inViewer=0&pdfJsDownload=0&origin=publication_detail","viewerUrl":"https:\/\/www.researchgate.net\/profile\/Tim_Salimans\/publication\/228083473_Fixed-Form_Variational_Posterior_Approximation_through_Stochastic_Linear_Regression\/links\/544f7c230cf26dda089103c3.pdf?inViewer=1&pdfJsDownload=1&origin=publication_detail","downloadHash":"04724e639aa5175343ffb84936975ea9","showFileSizeNote":false,"fileSize":"585.84 KB","noFollow":false,"isDefault":false,"doi":null}],"hasDisplayableLinks":true,"reader":{"data":{"pdfCommentsActive":false,"publicationType":"Article","onlyRenderFirstPage":false,"readMoreExperimentGoal":"goalPublicationPdfClicksReadMore","readMoreExperimentViewId":null,"comments":null,"figures":[],"figureAssetIds":[],"figureOverlayUrls":{"clickOnOverlay":"publication.PublicationFigures.html?_sg=pwNJg6LZowoEP44bUx01xSqUMygrgZLf1cnMWG3EMQJJDWPJRJESdNbUyl0o_ssMXI0fwTT8kpFjQuLVnDyJAw.ny432Av5_STLrg7RZ8OUsvxtxy1DONE2_vIBEp_zP2xF21SsX4HQObEE5dAUKAkNkcZ672zOmSk5yzURhQ8G8A","clickOnPill":"publication.PublicationFigures.html?_sg=X27emNVkeufrcOWM-vfqPEO7ni-Ar9YSr-zW9wF7sZiYNmKwmL5uoDZ3hCn0_YxPY66hDnpj7GYFlxSO1gdruA.Ijza5S5PFvhGSTy0HJFpJECWnKC3PEHgybzRY8A0xkMXp6qiBPsSb73fM43m-bB-FNrnm965PKEL1amN9QGLHw"},"canSelect":false,"javascriptPath":"https:\/\/www.researchgate.net\/c\/o1q2er\/","downloadUrl":"https%3A%2F%2Fwww.researchgate.net%2Fprofile%2FTim_Salimans%2Fpublication%2F228083473_Fixed-Form_Variational_Posterior_Approximation_through_Stochastic_Linear_Regression%2Flinks%2F5486e7290cf268d28f062892.pdf%3FinViewer%3D1%26pdfJsDownload%3D1%26origin%3Dpublication_detail","viewerUrl":"https:\/\/www.researchgate.net\/c\/o1q2er\/javascript\/lib\/pdfjs\/web\/viewer.html","commentEndpoint":"https:\/\/www.researchgate.net\/rgformat\/api\/comment","experimentEndpoint":"https:\/\/www.researchgate.net\/rgformat\/api\/experiment?key=YwONsFqJZ9bljDPaiPJMbGV1JPjzDMJXpHlzstYM1qmEJxksDRtM4fbSnsZXb45ThedJYdi5R5kszk-0GIE23g","urlHash":"a0e18df35ae77e1cd5ed3403cf97056b","downloadTrackUrl":"application.PdfJsReader.ajaxTrackDownload.html?msrp=YPI28lIHu3j6wXrW9MvHIoXjn5rC2bLyekeKWUFXJgyIJQk2MIlJGXRMCfZkZ1f93pnhdh4uZ--heb88xTlsn_eEgDfP-qkQ3H59HKt2l-o.f_JPXI5Mzt3wRHYZXujlgvJSCRKKfpgDmS-1Wg3gptKIPg_9Dg7CPCUrdxJsrllSTCCFfWlTWoBQ21wkmj_rXw.q0f5KeYH8vKz6jY67nS_GAhuii1729_g_Ar52eClc8zmI-qR532wacp64GJe9s5GzhSDOllepSEcDupL25cAqQ","viewportMilestoneTrackUrl":"application.PdfJsReader.ajaxTrackViewportMilestone.html","linkId":"5486e7290cf268d28f062892","trackedDownloads":{"5486e7290cf268d28f062892":{"v":false,"d":false}},"assetId":"AS:172451900174336@1418127145104","readerDocId":null,"assetType":"fulltext","interactionType":{"comment":"comment","highlight":"highlight"},"publicationUid":228083473,"commentCursorPromo":null,"widgetId":"rgw30_56ab9eee9ebe9"},"id":"rgw30_56ab9eee9ebe9","partials":[],"templateName":"application\/stubs\/PdfJsReader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PdfJsReader.html?fileHref=https%3A%2F%2Fwww.researchgate.net%2Fprofile%2FTim_Salimans%2Fpublication%2F228083473_Fixed-Form_Variational_Posterior_Approximation_through_Stochastic_Linear_Regression%2Flinks%2F5486e7290cf268d28f062892.pdf%3FinViewer%3D1%26pdfJsDownload%3D1%26origin%3Dpublication_detail&assetId=AS%3A172451900174336%401418127145104&publicationUid=228083473&linkId=5486e7290cf268d28f062892&onlyShowFirstPage=0","viewClass":null,"yuiModules":["css-pow-application-PdfJsReader"],"stylesheets":["pow\/application\/PdfJsReader.css"],"_isYUI":true},"showHeader":true,"title":"Fixed-Form Variational Posterior Approximation through Stochastic Linear Regression","publicationType":"Article","downloadTrackUrl":"publicliterature.PublicationInlineReader.ajaxTrackDownload.html?msrp=ggR3dp0QRjV5ULJpYMioqtnVG-rj0fv0PdVPXj043zC9p0o5sykzUD-A_miilM1Uo9Wng8o_Z87-oxMWaFqFBuoFytjXwThh073p9JhW7iQ.mHod7HcKAV517KG-6F5r2dnbds7526U0n5OLh61y4stf8ixxzD9Y_HzDzLw1uM8x7fbsJAig6nEHzu1Z-1aT_Q.DovPNAjLu5Etqkr2MflExmY72EU82bJFvR5mXE09FDLptoBQAL4JGjCtwu5QvFgynW6Tlz7vBW_S7js1mHsrSQ","publicationUid":228083473,"trackedDownloads":{"5486e7290cf268d28f062892":{"v":false,"d":false},"544f7c230cf26dda089103c3":{"v":false,"d":false}},"inlinePdf":false,"publicationComments":null,"showDownloadButton":true,"socialShare":{"data":{"shareItems":[{"data":{"name":"Facebook","url":"http:\/\/www.facebook.com\/share.php?u={{url}}{{#title}}&t={{title}}{{\/title}}","width":600,"height":350,"useUtmTags":true,"utmSource":"facebook","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareFacebook.ajaxTrackSocialShare.html","widgetId":"rgw32_56ab9eee9ebe9"},"id":"rgw32_56ab9eee9ebe9","partials":{"shareIcon":"application\/stubs\/partials\/shareFacebookBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareFacebook.html?provider=Facebook&shareIcon=shareIconBlog&utmSource=facebook&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"Twitter","url":"http:\/\/twitter.com\/intent\/tweet?text={{#title}}{{title}}: {{\/title}}{{url}}&via=researchgate","width":600,"height":350,"useUtmTags":true,"utmSource":"twitter","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareTwitter.ajaxTrackSocialShare.html","widgetId":"rgw33_56ab9eee9ebe9"},"id":"rgw33_56ab9eee9ebe9","partials":{"shareIcon":"application\/stubs\/partials\/shareTwitterBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareTwitter.html?provider=Twitter&shareIcon=shareIconBlog&utmSource=twitter&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"Google+","url":"https:\/\/plus.google.com\/share?url={{url}}","width":600,"height":600,"useUtmTags":true,"utmSource":"googleplus","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareGooglePlus.ajaxTrackSocialShare.html","widgetId":"rgw34_56ab9eee9ebe9"},"id":"rgw34_56ab9eee9ebe9","partials":{"shareIcon":"application\/stubs\/partials\/shareGooglePlusBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareGooglePlus.html?provider=Google%2B&shareIcon=shareIconBlog&utmSource=googleplus&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"LinkedIn","url":"http:\/\/www.linkedin.com\/shareArticle?mini=true&url={{url}}{{#title}}&title={{title}}{{\/title}}&source=ResearchGate","width":520,"height":570,"useUtmTags":true,"utmSource":"linkedin","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareLinkedIn.ajaxTrackSocialShare.html","widgetId":"rgw35_56ab9eee9ebe9"},"id":"rgw35_56ab9eee9ebe9","partials":{"shareIcon":"application\/stubs\/partials\/shareLinkedInBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareLinkedIn.html?provider=LinkedIn&shareIcon=shareIconBlog&utmSource=linkedin&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"Reddit","url":"https:\/\/www.reddit.com\/submit?url={{url}}{{#title}}&title={{title}}{{\/title}}","width":600,"height":600,"useUtmTags":true,"utmSource":"reddit","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareReddit.ajaxTrackSocialShare.html","widgetId":"rgw36_56ab9eee9ebe9"},"id":"rgw36_56ab9eee9ebe9","partials":{"shareIcon":"application\/stubs\/partials\/shareRedditBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareReddit.html?provider=Reddit&shareIcon=shareIconBlog&utmSource=reddit&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true}],"widgetId":"rgw31_56ab9eee9ebe9"},"id":"rgw31_56ab9eee9ebe9","partials":[],"templateName":"application\/stubs\/SocialShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.SocialShare.html?campaign=shareFullTextPublication&trackClick=1&shareIcon=shareIconBlog","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw29_56ab9eee9ebe9"},"id":"rgw29_56ab9eee9ebe9","partials":[],"templateName":"publicliterature\/stubs\/PublicationInlineReader.html","templateExtensions":["generalHelpers"],"attrs":{"showFulltextDownloadedSignupDialog":true,"preSignUpDialogContext":null,"requestFulltext":false},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationInlineReader.html","viewClass":"views.publicliterature.PublicationInlineReaderView","yuiModules":["rg.views.publicliterature.PublicationInlineReaderView","css-pow-publicliterature-PublicationInlineReader"],"stylesheets":["pow\/publicliterature\/PublicationInlineReader.css"],"_isYUI":true},"useFulltextOptimizedLayout":false,"publicationActions":null,"requestFulltextPromo":null,"currentUrl":"publication\/228083473_Fixed-Form_Variational_Posterior_Approximation_through_Stochastic_Linear_Regression","isLeaderboardAd":false,"enableStickyBox":null,"googleDfpSlotMobileBottom":null,"fullTextExitPopup":null,"showExitPopupDialog":false,"widgetId":"rgw2_56ab9eee9ebe9"},"id":"rgw2_56ab9eee9ebe9","partials":{"romeo_legal_notice":"publicliterature\/stubs\/partials\/romeo_legal_notice.html"},"templateName":"publicliterature\/stubs\/PublicPublicationDetails_NewLayout.html","templateExtensions":["generalHelpers"],"attrs":{"publicationUid":228083473},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicPublicationDetailsOld.html?publicationUid=228083473&isTestOldDesign=0","viewClass":"views.publicliterature.PublicPublicationDetailsOldView","yuiModules":["rg.views.publicliterature.PublicPublicationDetailsOldView"],"stylesheets":[],"_isYUI":true},"widgetId":"rgw1_56ab9eee9ebe9"},"id":"rgw1_56ab9eee9ebe9","partials":[],"templateName":"publicliterature\/stubs\/PublicPublicationDetails.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicPublicationDetails.html","viewClass":"views.publicliterature.PublicPublicationDetailsView","yuiModules":["rg.views.publicliterature.PublicPublicationDetailsView"],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"uaClass":"","headPrefix":[],"rootUrl":"https:\/\/www.researchgate.net\/","requestToken":"mUXJuJiCvW+btnynApBwxqH7B4l7FDkfhOtQpvoLMOA\/IQVzfq+6wjMmD3hwr6O1D8vGCAm\/65BCSiQPeNQCLXWlJ95XHOct\/fMkXLfMweRKruwi+Ain1W6FosyMy0qATV7XoYjYQaKgXZ+fyGePdm6Nst3yyA7nU1TZirPbl+sqvO+T8DVC9nZERd2pMkhqVnJif0SJ+XBBnOdaO6O5dwkx1YD7zLpayLUMH4ekWovNnhxvNplOt\/DwivDyMPdNYIwwXIrYcyJ\/cYruGX\/aly9JW+6pGUfNpt9R5DP8cqs=","faviconCdnUrl":"https:\/\/c5.rgstatic.net\/m\/2390829798215018\/images\/favicon.ico","headerOutput":"<noscript><\/noscript><link rel=\"canonical\" href=\"https:\/\/www.researchgate.net\/publication\/228083473_Fixed-Form_Variational_Posterior_Approximation_through_Stochastic_Linear_Regression\" \/>\n<link rel=\"dns-prefetch\" href=\"\/\/c5.rgstatic.net\" \/>\n<link rel=\"dns-prefetch\" href=\"\/\/i1.rgstatic.net\" \/>\n<meta property=\"twitter:card\" content=\"summary\" \/>\n<meta property=\"twitter:site\" content=\"@ResearchGate\" \/>\n<meta property=\"og:title\" content=\"Fixed-Form Variational Posterior Approximation through Stochastic Linear Regression\" \/>\n<meta property=\"og:description\" content=\"We propose a general algorithm for approximating nonstandard Bayesian\nposterior distributions. The algorithm minimizes the Kullback-Leibler\ndivergence of an approximating distribution to the...\" \/>\n<meta property=\"og:site_name\" content=\"ResearchGate\" \/>\n<meta property=\"og:image\" content=\"https:\/\/i1.rgstatic.net\/publication\/228083473_Fixed-Form_Variational_Posterior_Approximation_through_Stochastic_Linear_Regression\/links\/5486e7290cf268d28f062892\/smallpreview.png\" \/>\n<meta property=\"og:url\" content=\"https:\/\/www.researchgate.net\/publication\/228083473_Fixed-Form_Variational_Posterior_Approximation_through_Stochastic_Linear_Regression\" \/>\n<meta property=\"rg:id\" content=\"PB:228083473\" \/>\n<meta name=\"DC.identifier\" scheme=\"DCTERMS.URI\" content=\"http:\/\/dx.doi.org\/10.1214\/13-BA858\" \/>\n<meta name=\"gs_meta_revision\" content=\"1.1\" \/>\n<meta name=\"citation_title\" content=\"Fixed-Form Variational Posterior Approximation through Stochastic Linear Regression\" \/>\n<meta name=\"citation_author\" content=\"Tim Salimans\" \/>\n<meta name=\"citation_author\" content=\"David A. Knowles\" \/>\n<meta name=\"citation_publication_date\" content=\"2012\/06\/28\" \/>\n<meta name=\"citation_issn\" content=\"1936-0975\" \/>\n<meta name=\"citation_volume\" content=\"8\" \/>\n<meta name=\"citation_issue\" content=\"4\" \/>\n<meta name=\"citation_doi\" content=\"10.1214\/13-BA858\" \/>\n<meta name=\"citation_pdf_url\" content=\"https:\/\/www.researchgate.net\/profile\/Tim_Salimans\/publication\/228083473_Fixed-Form_Variational_Posterior_Approximation_through_Stochastic_Linear_Regression\/links\/5486e7290cf268d28f062892.pdf\" \/>\n<meta name=\"citation_abstract_html_url\" content=\"https:\/\/www.researchgate.net\/publication\/228083473_Fixed-Form_Variational_Posterior_Approximation_through_Stochastic_Linear_Regression\" \/>\n<meta name=\"citation_fulltext_html_url\" content=\"https:\/\/www.researchgate.net\/publication\/228083473_Fixed-Form_Variational_Posterior_Approximation_through_Stochastic_Linear_Regression\" \/>\n<meta name=\"viewport\" content=\"width=device-width,initial-scale=1\" \/>\n<link href=\"\/\/c5.rgstatic.net\/m\/22664197317151888\/styles\/rg.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/21004998181197492\/styles\/rg2.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<!--[if lt IE 9]><link href=\"\/\/c5.rgstatic.net\/m\/238176252723686\/styles\/ie.css\" type=\"text\/css\" rel=\"stylesheet\"\/><![endif]-->\n<link href=\"\/\/c5.rgstatic.net\/m\/217752362214895\/styles\/modules\/publicprofile.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/21993347442549\/styles\/pow\/publicliterature\/FollowPublicationPromo.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/282514599719602\/styles\/pow\/application\/PdfJsReader.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/23819663151220\/styles\/pow\/publicliterature\/PublicationInlineReader.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<script src=\"\/\/c5.rgstatic.net\/m\/2321000301012716\/javascript\/vendor\/webfontloader\/webfontloader.js\" type=\"text\/javascript\"><\/script>\n <script>(function(i,s,o,g,r,a,m){i[\"GoogleAnalyticsObject\"]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,\"script\",\"\/\/www.google-analytics.com\/analytics.js\",\"ga\");\n ga(\"create\",\"UA-58591210-1\");ga(\"set\",\"anonymizeIp\",true);ga('set', 'dimension1', 'publication full-text');ga('set', 'dimension2', 'Article');ga('set', 'dimension3', 'Logged out');ga('set', 'dimension4', 'https');ga(\"send\",\"pageview\");<\/script>\n","webfont":"<noscript><\/noscript><script> WebFontConfig = { custom: { families: ['source_sans_pro_italic', 'source_sans_pro_bold', 'source_sans_pro', 'martel'], urls : ['\/\/c5.rgstatic.net\/m\/231392577336386\/styles\/fonts.css'] } }; WebFont.load(WebFontConfig); <\/script>\n","correlationId":"rgreq-c5481979-0cab-4c2f-bd9e-84a725ad17bb","accountId":null,"module":"publicliterature","action":"publicliterature.PublicPublicationDetails","page":"publicationDetail","product":"publications","backendTime":1272,"continent":"Asia","stylesHome":"\/\/c5.rgstatic.net\/m\/","staticHost":"c5.rgstatic.net","useEarlyFlush":false,"longRunningRequestIdentifier":"LongRunningRequest.publicliterature.PublicPublicationDetails","longRunningRequestFp":"e9e5bbe1366c7ee8c8e41d02f793c884ac9be19b","widgetId":"rgw37_56ab9eee9ebe9"},"id":"rgw37_56ab9eee9ebe9","partials":[],"templateName":"application\/stubs\/StaticHeader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.StaticHeader.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){
            Y.rg.core.pagespeed.Monitoring.monitorPage("\/\/glassmoni.researchgate.net", "publicliterature.PublicPublicationDetails.run.html.loggedOut.get", "59de9668d07aeb77ab4de5f24d382b5d199d2437", "rgreq-c5481979-0cab-4c2f-bd9e-84a725ad17bb", "89ebee71b7a5e5eb439354c2dcd2fbb92e44d946");
        
            Y.rg.core.pagespeed.Monitoring.monitorPage("\/\/glassmoni.researchgate.net", "publicationDetail.loggedOut", "ed1993d9e20f6cefa83edacaa24401a18c071aea", "rgreq-c5481979-0cab-4c2f-bd9e-84a725ad17bb", "89ebee71b7a5e5eb439354c2dcd2fbb92e44d946");
        })();
(function(){Y.rg.createInitialWidget({"data":{"year":"2016","inlinePromo":null,"isAdmin":false,"contactUrl":"https:\/\/www.researchgate.net\/contact","aboutUsUrl":"https:\/\/www.researchgate.net\/about","widgetId":"rgw38_56ab9eee9ebe9"},"id":"rgw38_56ab9eee9ebe9","partials":[],"templateName":"application\/stubs\/DefaultFooter.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.DefaultFooter.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"headerLogin":{"data":{"urlAfterLogin":"publication\/228083473_Fixed-Form_Variational_Posterior_Approximation_through_Stochastic_Linear_Regression","requestToken":"ljrYRD4+\/XOEZfDF9FQPeKsM5jpERD48usEogaKilFHcc11t+OhHVGt0ZnH5G84fx+6WRrwEwY\/YDd2VPMSDmTcBRLuDYh72Wn4Sgn4rJZW\/7g4JtGpmhX0a4tJavYDpdg9gIqNKCXXui2u\/Ryf0PD3yV7yQlopeYmEBmeFGl8Fo+65ZNqNUYb1IVIqHchyw0FJnmDJGOkIcuSbI6Cm+XlQJcUh7Gr3zOXpevFhrnbJMQ9nitN9D1zWzp0HRU6UIILO0Li0nORGr2Z31QbFGQkeB4rzAJg3x5NE7w72APyQ=","loginUrl":"https:\/\/www.researchgate.net\/application.Login.html","signupUrl":"https:\/\/www.researchgate.net\/signup.SignUp.html?ev=su_chnl_index&hdrsu=1&_sg=UCKT13aG8DtCq_sF7zncbtz-l9rRY_dd9_p5A1q1SjOQFGS5nRu6HDMQmd2CZJc2","encodedUrlAfterLogin":"cHVibGljYXRpb24vMjI4MDgzNDczX0ZpeGVkLUZvcm1fVmFyaWF0aW9uYWxfUG9zdGVyaW9yX0FwcHJveGltYXRpb25fdGhyb3VnaF9TdG9jaGFzdGljX0xpbmVhcl9SZWdyZXNzaW9u","signupCallToAction":"Join for free","widgetId":"rgw40_56ab9eee9ebe9"},"id":"rgw40_56ab9eee9ebe9","partials":{"partial":"application\/stubs\/partials\/headerLoginDefault.html"},"templateName":"application\/stubs\/HeaderLogin.html","templateExtensions":[],"attrs":{"goal":"milestoneHeaderLoginSeen"},"widgetUrl":"https:\/\/www.researchgate.net\/application.HeaderLogin.html","viewClass":"views.application.HeaderLoginView","yuiModules":["rg.views.application.HeaderLoginView"],"stylesheets":[],"_isYUI":true},"cookieConsent":null,"logoSvgSrc":"https:\/\/c5.rgstatic.net\/m\/235107188705592\/images\/template\/brand-header-logo.svg","logoFallbackSrc":"https:\/\/c5.rgstatic.net\/m\/238113351022438\/images\/template\/brand-header-logo.png","widgetId":"rgw39_56ab9eee9ebe9"},"id":"rgw39_56ab9eee9ebe9","partials":{"schemaSocialProfiles":"application\/stubs\/partials\/schemaSocialProfiles.html"},"templateName":"application\/stubs\/HeaderLoggedOut.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.HeaderLoggedOut.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"logEvent":"su_banner","specialCopy":false,"widgetId":"rgw41_56ab9eee9ebe9"},"id":"rgw41_56ab9eee9ebe9","partials":[],"templateName":"application\/stubs\/LoggedOutBanner.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.LoggedOutBanner.html","viewClass":"views.application.LoggedOutBannerView","yuiModules":["rg.views.application.LoggedOutBannerView"],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.core.util.ParameterFilter.filter(["ev","cp","ch","ref","dbw","pli","loginT","uid","claimChannel","enrichId","enrichSource","utm_source","utm_medium","utm_campaign","el","ci"]);})();
});}); } else { throw 'YRG was not loaded when attaching widgets'; }</script><script> dataLayer = [{"pageCategory":"publication full-text","publicationType":"Article","eventCategory":"Publication page"}]; </script> <noscript><iframe src="//www.googletagmanager.com/ns.html?id=GTM-MKVKH7" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-MKVKH7');</script><script>(function(e){function n(n,t,o,a){"use strict";var i=e.document.createElement("link"),r=t||e.document.getElementsByTagName("script")[0],d=e.document.styleSheets;return i.rel="stylesheet",i.href=n,i.media="only x",a&&(i.onload=a),r.parentNode.insertBefore(i,r),i.onloadcssdefined=function(e){for(var t,o=0;d.length>o;o++)d[o].href&&d[o].href.indexOf(n)>-1&&(t=!0);t?e():setTimeout(function(){i.onloadcssdefined(e)})},i.onloadcssdefined(function(){i.media=o||"all"}),i}function t(e,n){e.onload=function(){e.onload=null,n&&n.call(e)},"isApplicationInstalled"in navigator&&"onloadcssdefined"in e&&e.onloadcssdefined(n)}var o=function(a,i){"use strict";if(a&&3===a.length){var r=e.Image,d=!(!document.createElementNS||!document.createElementNS("http://www.w3.org/2000/svg","svg").createSVGRect||!document.implementation.hasFeature("http://www.w3.org/TR/SVG11/feature#Image","1.1")||e.opera&&-1===navigator.userAgent.indexOf("Chrome")||-1!==navigator.userAgent.indexOf("Series40")),c=new r;c.onerror=function(){o.method="png",o.href=a[2],n(a[2])},c.onload=function(){var e=1===c.width&&1===c.height,r=a[e&&d?0:e?1:2];o.method=e&&d?"svg":e?"datapng":"png",o.href=r,t(n(r),i)},c.src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///ywAAAAAAQABAAACAUwAOw==",document.documentElement.className+=" grunticon"}};o.loadCSS=n,o.onloadCSS=t,e.grunticon=o})(this);grunticon(["https://c5.rgstatic.net/c/o1q2er/styles/icons/_header-ico.svg.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_header-ico.png.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_header-ico.fallback.scss"]);grunticon(["https://c5.rgstatic.net/c/o1q2er/styles/icons/_admin-ico.svg.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_admin-ico.png.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_admin-ico.fallback.scss"]);grunticon(["https://c5.rgstatic.net/c/o1q2er/styles/icons/_ico.svg.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_ico.png.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_ico.fallback.scss"]);</script></body>
</html>
