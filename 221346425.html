<!DOCTYPE html> <html lang="en" class="" id="rgw40_56ab1c9d76a8a"> <head > <meta charset="utf-8"/> <meta http-equiv="content-type" content="text/html; charset=UTF-8"/> <meta name="Rg-Request-Token" id="Rg-Request-Token" content="03vUuvydhmVIm4j2Mc5e5QAT3gYtzKp8C8f9XT1KYBnNN8Cr3NOC/Pibo3WONj7J9g8pNsX8M6GCfYklEJVebV37CFyK2ikQ8vJZjd7vPuHcBupqSPy4dKlm3ZUDZXomB0BD4Yi+esXhGixoD4JnfZk6Y4WDvUwz65im65LfRyWHERaH682/k33hFAyaJQZb5m7OAOR291jjtz96RdezoPEjc+obo6joO/arv5mqxWZkxf1sf+uZ3/Z4P5OMeoE/WEkyCbfKYYnNk+6j9IgsJ88oiu5AbXmuctI/fr/TnRQ="/> <meta http-equiv="expires" content="0"/> <link rel="apple-touch-icon" sizes="57x57" href="https://www.researchgate.net/apple-touch-icon-57x57.png"> <link rel="apple-touch-icon" sizes="60x60" href="https://www.researchgate.net/apple-touch-icon-60x60.png"> <link rel="apple-touch-icon" sizes="72x72" href="https://www.researchgate.net/apple-touch-icon-72x72.png"> <link rel="apple-touch-icon" sizes="76x76" href="https://www.researchgate.net/apple-touch-icon-76x76.png"> <link rel="apple-touch-icon" sizes="114x114" href="https://www.researchgate.net/apple-touch-icon-114x114.png"> <link rel="apple-touch-icon" sizes="120x120" href="https://www.researchgate.net/apple-touch-icon-120x120.png"> <link rel="apple-touch-icon" sizes="144x144" href="https://www.researchgate.net/apple-touch-icon-144x144.png"> <link rel="apple-touch-icon" sizes="152x152" href="https://www.researchgate.net/apple-touch-icon-152x152.png"> <link rel="apple-touch-icon" sizes="180x180" href="https://www.researchgate.net/apple-touch-icon-180x180.png"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-32x32.png" sizes="32x32"> <link rel="icon" type="image/png" href="https://www.researchgate.net/android-chrome-192x192.png" sizes="192x192"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-96x96.png" sizes="96x96"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-16x16.png" sizes="16x16"> <link rel="shortcut icon" type="image/x-icon" href="https://c5.rgstatic.net/m/2390829798215018/images/favicon.ico"/> <link rel="manifest" href="https://www.researchgate.net/manifest.json"> <meta name="msapplication-TileColor" content="#da532c"> <meta name="msapplication-TileImage" content="https://www.researchgate.net/mstile-144x144.png"> <meta name="theme-color" content="#444444"> <link rel="search" type="application/opensearchdescription+xml" title="ResearchGate search" href="https://www.researchgate.net/application.DownloadOpenSearchPlugin.html"/> <link rel="meta" type="application/rdf+xml" title="ICRA labels" href="https://www.researchgate.net/application.DownloadLabels.html"/> <link rel="http://oexchange.org/spec/0.8/rel/related-target" type="application/xrd+xml" href="https://www.researchgate.net/application.DownloadOExchange.html"/> <base href="https://www.researchgate.net/"/> <script>
    var rgConfig = {
        correlationId: "rgreq-e2667482-f011-4e2d-9f3b-fa3b478147cd",
        accountId: "",
        module: "publicliterature",
        action: "publicliterature.PublicPublicationDetails",
        page: "publicationDetail",
        product: "publications",
        continent: "Asia",
        stylesHome: "//c5.rgstatic.net/m/",
        staticHost: "c5.rgstatic.net",
        longRunningRequestIdentifier: "LongRunningRequest.publicliterature.PublicPublicationDetails",
        longRunningRequestFp: "e9e5bbe1366c7ee8c8e41d02f793c884ac9be19b"
    };
    window.rootUrl = "https://www.researchgate.net/";
</script> <link rel="canonical" href="https://www.researchgate.net/publication/221346425_Bayesian_Learning_via_Stochastic_Gradient_Langevin_Dynamics" />
<link rel="dns-prefetch" href="//c5.rgstatic.net" />
<link rel="dns-prefetch" href="//i1.rgstatic.net" />
<meta property="twitter:card" content="summary" />
<meta property="twitter:site" content="@ResearchGate" />
<meta property="og:title" content="Bayesian Learning via Stochastic Gradient Langevin Dynamics" />
<meta property="og:description" content="In this paper we propose a new framework for learning from large scale datasets based on iterative learning from small mini-batches. By adding the right amount of noise to a standard stochastic..." />
<meta property="og:site_name" content="ResearchGate" />
<meta property="og:image" content="https://i1.rgstatic.net/publication/221346425_Bayesian_Learning_via_Stochastic_Gradient_Langevin_Dynamics/links/0ffd5c240cf255165fca9437/smallpreview.png" />
<meta property="og:url" content="https://www.researchgate.net/publication/221346425_Bayesian_Learning_via_Stochastic_Gradient_Langevin_Dynamics" />
<meta property="rg:id" content="PB:221346425" />
<meta name="DC.identifier" scheme="DCTERMS.URI" content="http://dx.doi.org/" />
<meta name="gs_meta_revision" content="1.1" />
<meta name="citation_title" content="Bayesian Learning via Stochastic Gradient Langevin Dynamics" />
<meta name="citation_author" content="Max Welling" />
<meta name="citation_author" content="Yee Whye Teh" />
<meta name="citation_conference_title" content="Proceedings of the 28th International Conference on Machine Learning, ICML 2011, Bellevue, Washington, USA, June 28 - July 2, 2011" />
<meta name="citation_publication_date" content="2011/01/01" />
<meta name="citation_firstpage" content="681" />
<meta name="citation_lastpage" content="688" />
<meta name="citation_abstract_html_url" content="https://www.researchgate.net/publication/221346425_Bayesian_Learning_via_Stochastic_Gradient_Langevin_Dynamics" />
<meta name="citation_fulltext_html_url" content="https://www.researchgate.net/publication/221346425_Bayesian_Learning_via_Stochastic_Gradient_Langevin_Dynamics" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<link href="//c5.rgstatic.net/m/22664197317151888/styles/rg.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/21004998181197492/styles/rg2.css" type="text/css" rel="stylesheet"/>
<!--[if lt IE 9]><link href="//c5.rgstatic.net/m/238176252723686/styles/ie.css" type="text/css" rel="stylesheet"/><![endif]-->
<link href="//c5.rgstatic.net/m/217752362214895/styles/modules/publicprofile.css" type="text/css" rel="stylesheet"/>
<script src="//c5.rgstatic.net/m/2321000301012716/javascript/vendor/webfontloader/webfontloader.js" type="text/javascript"></script>
 <script>(function(i,s,o,g,r,a,m){i["GoogleAnalyticsObject"]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,"script","//www.google-analytics.com/analytics.js","ga");
 ga("create","UA-58591210-1");ga("set","anonymizeIp",true);ga('set', 'dimension1', 'publication slurped');ga('set', 'dimension2', 'Conference Paper');ga('set', 'dimension3', 'Logged out');ga('set', 'dimension4', 'https');ga("send","pageview");</script>
  <script> WebFontConfig = { custom: { families: ['source_sans_pro_italic', 'source_sans_pro_bold', 'source_sans_pro', 'martel'], urls : ['//c5.rgstatic.net/m/231392577336386/styles/fonts.css'] } }; WebFont.load(WebFontConfig); </script><noscript></noscript>

<title>Bayesian Learning via Stochastic Gradient Langevin Dynamics</title>
<meta name="description" content="Bayesian Learning via Stochastic Gradient Langevin Dynamics on ResearchGate, the professional network for scientists."/>
<meta name="keywords" content="scientific network, scientific platform, scientific community, research partner, research collaboration, journal articles, international collaboration, find researcher, lifescience researcher, interdisciplinary research, research collaboration"/>
</head>
<body class="use-svg-icons logged-out">
<div id="page-container">
<script type="text/javascript">var googletag = googletag || {}; googletag.cmd = googletag.cmd || [];
(function() { var gads = document.createElement("script"); gads.async = true; gads.type = "text/javascript"; var useSSL = "https:" == document.location.protocol; gads.src = (useSSL ? "https:" : "http:") + "//www.googletagservices.com/tag/js/gpt.js"; var node =document.getElementsByTagName("script")[0]; node.parentNode.insertBefore(gads, node); })();</script><div id="main" class="logged-out-header-support">
<div id="content" class="">

<noscript>
<div class="c-box-warning full-width-element" style="text-align: center; ">
    <div style="margin: auto; padding:10px;" class="container">
        <b>For full functionality of ResearchGate it is necessary to enable JavaScript.
            Here are the <a href="http://www.enable-javascript.com/" rel="nofollow" target="_blank">
                instructions how to enable JavaScript in your web browser</a>.</b>
    </div>
</div>
</noscript>

<div id="rgw1_56ab1c9d76a8a" itemscope itemtype="http://schema.org/ScholarlyArticle"><div class="publication-wrapper publication-wrapper-onecol" id="rgw2_56ab1c9d76a8a" itemscope itemtype="http://schema.org/ScholarlyArticle"> <div class="c-col-content"> <div class="c-content"> <div class="clearfix">  <div class="publication-header"> <div id="rgw8_56ab1c9d76a8a">  <div class="type-label"> Conference Paper   </div> <span class="Z3988" title="ctx_ver=Z39.88-2004&rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&rfr_id=info%3Asid%2Fresearchgate.net%3Aresearchgate&rft.atitle=Bayesian%20Learning%20via%20Stochastic%20Gradient%20Langevin%20Dynamics&rft.date=2011&rft.pages=681-688&rft.au=Max%20Welling%2CYee%20Whye%20Teh&rft.genre=inProceedings"></span> <h1 class="pub-title" itemprop="name">Bayesian Learning via Stochastic Gradient Langevin Dynamics</h1> <meta itemprop="headline" content="Bayesian Learning via Stochastic Gradient Langevin Dynamics">  <meta itemprop="image" content="https://i1.rgstatic.net/publication/221346425_Bayesian_Learning_via_Stochastic_Gradient_Langevin_Dynamics/links/0ffd5c240cf255165fca9437/smallpreview.png">  <div id="rgw10_56ab1c9d76a8a" class="publication-detail-author-list"> <div> <ul class="clearfix js-people-list">  <li id="rgw11_56ab1c9d76a8a"> <a href="researcher/69847505_Max_Welling" class="pub-detail-item author-item" itemprop="author" itemscope itemtype="http://schema.org/Person"> <div class="indent-left"> <div class="people-img">  <img src="https://c5.rgstatic.net/m/2951093203564/images/template/default/profile/profile_default_s.jpg" title="Max Welling" alt="Max Welling" height="20px" width="20px" style="height: 20px;"/>  </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Max Welling</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item   not-claimed " id="rgw12_56ab1c9d76a8a">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="researcher/69847505_Max_Welling"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="Max Welling" alt="Max Welling" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">       </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="researcher/69847505_Max_Welling" class="display-name">Max Welling</a>    </h5> <div class="truncate-single-line meta">   </div>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>  <li id="rgw13_56ab1c9d76a8a"> <a href="researcher/9164246_Yee_Whye_Teh" class="pub-detail-item author-item" itemprop="author" itemscope itemtype="http://schema.org/Person"> <div class="indent-left"> <div class="people-img">  <img src="https://c5.rgstatic.net/m/2951093203564/images/template/default/profile/profile_default_s.jpg" title="Yee Whye Teh" alt="Yee Whye Teh" height="20px" width="20px" style="height: 20px;"/>  </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Yee Whye Teh</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item   not-claimed " id="rgw14_56ab1c9d76a8a">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="researcher/9164246_Yee_Whye_Teh"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="Yee Whye Teh" alt="Yee Whye Teh" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">       </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="researcher/9164246_Yee_Whye_Teh" class="display-name">Yee Whye Teh</a>    </h5> <div class="truncate-single-line meta">   </div>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>   </ul> <div class="js-loading"></div>  </div> </div> <div class="pub-details js-pub-details">         Conference: Proceedings of the 28th International Conference on Machine Learning, ICML 2011, Bellevue, Washington, USA, June 28 - July 2, 2011      <div class="pub-source"> Source: <a href="http://dblp.uni-trier.de/db/conf/icml/icml2011.html#WellingT11" rel="nofollow">DBLP</a> </div>  </div> <div id="rgw15_56ab1c9d76a8a" class="pub-abstract">  <div class="clearfix">   <p itemprop="description"> <strong>ABSTRACT</strong> <div>In this paper we propose a new framework for learning from large scale datasets based on iterative learning from small mini-batches. By adding the right amount of noise to a standard stochastic gradient optimization algorithm we show that the iterates will converge to samples from the true posterior distribution as we anneal the stepsize. This seamless transition between optimization and Bayesian posterior sampling provides an inbuilt protection against overfitting. We also propose a practical method for Monte Carlo estimates of posterior statistics which monitors a &ldquo;sampling threshold &rdquo; and collects samples after it has been surpassed. We apply the method to three models: a mixture of Gaussians, logistic regression and ICA with natural gradients. 1.</div> </p>  </div>   </div>      <div class="action-container">   <div class="clear"></div> <div class="share-dialog-container" style="display: none;">  </div> </div> </div> <div style="margin-left: -20px; margin-right: -20px;">  </div> </div>  <div class="publication-detail-dfp-container rf"> <div id="rgw28_56ab1c9d76a8a">  </div> </div>  </div>  <div class="clearfix">  <noscript> <div id="rgw27_56ab1c9d76a8a"  itemprop="articleBody">  <p>Page 1</p> <p>Bayesian Learning via Stochastic Gradient Langevin Dynamics<br />Max Welling<br />D. Bren School of Information and Computer Science, University of California, Irvine, CA 92697-3425, USA<br />welling@ics.uci.edu<br />Yee Whye Teh<br />Gatsby Computational Neuroscience Unit, UCL, 17 Queen Square, London WC1N 3AR, UK<br />ywteh@gatsby.ucl.ac.uk<br />Abstract<br />In this paper we propose a new framework<br />for learning from large scale datasets based<br />on iterative learning from small mini-batches.<br />By adding the right amount of noise to a<br />standard stochastic gradient optimization al-<br />gorithm we show that the iterates will con-<br />verge to samples from the true posterior dis-<br />tribution as we anneal the stepsize.<br />seamless transition between optimization and<br />Bayesian posterior sampling provides an in-<br />built protection against overfitting. We also<br />propose a practical method for Monte Carlo<br />estimates of posterior statistics which moni-<br />tors a “sampling threshold” and collects sam-<br />ples after it has been surpassed. We apply<br />the method to three models: a mixture of<br />Gaussians, logistic regression and ICA with<br />natural gradients.<br />This<br />1. Introduction<br />In recent years there has been an increasing amount<br />of very large scale machine learning datasets, ranging<br />from internet traffic and network data, computer vi-<br />sion, natural language processing, to bioinformatics.<br />More and more advances in machine learning are now<br />driven by these large scale data, which offers the op-<br />portunity to learn large and complex models for solv-<br />ing many useful applied problems. Recent successes<br />in large scale machine learning have mostly been opti-<br />mization based approaches. While there are sophisti-<br />cated algorithms designed specifically for certain types<br />of models, one of the most successful class of algo-<br />rithms are stochastic optimization, or Robbins-Monro,<br />algorithms. These algorithms process small (mini-<br />Appearing in Proceedings of the 28thInternational Con-<br />ference on Machine Learning, Bellevue, WA, USA, 2011.<br />Copyright 2011 by the author(s)/owner(s).<br />)batches of data at each iteration, updating model<br />parameters by taking small gradient steps in a cost<br />function. Often these algorithms are run in an on-<br />line setting, where the data batches are discarded af-<br />ter processing and only one pass through the data is<br />performed, reducing memory requirements drastically.<br />One class of methods “left-behind” by the recent ad-<br />vances in large scale machine learning are the Bayesian<br />methods. This has partially to do with the negative<br />results in Bayesian online parameter estimation (An-<br />drieu et al., 1999), but also the fact that each iteration<br />of typical Markov chain Monte Carlo (MCMC) algo-<br />rithms requires computations over the whole dataset.<br />Nevertheless, Bayesian methods are appealing in their<br />ability to capture uncertainty in learned parameters<br />and avoid overfitting. Arguably with large datasets<br />there will be little overfitting.<br />have access to larger datasets and more computational<br />resources, we become interested in building more com-<br />plex models, so that there will always be a need to<br />quantify the amount of parameter uncertainty.<br />Alternatively, as we<br />In this paper, we propose a method for Bayesian learn-<br />ing from large scale datasets. Our method combines<br />Robbins-Monro type algorithms which stochastically<br />optimize a likelihood, with Langevin dynamics which<br />injects noise into the parameter updates in such a way<br />that the trajectory of the parameters will converge<br />to the full posterior distribution rather than just the<br />maximum a posteriori mode. The resulting algorithm<br />starts off being similar to stochastic optimization, then<br />automatically transitions to one that simulates sam-<br />ples from the posterior using Langevin dynamics.<br />In Section 2 we introduce the two ingredients of our<br />method: stochastic optimization and Langevin dy-<br />namics. Section 3 describes our algorithm and how<br />it converges to the posterior distribution. Section 4<br />describes a practical method of estimating when our<br />algorithm will transition from stochastic optimization<br />to Langevin dynamics. Section 5 demonstrates our al-</p>  <p>Page 2</p> <p>Stochastic Gradient Langevin Dynamics<br />gorithm on a few models and Section 6 concludes.<br />2. Preliminaries<br />Let θ denote a parameter vector, with p(θ) a prior<br />distribution, and p(x|θ) the probability of data item<br />x given our model parameterized by θ. The posterior<br />distribution of a set of N data items X = {xi}N<br />is: p(θ|X) ∝ p(θ)∏N<br />the likelihood terms constitute the cost function to<br />be optimized, and the task is to find the maximum<br />a posteriori (MAP) parameters θ∗. A popular class<br />of methods called stochastic optimization (Robbins &amp;<br />Monro, 1951) operates as follows. At each iteration t,<br />a subset of n data items Xt= {xt1,...,xtn} is given,<br />and the parameters are updated as follows:<br />(<br />where ϵt is a sequence of step sizes.<br />idea is that the gradient computed on the subset is<br />used to approximate the true gradient over the whole<br />dataset. Over multiple iterations the whole dataset<br />is used and the noise in the gradient caused by using<br />subsets rather than the whole dataset averages out.<br />For large datasets where the subset gradient approx-<br />imation is accurate enough, this can give significant<br />computational savings over using the whole dataset to<br />compute gradients at each iteration.<br />i=1<br />i=1p(xi|θ). In the optimization<br />literature the prior regularizes the parameters while<br />∆θt=ϵt<br />2<br />∇logp(θt) +N<br />n<br />n<br />∑<br />i=1<br />∇logp(xti|θt)<br />)<br />(1)<br />The general<br />To ensure convergence to a local maximum, in addition<br />to other technical assumptions, a major requirement<br />is for the step sizes to satisfy the property<br />∞<br />∑<br />t=1<br />ϵt= ∞<br />∞<br />∑<br />t=1<br />ϵ2<br />t&lt; ∞<br />(2)<br />Intuitively, the first constraint ensures that parameters<br />will reach the high probability regions no matter how<br />far away it was initialized to, while the second ensures<br />that the parameters will converge to the mode instead<br />of just bouncing around it. Typically, step sizes ϵt=<br />a(b + t)−γare decayed polynomially with γ ∈ (0.5,1].<br />The issue with ML or MAP estimation, as stochas-<br />tic optimization aims to do, is that they do not cap-<br />ture parameter uncertainty and can potentially overfit<br />data. The typical way in which Bayesian approaches<br />capture parameter uncertainty is via Markov chain<br />Monte Carlo (MCMC) techniques (Robert &amp; Casella,<br />2004). In this paper we will consider a class of MCMC<br />techniques called Langevin dynamics (Neal, 2010). As<br />before, these take gradient steps, but also injects Gaus-<br />sian noise into the parameter updates so that they do<br />not collapse to just the MAP solution:<br />∆θt=ϵ<br />2<br />(<br />∇logp(θt) +<br />N<br />∑<br />i=1<br />∇logp(xi|θt)<br />)<br />+ ηt<br />ηt∼ N(0,ϵ)<br />The gradient step sizes and the variances of the in-<br />jected noise are balanced so that the variance of the<br />samples matches that of the posterior. Langevin dy-<br />namics is motivated and originally derived as a dis-<br />cretization of a stochastic differential equation whose<br />equilibrium distribution is the posterior distribution.<br />To correct for discretization error, one can take (3)<br />to just be a proposal distribution and correct using<br />Metropolis-Hastings. Interestingly, as we decrease ϵ<br />the discretization error decreases as well so that the re-<br />jection rate approaches zero. However typical MCMC<br />practice is to allow an initial adaptation phase where<br />the step sizes are adjusted, followed by fixing the step<br />sizes to ensure a stationary Markov chain thereafter.<br />(3)<br />More sophisticated techniques use Hamiltonian dy-<br />namics with momentum variables to allow parameters<br />to move over larger distances without the inefficient<br />random walk behaviour of Langevin dynamics (Neal,<br />2010). However, to the extent of our knowledge all<br />MCMC methods proposed thus far require computa-<br />tions over the whole dataset at every iteration, result-<br />ing in very high computational costs for large datasets.<br />3. Stochastic Gradient Langevin<br />Dynamics<br />Given the similarities between stochastic gradient al-<br />gorithms (1) and Langevin dynamics (3), it is nat-<br />ural to consider combining ideas from the two ap-<br />proaches. This allows efficient use of large datasets<br />while allowing for parameter uncertainty to be cap-<br />tured in a Bayesian manner. The approach is straight-<br />forward: use Robbins-Monro stochastic gradients, add<br />an amount of Gaussian noise balanced with the step<br />size used, and allow step sizes to go to zero. The pro-<br />posed update is simply:<br />(<br />ηt∼ N(0,ϵt)<br />where the step sizes decrease towards zero at rates sat-<br />isfying (2). This allows averaging out of the stochastic-<br />ity in the gradients, as well as MH rejection rates that<br />go to zero asymptotically, so that we can simply ignore<br />the MH acceptance steps, which require evaluation of<br />probabilities over the whole dataset, all together.<br />∆θt=ϵt<br />2<br />∇logp(θt) +N<br />n<br />n<br />∑<br />i=1<br />∇logp(xti|θt)<br />)<br />+ ηt<br />(4)</p>  <p>Page 3</p> <p>Stochastic Gradient Langevin Dynamics<br />In the rest of this section we will give an intuitive argu-<br />ment for why θtwill approach samples from the pos-<br />terior distribution as t → ∞. In particular, we will<br />show that for large t, the updates (4) will approach<br />Langevin dynamics (3), which converges to the poste-<br />rior distribution. Let<br />g(θ) = ∇logp(θ) +<br />N<br />∑<br />i=1<br />∇logp(xi|θ) (5)<br />be the true gradient of the log probability at θ and<br />ht(θ) = ∇logp(θ) +N<br />n<br />n<br />∑<br />i=1<br />∇logp(xti|θ) − g(θ) (6)<br />The stochastic gradient is then g(θ)+ht(θ), with ht(θ)<br />a zero mean random variable (due to the stochasticity<br />of the data items chosen at step t) with finite variance<br />V (θ), and (4) is,<br />∆θt=ϵt<br />2(g(θt) + ht(θt)) + ηt,ηt∼ N(0,ϵt) (7)<br />There are two sources of stochasticity in (7): the in-<br />jected Gaussian noise with variance ϵt, and the noise in<br />the stochastic gradient, which has variance (ϵt<br />The first observation is that for large t, ϵt→ 0, and<br />the injected noise will dominate the stochastic gradient<br />noise, so that (7) will be effectively Langevin dynam-<br />ics (3). The second observation is that as ϵt → 0,<br />the discretization error of Langevin dynamics will be<br />negligible so that the MH rejection probability will ap-<br />proach 0 and we may simply ignore this step.<br />2)2V (θt).<br />In other words, (4), (7) effectively define a non-<br />stationary Markov chain such that the tth step tran-<br />sition operator, for all large t, will have as its equilib-<br />rium distribution the posterior over θ. The next ques-<br />tion we address is whether the sequence of parameters<br />θ1,θ2,... will converge to the posterior distribution.<br />Because the Markov chain is not stationary and the<br />step sizes reduce to 0, it is not immediately clear that<br />this is the case. To see that this is indeed true, we<br />will show that a subsequence θt1,θt2,... will converge<br />to the posterior as intended so the whole sequence will<br />also converge.<br />First fix an ϵ0such that 0 &lt; ϵ0≪ 1. Since {ϵt} satisfy<br />the step size property (2), we can find a subsequence<br />t1&lt; t2&lt; ··· such that∑ts+1<br />large enough s the total injected noise, ∥∑ts+1<br />show that the total noise due to the stochasticity of<br />the gradients among these steps will be dominated by<br />the total injected noise. Since ϵ0 ≪ 1, we may take<br />t=ts+1ϵt→ ϵ0as s → ∞.<br />Since the injected noise at each step is independent, for<br />t=ts+1ηt∥2,<br />between steps ts and ts+1 will be O(√ϵ0). We now<br />∥θt− θts∥2 ≪ 1 for t between ts and ts+1. Making<br />the assumption that the gradient g(·) vary smoothly<br />(e.g. they are Lipschitz continuous in the models in<br />Section 5), the total stochastic gradient is:<br />ts+1<br />∑<br />t=ts+1<br />ϵt<br />2(g(θt) + ht(θt))(8)<br />=ϵ0<br />2g(θts) + O(ϵ0) +<br />ts+1<br />∑<br />t=ts+1<br />ϵt<br />2ht(θt)<br />Since the parameters did not vary much between ts<br />and ts+1, the stochasticity in ht(θt) will be dominated<br />by the randomness in the choice of the mini-batches.<br />Assuming that these are chosen randomly and inde-<br />pendently, ht(θt) for each t will be basically iid (if<br />mini-batches were chosen by random partitioning of<br />the whole dataset, ht(θt) will be negatively correlated<br />instead and will not change the results here). Thus<br />the variance of∑ts+1<br />=ϵ0<br />2g(θts) + O(ϵ0) + O<br />=ϵ0<br />2g(θts) + O(ϵ0)<br />The last equation says that the total stochastic gra-<br />dient step is approximately the exact gradient step at<br />θtswith a step size of ϵ0, with a deviation dominated<br />by O(ϵ0). Since this is in turn dominated by the total<br />injected noise which is O(√ϵ0), this means that the se-<br />quence θt1,θt2,... will approach a sequence generated<br />by Langevin dynamics with a fixed step size ϵ0, so it<br />will converge to the posterior distribution. Note also<br />that it will have infinite effective sample size.<br />t=ts+1<br />ϵt<br />2ht(θt) is O(∑<br />t<br />ϵ2<br />t<br />4) and<br />)(√∑ts+1<br />t=ts+1<br />ϵ2<br />t<br />4<br />The implication of this argument is that we can use<br />stochastic gradient Langevin dynamics as an “any-<br />time” and general-purpose algorithm. In the initial<br />phase the stochastic gradient noise will dominate and<br />the algorithm will imitate an efficient stochastic gra-<br />dient ascent algorithm. In the later phase the injected<br />noise will dominate, so the algorithm will imitate a<br />Langevin dynamics MH algorithm, and the algorithm<br />will transition smoothly between the two. However<br />a disadvantage is that to guarantee the algorithm to<br />work it is important for the step sizes to decrease to<br />zero, so that the mixing rate of the algorithm will<br />slow down with increasing number of iterations. To<br />address this, we can keep the step size constant once<br />it has decreased below a critical level where the MH<br />rejection rate is considered negligible, or use this al-<br />gorithm for burn-in, but switch to a different MCMC<br />algorithm that makes more efficient use of the whole<br />dataset later. These alternatives can perform better</p>  <p>Page 4</p> <p>Stochastic Gradient Langevin Dynamics<br />but will require further hand-tuning and are beyond<br />the scope of this paper. The point of this paper is<br />to demonstrate a practical algorithm that can achieve<br />proper Bayesian learning using only mini-batch data.<br />4. Posterior Sampling<br />In this section we consider the use of our stochastic<br />gradient Langevin dynamics algorithm as one which<br />produces samples from the posterior distribution. We<br />first derive an estimate of when the algorithm will<br />transition from stochastic optimization to Langevin<br />dynamics. The idea is that we should only start col-<br />lecting samples after it has entered its posterior sam-<br />pling phase, which will not happen until after it be-<br />comes Langevin dynamics. Then we discuss how the<br />algorithm scales with the dataset size N and give a<br />rough estimate of the number of iterations required for<br />the algorithm to traverse the whole posterior. Finally<br />we discuss how the obtained samples can be used to<br />form Monte Carlo estimates of posterior expectations.<br />4.1. Transition into Langevin dynamics phase<br />We first generalize our method to allow for precon-<br />ditioning, which can lead to significant speed ups by<br />better adapting the step sizes to the local structure of<br />the posterior (Roberts &amp; Stramer, 2002; Girolami &amp;<br />Calderhead, 2011). For instance, certain dimensions<br />may have a vastly larger curvature leading to much<br />bigger gradients. In this case a symmetric precondi-<br />tioning matrix M can transform all dimensions to the<br />same scale. The preconditioned stochastic gradient<br />Langevin dynamics is simply,<br />(<br />As noted previously, whether the algorithm is in the<br />stochastic optimization phase or Langevin dynamics<br />phase depends on the variance of the injected noise,<br />which is simply ϵtM, versus that of the stochastic gra-<br />dient. Since the stochastic gradient is a sum over the<br />current mini-batch, if its size n is large enough the<br />central limit theorem will kick in and the variations<br />ht(θt) around the true gradient g(θt) will become nor-<br />mally distributed. Its covariance matrix can then be<br />estimated from the empirical covariance:<br />∆θt=ϵt<br />2Mg(θt) + ht(θt)<br />)<br />+ ηt,ηt∼ N(0,ϵtM)<br />V (θt) ≡ V [ht(θt)] ≈N2<br />n2<br />n<br />∑<br />i=1<br />(sti− st)(sti− st)⊤<br />(9)<br />where sti= ∇logp(xti|θt) +<br />of data item i at iteration t and st =<br />the empirical mean. Note that V (θt) =N2<br />1<br />N∇logp(θt) is the score<br />1<br />n<br />∑n<br />i=1sti is<br />nVs, where<br />Vs is the empirical covariance of the scores {sti}, so<br />scales as<br />the stochastic gradient step is<br />get the injected noise to dominate in all directions, we<br />need the condition<br />N2<br />n. From this we see that the variance of<br />ϵ2<br />tN2<br />4nMVsM, so that to<br />ϵtN2<br />4n<br />λmax(M<br />1<br />2VsM<br />1<br />2) = α ≪ 1 (10)<br />where λmax(A) is the largest eigenvalue of A. In other<br />words, if we choose a stepsize such that the sample<br />threshold α ≪ 1, the algorithm will be in its Langevin<br />dynamics phase and will be sampling approximately<br />from the posterior.<br />We can now relate the step size at the sampling thresh-<br />old to the posterior variance via the Fisher informa-<br />tion, which is related to Vsas IF ≈ NVs, and to the<br />posterior variance Σθ≈ I−1<br />as well as (10), we see that the step size at the sam-<br />pling threshold is ϵt≈<br />dynamics explores the posterior via a random walk,<br />using this step size implies that we need on the order<br />of N/n steps to traverse the posterior, i.e. we process<br />the whole dataset. So we see this method is not a<br />silver bullet. However, the advantage of the method<br />is its convenience: stochastic optimization smoothly<br />and automatically transitions into posterior sampling<br />without changing the update equation. Even without<br />measuring the sampling threshold one will enjoy the<br />benefit of protection against overfitting and the ability<br />to perform Bayesian learning. Measuring the sampling<br />threshold will only be important if one needs to faith-<br />fully represent the posterior distribution with a finite<br />collection of samples.<br />F. Using these relationships<br />4αn<br />Nλmin(Σθ). Since Langevin<br />4.2. Estimating Posterior Expectations<br />Since θ1,θ2,... converges to the posterior distribution,<br />we can estimate the posterior expectation E[f(θ)] of<br />some function f(θ) by simply taking the sample av-<br />erage<br />T<br />remove the initial burn-in phase, say estimated using<br />the sampling threshold). Since f(θt) is an asymptoti-<br />cally unbiased estimator for E[f(θ)], this sample aver-<br />age will be consistent. Observe however that because<br />the step size decreases, the mixing rate of the Markov<br />chain decreases as well, and the simple sample aver-<br />age will over-emphasize the tail end of the sequence<br />where there is higher correlation among the samples,<br />resulting in higher variance in the estimator. Instead<br />we propose to use the step sizes to weight the samples:<br />∑T<br />1<br />∑T<br />t=1f(θt) (as typically in MCMC, we may<br />E[f(θ)] ≈<br />t=1ϵtf(θt)<br />∑T<br />t=1ϵt<br />(11)</p>  <p>Page 5</p> <p>Stochastic Gradient Langevin Dynamics<br />−1012<br />−3<br />−2<br />−1<br />0<br />1<br />2<br />3<br />−1012<br />−3<br />−2<br />−1<br />0<br />1<br />2<br />3<br />Figure 1. True and estimated posterior distribution.<br />10<br />0<br />10<br />2<br />10<br />4<br />10<br />6<br />10<br />−6<br />10<br />−4<br />10<br />−2<br />10<br />0<br />iteration<br />noise variance<br /> <br /> <br />∇θ1 noise<br />∇θ2 noise<br />injected noise<br />10<br />−8<br />10<br />−6<br />10<br />−4<br />10<br />−2<br />10<br />−3<br />10<br />−2<br />10<br />−1<br />10<br />0<br />step size<br />average rejection rate<br />Figure 2. Left: variances of stochastic gradient noise and<br />injected noise. Right: rejection probability versus step size.<br />We report the average rejection probability per iteration in<br />each sweep through the dataset.<br />Since∑∞<br />Markov chain mixes is proportional to the step size, so<br />that we expect the effective sample size of {θ1,...,θT}<br />to be proportional to∑T<br />t=1ϵt= ∞, this estimator will be consistent<br />as well. The intuition is that the rate at which the<br />t=1ϵt, and that each θt will<br />contribute an effective sample size proportional to ϵt.<br />5. Experiments<br />5.1. Simple Demonstration<br />We first demonstrate the workings of our stochastic<br />gradient Langevin algorithm on a simple example in-<br />volving only two parameters. To make the posterior<br />multimodal and a little more interesting, we use a mix-<br />ture of Gaussians with tied means:<br />θ1∼ N(0,σ2<br />xi∼1<br />1= 10, σ2<br />1) ;<br />θ2∼ N(0,σ2<br />x) +1<br />2)<br />2N(θ1,σ2<br />2N(θ1+ θ2,σ2<br />x)<br />where σ2<br />are drawn from the model with θ1 = 0 and θ2 = 1.<br />There is a mode at this parameter setting, but also a<br />secondary mode at θ1= 1, θ2= −1, with strong neg-<br />ative correlation between the parameters. We ran the<br />stochastic gradient Langevin algorithm with a batch-<br />2= 1 and σ2<br />x= 2. 100 data points<br />0<br />0<br />2<br />2<br />4<br />4<br />6<br />6<br />8<br />8<br />10<br />10<br />−7<br />−6<br />−5<br />−4<br />−3<br />−2<br />−1<br />0<br />Number of iterations through whole dataset<br />Log joint probability per datum<br />-6<br />-4<br />-5<br />-3<br />-2<br />-1<br />0<br />-7<br />0<br />0<br />0.5<br />0.5<br />1<br />1<br />1.5<br />1.5<br />2<br />2<br />0.65<br />0.7<br />0.75<br />0.8<br />0.85<br />Number of iterations through whole dataset<br />Accuracy on test data<br /> <br /> <br />Accuracy after 10 iterations<br />Accuracy<br />0.7<br />0.8<br />0.75<br />0.85<br />0.65<br />Figure 3. Average log joint probability per data item (left)<br />and accuracy on test set (right) as functions of the num-<br />ber of sweeps through the whole dataset. Red dashed line<br />represents accuracy after 10 iterations. Results are aver-<br />aged over 50 runs; blue dotted lines indicate 1 standard<br />deviation.<br />size of 1 and using 10000 sweeps through the whole<br />dataset.The step sizes are ϵt = a(b + t)−γwhere<br />γ = .55 and a and b are set such that ϵt decreases<br />from .01 to .0001 over the duration of the run. We see<br />from Figure 1 that the estimated posterior distribu-<br />tion is very accurate. In Figure 2 we see that there are<br />indeed two phases to the stochastic gradient Langevin<br />algorithm: a first phase where the stochastic gradient<br />noise dominates the injected noise, and a second phase<br />where the converse occurs. To explore the scaling of<br />the rejection rate as a function of step sizes, we reran<br />the experiment with step sizes exponentially decreas-<br />ing from 10−2to 10−8. In the original experiment the<br />dynamic range of the step sizes is not wide enough for<br />visual inspection. Figure 2(right) shows the rejection<br />probability decreasing to zero as step size decreases.<br />5.2. Logistic Regression<br />We applied our stochastic gradient Langevin algorithm<br />to a Bayesian logistic regression model. The probabil-<br />ity of the ith output yi ∈ {−1,+1} given the corre-<br />sponding input vector xiis modelled as:<br />p(yi|xi) = σ(yiβ⊤xi)(12)<br />where β are the parameters, and σ(z) =<br />The bias parameter is absorbed into β by including 1<br />as an entry in xi. We use a Laplace prior for β with a<br />scale of 1. The gradient of the log likelihood is:<br />1<br />1+exp(−z).<br />∂<br />∂βlogp(yi|xi) = σ(−yiβ⊤xi)yixi<br />while the gradient of the prior is simply −sign(β),<br />which is applied elementwise.<br />(13)<br />We applied our inference algorithm to the a9a dataset<br />derived by (Lin et al., 2008) from the UCI adult<br />dataset. It consists of 32561 observations and 123 fea-<br />tures, and we used batch sizes of 10. Results from 50</p>  <p>Page 6</p> <p>Stochastic Gradient Langevin Dynamics<br />runs are shown in Figure 3, with the model trained<br />on a random 80% of the dataset and tested on the<br />other 20% in each run. We see that both the joint<br />probability and the accuracy increase rapidly, with the<br />joint probability converging after at most 10 iterations,<br />while the accuracy converging after less than 1 itera-<br />tion through the dataset, demonstrating the efficiency<br />of the stochastic gradient Langevin dynamics.<br />5.3. Independent Components Analysis<br />In the following we will briefly review a popular ICA<br />algorithm based on stochastic (natural) gradient opti-<br />mization (Amari et al., 1996). We start from a proba-<br />bilistic model that assumes independent, heavy tailed<br />marginal distributions,<br />[∏<br />where we have used a Gaussian prior over the weights.<br />It has been found that the efficiency of gradient descent<br />can be significantly improved if we use a natural gradi-<br />ent. This is implemented by post-multiplication of the<br />gradient with the term WTW (Amari et al., 1996). If<br />we choose pi(yi) =<br />4cosh2(1<br />p(x,W) = |det(W)|<br />i<br />pi(wT<br />ix)<br />]∏<br />ij<br />N(Wij;0,λ)<br />(14)<br />1<br />2yi)with yi= wT<br />ix, we get<br />DW<br />(<br />.= ∇Wlog[p(X,W)] WTW =<br />N<br />∑<br />NI −<br />n=1<br />tanh(1<br />2yn)yT<br />n<br />)<br />W − λWWTW<br />(15)<br />The term WTW acts like a preconditioning matrix (see<br />section 4.1), Mij,kl= δik(WTW)jlwhich is symmetric<br />under the exchange (i ↔ k,j ↔ l). It can be shown<br />that the inverse of M is given by M−1= δ(WTW)−1,<br />and the matrix square root as<br />√WTW = UΛ<br />√M = δ√WTW with<br />1<br />2UTif WTW = UΛUT.<br />The update equation for Langevin dynamics thus be-<br />comes,<br />Wt+1= Wt+1<br />2εtDW+ ηt<br />√<br />WTW<br />(16)<br />where every element of ηtis normally distributed with<br />variance εt: ηij,t ∼ N[0,εt]. Our stochastic version<br />simply approximates the part of the gradient that<br />sums over data-cases with a sum over a small mini-<br />batch of size n and multiplies the result with N/n to<br />bring it back to the correct scale. We also anneal the<br />stepsizes according to εt∝ a(b + t)−γ.<br />To assess how well our stochastic Langevin approach<br />compares against a standard Bayesian method we im-<br />plemented the ”corrected Langevin” MCMC sampler.<br />This sampler, proposes a new state W∗, as in Eqn.16.<br />Note however that we sum over all data-cases and that<br />we do not anneal the stepsize. Secondly, we need to<br />accept or reject the proposed step based on all the<br />data-cases in order to guarantee detailed balance. The<br />proposal distribution is given by (suppressing depen-<br />dence on t),<br />[<br />where the quadratic function in the exponent is con-<br />veniently computed as,<br />q(W → W∗) = N<br />W∗;W +1<br />2εDW;εM<br />]<br />(17)<br />−1<br />2εtr[(δW −1<br />2εDW)(WTW)−1(δW −1<br />2εDW)T]<br />(18)<br />with δW = W∗− W and the normalization constant<br />requires the quantity detM = det(WTW)D. The ac-<br />cept/reject step is then given by the usual Metropolis<br />Hastings rule:<br />[<br />Finally, to compute the sampling threshold of Eqn.10,<br />we can use<br />p(accept) = min1,p(W∗)q(W∗→ W)<br />p(W)q(W → W∗)<br />]<br />(19)<br />M<br />1<br />2V(s)M<br />[(1<br />1<br />2=(20)<br />]<br />covn<br />N∇logp(W) + ∇logp(xi|W)<br />)<br />(WTW)<br />1<br />2<br />with covnthe sample covariance over the mini-batch<br />of n data-cases.<br />To show the utility of our Bayesian variant of ICA we<br />define the following “instability” metric for indepen-<br />dent components:<br />∑<br />where var(Wij) is computed over the posterior sam-<br />ples and var(xj) is computed over the data-cases.<br />The reason that we scale the variance of the weight<br />entry Wij with the variance of xj is that the vari-<br />ance of the sources yi =∑<br />pi(yi) =<br />4cosh2(1<br />Ii=<br />j<br />var(Wij)var(xj)(21)<br />jWijxj is approximately<br />equal for all i because they are fit to the distribution<br />1<br />2yi).<br />5.3.1. Artificial Data<br />In the first experiment we generated 1000 data-cases<br />IID in six channels. Three channels had high kurtosis<br />distributions while three others where normally dis-<br />tributed. We ran stochastic Langevin dynamics with</p>  <p>Page 7</p> <p>Stochastic Gradient Langevin Dynamics<br />2468<br />x 10<br />4<br />2<br />4<br />6<br />8<br />10<br />iteration<br />Amari distance<br />Amari Distance Stoc. Lan.<br />0 0.51 1.52<br />4<br />x 10<br />2<br />4<br />6<br />8<br />10<br />iteration<br />Amari distance<br />Amari Distance Corr. Lan.<br />123456<br />0<br />50<br />100<br />150<br />200<br />Sorted Component ID<br />Instability Metric<br />Instability Metric Stoc. Lan.<br />123456<br />0<br />20<br />40<br />60<br />80<br />100<br />Sorted Component ID<br />Instability Metric<br />Instability Metric Corr. Lan.<br />Figure 4. Left two figures: Amari distance over time for stochastic Langevin dynamics and corrected Langevin dynamics.<br />Thick line represents the online average. First few hundred iterations were removed to show the scale of the fluctuations.<br />Right two figures: Instability index for the 6 independent components computed in section 5.3.1 for stochastic Langevin<br />dynamics and corrected Langevin dynamics.<br />W(1,1)<br />W(1,2)<br />PDF W(1,1) vs W(1,2) Stoc. Lan.<br />−505<br />−6<br />−4<br />−2<br />0<br />2<br />4<br />6<br />W(1,1)<br />W(1,2)<br />PDF W(1,1) vs W(1,2) Corr. Lan.<br />−4−2024<br />−6<br />−4<br />−2<br />0<br />2<br />4<br />W(1,1)<br />W(2,1)<br />PDF W(1,1) vs W(2,1) Stoc. Lan.<br />−505<br />−5<br />0<br />5<br />W(1,1)<br />W(2,1)<br />PDF W(1,1) vs W(2,1) Corr. Lan.<br />−4−2024<br />0<br />1<br />2<br />3<br />4<br />5<br />Figure 5. Posterior density estimates for artificial dataset for stochastic Langevin and corrected Langevin dynamics mea-<br />sured across the W11− W12 and W1,1− W2,1 axes.<br />a batch-size of 100 for a total of 500,000 iterations<br />and a polynomial annealing schedule εt =<br />After around 10,000 iterations the sampling threshold<br />at α = 0.1 was met. At that point we recorded the<br />“mixing distance” as D0 = εt and collected samples<br />only when the sum∑<br />lect fewer samples per unit time). We note that simply<br />collecting all samples had no noticeable impact on the<br />final results. The last estimate of W was used to ini-<br />tialize corrected Langevin dynamics (this was done to<br />force the samplers into the same local maximum) after<br />which we also collected 500,000 samples. For corrected<br />Langevin we used a constant stepsize of ε =0.1<br />4<br />Nt−0.55.<br />tεt from the last sample time<br />exceeded D0(in other words, as εtdecreases we col-<br />N.<br />The two left figures of Figure 4 show the Amari dis-<br />tance (Amari et al., 1996) over time for stochastic<br />and corrected Langevin dynamics respectively. The<br />right two figures show the sorted values of our pro-<br />posed instability index. Figures 5 show two dimen-<br />sional marginal density estimates of the posterior dis-<br />tribution of W. ICA cannot determine the Gaussian<br />components and this fact is verified by looking at the<br />posterior distribution. In fact, the stochastic Langevin<br />algorithm has mixed over a number of modes that pre-<br />sumably correspond to different linear combinations of<br />the Gaussian components. To a lesser degree the cor-<br />rected Langevin has also explored two modes. Due<br />to the complicated structure of the posterior distri-<br />bution the stability index varies strongly between the<br />two sampling algorithms for the Gaussian components<br />(and in fact also varies across different runs). We veri-<br />fied that the last three components correspond to sta-<br />ble, high kurtosis components.<br />5.3.2. MEG Data<br />We<br />http://www.cis.hut.fi/projects/ica/eegmeg/MEG data.html.<br />There are 122 channels and 17730 time-points, from<br />which we extracted the first 10 channels for our<br />experiment.To initialize the sampling algorithms,<br />we first ran fastICA (Hyvarinen, 1999) to find an<br />initial estimate of the de-mixing matrix W.<br />then ran stochastic Langevin and corrected Langevin<br />dynamics to sample from the posterior. The settings<br />were very similar to the previous experiment with a<br />schedule of εt=0.1<br />a constant stepsize of 1/N for corrected Langevin.<br />We obtained 500,000 samples for stochastic Langevin<br />in 800 seconds and 100,000 samples for corrected<br />Langevin in 9000 seconds.<br />that the two dimensional marginal distributions of<br />stochastic Langevin and corrected Langevin dynamics<br />were very similar. The instability values are shown in<br />figure 6. Due to the absence of Gaussian components<br />we see that the stability indices are very similar across<br />the two sampling algorithms.<br />downloadedtheMEGdatasetfrom<br />We<br />Nt−0.55for stochastic Langevin and<br />We visually verified<br />It was verified that</p>  <p>Page 8</p> <p>Stochastic Gradient Langevin Dynamics<br />12345678910<br />0<br />0.01<br />0.02<br />0.03<br />0.04<br />0.05<br />0.06<br />0.07<br />Sorted Components<br />Instability Index<br />Instability Index Stoc. Lan.<br />123456789 10<br />0<br />0.01<br />0.02<br />0.03<br />0.04<br />0.05<br />0.06<br />0.07<br />Sorted Components<br />Instability Index<br />Intability Index Corr. Lan.<br />Figure 6. Instability indices of 10 components for MEG<br />dataset for stochastic Langevin (left) and corrected<br />Langevin (right) respectively.<br />the most stable component corresponded to a highly<br />kurtotic source (kurtosus = 15.4), while the most<br />unstable component was closer to Gaussian noise<br />with a kurtosis of 3.4 (2 corresponds to Gaussian).<br />These findings verify that the stochastic Langevin<br />procedure produces accurate posterior distributions<br />that are in full agreement with a well established<br />MCMC procedure.<br />6. Discussion<br />Stochastic gradient optimization is among the most ef-<br />fective algorithms if we measure “predictive accuracy<br />obtained per unit of computation” (Bottou &amp; Bous-<br />quet, 2008). Due to subsampling noise, the parame-<br />ter estimates fluctuate around their MAP values. The<br />common wisdom is that one must anneal these step-<br />sizes to zero to reach the fixed point. However, we<br />argue that one should not optimize beyond the scale<br />of the posterior distribution. The posterior represents<br />the intrinsic statistical scale of precision and trying to<br />determine parameter values with more precision runs<br />the risk of overfitting at additional computational cost.<br />MCMC sampling from the posterior distribution does<br />of course address the overfitting issue. However, gen-<br />eral MCMC algorithms need to see all the data at ev-<br />ery iteration, and thus lose the benefits of the stochas-<br />tic approximation approaches. This paper offers for<br />the first time a surprisingly simple solution that rep-<br />resents the best of both worlds: stick with stochastic<br />gradients but sample from the posterior nevertheless.<br />But perhaps the biggest advantage of stochastic gra-<br />dient Langevin dynamics is the fact that stochastic<br />optimization seamlessly transitions into posterior sam-<br />pling. By simply adding Gaussian noise with the cor-<br />rect variance our method performs “early stopping”<br />automatically without ever having to worry about it.<br />In fact, we have shown that with a polynomial anneal-<br />ing schedule the obtained samples will asymptotically<br />represent the posterior distribution faithfully.<br />We believe that this work represents only a tentative<br />first step to further work on efficient MCMC sampling<br />based on stochastic gradients. Interesting directions of<br />research include stronger theory providing a solid proof<br />of convergence, deriving a MH rejection step based<br />on mini-batch data, extending the algorithm to the<br />online estimation of dynamical systems, and deriving<br />algorithms based on more sophisticated Hamiltonian<br />Monte Carlo approaches which do not suffer from ran-<br />dom walk behaviour.<br />Acknowledgements<br />This material is based upon work supported by the Na-<br />tional Science Foundation under Grant No.<br />1018433 (MW) and the Gatsby Charitable Foundation<br />(YWT).<br />0447903,<br />References<br />Amari, S., Cichocki, A., and Yang, H.H. A new algorithm<br />for blind signal separation. In Neural Information Pro-<br />cessing Systems, volume 8, pp. 757–763, 1996.<br />Andrieu, C., de Freitas, N., and Doucet, A. Sequential<br />MCMC for Bayesian model selection. In Proceedings of<br />the IEEE Signal Processing Workshop on Higher-Order<br />Statistics, pp. 130–134, 1999.<br />Bottou, L. and Bousquet, O. The tradeoffs of large scale<br />learning. In Advances in Neural Information Processing<br />Systems, volume 20, pp. 161–168, 2008.<br />Girolami, M. and Calderhead, B.<br />Langevin and Hamiltonian Monte Carlo methods. Jour-<br />nal of the Royal Statistical Society B, 73:1–37, 2011.<br />Riemann manifold<br />Hyvarinen, A. Fast and robust fixed-point algorithms for<br />independent component analysis. IEEE Transactions on<br />Neural Networks, 10(3):626–634, 1999.<br />Lin, C.-J., Weng, R. C., and Keerthi, S. S. Trust region<br />Newton method for large-scale logistic regression. Jour-<br />nal of Machine Learning Research, 9:627–650, 2008.<br />Neal, R. M.<br />Brooks, S., Gelman, A., Jones, G., and Meng, X.-L.<br />(eds.), Handbook of Markov Chain Monte Carlo. Chap-<br />man &amp; Hall / CRC Press, 2010.<br />MCMC using Hamiltonian dynamics. In<br />Robbins, H. and Monro, S. A stochastic approximation<br />method. Annals of Mathematical Statistics, 22(3):400–<br />407, 1951.<br />Robert, C. P. and Casella, G. Monte Carlo statistical meth-<br />ods. Springer Verlag, 2004.<br />Roberts, G. O. and Stramer, O. Langevin diffusions and<br />metropolis-hastings algorithms. Methodology and Com-<br />puting in Applied Probability, 4:337–357, 2002.</p>   </div> <div id="rgw20_56ab1c9d76a8a" class="c-box pub-resource-container js-toggle" style=""> <h4 class="lf js-expand-list"><small><a href="javascript:" class="lf">View other sources <span class="ico-expand-list"></span></a></small></h4> <h4 class="lf js-collapse-list hidden"><small><a href="javascript:" class="lf">Hide other sources <span class="ico-collapse-list"></span></a></small></h4> <div class="clear"></div> <div class="scroll-wrapper hidden"> <ul class="files-list c-list" id="rgw21_56ab1c9d76a8a">  <li class="c-list-item pub-resource-item"  data-type="fulltext" id="rgw22_56ab1c9d76a8a"> <span class="ico-pub"></span> <div class="file-content"> <div class="download"> <a href="http://www.ics.uci.edu/~welling/publications/papers/stoclangevin_v6.pdf" target="_blank" rel="nofollow" class="publication-viewer" title="Bayesian Learning via Stochastic Gradient Langevin Dynamics">Bayesian Learning via Stochastic Gradient Langevin...</a> </div>  <div class="details">   Available from <a href="http://www.ics.uci.edu/~welling/publications/papers/stoclangevin_v6.pdf" target="_blank" rel="nofollow">uci.edu</a>  </div>    </div> </li>  </ul> </div> </div> </noscript> <div class="clearfix"> <div class="action-container">  </div> <div class="pub-legal"> Data provided are for informational purposes only. Although carefully collected, accuracy cannot be guaranteed. The impact factor represents a rough estimation of the journal's impact factor and does not reflect the actual current impact factor. Publisher conditions are provided by RoMEO. Differing provisions from the publisher's actual policy or licence agreement may be applicable. </div>  <div id="rgw29_56ab1c9d76a8a" class="citations-container"> <div class="tab-container"> <ul class="tab-list"> <li class="lf tab-item  js-citations"> <a href="javascript:void(0);" class="tab-link"> References  </small> </a> </li>  <li class="lf tab-item tab-item-active js-cited-in js-cited-in-tooltip"> <a href="javascript:void(0);" class="tab-link"> Cited In <small> (49) </small> </a> </li>    <li class="rf"> <div class="dropdown js-citations-sorter dropdown-right-align" style="position: relative; bottom: -1px;display:none;"> <a href="javascript:void(0);" class="dropdown-toggle"> Sorted by: <strong class="js-current-sorting"> Order of availability  </strong> <span class="caret"></span> </a> <ul class="dropdown-menu"> <li><a href="javascript:void(0);" data-sort="normal">Order of availability</a></li> <li><a href="javascript:void(0);" data-sort="original">Appearance in publication</a></li> </ul> </div> </li>  </ul> <div class="tab-section tab-section-active js-citations-list-container"> <div id="rgw30_56ab1c9d76a8a" class="pub-citations-list">  <ul class="c-list">  <li class="c-list-item li-publication   includes-citation-list"  id="rgw31_56ab1c9d76a8a" >  <div class="indent-left">  <div id="rgw32_56ab1c9d76a8a" class="js-publication-item-fulltext fulltext-thumb">    <a class="publication-preview ga-publication-viewer js-publication-item-fulltext-content" href="publication/288713780_Bridging_the_Gap_between_Stochastic_Gradient_MCMC_and_Stochastic_Optimization">       </a>   <div class="preview-source-info"> <a class="details js-show-source ga-source-url" href="deref/http%3A%2F%2Fde.arxiv.org%2Fpdf%2F1512.07962" target="_blank" >Source</a>  <div class="tooltip-content" style="display: none"> Available from: de.arxiv.org </div> </div>   </div>  </div>  <div class="indent-right">      </div>  <ul class="citation-contexts" id="rgw33_56ab1c9d76a8a">  <li class="citation-context-item"> "The SG-MCMC analog to this is SGLD, with updates θ t = θ t−1 − η t ˜ f t−1 (θ) + √ 2η t ζ t . The additional term is a standard normal random vector, ζ t ∼ N (0, I p ) (Welling and Teh, 2011). The SGLD method draws approximate posterior samples instead of obtaining a local minima. " </li>  </ul>   <div  style="margin-top: -2px">  <h5 class="pub-type-and-title">  <span class="publication-type">Article:</span>    <a class="js-publication-title-link js-go-to-publication ga-publication-item" href="publication/288713780_Bridging_the_Gap_between_Stochastic_Gradient_MCMC_and_Stochastic_Optimization"> <span class="publication-title js-publication-title">Bridging the Gap between Stochastic Gradient MCMC and Stochastic Optimization</span> </a>     </h5>  </div>    <div class="authors">     <a href="researcher/2075738569_Changyou_Chen" class="authors js-author-name ga-publications-authors">Changyou Chen</a> &middot;     <a href="researcher/71191078_David_Carlson" class="authors js-author-name ga-publications-authors">David Carlson</a> &middot;     <a href="researcher/2075686701_Zhe_Gan" class="authors js-author-name ga-publications-authors">Zhe Gan</a> &middot;     <a href="researcher/2081618664_Chunyuan_Li" class="authors js-author-name ga-publications-authors">Chunyuan Li</a> &middot;     <a href="researcher/10135830_Lawrence_Carin" class="authors js-author-name ga-publications-authors">Lawrence Carin</a>      </div>        <div class="abstract"> <span class="shorten"> <a href="javascript:" class="js-toggle-abstract">[Show abstract]</a> </span> <span class="full"> <a href="javascript:" class="js-toggle-abstract">[Hide abstract]</a><br/>  <strong>ABSTRACT:</strong> Stochastic gradient Markov chain Monte Carlo (SG-MCMC) methods are Bayesian
analogs to popular stochastic optimization methods; however, this connection is
not well studied. We explore this relationship by applying simulated annealing
to an SGMCMC algorithm. Furthermore, we extend recent SG-MCMC methods with two
key components: i) adaptive preconditioners (as in ADAgrad or RMSprop), and ii)
adaptive element-wise momentum weights. The zero-temperature limit gives a
novel stochastic optimization method with adaptive element-wise momentum
weights, while conventional optimization methods only have a shared, static
momentum weight. Under certain assumptions, our theoretical analysis suggests
the proposed simulated annealing approach converges close to the global optima.
Experiments on several deep neural network models show state-of-the-art results
compared to related stochastic optimization algorithms. </span> </div>    <div class="publication-meta publication-meta">  <span class="ico-publication-preview reset-background"></span> Preview    &middot; Article &middot; Dec 2015  </div>        <div class="publication-actions"> <div class="btn-group">  <a class="btn btn-plain action-request-external  " href="javascript:;" data-context="pubCit">  <span class="js-btn-label">Request full-text</span> </a>    </div> </div>      </li>  <li class="c-list-item li-publication   includes-citation-list"  id="rgw34_56ab1c9d76a8a" >  <div class="indent-left">  <div id="rgw35_56ab1c9d76a8a" class="js-publication-item-fulltext fulltext-thumb">    <a class="publication-preview ga-publication-viewer js-publication-item-fulltext-content" href="publication/288059869_Preconditioned_Stochastic_Gradient_Langevin_Dynamics_for_Deep_Neural_Networks">       </a>   <div class="preview-source-info"> <a class="details js-show-source ga-source-url" href="deref/http%3A%2F%2Fde.arxiv.org%2Fpdf%2F1512.07666" target="_blank" >Source</a>  <div class="tooltip-content" style="display: none"> Available from: de.arxiv.org </div> </div>   </div>  </div>  <div class="indent-right">      </div>  <ul class="citation-contexts" id="rgw36_56ab1c9d76a8a">  <li class="citation-context-item"> "Traditional MCMC methods use the full dataset, which does not scale to large data problems. A pioneering work in combining stochastic optimization with MCMC was presented in (Welling and Teh 2011), based on Langevin dynamics (Neal 2011). This method was referred to as Stochastic Gradient Langevin Dynamics (SGLD), and required only the gradient on mini-batches of data. " </li>  </ul>   <div  style="margin-top: -2px">  <h5 class="pub-type-and-title">  <span class="publication-type">Article:</span>    <a class="js-publication-title-link js-go-to-publication ga-publication-item" href="publication/288059869_Preconditioned_Stochastic_Gradient_Langevin_Dynamics_for_Deep_Neural_Networks"> <span class="publication-title js-publication-title">Preconditioned Stochastic Gradient Langevin Dynamics for Deep Neural Networks</span> </a>     </h5>  </div>    <div class="authors">     <a href="researcher/2081618664_Chunyuan_Li" class="authors js-author-name ga-publications-authors">Chunyuan Li</a> &middot;     <a href="researcher/2075738569_Changyou_Chen" class="authors js-author-name ga-publications-authors">Changyou Chen</a> &middot;     <a href="researcher/71191078_David_Carlson" class="authors js-author-name ga-publications-authors">David Carlson</a> &middot;     <a href="researcher/10135830_Lawrence_Carin" class="authors js-author-name ga-publications-authors">Lawrence Carin</a>      </div>        <div class="abstract"> <span class="shorten"> <a href="javascript:" class="js-toggle-abstract">[Show abstract]</a> </span> <span class="full"> <a href="javascript:" class="js-toggle-abstract">[Hide abstract]</a><br/>  <strong>ABSTRACT:</strong> Effective training of deep neural networks suffers from two main issues. The
first is that the parameter spaces of these models exhibit pathological
curvature. Recent methods address this problem by using adaptive
preconditioning for Stochastic Gradient Descent (SGD). These methods improve
convergence by adapting to the local geometry of parameter space. A second
issue is overfitting, which is typically addressed by early stopping. However,
recent work has demonstrated that Bayesian model averaging mitigates this
problem. The posterior can be sampled by using Stochastic Gradient Langevin
Dynamics (SGLD). However, the rapidly changing curvature renders default SGLD
methods inefficient. Here, we propose combining adaptive preconditioners with
SGLD. In support of this idea, we give theoretical properties on asymptotic
convergence and predictive risk. We also provide empirical results for Logistic
Regression, Feedforward Neural Nets, and Convolutional Neural Nets,
demonstrating that our preconditioned SGLD method gives state-of-the-art
performance on these models. </span> </div>    <div class="publication-meta publication-meta">  <span class="ico-publication-preview reset-background"></span> Preview    &middot; Article &middot; Dec 2015  </div>        <div class="publication-actions"> <div class="btn-group">  <a class="btn btn-plain action-request-external  " href="javascript:;" data-context="pubCit">  <span class="js-btn-label">Request full-text</span> </a>    </div> </div>      </li>  <li class="c-list-item li-publication   includes-citation-list"  id="rgw37_56ab1c9d76a8a" >  <div class="indent-left">  <div id="rgw38_56ab1c9d76a8a" class="js-publication-item-fulltext fulltext-thumb">    <a class="publication-preview ga-publication-viewer js-publication-item-fulltext-content" href="publication/283043210_A_General_Method_for_Robust_Bayesian_Modeling">       </a>   <div class="preview-source-info"> <a class="details js-show-source ga-source-url" href="deref/http%3A%2F%2Fde.arxiv.org%2Fpdf%2F1510.05078" target="_blank" >Source</a>  <div class="tooltip-content" style="display: none"> Available from: de.arxiv.org </div> </div>   </div>  </div>  <div class="indent-right">      </div>  <ul class="citation-contexts" id="rgw39_56ab1c9d76a8a">  <li class="citation-context-item"> "We use a model to encode the types of patterns we want to discover in the data—either to predict about future data or explore existing data—and then use a posterior inference algorithm to uncover the realization of those patterns that underlie the observations. Innovations in scalable inference allow us to use Bayesian models to analyze massive data (Hoffman et al., 2013; Welling and Teh, 2011; Ahn et al., 2012; Xing et al., 2013); innovations in generic inference allow us to easily explore a wide variety of models (Ranganath et al., 2014; Wood et al., 2014; Hoffman and Gelman, 2014). Consequently, modern Bayesian modeling has had an impact on many fields, including natural language processing (Teh, 2006), computer vision (Fei-Fei and Perona, 2005), the natural sciences (Pritchard et al., 2000), and the social sciences (Grimmer, 2009). " </li>  </ul>   <div  style="margin-top: -2px">  <h5 class="pub-type-and-title">  <span class="publication-type">Article:</span>    <a class="js-publication-title-link js-go-to-publication ga-publication-item" href="publication/283043210_A_General_Method_for_Robust_Bayesian_Modeling"> <span class="publication-title js-publication-title">A General Method for Robust Bayesian Modeling</span> </a>     </h5>  </div>    <div class="authors">     <a href="researcher/2083133647_Chong_Wang" class="authors js-author-name ga-publications-authors">Chong Wang</a> &middot;     <a href="researcher/2064238818_David_M_Blei" class="authors js-author-name ga-publications-authors">David M. Blei</a>      </div>        <div class="abstract"> <span class="shorten"> <a href="javascript:" class="js-toggle-abstract">[Show abstract]</a> </span> <span class="full"> <a href="javascript:" class="js-toggle-abstract">[Hide abstract]</a><br/>  <strong>ABSTRACT:</strong> Robust Bayesian models are appealing alternatives to standard models,
providing protection from data that contains outliers or other departures from
the model assumptions. Historically, robust models were mostly developed on a
case-by-case basis; examples include robust linear regression, robust mixture
models, and bursty topic models. In this paper we develop a general approach to
robust Bayesian modeling. We show how to turn an existing Bayesian model into a
robust model, and then develop a generic strategy for computing with it. We use
our method to study robust variants of several models, including linear
regression, Poisson regression, logistic regression, and probabilistic topic
models. We discuss the connections between our methods and existing approaches,
especially empirical Bayes and James-Stein estimation. </span> </div>    <div class="publication-meta publication-meta">  <span class="ico-publication-preview reset-background"></span> Preview    &middot; Article &middot; Oct 2015  </div>        <div class="publication-actions"> <div class="btn-group">  <a class="btn btn-plain action-request-external  " href="javascript:;" data-context="pubCit">  <span class="js-btn-label">Request full-text</span> </a>    </div> </div>      </li>  </ul>    <a class="show-more-rebranded js-show-more rf text-gray-lighter">Show more</a> <span class="ajax-loading-small list-loading" style="display: none"></span>  <div class="clearfix"></div>  <div class="publication-detail-sidebar-legal">Note: This list is based on the publications in our database and might not be exhaustive.</div> <div class="clearfix"></div>  </div> </div> </div> </div> </div> </div> <div class="clearfix">     <div id="rgw24_56ab1c9d76a8a" class="c-box pub-resource-container js-toggle" style="display: none;"> <h4 class="lf js-expand-list"><small><a href="javascript:" class="lf">View other sources <span class="ico-expand-list"></span></a></small></h4> <h4 class="lf js-collapse-list hidden"><small><a href="javascript:" class="lf">Hide other sources <span class="ico-collapse-list"></span></a></small></h4> <div class="clear"></div> <div class="scroll-wrapper hidden"> <ul class="files-list c-list" id="rgw25_56ab1c9d76a8a">  </ul> </div> </div>   <div id="rgw16_56ab1c9d76a8a" class="similar-publications"> <h2>Similar Publications</h2> <ul class="list-bordered">  <li class="c-list-item li-publication-teaser" id="rgw17_56ab1c9d76a8a"> <div> <h5> <a href="publication/286412971_Fast_fire_flame_detection_in_surveillance_video_using_logistic_regression_and_temporal_smoothing" class="color-inherit ga-similar-publication-title"><span class="publication-title">Fast fire flame detection in surveillance video using logistic regression and temporal smoothing</span></a>  </h5>  <div class="authors"> <a href="researcher/2088072251_Seong_G_Kong" class="authors ga-similar-publication-author">Seong G. Kong</a>, <a href="researcher/2088087152_Donglin_Jin" class="authors ga-similar-publication-author">Donglin Jin</a>, <a href="researcher/69630502_Shengzhe_Li" class="authors ga-similar-publication-author">Shengzhe Li</a>, <a href="researcher/69776835_Hakil_Kim" class="authors ga-similar-publication-author">Hakil Kim</a>  </div>  </div> <div class="clear"></div> </li>  <li class="c-list-item li-publication-teaser" id="rgw18_56ab1c9d76a8a"> <div> <h5> <a href="publication/292077828_Maximum_Likelihood_and_Firth_Logistic_Regression_of_the_Pedestrian_Route_Choice" class="color-inherit ga-similar-publication-title"><span class="publication-title">Maximum Likelihood and Firth Logistic Regression of the Pedestrian Route Choice</span></a>  </h5>  <div class="authors"> <a href="researcher/2096006898_T-H_T_Gim" class="authors ga-similar-publication-author">T.-H. T. Gim</a>, <a href="researcher/2096044027_Joonho_Ko" class="authors ga-similar-publication-author">Joonho Ko</a>  </div>  </div> <div class="clear"></div> </li>  <li class="c-list-item li-publication-teaser" id="rgw19_56ab1c9d76a8a"> <div> <h5> <a href="publication/283336374_Longitudinal_predictors_of_cyberbullying_perpetration_Evidence_from_Korean_middle_school_students" class="color-inherit ga-similar-publication-title"><span class="publication-title">Longitudinal predictors of cyberbullying perpetration: Evidence from Korean middle school students</span></a>  </h5>  <div class="authors"> <a href="researcher/79847105_Sukkyung_You" class="authors ga-similar-publication-author">Sukkyung You</a>, <a href="researcher/2072009586_Sun_Ah_Lim" class="authors ga-similar-publication-author">Sun Ah Lim</a>  </div>  </div> <div class="clear"></div> </li>  </ul> </div> </div> </div> </div> </div></div></div>
<div class="clear"></div><div id="rgw41_56ab1c9d76a8a" class="default-footer"> <div id="footer" class="clearfix"> <span class="footer-left"> &copy; 2008&dash;2016 researchgate.net. All rights reserved. </span> <span class="footer-right"> <a href="https://www.researchgate.net/about">About us</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="https://www.researchgate.net/contact">Contact us</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="careers">Careers</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="developers">Developers</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="blog" target="_blank">News</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="application.PrivacyPolicy.html">Privacy</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="application.TermsAndConditions.html">Terms</a> <span class="footer-link-separator" style="padding: 0 5px;">&nbsp;|&nbsp;</span> <a href="advertising?_ref=ft">Advertising</a> <span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="recruiters?_ref=ft">Recruiting</a> </span> </div>  </div></div>
<div id="rgw42_56ab1c9d76a8a">  <div class="header-wrapper-logged-out"> <div id="header"> <div class="header-content"> <a href="" class="g-l-logo"> <svg width="149" height="19"> <image xlink:href="https://c5.rgstatic.net/m/235107188705592/images/template/brand-header-logo.svg" src="https://c5.rgstatic.net/m/238113351022438/images/template/brand-header-logo.png" width="149" height="19"/> </svg> </a> <a href="" class="g-l-logo-ico"> <svg width="127" height="17" viewbox="0 0 127 22"> <image xlink:href="https://c5.rgstatic.net/m/235107188705592/images/template/brand-header-logo.svg" src="https://c5.rgstatic.net/m/238113351022438/images/template/brand-header-logo.png" width="127" height="17"/> </svg> </a> <div id="rgw43_56ab1c9d76a8a" class="header-login-wrapper js-header-login"> <div class="dropdown-right-align"> <div class="login-signup-container lf"> <a href="https://www.researchgate.net/signup.SignUp.html?ev=su_chnl_index&amp;hdrsu=1&amp;_sg=-m7qnoq5EgZthpQBAlFhJzA_de8uUbUJ22e1kmwAg4r_035u3SlNszcbTPMhcRfz" class="dropdown-toggle lf">Join for free</a> </div> <div class="dropdown lf" style="height: 20px;"> <a href="https://www.researchgate.net/application.Login.html" class="js-login-url dropdown-toggle lf">Log in <span class="caret"></span></a> <div class="dropdown-menu"> <div class="header-login-form-wrapper"> <!--[if IE 6]><p class="box-warning" style="margin-bottom: 0;">Sorry, ResearchGate no longer supports the version of Internet Explorer you are using. <a href="http://whatbrowser.org/" rel="nofollow" target="_blank">Update your web browser</a> and then log in. </p><![endif]--> <form method="post" action="https://www.researchgate.net/application.Login.html" class="form-big header-login-form js-login-form" name="loginForm" id="headerLoginForm"> <input type="hidden" name="request_token" value="i80VxJZASMCFSiP+5NpiW+Ixi4RLinBshEKe2cWTEca/uxBaaYmJ4QEO3QIkBmqAl9v8Z7LHPI6WoDoPMsmjy+3ug27Fu5RRAhWaLfcRFGdd2BB0xUt4noyhbZD8rW4OC41Fhg5yi+peNfLwHPMp36lCyFocHoqo3xQZE2Or5CInRlI9fVUsLf5DdQNL0OIuMSCStpFr8aKJeM7jxIfpk8IQB77WY0yzvDVaElpGbLJQzZdb6GB7CRLYlyy67yNVASmG4/ccHiB20h7GuB/q59F9kxmYo/IQRXqIdY56gas="/> <input type="hidden" name="urlAfterLogin" value="publication/221346425_Bayesian_Learning_via_Stochastic_Gradient_Langevin_Dynamics"/> <input type="hidden" name="invalidPasswordCount" value="0"/> <input type="hidden" name="headerLogin" value="yes"/> <label for="input-header-login">Email</label> <div class="login-input"> <div class="info-tip-wrapper"> <span class="ico-info js-info"></span> </div> <input type="email" value="" name="login" class="login js-login-input text" id="input-header-login" tabindex="1"/> </div> <div class="clear"></div> <label class="lf" for="input-header-password"> Password </label> <a class="rf forgot-password js-forgot-password" href="application.LostPassword.html">Forgot password?</a> <div class="clear"></div> <input type="password" value="" name="password" class="password js-password-input text" id="input-header-password" tabindex="2"/> <div class="clear"></div> <label class="remember-me" for="headerLoginCookie"> <input type="checkbox" checked="checked" value="yes" name="setLoginCookie" class="lf checkbox" id="headerLoginCookie" tabindex="3"/> Keep me logged in </label> <div class="clear"></div> <input value="Log in" name="loginSubmit" class="btn btn-promote btn-fullwidth btn-large allow-leave js-submit-button" type="submit" tabindex="4"/> </form> <div class="connectors"> <div class="text">or log in with</div> <div class="connector-actions"> <a href="connector/linkedin/" class="li-connect js-li-connect" data-redirect-url="cHVibGljYXRpb24vMjIxMzQ2NDI1X0JheWVzaWFuX0xlYXJuaW5nX3ZpYV9TdG9jaGFzdGljX0dyYWRpZW50X0xhbmdldmluX0R5bmFtaWNz"> <span class="icon ico-linkedin-round-grey"></span> <span class="icon ico-linkedin-round"></span> </a> <a href="connector/facebook/" class="fb-connect middle js-fb-connect" data-redirect-url="cHVibGljYXRpb24vMjIxMzQ2NDI1X0JheWVzaWFuX0xlYXJuaW5nX3ZpYV9TdG9jaGFzdGljX0dyYWRpZW50X0xhbmdldmluX0R5bmFtaWNz"> <span class="icon ico-facebook-round-grey"></span> <span class="icon ico-facebook-round"></span> </a> <a href="connector/google/" class="g-connect js-g-connect" data-redirect-url="cHVibGljYXRpb24vMjIxMzQ2NDI1X0JheWVzaWFuX0xlYXJuaW5nX3ZpYV9TdG9jaGFzdGljX0dyYWRpZW50X0xhbmdldmluX0R5bmFtaWNz"> <span class="icon ico-google-round-grey"></span> <span class="icon ico-google-round"></span> </a> </div> </div> </div> </div> </div> </div> </div> </div> </div> <script type="application/ld+json">
{ "@context" : "http://schema.org",
  "@type" : "Organization",
  "name" : "ResearchGate",
  "url" : "http://www.researchgate.net",
  "logo" : "http://www.researchgate.net/images/template/rg_logo_square_brand.png",
  "sameAs" : [ "https://www.facebook.com/ResearchGate",
    "https://twitter.com/ResearchGate",
    "https://plus.google.com/+researchgate",
    "https://www.linkedin.com/company/researchgate"] 
}
</script> </div> </div><div class="c-signup-bar" id="rgw44_56ab1c9d76a8a"> <div class="banner-contents">   <span class="message">ResearchGate is the professional network for scientists and researchers.</span> <a href="signup.SignUp.html?ev=su_banner" class="btn btn-large btn-promote">Join for free</a>  </div> </div></div>
<script>
rgConfig.backendTime = 489;
</script>
<script src="//c5.rgstatic.net/m/2277196935388619/javascript/lib/yui3/yui/yui-min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/2448732603281275/javascript/yuiLoaderConfig-min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/23178613132105398/javascript/vendor/babel-core/browser-polyfill.min.js" type="text/javascript"></script>
<script>
(function (){
if (typeof YRG === "undefined") {
var xmlHttpRequest = new XMLHttpRequest();
xmlHttpRequest.open("post", "go.Error.html");
xmlHttpRequest.setRequestHeader("Content-Type", "application/json");
xmlHttpRequest.setRequestHeader("Accept", "application/json"); var loadedScripts = "";
if (window.performance && window.performance.getEntriesByType) {
    var result = [];
    var resources = performance.getEntriesByType("resource");
    for (var i in resources) {
        if (resources.hasOwnProperty(i)) {
            result.push({
                name: resources[i].name,
                duration: resources[i].duration
            });
        }
    }
    loadedScripts += "&loadedScripts=" + encodeURIComponent(JSON.stringify(result));
}
if (typeof YUI === "undefined") {
    loadedScripts += "&yuiLoaded=false";
} else {
    loadedScripts += "&yuiLoaded=true";
}
xmlHttpRequest.send("Type=InformationException&message=" + encodeURIComponent("Error loading YUI") + loadedScripts);
}
})();
</script>
<script>if (typeof YRG !== 'undefined') { YRG.use('rg-base',function(Y){Y.applyConfig({ignore: ["css-rg","css-rg2","css-ie","css-modules-publicprofile"]});Y.use(["rg.core.pagespeed.Monitoring"],function(Y){(function(){Y.rg.createInitialWidget({"data":{"content":{"data":{"profileSmallHeader":{"data":{"profileBadge":{"data":{"profileUrl":"researcher\/69847505_Max_Welling","fullname":"Max Welling","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2549355721578\/images\/template\/default\/profile\/profile_default_m.png","profileStats":[{"data":{"impactPoints":"28.03","widgetId":"rgw5_56ab1c9d76a8a"},"id":"rgw5_56ab1c9d76a8a","partials":[],"templateName":"publicliterature\/stubs\/PublicLiteratureAuthorImpactPoints.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicLiteratureAuthorImpactPoints.html?authorUid=69847505","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"publicationCount":88,"widgetId":"rgw6_56ab1c9d76a8a"},"id":"rgw6_56ab1c9d76a8a","partials":[],"templateName":"publicliterature\/stubs\/PublicLiteratureAuthorPublicationCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicLiteratureAuthorPublicationCount.html?authorUid=69847505","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"followerCount":1,"widgetId":"rgw7_56ab1c9d76a8a"},"id":"rgw7_56ab1c9d76a8a","partials":[],"templateName":"publicliterature\/stubs\/PublicLiteratureAuthorFollowerCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicLiteratureAuthorFollowerCount.html?authorUid=69847505","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"widgetId":"rgw4_56ab1c9d76a8a"},"id":"rgw4_56ab1c9d76a8a","partials":[],"templateName":"publicprofile\/stubs\/ProfileBadge.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicLiteratureAuthorBadge.html?authorUid=69847505","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw3_56ab1c9d76a8a"},"id":"rgw3_56ab1c9d76a8a","partials":[],"templateName":"publicprofile\/stubs\/ProfileSmallHeader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicprofile.ProfileSmallHeader.html?publicationUid=221346425","viewClass":null,"yuiModules":["css-modules-publicprofile"],"stylesheets":["modules\/publicprofile.css"],"_isYUI":true},"publication":{"data":{"publicationUid":221346425,"title":"Bayesian Learning via Stochastic Gradient Langevin Dynamics","journalTitle":false,"journalDetailsTooltip":false,"affiliation":false,"type":"Conference Paper","details":{"conferenceInfos":"Conference: Proceedings of the 28th International Conference on Machine Learning, ICML 2011, Bellevue, Washington, USA, June 28 - July 2, 2011"},"source":{"sourceUrl":"http:\/\/dblp.uni-trier.de\/db\/conf\/icml\/icml2011.html#WellingT11","sourceName":"DBLP"},"publicationActions":null,"publicationCoins":{"data":{"tags":[{"key":"ctx_ver","value":"Z39.88-2004"},{"key":"rft_val_fmt","value":"info:ofi\/fmt:kev:mtx:journal"},{"key":"rfr_id","value":"info:sid\/researchgate.net:researchgate"},{"key":"rft.atitle","value":"Bayesian Learning via Stochastic Gradient Langevin Dynamics"},{"key":"rft.date","value":"2011"},{"key":"rft.pages","value":"681-688"},{"key":"rft.au","value":"Max Welling,Yee Whye Teh"},{"key":"rft.genre","value":"inProceedings"}],"widgetId":"rgw9_56ab1c9d76a8a"},"id":"rgw9_56ab1c9d76a8a","partials":[],"templateName":"publicliterature\/stubs\/PublicationCoins.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationCoins.html?publicationUid=221346425","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationAuthors":{"data":{"publicationUid":221346425,"peopleItems":[{"data":{"authorUrl":"researcher\/69847505_Max_Welling","authorNameOnPublication":"Max Welling","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg","imageSize":"s","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Max Welling","profile":{"professionalInstitution":{"professionalInstitutionName":false,"professionalInstitutionUrl":null}},"professionalInstitutionName":false,"professionalInstitutionUrl":null,"url":"researcher\/69847505_Max_Welling","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":true,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":false,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"widgetId":"rgw12_56ab1c9d76a8a"},"id":"rgw12_56ab1c9d76a8a","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAuthorItem.html?entityId=69847505&imageSize=l&enableAuthorInviteButton=0","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"largeTooltip":false,"useRebrandedImageStyle":null,"widgetId":"rgw11_56ab1c9d76a8a"},"id":"rgw11_56ab1c9d76a8a","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorItem.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorItem.html?authorUid=69847505&authorNameOnPublication=Max%20Welling","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true},{"data":{"authorUrl":"researcher\/9164246_Yee_Whye_Teh","authorNameOnPublication":"Yee Whye Teh","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg","imageSize":"s","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Yee Whye Teh","profile":{"professionalInstitution":{"professionalInstitutionName":false,"professionalInstitutionUrl":null}},"professionalInstitutionName":false,"professionalInstitutionUrl":null,"url":"researcher\/9164246_Yee_Whye_Teh","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":true,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":false,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"widgetId":"rgw14_56ab1c9d76a8a"},"id":"rgw14_56ab1c9d76a8a","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAuthorItem.html?entityId=9164246&imageSize=l&enableAuthorInviteButton=0","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"largeTooltip":false,"useRebrandedImageStyle":null,"widgetId":"rgw13_56ab1c9d76a8a"},"id":"rgw13_56ab1c9d76a8a","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorItem.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorItem.html?authorUid=9164246&authorNameOnPublication=Yee%20Whye%20Teh","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true}],"hasMore":false,"nextOffset":6,"useRebrandedImageStyle":null,"widgetId":"rgw10_56ab1c9d76a8a"},"id":"rgw10_56ab1c9d76a8a","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorList.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorList.html?publicationUid=221346425&context=pubdetail_authors_xflw&showContactAuthorButton=1","viewClass":"views.publicliterature.PublicationDetailAuthorListView","yuiModules":["rg.views.publicliterature.PublicationDetailAuthorListView"],"stylesheets":[],"_isYUI":true},"publicationAbstract":{"data":{"publicationUid":221346425,"abstract":"<noscript><\/noscript><div>In this paper we propose a new framework for learning from large scale datasets based on iterative learning from small mini-batches. By adding the right amount of noise to a standard stochastic gradient optimization algorithm we show that the iterates will converge to samples from the true posterior distribution as we anneal the stepsize. This seamless transition between optimization and Bayesian posterior sampling provides an inbuilt protection against overfitting. We also propose a practical method for Monte Carlo estimates of posterior statistics which monitors a &ldquo;sampling threshold &rdquo; and collects samples after it has been surpassed. We apply the method to three models: a mixture of Gaussians, logistic regression and ICA with natural gradients. 1.<\/div>","canEdit":false,"isAdmin":false,"isArtifact":false,"showFullAbstract":true,"widgetId":"rgw15_56ab1c9d76a8a"},"id":"rgw15_56ab1c9d76a8a","partials":[],"templateName":"publicliterature\/stubs\/PublicationAbstract.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationAbstract.html?publicationUid=221346425","viewClass":"views.publicliterature.PublicationAbstractView","yuiModules":["rg.views.publicliterature.PublicationAbstractView"],"stylesheets":[],"_isYUI":true},"publicationKeywords":null,"publicationState":null,"isGuest":true,"isAdminEditingAllowed":false,"isArtifact":false,"figureListWidget":null,"previewImage":"https:\/\/i1.rgstatic.net\/publication\/221346425_Bayesian_Learning_via_Stochastic_Gradient_Langevin_Dynamics\/links\/0ffd5c240cf255165fca9437\/smallpreview.png","nativeAdDisclosure":null,"showFollowPublicationButton":false,"followPublicationPromo":"","widgetId":"rgw8_56ab1c9d76a8a"},"id":"rgw8_56ab1c9d76a8a","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailItem.html","templateExtensions":["generalHelpers"],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailItem.html?publicationUid=221346425&showActionBar=0&showContactAuthorButton=1&showRequestFulltextExperience=0&showNoRgAuthorsRequestFulltextExperience=0&showFollowPublicationPromo=0","viewClass":"views.publicliterature.PublicationDetailItemView","yuiModules":["rg.views.publicliterature.PublicationDetailItemView"],"stylesheets":[],"_isYUI":true},"similarPublications":{"data":{"publicationListItems":[{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore","clickThrough":"experimentMilestoneClickedToPublicationFromReferenceWithNoFulltext","clickThroughWithContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":2088072251,"url":"researcher\/2088072251_Seong_G_Kong","fullname":"Seong G. Kong","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2088087152,"url":"researcher\/2088087152_Donglin_Jin","fullname":"Donglin Jin","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":69630502,"url":"researcher\/69630502_Shengzhe_Li","fullname":"Shengzhe Li","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":69776835,"url":"researcher\/69776835_Hakil_Kim","fullname":"Hakil Kim","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Jan 2016","journal":"Fire Safety Journal","showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/286412971_Fast_fire_flame_detection_in_surveillance_video_using_logistic_regression_and_temporal_smoothing","usePlainButton":true,"publicationUid":286412971,"feedStubs":null,"hasFeedStubs":false,"impactPoints":"0.96","url":"publication\/286412971_Fast_fire_flame_detection_in_surveillance_video_using_logistic_regression_and_temporal_smoothing","title":"Fast fire flame detection in surveillance video using logistic regression and temporal smoothing","displayTitleAsLink":true,"authors":[{"id":2088072251,"url":"researcher\/2088072251_Seong_G_Kong","fullname":"Seong G. Kong","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2088087152,"url":"researcher\/2088087152_Donglin_Jin","fullname":"Donglin Jin","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":69630502,"url":"researcher\/69630502_Shengzhe_Li","fullname":"Shengzhe Li","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":69776835,"url":"researcher\/69776835_Hakil_Kim","fullname":"Hakil Kim","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["Fire Safety Journal 01\/2016; 79:37-43. DOI:10.1016\/j.firesaf.2015.11.015"],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/286412971_Fast_fire_flame_detection_in_surveillance_video_using_logistic_regression_and_temporal_smoothing","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/286412971_Fast_fire_flame_detection_in_surveillance_video_using_logistic_regression_and_temporal_smoothing\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw17_56ab1c9d76a8a"},"id":"rgw17_56ab1c9d76a8a","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=286412971","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore","clickThrough":"experimentMilestoneClickedToPublicationFromReferenceWithNoFulltext","clickThroughWithContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":2096006898,"url":"researcher\/2096006898_T-H_T_Gim","fullname":"T.-H. T. Gim","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2096044027,"url":"researcher\/2096044027_Joonho_Ko","fullname":"Joonho Ko","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Jan 2016","journal":"International Regional Science Review","showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/292077828_Maximum_Likelihood_and_Firth_Logistic_Regression_of_the_Pedestrian_Route_Choice","usePlainButton":true,"publicationUid":292077828,"feedStubs":null,"hasFeedStubs":false,"impactPoints":"0.73","url":"publication\/292077828_Maximum_Likelihood_and_Firth_Logistic_Regression_of_the_Pedestrian_Route_Choice","title":"Maximum Likelihood and Firth Logistic Regression of the Pedestrian Route Choice","displayTitleAsLink":true,"authors":[{"id":2096006898,"url":"researcher\/2096006898_T-H_T_Gim","fullname":"T.-H. T. Gim","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2096044027,"url":"researcher\/2096044027_Joonho_Ko","fullname":"Joonho Ko","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["International Regional Science Review 01\/2016;  DOI:10.1177\/0160017615626214"],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/292077828_Maximum_Likelihood_and_Firth_Logistic_Regression_of_the_Pedestrian_Route_Choice","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/292077828_Maximum_Likelihood_and_Firth_Logistic_Regression_of_the_Pedestrian_Route_Choice\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw18_56ab1c9d76a8a"},"id":"rgw18_56ab1c9d76a8a","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=292077828","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore","clickThrough":"experimentMilestoneClickedToPublicationFromReferenceWithNoFulltext","clickThroughWithContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":79847105,"url":"researcher\/79847105_Sukkyung_You","fullname":"Sukkyung You","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2072009586,"url":"researcher\/2072009586_Sun_Ah_Lim","fullname":"Sun Ah Lim","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Jan 2016","journal":"Personality and Individual Differences","showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/283336374_Longitudinal_predictors_of_cyberbullying_perpetration_Evidence_from_Korean_middle_school_students","usePlainButton":true,"publicationUid":283336374,"feedStubs":null,"hasFeedStubs":false,"impactPoints":"1.95","url":"publication\/283336374_Longitudinal_predictors_of_cyberbullying_perpetration_Evidence_from_Korean_middle_school_students","title":"Longitudinal predictors of cyberbullying perpetration: Evidence from Korean middle school students","displayTitleAsLink":true,"authors":[{"id":79847105,"url":"researcher\/79847105_Sukkyung_You","fullname":"Sukkyung You","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2072009586,"url":"researcher\/2072009586_Sun_Ah_Lim","fullname":"Sun Ah Lim","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["Personality and Individual Differences 01\/2016; 89:172-176. DOI:10.1016\/j.paid.2015.10.019"],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/283336374_Longitudinal_predictors_of_cyberbullying_perpetration_Evidence_from_Korean_middle_school_students","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/283336374_Longitudinal_predictors_of_cyberbullying_perpetration_Evidence_from_Korean_middle_school_students\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw19_56ab1c9d76a8a"},"id":"rgw19_56ab1c9d76a8a","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=283336374","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"viewClass":"sidebar","widgetId":"rgw16_56ab1c9d76a8a"},"id":"rgw16_56ab1c9d76a8a","partials":[],"templateName":"publicliterature\/stubs\/SimilarPublications.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.SimilarPublications.html?referencePublicationId=221346425&view=sidebar","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationFulltextPreview":null,"publicationResourcesFulltext":{"data":{"publicationUid":221346425,"publicationResourceList":{"data":{"publicationResourceItems":[{"data":{"publicationUid":221346425,"publicationType":"inProceedings","linkId":"0ffd5c240cf255165fca9437","fileName":"Bayesian Learning via Stochastic Gradient Langevin Dynamics","fileUrl":"http:\/\/www.ics.uci.edu\/~welling\/publications\/papers\/stoclangevin_v6.pdf","name":"uci.edu","nameUrl":"http:\/\/www.ics.uci.edu\/~welling\/publications\/papers\/stoclangevin_v6.pdf","canRemove":false,"fileIcon":"ico-pub","canPreview":true,"hasPublisherLink":null,"hasMetaData":true,"hide":false,"fulltext":"ico-pub","origin":"publication_list","isLastLink":true,"isUserLink":false,"widgetId":"rgw22_56ab1c9d76a8a"},"id":"rgw22_56ab1c9d76a8a","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceItem.html","templateExtensions":["generalHelpers"],"attrs":{"fileRequiredPublicationTypes":["code","coverPage","experimentFindings","method","negativeResults","presentation","rawData","researchProposal","workingPaper","artifact","dataset"]},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceItem.html?publicationUid=221346425&linkId=0ffd5c240cf255165fca9437&hide=0&disableJavascript=disableJavascript&useAlternativeTemplate=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"widgetId":"rgw21_56ab1c9d76a8a"},"id":"rgw21_56ab1c9d76a8a","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceList.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceList.html?publicationUid=221346425&limit=3&disableJavascript=disableJavascript&type=fulltextFile","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"resourceCount":1,"hidden":false,"showMore":false,"fulltext":true,"publicationDownloadCount":{"data":{"value":5,"valueFormatted":"5","widgetId":"rgw23_56ab1c9d76a8a"},"id":"rgw23_56ab1c9d76a8a","partials":[],"templateName":"publicliterature\/stubs\/PublicationDownloadCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDownloadCount.html?publicationUid=221346425","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw20_56ab1c9d76a8a"},"id":"rgw20_56ab1c9d76a8a","partials":[],"templateName":"publicliterature\/stubs\/PublicationResources.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResources.html?publicationUid=221346425&type=fulltextFile&disableJavascript=1","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationResourcesAttachments":{"data":{"publicationUid":221346425,"publicationResourceList":{"data":{"publicationResourceItems":[],"widgetId":"rgw25_56ab1c9d76a8a"},"id":"rgw25_56ab1c9d76a8a","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceList.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceList.html?publicationUid=221346425&limit=3&disableJavascript=disableJavascript&type=attachmentFile","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"resourceCount":0,"hidden":true,"showMore":false,"fulltext":false,"publicationDownloadCount":{"data":{"value":5,"valueFormatted":"5","widgetId":"rgw26_56ab1c9d76a8a"},"id":"rgw26_56ab1c9d76a8a","partials":[],"templateName":"publicliterature\/stubs\/PublicationDownloadCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDownloadCount.html?publicationUid=221346425","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw24_56ab1c9d76a8a"},"id":"rgw24_56ab1c9d76a8a","partials":[],"templateName":"publicliterature\/stubs\/PublicationResources.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResources.html?publicationUid=221346425&type=attachmentFile","viewClass":"views.publicliterature.PublicationResourcesView","yuiModules":["rg.views.publicliterature.PublicationResourcesView"],"stylesheets":[],"_isYUI":true},"publicationText":{"data":{"hide":false,"pages":[{"page":1,"text":"Bayesian Learning via Stochastic Gradient Langevin Dynamics\nMax Welling\nD. Bren School of Information and Computer Science, University of California, Irvine, CA 92697-3425, USA\nwelling@ics.uci.edu\nYee Whye Teh\nGatsby Computational Neuroscience Unit, UCL, 17 Queen Square, London WC1N 3AR, UK\nywteh@gatsby.ucl.ac.uk\nAbstract\nIn this paper we propose a new framework\nfor learning from large scale datasets based\non iterative learning from small mini-batches.\nBy adding the right amount of noise to a\nstandard stochastic gradient optimization al-\ngorithm we show that the iterates will con-\nverge to samples from the true posterior dis-\ntribution as we anneal the stepsize.\nseamless transition between optimization and\nBayesian posterior sampling provides an in-\nbuilt protection against overfitting. We also\npropose a practical method for Monte Carlo\nestimates of posterior statistics which moni-\ntors a \u201csampling threshold\u201d and collects sam-\nples after it has been surpassed. We apply\nthe method to three models: a mixture of\nGaussians, logistic regression and ICA with\nnatural gradients.\nThis\n1. Introduction\nIn recent years there has been an increasing amount\nof very large scale machine learning datasets, ranging\nfrom internet traffic and network data, computer vi-\nsion, natural language processing, to bioinformatics.\nMore and more advances in machine learning are now\ndriven by these large scale data, which offers the op-\nportunity to learn large and complex models for solv-\ning many useful applied problems. Recent successes\nin large scale machine learning have mostly been opti-\nmization based approaches. While there are sophisti-\ncated algorithms designed specifically for certain types\nof models, one of the most successful class of algo-\nrithms are stochastic optimization, or Robbins-Monro,\nalgorithms. These algorithms process small (mini-\nAppearing in Proceedings of the 28thInternational Con-\nference on Machine Learning, Bellevue, WA, USA, 2011.\nCopyright 2011 by the author(s)\/owner(s).\n)batches of data at each iteration, updating model\nparameters by taking small gradient steps in a cost\nfunction. Often these algorithms are run in an on-\nline setting, where the data batches are discarded af-\nter processing and only one pass through the data is\nperformed, reducing memory requirements drastically.\nOne class of methods \u201cleft-behind\u201d by the recent ad-\nvances in large scale machine learning are the Bayesian\nmethods. This has partially to do with the negative\nresults in Bayesian online parameter estimation (An-\ndrieu et al., 1999), but also the fact that each iteration\nof typical Markov chain Monte Carlo (MCMC) algo-\nrithms requires computations over the whole dataset.\nNevertheless, Bayesian methods are appealing in their\nability to capture uncertainty in learned parameters\nand avoid overfitting. Arguably with large datasets\nthere will be little overfitting.\nhave access to larger datasets and more computational\nresources, we become interested in building more com-\nplex models, so that there will always be a need to\nquantify the amount of parameter uncertainty.\nAlternatively, as we\nIn this paper, we propose a method for Bayesian learn-\ning from large scale datasets. Our method combines\nRobbins-Monro type algorithms which stochastically\noptimize a likelihood, with Langevin dynamics which\ninjects noise into the parameter updates in such a way\nthat the trajectory of the parameters will converge\nto the full posterior distribution rather than just the\nmaximum a posteriori mode. The resulting algorithm\nstarts off being similar to stochastic optimization, then\nautomatically transitions to one that simulates sam-\nples from the posterior using Langevin dynamics.\nIn Section 2 we introduce the two ingredients of our\nmethod: stochastic optimization and Langevin dy-\nnamics. Section 3 describes our algorithm and how\nit converges to the posterior distribution. Section 4\ndescribes a practical method of estimating when our\nalgorithm will transition from stochastic optimization\nto Langevin dynamics. Section 5 demonstrates our al-"},{"page":2,"text":"Stochastic Gradient Langevin Dynamics\ngorithm on a few models and Section 6 concludes.\n2. Preliminaries\nLet \u03b8 denote a parameter vector, with p(\u03b8) a prior\ndistribution, and p(x|\u03b8) the probability of data item\nx given our model parameterized by \u03b8. The posterior\ndistribution of a set of N data items X = {xi}N\nis: p(\u03b8|X) \u221d p(\u03b8)\u220fN\nthe likelihood terms constitute the cost function to\nbe optimized, and the task is to find the maximum\na posteriori (MAP) parameters \u03b8\u2217. A popular class\nof methods called stochastic optimization (Robbins &\nMonro, 1951) operates as follows. At each iteration t,\na subset of n data items Xt= {xt1,...,xtn} is given,\nand the parameters are updated as follows:\n(\nwhere \u03f5t is a sequence of step sizes.\nidea is that the gradient computed on the subset is\nused to approximate the true gradient over the whole\ndataset. Over multiple iterations the whole dataset\nis used and the noise in the gradient caused by using\nsubsets rather than the whole dataset averages out.\nFor large datasets where the subset gradient approx-\nimation is accurate enough, this can give significant\ncomputational savings over using the whole dataset to\ncompute gradients at each iteration.\ni=1\ni=1p(xi|\u03b8). In the optimization\nliterature the prior regularizes the parameters while\n\u2206\u03b8t=\u03f5t\n2\n\u2207logp(\u03b8t) +N\nn\nn\n\u2211\ni=1\n\u2207logp(xti|\u03b8t)\n)\n(1)\nThe general\nTo ensure convergence to a local maximum, in addition\nto other technical assumptions, a major requirement\nis for the step sizes to satisfy the property\n\u221e\n\u2211\nt=1\n\u03f5t= \u221e\n\u221e\n\u2211\nt=1\n\u03f52\nt< \u221e\n(2)\nIntuitively, the first constraint ensures that parameters\nwill reach the high probability regions no matter how\nfar away it was initialized to, while the second ensures\nthat the parameters will converge to the mode instead\nof just bouncing around it. Typically, step sizes \u03f5t=\na(b + t)\u2212\u03b3are decayed polynomially with \u03b3 \u2208 (0.5,1].\nThe issue with ML or MAP estimation, as stochas-\ntic optimization aims to do, is that they do not cap-\nture parameter uncertainty and can potentially overfit\ndata. The typical way in which Bayesian approaches\ncapture parameter uncertainty is via Markov chain\nMonte Carlo (MCMC) techniques (Robert & Casella,\n2004). In this paper we will consider a class of MCMC\ntechniques called Langevin dynamics (Neal, 2010). As\nbefore, these take gradient steps, but also injects Gaus-\nsian noise into the parameter updates so that they do\nnot collapse to just the MAP solution:\n\u2206\u03b8t=\u03f5\n2\n(\n\u2207logp(\u03b8t) +\nN\n\u2211\ni=1\n\u2207logp(xi|\u03b8t)\n)\n+ \u03b7t\n\u03b7t\u223c N(0,\u03f5)\nThe gradient step sizes and the variances of the in-\njected noise are balanced so that the variance of the\nsamples matches that of the posterior. Langevin dy-\nnamics is motivated and originally derived as a dis-\ncretization of a stochastic differential equation whose\nequilibrium distribution is the posterior distribution.\nTo correct for discretization error, one can take (3)\nto just be a proposal distribution and correct using\nMetropolis-Hastings. Interestingly, as we decrease \u03f5\nthe discretization error decreases as well so that the re-\njection rate approaches zero. However typical MCMC\npractice is to allow an initial adaptation phase where\nthe step sizes are adjusted, followed by fixing the step\nsizes to ensure a stationary Markov chain thereafter.\n(3)\nMore sophisticated techniques use Hamiltonian dy-\nnamics with momentum variables to allow parameters\nto move over larger distances without the inefficient\nrandom walk behaviour of Langevin dynamics (Neal,\n2010). However, to the extent of our knowledge all\nMCMC methods proposed thus far require computa-\ntions over the whole dataset at every iteration, result-\ning in very high computational costs for large datasets.\n3. Stochastic Gradient Langevin\nDynamics\nGiven the similarities between stochastic gradient al-\ngorithms (1) and Langevin dynamics (3), it is nat-\nural to consider combining ideas from the two ap-\nproaches. This allows efficient use of large datasets\nwhile allowing for parameter uncertainty to be cap-\ntured in a Bayesian manner. The approach is straight-\nforward: use Robbins-Monro stochastic gradients, add\nan amount of Gaussian noise balanced with the step\nsize used, and allow step sizes to go to zero. The pro-\nposed update is simply:\n(\n\u03b7t\u223c N(0,\u03f5t)\nwhere the step sizes decrease towards zero at rates sat-\nisfying (2). This allows averaging out of the stochastic-\nity in the gradients, as well as MH rejection rates that\ngo to zero asymptotically, so that we can simply ignore\nthe MH acceptance steps, which require evaluation of\nprobabilities over the whole dataset, all together.\n\u2206\u03b8t=\u03f5t\n2\n\u2207logp(\u03b8t) +N\nn\nn\n\u2211\ni=1\n\u2207logp(xti|\u03b8t)\n)\n+ \u03b7t\n(4)"},{"page":3,"text":"Stochastic Gradient Langevin Dynamics\nIn the rest of this section we will give an intuitive argu-\nment for why \u03b8twill approach samples from the pos-\nterior distribution as t \u2192 \u221e. In particular, we will\nshow that for large t, the updates (4) will approach\nLangevin dynamics (3), which converges to the poste-\nrior distribution. Let\ng(\u03b8) = \u2207logp(\u03b8) +\nN\n\u2211\ni=1\n\u2207logp(xi|\u03b8) (5)\nbe the true gradient of the log probability at \u03b8 and\nht(\u03b8) = \u2207logp(\u03b8) +N\nn\nn\n\u2211\ni=1\n\u2207logp(xti|\u03b8) \u2212 g(\u03b8) (6)\nThe stochastic gradient is then g(\u03b8)+ht(\u03b8), with ht(\u03b8)\na zero mean random variable (due to the stochasticity\nof the data items chosen at step t) with finite variance\nV (\u03b8), and (4) is,\n\u2206\u03b8t=\u03f5t\n2(g(\u03b8t) + ht(\u03b8t)) + \u03b7t,\u03b7t\u223c N(0,\u03f5t) (7)\nThere are two sources of stochasticity in (7): the in-\njected Gaussian noise with variance \u03f5t, and the noise in\nthe stochastic gradient, which has variance (\u03f5t\nThe first observation is that for large t, \u03f5t\u2192 0, and\nthe injected noise will dominate the stochastic gradient\nnoise, so that (7) will be effectively Langevin dynam-\nics (3). The second observation is that as \u03f5t \u2192 0,\nthe discretization error of Langevin dynamics will be\nnegligible so that the MH rejection probability will ap-\nproach 0 and we may simply ignore this step.\n2)2V (\u03b8t).\nIn other words, (4), (7) effectively define a non-\nstationary Markov chain such that the tth step tran-\nsition operator, for all large t, will have as its equilib-\nrium distribution the posterior over \u03b8. The next ques-\ntion we address is whether the sequence of parameters\n\u03b81,\u03b82,... will converge to the posterior distribution.\nBecause the Markov chain is not stationary and the\nstep sizes reduce to 0, it is not immediately clear that\nthis is the case. To see that this is indeed true, we\nwill show that a subsequence \u03b8t1,\u03b8t2,... will converge\nto the posterior as intended so the whole sequence will\nalso converge.\nFirst fix an \u03f50such that 0 < \u03f50\u226a 1. Since {\u03f5t} satisfy\nthe step size property (2), we can find a subsequence\nt1< t2< \u00b7\u00b7\u00b7 such that\u2211ts+1\nlarge enough s the total injected noise, \u2225\u2211ts+1\nshow that the total noise due to the stochasticity of\nthe gradients among these steps will be dominated by\nthe total injected noise. Since \u03f50 \u226a 1, we may take\nt=ts+1\u03f5t\u2192 \u03f50as s \u2192 \u221e.\nSince the injected noise at each step is independent, for\nt=ts+1\u03b7t\u22252,\nbetween steps ts and ts+1 will be O(\u221a\u03f50). We now\n\u2225\u03b8t\u2212 \u03b8ts\u22252 \u226a 1 for t between ts and ts+1. Making\nthe assumption that the gradient g(\u00b7) vary smoothly\n(e.g. they are Lipschitz continuous in the models in\nSection 5), the total stochastic gradient is:\nts+1\n\u2211\nt=ts+1\n\u03f5t\n2(g(\u03b8t) + ht(\u03b8t))(8)\n=\u03f50\n2g(\u03b8ts) + O(\u03f50) +\nts+1\n\u2211\nt=ts+1\n\u03f5t\n2ht(\u03b8t)\nSince the parameters did not vary much between ts\nand ts+1, the stochasticity in ht(\u03b8t) will be dominated\nby the randomness in the choice of the mini-batches.\nAssuming that these are chosen randomly and inde-\npendently, ht(\u03b8t) for each t will be basically iid (if\nmini-batches were chosen by random partitioning of\nthe whole dataset, ht(\u03b8t) will be negatively correlated\ninstead and will not change the results here). Thus\nthe variance of\u2211ts+1\n=\u03f50\n2g(\u03b8ts) + O(\u03f50) + O\n=\u03f50\n2g(\u03b8ts) + O(\u03f50)\nThe last equation says that the total stochastic gra-\ndient step is approximately the exact gradient step at\n\u03b8tswith a step size of \u03f50, with a deviation dominated\nby O(\u03f50). Since this is in turn dominated by the total\ninjected noise which is O(\u221a\u03f50), this means that the se-\nquence \u03b8t1,\u03b8t2,... will approach a sequence generated\nby Langevin dynamics with a fixed step size \u03f50, so it\nwill converge to the posterior distribution. Note also\nthat it will have infinite effective sample size.\nt=ts+1\n\u03f5t\n2ht(\u03b8t) is O(\u2211\nt\n\u03f52\nt\n4) and\n)(\u221a\u2211ts+1\nt=ts+1\n\u03f52\nt\n4\nThe implication of this argument is that we can use\nstochastic gradient Langevin dynamics as an \u201cany-\ntime\u201d and general-purpose algorithm. In the initial\nphase the stochastic gradient noise will dominate and\nthe algorithm will imitate an efficient stochastic gra-\ndient ascent algorithm. In the later phase the injected\nnoise will dominate, so the algorithm will imitate a\nLangevin dynamics MH algorithm, and the algorithm\nwill transition smoothly between the two. However\na disadvantage is that to guarantee the algorithm to\nwork it is important for the step sizes to decrease to\nzero, so that the mixing rate of the algorithm will\nslow down with increasing number of iterations. To\naddress this, we can keep the step size constant once\nit has decreased below a critical level where the MH\nrejection rate is considered negligible, or use this al-\ngorithm for burn-in, but switch to a different MCMC\nalgorithm that makes more efficient use of the whole\ndataset later. These alternatives can perform better"},{"page":4,"text":"Stochastic Gradient Langevin Dynamics\nbut will require further hand-tuning and are beyond\nthe scope of this paper. The point of this paper is\nto demonstrate a practical algorithm that can achieve\nproper Bayesian learning using only mini-batch data.\n4. Posterior Sampling\nIn this section we consider the use of our stochastic\ngradient Langevin dynamics algorithm as one which\nproduces samples from the posterior distribution. We\nfirst derive an estimate of when the algorithm will\ntransition from stochastic optimization to Langevin\ndynamics. The idea is that we should only start col-\nlecting samples after it has entered its posterior sam-\npling phase, which will not happen until after it be-\ncomes Langevin dynamics. Then we discuss how the\nalgorithm scales with the dataset size N and give a\nrough estimate of the number of iterations required for\nthe algorithm to traverse the whole posterior. Finally\nwe discuss how the obtained samples can be used to\nform Monte Carlo estimates of posterior expectations.\n4.1. Transition into Langevin dynamics phase\nWe first generalize our method to allow for precon-\nditioning, which can lead to significant speed ups by\nbetter adapting the step sizes to the local structure of\nthe posterior (Roberts & Stramer, 2002; Girolami &\nCalderhead, 2011). For instance, certain dimensions\nmay have a vastly larger curvature leading to much\nbigger gradients. In this case a symmetric precondi-\ntioning matrix M can transform all dimensions to the\nsame scale. The preconditioned stochastic gradient\nLangevin dynamics is simply,\n(\nAs noted previously, whether the algorithm is in the\nstochastic optimization phase or Langevin dynamics\nphase depends on the variance of the injected noise,\nwhich is simply \u03f5tM, versus that of the stochastic gra-\ndient. Since the stochastic gradient is a sum over the\ncurrent mini-batch, if its size n is large enough the\ncentral limit theorem will kick in and the variations\nht(\u03b8t) around the true gradient g(\u03b8t) will become nor-\nmally distributed. Its covariance matrix can then be\nestimated from the empirical covariance:\n\u2206\u03b8t=\u03f5t\n2Mg(\u03b8t) + ht(\u03b8t)\n)\n+ \u03b7t,\u03b7t\u223c N(0,\u03f5tM)\nV (\u03b8t) \u2261 V [ht(\u03b8t)] \u2248N2\nn2\nn\n\u2211\ni=1\n(sti\u2212 st)(sti\u2212 st)\u22a4\n(9)\nwhere sti= \u2207logp(xti|\u03b8t) +\nof data item i at iteration t and st =\nthe empirical mean. Note that V (\u03b8t) =N2\n1\nN\u2207logp(\u03b8t) is the score\n1\nn\n\u2211n\ni=1sti is\nnVs, where\nVs is the empirical covariance of the scores {sti}, so\nscales as\nthe stochastic gradient step is\nget the injected noise to dominate in all directions, we\nneed the condition\nN2\nn. From this we see that the variance of\n\u03f52\ntN2\n4nMVsM, so that to\n\u03f5tN2\n4n\n\u03bbmax(M\n1\n2VsM\n1\n2) = \u03b1 \u226a 1 (10)\nwhere \u03bbmax(A) is the largest eigenvalue of A. In other\nwords, if we choose a stepsize such that the sample\nthreshold \u03b1 \u226a 1, the algorithm will be in its Langevin\ndynamics phase and will be sampling approximately\nfrom the posterior.\nWe can now relate the step size at the sampling thresh-\nold to the posterior variance via the Fisher informa-\ntion, which is related to Vsas IF \u2248 NVs, and to the\nposterior variance \u03a3\u03b8\u2248 I\u22121\nas well as (10), we see that the step size at the sam-\npling threshold is \u03f5t\u2248\ndynamics explores the posterior via a random walk,\nusing this step size implies that we need on the order\nof N\/n steps to traverse the posterior, i.e. we process\nthe whole dataset. So we see this method is not a\nsilver bullet. However, the advantage of the method\nis its convenience: stochastic optimization smoothly\nand automatically transitions into posterior sampling\nwithout changing the update equation. Even without\nmeasuring the sampling threshold one will enjoy the\nbenefit of protection against overfitting and the ability\nto perform Bayesian learning. Measuring the sampling\nthreshold will only be important if one needs to faith-\nfully represent the posterior distribution with a finite\ncollection of samples.\nF. Using these relationships\n4\u03b1n\nN\u03bbmin(\u03a3\u03b8). Since Langevin\n4.2. Estimating Posterior Expectations\nSince \u03b81,\u03b82,... converges to the posterior distribution,\nwe can estimate the posterior expectation E[f(\u03b8)] of\nsome function f(\u03b8) by simply taking the sample av-\nerage\nT\nremove the initial burn-in phase, say estimated using\nthe sampling threshold). Since f(\u03b8t) is an asymptoti-\ncally unbiased estimator for E[f(\u03b8)], this sample aver-\nage will be consistent. Observe however that because\nthe step size decreases, the mixing rate of the Markov\nchain decreases as well, and the simple sample aver-\nage will over-emphasize the tail end of the sequence\nwhere there is higher correlation among the samples,\nresulting in higher variance in the estimator. Instead\nwe propose to use the step sizes to weight the samples:\n\u2211T\n1\n\u2211T\nt=1f(\u03b8t) (as typically in MCMC, we may\nE[f(\u03b8)] \u2248\nt=1\u03f5tf(\u03b8t)\n\u2211T\nt=1\u03f5t\n(11)"},{"page":5,"text":"Stochastic Gradient Langevin Dynamics\n\u22121012\n\u22123\n\u22122\n\u22121\n0\n1\n2\n3\n\u22121012\n\u22123\n\u22122\n\u22121\n0\n1\n2\n3\nFigure 1. True and estimated posterior distribution.\n10\n0\n10\n2\n10\n4\n10\n6\n10\n\u22126\n10\n\u22124\n10\n\u22122\n10\n0\niteration\nnoise variance\n \n \n\u2207\u03b81 noise\n\u2207\u03b82 noise\ninjected noise\n10\n\u22128\n10\n\u22126\n10\n\u22124\n10\n\u22122\n10\n\u22123\n10\n\u22122\n10\n\u22121\n10\n0\nstep size\naverage rejection rate\nFigure 2. Left: variances of stochastic gradient noise and\ninjected noise. Right: rejection probability versus step size.\nWe report the average rejection probability per iteration in\neach sweep through the dataset.\nSince\u2211\u221e\nMarkov chain mixes is proportional to the step size, so\nthat we expect the effective sample size of {\u03b81,...,\u03b8T}\nto be proportional to\u2211T\nt=1\u03f5t= \u221e, this estimator will be consistent\nas well. The intuition is that the rate at which the\nt=1\u03f5t, and that each \u03b8t will\ncontribute an effective sample size proportional to \u03f5t.\n5. Experiments\n5.1. Simple Demonstration\nWe first demonstrate the workings of our stochastic\ngradient Langevin algorithm on a simple example in-\nvolving only two parameters. To make the posterior\nmultimodal and a little more interesting, we use a mix-\nture of Gaussians with tied means:\n\u03b81\u223c N(0,\u03c32\nxi\u223c1\n1= 10, \u03c32\n1) ;\n\u03b82\u223c N(0,\u03c32\nx) +1\n2)\n2N(\u03b81,\u03c32\n2N(\u03b81+ \u03b82,\u03c32\nx)\nwhere \u03c32\nare drawn from the model with \u03b81 = 0 and \u03b82 = 1.\nThere is a mode at this parameter setting, but also a\nsecondary mode at \u03b81= 1, \u03b82= \u22121, with strong neg-\native correlation between the parameters. We ran the\nstochastic gradient Langevin algorithm with a batch-\n2= 1 and \u03c32\nx= 2. 100 data points\n0\n0\n2\n2\n4\n4\n6\n6\n8\n8\n10\n10\n\u22127\n\u22126\n\u22125\n\u22124\n\u22123\n\u22122\n\u22121\n0\nNumber of iterations through whole dataset\nLog joint probability per datum\n-6\n-4\n-5\n-3\n-2\n-1\n0\n-7\n0\n0\n0.5\n0.5\n1\n1\n1.5\n1.5\n2\n2\n0.65\n0.7\n0.75\n0.8\n0.85\nNumber of iterations through whole dataset\nAccuracy on test data\n \n \nAccuracy after 10 iterations\nAccuracy\n0.7\n0.8\n0.75\n0.85\n0.65\nFigure 3. Average log joint probability per data item (left)\nand accuracy on test set (right) as functions of the num-\nber of sweeps through the whole dataset. Red dashed line\nrepresents accuracy after 10 iterations. Results are aver-\naged over 50 runs; blue dotted lines indicate 1 standard\ndeviation.\nsize of 1 and using 10000 sweeps through the whole\ndataset.The step sizes are \u03f5t = a(b + t)\u2212\u03b3where\n\u03b3 = .55 and a and b are set such that \u03f5t decreases\nfrom .01 to .0001 over the duration of the run. We see\nfrom Figure 1 that the estimated posterior distribu-\ntion is very accurate. In Figure 2 we see that there are\nindeed two phases to the stochastic gradient Langevin\nalgorithm: a first phase where the stochastic gradient\nnoise dominates the injected noise, and a second phase\nwhere the converse occurs. To explore the scaling of\nthe rejection rate as a function of step sizes, we reran\nthe experiment with step sizes exponentially decreas-\ning from 10\u22122to 10\u22128. In the original experiment the\ndynamic range of the step sizes is not wide enough for\nvisual inspection. Figure 2(right) shows the rejection\nprobability decreasing to zero as step size decreases.\n5.2. Logistic Regression\nWe applied our stochastic gradient Langevin algorithm\nto a Bayesian logistic regression model. The probabil-\nity of the ith output yi \u2208 {\u22121,+1} given the corre-\nsponding input vector xiis modelled as:\np(yi|xi) = \u03c3(yi\u03b2\u22a4xi)(12)\nwhere \u03b2 are the parameters, and \u03c3(z) =\nThe bias parameter is absorbed into \u03b2 by including 1\nas an entry in xi. We use a Laplace prior for \u03b2 with a\nscale of 1. The gradient of the log likelihood is:\n1\n1+exp(\u2212z).\n\u2202\n\u2202\u03b2logp(yi|xi) = \u03c3(\u2212yi\u03b2\u22a4xi)yixi\nwhile the gradient of the prior is simply \u2212sign(\u03b2),\nwhich is applied elementwise.\n(13)\nWe applied our inference algorithm to the a9a dataset\nderived by (Lin et al., 2008) from the UCI adult\ndataset. It consists of 32561 observations and 123 fea-\ntures, and we used batch sizes of 10. Results from 50"},{"page":6,"text":"Stochastic Gradient Langevin Dynamics\nruns are shown in Figure 3, with the model trained\non a random 80% of the dataset and tested on the\nother 20% in each run. We see that both the joint\nprobability and the accuracy increase rapidly, with the\njoint probability converging after at most 10 iterations,\nwhile the accuracy converging after less than 1 itera-\ntion through the dataset, demonstrating the efficiency\nof the stochastic gradient Langevin dynamics.\n5.3. Independent Components Analysis\nIn the following we will briefly review a popular ICA\nalgorithm based on stochastic (natural) gradient opti-\nmization (Amari et al., 1996). We start from a proba-\nbilistic model that assumes independent, heavy tailed\nmarginal distributions,\n[\u220f\nwhere we have used a Gaussian prior over the weights.\nIt has been found that the efficiency of gradient descent\ncan be significantly improved if we use a natural gradi-\nent. This is implemented by post-multiplication of the\ngradient with the term WTW (Amari et al., 1996). If\nwe choose pi(yi) =\n4cosh2(1\np(x,W) = |det(W)|\ni\npi(wT\nix)\n]\u220f\nij\nN(Wij;0,\u03bb)\n(14)\n1\n2yi)with yi= wT\nix, we get\nDW\n(\n.= \u2207Wlog[p(X,W)] WTW =\nN\n\u2211\nNI \u2212\nn=1\ntanh(1\n2yn)yT\nn\n)\nW \u2212 \u03bbWWTW\n(15)\nThe term WTW acts like a preconditioning matrix (see\nsection 4.1), Mij,kl= \u03b4ik(WTW)jlwhich is symmetric\nunder the exchange (i \u2194 k,j \u2194 l). It can be shown\nthat the inverse of M is given by M\u22121= \u03b4(WTW)\u22121,\nand the matrix square root as\n\u221aWTW = U\u039b\n\u221aM = \u03b4\u221aWTW with\n1\n2UTif WTW = U\u039bUT.\nThe update equation for Langevin dynamics thus be-\ncomes,\nWt+1= Wt+1\n2\u03b5tDW+ \u03b7t\n\u221a\nWTW\n(16)\nwhere every element of \u03b7tis normally distributed with\nvariance \u03b5t: \u03b7ij,t \u223c N[0,\u03b5t]. Our stochastic version\nsimply approximates the part of the gradient that\nsums over data-cases with a sum over a small mini-\nbatch of size n and multiplies the result with N\/n to\nbring it back to the correct scale. We also anneal the\nstepsizes according to \u03b5t\u221d a(b + t)\u2212\u03b3.\nTo assess how well our stochastic Langevin approach\ncompares against a standard Bayesian method we im-\nplemented the \u201dcorrected Langevin\u201d MCMC sampler.\nThis sampler, proposes a new state W\u2217, as in Eqn.16.\nNote however that we sum over all data-cases and that\nwe do not anneal the stepsize. Secondly, we need to\naccept or reject the proposed step based on all the\ndata-cases in order to guarantee detailed balance. The\nproposal distribution is given by (suppressing depen-\ndence on t),\n[\nwhere the quadratic function in the exponent is con-\nveniently computed as,\nq(W \u2192 W\u2217) = N\nW\u2217;W +1\n2\u03b5DW;\u03b5M\n]\n(17)\n\u22121\n2\u03b5tr[(\u03b4W \u22121\n2\u03b5DW)(WTW)\u22121(\u03b4W \u22121\n2\u03b5DW)T]\n(18)\nwith \u03b4W = W\u2217\u2212 W and the normalization constant\nrequires the quantity detM = det(WTW)D. The ac-\ncept\/reject step is then given by the usual Metropolis\nHastings rule:\n[\nFinally, to compute the sampling threshold of Eqn.10,\nwe can use\np(accept) = min1,p(W\u2217)q(W\u2217\u2192 W)\np(W)q(W \u2192 W\u2217)\n]\n(19)\nM\n1\n2V(s)M\n[(1\n1\n2=(20)\n]\ncovn\nN\u2207logp(W) + \u2207logp(xi|W)\n)\n(WTW)\n1\n2\nwith covnthe sample covariance over the mini-batch\nof n data-cases.\nTo show the utility of our Bayesian variant of ICA we\ndefine the following \u201cinstability\u201d metric for indepen-\ndent components:\n\u2211\nwhere var(Wij) is computed over the posterior sam-\nples and var(xj) is computed over the data-cases.\nThe reason that we scale the variance of the weight\nentry Wij with the variance of xj is that the vari-\nance of the sources yi =\u2211\npi(yi) =\n4cosh2(1\nIi=\nj\nvar(Wij)var(xj)(21)\njWijxj is approximately\nequal for all i because they are fit to the distribution\n1\n2yi).\n5.3.1. Artificial Data\nIn the first experiment we generated 1000 data-cases\nIID in six channels. Three channels had high kurtosis\ndistributions while three others where normally dis-\ntributed. We ran stochastic Langevin dynamics with"},{"page":7,"text":"Stochastic Gradient Langevin Dynamics\n2468\nx 10\n4\n2\n4\n6\n8\n10\niteration\nAmari distance\nAmari Distance Stoc. Lan.\n0 0.51 1.52\n4\nx 10\n2\n4\n6\n8\n10\niteration\nAmari distance\nAmari Distance Corr. Lan.\n123456\n0\n50\n100\n150\n200\nSorted Component ID\nInstability Metric\nInstability Metric Stoc. Lan.\n123456\n0\n20\n40\n60\n80\n100\nSorted Component ID\nInstability Metric\nInstability Metric Corr. Lan.\nFigure 4. Left two figures: Amari distance over time for stochastic Langevin dynamics and corrected Langevin dynamics.\nThick line represents the online average. First few hundred iterations were removed to show the scale of the fluctuations.\nRight two figures: Instability index for the 6 independent components computed in section 5.3.1 for stochastic Langevin\ndynamics and corrected Langevin dynamics.\nW(1,1)\nW(1,2)\nPDF W(1,1) vs W(1,2) Stoc. Lan.\n\u2212505\n\u22126\n\u22124\n\u22122\n0\n2\n4\n6\nW(1,1)\nW(1,2)\nPDF W(1,1) vs W(1,2) Corr. Lan.\n\u22124\u22122024\n\u22126\n\u22124\n\u22122\n0\n2\n4\nW(1,1)\nW(2,1)\nPDF W(1,1) vs W(2,1) Stoc. Lan.\n\u2212505\n\u22125\n0\n5\nW(1,1)\nW(2,1)\nPDF W(1,1) vs W(2,1) Corr. Lan.\n\u22124\u22122024\n0\n1\n2\n3\n4\n5\nFigure 5. Posterior density estimates for artificial dataset for stochastic Langevin and corrected Langevin dynamics mea-\nsured across the W11\u2212 W12 and W1,1\u2212 W2,1 axes.\na batch-size of 100 for a total of 500,000 iterations\nand a polynomial annealing schedule \u03b5t =\nAfter around 10,000 iterations the sampling threshold\nat \u03b1 = 0.1 was met. At that point we recorded the\n\u201cmixing distance\u201d as D0 = \u03b5t and collected samples\nonly when the sum\u2211\nlect fewer samples per unit time). We note that simply\ncollecting all samples had no noticeable impact on the\nfinal results. The last estimate of W was used to ini-\ntialize corrected Langevin dynamics (this was done to\nforce the samplers into the same local maximum) after\nwhich we also collected 500,000 samples. For corrected\nLangevin we used a constant stepsize of \u03b5 =0.1\n4\nNt\u22120.55.\nt\u03b5t from the last sample time\nexceeded D0(in other words, as \u03b5tdecreases we col-\nN.\nThe two left figures of Figure 4 show the Amari dis-\ntance (Amari et al., 1996) over time for stochastic\nand corrected Langevin dynamics respectively. The\nright two figures show the sorted values of our pro-\nposed instability index. Figures 5 show two dimen-\nsional marginal density estimates of the posterior dis-\ntribution of W. ICA cannot determine the Gaussian\ncomponents and this fact is verified by looking at the\nposterior distribution. In fact, the stochastic Langevin\nalgorithm has mixed over a number of modes that pre-\nsumably correspond to different linear combinations of\nthe Gaussian components. To a lesser degree the cor-\nrected Langevin has also explored two modes. Due\nto the complicated structure of the posterior distri-\nbution the stability index varies strongly between the\ntwo sampling algorithms for the Gaussian components\n(and in fact also varies across different runs). We veri-\nfied that the last three components correspond to sta-\nble, high kurtosis components.\n5.3.2. MEG Data\nWe\nhttp:\/\/www.cis.hut.fi\/projects\/ica\/eegmeg\/MEG data.html.\nThere are 122 channels and 17730 time-points, from\nwhich we extracted the first 10 channels for our\nexperiment.To initialize the sampling algorithms,\nwe first ran fastICA (Hyvarinen, 1999) to find an\ninitial estimate of the de-mixing matrix W.\nthen ran stochastic Langevin and corrected Langevin\ndynamics to sample from the posterior. The settings\nwere very similar to the previous experiment with a\nschedule of \u03b5t=0.1\na constant stepsize of 1\/N for corrected Langevin.\nWe obtained 500,000 samples for stochastic Langevin\nin 800 seconds and 100,000 samples for corrected\nLangevin in 9000 seconds.\nthat the two dimensional marginal distributions of\nstochastic Langevin and corrected Langevin dynamics\nwere very similar. The instability values are shown in\nfigure 6. Due to the absence of Gaussian components\nwe see that the stability indices are very similar across\nthe two sampling algorithms.\ndownloadedtheMEGdatasetfrom\nWe\nNt\u22120.55for stochastic Langevin and\nWe visually verified\nIt was verified that"},{"page":8,"text":"Stochastic Gradient Langevin Dynamics\n12345678910\n0\n0.01\n0.02\n0.03\n0.04\n0.05\n0.06\n0.07\nSorted Components\nInstability Index\nInstability Index Stoc. Lan.\n123456789 10\n0\n0.01\n0.02\n0.03\n0.04\n0.05\n0.06\n0.07\nSorted Components\nInstability Index\nIntability Index Corr. Lan.\nFigure 6. Instability indices of 10 components for MEG\ndataset for stochastic Langevin (left) and corrected\nLangevin (right) respectively.\nthe most stable component corresponded to a highly\nkurtotic source (kurtosus = 15.4), while the most\nunstable component was closer to Gaussian noise\nwith a kurtosis of 3.4 (2 corresponds to Gaussian).\nThese findings verify that the stochastic Langevin\nprocedure produces accurate posterior distributions\nthat are in full agreement with a well established\nMCMC procedure.\n6. Discussion\nStochastic gradient optimization is among the most ef-\nfective algorithms if we measure \u201cpredictive accuracy\nobtained per unit of computation\u201d (Bottou & Bous-\nquet, 2008). Due to subsampling noise, the parame-\nter estimates fluctuate around their MAP values. The\ncommon wisdom is that one must anneal these step-\nsizes to zero to reach the fixed point. However, we\nargue that one should not optimize beyond the scale\nof the posterior distribution. The posterior represents\nthe intrinsic statistical scale of precision and trying to\ndetermine parameter values with more precision runs\nthe risk of overfitting at additional computational cost.\nMCMC sampling from the posterior distribution does\nof course address the overfitting issue. However, gen-\neral MCMC algorithms need to see all the data at ev-\nery iteration, and thus lose the benefits of the stochas-\ntic approximation approaches. This paper offers for\nthe first time a surprisingly simple solution that rep-\nresents the best of both worlds: stick with stochastic\ngradients but sample from the posterior nevertheless.\nBut perhaps the biggest advantage of stochastic gra-\ndient Langevin dynamics is the fact that stochastic\noptimization seamlessly transitions into posterior sam-\npling. By simply adding Gaussian noise with the cor-\nrect variance our method performs \u201cearly stopping\u201d\nautomatically without ever having to worry about it.\nIn fact, we have shown that with a polynomial anneal-\ning schedule the obtained samples will asymptotically\nrepresent the posterior distribution faithfully.\nWe believe that this work represents only a tentative\nfirst step to further work on efficient MCMC sampling\nbased on stochastic gradients. Interesting directions of\nresearch include stronger theory providing a solid proof\nof convergence, deriving a MH rejection step based\non mini-batch data, extending the algorithm to the\nonline estimation of dynamical systems, and deriving\nalgorithms based on more sophisticated Hamiltonian\nMonte Carlo approaches which do not suffer from ran-\ndom walk behaviour.\nAcknowledgements\nThis material is based upon work supported by the Na-\ntional Science Foundation under Grant No.\n1018433 (MW) and the Gatsby Charitable Foundation\n(YWT).\n0447903,\nReferences\nAmari, S., Cichocki, A., and Yang, H.H. A new algorithm\nfor blind signal separation. In Neural Information Pro-\ncessing Systems, volume 8, pp. 757\u2013763, 1996.\nAndrieu, C., de Freitas, N., and Doucet, A. Sequential\nMCMC for Bayesian model selection. In Proceedings of\nthe IEEE Signal Processing Workshop on Higher-Order\nStatistics, pp. 130\u2013134, 1999.\nBottou, L. and Bousquet, O. The tradeoffs of large scale\nlearning. In Advances in Neural Information Processing\nSystems, volume 20, pp. 161\u2013168, 2008.\nGirolami, M. and Calderhead, B.\nLangevin and Hamiltonian Monte Carlo methods. Jour-\nnal of the Royal Statistical Society B, 73:1\u201337, 2011.\nRiemann manifold\nHyvarinen, A. Fast and robust fixed-point algorithms for\nindependent component analysis. IEEE Transactions on\nNeural Networks, 10(3):626\u2013634, 1999.\nLin, C.-J., Weng, R. C., and Keerthi, S. S. Trust region\nNewton method for large-scale logistic regression. Jour-\nnal of Machine Learning Research, 9:627\u2013650, 2008.\nNeal, R. M.\nBrooks, S., Gelman, A., Jones, G., and Meng, X.-L.\n(eds.), Handbook of Markov Chain Monte Carlo. Chap-\nman & Hall \/ CRC Press, 2010.\nMCMC using Hamiltonian dynamics. In\nRobbins, H. and Monro, S. A stochastic approximation\nmethod. Annals of Mathematical Statistics, 22(3):400\u2013\n407, 1951.\nRobert, C. P. and Casella, G. Monte Carlo statistical meth-\nods. Springer Verlag, 2004.\nRoberts, G. O. and Stramer, O. Langevin diffusions and\nmetropolis-hastings algorithms. Methodology and Com-\nputing in Applied Probability, 4:337\u2013357, 2002."}],"widgetId":"rgw27_56ab1c9d76a8a"},"id":"rgw27_56ab1c9d76a8a","partials":[],"templateName":"publicliterature\/stubs\/PublicationText.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationText.html?publicationUid=221346425&hide=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationDetailAd":{"data":{"googleDfpSlot":null,"widgetId":"rgw28_56ab1c9d76a8a"},"id":"rgw28_56ab1c9d76a8a","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAd.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAd.html?publicationUid=221346425&slotId=336x280_Publications_ATF_Right&collapseSlotMode=never&fallbackContainerEnabled=1","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationRelations":null,"publicationRelationsReverse":null,"publicationUid":221346425,"showSignUpDialog":false,"selectNewSignUpDialog":false,"publicationQuestions":null,"publicationCitations":{"data":{"publicationUid":221346425,"publicationCitationsList":{"data":{"citationItems":[{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore","clickThrough":"experimentMilestoneClickedToPublicationFromCitationWithSlurp","clickThroughWithContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextSlurp","nextPublicationViewId":null,"authorsPartOne":[{"id":2075738569,"url":"researcher\/2075738569_Changyou_Chen","fullname":"Changyou Chen","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":71191078,"url":"researcher\/71191078_David_Carlson","fullname":"David Carlson","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2075686701,"url":"researcher\/2075686701_Zhe_Gan","fullname":"Zhe Gan","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":{"id":2081618664,"url":"researcher\/2081618664_Chunyuan_Li","fullname":"Chunyuan Li","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},"surplusAuthors":1,"additionalCssClasses":[["includes-citation-list"]],"isFulltext":false,"isSlurp":true,"isNoText":false,"publicationType":"Article","publicationDate":"Dec 2015","journal":null,"showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/288713780_Bridging_the_Gap_between_Stochastic_Gradient_MCMC_and_Stochastic_Optimization","usePlainButton":true,"publicationUid":288713780,"feedStubs":null,"hasFeedStubs":false,"impactPoints":false,"url":"publication\/288713780_Bridging_the_Gap_between_Stochastic_Gradient_MCMC_and_Stochastic_Optimization","title":"Bridging the Gap between Stochastic Gradient MCMC and Stochastic Optimization","displayTitleAsLink":true,"authors":[{"id":2075738569,"url":"researcher\/2075738569_Changyou_Chen","fullname":"Changyou Chen","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":71191078,"url":"researcher\/71191078_David_Carlson","fullname":"David Carlson","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2075686701,"url":"researcher\/2075686701_Zhe_Gan","fullname":"Zhe Gan","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2081618664,"url":"researcher\/2081618664_Chunyuan_Li","fullname":"Chunyuan Li","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":10135830,"url":"researcher\/10135830_Lawrence_Carin","fullname":"Lawrence Carin","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":[],"abstract":"Stochastic gradient Markov chain Monte Carlo (SG-MCMC) methods are Bayesian\nanalogs to popular stochastic optimization methods; however, this connection is\nnot well studied. We explore this relationship by applying simulated annealing\nto an SGMCMC algorithm. Furthermore, we extend recent SG-MCMC methods with two\nkey components: i) adaptive preconditioners (as in ADAgrad or RMSprop), and ii)\nadaptive element-wise momentum weights. The zero-temperature limit gives a\nnovel stochastic optimization method with adaptive element-wise momentum\nweights, while conventional optimization methods only have a shared, static\nmomentum weight. Under certain assumptions, our theoretical analysis suggests\nthe proposed simulated annealing approach converges close to the global optima.\nExperiments on several deep neural network models show state-of-the-art results\ncompared to related stochastic optimization algorithms.","description":false,"swapJournalAndAuthorPositions":false,"showAbstract":true,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/288713780_Bridging_the_Gap_between_Stochastic_Gradient_MCMC_and_Stochastic_Optimization","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":false,"actions":[{"type":"request-external","text":"Request full-text","url":"javascript:;","active":false,"primary":false,"extraClass":null,"icon":null,"data":[{"key":"context","value":"pubCit"}]}],"actionWidgets":[],"publicationItemFulltext":{"data":{"isDataset":false,"isResearch":false,"isFulltext":true,"source":{"isPreview":true,"sourceUrl":"deref\/http%3A%2F%2Fde.arxiv.org%2Fpdf%2F1512.07962","sourceName":"de.arxiv.org","hasSourceUrl":true},"publicationUid":288713780,"publicationUrl":"publication\/288713780_Bridging_the_Gap_between_Stochastic_Gradient_MCMC_and_Stochastic_Optimization","eventCode":"","citationCount":0,"additionalContentWidgets":[],"disableViewer":true,"showLoggedOutRequestButton":false,"context":null,"previewUrl":"https:\/\/i1.rgstatic.net\/publication\/288713780_Bridging_the_Gap_between_Stochastic_Gradient_MCMC_and_Stochastic_Optimization\/links\/5689b80b08ae051f9af78388\/smallpreview.png","linkId":"5689b80b08ae051f9af78388","origin":"publication_list","showRequestCount":false,"publish":false,"request":false,"showAction":false,"displayAsLink":true,"documentViewerUrl":"publicliterature.PublicLiteratureDocumentViewer.html?publicationId=288713780&reference=5689b80b08ae051f9af78388&eventCode=&origin=publication_list","widgetId":"rgw32_56ab1c9d76a8a"},"id":"rgw32_56ab1c9d76a8a","partials":[],"templateName":"publicliterature\/stubs\/PublicationItemFulltext.html","templateExtensions":["generalHelpers"],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItemFulltext.html?publicationUid=288713780&showAction=1&eventCode=&hideSource=0&displayAsLink=1&showPublishAsSelectFile=0","viewClass":"views.publicliterature.PublicationItemFulltextView","yuiModules":["rg.views.publicliterature.PublicationItemFulltextView"],"stylesheets":[],"_isYUI":true},"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":true,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":221346425,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/288713780_Bridging_the_Gap_between_Stochastic_Gradient_MCMC_and_Stochastic_Optimization\/review","additionalRightSideTopWidgets":[{"data":{"citationContexts":["The SG-MCMC analog to this is SGLD, with updates \u03b8 t = \u03b8 t\u22121 \u2212 \u03b7 t \u02dc f t\u22121 (\u03b8) + \u221a 2\u03b7 t \u03b6 t . The additional term is a standard normal random vector, \u03b6 t \u223c N (0, I p ) (Welling and Teh, 2011). The SGLD method draws approximate posterior samples instead of obtaining a local minima. "],"widgetId":"rgw33_56ab1c9d76a8a"},"id":"rgw33_56ab1c9d76a8a","partials":[],"templateName":"publicliterature\/stubs\/PublicationItemCitationContexts.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItemCitationContexts.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":true,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw31_56ab1c9d76a8a"},"id":"rgw31_56ab1c9d76a8a","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":true,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItem.html?showEnrichedPublicationItem=0&showRequestButton=1&publicationUid=288713780&additionalCssClasses%5B0%5D=includes-citation-list&citationContextItemVersion=old&isIncomingCitation=1","viewClass":"views.publicliterature.PublicationItemView","yuiModules":["rg.views.publicliterature.PublicationItemView"],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore","clickThrough":"experimentMilestoneClickedToPublicationFromCitationWithSlurp","clickThroughWithContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextSlurp","nextPublicationViewId":null,"authorsPartOne":[{"id":2081618664,"url":"researcher\/2081618664_Chunyuan_Li","fullname":"Chunyuan Li","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2075738569,"url":"researcher\/2075738569_Changyou_Chen","fullname":"Changyou Chen","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":71191078,"url":"researcher\/71191078_David_Carlson","fullname":"David Carlson","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":10135830,"url":"researcher\/10135830_Lawrence_Carin","fullname":"Lawrence Carin","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":[["includes-citation-list"]],"isFulltext":false,"isSlurp":true,"isNoText":false,"publicationType":"Article","publicationDate":"Dec 2015","journal":null,"showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/288059869_Preconditioned_Stochastic_Gradient_Langevin_Dynamics_for_Deep_Neural_Networks","usePlainButton":true,"publicationUid":288059869,"feedStubs":null,"hasFeedStubs":false,"impactPoints":false,"url":"publication\/288059869_Preconditioned_Stochastic_Gradient_Langevin_Dynamics_for_Deep_Neural_Networks","title":"Preconditioned Stochastic Gradient Langevin Dynamics for Deep Neural Networks","displayTitleAsLink":true,"authors":[{"id":2081618664,"url":"researcher\/2081618664_Chunyuan_Li","fullname":"Chunyuan Li","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2075738569,"url":"researcher\/2075738569_Changyou_Chen","fullname":"Changyou Chen","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":71191078,"url":"researcher\/71191078_David_Carlson","fullname":"David Carlson","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":10135830,"url":"researcher\/10135830_Lawrence_Carin","fullname":"Lawrence Carin","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":[],"abstract":"Effective training of deep neural networks suffers from two main issues. The\nfirst is that the parameter spaces of these models exhibit pathological\ncurvature. Recent methods address this problem by using adaptive\npreconditioning for Stochastic Gradient Descent (SGD). These methods improve\nconvergence by adapting to the local geometry of parameter space. A second\nissue is overfitting, which is typically addressed by early stopping. However,\nrecent work has demonstrated that Bayesian model averaging mitigates this\nproblem. The posterior can be sampled by using Stochastic Gradient Langevin\nDynamics (SGLD). However, the rapidly changing curvature renders default SGLD\nmethods inefficient. Here, we propose combining adaptive preconditioners with\nSGLD. In support of this idea, we give theoretical properties on asymptotic\nconvergence and predictive risk. We also provide empirical results for Logistic\nRegression, Feedforward Neural Nets, and Convolutional Neural Nets,\ndemonstrating that our preconditioned SGLD method gives state-of-the-art\nperformance on these models.","description":false,"swapJournalAndAuthorPositions":false,"showAbstract":true,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/288059869_Preconditioned_Stochastic_Gradient_Langevin_Dynamics_for_Deep_Neural_Networks","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":false,"actions":[{"type":"request-external","text":"Request full-text","url":"javascript:;","active":false,"primary":false,"extraClass":null,"icon":null,"data":[{"key":"context","value":"pubCit"}]}],"actionWidgets":[],"publicationItemFulltext":{"data":{"isDataset":false,"isResearch":false,"isFulltext":true,"source":{"isPreview":true,"sourceUrl":"deref\/http%3A%2F%2Fde.arxiv.org%2Fpdf%2F1512.07666","sourceName":"de.arxiv.org","hasSourceUrl":true},"publicationUid":288059869,"publicationUrl":"publication\/288059869_Preconditioned_Stochastic_Gradient_Langevin_Dynamics_for_Deep_Neural_Networks","eventCode":"","citationCount":0,"additionalContentWidgets":[],"disableViewer":true,"showLoggedOutRequestButton":false,"context":null,"previewUrl":"https:\/\/i1.rgstatic.net\/publication\/288059869_Preconditioned_Stochastic_Gradient_Langevin_Dynamics_for_Deep_Neural_Networks\/links\/5681cf0108aebccc4e0bebee\/smallpreview.png","linkId":"5681cf0108aebccc4e0bebee","origin":"publication_list","showRequestCount":false,"publish":false,"request":false,"showAction":false,"displayAsLink":true,"documentViewerUrl":"publicliterature.PublicLiteratureDocumentViewer.html?publicationId=288059869&reference=5681cf0108aebccc4e0bebee&eventCode=&origin=publication_list","widgetId":"rgw35_56ab1c9d76a8a"},"id":"rgw35_56ab1c9d76a8a","partials":[],"templateName":"publicliterature\/stubs\/PublicationItemFulltext.html","templateExtensions":["generalHelpers"],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItemFulltext.html?publicationUid=288059869&showAction=1&eventCode=&hideSource=0&displayAsLink=1&showPublishAsSelectFile=0","viewClass":"views.publicliterature.PublicationItemFulltextView","yuiModules":["rg.views.publicliterature.PublicationItemFulltextView"],"stylesheets":[],"_isYUI":true},"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":true,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":221346425,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/288059869_Preconditioned_Stochastic_Gradient_Langevin_Dynamics_for_Deep_Neural_Networks\/review","additionalRightSideTopWidgets":[{"data":{"citationContexts":["Traditional MCMC methods use the full dataset, which does not scale to large data problems. A pioneering work in combining stochastic optimization with MCMC was presented in (Welling and Teh 2011), based on Langevin dynamics (Neal 2011). This method was referred to as Stochastic Gradient Langevin Dynamics (SGLD), and required only the gradient on mini-batches of data. "],"widgetId":"rgw36_56ab1c9d76a8a"},"id":"rgw36_56ab1c9d76a8a","partials":[],"templateName":"publicliterature\/stubs\/PublicationItemCitationContexts.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItemCitationContexts.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":true,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw34_56ab1c9d76a8a"},"id":"rgw34_56ab1c9d76a8a","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":true,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItem.html?showEnrichedPublicationItem=0&showRequestButton=1&publicationUid=288059869&additionalCssClasses%5B0%5D=includes-citation-list&citationContextItemVersion=old&isIncomingCitation=1","viewClass":"views.publicliterature.PublicationItemView","yuiModules":["rg.views.publicliterature.PublicationItemView"],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore","clickThrough":"experimentMilestoneClickedToPublicationFromCitationWithSlurp","clickThroughWithContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextSlurp","nextPublicationViewId":null,"authorsPartOne":[{"id":2083133647,"url":"researcher\/2083133647_Chong_Wang","fullname":"Chong Wang","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2064238818,"url":"researcher\/2064238818_David_M_Blei","fullname":"David M. Blei","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":[["includes-citation-list"]],"isFulltext":false,"isSlurp":true,"isNoText":false,"publicationType":"Article","publicationDate":"Oct 2015","journal":null,"showEnrichedPublicationItem":false,"citationCount":1,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/283043210_A_General_Method_for_Robust_Bayesian_Modeling","usePlainButton":true,"publicationUid":283043210,"feedStubs":null,"hasFeedStubs":false,"impactPoints":false,"url":"publication\/283043210_A_General_Method_for_Robust_Bayesian_Modeling","title":"A General Method for Robust Bayesian Modeling","displayTitleAsLink":true,"authors":[{"id":2083133647,"url":"researcher\/2083133647_Chong_Wang","fullname":"Chong Wang","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2064238818,"url":"researcher\/2064238818_David_M_Blei","fullname":"David M. Blei","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":[],"abstract":"Robust Bayesian models are appealing alternatives to standard models,\nproviding protection from data that contains outliers or other departures from\nthe model assumptions. Historically, robust models were mostly developed on a\ncase-by-case basis; examples include robust linear regression, robust mixture\nmodels, and bursty topic models. In this paper we develop a general approach to\nrobust Bayesian modeling. We show how to turn an existing Bayesian model into a\nrobust model, and then develop a generic strategy for computing with it. We use\nour method to study robust variants of several models, including linear\nregression, Poisson regression, logistic regression, and probabilistic topic\nmodels. We discuss the connections between our methods and existing approaches,\nespecially empirical Bayes and James-Stein estimation.","description":false,"swapJournalAndAuthorPositions":false,"showAbstract":true,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/283043210_A_General_Method_for_Robust_Bayesian_Modeling","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":false,"actions":[{"type":"request-external","text":"Request full-text","url":"javascript:;","active":false,"primary":false,"extraClass":null,"icon":null,"data":[{"key":"context","value":"pubCit"}]}],"actionWidgets":[],"publicationItemFulltext":{"data":{"isDataset":false,"isResearch":false,"isFulltext":true,"source":{"isPreview":true,"sourceUrl":"deref\/http%3A%2F%2Fde.arxiv.org%2Fpdf%2F1510.05078","sourceName":"de.arxiv.org","hasSourceUrl":true},"publicationUid":283043210,"publicationUrl":"publication\/283043210_A_General_Method_for_Robust_Bayesian_Modeling","eventCode":"","citationCount":0,"additionalContentWidgets":[],"disableViewer":true,"showLoggedOutRequestButton":false,"context":null,"previewUrl":"https:\/\/i1.rgstatic.net\/publication\/283043210_A_General_Method_for_Robust_Bayesian_Modeling\/links\/562ec76508ae518e348386b2\/smallpreview.png","linkId":"562ec76508ae518e348386b2","origin":"publication_list","showRequestCount":false,"publish":false,"request":false,"showAction":false,"displayAsLink":true,"documentViewerUrl":"publicliterature.PublicLiteratureDocumentViewer.html?publicationId=283043210&reference=562ec76508ae518e348386b2&eventCode=&origin=publication_list","widgetId":"rgw38_56ab1c9d76a8a"},"id":"rgw38_56ab1c9d76a8a","partials":[],"templateName":"publicliterature\/stubs\/PublicationItemFulltext.html","templateExtensions":["generalHelpers"],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItemFulltext.html?publicationUid=283043210&showAction=1&eventCode=&hideSource=0&displayAsLink=1&showPublishAsSelectFile=0","viewClass":"views.publicliterature.PublicationItemFulltextView","yuiModules":["rg.views.publicliterature.PublicationItemFulltextView"],"stylesheets":[],"_isYUI":true},"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":true,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":221346425,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/283043210_A_General_Method_for_Robust_Bayesian_Modeling\/review","additionalRightSideTopWidgets":[{"data":{"citationContexts":["We use a model to encode the types of patterns we want to discover in the data\u2014either to predict about future data or explore existing data\u2014and then use a posterior inference algorithm to uncover the realization of those patterns that underlie the observations. Innovations in scalable inference allow us to use Bayesian models to analyze massive data (Hoffman et al., 2013; Welling and Teh, 2011; Ahn et al., 2012; Xing et al., 2013); innovations in generic inference allow us to easily explore a wide variety of models (Ranganath et al., 2014; Wood et al., 2014; Hoffman and Gelman, 2014). Consequently, modern Bayesian modeling has had an impact on many fields, including natural language processing (Teh, 2006), computer vision (Fei-Fei and Perona, 2005), the natural sciences (Pritchard et al., 2000), and the social sciences (Grimmer, 2009). "],"widgetId":"rgw39_56ab1c9d76a8a"},"id":"rgw39_56ab1c9d76a8a","partials":[],"templateName":"publicliterature\/stubs\/PublicationItemCitationContexts.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItemCitationContexts.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":true,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw37_56ab1c9d76a8a"},"id":"rgw37_56ab1c9d76a8a","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":true,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItem.html?showEnrichedPublicationItem=0&showRequestButton=1&publicationUid=283043210&additionalCssClasses%5B0%5D=includes-citation-list&citationContextItemVersion=old&isIncomingCitation=1","viewClass":"views.publicliterature.PublicationItemView","yuiModules":["rg.views.publicliterature.PublicationItemView"],"stylesheets":[],"_isYUI":true}],"hasCitations":true,"isPublicationAuthor":false,"isPublicationVisitor":false,"publicationUid":221346425,"publicationLink":"publication\/221346425_Bayesian_Learning_via_Stochastic_Gradient_Langevin_Dynamics","hasShowMore":true,"newOffset":3,"pageSize":10,"widgetId":"rgw30_56ab1c9d76a8a"},"id":"rgw30_56ab1c9d76a8a","partials":[],"templateName":"publicliterature\/stubs\/PublicationIncomingCitationsList.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationIncomingCitationsList.html?publicationUid=221346425&citedInPage=1&swapJournalAndAuthorPositions=0&showAbstract=1&showType=1&showPublicationPreview=1&totalCount=49","viewClass":"views.publicliterature.PublicationIncomingCitationsListView","yuiModules":["rg.views.publicliterature.PublicationIncomingCitationsListView"],"stylesheets":[],"_isYUI":true},"hasCitations":false,"citationsCount":0,"hasIncomingCitations":true,"incomingCitationsCount":49,"showCitationsSorter":true,"showAbstract":true,"showType":true,"showPublicationPreview":true,"swapJournalAndAuthorPositions":false,"sort":"","sortOriginal":false,"citationList":"incoming","showsIncoming":true,"showSorting":false,"usePlainButton":null,"useEnrichedContext":null,"widgetId":"rgw29_56ab1c9d76a8a"},"id":"rgw29_56ab1c9d76a8a","partials":[],"templateName":"publicliterature\/stubs\/PublicationCitations.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationCitations.html?publicationUid=221346425&citationList=&citedInPage=1&sort=","viewClass":"views.publicliterature.PublicationCitationsView","yuiModules":["rg.views.publicliterature.PublicationCitationsView"],"stylesheets":[],"_isYUI":true},"publicationReviewPromo":null,"publicationUsedInReviews":null,"publicationPdfJsReader":null,"useFulltextOptimizedLayout":false,"publicationActions":null,"requestFulltextPromo":null,"currentUrl":"publication\/221346425_Bayesian_Learning_via_Stochastic_Gradient_Langevin_Dynamics","isLeaderboardAd":false,"enableStickyBox":null,"googleDfpSlotMobileBottom":null,"fullTextExitPopup":null,"showExitPopupDialog":false,"widgetId":"rgw2_56ab1c9d76a8a"},"id":"rgw2_56ab1c9d76a8a","partials":{"romeo_legal_notice":"publicliterature\/stubs\/partials\/romeo_legal_notice.html"},"templateName":"publicliterature\/stubs\/PublicPublicationDetails_NewLayout.html","templateExtensions":["generalHelpers"],"attrs":{"publicationUid":221346425},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicPublicationDetailsOld.html?publicationUid=221346425&isTestOldDesign=0","viewClass":"views.publicliterature.PublicPublicationDetailsOldView","yuiModules":["rg.views.publicliterature.PublicPublicationDetailsOldView"],"stylesheets":[],"_isYUI":true},"widgetId":"rgw1_56ab1c9d76a8a"},"id":"rgw1_56ab1c9d76a8a","partials":[],"templateName":"publicliterature\/stubs\/PublicPublicationDetails.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicPublicationDetails.html","viewClass":"views.publicliterature.PublicPublicationDetailsView","yuiModules":["rg.views.publicliterature.PublicPublicationDetailsView"],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"uaClass":"","headPrefix":[],"rootUrl":"https:\/\/www.researchgate.net\/","requestToken":"03vUuvydhmVIm4j2Mc5e5QAT3gYtzKp8C8f9XT1KYBnNN8Cr3NOC\/Pibo3WONj7J9g8pNsX8M6GCfYklEJVebV37CFyK2ikQ8vJZjd7vPuHcBupqSPy4dKlm3ZUDZXomB0BD4Yi+esXhGixoD4JnfZk6Y4WDvUwz65im65LfRyWHERaH682\/k33hFAyaJQZb5m7OAOR291jjtz96RdezoPEjc+obo6joO\/arv5mqxWZkxf1sf+uZ3\/Z4P5OMeoE\/WEkyCbfKYYnNk+6j9IgsJ88oiu5AbXmuctI\/fr\/TnRQ=","faviconCdnUrl":"https:\/\/c5.rgstatic.net\/m\/2390829798215018\/images\/favicon.ico","headerOutput":"<noscript><\/noscript><link rel=\"canonical\" href=\"https:\/\/www.researchgate.net\/publication\/221346425_Bayesian_Learning_via_Stochastic_Gradient_Langevin_Dynamics\" \/>\n<link rel=\"dns-prefetch\" href=\"\/\/c5.rgstatic.net\" \/>\n<link rel=\"dns-prefetch\" href=\"\/\/i1.rgstatic.net\" \/>\n<meta property=\"twitter:card\" content=\"summary\" \/>\n<meta property=\"twitter:site\" content=\"@ResearchGate\" \/>\n<meta property=\"og:title\" content=\"Bayesian Learning via Stochastic Gradient Langevin Dynamics\" \/>\n<meta property=\"og:description\" content=\"In this paper we propose a new framework for learning from large scale datasets based on iterative learning from small mini-batches. By adding the right amount of noise to a standard stochastic...\" \/>\n<meta property=\"og:site_name\" content=\"ResearchGate\" \/>\n<meta property=\"og:image\" content=\"https:\/\/i1.rgstatic.net\/publication\/221346425_Bayesian_Learning_via_Stochastic_Gradient_Langevin_Dynamics\/links\/0ffd5c240cf255165fca9437\/smallpreview.png\" \/>\n<meta property=\"og:url\" content=\"https:\/\/www.researchgate.net\/publication\/221346425_Bayesian_Learning_via_Stochastic_Gradient_Langevin_Dynamics\" \/>\n<meta property=\"rg:id\" content=\"PB:221346425\" \/>\n<meta name=\"DC.identifier\" scheme=\"DCTERMS.URI\" content=\"http:\/\/dx.doi.org\/\" \/>\n<meta name=\"gs_meta_revision\" content=\"1.1\" \/>\n<meta name=\"citation_title\" content=\"Bayesian Learning via Stochastic Gradient Langevin Dynamics\" \/>\n<meta name=\"citation_author\" content=\"Max Welling\" \/>\n<meta name=\"citation_author\" content=\"Yee Whye Teh\" \/>\n<meta name=\"citation_conference_title\" content=\"Proceedings of the 28th International Conference on Machine Learning, ICML 2011, Bellevue, Washington, USA, June 28 - July 2, 2011\" \/>\n<meta name=\"citation_publication_date\" content=\"2011\/01\/01\" \/>\n<meta name=\"citation_firstpage\" content=\"681\" \/>\n<meta name=\"citation_lastpage\" content=\"688\" \/>\n<meta name=\"citation_abstract_html_url\" content=\"https:\/\/www.researchgate.net\/publication\/221346425_Bayesian_Learning_via_Stochastic_Gradient_Langevin_Dynamics\" \/>\n<meta name=\"citation_fulltext_html_url\" content=\"https:\/\/www.researchgate.net\/publication\/221346425_Bayesian_Learning_via_Stochastic_Gradient_Langevin_Dynamics\" \/>\n<meta name=\"viewport\" content=\"width=device-width,initial-scale=1\" \/>\n<link href=\"\/\/c5.rgstatic.net\/m\/22664197317151888\/styles\/rg.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/21004998181197492\/styles\/rg2.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<!--[if lt IE 9]><link href=\"\/\/c5.rgstatic.net\/m\/238176252723686\/styles\/ie.css\" type=\"text\/css\" rel=\"stylesheet\"\/><![endif]-->\n<link href=\"\/\/c5.rgstatic.net\/m\/217752362214895\/styles\/modules\/publicprofile.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<script src=\"\/\/c5.rgstatic.net\/m\/2321000301012716\/javascript\/vendor\/webfontloader\/webfontloader.js\" type=\"text\/javascript\"><\/script>\n <script>(function(i,s,o,g,r,a,m){i[\"GoogleAnalyticsObject\"]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,\"script\",\"\/\/www.google-analytics.com\/analytics.js\",\"ga\");\n ga(\"create\",\"UA-58591210-1\");ga(\"set\",\"anonymizeIp\",true);ga('set', 'dimension1', 'publication slurped');ga('set', 'dimension2', 'Conference Paper');ga('set', 'dimension3', 'Logged out');ga('set', 'dimension4', 'https');ga(\"send\",\"pageview\");<\/script>\n","webfont":"<noscript><\/noscript><script> WebFontConfig = { custom: { families: ['source_sans_pro_italic', 'source_sans_pro_bold', 'source_sans_pro', 'martel'], urls : ['\/\/c5.rgstatic.net\/m\/231392577336386\/styles\/fonts.css'] } }; WebFont.load(WebFontConfig); <\/script>\n","correlationId":"rgreq-e2667482-f011-4e2d-9f3b-fa3b478147cd","accountId":null,"module":"publicliterature","action":"publicliterature.PublicPublicationDetails","page":"publicationDetail","product":"publications","backendTime":471,"continent":"Asia","stylesHome":"\/\/c5.rgstatic.net\/m\/","staticHost":"c5.rgstatic.net","useEarlyFlush":false,"longRunningRequestIdentifier":"LongRunningRequest.publicliterature.PublicPublicationDetails","longRunningRequestFp":"e9e5bbe1366c7ee8c8e41d02f793c884ac9be19b","widgetId":"rgw40_56ab1c9d76a8a"},"id":"rgw40_56ab1c9d76a8a","partials":[],"templateName":"application\/stubs\/StaticHeader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.StaticHeader.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){
            Y.rg.core.pagespeed.Monitoring.monitorPage("\/\/glassmoni.researchgate.net", "publicliterature.PublicPublicationDetails.run.html.loggedOut.get", "59de9668d07aeb77ab4de5f24d382b5d199d2437", "rgreq-e2667482-f011-4e2d-9f3b-fa3b478147cd", "3892c11f497ba81445ed219fe81a5c811a38a209");
        
            Y.rg.core.pagespeed.Monitoring.monitorPage("\/\/glassmoni.researchgate.net", "publicationDetail.loggedOut", "ed1993d9e20f6cefa83edacaa24401a18c071aea", "rgreq-e2667482-f011-4e2d-9f3b-fa3b478147cd", "3892c11f497ba81445ed219fe81a5c811a38a209");
        })();
(function(){Y.rg.createInitialWidget({"data":{"year":"2016","inlinePromo":null,"isAdmin":false,"contactUrl":"https:\/\/www.researchgate.net\/contact","aboutUsUrl":"https:\/\/www.researchgate.net\/about","widgetId":"rgw41_56ab1c9d76a8a"},"id":"rgw41_56ab1c9d76a8a","partials":[],"templateName":"application\/stubs\/DefaultFooter.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.DefaultFooter.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"headerLogin":{"data":{"urlAfterLogin":"publication\/221346425_Bayesian_Learning_via_Stochastic_Gradient_Langevin_Dynamics","requestToken":"i80VxJZASMCFSiP+5NpiW+Ixi4RLinBshEKe2cWTEca\/uxBaaYmJ4QEO3QIkBmqAl9v8Z7LHPI6WoDoPMsmjy+3ug27Fu5RRAhWaLfcRFGdd2BB0xUt4noyhbZD8rW4OC41Fhg5yi+peNfLwHPMp36lCyFocHoqo3xQZE2Or5CInRlI9fVUsLf5DdQNL0OIuMSCStpFr8aKJeM7jxIfpk8IQB77WY0yzvDVaElpGbLJQzZdb6GB7CRLYlyy67yNVASmG4\/ccHiB20h7GuB\/q59F9kxmYo\/IQRXqIdY56gas=","loginUrl":"https:\/\/www.researchgate.net\/application.Login.html","signupUrl":"https:\/\/www.researchgate.net\/signup.SignUp.html?ev=su_chnl_index&hdrsu=1&_sg=-m7qnoq5EgZthpQBAlFhJzA_de8uUbUJ22e1kmwAg4r_035u3SlNszcbTPMhcRfz","encodedUrlAfterLogin":"cHVibGljYXRpb24vMjIxMzQ2NDI1X0JheWVzaWFuX0xlYXJuaW5nX3ZpYV9TdG9jaGFzdGljX0dyYWRpZW50X0xhbmdldmluX0R5bmFtaWNz","signupCallToAction":"Join for free","widgetId":"rgw43_56ab1c9d76a8a"},"id":"rgw43_56ab1c9d76a8a","partials":{"partial":"application\/stubs\/partials\/headerLoginDefault.html"},"templateName":"application\/stubs\/HeaderLogin.html","templateExtensions":[],"attrs":{"goal":"milestoneHeaderLoginSeen"},"widgetUrl":"https:\/\/www.researchgate.net\/application.HeaderLogin.html","viewClass":"views.application.HeaderLoginView","yuiModules":["rg.views.application.HeaderLoginView"],"stylesheets":[],"_isYUI":true},"cookieConsent":null,"logoSvgSrc":"https:\/\/c5.rgstatic.net\/m\/235107188705592\/images\/template\/brand-header-logo.svg","logoFallbackSrc":"https:\/\/c5.rgstatic.net\/m\/238113351022438\/images\/template\/brand-header-logo.png","widgetId":"rgw42_56ab1c9d76a8a"},"id":"rgw42_56ab1c9d76a8a","partials":{"schemaSocialProfiles":"application\/stubs\/partials\/schemaSocialProfiles.html"},"templateName":"application\/stubs\/HeaderLoggedOut.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.HeaderLoggedOut.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"logEvent":"su_banner","specialCopy":false,"widgetId":"rgw44_56ab1c9d76a8a"},"id":"rgw44_56ab1c9d76a8a","partials":[],"templateName":"application\/stubs\/LoggedOutBanner.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.LoggedOutBanner.html","viewClass":"views.application.LoggedOutBannerView","yuiModules":["rg.views.application.LoggedOutBannerView"],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.core.util.ParameterFilter.filter(["ev","cp","ch","ref","dbw","pli","loginT","uid","claimChannel","enrichId","enrichSource","utm_source","utm_medium","utm_campaign","el","ci"]);})();
});}); } else { throw 'YRG was not loaded when attaching widgets'; }</script><script> dataLayer = [{"pageCategory":"publication slurped","publicationType":"Conference Paper","eventCategory":"Publication page"}]; </script> <noscript><iframe src="//www.googletagmanager.com/ns.html?id=GTM-MKVKH7" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-MKVKH7');</script><script>(function(e){function n(n,t,o,a){"use strict";var i=e.document.createElement("link"),r=t||e.document.getElementsByTagName("script")[0],d=e.document.styleSheets;return i.rel="stylesheet",i.href=n,i.media="only x",a&&(i.onload=a),r.parentNode.insertBefore(i,r),i.onloadcssdefined=function(e){for(var t,o=0;d.length>o;o++)d[o].href&&d[o].href.indexOf(n)>-1&&(t=!0);t?e():setTimeout(function(){i.onloadcssdefined(e)})},i.onloadcssdefined(function(){i.media=o||"all"}),i}function t(e,n){e.onload=function(){e.onload=null,n&&n.call(e)},"isApplicationInstalled"in navigator&&"onloadcssdefined"in e&&e.onloadcssdefined(n)}var o=function(a,i){"use strict";if(a&&3===a.length){var r=e.Image,d=!(!document.createElementNS||!document.createElementNS("http://www.w3.org/2000/svg","svg").createSVGRect||!document.implementation.hasFeature("http://www.w3.org/TR/SVG11/feature#Image","1.1")||e.opera&&-1===navigator.userAgent.indexOf("Chrome")||-1!==navigator.userAgent.indexOf("Series40")),c=new r;c.onerror=function(){o.method="png",o.href=a[2],n(a[2])},c.onload=function(){var e=1===c.width&&1===c.height,r=a[e&&d?0:e?1:2];o.method=e&&d?"svg":e?"datapng":"png",o.href=r,t(n(r),i)},c.src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///ywAAAAAAQABAAACAUwAOw==",document.documentElement.className+=" grunticon"}};o.loadCSS=n,o.onloadCSS=t,e.grunticon=o})(this);grunticon(["https://c5.rgstatic.net/c/o1o9o3/styles/icons/_header-ico.svg.css", "https://c5.rgstatic.net/c/o1o9o3/styles/icons/_header-ico.png.css", "https://c5.rgstatic.net/c/o1o9o3/styles/icons/_header-ico.fallback.scss"]);grunticon(["https://c5.rgstatic.net/c/o1o9o3/styles/icons/_admin-ico.svg.css", "https://c5.rgstatic.net/c/o1o9o3/styles/icons/_admin-ico.png.css", "https://c5.rgstatic.net/c/o1o9o3/styles/icons/_admin-ico.fallback.scss"]);grunticon(["https://c5.rgstatic.net/c/o1o9o3/styles/icons/_ico.svg.css", "https://c5.rgstatic.net/c/o1o9o3/styles/icons/_ico.png.css", "https://c5.rgstatic.net/c/o1o9o3/styles/icons/_ico.fallback.scss"]);</script></body>
</html>
