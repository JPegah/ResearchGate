<!DOCTYPE html> <html lang="en" class="" id="rgw40_56aba0bb928c6"> <head > <meta charset="utf-8"/> <meta http-equiv="content-type" content="text/html; charset=UTF-8"/> <meta name="Rg-Request-Token" id="Rg-Request-Token" content="+ittulQqRoOZCZ6PLxndSKQiu+TIAQ72vB5I97Y+fUAJaYFOFFh/rx6uITwRq5Sat044U91DIvKybIktPwehxCJYoBNNcWOmBxPNQWL3BA1ncCo6KqJ74a5G+Su/LAShj6WCTAz8p+nF0pU+wkSeH905BXWsRB8uf0wP9KwHnjwEhwIJi3AmxyqtNEGYScUKal0/wXWYQRk0qixBbqUT+FDhn4rI3f0KxZGUFk0jVQY0nBb2y6yIoYPlrBgxi4Z/udkO3TPGE2gyhjhci9Sp6C51ECbcg3lSk/2iaz36uEY="/> <meta http-equiv="expires" content="0"/> <link rel="apple-touch-icon" sizes="57x57" href="https://www.researchgate.net/apple-touch-icon-57x57.png"> <link rel="apple-touch-icon" sizes="60x60" href="https://www.researchgate.net/apple-touch-icon-60x60.png"> <link rel="apple-touch-icon" sizes="72x72" href="https://www.researchgate.net/apple-touch-icon-72x72.png"> <link rel="apple-touch-icon" sizes="76x76" href="https://www.researchgate.net/apple-touch-icon-76x76.png"> <link rel="apple-touch-icon" sizes="114x114" href="https://www.researchgate.net/apple-touch-icon-114x114.png"> <link rel="apple-touch-icon" sizes="120x120" href="https://www.researchgate.net/apple-touch-icon-120x120.png"> <link rel="apple-touch-icon" sizes="144x144" href="https://www.researchgate.net/apple-touch-icon-144x144.png"> <link rel="apple-touch-icon" sizes="152x152" href="https://www.researchgate.net/apple-touch-icon-152x152.png"> <link rel="apple-touch-icon" sizes="180x180" href="https://www.researchgate.net/apple-touch-icon-180x180.png"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-32x32.png" sizes="32x32"> <link rel="icon" type="image/png" href="https://www.researchgate.net/android-chrome-192x192.png" sizes="192x192"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-96x96.png" sizes="96x96"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-16x16.png" sizes="16x16"> <link rel="shortcut icon" type="image/x-icon" href="https://c5.rgstatic.net/m/2390829798215018/images/favicon.ico"/> <link rel="manifest" href="https://www.researchgate.net/manifest.json"> <meta name="msapplication-TileColor" content="#da532c"> <meta name="msapplication-TileImage" content="https://www.researchgate.net/mstile-144x144.png"> <meta name="theme-color" content="#444444"> <link rel="search" type="application/opensearchdescription+xml" title="ResearchGate search" href="https://www.researchgate.net/application.DownloadOpenSearchPlugin.html"/> <link rel="meta" type="application/rdf+xml" title="ICRA labels" href="https://www.researchgate.net/application.DownloadLabels.html"/> <link rel="http://oexchange.org/spec/0.8/rel/related-target" type="application/xrd+xml" href="https://www.researchgate.net/application.DownloadOExchange.html"/> <base href="https://www.researchgate.net/"/> <script>
    var rgConfig = {
        correlationId: "rgreq-3127d4e9-8a61-4c1d-ae84-2dc6ecfd704b",
        accountId: "",
        module: "publicliterature",
        action: "publicliterature.PublicPublicationDetails",
        page: "publicationDetail",
        product: "publications",
        continent: "Asia",
        stylesHome: "//c5.rgstatic.net/m/",
        staticHost: "c5.rgstatic.net",
        longRunningRequestIdentifier: "LongRunningRequest.publicliterature.PublicPublicationDetails",
        longRunningRequestFp: "e9e5bbe1366c7ee8c8e41d02f793c884ac9be19b"
    };
    window.rootUrl = "https://www.researchgate.net/";
</script> <link rel="canonical" href="https://www.researchgate.net/publication/277022910_Weight_Uncertainty_in_Neural_Networks" />
<link rel="dns-prefetch" href="//c5.rgstatic.net" />
<link rel="dns-prefetch" href="//i1.rgstatic.net" />
<meta property="twitter:card" content="summary" />
<meta property="twitter:site" content="@ResearchGate" />
<meta property="og:title" content="Weight Uncertainty in Neural Networks" />
<meta property="og:description" content="We introduce a new, efficient, principled and backpropagation-compatible
algorithm for learning a probability distribution on the weights of a neural
network, called Bayes by Backprop. It..." />
<meta property="og:site_name" content="ResearchGate" />
<meta property="og:image" content="https://i1.rgstatic.net/publication/277022910_Weight_Uncertainty_in_Neural_Networks/links/56ab3cb808aeadd1bdccd5b7/smallpreview.png" />
<meta property="og:url" content="https://www.researchgate.net/publication/277022910_Weight_Uncertainty_in_Neural_Networks" />
<meta property="rg:id" content="PB:277022910" />
<meta name="DC.identifier" scheme="DCTERMS.URI" content="http://dx.doi.org/" />
<meta name="gs_meta_revision" content="1.1" />
<meta name="citation_title" content="Weight Uncertainty in Neural Networks" />
<meta name="citation_author" content="Charles Blundell" />
<meta name="citation_author" content="Julien Cornebise" />
<meta name="citation_author" content="Koray Kavukcuoglu" />
<meta name="citation_author" content="Daan Wierstra" />
<meta name="citation_publication_date" content="2015/05/20" />
<meta name="citation_pdf_url" content="https://www.researchgate.net/profile/Julien_Cornebise/publication/277022910_Weight_Uncertainty_in_Neural_Networks/links/56ab3cb808aeadd1bdccd5b7.pdf" />
<meta name="citation_abstract_html_url" content="https://www.researchgate.net/publication/277022910_Weight_Uncertainty_in_Neural_Networks" />
<meta name="citation_fulltext_html_url" content="https://www.researchgate.net/publication/277022910_Weight_Uncertainty_in_Neural_Networks" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<link href="//c5.rgstatic.net/m/22664197317151888/styles/rg.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/21004998181197492/styles/rg2.css" type="text/css" rel="stylesheet"/>
<!--[if lt IE 9]><link href="//c5.rgstatic.net/m/238176252723686/styles/ie.css" type="text/css" rel="stylesheet"/><![endif]-->
<link href="//c5.rgstatic.net/m/217752362214895/styles/modules/publicprofile.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/21993347442549/styles/pow/publicliterature/FollowPublicationPromo.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/282514599719602/styles/pow/application/PdfJsReader.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/23819663151220/styles/pow/publicliterature/PublicationInlineReader.css" type="text/css" rel="stylesheet"/>
<script src="//c5.rgstatic.net/m/2321000301012716/javascript/vendor/webfontloader/webfontloader.js" type="text/javascript"></script>
 <script>(function(i,s,o,g,r,a,m){i["GoogleAnalyticsObject"]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,"script","//www.google-analytics.com/analytics.js","ga");
 ga("create","UA-58591210-1");ga("set","anonymizeIp",true);ga('set', 'dimension1', 'publication full-text');ga('set', 'dimension2', 'Article');ga('set', 'dimension3', 'Logged out');ga('set', 'dimension4', 'https');ga("send","pageview");</script>
  <script> WebFontConfig = { custom: { families: ['source_sans_pro_italic', 'source_sans_pro_bold', 'source_sans_pro', 'martel'], urls : ['//c5.rgstatic.net/m/231392577336386/styles/fonts.css'] } }; WebFont.load(WebFontConfig); </script><noscript></noscript>

<title>Weight Uncertainty in Neural Networks (PDF Download Available)</title>
<meta name="description" content="Official Full-Text Publication: Weight Uncertainty in Neural Networks on ResearchGate, the professional network for scientists."/>
<meta name="keywords" content="scientific network, scientific platform, scientific community, research partner, research collaboration, journal articles, international collaboration, find researcher, lifescience researcher, interdisciplinary research, research collaboration"/>
</head>
<body class="use-svg-icons logged-out">
<div id="page-container">
<script type="text/javascript">var googletag = googletag || {}; googletag.cmd = googletag.cmd || [];
(function() { var gads = document.createElement("script"); gads.async = true; gads.type = "text/javascript"; var useSSL = "https:" == document.location.protocol; gads.src = (useSSL ? "https:" : "http:") + "//www.googletagservices.com/tag/js/gpt.js"; var node =document.getElementsByTagName("script")[0]; node.parentNode.insertBefore(gads, node); })();</script><div id="main" class="logged-out-header-support">
<div id="content" class="">

<noscript>
<div class="c-box-warning full-width-element" style="text-align: center; ">
    <div style="margin: auto; padding:10px;" class="container">
        <b>For full functionality of ResearchGate it is necessary to enable JavaScript.
            Here are the <a href="http://www.enable-javascript.com/" rel="nofollow" target="_blank">
                instructions how to enable JavaScript in your web browser</a>.</b>
    </div>
</div>
</noscript>

<div id="rgw1_56aba0bb928c6" itemscope itemtype="http://schema.org/ScholarlyArticle"><div class="publication-wrapper publication-wrapper-onecol" id="rgw2_56aba0bb928c6" itemscope itemtype="http://schema.org/ScholarlyArticle"> <div class="c-col-content"> <div class="c-content"> <div class="clearfix">  <div class="publication-header"> <div id="rgw5_56aba0bb928c6">  <div class="type-label"> Article   </div> <span class="Z3988" title="ctx_ver=Z39.88-2004&rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&rfr_id=info%3Asid%2Fresearchgate.net%3Aresearchgate&rft.atitle=Weight%20Uncertainty%20in%20Neural%20Networks&rft.date=2015&rft.au=Charles%20Blundell%2CJulien%20Cornebise%2CKoray%20Kavukcuoglu%2CDaan%20Wierstra&rft.genre=article"></span> <h1 class="pub-title" itemprop="name">Weight Uncertainty in Neural Networks</h1> <meta itemprop="headline" content="Weight Uncertainty in Neural Networks">  <meta itemprop="image" content="https://i1.rgstatic.net/publication/277022910_Weight_Uncertainty_in_Neural_Networks/links/56ab3cb808aeadd1bdccd5b7/smallpreview.png">  <div id="rgw7_56aba0bb928c6" class="publication-detail-author-list"> <div> <ul class="clearfix js-people-list">  <li id="rgw8_56aba0bb928c6"> <a href="researcher/2074234412_Charles_Blundell" class="pub-detail-item author-item" itemprop="author" itemscope itemtype="http://schema.org/Person"> <div class="indent-left"> <div class="people-img">  <img src="https://c5.rgstatic.net/m/2951093203564/images/template/default/profile/profile_default_s.jpg" title="Charles Blundell" alt="Charles Blundell" height="20px" width="20px" style="height: 20px;"/>  </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Charles Blundell</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item   not-claimed " id="rgw9_56aba0bb928c6">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="researcher/2074234412_Charles_Blundell"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="Charles Blundell" alt="Charles Blundell" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">       </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="researcher/2074234412_Charles_Blundell" class="display-name">Charles Blundell</a>    </h5> <div class="truncate-single-line meta">   </div>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>  <li id="rgw10_56aba0bb928c6" itemprop="author" itemscope itemtype="http://schema.org/Person"> <a itemprop="sameAs" href="profile/Julien_Cornebise" class="pub-detail-item account-item"> <div class="indent-left"> <div class="people-img"> <img  src="https://c5.rgstatic.net/m/2671872220764/images/template/default/profile/profile_default_m.jpg" title="Julien Cornebise" alt="Julien Cornebise" height="20px" width="20px" style="height: 20px;"/> </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Julien Cornebise</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item  remove-action-indent   " id="rgw11_56aba0bb928c6" data-account-key="Julien_Cornebise">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="profile/Julien_Cornebise"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="Julien Cornebise" alt="Julien Cornebise" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">     </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="profile/Julien_Cornebise" class="display-name">Julien Cornebise</a>    </h5> <div class="truncate-single-line meta">   <a class="meta ga-top-coauthor-institution" href="institution/Google_Inc" title="Google Inc.">Google Inc.</a>     </div>  <a href="javascript:" class="btn btn-promote btn-large people-item-contact-author js-contact-author">Message author</a>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>  <li id="rgw12_56aba0bb928c6"> <a href="researcher/2040167286_Koray_Kavukcuoglu" class="pub-detail-item author-item" itemprop="author" itemscope itemtype="http://schema.org/Person"> <div class="indent-left"> <div class="people-img">  <img src="https://c5.rgstatic.net/m/2951093203564/images/template/default/profile/profile_default_s.jpg" title="Koray Kavukcuoglu" alt="Koray Kavukcuoglu" height="20px" width="20px" style="height: 20px;"/>  </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Koray Kavukcuoglu</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item   not-claimed " id="rgw13_56aba0bb928c6">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="researcher/2040167286_Koray_Kavukcuoglu"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="Koray Kavukcuoglu" alt="Koray Kavukcuoglu" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">       </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="researcher/2040167286_Koray_Kavukcuoglu" class="display-name">Koray Kavukcuoglu</a>    </h5> <div class="truncate-single-line meta">   </div>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>  <li id="rgw14_56aba0bb928c6"> <a href="researcher/12447169_Daan_Wierstra" class="pub-detail-item author-item" itemprop="author" itemscope itemtype="http://schema.org/Person"> <div class="indent-left"> <div class="people-img">  <img src="https://c5.rgstatic.net/m/2951093203564/images/template/default/profile/profile_default_s.jpg" title="Daan Wierstra" alt="Daan Wierstra" height="20px" width="20px" style="height: 20px;"/>  </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Daan Wierstra</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item   not-claimed " id="rgw15_56aba0bb928c6">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="researcher/12447169_Daan_Wierstra"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="Daan Wierstra" alt="Daan Wierstra" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">       </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="researcher/12447169_Daan_Wierstra" class="display-name">Daan Wierstra</a>    </h5> <div class="truncate-single-line meta">   </div>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>   </ul> <div class="js-loading"></div>  </div> </div> <div class="pub-details js-pub-details">        <meta itemprop="datePublished" content="2015-05">  05/2015;               <div class="pub-source"> Source: <a href="http://arxiv.org/abs/1505.05424" rel="nofollow">arXiv</a> </div>  </div> <div id="rgw16_56aba0bb928c6" class="pub-abstract">  <div class="clearfix">   <div style="max-height: 54px;" class="js-expander-container js-expander-collapsed">  <p itemprop="description"> <strong>ABSTRACT</strong> <div>We introduce a new, efficient, principled and backpropagation-compatible<br />
algorithm for learning a probability distribution on the weights of a neural<br />
network, called Bayes by Backprop. It regularises the weights by minimising a<br />
compression cost, known as the variational free energy or the expected lower<br />
bound on the marginal likelihood. We show that this principled kind of<br />
regularisation yields comparable performance to dropout on MNIST<br />
classification. We then demonstrate how the learnt uncertainty in the weights<br />
can be used to improve generalisation in non-linear regression problems, and<br />
how this weight uncertainty can be used to drive the exploration-exploitation<br />
trade-off in reinforcement learning.</div> </p>  </div>  </div>   </div>      <div class="action-container"> <div id="rgw17_56aba0bb928c6" class="follow-publication-promo"> <table> <tr> <td class="follow-publication-promo-text-cell"> <p>Get notified about updates to this publication</p> <a class="btn btn-large btn-promote js-follow-publication ga-follow-publication-new-promo">Follow publication</a> </td> <td> <div class="follow-publication-publication-image"></div> </td> </tr> </table> </div>  <div class="clear"></div> <div class="share-dialog-container" style="display: none;">  </div> </div> </div> <div style="margin-left: -20px; margin-right: -20px;">  </div> </div>  <div class="publication-detail-dfp-container rf"> <div id="rgw31_56aba0bb928c6">  </div> </div>  </div>  <div class="clearfix"> <div class="pdf-js-container clearfix " id="rgw32_56aba0bb928c6">  <div class="pdf-js-header js-sticky-header clear">  <a class="blue-link js-download rf btn btn-promote" href="https://www.researchgate.net/profile/Julien_Cornebise/publication/277022910_Weight_Uncertainty_in_Neural_Networks/links/56ab3cb808aeadd1bdccd5b7.pdf?inViewer=0&amp;pdfJsDownload=0&amp;origin=publication_detail">Download full-text</a>  <h3>Full-text</h3> <span class="publication-info">  <span class="js-doi-container" style="display: none;"> DOI: <span class="js-doi"></span> &middot; </span> Available from: <a class="js-name" href="profile/Julien_Cornebise">Julien Cornebise</a>, <span class="js-publication-date"> Jan 29, 2016 </span>   </span>  </div>  <div class="social-share-container"><div id="rgw34_56aba0bb928c6" class="social-share js-social-share"> <div class="social-share-heading">Share</div>  <a id="rgw35_56aba0bb928c6" href="javascript:" title="Share on Facebook" class="link-nostyle js-share-item share-icon "  data-url="http://www.facebook.com/share.php?u={{url}}{{#title}}&amp;t={{title}}{{/title}}" data-width="600" data-height="350" data-name="Facebook"> <span class="share-icon ico-share-facebook-round reset-background ga-share-blog-facebook"></span> </a>  <a id="rgw36_56aba0bb928c6" href="javascript:" title="Share on Twitter" class="link-nostyle js-share-item share-icon "  data-url="http://twitter.com/intent/tweet?text={{#title}}{{title}}: {{/title}}{{url}}&amp;via=researchgate" data-width="600" data-height="350" data-name="Twitter"> <span class="share-icon ico-share-twitter-round reset-background ga-share-blog-twitter"></span> </a>  <a id="rgw37_56aba0bb928c6" href="javascript:" title="Share on Google+" class="link-nostyle js-share-item share-icon "  data-url="https://plus.google.com/share?url={{url}}" data-width="600" data-height="600" data-name="Google+"> <span class="share-icon ico-share-gplus-round reset-background ga-share-blog-gplus"></span> </a>  <a id="rgw38_56aba0bb928c6" href="javascript:" title="Share on LinkedIn" class="link-nostyle js-share-item share-icon "  data-url="http://www.linkedin.com/shareArticle?mini=true&amp;url={{url}}{{#title}}&amp;title={{title}}{{/title}}&amp;source=ResearchGate" data-width="520" data-height="570" data-name="LinkedIn"> <span class="share-icon ico-share-linkedin-round reset-background ga-share-blog-linkedin"></span> </a>  <a id="rgw39_56aba0bb928c6" href="javascript:" title="Share on Reddit" class="link-nostyle js-share-item share-icon "  data-url="https://www.reddit.com/submit?url={{url}}{{#title}}&amp;title={{title}}{{/title}}" data-width="600" data-height="600" data-name="Reddit"> <span class="share-icon ico-share-reddit reset-background ga-share-blog-reddit"></span> </a>  </div></div>    <iframe id="rgw33_56aba0bb928c6" src="https://www.researchgate.net/c/o1q2er/javascript/lib/pdfjs/web/viewer.html?file=https%3A%2F%2Fwww.researchgate.net%2Fprofile%2FJulien_Cornebise%2Fpublication%2F277022910_Weight_Uncertainty_in_Neural_Networks%2Flinks%2F56ab3cb808aeadd1bdccd5b7.pdf%3FinViewer%3D1%26pdfJsDownload%3D1%26origin%3Dpublication_detail" allowfullscreen frameborder="0" style="width: 100%; height: 100%; box-sizing: border-box;"></iframe>    </div> <noscript> <div id="rgw30_56aba0bb928c6"  itemprop="articleBody">  <p>Page 1</p> <p>Weight Uncertainty in Neural Networks<br />Charles Blundell<br />Julien Cornebise<br />Koray Kavukcuoglu<br />Daan Wierstra<br />Google DeepMind<br />CBLUNDELL@GOOGLE.COM<br />JUCOR@GOOGLE.COM<br />KORAYK@GOOGLE.COM<br />WIERSTRA@GOOGLE.COM<br />Abstract<br />We introduce a new, efficient, principled and<br />backpropagation-compatible algorithm for learn-<br />ing a probability distribution on the weights of<br />a neural network, called Bayes by Backprop. It<br />regularises the weights by minimising a com-<br />pression cost, known as the variational free en-<br />ergy or the expected lower bound on the marginal<br />likelihood. We show that this principled kind<br />of regularisation yields comparable performance<br />to dropout on MNIST classification. We then<br />demonstrate how the learnt uncertainty in the<br />weights can be used to improve generalisation<br />in non-linear regression problems, and how this<br />weight uncertainty can be used to drive the<br />exploration-exploitation trade-off in reinforce-<br />ment learning.<br />1. Introduction<br />Plain feedforward neural networks are prone to overfit-<br />ting. When applied to supervised or reinforcement learn-<br />ing problems these networks are also often incapable of<br />correctly assessing the uncertainty in the training data and<br />so make overly confident decisions about the correct class,<br />prediction or action. We shall address both of these con-<br />cerns by using variational Bayesian learning to introduce<br />uncertainty in the weights of the network. We call our al-<br />gorithm Bayes by Backprop. We suggest at least three mo-<br />tivations for introducing uncertainty on the weights: 1) reg-<br />ularisation via a compression cost on the weights, 2) richer<br />representations and predictions from cheap model averag-<br />ing, and 3) exploration in simple reinforcement learning<br />problems such as contextual bandits.<br />Variousregularisationschemeshavebeendevelopedtopre-<br />Proceedings of the 32ndInternational Conference on Machine<br />Learning, Lille, France, 2015. JMLR: W&amp;CP volume 37. Copy-<br />right 2015 by the author(s).<br />vent overfitting in neural networks such as early stopping,<br />weight decay, and dropout (Hinton et al., 2012). In this<br />work, we introduce an efficient, principled algorithm for<br />regularisation built upon Bayesian inference on the weights<br />of the network (MacKay, 1992; Buntine and Weigend,<br />1991; MacKay, 1995). This leads to a simple approxi-<br />mate learning algorithm similar to backpropagation (Le-<br />Cun, 1985; Rumelhart et al., 1988). We shall demonstrate<br />how this uncertainty can improve predictive performance<br />in regression problems by expressing uncertainty in regions<br />with little or no data, how this uncertainty can lead to more<br />systematic exploration than ?-greedy in contextual bandit<br />tasks.<br />All weights in our neural networks are represented by prob-<br />abilitydistributionsoverpossiblevalues, ratherthanhaving<br />a single fixed value as is the norm (see Figure 1). Learnt<br />representations and computations must therefore be robust<br />under perturbation of the weights, but the amount of per-<br />turbation each weight exhibits is also learnt in a way that<br />coherently explains variability in the training data. Thus<br />instead of training a single network, the proposed method<br />trains an ensemble of networks, where each network has its<br />weights drawn from a shared, learnt probability distribu-<br />tion. Unlike other ensemble methods, our method typically<br />only doubles the number of parameters yet trains an infi-<br />nite ensemble using unbiased Monte Carlo estimates of the<br />gradients.<br />In general, exact Bayesian inference on the weights of a<br />neural network is intractable as the number of parameters<br />is very large and the functional form of a neural network<br />does not lend itself to exact integration. Instead we take a<br />variational approximation to exact Bayesian updates. We<br />build upon the work of Graves (2011), who in turn built<br />upon the work of Hinton and Van Camp (1993). In con-<br />trast to this previous work, we show how the gradients<br />of Graves (2011) can be made unbiased and further how<br />this method can be used with non-Gaussian priors. Con-<br />sequently, Bayes by Backprop attains performance compa-<br />rable to that of dropout (Hinton et al., 2012). Our method<br />arXiv:1505.05424v2  [stat.ML]  21 May 2015</p>  <p>Page 2</p> <p>Weight Uncertainty in Neural Networks<br />H1H2H3<br />1<br />X1<br />Y<br />0.5<br />0.1<br />0.7<br />1.3<br />1.4<br />0.3<br />1.2<br />0.10.1<br />0.2<br />H1H2H3<br />1<br />X1<br />Y<br />Figure 1. Left: each weight has a fixed value, as provided by clas-<br />sical backpropagation. Right: each weight is assigned a distribu-<br />tion, as provided by Bayes by Backprop.<br />is related to recent methods in deep, generative modelling<br />(Kingma and Welling, 2014; Rezende et al., 2014; Gregor<br />et al., 2014), where variational inference has been applied<br />to stochastic hidden units of an autoencoder. Whilst the<br />number of stochastic hidden units might be in the order of<br />thousands, the number of weights in a neural network is<br />easilytwoordersofmagnitudelarger, makingtheoptimisa-<br />tion problem much larger scale. Uncertainty in the hidden<br />units allows the expression of uncertainty about a particular<br />observation, uncertainty in the weights is complementary<br />in that it captures uncertainty about which neural network<br />is appropriate, leading to regularisation of the weights and<br />model averaging.<br />This uncertainty can be used to drive exploration in contex-<br />tual bandit problems using Thompson sampling (Thomp-<br />son, 1933; Chapelle and Li, 2011; Agrawal and Goyal,<br />2012; May et al., 2012). Weights with greater uncertainty<br />introduce more variability into the decisions made by the<br />network, leading naturally to exploration. As more data are<br />observed, the uncertainty can decrease, allowing the deci-<br />sions made by the network to become more deterministic<br />as the environment is better understood.<br />The remainder of the paper is organised as follows: Sec-<br />tion 2 introduces notation and standard learning in neural<br />networks, Section 3 describes variational Bayesian learn-<br />ing for neural networks and our contributions, Section 4<br />describes the application to contextual bandit problems,<br />whilst Section 5 contains empirical results on a classifica-<br />tion, a regression and a bandit problem. We conclude with<br />a brief discussion in Section 6.<br />2. Point Estimates of Neural Networks<br />We view a neural network as a probabilistic model<br />P(y|x,w): given an input x ∈ Rpa neural network as-<br />signs a probability to each possible output y ∈ Y, using<br />the set of parameters or weights w. For classification, Y is<br />asetofclassesandP(y|x,w)isacategoricaldistribution–<br />this corresponds to the cross-entropy or softmax loss, when<br />the parameters of the categorical distribution are passed<br />through the exponential function then re-normalised. For<br />regression Y is R and P(y|x,w) is a Gaussian distribution<br />– this corresponds to a squared loss.<br />Inputs x are mapped onto the parameters of a distribu-<br />tion on Y by several successive layers of linear transforma-<br />tion (given by w) interleaved with element-wise non-linear<br />transforms.<br />The weights can be learnt by maximum likelihood estima-<br />tion (MLE): given a set of training examples D = (xi,yi)i,<br />the MLE weights wMLEare given by:<br />wMLE= argmax<br />w<br />logP(D|w)<br />?<br />= argmax<br />w<br />i<br />logP(yi|xi,w).<br />This is typically achieved by gradient descent (e.g., back-<br />propagation), where we assume that logP(D|w) is differ-<br />entiable in w.<br />Regularisation can be introduced by placing a prior upon<br />the weights w and finding the maximum a posteriori<br />(MAP) weights wMAP:<br />wMAP= argmax<br />w<br />logP(w|D)<br />logP(D|w) + logP(w).= argmax<br />w<br />If w are given a Gaussian prior, this yields L2 regularisa-<br />tion (or weight decay). If w are given a Laplace prior, then<br />L1 regularisation is recovered.<br />3. Being Bayesian by Backpropagation<br />Bayesian inference for neural networks calculates the pos-<br />terior distribution of the weights given the training data,<br />P(w|D).<br />about unseen data by taking expectations: the predictive<br />distribution of an unknown label ˆ y of a test data item ˆ x,<br />is given by P(ˆ y|ˆ x) = EP(w|D)[P(ˆ y|ˆ x,w)]. Each pos-<br />sible configuration of the weights, weighted according to<br />the posterior distribution, makes a prediction about the un-<br />known label given the test data item ˆ x. Thus taking an<br />expectation under the posterior distribution on weights is<br />equivalent to using an ensemble of an uncountably infi-<br />nite number of neural networks. Unfortunately, this is in-<br />tractable for neural networks of any practical size.<br />This distribution answers predictive queries<br />Previously Hinton and Van Camp (1993) and Graves<br />(2011) suggested finding a variational approximation to the<br />Bayesian posterior distribution on the weights. Variational<br />learning finds the parameters θ of a distribution on the<br />weights q(w|θ) that minimises the Kullback-Leibler (KL)</p>  <p>Page 3</p> <p>Weight Uncertainty in Neural Networks<br />divergence with the true Bayesian posterior on the weights:<br />θ?= argmin<br />θ<br />KL[q(w|θ)||P(w|D)]<br />?<br />KL[q(w|θ) || P(w)] − Eq(w|θ)[logP(D|w)].<br />= argmin<br />θ<br />q(w|θ)log<br />q(w|θ)<br />P(w)P(D|w)dw<br />= argmin<br />θ<br />The resulting cost function is variously known as the varia-<br />tional free energy (Neal and Hinton, 1998; Yedidia et al.,<br />2000; Friston et al., 2007) or the expected lower bound<br />(Saul et al., 1996; Neal and Hinton, 1998; Jaakkola and<br />Jordan, 2000). For simplicity we shall denote it as<br />F(D,θ) = KL[q(w|θ) || P(w)]<br />− Eq(w|θ)[logP(D|w)].<br />(1)<br />The cost function of (1) is a sum of a data-dependent part,<br />which we shall refer to as the likelihood cost, and a prior-<br />dependent part, which we shall refer to as the complexity<br />cost. The cost function embodies a trade-off between satis-<br />fying the complexity of the data D and satisfying the sim-<br />plicity prior P(w). (1) is also readily given an information<br />theoretic interpretation as a minimum description length<br />cost (Hinton and Van Camp, 1993; Graves, 2011). Exactly<br />minimisingthiscostna¨ ıvelyiscomputationallyprohibitive.<br />Instead gradient descent and various approximations are<br />used.<br />3.1. Unbiased Monte Carlo gradients<br />Under certain conditions, the derivative of an expectation<br />can be expressed as the expectation of a derivative:<br />Proposition 1. Let ? be a random variable having a prob-<br />ability density given by q(?) and let w = t(θ,?) where<br />t(θ,?) is a deterministic function. Suppose further that<br />the marginal probability density of w, q(w|θ), is such that<br />q(?)d? = q(w|θ)dw. Then for a function f with deriva-<br />tives in w:<br />?∂f(w,θ)<br />∂<br />∂θEq(w|θ)[f(w,θ)] = Eq(?)<br />∂w<br />∂w<br />∂θ+∂f(w,θ)<br />∂θ<br />?<br />.<br />Proof.<br />∂<br />∂θEq(w|θ)[f(w,θ)] =<br />∂<br />∂θ<br />∂<br />∂θ<br />?<br />?<br />f(w,θ)q(w|θ)dw<br />=f(w,θ)q(?)d?<br />?∂f(w,θ)<br />= Eq(?)<br />∂w<br />∂w<br />∂θ+∂f(w,θ)<br />∂θ<br />?<br />The deterministic function t(θ,?) transforms a sample of<br />parameter-free noise ? and the variational posterior param-<br />eters θ into a sample from the variational posterior. Below<br />we shall see how this transform works in practice for the<br />Gaussian case.<br />We apply Proposition 1 to the optimisation problem in<br />(1): let f(w,θ) = logq(w|θ) − logP(w)P(D|w). Us-<br />ing Monte Carlo sampling to evaluate the expectations,<br />a backpropagation-like (LeCun, 1985; Rumelhart et al.,<br />1988) algorithm is obtained for variational Bayesian infer-<br />ence in neural networks – Bayes by Backprop – which uses<br />unbiased estimates of gradients of the cost in (1) to learn a<br />distribution over the weights of a neural network.<br />Proposition 1 is a generalisation of the Gaussian re-<br />parameterisation trick (Opper and Archambeau, 2009;<br />Kingma and Welling, 2014; Rezende et al., 2014) used for<br />latent variable models, applied to Bayesian learning of neu-<br />ral networks. Our work differs from this previous work in<br />several significant ways. Bayes by Backprop operates on<br />weights (of which there are a great many), whilst most pre-<br />vious work applies this method to learning distributions on<br />stochastic hidden units (of which there are far fewer than<br />the number of weights). Titsias and L´ azaro-Gredilla (2014)<br />considered a large-scale logistic regression task. Unlike<br />previous work, we do not use the closed form of the com-<br />plexity cost (or entropic part): not requiring a closed form<br />of the complexity cost allows many more combinations of<br />prior and variational posterior families. Indeed this scheme<br />is also simple to implement and allows prior/posterior com-<br />binations to be interchanged. We approximate the exact<br />cost (1) as:<br />F(D,θ) ≈<br />n<br />?<br />i=1<br />logq(w(i)|θ) − logP(w(i))<br />− logP(D|w(i))<br />(2)<br />wherew(i)denotestheithMonteCarlosampledrawnfrom<br />the variational posterior q(w(i)|θ). Note that every term of<br />this approximate cost depends upon the particular weights<br />drawn from the variational posterior: this is an instance of<br />a variance reduction technique known as common random<br />numbers (Owen, 2013). In previous work, where a closed<br />form complexity cost or closed form entropy term are used,<br />part of the cost is sensitive to particular draws from the<br />posterior, whilst the closed form part is oblivious. Since<br />each additive term in the approximate cost in (2) uses the<br />same weight samples, the gradients of (2) are only affected<br />by the parts of the posterior distribution characterised by<br />the weight samples. In practice, we did not find this to<br />perform better than using a closed form KL (where it could<br />be computed), but we did not find it to perform worse. In<br />our experiments, we found that a prior without an easy-to-<br />compute closed form complexity cost performed best.</p>  <p>Page 4</p> <p>Weight Uncertainty in Neural Networks<br />3.2. Gaussian variational posterior<br />Suppose that the variational posterior is a diagonal Gaus-<br />sian distribution, then a sample of the weights w can be<br />obtained by sampling a unit Gaussian, shifting it by a mean<br />µ and scaling by a standard deviation σ. We parameterise<br />the standard deviation pointwise as σ = log(1 + exp(ρ))<br />and so σ is always non-negative. The variational posterior<br />parameters are θ = (µ,ρ). Thus the transform from a sam-<br />ple of parameter-free noise and the variational posterior pa-<br />rameters that yields a posterior sample of the weights w is:<br />w = t(θ,?) = µ + log(1 + exp(ρ)) ◦ ? where ◦ is point-<br />wise multiplication. Each step of optimisation proceeds as<br />follows:<br />1. Sample ? ∼ N(0,I).<br />2. Let w = µ + log(1 + exp(ρ)) ◦ ?.<br />3. Let θ = (µ,ρ).<br />4. Let f(w,θ) = logq(w|θ) − logP(w)P(D|w).<br />5. Calculate the gradient with respect to the mean<br />∆µ=∂f(w,θ)<br />∂w<br />+∂f(w,θ)<br />∂µ<br />.<br />(3)<br />6. Calculate the gradient with respect to the standard de-<br />viation parameter ρ<br />∆ρ=∂f(w,θ)<br />∂w<br />?<br />1 + exp(−ρ)+∂f(w,θ)<br />∂ρ<br />.<br />(4)<br />7. Update the variational parameters:<br />µ ← µ − α∆µ<br />ρ ← ρ − α∆ρ.<br />(5)<br />(6)<br />Notethatthe∂f(w,θ)<br />standard deviation are shared and are exactly the gradients<br />found by the usual backpropagation algorithm on a neural<br />network. Thus, remarkably, to learn both the mean and the<br />standard deviation we must simply calculate the usual gra-<br />dients found by backpropagation, and then scale and shift<br />them as above.<br />∂w<br />termofthegradientsforthemeanand<br />3.3. Scale mixture prior<br />Having liberated our algorithm from the confines of Gaus-<br />sian priors and posteriors, we propose a simple scale mix-<br />ture prior combined with a diagonal Gaussian posterior.<br />The diagonal Gaussian posterior is largely free from nu-<br />merical issues, and two degrees of freedom per weight only<br />increases the number of parameters to optimise by a factor<br />of two, whilst giving each weight its own quantity of un-<br />certainty.<br />We pick a fixed-form prior and do not adjust its hyper-<br />parameters during training, instead picking the them by<br />cross-validation where possible. Empirically we found op-<br />timising the parameters of a prior P(w) (by taking deriva-<br />tives of (1)) to not be useful, and yield worse results.<br />Graves (2011) and Titsias and L´ azaro-Gredilla (2014) pro-<br />pose closed form updates of the prior hyperparameters.<br />Changing the prior based upon the data that it is meant to<br />regularise is known as empirical Bayes and there is much<br />debate as to its validity (Gelman, 2008). A reason why it<br />fails for Bayes by Backprop is as follows: it can be eas-<br />ier to change the prior parameters (of which there are few)<br />than it is to change the posterior parameters (of which there<br />are many) and so very quickly the prior parameters try to<br />capture the empirical distribution of the weights at the be-<br />ginning of learning. Thus the prior learns to fit poor initial<br />parameters quickly, and makes the cost in (1) less willing<br />to move away from poor initial parameters. This can yield<br />slow convergence, introduce strange local minima and re-<br />sult in poor performance.<br />We propose using a scale mixture of two Gaussian densi-<br />ties as the prior. Each density is zero mean, but differing<br />variances:<br />P(w) =<br />?<br />j<br />πN(wj|0,σ2<br />1) + (1 − π)N(wj|0,σ2<br />2), (7)<br />where wjis the jth weight of the network, N(x|µ,σ2) is<br />the Gaussian density evaluated at x with mean µ and vari-<br />ance σ2and σ2<br />components. The first mixture component of the prior is<br />given a larger variance than the second, σ1&gt; σ2, provid-<br />ing a heavier tail in the prior density than a plain Gaussian<br />prior. The second mixture component has a small variance<br />σ2? 1causingmanyoftheweightstoaprioritightlycon-<br />centrate around zero. Our prior resembles a spike-and-slab<br />prior (Mitchell and Beauchamp, 1988; George and McCul-<br />loch, 1993; Chipman, 1996), where instead all the prior pa-<br />rameters are shared among all the weights. This makes the<br />prior more amenable to use during optimisation by stochas-<br />tic gradient descent and avoids the need for prior parameter<br />optimisation based upon training data.<br />1and σ2<br />2are the variances of the mixture<br />3.4. Minibatches and KL re-weighting<br />As several authors have noted, the cost in (1) is amenable<br />tominibatchoptimisation, oftenusedwithneuralnetworks:<br />for each epoch of optimisation the training data D is ran-<br />domly split into a partition of M equally-sized subsets,<br />D1,D2,...,DM. Each gradient is averaged over all ele-<br />ments in one of these minibatches; a trade-off between a<br />fully batched gradient descent and a fully stochastic gradi-<br />ent descent. Graves (2011) proposes minimising the mini-</p>  <p>Page 5</p> <p>Weight Uncertainty in Neural Networks<br />batch cost for minibatch i = 1,2,...,M:<br />FEQ<br />i(Di,θ) =<br />1<br />MKL[q(w|θ) || P(w)]<br />− Eq(w|θ)[logP(Di|w)].<br />This is equivalent to the cost in (1) since?<br />cost relative to the likelihood cost on each minibatch. For<br />example, if minibatches are partitioned uniformly at ran-<br />dom, the KL cost can be distributed non-uniformly among<br />the minibatches at each epoch.<br />?M<br />Fπ<br />− Eq(w|θ)[logP(Di|w)]<br />Then EM[?M<br />In particular, we found the scheme πi =<br />well: the first few minibatches are heavily influenced by<br />the complexity cost, whilst the later minibatches are largely<br />influenced by the data. At the beginning of learning this is<br />particularly useful as for the first few minibatches changes<br />in the weights due to the data are slight and as more data<br />are seen, data become more influential and the prior less<br />influential.<br />(8)<br />iFEQ<br />i(Di,θ) =<br />F(D,θ). There are many ways to weight the complexity<br />Let π ∈ [0,1]Mand<br />i=1πi= 1, and define:<br />i(Di,θ) = πiKL[q(w|θ) || P(w)]<br />(9)<br />i=1Fπ<br />i(Di,θ)] = F(D,θ) where EMdenotes<br />anexpectationovertherandompartitioningofminibatches.<br />2M−i<br />2M−1to work<br />4. Contextual Bandits<br />Contextual bandits are simple reinforcement learning prob-<br />lems without persistent state (Li et al., 2010; Filippi et al.,<br />2010). At each step an agent is presented with a context<br />x and a choice of one of K possible actions a. Different<br />actions yield different unknown rewards r. The agent must<br />pick the action that yields the highest expected reward. The<br />context is assumed to be presented independent of any pre-<br />vious actions, rewards or contexts.<br />An agent builds a model of the distribution of the rewards<br />conditioned upon the action and the context: P(r|x,a,w).<br />It then uses this model to pick its action. Note, importantly,<br />that an agent does not know what reward it could have re-<br />ceived for an action that it did not pick, a difficulty often<br />known as “the absence of counterfactual”. As the agent’s<br />model P(r|x,a,w) is trained online, based upon the ac-<br />tionschosen, unlessexploratoryactionsaretaken, theagent<br />may perform suboptimally.<br />4.1. Thompson Sampling for Neural Networks<br />As in Section 2, P(r|x,a,w) can be modelled by a neural<br />network where w are the weights of the neural network.<br />However if this network is simply fit to observations and<br />the action with the highest expected reward taken at each<br />time, the agent can under-explore, as it may miss more re-<br />warding actions.1<br />Thompson sampling (Thompson, 1933) is a popular means<br />of picking an action that trades-off between exploitation<br />(picking the best known action) and exploration (picking<br />what might be a suboptimal arm to learn more). Thomp-<br />son sampling usually necessitates a Bayesian treatment of<br />the model parameters. At each step, Thompson sampling<br />draws a new set of parameters and then picks the action<br />relative to those parameters. This can be seen as a kind<br />of stochastic hypothesis testing: more probable parame-<br />ters are drawn more often and thus refuted or confirmed<br />the fastest. More concretely Thompson sampling proceeds<br />as follows:<br />1. Sample a new set of parameters for the model.<br />2. Pick the action with the highest expected reward ac-<br />cording to the sampled parameters.<br />3. Update the model. Go to 1.<br />Thereisanincreasingliteratureconcerningtheefficacyand<br />justification of this means of exploration (Chapelle and Li,<br />2011; May et al., 2012; Kaufmann et al., 2012; Agrawal<br />and Goyal, 2012; 2013). Thompson sampling is easily<br />adapted to neural networks using the variational posterior<br />found in Section 3:<br />1. Sample weights from the variational posterior: w ∼<br />q(w|θ).<br />2. Receive the context x.<br />3. Pick the action a that minimises EP(r|x,a,w)[r]<br />4. Receive reward r.<br />5. Update variational parameters θ according to Sec-<br />tion 3. Go to 1.<br />Note that it is possible, as mentioned in Section 3.1, to de-<br />crease the variance of the gradient estimates, trading off for<br />reduced exploration, by using more than one Monte Carlo<br />sample, using the corresponding networks as an ensemble<br />and picking the action by minimising the average of the<br />expectations.<br />Initially the variational posterior will be close to the prior,<br />and actions will be picked uniformly. As the agent takes ac-<br />tions, the variational posterior will begin to converge, and<br />uncertainty on many parameters can decrease, and so ac-<br />tion selection will become more deterministic, focusing on<br />the high expected reward actions discovered so far. It is<br />1Interestingly, depending upon how w are initialised and the<br />mean of prior used during MAP inference, it is sometimes pos-<br />sible to obtain another heuristic for the exploration-exploitation<br />trade-off: optimism-under-uncertainty. We leave this for future<br />investigation.</p>  <p>Page 6</p> <p>Weight Uncertainty in Neural Networks<br />Table 1. Classification Error Rates on MNIST. ? indicates result<br />used an ensemble of 5 networks.<br />Method<br />SGD, no regularisation (Simard et al., 2003)<br />SGD, dropout (Hinton et al., 2012)<br />SGD, dropconnect (Wan et al., 2013)<br />SGD<br /># Units/Layer<br /># Weights<br />Test<br />Error<br />1.6%<br />≈ 1.3%<br />1.2%?<br />1.83%<br />1.84%<br />1.88%<br />1.51%<br />1.33%<br />1.36%<br />1.82%<br />1.99%<br />2.04%<br />1.36%<br />1.34%<br />1.32%<br />800 1.3m<br />800<br />400<br />800<br />1200<br />400<br />800<br />1200<br />400<br />800<br />1200<br />400<br />800<br />1200<br />1.3m<br />500k<br />1.3m<br />2.4m<br />500k<br />1.3m<br />2.4m<br />500k<br />1.3m<br />2.4m<br />500k<br />1.3m<br />2.4m<br />SGD, dropout<br />Bayes by Backprop, Gaussian<br />Bayes by Backprop, Scale mixture<br />known that variational methods under-estimate uncertainty<br />(Minka, 2001; 2005; Bishop, 2006) which could lead to<br />under-exploration and premature convergence in practice,<br />but we did not find this in practice.<br />5. Experiments<br />We present some empirical evaluation of the methods pro-<br />posed above: on MNIST classification, on a non-linear re-<br />gression task, and on a contextual bandits task.<br />5.1. Classification on MNIST<br />We trained networks of various sizes on the MNIST dig-<br />its dataset (LeCun and Cortes, 1998), consisting of 60,000<br />training and 10,000 testing pixel images of size 28 by 28.<br />Each image is labelled with its corresponding number (be-<br />tween zero and nine, inclusive). We preprocessed the pix-<br />els by dividing values by 126. Many methods have been<br />proposed to improve results on MNIST: generative pre-<br />training, convolutions, distortions, etc. Here we shall focus<br />on improving the performance of an ordinary feedforward<br />neural network without using any of these methods. We<br />used a network of two hidden layers of rectified linear units<br />(Nair and Hinton, 2010; Glorot et al., 2011), and a softmax<br />output layer with 10 units, one for each possible label.<br />According to Hinton et al. (2012), the best published feed-<br />forward neural network classification result on MNIST (ex-<br />cluding those using data set augmentation, convolutions,<br />etc.) is 1.6% (Simard et al., 2003), whilst dropout with<br />an L2 regulariser attains errors around 1.3%. Results from<br />Bayes by Backprop are shown in Table 1, for various sized<br />0.8<br />1.2<br />1.6<br />2.0<br />0100200300 400500600<br />Epochs<br />Test error (%)<br />Algorithm<br />Bayes by Backprop<br />Dropout<br />Vanilla SGD<br />Figure 2. Test error on MNIST as training progresses.<br />0<br />5<br />10<br />15<br />−0.2−0.10.00.1 0.2<br />Weight<br />Density<br />Algorithm<br />Bayes by Backprop<br />Dropout<br />Vanilla SGD<br />Figure 3. Histogram of the trained weights of the neural network,<br />for Dropout, plain SGD, and samples from Bayes by Backprop.<br />networks, using either a Gaussian or Gaussian scale mix-<br />ture prior. Performance is comparable to that of dropout,<br />perhaps slightly better, as also see on Figure 2. Note that<br />we trained on 50,000 digits and used 10,000 digits as a val-<br />idation set, whilst Hinton et al. (2012) trained on 60,000<br />digits and did not use a validation set. We used the vali-<br />dation set to pick the best hyperparameters (learning rate,<br />number of gradients to average) and so we also repeated<br />thisprotocolfordropoutandSGD(StochasticGradientDe-<br />scent on the MLE objective in Section 2). We considered<br />learning rates of 10−3, 10−4and 10−5with minibatches<br />of size 128. For Bayes by Backprop, we averaged over ei-<br />ther 1, 2, 5, or 10 samples and considered π ∈ {1<br />−logσ1∈ {0,1,2} and −logσ2∈ {6,7,8}.<br />Figure 2 shows the learning curves on the test set for Bayes<br />by Backprop, dropout and SGD on a network with two lay-<br />ers of 1200 rectified linear units. As can be seen, SGD<br />converges the quickest, initially obtaining a low test er-<br />ror and then overfitting. Bayes by Backprop and dropout<br />converge at similar rates (although each iteration of Bayes<br />by Backprop is more expensive than dropout – around two<br />times slower). Eventually Bayes by Backprop converges<br />on a better test error than dropout after 600 epochs.<br />4,1<br />2,3<br />4},<br />Figure3showsdensityestimatesoftheweights. TheBayes<br />by Backprop weights are sampled from the variational pos-<br />terior, and the dropout weights are those used at test time.<br />Interestingly the regularised networks found by dropout</p>  <p>Page 7</p> <p>Weight Uncertainty in Neural Networks<br />andBayesbyBackprophaveagreaterrangeandwithfewer<br />centred at zero than those found by SGD. Bayes by Back-<br />prop uses the greatest range of weights.<br />0.0<br />0.2<br />0.4<br />0.6<br />0.8<br />−5.0−2.50.0<br />Signal−to−Noise Ratio (dB)<br />Density<br />0.00<br />0.25<br />0.50<br />0.75<br />1.00<br />−7.5 −5.0−2.50.0<br />Signal−to−Noise Ratio (dB)<br />CDF<br />Figure 4. Density and CDF of the Signal-to-Noise ratio over all<br />weights in the network. The red line denotes the 75% cut-off.<br />In Table 2, we examine the effect of replacing the vari-<br />ational posterior on some of the weights with a constant<br />zero, so as to determine the level of redundancy in the<br />network found by Bayes by Backprop. We took a Bayes<br />by Backprop trained network with two layers of 1200<br />units2and ordered the weights by their signal-to-noise ra-<br />tio (|µi|/σi). We removed the weights with the lowest sig-<br />nal to noise ratio. As can be seen in Table 2, even when<br />95% of the weights are removed the network still performs<br />well, with a significant drop in performance once 98% of<br />the weights have been removed.<br />In Figure 4 we examined the distribution of the signal-to-<br />noise relative to the cut-off in the network uses in Table 2.<br />The lower plot shows the cumulative distribution of signal-<br />to-noise ratio, whilst the top plot shows the density. From<br />the density plot we see there are two modalities of signal-<br />to-noise ratios, and from the CDF we see that the 75%<br />cut-off separates these two peaks. These two peaks coin-<br />cide with a drop in performance in Table 2 from 1.24%<br />to 1.29%, suggesting that the signal-to-noise heuristic is in<br />fact related to the test performance.<br />2We used a network from the end of training rather than pick-<br />ing a network with a low validation cost found during training,<br />hence the disparity with results in Table 1. The lowest test error<br />observed was 1.12%.<br />Table 2. Classification Errors after Weight pruning<br />Proportion removed<br />0%<br />50%<br />75%<br />95%<br />98%<br /># Weights<br />2.4m<br />1.2m<br />600k<br />120k<br />48k<br />Test Error<br />1.24%<br />1.24%<br />1.24%<br />1.29%<br />1.39%<br />It is interesting to contrast this weight removal approach<br />to obtaining a fast, smaller, sparse network for prediction<br />after training with the approach taken by distillation (Hin-<br />ton et al., 2014) which requires an extra stage of training<br />to obtain a compressed prediction model. As with distil-<br />lation, our method begins with an ensemble (one for each<br />possible assignment of the weights). However, unlike dis-<br />tillation, we can simply obtain a subset of this ensemble by<br />usingtheprobabilisticpropertiesoftheweightdistributions<br />learnt to gracefully prune the ensemble down into a smaller<br />network. Thus even though networks trained by Bayes by<br />Backprop may have twice as many weights, the number of<br />parameters that actually need to be stored at run time can be<br />far fewer. Graves (2011) also considered pruning weights<br />using the signal to noise ratio, but demonstrated results on<br />a network 20 times smaller and did not prune as high a<br />proportion of weights (at most 11%) whilst still maintain-<br />ing good test performance. The scale mixture prior used<br />by Bayes by Backprop encourages a broad spread of the<br />weights. Many of these weights can be successfully pruned<br />without impacting performance significantly.<br />5.2. Regression curves<br />We generated training data from the curve:<br />y = x + 0.3sin(2π(x + ?)) + 0.3sin(4π(x + ?)) + ?<br />where ? ∼ N(0,0.02). Figure 5 shows two examples of<br />fitting a neural network to these data, minimising a condi-<br />tional Gaussian loss. Note that in the regions of the input<br />space where there are no data, the ordinary neural network<br />reduces the variance to zero and chooses to fit a particu-<br />lar function, even though there are many possible extrap-<br />olations of the training data. On the left, Bayesian model<br />averaging affects predictions: where there are no data, the<br />confidence intervals diverge, reflecting there being many<br />possible extrapolations. In this case Bayes by Backprop<br />prefers to be uncertain where there are no nearby data, as<br />opposed to a standard neural network which can be overly<br />confident.<br />5.3. Bandits on Mushroom Task<br />We take the UCI Mushrooms data set (Bache and Lichman,<br />2013), and cast it as a bandit task, similar to Guez (2015,</p>  <p>Page 8</p> <p>Weight Uncertainty in Neural Networks<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />xxx<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />xx<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />xx<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />xx<br />x<br />xx<br />x<br />x<br />xx<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />xx<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />xx<br />x<br />x<br />x<br />x x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />xx<br />x<br />x<br />x<br />x<br />x<br />xx<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />xx<br />xx<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />xx<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />xxx<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />xx<br />x<br />x<br />x<br />xx<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />xx<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />xx<br />x<br />x<br />x<br />x x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />xx<br />x<br />xx<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />xx<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />xx<br />x<br />x<br />x<br />xx<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />xx<br />x<br />x<br />x<br />x<br />xxx<br />x<br />xx<br />x<br />x<br />x<br />−0.4<br />0.0<br />0.4<br />0.8<br />1.2<br />0.00.40.81.2<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />xxx<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />xx<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />xx<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />xx<br />x<br />xx<br />x<br />x<br />xx<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />xx<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />xx<br />x<br />x<br />x<br />x x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />xx<br />x<br />x<br />x<br />x<br />x<br />xx<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />xx<br />xx<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />xx<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />xxx<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />xx<br />x<br />x<br />x<br />xx<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />xx<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />xx<br />x<br />x<br />x<br />x x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />xx<br />x<br />xx<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />xx<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />xx<br />x<br />x<br />x<br />xx<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />x<br />xx<br />x<br />x<br />x<br />x<br />xxx<br />x<br />xx<br />x<br />x<br />x<br />−0.4<br />0.0<br />0.4<br />0.8<br />1.2<br />0.0 0.4 0.8 1.2<br />Figure 5. Regression of noisy data with interquatile ranges. Black<br />crosses are training samples. Red lines are median predictions.<br />Blue/purple region is interquartile range. Left: Bayes by Back-<br />prop neural network, Right: standard neural network.<br />1000<br />10000<br />01000020000300004000050000<br />Step<br />Cumulative Regret<br />5% Greedy<br />1% Greedy<br />Greedy<br />Bayes by Backprop<br />Figure 6. Comparison of cumulative regret of various agents on<br />the mushroom bandit task, averaged over five runs. Lower is bet-<br />ter.<br />Chapter 6). Each mushroom has a set of features, which we<br />treat as the context for the bandit, and is labelled as edible<br />or poisonous. An agent can either eat or not eat a mush-<br />room. If an agent eats an edible mushroom, then it receives<br />a reward of 5. If an agent eats a poisonous mushroom, then<br />with probability1<br />a reward of 5. If an agent elects not to eat a mushroom,<br />it receives a reward of 0. Thus an agent expects to receive<br />a reward of 5 for eating an edible reward, but an expected<br />reward of −15 for eating a poisonous mushroom.<br />Regret measures the difference between the reward achiev-<br />able by an oracle and the reward received by an agent. In<br />this case, an oracle will always receive a reward of 5 for an<br />edible mushroom, or 0 for a poisonous mushroom. We take<br />the cumulative sum of regret of several agents and show<br />them in Figure 6. Each agent uses a neural network with<br />two hidden layers of 100 rectified linear units. The input<br />to the network is a vector consisting of the mushroom fea-<br />tures (context) and a one of K encoding of the action. The<br />output of the network is a single scalar, representing the ex-<br />pected reward of the given action in the given context. For<br />Bayes by Backprop, we sampled the weights twice and av-<br />eraged two of these outputs to obtain the expected reward<br />2it receives a reward of −35, otherwise<br />for action selection. We kept the last 4096 reward, context<br />and action tuples in a buffer, and trained the networks us-<br />ing randomly drawn minibatches of size 64 for 64 training<br />steps (64×64 = 4096) per interaction with the Mushroom<br />bandit. A common heuristic for trading-off exploration vs.<br />exploitation is to follow an ε-greedy policy: with proba-<br />bility ε propose a uniformly random action, otherwise pick<br />the best action according to the neural network.<br />Figure 6 compares a Bayes by Backprop agent with three<br />ε-greedy agents, for values of ε of 0% (pure greedy), 1%,<br />and 5%. An ε of 5% appears to over-explore, whereas a<br />purely greedy agent does poorly at the beginning, greed-<br />ily electing to eat nothing, but then does much better once<br />it has seen enough data. It seems that non-local function<br />approximation updates allow the greedy agent to explore,<br />as for the first 1,000 steps, the agent eats nothing but after<br />approximately 1,000 the greedy agent suddenly decides to<br />eat mushrooms. The Bayes by Backprop agent explores<br />from the beginning, both eating and ignoring mushrooms<br />and quickly converges on eating and non-eating with an al-<br />most perfect rate (hence the almost flat regret).<br />6. Discussion<br />We introduced a new algorithm for learning neural net-<br />works with uncertainty on the weights called Bayes by<br />Backprop. It optimises a well-defined objective function<br />to learn a distribution on the weights of a neural network.<br />The algorithm achieves good results in several domains.<br />When classifying MNIST digits, performance from Bayes<br />by Backprop is comparable to that of dropout. We demon-<br />strated on a simple non-linear regression problem that the<br />uncertainty introduced allows the network to make more<br />reasonable predictions about unseen data. Finally, for con-<br />textual bandits, we showed how Bayes by Backprop can<br />automatically learn how to trade-off exploration and ex-<br />ploitation. Since Bayes by Backprop simply uses gradient<br />updates, it can readily be scaled using multi-machine opti-<br />misation schemes such as asynchronous SGD (Dean et al.,<br />2012). Furthermore, all of the operations used are readily<br />implemented on a GPU.<br />Acknowledgements<br />Danihelka, Danilo Rezende, Silvia Chiappa, Alex Graves,<br />Remi Munos, Ben Coppin, Liam Clancy, James Kirk-<br />patrick, Shakir Mohamed, David Pfau, and Theophane We-<br />ber for useful discussions and comments.<br />The authors would like to thank Ivo<br />References<br />Shipra Agrawal and Navin Goyal. Analysis of Thompson<br />sampling for the multi-armed bandit problem. In Pro-<br />ceedings of the 25th Annual Conference On Learning</p>  <p>Page 9</p> <p>Weight Uncertainty in Neural Networks<br />Theory (COLT), volume 23, pages 39.1–39.26, 2012.<br />Shipra Agrawal and Navin Goyal. Further optimal regret<br />bounds for Thompson sampling. In Proceedings of the<br />16th International Conference on Artificial Intelligence<br />and Statistics Learning (AISTATS), pages 99–107, 2013.<br />Kevin Bache and Moshe Lichman. UCI Machine Learning<br />Repository. University of California, Irvine, School of<br />Information and Computer Sciences, 2013. URL http:<br />//archive.ics.uci.edu/ml.<br />Christopher M Bishop. Section 10.1: variational inference.<br />In Pattern Recognition and Machine Learning. Springer,<br />2006. ISBN 9780387310732.<br />Wray L Buntine and Andreas S Weigend. Bayesian back-<br />propagation. Complex systems, 5(6):603–643, 1991.<br />Olivier Chapelle and Lihong Li. An empirical evaluation of<br />Thompson sampling. In Advances in Neural Information<br />Processing Systems (NIPS), pages 2249–2257, 2011.<br />Hugh Chipman. Bayesian variable selection with related<br />predictors. Canadian Journal of Statistics, 24(1):17–36,<br />1996.<br />Jeffrey Dean, Greg Corrado, Rajat Monga, Kai Chen,<br />Matthieu Devin, Mark Mao, Andrew Senior, Paul<br />Tucker, Ke Yang, Quoc V Le, et al. Large scale dis-<br />tributed deep networks. In Advances in Neural Infor-<br />mation Processing Systems (NIPS), pages 1223–1231,<br />2012.<br />Sarah Filippi, Olivier Cappe, Aurlien Garivier, and Csaba<br />Szepesvri. Parametric bandits: The generalized linear<br />case. In Advances in Neural Information Processing Sys-<br />tems, pages 586–594, 2010.<br />Karl Friston, J´ er´ emie Mattout, Nelson Trujillo-Barreto,<br />John Ashburner, and Will Penny. Variational free en-<br />ergy and the Laplace approximation. Neuroimage, 34<br />(1):220–234, 2007.<br />Andrew Gelman.<br />Bayesian Analysis, 3:445–450, 2008. ISSN 1931-6690.<br />doi: 11.1214/08-BA318.<br />Objections to Bayesian statistics.<br />Edward I George and Robert E McCulloch. Variable selec-<br />tion via gibbs sampling. Journal of the American Statis-<br />tical Association, 88(423):881–889, 1993.<br />Xavier Glorot, Antoine Bordes, and Yoshua Bengio. Deep<br />sparse rectifier networks. In Proceedings of the 14th<br />International Conference on Artificial Intelligence and<br />Statistics Learning (AISTATS), volume 15, pages 315–<br />323, 2011.<br />Alex Graves. Practical variational inference for neural net-<br />works. In Advances in Neural Information Processing<br />Systems (NIPS), pages 2348–2356, 2011.<br />Karol Gregor, Ivo Danihelka, Andriy Mnih, Charles Blun-<br />dell, and Daan Wierstra.<br />works. In Proceedings of the 31st International Confer-<br />ence on Machine Learning (ICML), pages 1242–1250,<br />2014.<br />Deep AutoRegressive net-<br />Arthur Guez. Sample-Based Search Methods For Bayes-<br />Adaptive Planning. PhD thesis, University College Lon-<br />don, 2015.<br />Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. Distilling<br />the knowledge in a neural network. In NIPS 2014 Deep<br />Learning and Representation Learning Workshop, 2014.<br />Geoffrey E Hinton and Drew Van Camp. Keeping the neu-<br />ralnetworkssimplebyminimizingthedescriptionlength<br />of the weights. In Proceedings of the 16th Annual Con-<br />ference On Learning Theory (COLT), pages 5–13. ACM,<br />1993.<br />Geoffrey E. Hinton, Nitish Srivastava, Alex Krizhevsky,<br />Ilya Sutskever, and Ruslan R. Salakhutdinov. Improving<br />neural networks by preventing co-adaptation of feature<br />detectors. arXiv:1207.0580, July 2012.<br />TommiS.JaakkolaandMichaelI.Jordan. Bayesianparam-<br />eter estimation via variational methods. Statistics and<br />Computing, 10(1):25–37, 2000.<br />Emilie Kaufmann, Nathaniel Korda, and R´ emi Munos.<br />Thompson sampling: An asymptotically optimal finite-<br />timeanalysis. InProceedingsofthe23rdAnnualConfer-<br />ence on Algorithmic Learning Theory (ALT), pages 199–<br />213. Springer, 2012.<br />Diederik P. Kingma and Max Welling. Auto-encoding vari-<br />ational Bayes. In Proceedings of the 2nd International<br />Conference on Learning Representations (ICLR), 2014.<br />arXiv: 1312.6114.<br />Yann LeCun. Une proc´ edure d’apprentissage pour r´ eseau<br />` a seuil asymmetrique (a learning scheme for asymmetric<br />threshold networks). In Proceedings of Cognitiva 85,<br />Paris, France, pages 599–604, 1985.<br />Yann LeCun and Corinna Cortes. The MNIST database<br />of handwritten digits. 1998. URL http://yann.<br />lecun.com/exdb/mnist/.<br />Lihong Li, Wei Chu, John Langford, and Robert E.<br />Schapire.A contextual-bandit approach to personal-<br />ized news article recommendation. In Proceedings of<br />the 19th International Conference on World Wide Web,<br />WWW ’10, pages 661–670, New York, NY, USA,</p>  <p>Page 10</p> <p>Weight Uncertainty in Neural Networks<br />2010. ACM. ISBN 978-1-60558-799-8. doi: 10.1145/<br />1772690.1772758.<br />David JC MacKay. A practical Bayesian framework for<br />backpropagation networks. Neural computation, 4(3):<br />448–472, 1992.<br />David JC MacKay.<br />predictions-a review of practical Bayesian methods for<br />supervised neural networks. Network: Computation in<br />Neural Systems, 6(3):469–505, 1995.<br />Probable networks and plausible<br />Benedict C May, Nathan Korda, Anthony Lee, and<br />David S. Leslie. Optimistic Bayesian sampling in<br />contextual-bandit problems.<br />Learning Research, 13(1):2069–2106, 2012.<br />The Journal of Machine<br />Thomas P Minka. A family of algorithms for approximate<br />Bayesian inference. PhD thesis, Massachusetts Institute<br />of Technology, 2001.<br />Thomas P Minka. Divergence measures and message pass-<br />ing. Technical report, Microsoft Research, 2005.<br />Toby J Mitchell and John J Beauchamp. Bayesian variable<br />selection in linear regression. Journal of the American<br />Statistical Association, 83(404):1023–1032, 1988.<br />Vinod Nair and Geoffrey E Hinton. Rectified linear units<br />improve restricted Boltzmann machines. In Proceedings<br />of the 27th International Conference on Machine Learn-<br />ing (ICML), pages 807–814, 2010.<br />Radford M Neal and Geoffrey E Hinton. A view of the EM<br />algorithm that justifies incremental, sparse, and other<br />variants. In Learning in graphical models, pages 355–<br />368. Springer, 1998.<br />Manfred Opper and C´ edric Archambeau. The variational<br />Gaussian approximation revisited. Neural computation,<br />21(3):786–792, 2009.<br />Art B. Owen. Monte Carlo theory, methods and examples.<br />2013.<br />Danilo Jimenez Rezende, Shakir Mohamed, and Daan<br />Wierstra. Stochastic backpropagation and approximate<br />inference in deep generative models. In Proceedings of<br />the 31st International Conference on Machine Learning<br />(ICML), pages 1278–1286, 2014.<br />David E Rumelhart, Geoffrey E Hinton, and Ronald J<br />Williams. Learning representations by back-propagating<br />errors. Cognitive modeling, 5, 1988.<br />Lawrence K Saul, Tommi Jaakkola, and Michael I Jordan.<br />Mean field theory for sigmoid belief networks. Journal<br />of artificial intelligence research, 4(1):61–76, 1996.<br />Patrice Y Simard, Dave Steinkraus, and John C Platt. Best<br />practicesforconvolutionalneuralnetworksappliedtovi-<br />sualdocumentanalysis. InProceedingsofthe12thInter-<br />national Conference on Document Analysis and Recog-<br />nition (ICDAR), volume 2, pages 958–958. IEEE Com-<br />puter Society, 2003.<br />William R Thompson. On the likelihood that one unknown<br />probability exceeds another in view of the evidence of<br />two samples. Biometrika, pages 285–294, 1933.<br />Michalis Titsias and Miguel L´ azaro-Gredilla.<br />stochastic variational bayes for non-conjugate inference.<br />In Proceedings of the 31st International Conference on<br />Machine Learning (ICML-14), pages 1971–1979, 2014.<br />Doubly<br />Li Wan, Matthew Zeiler, Sixin Zhang, Yann L Cun, and<br />Rob Fergus.Regularization of neural networks us-<br />ing dropconnect.In Proceedings of the 30th Inter-<br />national Conference on Machine Learning (ICML-13),<br />pages 1058–1066, 2013.<br />Jonathan S Yedidia, William T Freeman, and Yair Weiss.<br />Generalized belief propagation. In Advances in Neu-<br />ral Information Processing Systems (NIPS), volume 13,<br />pages 689–695, 2000.</p>  <a href="https://www.researchgate.net/profile/Julien_Cornebise/publication/277022910_Weight_Uncertainty_in_Neural_Networks/links/56ab3cb808aeadd1bdccd5b7.pdf">Download full-text</a> </div> <div id="rgw22_56aba0bb928c6" class="c-box pub-resource-container js-toggle" style=""> <h4 class="lf js-expand-list"><small><a href="javascript:" class="lf">View other sources <span class="ico-expand-list"></span></a></small></h4> <h4 class="lf js-collapse-list hidden"><small><a href="javascript:" class="lf">Hide other sources <span class="ico-collapse-list"></span></a></small></h4> <div class="clear"></div> <div class="scroll-wrapper hidden"> <ul class="files-list c-list" id="rgw23_56aba0bb928c6">  <li class="c-list-item pub-resource-item"  data-type="fulltext" id="rgw24_56aba0bb928c6"> <span class="ico-pub"></span> <div class="file-content"> <div class="download"> <a href="profile/Julien_Cornebise/publication/277022910_Weight_Uncertainty_in_Neural_Networks/links/56ab3cb808aeadd1bdccd5b7.pdf" class="publication-viewer" title="56ab3cb808aeadd1bdccd5b7.pdf">56ab3cb808aeadd1bdccd5b7.pdf</a> </div>  <div class="details">  <span> Available from <a href="profile/Julien_Cornebise">Julien Cornebise</a> &middot; Jan 29, 2016 </span>   </div>    </div> </li>  <li class="c-list-item pub-resource-item"  data-type="fulltext" id="rgw25_56aba0bb928c6"> <span class="ico-pub"></span> <div class="file-content"> <div class="download"> <a href="http://de.arxiv.org/pdf/1505.05424" target="_blank" rel="nofollow" class="publication-viewer" title="Weight Uncertainty in Neural Networks">Weight Uncertainty in Neural Networks</a> </div>  <div class="details">   Available from <a href="http://de.arxiv.org/pdf/1505.05424" target="_blank" rel="nofollow">de.arxiv.org</a>  </div>    </div> </li>  </ul> </div> </div> </noscript> <div class="clearfix"> <div class="action-container">  </div> <div class="pub-legal"> Data provided are for informational purposes only. Although carefully collected, accuracy cannot be guaranteed. The impact factor represents a rough estimation of the journal's impact factor and does not reflect the actual current impact factor. Publisher conditions are provided by RoMEO. Differing provisions from the publisher's actual policy or licence agreement may be applicable. </div>   </div> </div> <div class="clearfix">     <div id="rgw27_56aba0bb928c6" class="c-box pub-resource-container js-toggle" style="display: none;"> <h4 class="lf js-expand-list"><small><a href="javascript:" class="lf">View other sources <span class="ico-expand-list"></span></a></small></h4> <h4 class="lf js-collapse-list hidden"><small><a href="javascript:" class="lf">Hide other sources <span class="ico-collapse-list"></span></a></small></h4> <div class="clear"></div> <div class="scroll-wrapper hidden"> <ul class="files-list c-list" id="rgw28_56aba0bb928c6">  </ul> </div> </div>   <div id="rgw18_56aba0bb928c6" class="similar-publications"> <h2>Similar Publications</h2> <ul class="list-bordered">  <li class="c-list-item li-publication-teaser" id="rgw19_56aba0bb928c6"> <div> <h5> <a href="publication/290028587_Learning_to_Compose_Neural_Networks_for_Question_Answering" class="color-inherit ga-similar-publication-title"><span class="publication-title">Learning to Compose Neural Networks for Question Answering</span></a>  </h5>  <div class="authors"> <a href="researcher/2063279489_Jacob_Andreas" class="authors ga-similar-publication-author">Jacob Andreas</a>, <a href="researcher/74818195_Marcus_Rohrbach" class="authors ga-similar-publication-author">Marcus Rohrbach</a>, <a href="researcher/2093444675_Trevor_Darrell" class="authors ga-similar-publication-author">Trevor Darrell</a>, <a href="researcher/2078925806_Dan_Klein" class="authors ga-similar-publication-author">Dan Klein</a>  </div>  </div> <div class="clear"></div> </li>  <li class="c-list-item li-publication-teaser" id="rgw20_56aba0bb928c6"> <div> <h5> <a href="publication/290508979_Metacognition_and_the_next_generation_of_cognitive_radio_engines" class="color-inherit ga-similar-publication-title"><span class="publication-title">Metacognition and the next generation of cognitive radio engines</span></a>  </h5>  <div class="authors"> <a href="researcher/2068769015_Hamed_Asadi" class="authors ga-similar-publication-author">Hamed Asadi</a>, <a href="researcher/74631622_Haris_Volos" class="authors ga-similar-publication-author">Haris Volos</a>, <a href="researcher/2094170101_Michael_M_Marefat" class="authors ga-similar-publication-author">Michael M. Marefat</a>, <a href="researcher/74573556_Tamal_Bose" class="authors ga-similar-publication-author">Tamal Bose</a>  </div>  </div> <div class="clear"></div> </li>  <li class="c-list-item li-publication-teaser" id="rgw21_56aba0bb928c6"> <div> <h5> <a href="publication/287419646_Spiking_neural_network_model_of_reinforcement_learning_in_the_honeybee_implemented_on_the_GPU" class="color-inherit ga-similar-publication-title"><span class="publication-title">Spiking neural network model of reinforcement learning in the honeybee implemented on the GPU</span></a>  </h5>  <div class="authors"> <a href="researcher/2048034942_Esin_Yavuz" class="authors ga-similar-publication-author">Esin Yavuz</a>, <a href="researcher/2089610963_Pascale_Maul" class="authors ga-similar-publication-author">Pascale Maul</a>, <a href="researcher/38362455_Thomas_Nowotny" class="authors ga-similar-publication-author">Thomas Nowotny</a>  </div>  </div> <div class="clear"></div> </li>  </ul> </div> </div> </div> </div> </div></div></div>
<div class="clear"></div><div id="rgw41_56aba0bb928c6" class="default-footer"> <div id="footer" class="clearfix"> <span class="footer-left"> &copy; 2008&dash;2016 researchgate.net. All rights reserved. </span> <span class="footer-right"> <a href="https://www.researchgate.net/about">About us</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="https://www.researchgate.net/contact">Contact us</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="careers">Careers</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="developers">Developers</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="blog" target="_blank">News</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="application.PrivacyPolicy.html">Privacy</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="application.TermsAndConditions.html">Terms</a> <span class="footer-link-separator" style="padding: 0 5px;">&nbsp;|&nbsp;</span> <a href="advertising?_ref=ft">Advertising</a> <span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="recruiters?_ref=ft">Recruiting</a> </span> </div>  </div></div>
<div id="rgw42_56aba0bb928c6">  <div class="header-wrapper-logged-out"> <div id="header"> <div class="header-content"> <a href="" class="g-l-logo"> <svg width="149" height="19"> <image xlink:href="https://c5.rgstatic.net/m/235107188705592/images/template/brand-header-logo.svg" src="https://c5.rgstatic.net/m/238113351022438/images/template/brand-header-logo.png" width="149" height="19"/> </svg> </a> <a href="" class="g-l-logo-ico"> <svg width="127" height="17" viewbox="0 0 127 22"> <image xlink:href="https://c5.rgstatic.net/m/235107188705592/images/template/brand-header-logo.svg" src="https://c5.rgstatic.net/m/238113351022438/images/template/brand-header-logo.png" width="127" height="17"/> </svg> </a> <div id="rgw43_56aba0bb928c6" class="header-login-wrapper js-header-login"> <div class="dropdown-right-align"> <div class="login-signup-container lf"> <a href="https://www.researchgate.net/signup.SignUp.html?ev=su_chnl_index&amp;hdrsu=1&amp;_sg=9WxScfepB2FKQe2nYkQGkZqUTzB_dV8_eqdcYAfuh_DNSkVIML_K409sORvx84LM" class="dropdown-toggle lf">Join for free</a> </div> <div class="dropdown lf" style="height: 20px;"> <a href="https://www.researchgate.net/application.Login.html" class="js-login-url dropdown-toggle lf">Log in <span class="caret"></span></a> <div class="dropdown-menu"> <div class="header-login-form-wrapper"> <!--[if IE 6]><p class="box-warning" style="margin-bottom: 0;">Sorry, ResearchGate no longer supports the version of Internet Explorer you are using. <a href="http://whatbrowser.org/" rel="nofollow" target="_blank">Update your web browser</a> and then log in. </p><![endif]--> <form method="post" action="https://www.researchgate.net/application.Login.html" class="form-big header-login-form js-login-form" name="loginForm" id="headerLoginForm"> <input type="hidden" name="request_token" value="kSLeJzbi+8cnpp3gIwTWg3OnapVfxHOi3qmg0LLjsWmXq3yeYb//t74U3a2ce7GdG61KdzaHrife/NywKwKVIzrYobMdJYG0drshaPi3y/dUKw2629IyLu19jn+30WBm/+bQsDyuRwwObXSWMaqbxOS+5lW7stnDdnDx7N7T5WNb5ETOUDbQizekWStM3WgPE+jG24VmyqKlSAEaX4ts+HjX1oZqhzuZloaRqDbQd6Fte1WIphvFWHuN3IurX+xA/cRC8hru8ehFcfhMmOdXzmfzc30IagVsjJU059Q9K4g="/> <input type="hidden" name="urlAfterLogin" value="publication/277022910_Weight_Uncertainty_in_Neural_Networks"/> <input type="hidden" name="invalidPasswordCount" value="0"/> <input type="hidden" name="headerLogin" value="yes"/> <label for="input-header-login">Email</label> <div class="login-input"> <div class="info-tip-wrapper"> <span class="ico-info js-info"></span> </div> <input type="email" value="" name="login" class="login js-login-input text" id="input-header-login" tabindex="1"/> </div> <div class="clear"></div> <label class="lf" for="input-header-password"> Password </label> <a class="rf forgot-password js-forgot-password" href="application.LostPassword.html">Forgot password?</a> <div class="clear"></div> <input type="password" value="" name="password" class="password js-password-input text" id="input-header-password" tabindex="2"/> <div class="clear"></div> <label class="remember-me" for="headerLoginCookie"> <input type="checkbox" checked="checked" value="yes" name="setLoginCookie" class="lf checkbox" id="headerLoginCookie" tabindex="3"/> Keep me logged in </label> <div class="clear"></div> <input value="Log in" name="loginSubmit" class="btn btn-promote btn-fullwidth btn-large allow-leave js-submit-button" type="submit" tabindex="4"/> </form> <div class="connectors"> <div class="text">or log in with</div> <div class="connector-actions"> <a href="connector/linkedin/" class="li-connect js-li-connect" data-redirect-url="cHVibGljYXRpb24vMjc3MDIyOTEwX1dlaWdodF9VbmNlcnRhaW50eV9pbl9OZXVyYWxfTmV0d29ya3M%3D"> <span class="icon ico-linkedin-round-grey"></span> <span class="icon ico-linkedin-round"></span> </a> <a href="connector/facebook/" class="fb-connect middle js-fb-connect" data-redirect-url="cHVibGljYXRpb24vMjc3MDIyOTEwX1dlaWdodF9VbmNlcnRhaW50eV9pbl9OZXVyYWxfTmV0d29ya3M%3D"> <span class="icon ico-facebook-round-grey"></span> <span class="icon ico-facebook-round"></span> </a> <a href="connector/google/" class="g-connect js-g-connect" data-redirect-url="cHVibGljYXRpb24vMjc3MDIyOTEwX1dlaWdodF9VbmNlcnRhaW50eV9pbl9OZXVyYWxfTmV0d29ya3M%3D"> <span class="icon ico-google-round-grey"></span> <span class="icon ico-google-round"></span> </a> </div> </div> </div> </div> </div> </div> </div> </div> </div> <script type="application/ld+json">
{ "@context" : "http://schema.org",
  "@type" : "Organization",
  "name" : "ResearchGate",
  "url" : "http://www.researchgate.net",
  "logo" : "http://www.researchgate.net/images/template/rg_logo_square_brand.png",
  "sameAs" : [ "https://www.facebook.com/ResearchGate",
    "https://twitter.com/ResearchGate",
    "https://plus.google.com/+researchgate",
    "https://www.linkedin.com/company/researchgate"] 
}
</script> </div> </div><div class="c-signup-bar" id="rgw44_56aba0bb928c6"> <div class="banner-contents">   <span class="message">ResearchGate is the professional network for scientists and researchers.</span> <a href="signup.SignUp.html?ev=su_banner" class="btn btn-large btn-promote">Join for free</a>  </div> </div></div>
<script>
rgConfig.backendTime = 416;
</script>
<script src="//c5.rgstatic.net/m/2277196935388619/javascript/lib/yui3/yui/yui-min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/21832295316281274/javascript/yuiLoaderConfig-min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/23178613132105398/javascript/vendor/babel-core/browser-polyfill.min.js" type="text/javascript"></script>
<script>
(function (){
if (typeof YRG === "undefined") {
var xmlHttpRequest = new XMLHttpRequest();
xmlHttpRequest.open("post", "go.Error.html");
xmlHttpRequest.setRequestHeader("Content-Type", "application/json");
xmlHttpRequest.setRequestHeader("Accept", "application/json"); var loadedScripts = "";
if (window.performance && window.performance.getEntriesByType) {
    var result = [];
    var resources = performance.getEntriesByType("resource");
    for (var i in resources) {
        if (resources.hasOwnProperty(i)) {
            result.push({
                name: resources[i].name,
                duration: resources[i].duration
            });
        }
    }
    loadedScripts += "&loadedScripts=" + encodeURIComponent(JSON.stringify(result));
}
if (typeof YUI === "undefined") {
    loadedScripts += "&yuiLoaded=false";
} else {
    loadedScripts += "&yuiLoaded=true";
}
xmlHttpRequest.send("Type=InformationException&message=" + encodeURIComponent("Error loading YUI") + loadedScripts);
}
})();
</script>
<script>if (typeof YRG !== 'undefined') { YRG.use('rg-base',function(Y){Y.applyConfig({ignore: ["css-rg","css-rg2","css-ie","css-modules-publicprofile","css-pow-publicliterature-FollowPublicationPromo","css-pow-application-PdfJsReader","css-pow-publicliterature-PublicationInlineReader"]});Y.use(["rg.core.pagespeed.Monitoring"],function(Y){(function(){Y.rg.createInitialWidget({"data":{"content":{"data":{"profileSmallHeader":{"data":{"profileBadge":{"data":{"fullname":"Julien Cornebise","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2671872220764\/images\/template\/default\/profile\/profile_default_m.jpg","profileStats":[],"profileFollowButton":null,"profileReputationScoreNumber":null,"profileUrl":"profile\/Julien_Cornebise","institution":"Google Inc.","institutionUrl":false,"widgetId":"rgw4_56aba0bb928c6"},"id":"rgw4_56aba0bb928c6","partials":[],"templateName":"publicprofile\/stubs\/ProfileBadge.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicprofile.ProfileBadge.html?accountId=9944539","viewClass":null,"yuiModules":["css-modules-publicprofile"],"stylesheets":["modules\/publicprofile.css"],"_isYUI":true},"widgetId":"rgw3_56aba0bb928c6"},"id":"rgw3_56aba0bb928c6","partials":[],"templateName":"publicprofile\/stubs\/ProfileSmallHeader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicprofile.ProfileSmallHeader.html?publicationUid=277022910","viewClass":null,"yuiModules":["css-modules-publicprofile"],"stylesheets":["modules\/publicprofile.css"],"_isYUI":true},"publication":{"data":{"publicationUid":277022910,"title":"Weight Uncertainty in Neural Networks","journalTitle":false,"journalDetailsTooltip":false,"affiliation":false,"type":"Article","details":{"journalInfos":{"journal":"","publicationDate":"05\/2015;","publicationDateRobot":"2015-05","article":""}},"source":{"sourceUrl":"http:\/\/arxiv.org\/abs\/1505.05424","sourceName":"arXiv"},"publicationActions":null,"publicationCoins":{"data":{"tags":[{"key":"ctx_ver","value":"Z39.88-2004"},{"key":"rft_val_fmt","value":"info:ofi\/fmt:kev:mtx:journal"},{"key":"rfr_id","value":"info:sid\/researchgate.net:researchgate"},{"key":"rft.atitle","value":"Weight Uncertainty in Neural Networks"},{"key":"rft.date","value":"2015"},{"key":"rft.au","value":"Charles Blundell,Julien Cornebise,Koray Kavukcuoglu,Daan Wierstra"},{"key":"rft.genre","value":"article"}],"widgetId":"rgw6_56aba0bb928c6"},"id":"rgw6_56aba0bb928c6","partials":[],"templateName":"publicliterature\/stubs\/PublicationCoins.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationCoins.html?publicationUid=277022910","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationAuthors":{"data":{"publicationUid":277022910,"peopleItems":[{"data":{"authorUrl":"researcher\/2074234412_Charles_Blundell","authorNameOnPublication":"Charles Blundell","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg","imageSize":"s","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Charles Blundell","profile":{"professionalInstitution":{"professionalInstitutionName":false,"professionalInstitutionUrl":null}},"professionalInstitutionName":false,"professionalInstitutionUrl":null,"url":"researcher\/2074234412_Charles_Blundell","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":true,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":false,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"widgetId":"rgw9_56aba0bb928c6"},"id":"rgw9_56aba0bb928c6","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAuthorItem.html?entityId=2074234412&imageSize=l&enableAuthorInviteButton=0","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"largeTooltip":false,"useRebrandedImageStyle":null,"widgetId":"rgw8_56aba0bb928c6"},"id":"rgw8_56aba0bb928c6","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorItem.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorItem.html?authorUid=2074234412&authorNameOnPublication=Charles%20Blundell","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true},{"data":{"authorNameOnPublication":"Julien Cornebise","accountUrl":"profile\/Julien_Cornebise","accountKey":"Julien_Cornebise","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2671872220764\/images\/template\/default\/profile\/profile_default_m.jpg","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Julien Cornebise","profile":{"professionalInstitution":{"professionalInstitutionName":"Google Inc.","professionalInstitutionUrl":"institution\/Google_Inc"}},"professionalInstitutionName":"Google Inc.","professionalInstitutionUrl":"institution\/Google_Inc","url":"profile\/Julien_Cornebise","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":false,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":true,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"accountKey":"Julien_Cornebise","hasInfoPopup":false,"hasTeaserPopup":true,"showContactAuthorButton":true,"widgetId":"rgw11_56aba0bb928c6"},"id":"rgw11_56aba0bb928c6","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAccountItem.html?entityId=9944539&enableUnfollow=0&imageSize=l&enableFollowButton=0&showContactAuthorButton=1","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"accountInstitution":"Google Inc.","score":null,"largeTooltip":false,"useRebrandedImageStyle":null,"authorCount":4,"accountCount":1,"publicationUid":277022910,"widgetId":"rgw10_56aba0bb928c6"},"id":"rgw10_56aba0bb928c6","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAccountItem.html","templateExtensions":[],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAccountItem.html?accountId=9944539&context=pubdetail_authors_xflw&showContactAuthorButton=1&authorCount=4&accountCount=1&publicationUid=277022910","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true},{"data":{"authorUrl":"researcher\/2040167286_Koray_Kavukcuoglu","authorNameOnPublication":"Koray Kavukcuoglu","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg","imageSize":"s","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Koray Kavukcuoglu","profile":{"professionalInstitution":{"professionalInstitutionName":false,"professionalInstitutionUrl":null}},"professionalInstitutionName":false,"professionalInstitutionUrl":null,"url":"researcher\/2040167286_Koray_Kavukcuoglu","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":true,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":false,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"widgetId":"rgw13_56aba0bb928c6"},"id":"rgw13_56aba0bb928c6","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAuthorItem.html?entityId=2040167286&imageSize=l&enableAuthorInviteButton=0","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"largeTooltip":false,"useRebrandedImageStyle":null,"widgetId":"rgw12_56aba0bb928c6"},"id":"rgw12_56aba0bb928c6","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorItem.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorItem.html?authorUid=2040167286&authorNameOnPublication=Koray%20Kavukcuoglu","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true},{"data":{"authorUrl":"researcher\/12447169_Daan_Wierstra","authorNameOnPublication":"Daan Wierstra","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg","imageSize":"s","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Daan Wierstra","profile":{"professionalInstitution":{"professionalInstitutionName":false,"professionalInstitutionUrl":null}},"professionalInstitutionName":false,"professionalInstitutionUrl":null,"url":"researcher\/12447169_Daan_Wierstra","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":true,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":false,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"widgetId":"rgw15_56aba0bb928c6"},"id":"rgw15_56aba0bb928c6","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAuthorItem.html?entityId=12447169&imageSize=l&enableAuthorInviteButton=0","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"largeTooltip":false,"useRebrandedImageStyle":null,"widgetId":"rgw14_56aba0bb928c6"},"id":"rgw14_56aba0bb928c6","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorItem.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorItem.html?authorUid=12447169&authorNameOnPublication=Daan%20Wierstra","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true}],"hasMore":false,"nextOffset":6,"useRebrandedImageStyle":null,"widgetId":"rgw7_56aba0bb928c6"},"id":"rgw7_56aba0bb928c6","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorList.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorList.html?publicationUid=277022910&context=pubdetail_authors_xflw&showContactAuthorButton=1","viewClass":"views.publicliterature.PublicationDetailAuthorListView","yuiModules":["rg.views.publicliterature.PublicationDetailAuthorListView"],"stylesheets":[],"_isYUI":true},"publicationAbstract":{"data":{"publicationUid":277022910,"abstract":"<noscript><\/noscript><div>We introduce a new, efficient, principled and backpropagation-compatible<br \/>\nalgorithm for learning a probability distribution on the weights of a neural<br \/>\nnetwork, called Bayes by Backprop. It regularises the weights by minimising a<br \/>\ncompression cost, known as the variational free energy or the expected lower<br \/>\nbound on the marginal likelihood. We show that this principled kind of<br \/>\nregularisation yields comparable performance to dropout on MNIST<br \/>\nclassification. We then demonstrate how the learnt uncertainty in the weights<br \/>\ncan be used to improve generalisation in non-linear regression problems, and<br \/>\nhow this weight uncertainty can be used to drive the exploration-exploitation<br \/>\ntrade-off in reinforcement learning.<\/div>","canEdit":false,"isAdmin":false,"isArtifact":false,"showFullAbstract":false,"widgetId":"rgw16_56aba0bb928c6"},"id":"rgw16_56aba0bb928c6","partials":[],"templateName":"publicliterature\/stubs\/PublicationAbstract.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationAbstract.html?publicationUid=277022910","viewClass":"views.publicliterature.PublicationAbstractView","yuiModules":["rg.views.publicliterature.PublicationAbstractView"],"stylesheets":[],"_isYUI":true},"publicationKeywords":null,"publicationState":null,"isGuest":true,"isAdminEditingAllowed":false,"isArtifact":false,"figureListWidget":null,"previewImage":"https:\/\/i1.rgstatic.net\/publication\/277022910_Weight_Uncertainty_in_Neural_Networks\/links\/56ab3cb808aeadd1bdccd5b7\/smallpreview.png","nativeAdDisclosure":null,"showFollowPublicationButton":false,"followPublicationPromo":{"data":{"widgetId":"rgw17_56aba0bb928c6"},"id":"rgw17_56aba0bb928c6","partials":[],"templateName":"publicliterature\/stubs\/FollowPublicationPromo.html","templateExtensions":[],"attrs":{"context":null,"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.FollowPublicationPromo.html","viewClass":null,"yuiModules":["css-pow-publicliterature-FollowPublicationPromo"],"stylesheets":["pow\/publicliterature\/FollowPublicationPromo.css"],"_isYUI":true},"widgetId":"rgw5_56aba0bb928c6"},"id":"rgw5_56aba0bb928c6","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailItem.html","templateExtensions":["generalHelpers"],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailItem.html?publicationUid=277022910&showActionBar=0&showContactAuthorButton=1&showRequestFulltextExperience=0&showNoRgAuthorsRequestFulltextExperience=0&showFollowPublicationPromo=1","viewClass":"views.publicliterature.PublicationDetailItemView","yuiModules":["rg.views.publicliterature.PublicationDetailItemView"],"stylesheets":[],"_isYUI":true},"similarPublications":{"data":{"publicationListItems":[{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":2063279489,"url":"researcher\/2063279489_Jacob_Andreas","fullname":"Jacob Andreas","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":74818195,"url":"researcher\/74818195_Marcus_Rohrbach","fullname":"Marcus Rohrbach","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2093444675,"url":"researcher\/2093444675_Trevor_Darrell","fullname":"Trevor Darrell","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2078925806,"url":"researcher\/2078925806_Dan_Klein","fullname":"Dan Klein","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Jan 2016","journal":null,"showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/290028587_Learning_to_Compose_Neural_Networks_for_Question_Answering","usePlainButton":true,"publicationUid":290028587,"feedStubs":null,"hasFeedStubs":false,"impactPoints":false,"url":"publication\/290028587_Learning_to_Compose_Neural_Networks_for_Question_Answering","title":"Learning to Compose Neural Networks for Question Answering","displayTitleAsLink":true,"authors":[{"id":2063279489,"url":"researcher\/2063279489_Jacob_Andreas","fullname":"Jacob Andreas","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":74818195,"url":"researcher\/74818195_Marcus_Rohrbach","fullname":"Marcus Rohrbach","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2093444675,"url":"researcher\/2093444675_Trevor_Darrell","fullname":"Trevor Darrell","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2078925806,"url":"researcher\/2078925806_Dan_Klein","fullname":"Dan Klein","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":[],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/290028587_Learning_to_Compose_Neural_Networks_for_Question_Answering","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/290028587_Learning_to_Compose_Neural_Networks_for_Question_Answering\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw19_56aba0bb928c6"},"id":"rgw19_56aba0bb928c6","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=290028587","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":2068769015,"url":"researcher\/2068769015_Hamed_Asadi","fullname":"Hamed Asadi","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":74631622,"url":"researcher\/74631622_Haris_Volos","fullname":"Haris Volos","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2094170101,"url":"researcher\/2094170101_Michael_M_Marefat","fullname":"Michael M. Marefat","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":74573556,"url":"researcher\/74573556_Tamal_Bose","fullname":"Tamal Bose","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Jan 2016","journal":"IEEE Communications Magazine","showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/290508979_Metacognition_and_the_next_generation_of_cognitive_radio_engines","usePlainButton":true,"publicationUid":290508979,"feedStubs":null,"hasFeedStubs":false,"impactPoints":"4.01","url":"publication\/290508979_Metacognition_and_the_next_generation_of_cognitive_radio_engines","title":"Metacognition and the next generation of cognitive radio engines","displayTitleAsLink":true,"authors":[{"id":2068769015,"url":"researcher\/2068769015_Hamed_Asadi","fullname":"Hamed Asadi","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":74631622,"url":"researcher\/74631622_Haris_Volos","fullname":"Haris Volos","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2094170101,"url":"researcher\/2094170101_Michael_M_Marefat","fullname":"Michael M. Marefat","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":74573556,"url":"researcher\/74573556_Tamal_Bose","fullname":"Tamal Bose","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["IEEE Communications Magazine 01\/2016; 54(1):76-82. DOI:10.1109\/MCOM.2016.7378429"],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/290508979_Metacognition_and_the_next_generation_of_cognitive_radio_engines","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/290508979_Metacognition_and_the_next_generation_of_cognitive_radio_engines\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw20_56aba0bb928c6"},"id":"rgw20_56aba0bb928c6","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=290508979","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":2048034942,"url":"researcher\/2048034942_Esin_Yavuz","fullname":"Esin Yavuz","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2089610963,"url":"researcher\/2089610963_Pascale_Maul","fullname":"Pascale Maul","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":38362455,"url":"researcher\/38362455_Thomas_Nowotny","fullname":"Thomas Nowotny","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Dec 2015","journal":"BMC Neuroscience","showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/287419646_Spiking_neural_network_model_of_reinforcement_learning_in_the_honeybee_implemented_on_the_GPU","usePlainButton":true,"publicationUid":287419646,"feedStubs":null,"hasFeedStubs":false,"impactPoints":"2.67","url":"publication\/287419646_Spiking_neural_network_model_of_reinforcement_learning_in_the_honeybee_implemented_on_the_GPU","title":"Spiking neural network model of reinforcement learning in the honeybee implemented on the GPU","displayTitleAsLink":true,"authors":[{"id":2048034942,"url":"researcher\/2048034942_Esin_Yavuz","fullname":"Esin Yavuz","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2089610963,"url":"researcher\/2089610963_Pascale_Maul","fullname":"Pascale Maul","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":38362455,"url":"researcher\/38362455_Thomas_Nowotny","fullname":"Thomas Nowotny","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["BMC Neuroscience 12\/2015; 16(Suppl 1):P181. DOI:10.1186\/1471-2202-16-S1-P181"],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/287419646_Spiking_neural_network_model_of_reinforcement_learning_in_the_honeybee_implemented_on_the_GPU","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/287419646_Spiking_neural_network_model_of_reinforcement_learning_in_the_honeybee_implemented_on_the_GPU\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw21_56aba0bb928c6"},"id":"rgw21_56aba0bb928c6","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=287419646","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"viewClass":"sidebar","widgetId":"rgw18_56aba0bb928c6"},"id":"rgw18_56aba0bb928c6","partials":[],"templateName":"publicliterature\/stubs\/SimilarPublications.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.SimilarPublications.html?referencePublicationId=277022910&view=sidebar","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationFulltextPreview":null,"publicationResourcesFulltext":{"data":{"publicationUid":277022910,"publicationResourceList":{"data":{"publicationResourceItems":[{"data":{"publicationUid":277022910,"publicationType":"article","linkId":"56ab3cb808aeadd1bdccd5b7","fileName":"56ab3cb808aeadd1bdccd5b7.pdf","fileUrl":"profile\/Julien_Cornebise\/publication\/277022910_Weight_Uncertainty_in_Neural_Networks\/links\/56ab3cb808aeadd1bdccd5b7.pdf","name":"Julien Cornebise","nameUrl":"profile\/Julien_Cornebise","canRemove":false,"fileIcon":"ico-pub","canPreview":true,"hasPublisherLink":null,"hasMetaData":true,"hide":false,"fulltext":"ico-pub","origin":"publication_list","isLastLink":false,"isUserLink":true,"uploadDate":"Jan 29, 2016","fileSize":"614.04 KB","widgetId":"rgw24_56aba0bb928c6"},"id":"rgw24_56aba0bb928c6","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceItem.html","templateExtensions":["generalHelpers"],"attrs":{"fileRequiredPublicationTypes":["code","coverPage","experimentFindings","method","negativeResults","presentation","rawData","researchProposal","workingPaper","artifact","dataset"]},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceItem.html?publicationUid=277022910&linkId=56ab3cb808aeadd1bdccd5b7&hide=0&disableJavascript=disableJavascript&useAlternativeTemplate=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"publicationUid":277022910,"publicationType":"article","linkId":"556fc35b08aeccd777416cec","fileName":"Weight Uncertainty in Neural Networks","fileUrl":"http:\/\/de.arxiv.org\/pdf\/1505.05424","name":"de.arxiv.org","nameUrl":"http:\/\/de.arxiv.org\/pdf\/1505.05424","canRemove":false,"fileIcon":"ico-pub","canPreview":true,"hasPublisherLink":null,"hasMetaData":true,"hide":false,"fulltext":"ico-pub","origin":"publication_list","isLastLink":false,"isUserLink":false,"widgetId":"rgw25_56aba0bb928c6"},"id":"rgw25_56aba0bb928c6","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceItem.html","templateExtensions":["generalHelpers"],"attrs":{"fileRequiredPublicationTypes":["code","coverPage","experimentFindings","method","negativeResults","presentation","rawData","researchProposal","workingPaper","artifact","dataset"]},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceItem.html?publicationUid=277022910&linkId=556fc35b08aeccd777416cec&hide=0&disableJavascript=disableJavascript&useAlternativeTemplate=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"widgetId":"rgw23_56aba0bb928c6"},"id":"rgw23_56aba0bb928c6","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceList.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceList.html?publicationUid=277022910&limit=3&disableJavascript=disableJavascript&type=fulltextFile","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"resourceCount":2,"hidden":false,"showMore":false,"fulltext":true,"publicationDownloadCount":{"data":{"value":1,"valueFormatted":"1","widgetId":"rgw26_56aba0bb928c6"},"id":"rgw26_56aba0bb928c6","partials":[],"templateName":"publicliterature\/stubs\/PublicationDownloadCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDownloadCount.html?publicationUid=277022910","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw22_56aba0bb928c6"},"id":"rgw22_56aba0bb928c6","partials":[],"templateName":"publicliterature\/stubs\/PublicationResources.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResources.html?publicationUid=277022910&type=fulltextFile&disableJavascript=1","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationResourcesAttachments":{"data":{"publicationUid":277022910,"publicationResourceList":{"data":{"publicationResourceItems":[],"widgetId":"rgw28_56aba0bb928c6"},"id":"rgw28_56aba0bb928c6","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceList.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceList.html?publicationUid=277022910&limit=3&disableJavascript=disableJavascript&type=attachmentFile","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"resourceCount":0,"hidden":true,"showMore":false,"fulltext":false,"publicationDownloadCount":{"data":{"value":1,"valueFormatted":"1","widgetId":"rgw29_56aba0bb928c6"},"id":"rgw29_56aba0bb928c6","partials":[],"templateName":"publicliterature\/stubs\/PublicationDownloadCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDownloadCount.html?publicationUid=277022910","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw27_56aba0bb928c6"},"id":"rgw27_56aba0bb928c6","partials":[],"templateName":"publicliterature\/stubs\/PublicationResources.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResources.html?publicationUid=277022910&type=attachmentFile","viewClass":"views.publicliterature.PublicationResourcesView","yuiModules":["rg.views.publicliterature.PublicationResourcesView"],"stylesheets":[],"_isYUI":true},"publicationText":{"data":{"hide":false,"pages":[{"page":1,"text":"Weight Uncertainty in Neural Networks\nCharles Blundell\nJulien Cornebise\nKoray Kavukcuoglu\nDaan Wierstra\nGoogle DeepMind\nCBLUNDELL@GOOGLE.COM\nJUCOR@GOOGLE.COM\nKORAYK@GOOGLE.COM\nWIERSTRA@GOOGLE.COM\nAbstract\nWe introduce a new, efficient, principled and\nbackpropagation-compatible algorithm for learn-\ning a probability distribution on the weights of\na neural network, called Bayes by Backprop. It\nregularises the weights by minimising a com-\npression cost, known as the variational free en-\nergy or the expected lower bound on the marginal\nlikelihood. We show that this principled kind\nof regularisation yields comparable performance\nto dropout on MNIST classification. We then\ndemonstrate how the learnt uncertainty in the\nweights can be used to improve generalisation\nin non-linear regression problems, and how this\nweight uncertainty can be used to drive the\nexploration-exploitation trade-off in reinforce-\nment learning.\n1. Introduction\nPlain feedforward neural networks are prone to overfit-\nting. When applied to supervised or reinforcement learn-\ning problems these networks are also often incapable of\ncorrectly assessing the uncertainty in the training data and\nso make overly confident decisions about the correct class,\nprediction or action. We shall address both of these con-\ncerns by using variational Bayesian learning to introduce\nuncertainty in the weights of the network. We call our al-\ngorithm Bayes by Backprop. We suggest at least three mo-\ntivations for introducing uncertainty on the weights: 1) reg-\nularisation via a compression cost on the weights, 2) richer\nrepresentations and predictions from cheap model averag-\ning, and 3) exploration in simple reinforcement learning\nproblems such as contextual bandits.\nVariousregularisationschemeshavebeendevelopedtopre-\nProceedings of the 32ndInternational Conference on Machine\nLearning, Lille, France, 2015. JMLR: W&CP volume 37. Copy-\nright 2015 by the author(s).\nvent overfitting in neural networks such as early stopping,\nweight decay, and dropout (Hinton et al., 2012). In this\nwork, we introduce an efficient, principled algorithm for\nregularisation built upon Bayesian inference on the weights\nof the network (MacKay, 1992; Buntine and Weigend,\n1991; MacKay, 1995). This leads to a simple approxi-\nmate learning algorithm similar to backpropagation (Le-\nCun, 1985; Rumelhart et al., 1988). We shall demonstrate\nhow this uncertainty can improve predictive performance\nin regression problems by expressing uncertainty in regions\nwith little or no data, how this uncertainty can lead to more\nsystematic exploration than ?-greedy in contextual bandit\ntasks.\nAll weights in our neural networks are represented by prob-\nabilitydistributionsoverpossiblevalues, ratherthanhaving\na single fixed value as is the norm (see Figure 1). Learnt\nrepresentations and computations must therefore be robust\nunder perturbation of the weights, but the amount of per-\nturbation each weight exhibits is also learnt in a way that\ncoherently explains variability in the training data. Thus\ninstead of training a single network, the proposed method\ntrains an ensemble of networks, where each network has its\nweights drawn from a shared, learnt probability distribu-\ntion. Unlike other ensemble methods, our method typically\nonly doubles the number of parameters yet trains an infi-\nnite ensemble using unbiased Monte Carlo estimates of the\ngradients.\nIn general, exact Bayesian inference on the weights of a\nneural network is intractable as the number of parameters\nis very large and the functional form of a neural network\ndoes not lend itself to exact integration. Instead we take a\nvariational approximation to exact Bayesian updates. We\nbuild upon the work of Graves (2011), who in turn built\nupon the work of Hinton and Van Camp (1993). In con-\ntrast to this previous work, we show how the gradients\nof Graves (2011) can be made unbiased and further how\nthis method can be used with non-Gaussian priors. Con-\nsequently, Bayes by Backprop attains performance compa-\nrable to that of dropout (Hinton et al., 2012). Our method\narXiv:1505.05424v2  [stat.ML]  21 May 2015"},{"page":2,"text":"Weight Uncertainty in Neural Networks\nH1H2H3\n1\nX1\nY\n0.5\n0.1\n0.7\n1.3\n1.4\n0.3\n1.2\n0.10.1\n0.2\nH1H2H3\n1\nX1\nY\nFigure 1. Left: each weight has a fixed value, as provided by clas-\nsical backpropagation. Right: each weight is assigned a distribu-\ntion, as provided by Bayes by Backprop.\nis related to recent methods in deep, generative modelling\n(Kingma and Welling, 2014; Rezende et al., 2014; Gregor\net al., 2014), where variational inference has been applied\nto stochastic hidden units of an autoencoder. Whilst the\nnumber of stochastic hidden units might be in the order of\nthousands, the number of weights in a neural network is\neasilytwoordersofmagnitudelarger, makingtheoptimisa-\ntion problem much larger scale. Uncertainty in the hidden\nunits allows the expression of uncertainty about a particular\nobservation, uncertainty in the weights is complementary\nin that it captures uncertainty about which neural network\nis appropriate, leading to regularisation of the weights and\nmodel averaging.\nThis uncertainty can be used to drive exploration in contex-\ntual bandit problems using Thompson sampling (Thomp-\nson, 1933; Chapelle and Li, 2011; Agrawal and Goyal,\n2012; May et al., 2012). Weights with greater uncertainty\nintroduce more variability into the decisions made by the\nnetwork, leading naturally to exploration. As more data are\nobserved, the uncertainty can decrease, allowing the deci-\nsions made by the network to become more deterministic\nas the environment is better understood.\nThe remainder of the paper is organised as follows: Sec-\ntion 2 introduces notation and standard learning in neural\nnetworks, Section 3 describes variational Bayesian learn-\ning for neural networks and our contributions, Section 4\ndescribes the application to contextual bandit problems,\nwhilst Section 5 contains empirical results on a classifica-\ntion, a regression and a bandit problem. We conclude with\na brief discussion in Section 6.\n2. Point Estimates of Neural Networks\nWe view a neural network as a probabilistic model\nP(y|x,w): given an input x \u2208 Rpa neural network as-\nsigns a probability to each possible output y \u2208 Y, using\nthe set of parameters or weights w. For classification, Y is\nasetofclassesandP(y|x,w)isacategoricaldistribution\u2013\nthis corresponds to the cross-entropy or softmax loss, when\nthe parameters of the categorical distribution are passed\nthrough the exponential function then re-normalised. For\nregression Y is R and P(y|x,w) is a Gaussian distribution\n\u2013 this corresponds to a squared loss.\nInputs x are mapped onto the parameters of a distribu-\ntion on Y by several successive layers of linear transforma-\ntion (given by w) interleaved with element-wise non-linear\ntransforms.\nThe weights can be learnt by maximum likelihood estima-\ntion (MLE): given a set of training examples D = (xi,yi)i,\nthe MLE weights wMLEare given by:\nwMLE= argmax\nw\nlogP(D|w)\n?\n= argmax\nw\ni\nlogP(yi|xi,w).\nThis is typically achieved by gradient descent (e.g., back-\npropagation), where we assume that logP(D|w) is differ-\nentiable in w.\nRegularisation can be introduced by placing a prior upon\nthe weights w and finding the maximum a posteriori\n(MAP) weights wMAP:\nwMAP= argmax\nw\nlogP(w|D)\nlogP(D|w) + logP(w).= argmax\nw\nIf w are given a Gaussian prior, this yields L2 regularisa-\ntion (or weight decay). If w are given a Laplace prior, then\nL1 regularisation is recovered.\n3. Being Bayesian by Backpropagation\nBayesian inference for neural networks calculates the pos-\nterior distribution of the weights given the training data,\nP(w|D).\nabout unseen data by taking expectations: the predictive\ndistribution of an unknown label \u02c6 y of a test data item \u02c6 x,\nis given by P(\u02c6 y|\u02c6 x) = EP(w|D)[P(\u02c6 y|\u02c6 x,w)]. Each pos-\nsible configuration of the weights, weighted according to\nthe posterior distribution, makes a prediction about the un-\nknown label given the test data item \u02c6 x. Thus taking an\nexpectation under the posterior distribution on weights is\nequivalent to using an ensemble of an uncountably infi-\nnite number of neural networks. Unfortunately, this is in-\ntractable for neural networks of any practical size.\nThis distribution answers predictive queries\nPreviously Hinton and Van Camp (1993) and Graves\n(2011) suggested finding a variational approximation to the\nBayesian posterior distribution on the weights. Variational\nlearning finds the parameters \u03b8 of a distribution on the\nweights q(w|\u03b8) that minimises the Kullback-Leibler (KL)"},{"page":3,"text":"Weight Uncertainty in Neural Networks\ndivergence with the true Bayesian posterior on the weights:\n\u03b8?= argmin\n\u03b8\nKL[q(w|\u03b8)||P(w|D)]\n?\nKL[q(w|\u03b8) || P(w)] \u2212 Eq(w|\u03b8)[logP(D|w)].\n= argmin\n\u03b8\nq(w|\u03b8)log\nq(w|\u03b8)\nP(w)P(D|w)dw\n= argmin\n\u03b8\nThe resulting cost function is variously known as the varia-\ntional free energy (Neal and Hinton, 1998; Yedidia et al.,\n2000; Friston et al., 2007) or the expected lower bound\n(Saul et al., 1996; Neal and Hinton, 1998; Jaakkola and\nJordan, 2000). For simplicity we shall denote it as\nF(D,\u03b8) = KL[q(w|\u03b8) || P(w)]\n\u2212 Eq(w|\u03b8)[logP(D|w)].\n(1)\nThe cost function of (1) is a sum of a data-dependent part,\nwhich we shall refer to as the likelihood cost, and a prior-\ndependent part, which we shall refer to as the complexity\ncost. The cost function embodies a trade-off between satis-\nfying the complexity of the data D and satisfying the sim-\nplicity prior P(w). (1) is also readily given an information\ntheoretic interpretation as a minimum description length\ncost (Hinton and Van Camp, 1993; Graves, 2011). Exactly\nminimisingthiscostna\u00a8 \u0131velyiscomputationallyprohibitive.\nInstead gradient descent and various approximations are\nused.\n3.1. Unbiased Monte Carlo gradients\nUnder certain conditions, the derivative of an expectation\ncan be expressed as the expectation of a derivative:\nProposition 1. Let ? be a random variable having a prob-\nability density given by q(?) and let w = t(\u03b8,?) where\nt(\u03b8,?) is a deterministic function. Suppose further that\nthe marginal probability density of w, q(w|\u03b8), is such that\nq(?)d? = q(w|\u03b8)dw. Then for a function f with deriva-\ntives in w:\n?\u2202f(w,\u03b8)\n\u2202\n\u2202\u03b8Eq(w|\u03b8)[f(w,\u03b8)] = Eq(?)\n\u2202w\n\u2202w\n\u2202\u03b8+\u2202f(w,\u03b8)\n\u2202\u03b8\n?\n.\nProof.\n\u2202\n\u2202\u03b8Eq(w|\u03b8)[f(w,\u03b8)] =\n\u2202\n\u2202\u03b8\n\u2202\n\u2202\u03b8\n?\n?\nf(w,\u03b8)q(w|\u03b8)dw\n=f(w,\u03b8)q(?)d?\n?\u2202f(w,\u03b8)\n= Eq(?)\n\u2202w\n\u2202w\n\u2202\u03b8+\u2202f(w,\u03b8)\n\u2202\u03b8\n?\nThe deterministic function t(\u03b8,?) transforms a sample of\nparameter-free noise ? and the variational posterior param-\neters \u03b8 into a sample from the variational posterior. Below\nwe shall see how this transform works in practice for the\nGaussian case.\nWe apply Proposition 1 to the optimisation problem in\n(1): let f(w,\u03b8) = logq(w|\u03b8) \u2212 logP(w)P(D|w). Us-\ning Monte Carlo sampling to evaluate the expectations,\na backpropagation-like (LeCun, 1985; Rumelhart et al.,\n1988) algorithm is obtained for variational Bayesian infer-\nence in neural networks \u2013 Bayes by Backprop \u2013 which uses\nunbiased estimates of gradients of the cost in (1) to learn a\ndistribution over the weights of a neural network.\nProposition 1 is a generalisation of the Gaussian re-\nparameterisation trick (Opper and Archambeau, 2009;\nKingma and Welling, 2014; Rezende et al., 2014) used for\nlatent variable models, applied to Bayesian learning of neu-\nral networks. Our work differs from this previous work in\nseveral significant ways. Bayes by Backprop operates on\nweights (of which there are a great many), whilst most pre-\nvious work applies this method to learning distributions on\nstochastic hidden units (of which there are far fewer than\nthe number of weights). Titsias and L\u00b4 azaro-Gredilla (2014)\nconsidered a large-scale logistic regression task. Unlike\nprevious work, we do not use the closed form of the com-\nplexity cost (or entropic part): not requiring a closed form\nof the complexity cost allows many more combinations of\nprior and variational posterior families. Indeed this scheme\nis also simple to implement and allows prior\/posterior com-\nbinations to be interchanged. We approximate the exact\ncost (1) as:\nF(D,\u03b8) \u2248\nn\n?\ni=1\nlogq(w(i)|\u03b8) \u2212 logP(w(i))\n\u2212 logP(D|w(i))\n(2)\nwherew(i)denotestheithMonteCarlosampledrawnfrom\nthe variational posterior q(w(i)|\u03b8). Note that every term of\nthis approximate cost depends upon the particular weights\ndrawn from the variational posterior: this is an instance of\na variance reduction technique known as common random\nnumbers (Owen, 2013). In previous work, where a closed\nform complexity cost or closed form entropy term are used,\npart of the cost is sensitive to particular draws from the\nposterior, whilst the closed form part is oblivious. Since\neach additive term in the approximate cost in (2) uses the\nsame weight samples, the gradients of (2) are only affected\nby the parts of the posterior distribution characterised by\nthe weight samples. In practice, we did not find this to\nperform better than using a closed form KL (where it could\nbe computed), but we did not find it to perform worse. In\nour experiments, we found that a prior without an easy-to-\ncompute closed form complexity cost performed best."},{"page":4,"text":"Weight Uncertainty in Neural Networks\n3.2. Gaussian variational posterior\nSuppose that the variational posterior is a diagonal Gaus-\nsian distribution, then a sample of the weights w can be\nobtained by sampling a unit Gaussian, shifting it by a mean\n\u00b5 and scaling by a standard deviation \u03c3. We parameterise\nthe standard deviation pointwise as \u03c3 = log(1 + exp(\u03c1))\nand so \u03c3 is always non-negative. The variational posterior\nparameters are \u03b8 = (\u00b5,\u03c1). Thus the transform from a sam-\nple of parameter-free noise and the variational posterior pa-\nrameters that yields a posterior sample of the weights w is:\nw = t(\u03b8,?) = \u00b5 + log(1 + exp(\u03c1)) \u25e6 ? where \u25e6 is point-\nwise multiplication. Each step of optimisation proceeds as\nfollows:\n1. Sample ? \u223c N(0,I).\n2. Let w = \u00b5 + log(1 + exp(\u03c1)) \u25e6 ?.\n3. Let \u03b8 = (\u00b5,\u03c1).\n4. Let f(w,\u03b8) = logq(w|\u03b8) \u2212 logP(w)P(D|w).\n5. Calculate the gradient with respect to the mean\n\u2206\u00b5=\u2202f(w,\u03b8)\n\u2202w\n+\u2202f(w,\u03b8)\n\u2202\u00b5\n.\n(3)\n6. Calculate the gradient with respect to the standard de-\nviation parameter \u03c1\n\u2206\u03c1=\u2202f(w,\u03b8)\n\u2202w\n?\n1 + exp(\u2212\u03c1)+\u2202f(w,\u03b8)\n\u2202\u03c1\n.\n(4)\n7. Update the variational parameters:\n\u00b5 \u2190 \u00b5 \u2212 \u03b1\u2206\u00b5\n\u03c1 \u2190 \u03c1 \u2212 \u03b1\u2206\u03c1.\n(5)\n(6)\nNotethatthe\u2202f(w,\u03b8)\nstandard deviation are shared and are exactly the gradients\nfound by the usual backpropagation algorithm on a neural\nnetwork. Thus, remarkably, to learn both the mean and the\nstandard deviation we must simply calculate the usual gra-\ndients found by backpropagation, and then scale and shift\nthem as above.\n\u2202w\ntermofthegradientsforthemeanand\n3.3. Scale mixture prior\nHaving liberated our algorithm from the confines of Gaus-\nsian priors and posteriors, we propose a simple scale mix-\nture prior combined with a diagonal Gaussian posterior.\nThe diagonal Gaussian posterior is largely free from nu-\nmerical issues, and two degrees of freedom per weight only\nincreases the number of parameters to optimise by a factor\nof two, whilst giving each weight its own quantity of un-\ncertainty.\nWe pick a fixed-form prior and do not adjust its hyper-\nparameters during training, instead picking the them by\ncross-validation where possible. Empirically we found op-\ntimising the parameters of a prior P(w) (by taking deriva-\ntives of (1)) to not be useful, and yield worse results.\nGraves (2011) and Titsias and L\u00b4 azaro-Gredilla (2014) pro-\npose closed form updates of the prior hyperparameters.\nChanging the prior based upon the data that it is meant to\nregularise is known as empirical Bayes and there is much\ndebate as to its validity (Gelman, 2008). A reason why it\nfails for Bayes by Backprop is as follows: it can be eas-\nier to change the prior parameters (of which there are few)\nthan it is to change the posterior parameters (of which there\nare many) and so very quickly the prior parameters try to\ncapture the empirical distribution of the weights at the be-\nginning of learning. Thus the prior learns to fit poor initial\nparameters quickly, and makes the cost in (1) less willing\nto move away from poor initial parameters. This can yield\nslow convergence, introduce strange local minima and re-\nsult in poor performance.\nWe propose using a scale mixture of two Gaussian densi-\nties as the prior. Each density is zero mean, but differing\nvariances:\nP(w) =\n?\nj\n\u03c0N(wj|0,\u03c32\n1) + (1 \u2212 \u03c0)N(wj|0,\u03c32\n2), (7)\nwhere wjis the jth weight of the network, N(x|\u00b5,\u03c32) is\nthe Gaussian density evaluated at x with mean \u00b5 and vari-\nance \u03c32and \u03c32\ncomponents. The first mixture component of the prior is\ngiven a larger variance than the second, \u03c31> \u03c32, provid-\ning a heavier tail in the prior density than a plain Gaussian\nprior. The second mixture component has a small variance\n\u03c32? 1causingmanyoftheweightstoaprioritightlycon-\ncentrate around zero. Our prior resembles a spike-and-slab\nprior (Mitchell and Beauchamp, 1988; George and McCul-\nloch, 1993; Chipman, 1996), where instead all the prior pa-\nrameters are shared among all the weights. This makes the\nprior more amenable to use during optimisation by stochas-\ntic gradient descent and avoids the need for prior parameter\noptimisation based upon training data.\n1and \u03c32\n2are the variances of the mixture\n3.4. Minibatches and KL re-weighting\nAs several authors have noted, the cost in (1) is amenable\ntominibatchoptimisation, oftenusedwithneuralnetworks:\nfor each epoch of optimisation the training data D is ran-\ndomly split into a partition of M equally-sized subsets,\nD1,D2,...,DM. Each gradient is averaged over all ele-\nments in one of these minibatches; a trade-off between a\nfully batched gradient descent and a fully stochastic gradi-\nent descent. Graves (2011) proposes minimising the mini-"},{"page":5,"text":"Weight Uncertainty in Neural Networks\nbatch cost for minibatch i = 1,2,...,M:\nFEQ\ni(Di,\u03b8) =\n1\nMKL[q(w|\u03b8) || P(w)]\n\u2212 Eq(w|\u03b8)[logP(Di|w)].\nThis is equivalent to the cost in (1) since?\ncost relative to the likelihood cost on each minibatch. For\nexample, if minibatches are partitioned uniformly at ran-\ndom, the KL cost can be distributed non-uniformly among\nthe minibatches at each epoch.\n?M\nF\u03c0\n\u2212 Eq(w|\u03b8)[logP(Di|w)]\nThen EM[?M\nIn particular, we found the scheme \u03c0i =\nwell: the first few minibatches are heavily influenced by\nthe complexity cost, whilst the later minibatches are largely\ninfluenced by the data. At the beginning of learning this is\nparticularly useful as for the first few minibatches changes\nin the weights due to the data are slight and as more data\nare seen, data become more influential and the prior less\ninfluential.\n(8)\niFEQ\ni(Di,\u03b8) =\nF(D,\u03b8). There are many ways to weight the complexity\nLet \u03c0 \u2208 [0,1]Mand\ni=1\u03c0i= 1, and define:\ni(Di,\u03b8) = \u03c0iKL[q(w|\u03b8) || P(w)]\n(9)\ni=1F\u03c0\ni(Di,\u03b8)] = F(D,\u03b8) where EMdenotes\nanexpectationovertherandompartitioningofminibatches.\n2M\u2212i\n2M\u22121to work\n4. Contextual Bandits\nContextual bandits are simple reinforcement learning prob-\nlems without persistent state (Li et al., 2010; Filippi et al.,\n2010). At each step an agent is presented with a context\nx and a choice of one of K possible actions a. Different\nactions yield different unknown rewards r. The agent must\npick the action that yields the highest expected reward. The\ncontext is assumed to be presented independent of any pre-\nvious actions, rewards or contexts.\nAn agent builds a model of the distribution of the rewards\nconditioned upon the action and the context: P(r|x,a,w).\nIt then uses this model to pick its action. Note, importantly,\nthat an agent does not know what reward it could have re-\nceived for an action that it did not pick, a difficulty often\nknown as \u201cthe absence of counterfactual\u201d. As the agent\u2019s\nmodel P(r|x,a,w) is trained online, based upon the ac-\ntionschosen, unlessexploratoryactionsaretaken, theagent\nmay perform suboptimally.\n4.1. Thompson Sampling for Neural Networks\nAs in Section 2, P(r|x,a,w) can be modelled by a neural\nnetwork where w are the weights of the neural network.\nHowever if this network is simply fit to observations and\nthe action with the highest expected reward taken at each\ntime, the agent can under-explore, as it may miss more re-\nwarding actions.1\nThompson sampling (Thompson, 1933) is a popular means\nof picking an action that trades-off between exploitation\n(picking the best known action) and exploration (picking\nwhat might be a suboptimal arm to learn more). Thomp-\nson sampling usually necessitates a Bayesian treatment of\nthe model parameters. At each step, Thompson sampling\ndraws a new set of parameters and then picks the action\nrelative to those parameters. This can be seen as a kind\nof stochastic hypothesis testing: more probable parame-\nters are drawn more often and thus refuted or confirmed\nthe fastest. More concretely Thompson sampling proceeds\nas follows:\n1. Sample a new set of parameters for the model.\n2. Pick the action with the highest expected reward ac-\ncording to the sampled parameters.\n3. Update the model. Go to 1.\nThereisanincreasingliteratureconcerningtheefficacyand\njustification of this means of exploration (Chapelle and Li,\n2011; May et al., 2012; Kaufmann et al., 2012; Agrawal\nand Goyal, 2012; 2013). Thompson sampling is easily\nadapted to neural networks using the variational posterior\nfound in Section 3:\n1. Sample weights from the variational posterior: w \u223c\nq(w|\u03b8).\n2. Receive the context x.\n3. Pick the action a that minimises EP(r|x,a,w)[r]\n4. Receive reward r.\n5. Update variational parameters \u03b8 according to Sec-\ntion 3. Go to 1.\nNote that it is possible, as mentioned in Section 3.1, to de-\ncrease the variance of the gradient estimates, trading off for\nreduced exploration, by using more than one Monte Carlo\nsample, using the corresponding networks as an ensemble\nand picking the action by minimising the average of the\nexpectations.\nInitially the variational posterior will be close to the prior,\nand actions will be picked uniformly. As the agent takes ac-\ntions, the variational posterior will begin to converge, and\nuncertainty on many parameters can decrease, and so ac-\ntion selection will become more deterministic, focusing on\nthe high expected reward actions discovered so far. It is\n1Interestingly, depending upon how w are initialised and the\nmean of prior used during MAP inference, it is sometimes pos-\nsible to obtain another heuristic for the exploration-exploitation\ntrade-off: optimism-under-uncertainty. We leave this for future\ninvestigation."},{"page":6,"text":"Weight Uncertainty in Neural Networks\nTable 1. Classification Error Rates on MNIST. ? indicates result\nused an ensemble of 5 networks.\nMethod\nSGD, no regularisation (Simard et al., 2003)\nSGD, dropout (Hinton et al., 2012)\nSGD, dropconnect (Wan et al., 2013)\nSGD\n# Units\/Layer\n# Weights\nTest\nError\n1.6%\n\u2248 1.3%\n1.2%?\n1.83%\n1.84%\n1.88%\n1.51%\n1.33%\n1.36%\n1.82%\n1.99%\n2.04%\n1.36%\n1.34%\n1.32%\n800 1.3m\n800\n400\n800\n1200\n400\n800\n1200\n400\n800\n1200\n400\n800\n1200\n1.3m\n500k\n1.3m\n2.4m\n500k\n1.3m\n2.4m\n500k\n1.3m\n2.4m\n500k\n1.3m\n2.4m\nSGD, dropout\nBayes by Backprop, Gaussian\nBayes by Backprop, Scale mixture\nknown that variational methods under-estimate uncertainty\n(Minka, 2001; 2005; Bishop, 2006) which could lead to\nunder-exploration and premature convergence in practice,\nbut we did not find this in practice.\n5. Experiments\nWe present some empirical evaluation of the methods pro-\nposed above: on MNIST classification, on a non-linear re-\ngression task, and on a contextual bandits task.\n5.1. Classification on MNIST\nWe trained networks of various sizes on the MNIST dig-\nits dataset (LeCun and Cortes, 1998), consisting of 60,000\ntraining and 10,000 testing pixel images of size 28 by 28.\nEach image is labelled with its corresponding number (be-\ntween zero and nine, inclusive). We preprocessed the pix-\nels by dividing values by 126. Many methods have been\nproposed to improve results on MNIST: generative pre-\ntraining, convolutions, distortions, etc. Here we shall focus\non improving the performance of an ordinary feedforward\nneural network without using any of these methods. We\nused a network of two hidden layers of rectified linear units\n(Nair and Hinton, 2010; Glorot et al., 2011), and a softmax\noutput layer with 10 units, one for each possible label.\nAccording to Hinton et al. (2012), the best published feed-\nforward neural network classification result on MNIST (ex-\ncluding those using data set augmentation, convolutions,\netc.) is 1.6% (Simard et al., 2003), whilst dropout with\nan L2 regulariser attains errors around 1.3%. Results from\nBayes by Backprop are shown in Table 1, for various sized\n0.8\n1.2\n1.6\n2.0\n0100200300 400500600\nEpochs\nTest error (%)\nAlgorithm\nBayes by Backprop\nDropout\nVanilla SGD\nFigure 2. Test error on MNIST as training progresses.\n0\n5\n10\n15\n\u22120.2\u22120.10.00.1 0.2\nWeight\nDensity\nAlgorithm\nBayes by Backprop\nDropout\nVanilla SGD\nFigure 3. Histogram of the trained weights of the neural network,\nfor Dropout, plain SGD, and samples from Bayes by Backprop.\nnetworks, using either a Gaussian or Gaussian scale mix-\nture prior. Performance is comparable to that of dropout,\nperhaps slightly better, as also see on Figure 2. Note that\nwe trained on 50,000 digits and used 10,000 digits as a val-\nidation set, whilst Hinton et al. (2012) trained on 60,000\ndigits and did not use a validation set. We used the vali-\ndation set to pick the best hyperparameters (learning rate,\nnumber of gradients to average) and so we also repeated\nthisprotocolfordropoutandSGD(StochasticGradientDe-\nscent on the MLE objective in Section 2). We considered\nlearning rates of 10\u22123, 10\u22124and 10\u22125with minibatches\nof size 128. For Bayes by Backprop, we averaged over ei-\nther 1, 2, 5, or 10 samples and considered \u03c0 \u2208 {1\n\u2212log\u03c31\u2208 {0,1,2} and \u2212log\u03c32\u2208 {6,7,8}.\nFigure 2 shows the learning curves on the test set for Bayes\nby Backprop, dropout and SGD on a network with two lay-\ners of 1200 rectified linear units. As can be seen, SGD\nconverges the quickest, initially obtaining a low test er-\nror and then overfitting. Bayes by Backprop and dropout\nconverge at similar rates (although each iteration of Bayes\nby Backprop is more expensive than dropout \u2013 around two\ntimes slower). Eventually Bayes by Backprop converges\non a better test error than dropout after 600 epochs.\n4,1\n2,3\n4},\nFigure3showsdensityestimatesoftheweights. TheBayes\nby Backprop weights are sampled from the variational pos-\nterior, and the dropout weights are those used at test time.\nInterestingly the regularised networks found by dropout"},{"page":7,"text":"Weight Uncertainty in Neural Networks\nandBayesbyBackprophaveagreaterrangeandwithfewer\ncentred at zero than those found by SGD. Bayes by Back-\nprop uses the greatest range of weights.\n0.0\n0.2\n0.4\n0.6\n0.8\n\u22125.0\u22122.50.0\nSignal\u2212to\u2212Noise Ratio (dB)\nDensity\n0.00\n0.25\n0.50\n0.75\n1.00\n\u22127.5 \u22125.0\u22122.50.0\nSignal\u2212to\u2212Noise Ratio (dB)\nCDF\nFigure 4. Density and CDF of the Signal-to-Noise ratio over all\nweights in the network. The red line denotes the 75% cut-off.\nIn Table 2, we examine the effect of replacing the vari-\national posterior on some of the weights with a constant\nzero, so as to determine the level of redundancy in the\nnetwork found by Bayes by Backprop. We took a Bayes\nby Backprop trained network with two layers of 1200\nunits2and ordered the weights by their signal-to-noise ra-\ntio (|\u00b5i|\/\u03c3i). We removed the weights with the lowest sig-\nnal to noise ratio. As can be seen in Table 2, even when\n95% of the weights are removed the network still performs\nwell, with a significant drop in performance once 98% of\nthe weights have been removed.\nIn Figure 4 we examined the distribution of the signal-to-\nnoise relative to the cut-off in the network uses in Table 2.\nThe lower plot shows the cumulative distribution of signal-\nto-noise ratio, whilst the top plot shows the density. From\nthe density plot we see there are two modalities of signal-\nto-noise ratios, and from the CDF we see that the 75%\ncut-off separates these two peaks. These two peaks coin-\ncide with a drop in performance in Table 2 from 1.24%\nto 1.29%, suggesting that the signal-to-noise heuristic is in\nfact related to the test performance.\n2We used a network from the end of training rather than pick-\ning a network with a low validation cost found during training,\nhence the disparity with results in Table 1. The lowest test error\nobserved was 1.12%.\nTable 2. Classification Errors after Weight pruning\nProportion removed\n0%\n50%\n75%\n95%\n98%\n# Weights\n2.4m\n1.2m\n600k\n120k\n48k\nTest Error\n1.24%\n1.24%\n1.24%\n1.29%\n1.39%\nIt is interesting to contrast this weight removal approach\nto obtaining a fast, smaller, sparse network for prediction\nafter training with the approach taken by distillation (Hin-\nton et al., 2014) which requires an extra stage of training\nto obtain a compressed prediction model. As with distil-\nlation, our method begins with an ensemble (one for each\npossible assignment of the weights). However, unlike dis-\ntillation, we can simply obtain a subset of this ensemble by\nusingtheprobabilisticpropertiesoftheweightdistributions\nlearnt to gracefully prune the ensemble down into a smaller\nnetwork. Thus even though networks trained by Bayes by\nBackprop may have twice as many weights, the number of\nparameters that actually need to be stored at run time can be\nfar fewer. Graves (2011) also considered pruning weights\nusing the signal to noise ratio, but demonstrated results on\na network 20 times smaller and did not prune as high a\nproportion of weights (at most 11%) whilst still maintain-\ning good test performance. The scale mixture prior used\nby Bayes by Backprop encourages a broad spread of the\nweights. Many of these weights can be successfully pruned\nwithout impacting performance significantly.\n5.2. Regression curves\nWe generated training data from the curve:\ny = x + 0.3sin(2\u03c0(x + ?)) + 0.3sin(4\u03c0(x + ?)) + ?\nwhere ? \u223c N(0,0.02). Figure 5 shows two examples of\nfitting a neural network to these data, minimising a condi-\ntional Gaussian loss. Note that in the regions of the input\nspace where there are no data, the ordinary neural network\nreduces the variance to zero and chooses to fit a particu-\nlar function, even though there are many possible extrap-\nolations of the training data. On the left, Bayesian model\naveraging affects predictions: where there are no data, the\nconfidence intervals diverge, reflecting there being many\npossible extrapolations. In this case Bayes by Backprop\nprefers to be uncertain where there are no nearby data, as\nopposed to a standard neural network which can be overly\nconfident.\n5.3. Bandits on Mushroom Task\nWe take the UCI Mushrooms data set (Bache and Lichman,\n2013), and cast it as a bandit task, similar to Guez (2015,"},{"page":8,"text":"Weight Uncertainty in Neural Networks\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nxxx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nxx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx x\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nxx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx x\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx x\nx\nx\nx\nx\nx\nx\nx\nxx\nx\nxx\nx\nx\nxx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nxx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nxx\nx\nx\nx\nx x\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx x\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nxx\nx\nx\nx\nx\nx\nxx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nxx\nxx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nxx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nxxx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nxx\nx\nx\nx\nxx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nxx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nxx\nx\nx\nx\nx x\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nxx\nx\nxx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nxx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nxx\nx\nx\nx\nxx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nxx\nx\nx\nx\nx\nxxx\nx\nxx\nx\nx\nx\n\u22120.4\n0.0\n0.4\n0.8\n1.2\n0.00.40.81.2\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nxxx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nxx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx x\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nxx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx x\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx x\nx\nx\nx\nx\nx\nx\nx\nxx\nx\nxx\nx\nx\nxx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nxx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nxx\nx\nx\nx\nx x\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx x\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nxx\nx\nx\nx\nx\nx\nxx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nxx\nxx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nxx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nxxx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nxx\nx\nx\nx\nxx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nxx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nxx\nx\nx\nx\nx x\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nxx\nx\nxx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nxx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nxx\nx\nx\nx\nxx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nxx\nx\nx\nx\nx\nxxx\nx\nxx\nx\nx\nx\n\u22120.4\n0.0\n0.4\n0.8\n1.2\n0.0 0.4 0.8 1.2\nFigure 5. Regression of noisy data with interquatile ranges. Black\ncrosses are training samples. Red lines are median predictions.\nBlue\/purple region is interquartile range. Left: Bayes by Back-\nprop neural network, Right: standard neural network.\n1000\n10000\n01000020000300004000050000\nStep\nCumulative Regret\n5% Greedy\n1% Greedy\nGreedy\nBayes by Backprop\nFigure 6. Comparison of cumulative regret of various agents on\nthe mushroom bandit task, averaged over five runs. Lower is bet-\nter.\nChapter 6). Each mushroom has a set of features, which we\ntreat as the context for the bandit, and is labelled as edible\nor poisonous. An agent can either eat or not eat a mush-\nroom. If an agent eats an edible mushroom, then it receives\na reward of 5. If an agent eats a poisonous mushroom, then\nwith probability1\na reward of 5. If an agent elects not to eat a mushroom,\nit receives a reward of 0. Thus an agent expects to receive\na reward of 5 for eating an edible reward, but an expected\nreward of \u221215 for eating a poisonous mushroom.\nRegret measures the difference between the reward achiev-\nable by an oracle and the reward received by an agent. In\nthis case, an oracle will always receive a reward of 5 for an\nedible mushroom, or 0 for a poisonous mushroom. We take\nthe cumulative sum of regret of several agents and show\nthem in Figure 6. Each agent uses a neural network with\ntwo hidden layers of 100 rectified linear units. The input\nto the network is a vector consisting of the mushroom fea-\ntures (context) and a one of K encoding of the action. The\noutput of the network is a single scalar, representing the ex-\npected reward of the given action in the given context. For\nBayes by Backprop, we sampled the weights twice and av-\neraged two of these outputs to obtain the expected reward\n2it receives a reward of \u221235, otherwise\nfor action selection. We kept the last 4096 reward, context\nand action tuples in a buffer, and trained the networks us-\ning randomly drawn minibatches of size 64 for 64 training\nsteps (64\u00d764 = 4096) per interaction with the Mushroom\nbandit. A common heuristic for trading-off exploration vs.\nexploitation is to follow an \u03b5-greedy policy: with proba-\nbility \u03b5 propose a uniformly random action, otherwise pick\nthe best action according to the neural network.\nFigure 6 compares a Bayes by Backprop agent with three\n\u03b5-greedy agents, for values of \u03b5 of 0% (pure greedy), 1%,\nand 5%. An \u03b5 of 5% appears to over-explore, whereas a\npurely greedy agent does poorly at the beginning, greed-\nily electing to eat nothing, but then does much better once\nit has seen enough data. It seems that non-local function\napproximation updates allow the greedy agent to explore,\nas for the first 1,000 steps, the agent eats nothing but after\napproximately 1,000 the greedy agent suddenly decides to\neat mushrooms. The Bayes by Backprop agent explores\nfrom the beginning, both eating and ignoring mushrooms\nand quickly converges on eating and non-eating with an al-\nmost perfect rate (hence the almost flat regret).\n6. Discussion\nWe introduced a new algorithm for learning neural net-\nworks with uncertainty on the weights called Bayes by\nBackprop. It optimises a well-defined objective function\nto learn a distribution on the weights of a neural network.\nThe algorithm achieves good results in several domains.\nWhen classifying MNIST digits, performance from Bayes\nby Backprop is comparable to that of dropout. We demon-\nstrated on a simple non-linear regression problem that the\nuncertainty introduced allows the network to make more\nreasonable predictions about unseen data. Finally, for con-\ntextual bandits, we showed how Bayes by Backprop can\nautomatically learn how to trade-off exploration and ex-\nploitation. Since Bayes by Backprop simply uses gradient\nupdates, it can readily be scaled using multi-machine opti-\nmisation schemes such as asynchronous SGD (Dean et al.,\n2012). Furthermore, all of the operations used are readily\nimplemented on a GPU.\nAcknowledgements\nDanihelka, Danilo Rezende, Silvia Chiappa, Alex Graves,\nRemi Munos, Ben Coppin, Liam Clancy, James Kirk-\npatrick, Shakir Mohamed, David Pfau, and Theophane We-\nber for useful discussions and comments.\nThe authors would like to thank Ivo\nReferences\nShipra Agrawal and Navin Goyal. Analysis of Thompson\nsampling for the multi-armed bandit problem. In Pro-\nceedings of the 25th Annual Conference On Learning"},{"page":9,"text":"Weight Uncertainty in Neural Networks\nTheory (COLT), volume 23, pages 39.1\u201339.26, 2012.\nShipra Agrawal and Navin Goyal. Further optimal regret\nbounds for Thompson sampling. In Proceedings of the\n16th International Conference on Artificial Intelligence\nand Statistics Learning (AISTATS), pages 99\u2013107, 2013.\nKevin Bache and Moshe Lichman. UCI Machine Learning\nRepository. University of California, Irvine, School of\nInformation and Computer Sciences, 2013. URL http:\n\/\/archive.ics.uci.edu\/ml.\nChristopher M Bishop. Section 10.1: variational inference.\nIn Pattern Recognition and Machine Learning. Springer,\n2006. ISBN 9780387310732.\nWray L Buntine and Andreas S Weigend. Bayesian back-\npropagation. Complex systems, 5(6):603\u2013643, 1991.\nOlivier Chapelle and Lihong Li. An empirical evaluation of\nThompson sampling. In Advances in Neural Information\nProcessing Systems (NIPS), pages 2249\u20132257, 2011.\nHugh Chipman. Bayesian variable selection with related\npredictors. Canadian Journal of Statistics, 24(1):17\u201336,\n1996.\nJeffrey Dean, Greg Corrado, Rajat Monga, Kai Chen,\nMatthieu Devin, Mark Mao, Andrew Senior, Paul\nTucker, Ke Yang, Quoc V Le, et al. Large scale dis-\ntributed deep networks. In Advances in Neural Infor-\nmation Processing Systems (NIPS), pages 1223\u20131231,\n2012.\nSarah Filippi, Olivier Cappe, Aurlien Garivier, and Csaba\nSzepesvri. Parametric bandits: The generalized linear\ncase. In Advances in Neural Information Processing Sys-\ntems, pages 586\u2013594, 2010.\nKarl Friston, J\u00b4 er\u00b4 emie Mattout, Nelson Trujillo-Barreto,\nJohn Ashburner, and Will Penny. Variational free en-\nergy and the Laplace approximation. Neuroimage, 34\n(1):220\u2013234, 2007.\nAndrew Gelman.\nBayesian Analysis, 3:445\u2013450, 2008. ISSN 1931-6690.\ndoi: 11.1214\/08-BA318.\nObjections to Bayesian statistics.\nEdward I George and Robert E McCulloch. Variable selec-\ntion via gibbs sampling. Journal of the American Statis-\ntical Association, 88(423):881\u2013889, 1993.\nXavier Glorot, Antoine Bordes, and Yoshua Bengio. Deep\nsparse rectifier networks. In Proceedings of the 14th\nInternational Conference on Artificial Intelligence and\nStatistics Learning (AISTATS), volume 15, pages 315\u2013\n323, 2011.\nAlex Graves. Practical variational inference for neural net-\nworks. In Advances in Neural Information Processing\nSystems (NIPS), pages 2348\u20132356, 2011.\nKarol Gregor, Ivo Danihelka, Andriy Mnih, Charles Blun-\ndell, and Daan Wierstra.\nworks. In Proceedings of the 31st International Confer-\nence on Machine Learning (ICML), pages 1242\u20131250,\n2014.\nDeep AutoRegressive net-\nArthur Guez. Sample-Based Search Methods For Bayes-\nAdaptive Planning. PhD thesis, University College Lon-\ndon, 2015.\nGeoffrey Hinton, Oriol Vinyals, and Jeff Dean. Distilling\nthe knowledge in a neural network. In NIPS 2014 Deep\nLearning and Representation Learning Workshop, 2014.\nGeoffrey E Hinton and Drew Van Camp. Keeping the neu-\nralnetworkssimplebyminimizingthedescriptionlength\nof the weights. In Proceedings of the 16th Annual Con-\nference On Learning Theory (COLT), pages 5\u201313. ACM,\n1993.\nGeoffrey E. Hinton, Nitish Srivastava, Alex Krizhevsky,\nIlya Sutskever, and Ruslan R. Salakhutdinov. Improving\nneural networks by preventing co-adaptation of feature\ndetectors. arXiv:1207.0580, July 2012.\nTommiS.JaakkolaandMichaelI.Jordan. Bayesianparam-\neter estimation via variational methods. Statistics and\nComputing, 10(1):25\u201337, 2000.\nEmilie Kaufmann, Nathaniel Korda, and R\u00b4 emi Munos.\nThompson sampling: An asymptotically optimal finite-\ntimeanalysis. InProceedingsofthe23rdAnnualConfer-\nence on Algorithmic Learning Theory (ALT), pages 199\u2013\n213. Springer, 2012.\nDiederik P. Kingma and Max Welling. Auto-encoding vari-\national Bayes. In Proceedings of the 2nd International\nConference on Learning Representations (ICLR), 2014.\narXiv: 1312.6114.\nYann LeCun. Une proc\u00b4 edure d\u2019apprentissage pour r\u00b4 eseau\n` a seuil asymmetrique (a learning scheme for asymmetric\nthreshold networks). In Proceedings of Cognitiva 85,\nParis, France, pages 599\u2013604, 1985.\nYann LeCun and Corinna Cortes. The MNIST database\nof handwritten digits. 1998. URL http:\/\/yann.\nlecun.com\/exdb\/mnist\/.\nLihong Li, Wei Chu, John Langford, and Robert E.\nSchapire.A contextual-bandit approach to personal-\nized news article recommendation. In Proceedings of\nthe 19th International Conference on World Wide Web,\nWWW \u201910, pages 661\u2013670, New York, NY, USA,"},{"page":10,"text":"Weight Uncertainty in Neural Networks\n2010. ACM. ISBN 978-1-60558-799-8. doi: 10.1145\/\n1772690.1772758.\nDavid JC MacKay. A practical Bayesian framework for\nbackpropagation networks. Neural computation, 4(3):\n448\u2013472, 1992.\nDavid JC MacKay.\npredictions-a review of practical Bayesian methods for\nsupervised neural networks. Network: Computation in\nNeural Systems, 6(3):469\u2013505, 1995.\nProbable networks and plausible\nBenedict C May, Nathan Korda, Anthony Lee, and\nDavid S. Leslie. Optimistic Bayesian sampling in\ncontextual-bandit problems.\nLearning Research, 13(1):2069\u20132106, 2012.\nThe Journal of Machine\nThomas P Minka. A family of algorithms for approximate\nBayesian inference. PhD thesis, Massachusetts Institute\nof Technology, 2001.\nThomas P Minka. Divergence measures and message pass-\ning. Technical report, Microsoft Research, 2005.\nToby J Mitchell and John J Beauchamp. Bayesian variable\nselection in linear regression. Journal of the American\nStatistical Association, 83(404):1023\u20131032, 1988.\nVinod Nair and Geoffrey E Hinton. Rectified linear units\nimprove restricted Boltzmann machines. In Proceedings\nof the 27th International Conference on Machine Learn-\ning (ICML), pages 807\u2013814, 2010.\nRadford M Neal and Geoffrey E Hinton. A view of the EM\nalgorithm that justifies incremental, sparse, and other\nvariants. In Learning in graphical models, pages 355\u2013\n368. Springer, 1998.\nManfred Opper and C\u00b4 edric Archambeau. The variational\nGaussian approximation revisited. Neural computation,\n21(3):786\u2013792, 2009.\nArt B. Owen. Monte Carlo theory, methods and examples.\n2013.\nDanilo Jimenez Rezende, Shakir Mohamed, and Daan\nWierstra. Stochastic backpropagation and approximate\ninference in deep generative models. In Proceedings of\nthe 31st International Conference on Machine Learning\n(ICML), pages 1278\u20131286, 2014.\nDavid E Rumelhart, Geoffrey E Hinton, and Ronald J\nWilliams. Learning representations by back-propagating\nerrors. Cognitive modeling, 5, 1988.\nLawrence K Saul, Tommi Jaakkola, and Michael I Jordan.\nMean field theory for sigmoid belief networks. Journal\nof artificial intelligence research, 4(1):61\u201376, 1996.\nPatrice Y Simard, Dave Steinkraus, and John C Platt. Best\npracticesforconvolutionalneuralnetworksappliedtovi-\nsualdocumentanalysis. InProceedingsofthe12thInter-\nnational Conference on Document Analysis and Recog-\nnition (ICDAR), volume 2, pages 958\u2013958. IEEE Com-\nputer Society, 2003.\nWilliam R Thompson. On the likelihood that one unknown\nprobability exceeds another in view of the evidence of\ntwo samples. Biometrika, pages 285\u2013294, 1933.\nMichalis Titsias and Miguel L\u00b4 azaro-Gredilla.\nstochastic variational bayes for non-conjugate inference.\nIn Proceedings of the 31st International Conference on\nMachine Learning (ICML-14), pages 1971\u20131979, 2014.\nDoubly\nLi Wan, Matthew Zeiler, Sixin Zhang, Yann L Cun, and\nRob Fergus.Regularization of neural networks us-\ning dropconnect.In Proceedings of the 30th Inter-\nnational Conference on Machine Learning (ICML-13),\npages 1058\u20131066, 2013.\nJonathan S Yedidia, William T Freeman, and Yair Weiss.\nGeneralized belief propagation. In Advances in Neu-\nral Information Processing Systems (NIPS), volume 13,\npages 689\u2013695, 2000."}],"fullTextUrl":"https:\/\/www.researchgate.net\/profile\/Julien_Cornebise\/publication\/277022910_Weight_Uncertainty_in_Neural_Networks\/links\/56ab3cb808aeadd1bdccd5b7.pdf","widgetId":"rgw30_56aba0bb928c6"},"id":"rgw30_56aba0bb928c6","partials":[],"templateName":"publicliterature\/stubs\/PublicationText.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationText.html?publicationUid=277022910&hide=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationDetailAd":{"data":{"googleDfpSlot":null,"widgetId":"rgw31_56aba0bb928c6"},"id":"rgw31_56aba0bb928c6","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAd.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAd.html?publicationUid=277022910&slotId=336x280_Publications_ATF_Right&collapseSlotMode=never&fallbackContainerEnabled=1","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationRelations":null,"publicationRelationsReverse":null,"publicationUid":277022910,"showSignUpDialog":false,"selectNewSignUpDialog":false,"publicationQuestions":null,"publicationCitations":null,"publicationReviewPromo":null,"publicationUsedInReviews":null,"publicationPdfJsReader":{"data":{"isPreview":false,"licenseUrl":null,"licenseInfo":null,"defaultLinkData":{"linkId":"56ab3cb808aeadd1bdccd5b7","name":"Julien Cornebise","date":"Jan 29, 2016 ","nameLink":"profile\/Julien_Cornebise","filename":"","downloadLink":"https:\/\/www.researchgate.net\/profile\/Julien_Cornebise\/publication\/277022910_Weight_Uncertainty_in_Neural_Networks\/links\/56ab3cb808aeadd1bdccd5b7.pdf?inViewer=0&pdfJsDownload=0&origin=publication_detail","viewerUrl":"https:\/\/www.researchgate.net\/profile\/Julien_Cornebise\/publication\/277022910_Weight_Uncertainty_in_Neural_Networks\/links\/56ab3cb808aeadd1bdccd5b7.pdf?inViewer=1&pdfJsDownload=1&origin=publication_detail","downloadHash":"0a544dca096cc7b47899085042064788","showFileSizeNote":false,"fileSize":"614.04 KB","noFollow":false,"isDefault":true,"doi":null},"displayableLinks":[{"linkId":"56ab3cb808aeadd1bdccd5b7","name":"Julien Cornebise","date":"Jan 29, 2016 ","nameLink":"profile\/Julien_Cornebise","filename":"","downloadLink":"https:\/\/www.researchgate.net\/profile\/Julien_Cornebise\/publication\/277022910_Weight_Uncertainty_in_Neural_Networks\/links\/56ab3cb808aeadd1bdccd5b7.pdf?inViewer=0&pdfJsDownload=0&origin=publication_detail","viewerUrl":"https:\/\/www.researchgate.net\/profile\/Julien_Cornebise\/publication\/277022910_Weight_Uncertainty_in_Neural_Networks\/links\/56ab3cb808aeadd1bdccd5b7.pdf?inViewer=1&pdfJsDownload=1&origin=publication_detail","downloadHash":"0a544dca096cc7b47899085042064788","showFileSizeNote":false,"fileSize":"614.04 KB","noFollow":false,"isDefault":true,"doi":null}],"hasDisplayableLinks":false,"reader":{"data":{"pdfCommentsActive":false,"publicationType":"Article","onlyRenderFirstPage":false,"readMoreExperimentGoal":"goalPublicationPdfClicksReadMore","readMoreExperimentViewId":null,"comments":null,"figures":[],"figureAssetIds":[],"figureOverlayUrls":{"clickOnOverlay":"publication.PublicationFigures.html?_sg=X380lgMMRj20F0tfvYr5ZnPy0t4w6Gyi0Kgy3AYoP00H4wUdMMpUwPDWnlfPbG90vdxyLx1pkhCGpkn8c4A6RA.1Iwvbk1hmFySiMvcWQBh9jMNx32u9_3PGxQwTUVupqktRAo6A7iEZtlH2YUH-RX1L0VOwYOWCIiIAS_cwu6mKg","clickOnPill":"publication.PublicationFigures.html?_sg=fCdPxFcv8VVZv2RWSiuQTpP694Qz7bSaj16WXI4j5C4vEcklA-lro49lUZr-vrq3-83W6KSZpjn-TgiTWxEkqA.P83U8M0Pj7Uuy3pin-HByNO7ALxXPXwrFqNJA5TYs0Wsnv8Bzlsj5vYJHjoSrG4NJvk20QuSpkgc029OeuAWlw"},"canSelect":false,"javascriptPath":"https:\/\/www.researchgate.net\/c\/o1q2er\/","downloadUrl":"https%3A%2F%2Fwww.researchgate.net%2Fprofile%2FJulien_Cornebise%2Fpublication%2F277022910_Weight_Uncertainty_in_Neural_Networks%2Flinks%2F56ab3cb808aeadd1bdccd5b7.pdf%3FinViewer%3D1%26pdfJsDownload%3D1%26origin%3Dpublication_detail","viewerUrl":"https:\/\/www.researchgate.net\/c\/o1q2er\/javascript\/lib\/pdfjs\/web\/viewer.html","commentEndpoint":"https:\/\/www.researchgate.net\/rgformat\/api\/comment","experimentEndpoint":"https:\/\/www.researchgate.net\/rgformat\/api\/experiment?key=duckf4ejSvCgPqpjiZIYKfOkGDRkICEdsQ29rz-Z6bwYCZ7kWtvP6MQu1h6SEEVj08JG55YxCbeRZzFIuz8WLg","urlHash":"f445bbed42f82a38cf4991a7304ca6d9","downloadTrackUrl":"application.PdfJsReader.ajaxTrackDownload.html?msrp=sTfrh2JeV_IR9VqzYtDnha5_5XjgfcxBy6cHyEIAy_L-JE0qJrkxf9CzFr0dX4A1GV5g8ElX4xthLA65F6sZsedJirHEC-NwWN2xuy8ELrU.WLrW0UTurcRnCXl1aDvKBCtFbi6RsHyFUqU_3ueWl4csPuuk2A1TLsS0e6qcfseq9-CTOxo-5CmsiP5_S1Lt1Q.1UJ00JA84wnZhLHlc7uLvl96wpblv6v3cTLzDBFdiej9k_quOGXcz6miT3hkOQSs92pZApw4LUL2VNfx6J7cxg","viewportMilestoneTrackUrl":"application.PdfJsReader.ajaxTrackViewportMilestone.html","linkId":"56ab3cb808aeadd1bdccd5b7","trackedDownloads":{"56ab3cb808aeadd1bdccd5b7":{"v":false,"d":false}},"assetId":"AS:323176863600642@1454062776864","readerDocId":null,"assetType":"fulltext","interactionType":{"comment":"comment","highlight":"highlight"},"publicationUid":277022910,"commentCursorPromo":null,"widgetId":"rgw33_56aba0bb928c6"},"id":"rgw33_56aba0bb928c6","partials":[],"templateName":"application\/stubs\/PdfJsReader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PdfJsReader.html?fileHref=https%3A%2F%2Fwww.researchgate.net%2Fprofile%2FJulien_Cornebise%2Fpublication%2F277022910_Weight_Uncertainty_in_Neural_Networks%2Flinks%2F56ab3cb808aeadd1bdccd5b7.pdf%3FinViewer%3D1%26pdfJsDownload%3D1%26origin%3Dpublication_detail&assetId=AS%3A323176863600642%401454062776864&publicationUid=277022910&linkId=56ab3cb808aeadd1bdccd5b7&onlyShowFirstPage=0","viewClass":null,"yuiModules":["css-pow-application-PdfJsReader"],"stylesheets":["pow\/application\/PdfJsReader.css"],"_isYUI":true},"showHeader":true,"title":"Weight Uncertainty in Neural Networks","publicationType":"Article","downloadTrackUrl":"publicliterature.PublicationInlineReader.ajaxTrackDownload.html?msrp=5JvcFJegK1QzBl2tyVjizSEsVpEaCQQeSpYTxDXaTz22YDBL9eC4lVLq58TiNVIKCe7aEFTNNm59v1CgTNAVDxMlan4z03W0CTqG0WTmCy8.zyDSAtUx7wJ1OcX7K8rt5k6lVwZTxtJVmaWBWKM4lhYf1obCJOoHCT4709wenZ1NBNtbLSteVKA-WEeAjd5CrA.AMVgGN_DOssrmKDWZJl4tqH_cKkCaF_wARZeZemD93lGK3Ah1vPry4Brro9aZEIZ6m14jHMJskuOD4WWvYnN1A","publicationUid":277022910,"trackedDownloads":{"56ab3cb808aeadd1bdccd5b7":{"v":false,"d":false}},"inlinePdf":false,"publicationComments":null,"showDownloadButton":true,"socialShare":{"data":{"shareItems":[{"data":{"name":"Facebook","url":"http:\/\/www.facebook.com\/share.php?u={{url}}{{#title}}&t={{title}}{{\/title}}","width":600,"height":350,"useUtmTags":true,"utmSource":"facebook","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareFacebook.ajaxTrackSocialShare.html","widgetId":"rgw35_56aba0bb928c6"},"id":"rgw35_56aba0bb928c6","partials":{"shareIcon":"application\/stubs\/partials\/shareFacebookBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareFacebook.html?provider=Facebook&shareIcon=shareIconBlog&utmSource=facebook&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"Twitter","url":"http:\/\/twitter.com\/intent\/tweet?text={{#title}}{{title}}: {{\/title}}{{url}}&via=researchgate","width":600,"height":350,"useUtmTags":true,"utmSource":"twitter","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareTwitter.ajaxTrackSocialShare.html","widgetId":"rgw36_56aba0bb928c6"},"id":"rgw36_56aba0bb928c6","partials":{"shareIcon":"application\/stubs\/partials\/shareTwitterBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareTwitter.html?provider=Twitter&shareIcon=shareIconBlog&utmSource=twitter&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"Google+","url":"https:\/\/plus.google.com\/share?url={{url}}","width":600,"height":600,"useUtmTags":true,"utmSource":"googleplus","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareGooglePlus.ajaxTrackSocialShare.html","widgetId":"rgw37_56aba0bb928c6"},"id":"rgw37_56aba0bb928c6","partials":{"shareIcon":"application\/stubs\/partials\/shareGooglePlusBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareGooglePlus.html?provider=Google%2B&shareIcon=shareIconBlog&utmSource=googleplus&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"LinkedIn","url":"http:\/\/www.linkedin.com\/shareArticle?mini=true&url={{url}}{{#title}}&title={{title}}{{\/title}}&source=ResearchGate","width":520,"height":570,"useUtmTags":true,"utmSource":"linkedin","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareLinkedIn.ajaxTrackSocialShare.html","widgetId":"rgw38_56aba0bb928c6"},"id":"rgw38_56aba0bb928c6","partials":{"shareIcon":"application\/stubs\/partials\/shareLinkedInBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareLinkedIn.html?provider=LinkedIn&shareIcon=shareIconBlog&utmSource=linkedin&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"Reddit","url":"https:\/\/www.reddit.com\/submit?url={{url}}{{#title}}&title={{title}}{{\/title}}","width":600,"height":600,"useUtmTags":true,"utmSource":"reddit","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareReddit.ajaxTrackSocialShare.html","widgetId":"rgw39_56aba0bb928c6"},"id":"rgw39_56aba0bb928c6","partials":{"shareIcon":"application\/stubs\/partials\/shareRedditBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareReddit.html?provider=Reddit&shareIcon=shareIconBlog&utmSource=reddit&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true}],"widgetId":"rgw34_56aba0bb928c6"},"id":"rgw34_56aba0bb928c6","partials":[],"templateName":"application\/stubs\/SocialShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.SocialShare.html?campaign=shareFullTextPublication&trackClick=1&shareIcon=shareIconBlog","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw32_56aba0bb928c6"},"id":"rgw32_56aba0bb928c6","partials":[],"templateName":"publicliterature\/stubs\/PublicationInlineReader.html","templateExtensions":["generalHelpers"],"attrs":{"showFulltextDownloadedSignupDialog":true,"preSignUpDialogContext":null,"requestFulltext":false},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationInlineReader.html","viewClass":"views.publicliterature.PublicationInlineReaderView","yuiModules":["rg.views.publicliterature.PublicationInlineReaderView","css-pow-publicliterature-PublicationInlineReader"],"stylesheets":["pow\/publicliterature\/PublicationInlineReader.css"],"_isYUI":true},"useFulltextOptimizedLayout":false,"publicationActions":null,"requestFulltextPromo":null,"currentUrl":"publication\/277022910_Weight_Uncertainty_in_Neural_Networks","isLeaderboardAd":false,"enableStickyBox":null,"googleDfpSlotMobileBottom":null,"fullTextExitPopup":null,"showExitPopupDialog":false,"widgetId":"rgw2_56aba0bb928c6"},"id":"rgw2_56aba0bb928c6","partials":{"romeo_legal_notice":"publicliterature\/stubs\/partials\/romeo_legal_notice.html"},"templateName":"publicliterature\/stubs\/PublicPublicationDetails_NewLayout.html","templateExtensions":["generalHelpers"],"attrs":{"publicationUid":277022910},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicPublicationDetailsOld.html?publicationUid=277022910&isTestOldDesign=0","viewClass":"views.publicliterature.PublicPublicationDetailsOldView","yuiModules":["rg.views.publicliterature.PublicPublicationDetailsOldView"],"stylesheets":[],"_isYUI":true},"widgetId":"rgw1_56aba0bb928c6"},"id":"rgw1_56aba0bb928c6","partials":[],"templateName":"publicliterature\/stubs\/PublicPublicationDetails.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicPublicationDetails.html","viewClass":"views.publicliterature.PublicPublicationDetailsView","yuiModules":["rg.views.publicliterature.PublicPublicationDetailsView"],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"uaClass":"","headPrefix":[],"rootUrl":"https:\/\/www.researchgate.net\/","requestToken":"+ittulQqRoOZCZ6PLxndSKQiu+TIAQ72vB5I97Y+fUAJaYFOFFh\/rx6uITwRq5Sat044U91DIvKybIktPwehxCJYoBNNcWOmBxPNQWL3BA1ncCo6KqJ74a5G+Su\/LAShj6WCTAz8p+nF0pU+wkSeH905BXWsRB8uf0wP9KwHnjwEhwIJi3AmxyqtNEGYScUKal0\/wXWYQRk0qixBbqUT+FDhn4rI3f0KxZGUFk0jVQY0nBb2y6yIoYPlrBgxi4Z\/udkO3TPGE2gyhjhci9Sp6C51ECbcg3lSk\/2iaz36uEY=","faviconCdnUrl":"https:\/\/c5.rgstatic.net\/m\/2390829798215018\/images\/favicon.ico","headerOutput":"<noscript><\/noscript><link rel=\"canonical\" href=\"https:\/\/www.researchgate.net\/publication\/277022910_Weight_Uncertainty_in_Neural_Networks\" \/>\n<link rel=\"dns-prefetch\" href=\"\/\/c5.rgstatic.net\" \/>\n<link rel=\"dns-prefetch\" href=\"\/\/i1.rgstatic.net\" \/>\n<meta property=\"twitter:card\" content=\"summary\" \/>\n<meta property=\"twitter:site\" content=\"@ResearchGate\" \/>\n<meta property=\"og:title\" content=\"Weight Uncertainty in Neural Networks\" \/>\n<meta property=\"og:description\" content=\"We introduce a new, efficient, principled and backpropagation-compatible\nalgorithm for learning a probability distribution on the weights of a neural\nnetwork, called Bayes by Backprop. It...\" \/>\n<meta property=\"og:site_name\" content=\"ResearchGate\" \/>\n<meta property=\"og:image\" content=\"https:\/\/i1.rgstatic.net\/publication\/277022910_Weight_Uncertainty_in_Neural_Networks\/links\/56ab3cb808aeadd1bdccd5b7\/smallpreview.png\" \/>\n<meta property=\"og:url\" content=\"https:\/\/www.researchgate.net\/publication\/277022910_Weight_Uncertainty_in_Neural_Networks\" \/>\n<meta property=\"rg:id\" content=\"PB:277022910\" \/>\n<meta name=\"DC.identifier\" scheme=\"DCTERMS.URI\" content=\"http:\/\/dx.doi.org\/\" \/>\n<meta name=\"gs_meta_revision\" content=\"1.1\" \/>\n<meta name=\"citation_title\" content=\"Weight Uncertainty in Neural Networks\" \/>\n<meta name=\"citation_author\" content=\"Charles Blundell\" \/>\n<meta name=\"citation_author\" content=\"Julien Cornebise\" \/>\n<meta name=\"citation_author\" content=\"Koray Kavukcuoglu\" \/>\n<meta name=\"citation_author\" content=\"Daan Wierstra\" \/>\n<meta name=\"citation_publication_date\" content=\"2015\/05\/20\" \/>\n<meta name=\"citation_pdf_url\" content=\"https:\/\/www.researchgate.net\/profile\/Julien_Cornebise\/publication\/277022910_Weight_Uncertainty_in_Neural_Networks\/links\/56ab3cb808aeadd1bdccd5b7.pdf\" \/>\n<meta name=\"citation_abstract_html_url\" content=\"https:\/\/www.researchgate.net\/publication\/277022910_Weight_Uncertainty_in_Neural_Networks\" \/>\n<meta name=\"citation_fulltext_html_url\" content=\"https:\/\/www.researchgate.net\/publication\/277022910_Weight_Uncertainty_in_Neural_Networks\" \/>\n<meta name=\"viewport\" content=\"width=device-width,initial-scale=1\" \/>\n<link href=\"\/\/c5.rgstatic.net\/m\/22664197317151888\/styles\/rg.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/21004998181197492\/styles\/rg2.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<!--[if lt IE 9]><link href=\"\/\/c5.rgstatic.net\/m\/238176252723686\/styles\/ie.css\" type=\"text\/css\" rel=\"stylesheet\"\/><![endif]-->\n<link href=\"\/\/c5.rgstatic.net\/m\/217752362214895\/styles\/modules\/publicprofile.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/21993347442549\/styles\/pow\/publicliterature\/FollowPublicationPromo.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/282514599719602\/styles\/pow\/application\/PdfJsReader.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/23819663151220\/styles\/pow\/publicliterature\/PublicationInlineReader.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<script src=\"\/\/c5.rgstatic.net\/m\/2321000301012716\/javascript\/vendor\/webfontloader\/webfontloader.js\" type=\"text\/javascript\"><\/script>\n <script>(function(i,s,o,g,r,a,m){i[\"GoogleAnalyticsObject\"]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,\"script\",\"\/\/www.google-analytics.com\/analytics.js\",\"ga\");\n ga(\"create\",\"UA-58591210-1\");ga(\"set\",\"anonymizeIp\",true);ga('set', 'dimension1', 'publication full-text');ga('set', 'dimension2', 'Article');ga('set', 'dimension3', 'Logged out');ga('set', 'dimension4', 'https');ga(\"send\",\"pageview\");<\/script>\n","webfont":"<noscript><\/noscript><script> WebFontConfig = { custom: { families: ['source_sans_pro_italic', 'source_sans_pro_bold', 'source_sans_pro', 'martel'], urls : ['\/\/c5.rgstatic.net\/m\/231392577336386\/styles\/fonts.css'] } }; WebFont.load(WebFontConfig); <\/script>\n","correlationId":"rgreq-3127d4e9-8a61-4c1d-ae84-2dc6ecfd704b","accountId":null,"module":"publicliterature","action":"publicliterature.PublicPublicationDetails","page":"publicationDetail","product":"publications","backendTime":399,"continent":"Asia","stylesHome":"\/\/c5.rgstatic.net\/m\/","staticHost":"c5.rgstatic.net","useEarlyFlush":false,"longRunningRequestIdentifier":"LongRunningRequest.publicliterature.PublicPublicationDetails","longRunningRequestFp":"e9e5bbe1366c7ee8c8e41d02f793c884ac9be19b","widgetId":"rgw40_56aba0bb928c6"},"id":"rgw40_56aba0bb928c6","partials":[],"templateName":"application\/stubs\/StaticHeader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.StaticHeader.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){
            Y.rg.core.pagespeed.Monitoring.monitorPage("\/\/glassmoni.researchgate.net", "publicliterature.PublicPublicationDetails.run.html.loggedOut.get", "59de9668d07aeb77ab4de5f24d382b5d199d2437", "rgreq-3127d4e9-8a61-4c1d-ae84-2dc6ecfd704b", "7d000604152ddf61548b9ed59b41119b860df9bc");
        
            Y.rg.core.pagespeed.Monitoring.monitorPage("\/\/glassmoni.researchgate.net", "publicationDetail.loggedOut", "ed1993d9e20f6cefa83edacaa24401a18c071aea", "rgreq-3127d4e9-8a61-4c1d-ae84-2dc6ecfd704b", "7d000604152ddf61548b9ed59b41119b860df9bc");
        })();
(function(){Y.rg.createInitialWidget({"data":{"year":"2016","inlinePromo":null,"isAdmin":false,"contactUrl":"https:\/\/www.researchgate.net\/contact","aboutUsUrl":"https:\/\/www.researchgate.net\/about","widgetId":"rgw41_56aba0bb928c6"},"id":"rgw41_56aba0bb928c6","partials":[],"templateName":"application\/stubs\/DefaultFooter.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.DefaultFooter.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"headerLogin":{"data":{"urlAfterLogin":"publication\/277022910_Weight_Uncertainty_in_Neural_Networks","requestToken":"kSLeJzbi+8cnpp3gIwTWg3OnapVfxHOi3qmg0LLjsWmXq3yeYb\/\/t74U3a2ce7GdG61KdzaHrife\/NywKwKVIzrYobMdJYG0drshaPi3y\/dUKw2629IyLu19jn+30WBm\/+bQsDyuRwwObXSWMaqbxOS+5lW7stnDdnDx7N7T5WNb5ETOUDbQizekWStM3WgPE+jG24VmyqKlSAEaX4ts+HjX1oZqhzuZloaRqDbQd6Fte1WIphvFWHuN3IurX+xA\/cRC8hru8ehFcfhMmOdXzmfzc30IagVsjJU059Q9K4g=","loginUrl":"https:\/\/www.researchgate.net\/application.Login.html","signupUrl":"https:\/\/www.researchgate.net\/signup.SignUp.html?ev=su_chnl_index&hdrsu=1&_sg=9WxScfepB2FKQe2nYkQGkZqUTzB_dV8_eqdcYAfuh_DNSkVIML_K409sORvx84LM","encodedUrlAfterLogin":"cHVibGljYXRpb24vMjc3MDIyOTEwX1dlaWdodF9VbmNlcnRhaW50eV9pbl9OZXVyYWxfTmV0d29ya3M%3D","signupCallToAction":"Join for free","widgetId":"rgw43_56aba0bb928c6"},"id":"rgw43_56aba0bb928c6","partials":{"partial":"application\/stubs\/partials\/headerLoginDefault.html"},"templateName":"application\/stubs\/HeaderLogin.html","templateExtensions":[],"attrs":{"goal":"milestoneHeaderLoginSeen"},"widgetUrl":"https:\/\/www.researchgate.net\/application.HeaderLogin.html","viewClass":"views.application.HeaderLoginView","yuiModules":["rg.views.application.HeaderLoginView"],"stylesheets":[],"_isYUI":true},"cookieConsent":null,"logoSvgSrc":"https:\/\/c5.rgstatic.net\/m\/235107188705592\/images\/template\/brand-header-logo.svg","logoFallbackSrc":"https:\/\/c5.rgstatic.net\/m\/238113351022438\/images\/template\/brand-header-logo.png","widgetId":"rgw42_56aba0bb928c6"},"id":"rgw42_56aba0bb928c6","partials":{"schemaSocialProfiles":"application\/stubs\/partials\/schemaSocialProfiles.html"},"templateName":"application\/stubs\/HeaderLoggedOut.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.HeaderLoggedOut.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"logEvent":"su_banner","specialCopy":false,"widgetId":"rgw44_56aba0bb928c6"},"id":"rgw44_56aba0bb928c6","partials":[],"templateName":"application\/stubs\/LoggedOutBanner.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.LoggedOutBanner.html","viewClass":"views.application.LoggedOutBannerView","yuiModules":["rg.views.application.LoggedOutBannerView"],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.core.util.ParameterFilter.filter(["ev","cp","ch","ref","dbw","pli","loginT","uid","claimChannel","enrichId","enrichSource","utm_source","utm_medium","utm_campaign","el","ci"]);})();
});}); } else { throw 'YRG was not loaded when attaching widgets'; }</script><script> dataLayer = [{"pageCategory":"publication full-text","publicationType":"Article","eventCategory":"Publication page"}]; </script> <noscript><iframe src="//www.googletagmanager.com/ns.html?id=GTM-MKVKH7" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-MKVKH7');</script><script>(function(e){function n(n,t,o,a){"use strict";var i=e.document.createElement("link"),r=t||e.document.getElementsByTagName("script")[0],d=e.document.styleSheets;return i.rel="stylesheet",i.href=n,i.media="only x",a&&(i.onload=a),r.parentNode.insertBefore(i,r),i.onloadcssdefined=function(e){for(var t,o=0;d.length>o;o++)d[o].href&&d[o].href.indexOf(n)>-1&&(t=!0);t?e():setTimeout(function(){i.onloadcssdefined(e)})},i.onloadcssdefined(function(){i.media=o||"all"}),i}function t(e,n){e.onload=function(){e.onload=null,n&&n.call(e)},"isApplicationInstalled"in navigator&&"onloadcssdefined"in e&&e.onloadcssdefined(n)}var o=function(a,i){"use strict";if(a&&3===a.length){var r=e.Image,d=!(!document.createElementNS||!document.createElementNS("http://www.w3.org/2000/svg","svg").createSVGRect||!document.implementation.hasFeature("http://www.w3.org/TR/SVG11/feature#Image","1.1")||e.opera&&-1===navigator.userAgent.indexOf("Chrome")||-1!==navigator.userAgent.indexOf("Series40")),c=new r;c.onerror=function(){o.method="png",o.href=a[2],n(a[2])},c.onload=function(){var e=1===c.width&&1===c.height,r=a[e&&d?0:e?1:2];o.method=e&&d?"svg":e?"datapng":"png",o.href=r,t(n(r),i)},c.src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///ywAAAAAAQABAAACAUwAOw==",document.documentElement.className+=" grunticon"}};o.loadCSS=n,o.onloadCSS=t,e.grunticon=o})(this);grunticon(["https://c5.rgstatic.net/c/o1q2er/styles/icons/_header-ico.svg.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_header-ico.png.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_header-ico.fallback.scss"]);grunticon(["https://c5.rgstatic.net/c/o1q2er/styles/icons/_admin-ico.svg.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_admin-ico.png.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_admin-ico.fallback.scss"]);grunticon(["https://c5.rgstatic.net/c/o1q2er/styles/icons/_ico.svg.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_ico.png.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_ico.fallback.scss"]);</script></body>
</html>
