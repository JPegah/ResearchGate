<!DOCTYPE html> <html lang="en" class="" id="rgw30_56ab9fbcdfce3"> <head > <meta charset="utf-8"/> <meta http-equiv="content-type" content="text/html; charset=UTF-8"/> <meta name="Rg-Request-Token" id="Rg-Request-Token" content="fWkduFcsVRqSX8O0L21a3Sfw0zutc9XwdU6oy1rZwMObNDpWyz35jOXKNbH9hkw/brV6TYISQyyaVEXVk3iJa8huLqfvcozMnolkfzlsT1rouGo/J34E7Iq/rqv9bgBKCfPYMUWtYHn2fXbg5tPQ1VXimI91NNi66iqRf10ScxQc6rDKv37XT5vp5vITC55/eguktBUMngUO+LbUL7mnquTui9H5ufn47Jn7wJj7a83y+P3t0KGBMmAhNn4eWVtNxVP6tB+Q9Bo4xJtrts2x11ptmrg7jwgmu2kL7V41mm0="/> <meta http-equiv="expires" content="0"/> <link rel="apple-touch-icon" sizes="57x57" href="https://www.researchgate.net/apple-touch-icon-57x57.png"> <link rel="apple-touch-icon" sizes="60x60" href="https://www.researchgate.net/apple-touch-icon-60x60.png"> <link rel="apple-touch-icon" sizes="72x72" href="https://www.researchgate.net/apple-touch-icon-72x72.png"> <link rel="apple-touch-icon" sizes="76x76" href="https://www.researchgate.net/apple-touch-icon-76x76.png"> <link rel="apple-touch-icon" sizes="114x114" href="https://www.researchgate.net/apple-touch-icon-114x114.png"> <link rel="apple-touch-icon" sizes="120x120" href="https://www.researchgate.net/apple-touch-icon-120x120.png"> <link rel="apple-touch-icon" sizes="144x144" href="https://www.researchgate.net/apple-touch-icon-144x144.png"> <link rel="apple-touch-icon" sizes="152x152" href="https://www.researchgate.net/apple-touch-icon-152x152.png"> <link rel="apple-touch-icon" sizes="180x180" href="https://www.researchgate.net/apple-touch-icon-180x180.png"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-32x32.png" sizes="32x32"> <link rel="icon" type="image/png" href="https://www.researchgate.net/android-chrome-192x192.png" sizes="192x192"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-96x96.png" sizes="96x96"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-16x16.png" sizes="16x16"> <link rel="shortcut icon" type="image/x-icon" href="https://c5.rgstatic.net/m/2390829798215018/images/favicon.ico"/> <link rel="manifest" href="https://www.researchgate.net/manifest.json"> <meta name="msapplication-TileColor" content="#da532c"> <meta name="msapplication-TileImage" content="https://www.researchgate.net/mstile-144x144.png"> <meta name="theme-color" content="#444444"> <link rel="search" type="application/opensearchdescription+xml" title="ResearchGate search" href="https://www.researchgate.net/application.DownloadOpenSearchPlugin.html"/> <link rel="meta" type="application/rdf+xml" title="ICRA labels" href="https://www.researchgate.net/application.DownloadLabels.html"/> <link rel="http://oexchange.org/spec/0.8/rel/related-target" type="application/xrd+xml" href="https://www.researchgate.net/application.DownloadOExchange.html"/> <base href="https://www.researchgate.net/"/> <script>
    var rgConfig = {
        correlationId: "rgreq-8ca8b9fb-ad6a-4db4-b63e-46e2ab5fca3b",
        accountId: "",
        module: "publicliterature",
        action: "publicliterature.PublicPublicationDetails",
        page: "publicationDetail",
        product: "publications",
        continent: "Asia",
        stylesHome: "//c5.rgstatic.net/m/",
        staticHost: "c5.rgstatic.net",
        longRunningRequestIdentifier: "LongRunningRequest.publicliterature.PublicPublicationDetails",
        longRunningRequestFp: "e9e5bbe1366c7ee8c8e41d02f793c884ac9be19b"
    };
    window.rootUrl = "https://www.researchgate.net/";
</script> <link rel="canonical" href="https://www.researchgate.net/publication/41781406_A_Unifying_View_of_Sparse_Approximate_Gaussian_Process_Regression" />
<link rel="dns-prefetch" href="//c5.rgstatic.net" />
<link rel="dns-prefetch" href="//i1.rgstatic.net" />
<meta property="twitter:card" content="summary" />
<meta property="twitter:site" content="@ResearchGate" />
<meta property="og:title" content="A Unifying View of Sparse Approximate Gaussian Process Regression" />
<meta property="og:description" content="We provide a new unifying view, including all existing proper probabilistic sparse approximations for Gaussian process regression. Our approach relies on expressing the effective prior which the..." />
<meta property="og:site_name" content="ResearchGate" />
<meta property="og:image" content="https://i1.rgstatic.net/publication/41781406_A_Unifying_View_of_Sparse_Approximate_Gaussian_Process_Regression/links/0f316af33829de2215f5a674/smallpreview.png" />
<meta property="og:url" content="https://www.researchgate.net/publication/41781406_A_Unifying_View_of_Sparse_Approximate_Gaussian_Process_Regression" />
<meta property="rg:id" content="PB:41781406" />
<meta name="DC.identifier" scheme="DCTERMS.URI" content="http://dx.doi.org/" />
<meta name="gs_meta_revision" content="1.1" />
<meta name="citation_title" content="A Unifying View of Sparse Approximate Gaussian Process Regression" />
<meta name="citation_author" content="JQ Quinonero-Candela" />
<meta name="citation_author" content="C.E. Rasmussen" />
<meta name="citation_publication_date" content="2005/12/01" />
<meta name="citation_journal_title" content="Journal of Machine Learning Research" />
<meta name="citation_issn" content="1533-7928" />
<meta name="citation_volume" content="6" />
<meta name="citation_abstract_html_url" content="https://www.researchgate.net/publication/41781406_A_Unifying_View_of_Sparse_Approximate_Gaussian_Process_Regression" />
<meta name="citation_fulltext_html_url" content="https://www.researchgate.net/publication/41781406_A_Unifying_View_of_Sparse_Approximate_Gaussian_Process_Regression" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<link href="//c5.rgstatic.net/m/22664197317151888/styles/rg.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/21004998181197492/styles/rg2.css" type="text/css" rel="stylesheet"/>
<!--[if lt IE 9]><link href="//c5.rgstatic.net/m/238176252723686/styles/ie.css" type="text/css" rel="stylesheet"/><![endif]-->
<link href="//c5.rgstatic.net/m/217752362214895/styles/modules/publicprofile.css" type="text/css" rel="stylesheet"/>
<script src="//c5.rgstatic.net/m/2321000301012716/javascript/vendor/webfontloader/webfontloader.js" type="text/javascript"></script>
 <script>(function(i,s,o,g,r,a,m){i["GoogleAnalyticsObject"]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,"script","//www.google-analytics.com/analytics.js","ga");
 ga("create","UA-58591210-1");ga("set","anonymizeIp",true);ga('set', 'dimension1', 'publication slurped');ga('set', 'dimension2', 'Article');ga('set', 'dimension3', 'Logged out');ga('set', 'dimension4', 'https');ga("send","pageview");</script>
  <script> WebFontConfig = { custom: { families: ['source_sans_pro_italic', 'source_sans_pro_bold', 'source_sans_pro', 'martel'], urls : ['//c5.rgstatic.net/m/231392577336386/styles/fonts.css'] } }; WebFont.load(WebFontConfig); </script><noscript></noscript>

<title>A Unifying View of Sparse Approximate Gaussian Process Regression</title>
<meta name="description" content="A Unifying View of Sparse Approximate Gaussian Process Regression on ResearchGate, the professional network for scientists."/>
<meta name="keywords" content="scientific network, scientific platform, scientific community, research partner, research collaboration, journal articles, international collaboration, find researcher, lifescience researcher, interdisciplinary research, research collaboration"/>
</head>
<body class="use-svg-icons logged-out">
<div id="page-container">
<script type="text/javascript">var googletag = googletag || {}; googletag.cmd = googletag.cmd || [];
(function() { var gads = document.createElement("script"); gads.async = true; gads.type = "text/javascript"; var useSSL = "https:" == document.location.protocol; gads.src = (useSSL ? "https:" : "http:") + "//www.googletagservices.com/tag/js/gpt.js"; var node =document.getElementsByTagName("script")[0]; node.parentNode.insertBefore(gads, node); })();</script><div id="main" class="logged-out-header-support">
<div id="content" class="">

<noscript>
<div class="c-box-warning full-width-element" style="text-align: center; ">
    <div style="margin: auto; padding:10px;" class="container">
        <b>For full functionality of ResearchGate it is necessary to enable JavaScript.
            Here are the <a href="http://www.enable-javascript.com/" rel="nofollow" target="_blank">
                instructions how to enable JavaScript in your web browser</a>.</b>
    </div>
</div>
</noscript>

<div id="rgw1_56ab9fbcdfce3" itemscope itemtype="http://schema.org/ScholarlyArticle"><div class="publication-wrapper publication-wrapper-onecol" id="rgw2_56ab9fbcdfce3" itemscope itemtype="http://schema.org/ScholarlyArticle"> <div class="c-col-content"> <div class="c-content"> <div class="clearfix">  <div class="publication-header"> <div id="rgw8_56ab9fbcdfce3">  <div class="type-label"> Article   </div> <span class="Z3988" title="ctx_ver=Z39.88-2004&rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&rfr_id=info%3Asid%2Fresearchgate.net%3Aresearchgate&rft.atitle=A%20Unifying%20View%20of%20Sparse%20Approximate%20Gaussian%20Process%20Regression&rft.title=Journal%20of%20Machine%20Learning%20Research%2C%20v.6%2C%201935-1959%20(2005)&rft.jtitle=Journal%20of%20Machine%20Learning%20Research%2C%20v.6%2C%201935-1959%20(2005)&rft.volume=6&rft.date=2005&rft.issn=1533-7928&rft.au=JQ%20Quinonero-Candela%2CC.E.%20Rasmussen&rft.genre=article"></span> <h1 class="pub-title" itemprop="name">A Unifying View of Sparse Approximate Gaussian Process Regression</h1> <meta itemprop="headline" content="A Unifying View of Sparse Approximate Gaussian Process Regression">  <meta itemprop="image" content="https://i1.rgstatic.net/publication/41781406_A_Unifying_View_of_Sparse_Approximate_Gaussian_Process_Regression/links/0f316af33829de2215f5a674/smallpreview.png">  <div id="rgw11_56ab9fbcdfce3" class="publication-detail-author-list"> <div> <ul class="clearfix js-people-list">  <li id="rgw12_56ab9fbcdfce3"> <a href="researcher/46151520_JQ_Quinonero-Candela" class="pub-detail-item author-item" itemprop="author" itemscope itemtype="http://schema.org/Person"> <div class="indent-left"> <div class="people-img">  <img src="https://c5.rgstatic.net/m/2951093203564/images/template/default/profile/profile_default_s.jpg" title="JQ Quinonero-Candela" alt="JQ Quinonero-Candela" height="20px" width="20px" style="height: 20px;"/>  </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">JQ Quinonero-Candela</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item   not-claimed " id="rgw13_56ab9fbcdfce3">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="researcher/46151520_JQ_Quinonero-Candela"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="JQ Quinonero-Candela" alt="JQ Quinonero-Candela" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">       </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="researcher/46151520_JQ_Quinonero-Candela" class="display-name">JQ Quinonero-Candela</a>    </h5> <div class="truncate-single-line meta">   </div>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>  <li id="rgw14_56ab9fbcdfce3"> <a href="researcher/43277170_CE_Rasmussen" class="pub-detail-item author-item" itemprop="author" itemscope itemtype="http://schema.org/Person"> <div class="indent-left"> <div class="people-img">  <img src="https://c5.rgstatic.net/m/2951093203564/images/template/default/profile/profile_default_s.jpg" title="C.E. Rasmussen" alt="C.E. Rasmussen" height="20px" width="20px" style="height: 20px;"/>  </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">C.E. Rasmussen</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item   not-claimed " id="rgw15_56ab9fbcdfce3">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="researcher/43277170_CE_Rasmussen"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="C.E. Rasmussen" alt="C.E. Rasmussen" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">       </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="researcher/43277170_CE_Rasmussen" class="display-name">C.E. Rasmussen</a>    </h5> <div class="truncate-single-line meta">   </div>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>   </ul> <div class="js-loading"></div>  </div> </div> <div class="pub-details js-pub-details">      <span itemprop="isPartOf" itemscope itemtype="http://schema.org/Periodical"> <a itemprop="sameAs" href="journal/1533-7928_Journal_of_Machine_Learning_Research"><span itemprop="name">Journal of Machine Learning Research</span></a> </span>    (Impact Factor: 2.47).     <meta itemprop="datePublished" content="2005-12">  12/2005;  6.             <div class="pub-source"> Source: <a href="http://edoc.mpg.de/270092" rel="nofollow">OAI</a> </div>  </div> <div id="rgw16_56ab9fbcdfce3" class="pub-abstract">  <div class="clearfix">   <div style="max-height: 54px;" class="js-expander-container js-expander-collapsed">  <p itemprop="description"> <strong>ABSTRACT</strong> <div>We provide a new unifying view, including all existing proper probabilistic sparse approximations for Gaussian process regression. Our approach relies on expressing the effective prior which the methods are using. This allows new insights to be gained, and highlights the relationship between existing methods. It also allows for a clear theoretically justified ranking of the closeness of the known approximations to the corresponding full GPs. Finally we point directly to designs of new better sparse approximations, combining the best of the existing strategies, within attractive computational constraints.</div> </p>  </div>  </div>   </div>      <div class="action-container">   <div class="clear"></div> <div class="share-dialog-container" style="display: none;">  </div> </div> </div> <div style="margin-left: -20px; margin-right: -20px;">  </div> </div>  <div class="publication-detail-dfp-container rf"> <div id="rgw29_56ab9fbcdfce3">  </div> </div>  </div>  <div class="clearfix">  <noscript> <div id="rgw28_56ab9fbcdfce3"  itemprop="articleBody">  <p>Page 1</p> <p>Journal of Machine Learning Research 6 (2005) 1939–1959Submitted 10/05; Published 12/05<br />A Unifying View of Sparse<br />Approximate Gaussian Process Regression<br />Joaquin Qui˜ nonero-Candela<br />Carl Edward Rasmussen<br />Max Planck Institute for Biological Cybernetics<br />Spemannstraße 38<br />72076 T¨ ubingen, Germany<br />JQC@TUEBINGEN.MPG.DE<br />CARL@TUEBINGEN.MPG.DE<br />Editor: Ralf Herbrich<br />Abstract<br />We provide a new unifying view, including all existing proper probabilistic sparse approximations<br />for Gaussian process regression. Our approach relies on expressing the effective prior which the<br />methods are using. This allows new insights to be gained, and highlights the relationship between<br />existing methods. It also allows for a clear theoretically justified ranking of the closeness of the<br />known approximations to the corresponding full GPs. Finally we point directly to designs of new<br />better sparse approximations, combining the best of the existing strategies, within attractive com-<br />putational constraints.<br />Keywords: Gaussian process, probabilistic regression, sparse approximation, Bayesian committee<br />machine<br />Regression models based on Gaussian processes (GPs) are simple to implement, flexible, fully<br />probabilistic models, and thus a powerful tool in many areas of application. Their main limitation<br />is that memory requirements and computational demands grow as the square and cube respectively,<br />of the number of training cases n, effectively limiting a direct implementation to problems with<br />at most a few thousand cases. To overcome the computational limitations numerous authors have<br />recently suggested a wealth of sparse approximations. Common to all these approximation schemes<br />is that only a subset of the latent variables are treated exactly, and the remaining variables are given<br />some approximate, but computationally cheaper treatment. However, the published algorithms have<br />widely different motivations, emphasis and exposition, so it is difficult to get an overview (see<br />Rasmussen and Williams, 2006, chapter 8) of how they relate to each other, and which can be<br />expected to give rise to the best algorithms.<br />In this paper we provide a unifying view of sparse approximations for GP regression. Our<br />approach is simple, but powerful: for each algorithm we analyze the posterior, and compute the<br />effective prior which it is using. Thus, we reinterpret the algorithms as “exact inference with an<br />approximated prior”, rather than the existing (ubiquitous) interpretation “approximate inference<br />with the exact prior”. This approach has the advantage of directly expressing the approximations in<br />terms of prior assumptions about the function, which makes the consequences of the approximations<br />much easier to understand. While our view of the approximations is not the only one possible, it has<br />the advantage of putting all existing probabilistic sparse approximations under one umbrella, thus<br />enabling direct comparison and revealing the relation between them.<br />In Section 1 we briefly introduce GP models for regression. In Section 2 we present our uni-<br />fying framework and write out the key equations in preparation for the unifying analysis of sparse<br />c ?2005 Joaquin Qui˜ nonero-Candela and Carl Edward Rasmussen.</p>  <p>Page 2</p> <p>QUI˜ NONERO-CANDELA AND RASMUSSEN<br />algorithms in Sections 4-7. The relation of transduction and augmentation to our sparse framework<br />is covered in Section 8. All our approximations are written in terms of a new set of inducing vari-<br />ables. The choice of these variables is itself a challenging problem, and is discussed in Section<br />9. We comment on a few special approximations outside our general scheme in Section 10 and<br />conclusions are drawn at the end.<br />1. Gaussian Processes for Regression<br />Probabilistic regression is usually formulated as follows: given a training set D = {(xi,yi),i =<br />1,...,n} of n pairs of (vectorial) inputs xiand noisy (real, scalar) outputs yi, compute the predictive<br />distribution of the function values f∗(or noisy y∗) at test locations x∗. In the simplest case (which<br />we deal with here) we assume that the noise is additive, independent and Gaussian, such that the<br />relationship between the (latent) function f(x) and the observed noisy targets y are given by<br />yi = f(xi)+εi,<br />where<br />εi ∼ N (0, σ2<br />noise) ,<br />(1)<br />where σ2<br />noiseis the variance of the noise.<br />Definition 1 A Gaussian process (GP) is a collection of random variables, any finite number of<br />which have consistent1joint Gaussian distributions.<br />Gaussian process (GP) regression is a Bayesian approach which assumes a GP prior2over functions,<br />i.e. assumes a priori that function values behave according to<br />p(f|x1,x2,...,xn) = N (0, K) ,<br />(2)<br />where f = [f1, f2,..., fn]?is a vector of latent function values, fi= f(xi) and K is a covariance ma-<br />trix, whose entries are given by the covariance function, Kij= k(xi,xj). Note that the GP treats the<br />latent function values fias random variables, indexed by the corresponding input. In the following,<br />for simplicity we will always neglect the explicit conditioning on the inputs; the GP model and all<br />expressions are always conditional on the corresponding inputs. The GP model is concerned only<br />with the conditional of the outputs given the inputs; we do not model anything about the inputs<br />themselves.<br />Remark 2 Note, that to adhere to a strict Bayesian formalism, the GP covariance function,3which<br />defines the prior, should not depend on the data (although it can depend on additional parameters).<br />As we will see in later sections, some approximations are strictly equivalent to GPs, while others<br />are not. That is, the implied prior may still be multivariate Gaussian, but the covariance function<br />may be different for training and test cases.<br />Definition 3 AGaussianprocessiscalled degenerateiffthecovariancefunctionhasafinitenumber<br />of non-zero eigenvalues.<br />1. By consistency is meant simply that the random variables obey the usual rules of marginalization, etc.<br />2. For notational simplicity we exclusively use zero-mean priors.<br />3. The covariance function itself shouldn’t depend on the data, though its value at a specific pair of inputs of course will.<br />1940</p>  <p>Page 3</p> <p>SPARSE APPROXIMATE GAUSSIAN PROCESS REGRESSION<br />Degenerate GPs (such as e.g. with polynomial covariance function) correspond to finite linear<br />(-in-the-parameters) models, whereas non-degenerate GPs (such as e.g. with squared exponential<br />or RBF covariance function) do not. The prior for a finite m dimensional linear model only consid-<br />ers a universe of at most m linearly independent functions; this may often be too restrictive when<br />n ? m. Note however, that non-degeneracy on its own doesn’t guarantee the existence of the “right<br />kind” of flexibility for a given particular modelling task. For a more detailed background on GP<br />models, see for example that of Rasmussen and Williams (2006).<br />Inference in the GP model is simple: we put a joint GP prior on training and test latent values, f<br />and f∗4, and combine it with the likelihood5p(y|f) using Bayes rule, to obtain the joint posterior<br />p(f,f∗)p(y|f)<br />p(f,f∗|y) =<br />p(y)<br />.<br />(3)<br />The final step needed to produce the desired posterior predictive distribution is to marginalize out<br />the unwanted training set latent variables:<br />p(f∗|y) =<br />Z<br />p(f,f∗|y)df =<br />1<br />p(y)<br />Z<br />p(y|f)p(f,f∗)df ,<br />(4)<br />or in words: the predictive distribution is the marginal of the renormalized joint prior times the<br />likelihood. The joint GP prior and the independent likelihood are both Gaussian<br />p(f,f∗) = N<br />?<br />0,<br />?Kf,f<br />K∗,f<br />K∗,∗<br />Kf,∗<br />??<br />,<br />and<br />p(y|f) = N (f, σ2<br />noiseI) ,<br />(5)<br />where K is subscript by the variables between which the covariance is computed (and we use the<br />asterisk ∗ as shorthand for f∗) and I is the identity matrix. Since both factors in the integral are<br />Gaussian, the integral can be evaluated in closed form to give the Gaussian predictive distribution<br />p(f∗|y) = N?K∗,f(Kf,f+σ2<br />see the relevant Gaussian identity in appendix A. The problem with the above expression is that it<br />requires inversion of a matrix of size n×n which requires O(n3) operations, where n is the number<br />of training cases. Thus, the simple exact implementation can handle problems with at most a few<br />thousand training cases.<br />noiseI)−1y, K∗,∗−K∗,f(Kf,f+σ2<br />noiseI)−1Kf,∗<br />?,<br />(6)<br />2. A New Unifying View<br />We now seek to modify the joint prior p(f∗,f) from (5) in ways which will reduce the computational<br />requirements from (6). Let us first rewrite that prior by introducing an additional set of m latent<br />variables u = [u1,...,um]?, which we call the inducing variables. These latent variables are values<br />of the Gaussian process (as also f and f∗), corresponding to a set of input locations Xu, which we<br />call the inducing inputs. Whereas the additional latent variables u are always marginalized out in<br />the predictive distribution, the choice of inducing inputs does leave an imprint on the final solution.<br />4. We will mostly consider a vector of test cases f∗(rather than a single f∗).<br />5. You may have been expecting the likelihood written as p(y|f∗,f) but since the likelihood is conditionally independent<br />of everything else given f, this makes no difference.<br />1941</p>  <p>Page 4</p> <p>QUI˜ NONERO-CANDELA AND RASMUSSEN<br />The inducing variables will turn out to be generalizations of variables which other authors have re-<br />ferred to variously as “support points”, “active set” or “pseudo-inputs”. Particular sparse algorithms<br />choose the inducing variables in various different ways; some algorithms chose the inducing inputs<br />to be a subset of the training set, others not, as we will discuss in Section 9. For now consider any<br />arbitrary inducing variables.<br />Due to the consistency of Gaussian processes, we know that we can recover p(f∗,f) by simply<br />integrating (marginalizing) out u from the joint GP prior p(f∗,f,u)<br />p(f∗,f) =<br />Z<br />p(f∗,f,u)du =<br />Z<br />p(f∗,f|u)p(u)du,<br />where<br />p(u) = N (0, Ku,u) .<br />(7)<br />This is an exact expression. Now, we introduce the fundamental approximation which gives rise<br />to almost all sparse approximations. We approximate the joint prior by assuming that f∗and f are<br />conditionally independent given u, see Figure 1, such that<br />p(f∗,f) ? q(f∗,f) =<br />Z<br />q(f∗|u)q(f|u)p(u)du .<br />(8)<br />The name inducing variable is motivated by the fact that f and f∗can only communicate though<br />u, and u therefore induces the dependencies between training and test cases. As we shall detail in<br />the following sections, the different computationally efficient algorithms proposed in the literature<br />correspond to different additional assumptions about the two approximate inducing conditionals<br />q(f|u), q(f∗|u) of the integral in (8). It will be useful for future reference to specify here the exact<br />expressions for the two conditionals<br />training conditional:<br />p(f|u) = N (Kf,uK−1<br />p(f∗|u) =N (K∗,uK−1<br />u,uu, Kf,f−Qf,f) ,<br />u,uu, K∗,∗−Q∗,∗) ,<br />(9a)<br />test conditional: (9b)<br />where we have introduced the shorthand notation6Qa,b? Ka,uK−1<br />expressions in (9) as special (noise free) cases of the standard predictive equation (6) with u playing<br />the role of (noise free) observations. Note that the (positive semi-definite) covariance matrices in (9)<br />have the form K−Q with the following interpretation: the prior covariance K minus a (non-negative<br />definite) matrixQ quantifyinghow much informationu provides about thevariables in question(for<br />f∗). We emphasize that all the sparse methods discussed in the paper correspond simply to different<br />approximations to the conditionals in (9), and throughout we use the exact likelihood and inducing<br />prior<br />p(y|f) = N (f, σ2<br />u,uKu,b. We can readily identify the<br />noiseI) ,<br />and<br />p(u) =N (0, Ku,u) .<br />(10)<br />3. The Subset of Data (SoD) Approximation<br />Before we get started with the more sophisticated approximations, we mention as a baseline method<br />the simplest possible sparse approximation (which doesn’t fall inside our general scheme): use<br />only a subset of the data (SoD). The computational complexity is reduced to O(m3), where m &lt; n.<br />We would not generally expect SoD to be a competitive method, since it would seem impossible<br />(even with fairly redundant data and a good choice of the subset) to get a realistic picture of the<br />6. Note, that Qa,bdepends on u although this is not explicit in the notation.<br />1942</p>  <p>Page 5</p> <p>SPARSE APPROXIMATE GAUSSIAN PROCESS REGRESSION<br />?<br />?<br />?<br />?<br />??<br />?<br />?<br />?<br />?<br />??<br />A<br />A<br />A<br />A<br />AA<br />Q<br />Q<br />Q<br />Q<br />Q<br />Q<br />Q<br />Q<br />Q<br />u<br />f1<br />f2<br />r r r<br />fn<br />f∗<br />rr<br />?<br />?<br />?<br />?<br />??<br />?<br />?<br />?<br />?<br />??<br />A<br />A<br />A<br />A<br />AA<br />Q<br />Q<br />Q<br />Q<br />Q<br />Q<br />Q<br />Q<br />Q<br />u<br />f1<br />f2<br />r r r<br />fn<br />f∗<br />rr<br />Figure 1: Graphical model of the relation between the inducing variables u, the training latent func-<br />tions values f = [f1,..., fn]?and the test function value f∗. The thick horizontal line rep-<br />resents a set of fully connected nodes. The observations y1,...,yn,y∗(not shown) would<br />dangle individually from the corresponding latent values, by way of the exact (factored)<br />likelihood (5). Left graph: the fully connected graph corresponds to the case where<br />no approximation is made to the full joint Gaussian process distribution between these<br />variables. The inducing variables u are superfluous in this case, since all latent func-<br />tion values can communicate with all others. Right graph: assumption of conditional<br />independence between training and test function values given u. This gives rise to the<br />separation between training and test conditionals from (8). Notice that having cut the<br />communication path between training and test latent function values, information from f<br />can only be transmitted to f∗via the inducing variables u.<br />uncertainties, when only a part of the training data is even considered. We include it here mostly as<br />a baseline against which to compare better sparse approximations.<br />In Figure 5 top, left we see how the SoD method produces wide predictive distributions, when<br />training on a randomly selected subset of 10 cases. A fair comparison to other methods would<br />take into account that the computational complexity is independent of n as opposed to other more<br />advanced methods. These extra computational resources could be spent in a number of ways,<br />e.g. larger m, or an active (rather than random) selection of the m points. In this paper we will<br />concentrate on understanding the theoretical foundations of the various approximations rather than<br />investigating the necessary heuristics needed to turn the approximation schemes into actually prac-<br />tical algorithms.<br />4. The Subset of Regressors (SoR) Approximation<br />The Subset of Regressors (SoR) algorithm was given by Silverman (1985), and mentioned again by<br />Wahba et al. (1999). It was then adapted by Smola and Bartlett (2001) to propose a sparse greedy<br />approximation to Gaussian process regression. SoR models are finite linear-in-the-parameters mod-<br />els with a particular prior on the weights. For any input x∗, the corresponding function value f∗is<br />given by:<br />f∗ = K∗,uwu,<br />with<br />p(wu) = N (0, K−1<br />u,u) ,<br />(11)<br />where there is one weight associated to each inducing input in Xu. Note that the covariance matrix<br />for the prior on the weights is the inverse of that on u, such that we recover the exact GP prior on u,<br />1943</p>  <p>Page 6</p> <p>QUI˜ NONERO-CANDELA AND RASMUSSEN<br />which is Gaussian with zero mean and covariance<br />u = Ku,uwu ⇒ ?uu?? = Ku,u?wuw?<br />u?Ku,u = Ku,u.<br />u,uu we can redefine the SoR model in an<br />(12)<br />Using the effective prior on u and the fact that wu= K−1<br />equivalent, more intuitive way:<br />f∗ = K∗,uK−1<br />u,uu ,<br />with<br />u ∼ N (0, Ku,u) .<br />(13)<br />We are now ready to integrate the SoR model in our unifying framework. Given that there is a<br />deterministic relation between any f∗and u, the approximate conditional distributions in the integral<br />in eq. (8) are given by:<br />qSoR(f|u) = N (Kf,uK−1<br />with zero conditional covariance, compare to (9). The effective prior implied by the SoR approxi-<br />mation is easily obtained from (8), giving<br />u,uu, 0) ,<br />and<br />qSoR(f∗|u) = N (K∗,uK−1<br />u,uu, 0) ,<br />(14)<br />qSoR(f,f∗) = N<br />?<br />0,<br />?Qf,f<br />Qf,∗<br />Q∗,∗<br />Q∗,f<br />??<br />,<br />(15)<br />where we recall Qa,b? Ka,uK−1<br />Deterministic Inducing Conditional (DIC) approximation. We see that this approximate prior is<br />degenerate. There are only m degrees of freedom in the model, which implies that only m linearly<br />independent functions can be drawn from the prior. The m+1-th one is a linear combination of the<br />previous. For example, in a very low noise regime, the posterior could be severely constrained by<br />only m training cases.<br />The degeneracy of the prior causes unreasonable predictive distributions. Indeed, the approx-<br />imate prior over functions is so restrictive, that given enough data only a very limited family of<br />functions will be plausible under the posterior, leading to overconfident predictive variances. This<br />is a general problem of finite linear models with small numbers of weights (for more details see<br />Rasmussen and Qui˜ nonero-Candela, 2005). Figure 5, top, right panel, illustrates the unreasonable<br />predictive uncertainties of the SoR approximation on a toy dataset.7<br />The predictive distribution is obtained by using the SoR approximate prior (15) instead of the<br />true prior in (4). For each algorithm we give two forms of the predictive distribution, one which is<br />easy to interpret, and the other which is economical to compute with:<br />u,uKu,b. A more descriptive name for this method, would be the<br />qSoR(f∗|y) = N?Q∗,f(Qf,f+σ2<br />= N?σ−2K∗,uΣKu,fy, K∗,uΣKu,∗<br />where we have defined Σ = (σ−2Ku,fKf,u+Ku,u)−1. Equation (16a) is readily recognized as the<br />regular prediction equation (6), except that the covariance K has everywhere been replaced by Q,<br />which was already suggested by (15). This corresponds to replacing the covariance function k with<br />kSoR(xi,xj)=k(xi,u)K−1<br />the following<br />noiseI)−1y, Q∗,∗−Q∗,f(Qf,f+σ2<br />?,<br />noiseI)−1Qf,∗<br />?,<br />(16a)<br />(16b)<br />u,uk(u,xj). The new covariance function has rank (at most) m. Thus we have<br />7. Wary of this fact, Smola and Bartlett (2001) propose using the predictive variances of the SoD, or a more accurate<br />computationally costly alternative (more details are given by Qui˜ nonero-Candela, 2004, Chapter 3).<br />1944</p>  <p>Page 7</p> <p>SPARSE APPROXIMATE GAUSSIAN PROCESS REGRESSION<br />Remark 4 The SoR approximation is equivalent to exact inference in the degenerate Gaussian<br />process with covariance function kSoR(xi,xj) = k(xi,u)K−1<br />The equivalent (16b) is computationally cheaper, and with (11) in mind, Σ is the covariance of the<br />posterior on the weights wu. Note that as opposed to the subset of data method, all training cases<br />are taken into account. The computational complexity is O(nm2) initially, and O(m) and O(m2) per<br />test case for the predictive mean and variance respectively.<br />u,uk(u,xj).<br />5. The Deterministic Training Conditional (DTC) Approximation<br />Taking up ideas already contained in the work of Csat´ o and Opper (2002), Seeger et al. (2003)<br />recently proposed another sparse approximation to Gaussian process regression, which does not<br />suffer from the nonsensical predictive uncertainties of the SoR approximation, but that interestingly<br />leads to exactly the same predictive mean. Seeger et al. (2003), who called the method Projected<br />Latent Variables (PLV), presented the method as relying on a likelihood approximation, based on<br />the projection f = Kf,uK−1<br />u,uu:<br />p(y|f) ? q(y|u) = N (Kf,uK−1<br />u,uu, σ2<br />noiseI) .<br />(17)<br />The method has also been called the Projected Process Approximation (PPA) by Rasmussen and<br />Williams (2006, Chapter 8). One way of obtaining an equivalent model is to retain the usual likeli-<br />hood, but to impose a deterministic training conditional and the exact test conditional from eq. (9b)<br />qDTC(f|u) = N (Kf,uK−1<br />u,uu,0),<br />and<br />qDTC(f∗|u) = p(f∗|u) .<br />(18)<br />This reformulation has the advantage of allowing us to stick to our view of exact inference (with<br />exact likelihood) with approximate priors. Indeed, under this model the conditional distribution<br />of f given u is identical to that of the SoR, given in the left of (14). A systematic name for this<br />approximation is the Deterministic Training Conditional (DTC).<br />The fundamental difference with SoR is that DTC uses the exact test conditional (9b) instead of<br />the deterministic relation between f∗and u of SoR. The joint prior implied by DTC is given by:<br />qDTC(f,f∗) = N<br />?<br />0,<br />?Qf,f<br />Qf,∗<br />K∗,∗<br />Q∗,f<br />??<br />,<br />(19)<br />which is surprisingly similar to the effective prior implied by the SoR approximation (15). The<br />fundamental difference is that under the DTC approximation f∗has a prior variance of its own,<br />given by K∗,∗. This prior variance reverses the behaviour of the predictive uncertainties, and turns<br />them into sensible ones, see Figure 5 for an illustration.<br />The predictive distribution is now given by:<br />qDTC(f∗|y) = N (Q∗,f(Qf,f+σ2<br />= N?σ−2K∗,uΣKu,fy, K∗,∗−Q∗,∗+K∗,uΣK?<br />where again we have defined Σ = (σ−2Ku,fKf,u+Ku,u)−1as in (16). The predictive mean for the<br />DTC is identical to that of the SoR approximation (16), but the predictive variance replaces the Q∗,∗<br />from SoR with K∗,∗(which is larger, since K∗,∗−Q∗,∗is positive definite). This added term is the<br />predictive variance of the posterior of f∗conditioned on u. It grows to the prior variance K∗,∗as x∗<br />moves far from the inducing inputs in Xu.<br />noiseI)−1y, K∗,∗−Q∗,f(Qf,f+σ2<br />noiseI)−1Qf,∗<br />(20a)<br />∗,u<br />?,<br />(20b)<br />1945</p>  <p>Page 8</p> <p>QUI˜ NONERO-CANDELA AND RASMUSSEN<br />?<br />?<br />?<br />?<br />??<br />?<br />?<br />?<br />?<br />??<br />A<br />A<br />A<br />A<br />AA<br />Q<br />Q<br />Q<br />Q<br />Q<br />Q<br />Q<br />Q<br />Q<br />u<br />f1<br />f2<br />r r r<br />fn<br />f∗<br />Figure 2: Graphical model for the FITC approximation. Compared to those in Figure 1, all edges<br />between latent function values have been removed: the latent function values are con-<br />ditionally fully independent given the inducing variables u. Although strictly speaking<br />the SoR and DTC approximations could also be represented by this graph, note that both<br />further assume a deterministic relation between f and u.<br />Remark 5 The only difference between the predictive distribution of DTC and SoR is the variance.<br />The predictive variance of DTC is never smaller than that of SoR.<br />Note, that since the covariances for training cases and test cases are computed differently, see (19),<br />it follows that<br />Remark 6 The DTC approximation does not correspond exactly to a Gaussian process,<br />as the covariance between latent values depends on whether they are considered training or test<br />cases, violating consistency, see Definition 1. The computational complexity has the same order as<br />for SoR.<br />6. The Fully Independent Training Conditional (FITC) Approximation<br />Recently Snelson and Ghahramani (2006) proposed another likelihood approximation to speed up<br />Gaussian process regression, which they called Sparse Gaussian Processes using Pseudo-inputs<br />(SGPP). While the DTC is based on the likelihood approximation given by (17), the SGPP proposes<br />a more sophisticated likelihood approximation with a richer covariance<br />p(y|f) ? q(y|u) = N (Kf,uK−1<br />u,uu, diag[Kf,f−Qf,f]+σ2<br />noiseI) ,<br />(21)<br />where diag[A] is a diagonal matrix whose elements match the diagonal of A. As we did in (18)<br />for the DTC, we provide an alternative equivalent formulation called Fully Independent Training<br />Conditional (FITC) based on the inducing conditionals:<br />qFITC(f|u) =<br />n<br />∏<br />i=1<br />p(fi|u) = N?Kf,uK−1<br />u,uu, diag[Kf,f−Qf,f]?, and qFITC(f∗|u) = p(f∗|u). (22)<br />We see that as opposed to SoR and DTC, FITC does not impose a deterministic relation between f<br />and u. Instead of ignoring the variance, FITC proposes an approximation to the training conditional<br />distribution of f given u as a further independence assumption. In addition, the exact test conditional<br />from (9b) is used in (22), although for reasons which will become clear towards the end of this<br />1946</p>  <p>Page 9</p> <p>SPARSE APPROXIMATE GAUSSIAN PROCESS REGRESSION<br />section, we initially consider only a single test case, f∗. The corresponding graphical model is given<br />in Figure 2. The effective prior implied by the FITC is given by<br />qFITC(f, f∗) = N<br />?<br />0,<br />?Qf,f−diag[Qf,f−Kf,f]<br />Qf,∗<br />K∗,∗<br />Q∗,f<br />??<br />.<br />(23)<br />Note, that the sole difference between the DTC and FITC is that in the top left corner of the implied<br />prior covariance, FITC replaces the approximate covariances of DTC by the exact ones on the<br />diagonal. The predictive distribution is<br />qFITC(f∗|y) = N?Q∗,f(Qf,f+Λ)−1y, K∗,∗−Q∗,f(Qf,f+Λ)−1Qf,∗<br />= N?K∗,uΣKu,fΛ−1y, K∗,∗−Q∗,∗+K∗,uΣKu,∗<br />where we have defined Σ = (Ku,u+Ku,fΛ−1Kf,u)−1and Λ = diag[Kf,f−Qf,f+σ2<br />tational complexity is identical to that of SoR and DTC.<br />So far we have only considered a single test case. There are two options for joint predictions,<br />either 1) use the exact full test conditional from (9b), or 2) extend the additional factorizing as-<br />sumption to the test conditional. Although Snelson and Ghahramani (2006) don’t explicitly discuss<br />joint predictions, it would seem that they probably intend the second option. Whereas the addi-<br />tional independence assumption for the test cases is not really necessary for computational reasons,<br />it does affect the nature of the approximation. Under option 1) the training and test covariance are<br />computed differently, and thus this does not correspond to our strict definition of a GP model, but<br />?<br />(24a)<br />?,<br />(24b)<br />noiseI]. The compu-<br />Remark 7 Iff the assumption of full independence is extended to the test conditional, the FITC ap-<br />proximation is equivalent to exact inference in a non-degenerate Gaussian process with covariance<br />function kFIC(xi,xj) = kSoR(xi,xj)+δi,j[k(xi,xj)−kSoR(xi,xj)],<br />where δi,jis Kronecker’s delta. A logical name for the method where the conditionals (training and<br />test) are always forced to be fully independent would be the Fully Independent Conditional (FIC)<br />approximation. The effective prior implied by FIC is:<br />qFIC(f,f∗) = N<br />?<br />0,<br />?Qf,f−diag[Qf,f−Kf,f]<br />Qf,∗<br />Q∗,f<br />Q∗,∗−diag[Q∗,∗−K∗,∗]<br />??<br />.<br />(25)<br />7. The Partially Independent Training Conditional (PITC) Approximation<br />In the previous section we saw how to improve the DTC approximation by approximating the train-<br />ing conditional with an independent distribution, i.e. one with a diagonal covariance matrix. In this<br />section we will further improve the approximation (while remaining computationally attractive) by<br />extending the training conditional to have a block diagonal covariance:<br />qPITC(f|u) = N?Kf,uK−1<br />where blockdiag[A] is a block diagonal matrix (where the blocking structure is not explicitly stated).<br />We represent graphically the PITC approximation in Figure 3. Developing this analogously to the<br />FITC approximation from the previous section, we get the joint prior<br />u,uu, blockdiag[Kf,f−Qf,f]?,<br />and<br />qPITC(f∗|u) = p(f∗|u) .<br />(26)<br />qPITC(f, f∗) = N<br />?<br />0,<br />?Qf,f−blockdiag[Qf,f−Kf,f]<br />Qf,∗<br />K∗,∗<br />Q∗,f<br />??<br />,<br />(27)<br />1947</p>  <p>Page 10</p> <p>QUI˜ NONERO-CANDELA AND RASMUSSEN<br />?<br />?<br />?<br />?<br />??<br />?<br />?<br />?<br />?<br />??<br />A<br />fIk<br />A<br />A<br />A<br />AA<br />Q<br />Q<br />Q<br />Q<br />Q<br />Q<br />Q<br />Q<br />Q<br />u<br />fI1<br />fI2<br />r r r<br />f∗<br />Figure 3: Graphical representation of the PITC approximation. The set of latent function values fIi<br />indexed by the the set of indices Iiis fully connected. The PITC differs from FITC (see<br />graph in Fig. 2) in that conditional independence is now between the k groups of training<br />latent function values. This corresponds to the block diagonal approximation to the true<br />training conditional given in (26).<br />and the predictive distribution is identical to (24), except for the alternative definition of Λ =<br />blockdiag[Kf,f−Qf,f+σ2<br />(2003, Sect. 3), developing from the original Bayesian committee machine (BCM) by Tresp (2000).<br />The relationship to the FITC was pointed out by Lehel Csat´ o. The BCM was originally proposed as<br />a transductive learner (i.e. where the test inputs have to be known before training), and the inducing<br />inputs Xuwere chosen to be the test inputs. We discuss transduction in detail in the next section.<br />It is important to realize that the BCM proposes two orthogonal ideas: first, the block diagonal<br />structure of the partially independent training conditional, and second setting the inducing inputs to<br />be the test inputs. These two ideas can be used independently and in Section 8 we propose using<br />the first without the second.<br />The computational complexity of the PITC approximation depends on the blocking structure<br />imposed in (26). A reasonable choice, also recommended by Tresp (2000) may be to choose<br />k = n/m blocks, each of size m×m. The computational complexity remains O(nm2). Since in<br />the PITC model the covariance is computed differently for training and test cases<br />noiseI]. An identical expression was obtained by Schwaighofer and Tresp<br />Remark 8 The PITC approximation does not correspond exactly to a Gaussian process.<br />This is because computing covariances requires knowing whether points are from the training- or<br />test-set, (27). One can obtain a Gaussian process from the PITC by extending the partial conditional<br />independence assumption to the test conditional, as we did in Remark 7 for the FITC.<br />8. Transduction and Augmentation<br />The idea of transduction is that one should restrict the goal of learning to prediction on a pre-<br />specified set of test cases, rather than trying to learn an entire function (induction) and then evaluate<br />it at the test inputs. There may be no universally agreed upon definition of transduction. In this<br />paper we use<br />Definition 9 Transduction occurs only if the predictive distribution depends on other test inputs.<br />This operational definition excludes models for which there exist an equivalent inductive counter-<br />part. According to this definition, it is irrelevant when the bulk of the computation takes place.<br />1948</p>  <p>Page 11</p> <p>SPARSE APPROXIMATE GAUSSIAN PROCESS REGRESSION<br />?<br />?<br />?<br />?<br />??<br />?<br />?<br />?<br />?<br />?<br />??<br />A<br />fIk<br />A<br />A<br />A<br />AA<br />?<br />???????? ?<br />fI2<br />?<br />?<br />??<br />u<br />fI1<br />r r r<br />f∗<br />Figure 4: Two views on Augmentation. One view is to see that the test latent function value f∗<br />is now part of the inducing variables u and therefore has access to the training latent<br />function values. An equivalent view is to consider that we have dropped the assumption<br />of conditional independence between f∗and the training latent function values. Even if<br />f∗has now direct access to each of the training fi, these still need to go through u to<br />talk to each other if they fall in conditionally independent blocks. We have in this figure<br />decided to recycle the graph for PITC from Figure 3 to show that all approximations we<br />have presented can be augmented, irrespective of what the approximation for the training<br />conditional is.<br />There are several different possible motivations for transduction: 1) transduction is somehow<br />easier than induction (Vapnik, 1995), 2) the test inputs may reveal important information, which<br />should be used during training. This motivation drives models in semi-supervised learning (studied<br />mostly in the context of classification) and 3) for approximate algorithms one may be able to limit<br />the discrepancies of the approximation at the test points.<br />For exact GP models it seems that the first reason doesn’t really apply. If you make predictions<br />at the test points that are consistent with a GP, then it is trivial inside the GP framework to extend<br />these to any other input points, and in effect we have done induction.<br />The second reason seems more interesting. However, in a standard GP setting, it is a conse-<br />quence of the consistency property, see Remark 2, that predictions at one test input are independent<br />of the location of any other test inputs. Therefore transduction can not be married with exact GPs:<br />Remark 10 Transduction can not occur in exact Gaussian process models.<br />Whereas this holds for the usual setting of GPs, it could be different in non-standard situations<br />where e.g. the covariance function depends on the empirical input densities.<br />Transduction can occur in the sparse approximation to GPs, by making the choice of inducing<br />variables depend on the test inputs. The BCM from the previous section, where Xu= X∗(where<br />X∗are the test inputs) is an example of this. Since the inducing variables are connected to all other<br />nodes (see Figure 3) we would expect the approximation to be good at u=f∗, which is what we care<br />about for predictions, relating to reason 3) above. While this reasoning is sound, it is not necessarily<br />a sufficient consideration for getting a good model. The model has to be able to simultaneously<br />explain the training targets as well and if the choice of u makes this difficult, the posterior at the<br />points of interest may be distorted. Thus, the choice of u should be governed by the ability to model<br />the conditional of the latents given the inputs, and not solely by the density of the (test) inputs.<br />The main drawback of transduction is that by its nature it doesn’t provide a predictive model<br />in the way inductive models do. In the usual GP model one can do the bulk of the computation<br />1949</p>  <p>Page 12</p> <p>QUI˜ NONERO-CANDELA AND RASMUSSEN<br />involved in the predictive distributions (e.g. matrix inversion) before seeing the test cases, enabling<br />fast computation of test predictions.<br />It is interesting that whereas other methods spend much effort trying to optimize the inducing<br />variables, the BCM simply uses the test set. The quality of the BCM approximation depends then<br />on the particular location of the test inputs, upon which one usually does not have any control. We<br />now see that there may be a better method, eliminating the drawback of transduction, namely use<br />the PITC approximation, but choose the u’s carefully (see Section 9), don’t just use the test set.<br />8.1 Augmentation<br />An idea closely related to transduction, but not covered by our definition, is augmentation, which<br />in contrast to transduction is done individually for each test case. Since in the previous sections,<br />we haven’t assumed anything about u, we can simply augment the set of inducing variables by f∗<br />(i.e. have one additional inducing variable equal to the current test latent), and see what happens<br />in the predictive distributions for the different methods. Let’s first investigate the consequences<br />for the test conditional from (9b). Note, the interpretation of the covariance matrix K∗,∗−Q∗,∗<br />was “the prior covariance minus the information which u provides about f∗”. It is clear that the<br />augmented u (with f∗) provides all possible information about f∗, and consequently Q∗,∗= K∗,∗.<br />An equivalent view on augmentation is that the assumption of conditional independence between<br />f∗and f is dropped. This is seen trivially by adding edges between f∗and the fiin the graphical<br />model, Figure 4.<br />Augmentation was originally proposed by Rasmussen (2002), and applied in detail to the SoR<br />with RBF covariance by Qui˜ nonero-Candela (2004). Because the SoR is a finite linear model, and<br />the basis functions are local (Gaussian bumps), the predictive distributions can be very misleading.<br />For example, when making predictions far away from the center of any basis function, all basis<br />functions have insignificant magnitudes, and the prediction (averaged over the posterior) will be<br />close to zero, with very small error-bars; this is the opposite of the desired behaviour, where we<br />would expect the error-bars to grow as we move away from the training cases. Here augmentation<br />makes a particularly big difference turning the nonsensical predictive distribution into a reasonable<br />one, by ensuring that there is always a basis function centered on the test case. Compare the non-<br />augmented to the augmented SoR in Figure 5. An analogous Gaussian process based finite linear<br />model that has recently been healed by augmentation is the relevance vector machine (Rasmussen<br />and Qui˜ nonero-Candela, 2005).<br />Although augmentation was initially proposed for a narrow set of circumstances, it is easily<br />applied to any of the approximations discussed. Of course, augmentation doesn’t make any sense<br />for an exact, non-degenerate Gaussian process model (a GP with a covariance function that has a<br />feature-space which is infinite dimensional, i.e. with basis functions everywhere).<br />Remark 11 A full non-degenerate Gaussian process cannot be augmented,<br />since the corresponding f∗would already be connected to all other variables in the graphical model.<br />But augmentation does make sense for sparse approximations to GPs.<br />The more general process view on augmentation has several advantages over the basis function<br />view. It is not completely clear from the basis function view, which basis function should be used<br />for augmentation. For example, Rasmussen and Qui˜ nonero-Candela (2005) successfully apply aug-<br />mentation using basis functions that have a zero contribution at the test location! In the process view<br />1950</p>  <p>Page 13</p> <p>SPARSE APPROXIMATE GAUSSIAN PROCESS REGRESSION<br />however, it seems clear that one would chose the additional inducing variable to be f∗, to minimize<br />the effects of the approximations.<br />Let us compute the effective prior for the augmented SoR. Given that f∗is in the inducing set,<br />the test conditional is not an approximation and we can rewrite the integral leading to the effective<br />prior:<br />qASoR(f∗,f) =<br />It is interesting to notice that this is also the effective prior that would result from augmenting the<br />DTC approximation, since qSoR(f|f∗,u) = qDTC(f|f∗,u).<br />Remark 12 Augmented SoR (ASoR) is equivalent to augmented DTC (ADTC).<br />Z<br />qSoR(f|f∗,u)p(f∗,u)du .<br />(28)<br />Augmented DTC only differs from DTC in the additional presence of f∗among the inducing vari-<br />ables in the training conditional. We can only expect augmented DTC to be a more accurate approx-<br />imation than DTC, since adding an additional inducing variable can only help capture information<br />from y. Therefore<br />Remark 13 DTC is a less accurate (but cheaper) approximation than augmented SoR.<br />We saw previously in Section 5 that the DTC approximation does not suffer from the nonsensi-<br />cal predictive variances of the SoR. The equivalence between the augmented SoR and augmented<br />DTC is another way of seeing how augmentation reverses the misbehaviour of SoR. The predictive<br />distribution of the augmented SoR is obtained by adding f∗to u in (20).<br />Prediction with an augmented sparse model comes at a higher computational cost, since now f∗<br />directly interacts with all of f and not just with u. For each new test case, updating the augmented Σ<br />in the predictive equation (for example (20b) for DTC) implies computing the vector matrix product<br />K∗,fKf,uwith complexity O(nm). This is clearly higher than the O(m) for the mean, and O(m2) for<br />the predictive distribution of all the non-augmented methods we have discussed.<br />Augmentation seems to be only really necessary for methods that make a severe approxima-<br />tion to the test conditional, like the SoR. For methods that make little or no approximation to the<br />test conditional, it is difficult to predict the degree to which augmentation would help. However,<br />one can see by giving f∗access to all of the training latent function values in f, one would expect<br />augmentation to give less under-confident predictive distributions near the training data. Figure 5<br />clearly shows that augmented DTC (equivalent to augmented SoR) has a superior predictive dis-<br />tribution (both mean and variance) than standard DTC. Note however that in the figure we have<br />purposely chosen a too short lengthscale to enhance visualization. Quantitatively, this superiority<br />was experimentally assessed by Qui˜ nonero-Candela (2004, Table 3.1). Augmentation hasn’t been<br />compared to the more advanced approximations FITC and PITC, and the figure would change in<br />the more realistic scenario where the inducing inputs and hyperparameters are learnt (Snelson and<br />Ghahramani, 2006).<br />TransductivemethodsliketheBCMcanbeseenasjointaugmentation, andonecouldpotentially<br />use it for any of the methods presented. It seems that the good performance of the BCM could<br />essentially stem from augmentation, the presence of the other test inputs in the inducing set being<br />probably of little benefit. Joint augmentation might bring some computational advantage, but won’t<br />change the scaling: note that augmenting m times at a cost of O(nm) apiece implies the same<br />O(nm2) total cost as the jointly augmented BCM.<br />1951</p>  <p>Page 14</p> <p>QUI˜ NONERO-CANDELA AND RASMUSSEN<br />−15−10−505 1015<br />−1.5<br />−1<br />−0.5<br />0<br />0.5<br />1<br />1.5<br />SoD<br />−15 −10 −505 10 15<br />−1.5<br />−1<br />−0.5<br />0<br />0.5<br />1<br />1.5<br />SoR<br />−15−10 −505 1015<br />−1.5<br />−1<br />−0.5<br />0<br />0.5<br />1<br />1.5<br />DTC<br />−15 −10−505 1015<br />−1.5<br />−1<br />−0.5<br />0<br />0.5<br />1<br />1.5<br />ASoR/ADTC<br />−15 −10−505 10 15<br />−1.5<br />−1<br />−0.5<br />0<br />0.5<br />1<br />1.5<br />FITC<br />−15 −10−505 1015<br />−1.5<br />−1<br />−0.5<br />0<br />0.5<br />1<br />1.5<br />PITC<br />Figure 5: Toy example with identical covariance function and hyperparameters. The squared ex-<br />ponential covariance function is used, and a slightly too short lengthscale is chosen on<br />purpose to emphasize the different behaviour of the predictive uncertainties. The dots<br />are the training points, the crosses are the targets corresponding to the inducing inputs,<br />randomly selected from the training set. The solid line is the mean of the predictive<br />distribution, and the dotted lines show the 95% confidence interval of the predictions.<br />Augmented DTC (ADTC) is equivalent to augmented SoR (ASoR), see Remark 12.<br />1952</p>  <p>Page 15</p> <p>SPARSE APPROXIMATE GAUSSIAN PROCESS REGRESSION<br />9. On the Choice of the Inducing Variables<br />We have until now assumed that the inducing inputs Xuwere given. Traditionally, sparse models<br />have very often been built upon a carefully chosen subset of the training inputs. This concept is<br />probably best exemplified in the popular support vector machine (Cortes and Vapnik, 1995). In<br />sparse Gaussian processes it has also been suggested to select the inducing inputs Xufrom among<br />the training inputs. Since this involves a prohibitive combinatorial optimization, greedy optimiza-<br />tion approaches have been suggested using various selection criteria like online learning (Csat´ o and<br />Opper, 2002), greedy posterior maximization (Smola and Bartlett, 2001), maximum information<br />gain (Seeger et al., 2003), matching pursuit (Keerthi and Chu, 2006), and probably more. As dis-<br />cussed in the previous section, selecting the inducing inputs from among the test inputs has also<br />been considered in transductive settings. Recently, Snelson and Ghahramani (2006) have proposed<br />to relax the constraint that the inducing variables must be a subset of training/test cases, turning the<br />discrete selection problem into one of continuous optimization. One may hope that finding a good<br />solution is easier in the continuous than the discrete case, although finding the global optimum is<br />intractable in both cases. And perhaps the less restrictive choice can lead to better performance in<br />very sparse models.<br />Which optimality criterion should be used to set the inducing inputs? Departing from a fully<br />Bayesian treatment which would involve defining priors on Xu, one could maximize the marginal<br />likelihood (also called the evidence) with respect to Xu, an approach also followed by Snelson and<br />Ghahramani (2006). Each of the approximate methods proposed involves a different effective prior,<br />and hence its own particular effective marginal likelihood conditioned on the inducing inputs<br />q(y|Xu) =<br />ZZ<br />p(y|f)q(f|u)p(u|Xu)dudf =<br />Z<br />p(y|f)q(f|Xu)df ,<br />(29)<br />which of course is independent of the test conditional. We have in the above equation explicitly<br />conditioned on the inducing inputs Xu. Using Gaussian identities, the effective marginal likelihood<br />is very easily obtained by adding a ridge σ2<br />prior on f. Using the appropriate definitions of Λ, the log marginal likelihood becomes<br />noiseI (from the likelihood) to the covariance of effective<br />logq(y|Xu) = −1<br />2log|Qf,f+Λ|−1<br />noiseI, ΛFITC= diag[Kf,f−Qf,f]+σ2<br />noiseI. The computational cost of the marginal likelihood is O(nm2) for all methods, that of<br />its gradient with respect to one element of Xuis O(nm). This of course implies that the complexity<br />of computing the gradient wrt. to the whole of Xuis O(dnm2), where d is the dimension of the input<br />space.<br />It has been proposed to maximize the effective posterior instead of the effective marginal likeli-<br />hood (Smola and Bartlett, 2001). However this is potentially dangerous and can lead to overfitting.<br />Maximizing the whole evidence instead is sound and comes at an identical computational cost (for<br />a deeper analysis see Qui˜ nonero-Candela, 2004, Sect. 3.3.5 and Fig. 3.2).<br />The marginal likelihood has traditionally been used to learn the hyperparameters of GPs in the<br />non fully Bayesian treatment (see for example Williams and Rasmussen, 1996). For the sparse<br />approximations presented here, once you are learning Xuit is straightforward to allow for learning<br />hyperparameters (of the covariance function) during the same optimization, and there is no need<br />to interleave optimization of u with learning of the hyperparameters as it has been proposed for<br />example by Seeger et al. (2003).<br />2y?(Qf,f+Λ)−1y−n<br />noiseI, and ΛPITC= blockdiag[Kf,f−<br />2log(2π) ,<br />(30)<br />where ΛSoR= ΛDTC= σ2<br />Qf,f]+σ2<br />1953</p>  <p>Page 16</p> <p>QUI˜ NONERO-CANDELA AND RASMUSSEN<br />10. Other Methods<br />In this section we briefly mention two approximations which don’t fit in our unifying scheme,<br />since one doesn’t correspond to a proper probabilistic model, and the other one uses a particular<br />construction for the covariance function, rather than allowing any general covariance function.<br />10.1 The Nystr¨ om Approximation<br />The Nystr¨ om Approximation for speeding up GP regression was originally proposed by Williams<br />and Seeger (2001), and then questioned by Williams et al. (2002). Like SoR and DTC, the Nystr¨ om<br />Approximation for GP regression approximates the prior covariance of f by Qf,f. However, unlike<br />these methods, the Nystr¨ om Approximation is not based on a generative probabilistic model. The<br />priorcovariancebetween f∗andfistakentobeexact, whichisinconsistent withthepriorcovariance<br />on f:<br />q(f,f∗) = N<br />?<br />0,<br />?Qf,f<br />Kf,∗<br />K∗,∗<br />K∗,f<br />??<br />.<br />(31)<br />As a result we cannot derive this method from our unifying framework, nor represent it with a<br />graphical model. Worse, the resulting prior covariance matrix is not even guaranteed to be positive<br />definite, allowing the predictive variances to be negative. Notice that replacing Kf,∗by Qf,∗in (31)<br />is enough to make the prior covariance positive definite, and one obtains the DTC approximation.<br />Remark 14 The Nystr¨ om Approximation does not correspond to a well-formed probabilistic model.<br />Ignoring any quibbles about positive definiteness, the predictive distribution of the Nystr¨ om Ap-<br />proximation is given by:<br />p(f∗|y) = N?K?<br />f,∗[Qf,f+σ2<br />noiseI]−1y, K∗,∗−K?<br />f,∗[Qf,f+σ2<br />noiseI]−1Kf,∗<br />?,<br />(32)<br />but the predictive variance is not guaranteed to be positive. The computational cost is O(nm2).<br />10.2 The Relevance Vector Machine<br />The relevance vector machine, introduced by Tipping (2001), is a finite linear model with an in-<br />dependent Gaussian prior imposed on the weights. For any input x∗, the corresponding function<br />output is given by:<br />f∗ = φ∗w ,<br />where φ∗= [φ1(x),...,φm(x)] is the (row) vector of responses of the m basis functions, and A =<br />diag(α1,...,αm) is the diagonal matrix of joint prior precisions (inverse variances) of the weights.<br />The αiare learnt by maximizing the RVM evidence (obtained by also assuming Gaussian additive<br />iid. noise, see (1)), and for the typical case of rich enough sets of basis functions many of the<br />precisions go to infinity effectively pruning out the corresponding weights (for a very interesting<br />analysis see Wipf et al., 2004). The RVM is thus a sparse method and the surviving basis functions<br />are called relevance vectors.<br />Note that since the RVM is a finite linear model with Gaussian priors on the weights, it can be<br />seen as a Gaussian process:<br />with<br />p(w|A) = N (0,A) ,<br />(33)<br />Remark 15 The RVM is equivalent to a degenerate Gaussian process with covariance function<br />kRVM(xi,xj) = φiA−1φ?<br />j=∑m<br />k=1α−1<br />kφk(xi)φk(xj),<br />1954</p>  <p>Page 17</p> <p>SPARSE APPROXIMATE GAUSSIAN PROCESS REGRESSION<br />Method<br />q(f∗|u)<br />exact<br />q(f|u)<br />exact<br />joint prior covariance<br />?Kf,f<br />K∗,f<br />?Qf,f<br />Q∗,f<br />?Qf,f<br />Q∗,f<br />?Qf,f−diag[Qf,f−Kf,f]<br />Q∗,f<br />?Qf,f−blokdiag[Qf,f−Kf,f]<br />Q∗,f<br />GP?<br />√<br />GP<br />Kf,∗<br />K∗,∗<br />Qf,∗<br />Q∗,∗<br />Qf,∗<br />K∗,∗<br />?<br />?<br />?<br />SoRdeterm.determ.<br />√<br />DTC exact determ.<br />FITC(exact)fully indep.<br />Qf,∗<br />K∗,∗<br />Qf,∗<br />K∗,∗<br />?<br />(√)<br />PITCexactpartially indep.<br />?<br />Table 1: Summary of the way approximations are built. All these methods are detailed in the previ-<br />oussections. Theinitialcostandthatofthemeanandvariancepertestcasearerespectively<br />n2, n and n2for the exact GP, and nm2, m and m2for all other methods. The “GP?” column<br />indicates whether the approximation is equivalent to a GP. For FITC see Remark 7.<br />as was also pointed out by Tipping (2001, eq. (59)). Whereas all sparse approximations we have<br />presented until now are totally independent of the choice of covariance function, for the RVM<br />this choice is restricted to covariance functions that can be expressed as finite expansions in terms<br />of some basis functions. Being degenerate GPs in exactly the same way as the SoR (presented<br />in Section 4), the RVM does also suffer from unreasonable predictive variances. Rasmussen and<br />Qui˜ nonero-Candela (2005) show that the predictive distributions of RVMs can also be healed by<br />augmentation, see Section 8. Once the αihave been learnt, denoting by m the number of surviving<br />relevance vectors, the complexity of computing the predictive distribution of the RVM is O(m) for<br />mean and O(m2) for the variance.<br />RVMs are often used with radial basis functions centered on the training inputs. One potentially<br />interestingextensiontotheRVMwouldbetolearnthelocationsofthecentersofthebasisfunctions,<br />in the same way as proposed by Snelson and Ghahramani (2006) for the FITC approximation, see<br />Section 6. This is a curious reminiscence of learning the centers in RBF Networks.<br />11. Conclusions<br />We have provided a unifying framework for sparse approximations to Gaussian processes for regres-<br />sion. Our approach consists of two steps, first 1) we recast the approximation in terms of approx-<br />imations to the prior, and second 2) we introduce inducing variables u and the idea of conditional<br />independence given u. We recover all existing sparse methods by making further simplifications of<br />the covariances of the training and test conditionals, see Table 1 for a summary.<br />Previous methods were presented based on different approximation paradigms (e.g. likelihood<br />approximations, projection methods, matrix approximations, minimization of Kullback-Leibler di-<br />vergence, etc), making direct comparison difficult. Under our unifying view we deconstruct meth-<br />ods, making it clear which building blocks they are based upon. For example, the SGPP by Snelson<br />1955</p>  <p>Page 18</p> <p>QUI˜ NONERO-CANDELA AND RASMUSSEN<br />and Ghahramani (2006) contains two ideas, 1) a likelihood approximation and 2) the idea of varying<br />the inducing inputs continuously; these two ideas could easily be used independently, and incorpo-<br />rated in other methods. Similarly, the BCM by Tresp (2000) contains two independent ideas 1) a<br />block diagonal assumption, and 2) the (transductive) idea of choosing the test inputs as the induc-<br />ing variables. Finally we note that although all three ideas of 1) transductively setting u = f∗, 2)<br />augmentation and 3) continuous optimization of Xuhave been proposed in very specific settings, in<br />fact they are completely general ideas, which can be applied to any of the approximation schemes<br />considered.<br />We have ranked the approximation according to how close they are to the corresponding full<br />GP. However, the performance in practical situations may not always follow this theoretical ranking<br />since the approximations might exhibit properties (not present in the full GP) which may be par-<br />ticularly suitable for specific datasets. This may make the interpretation of empirical comparisons<br />challenging. A further complication arises when adding the necessary heuristics for turning the<br />theoretical constructs into practical algorithms. We have not described full algorithms in this paper,<br />but are currently working on a detailed empirical study (in preparation, see also Rasmussen and<br />Williams, 2006, chapter 8).<br />We note that the order of the computational complexity is identical for all the methods consid-<br />ered, O(nm2). This highlights that there is no computational excuse for using gross approximations,<br />such as assuming deterministic relationships, in particular one should probably think twice before<br />using SoR or even DTC. Although augmentation has attractive predictive properties, it is com-<br />putationally expensive. It remains unclear whether augmentation could be beneficial on a fixed<br />computational budget.<br />We have only considered the simpler case of regression in this paper, but sparseness is also com-<br />monly sought in classification settings. It should not be difficult to cast probabilistic approximation<br />methods such as Expectation Propagation (EP) or the Laplace method (for a comparison, see Kuss<br />and Rasmussen, 2005) into our unifying framework.<br />Ouranalysissuggeststhatanewinterestingapproximationwouldcomefromcombiningthebest<br />possible approximation (PITC) with the most powerful selection method for the inducing inputs.<br />This would correspond to a non-transductive version of the BCM. We would evade the necessity of<br />knowing the test set before doing the bulk of the computation, and we could hope to supersede the<br />superior performance reported by Snelson and Ghahramani (2006) for very sparse approximations.<br />Acknowledgments<br />ThankstoNeilLawrenceforarrangingthe2005GaussianProcessRoundTablemeetinginSheffield,<br />which provided much inspiration to this paper. Special thanks to Olivier Chapelle, Lehel Csat´ o,<br />Zoubin Ghahramani, Matthias Seeger, Ed Snelson and Chris Williams for helpful discussions, and<br />to three anonymous reviewers. Both authors were supported by the German Research Council<br />(DFG) through grant RA 1030/1. This work was supported in part by the IST Programme of the<br />European Community, under the PASCAL Network of Excellence, IST-2002-506778.<br />1956</p>  <p>Page 19</p> <p>SPARSE APPROXIMATE GAUSSIAN PROCESS REGRESSION<br />Appendix A. Gaussian and Matrix Identities<br />In this appendix we provide identities used to manipulate matrices and Gaussian distributions<br />throughout the paper. Let x and y be jointly Gaussian<br />?x<br />y<br />?<br />∼ N<br />??µx<br />µy<br />?<br />,<br />?<br />AC<br />BC?<br />??<br />,<br />(34)<br />then the marginal and the conditional are given by<br />x ∼ N (µx, A) ,<br />and<br />x|y ∼ N?µx+CB−1(y−µy), A−CB−1C??<br />(35)<br />Also, the product of a Gaussian in x with a Gaussian in a linear projection Px is again a Gaussian,<br />although unnormalized<br />N (x|a,A)N (Px|b,B) = zcN (x|c,C) ,<br />where<br />C =<br />?A−1+P?B−1P?−1,<br />The normalizing constant zcis gaussian in the means a and b of the two Gaussians:<br />(36)<br />c = C?A−1a+P?B−1b?.<br />zc = (2π)−m<br />2|B+PAP?|−1<br />2exp<br />?<br />−1<br />2(b−Pa)??B+PAP??−1(b−Pa)<br />?<br />.<br />(37)<br />The matrix inversion lemma, also known as the Woodbury, Sherman &amp; Morrison formula states<br />that:<br />(Z+UWV?)−1= Z−1−Z−1U(W−1+V?Z−1U)−1V?Z−1,<br />assuming the relevant inverses all exist. Here Z is n×n, W is m×m and U and V are both of size<br />n×m; consequently if Z−1is known, and a low rank (ie. m &lt; n) perturbation are made to Z as in<br />left hand side of eq. (38), considerable speedup can be achieved.<br />(38)<br />References<br />Corinna Cortes and Vladimir Vapnik. Support-vector network. Machine Learning, 20(3):273–297,<br />1995.<br />Lehel Csat´ o and Manfred Opper. Sparse online Gaussian processes. Neural Computation, 14(3):<br />641–669, 2002.<br />Sathiya Keerthi and Wei Chu. A Matching Pursuit approach to sparse Gaussian process regression.<br />In Y. Weiss, B. Sch¨ olkopf, and J. Platt, editors, Advances in Neural Information Processing<br />Systems 18, Cambridge, Massachussetts, 2006. The MIT Press.<br />Malte Kuss and Carl Edward Rasmussen. Assessing approximate inference for binary Gaussian<br />process classification. Journal of Machine Learning Research, pages 1679–1704, 2005.<br />Joaquin Qui˜ nonero-Candela. Learning with Uncertainty – Gaussian Processes and Relevance Vec-<br />tor Machines. PhD thesis, Technical University of Denmark, Lyngby, Denmark, 2004.<br />Carl Edward Rasmussen. Reduced rank Gaussian process learning. Technical report, Gatsby Com-<br />putational Neuroscience Unit, UCL, 2002.<br />1957</p>  <p>Page 20</p> <p>QUI˜ NONERO-CANDELA AND RASMUSSEN<br />Carl Edward Rasmussen and Joaquin Qui˜ nonero-Candela. Healing the relevance vector machine by<br />augmentation. In International Conference on Machine Learning, 2005.<br />CarlEdwardRasmussenandChristopherK.I.Williams. GaussianProcessesforMachineLearning.<br />The MIT press, 2006.<br />Anton Schwaighofer and Volker Tresp. Transductive and inductive methods for approximate Gaus-<br />sian process regression. In Suzanna Becker, Sebastian Thrun, and Klaus Obermayer, editors,<br />Advances in Neural Information Processing Systems 15, pages 953–960, Cambridge, Massachus-<br />setts, 2003. The MIT Press.<br />Matthias Seeger, Christopher K. I. Williams, and Neil Lawrence. Fast forward selection to speed up<br />sparse Gaussian process regression. In Christopher M. Bishop and Brendan J. Frey, editors, Ninth<br />International Workshop on Artificial Intelligence and Statistics. Society for Artificial Intelligence<br />and Statistics, 2003.<br />Bernhard W. Silverman. Some aspects of the spline smoothing approach to non-parametric regres-<br />sion curve fitting. J. Roy. Stat. Soc. B, 47(1):1–52, 1985. (with discussion).<br />Alexander J. Smola and Peter L. Bartlett. Sparse greedy Gaussian process regression. In Todd K.<br />Leen, Thomas G. Dietterich, and Volker Tresp, editors, Advances in Neural Information Process-<br />ing Systems 13, pages 619–625, Cambridge, Massachussetts, 2001. The MIT Press.<br />Edward Snelson and Zoubin Ghahramani. Sparse Gaussian processes using pseudo-inputs. In<br />Y. Weiss, B. Sch¨ olkopf, and J. Platt, editors, Advances in Neural Information Processing Systems<br />18, Cambridge, Massachussetts, 2006. The MIT Press.<br />Michael E. Tipping. Sparse Bayesian learning and the Relevance Vector Machine. Journal of<br />Machine Learning Research, 1:211–244, 2001.<br />Volker Tresp. A Bayesian committee machine. Neural Computation, 12(11):2719–2741, 2000.<br />Vladimir N. Vapnik. The Nature of Statistical Learning Theory. Springer Verlag, 1995.<br />Grace Wahba, Xiwu Lin, Fangyu Gao, Dong Xiang, Ronald Klein, and Barbara Klein. The bias-<br />variance tradeoff and the randomized GACV. In Michael S. Kerns, Sara A. Solla, and David A.<br />Cohn, editors, Advances in Neural Information Processing Systems 11, pages 620–626, Cam-<br />bridge, Massachussetts, 1999. The MIT Press.<br />Christopher K. I. Williams and Carl Edward Rasmussen. Gaussian processes for regression. In<br />David S. Touretzky, Michael C. Mozer, and Michael E. Hasselmo, editors, Advances in Neural<br />Information Processing Systems 8, pages 514–520, Cambridge, Massachussetts, 1996. The MIT<br />Press.<br />Christopher K. I. Williams, Carl Edward Rasmussen, Anton Schwaighofer, and Volker Tresp. Ob-<br />servations of the Nystr¨ om method for Gaussiam process prediction. Technical report, University<br />of Edinburgh, Edinburgh, Scotland, 2002.<br />1958</p>  <p>Page 21</p> <p>SPARSE APPROXIMATE GAUSSIAN PROCESS REGRESSION<br />Christopher K. I. Williams and Mathias Seeger. Using the Nystr¨ om method to speed up kernel<br />machines. In Todd K. Leen, Thomas G. Dietterich, and Volker Tresp, editors, Advances in Neural<br />Information Processing Systems 13, pages 682–688, Cambridge, Massachussetts, 2001. The MIT<br />Press.<br />David Wipf, Jason Palmer, and Bhaskar Rao. Perspectives on sparse Bayesian learning. In Sebas-<br />tian Thrun, Lawrence Saul, and Bernhard Sch¨ olkopf, editors, Advances in Neural Information<br />Processing Systems 16, Cambridge, Massachussetts, 2004. The MIT Press.<br />1959</p>   </div> <div id="rgw21_56ab9fbcdfce3" class="c-box pub-resource-container js-toggle" style=""> <h4 class="lf js-expand-list"><small><a href="javascript:" class="lf">View other sources <span class="ico-expand-list"></span></a></small></h4> <h4 class="lf js-collapse-list hidden"><small><a href="javascript:" class="lf">Hide other sources <span class="ico-collapse-list"></span></a></small></h4> <div class="clear"></div> <div class="scroll-wrapper hidden"> <ul class="files-list c-list" id="rgw22_56ab9fbcdfce3">  <li class="c-list-item pub-resource-item"  data-type="fulltext" id="rgw23_56ab9fbcdfce3"> <span class="ico-pub"></span> <div class="file-content"> <div class="download"> <a href="http://lasa.epfl.ch/teaching/lectures/ML_Phd/readings/papers/SparseGP-Quinonero-Candela-Rasmussen05.pdf" target="_blank" rel="nofollow" class="publication-viewer" title="A Unifying View of Sparse Approximate Gaussian Process Regression">A Unifying View of Sparse Approximate Gaussian Pro...</a> </div>  <div class="details">   Available from <a href="http://lasa.epfl.ch/teaching/lectures/ML_Phd/readings/papers/SparseGP-Quinonero-Candela-Rasmussen05.pdf" target="_blank" rel="nofollow">epfl.ch</a>  </div>    </div> </li>  </ul> </div> </div> </noscript> <div class="clearfix"> <div class="action-container">  </div> <div class="pub-legal"> Data provided are for informational purposes only. Although carefully collected, accuracy cannot be guaranteed. The impact factor represents a rough estimation of the journal's impact factor and does not reflect the actual current impact factor. Publisher conditions are provided by RoMEO. Differing provisions from the publisher's actual policy or licence agreement may be applicable. </div>   </div> </div> <div class="clearfix">     <div id="rgw25_56ab9fbcdfce3" class="c-box pub-resource-container js-toggle" style="display: none;"> <h4 class="lf js-expand-list"><small><a href="javascript:" class="lf">View other sources <span class="ico-expand-list"></span></a></small></h4> <h4 class="lf js-collapse-list hidden"><small><a href="javascript:" class="lf">Hide other sources <span class="ico-collapse-list"></span></a></small></h4> <div class="clear"></div> <div class="scroll-wrapper hidden"> <ul class="files-list c-list" id="rgw26_56ab9fbcdfce3">  </ul> </div> </div>   <div id="rgw17_56ab9fbcdfce3" class="similar-publications"> <h2>Similar Publications</h2> <ul class="list-bordered">  <li class="c-list-item li-publication-teaser" id="rgw18_56ab9fbcdfce3"> <div> <h5> <a href="publication/220320671_A_Unifying_View_of_Sparse_Approximate_Gaussian_Process_Regression" class="color-inherit ga-similar-publication-title"><span class="publication-title">A Unifying View of Sparse Approximate Gaussian Process Regression.</span></a>  </h5>  <div class="authors"> <a href="researcher/70734799_Joaquin_Quinonero_Candela" class="authors ga-similar-publication-author">Joaquin Quiñonero Candela</a>, <a href="researcher/43277170_Carl_Edward_Rasmussen" class="authors ga-similar-publication-author">Carl Edward Rasmussen</a>  </div>  </div> <div class="clear"></div> </li>  <li class="c-list-item li-publication-teaser" id="rgw19_56ab9fbcdfce3"> <div> <h5> <a href="publication/278058976_Approximate_Gaussian_Process_Regression_with_Sparse_Functional_Learning_of_Inducing_Points_for_Components_Condition_Monitoring" class="color-inherit ga-similar-publication-title"><span class="publication-title">Approximate Gaussian Process Regression with Sparse Functional Learning of Inducing Points for Components Condition Monitoring</span></a>  </h5>  <div class="authors"> <a href="researcher/72821755_Valeria_Vitelli" class="authors ga-similar-publication-author">Valeria Vitelli</a>, <a href="researcher/8420504_Enrico_Zio" class="authors ga-similar-publication-author">Enrico Zio</a>  </div>  </div> <div class="clear"></div> </li>  <li class="c-list-item li-publication-teaser" id="rgw20_56ab9fbcdfce3"> <div> <h5> <a href="publication/258082179_Massively_Parallel_Approximate_Gaussian_Process_Regression" class="color-inherit ga-similar-publication-title"><span class="publication-title">Massively Parallel Approximate Gaussian Process Regression</span></a>  </h5>  <div class="authors"> <a href="researcher/11509338_Robert_B_Gramacy" class="authors ga-similar-publication-author">Robert B. Gramacy</a>, <a href="researcher/46284483_Jarad_Niemi" class="authors ga-similar-publication-author">Jarad Niemi</a>, <a href="researcher/2029974425_Robin_M_Weiss" class="authors ga-similar-publication-author">Robin M. Weiss</a>  </div>  </div> <div class="clear"></div> </li>  </ul> </div> </div> </div> </div> </div></div></div>
<div class="clear"></div><div id="rgw31_56ab9fbcdfce3" class="default-footer"> <div id="footer" class="clearfix"> <span class="footer-left"> &copy; 2008&dash;2016 researchgate.net. All rights reserved. </span> <span class="footer-right"> <a href="https://www.researchgate.net/about">About us</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="https://www.researchgate.net/contact">Contact us</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="careers">Careers</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="developers">Developers</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="blog" target="_blank">News</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="application.PrivacyPolicy.html">Privacy</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="application.TermsAndConditions.html">Terms</a> <span class="footer-link-separator" style="padding: 0 5px;">&nbsp;|&nbsp;</span> <a href="advertising?_ref=ft">Advertising</a> <span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="recruiters?_ref=ft">Recruiting</a> </span> </div>  </div></div>
<div id="rgw32_56ab9fbcdfce3">  <div class="header-wrapper-logged-out"> <div id="header"> <div class="header-content"> <a href="" class="g-l-logo"> <svg width="149" height="19"> <image xlink:href="https://c5.rgstatic.net/m/235107188705592/images/template/brand-header-logo.svg" src="https://c5.rgstatic.net/m/238113351022438/images/template/brand-header-logo.png" width="149" height="19"/> </svg> </a> <a href="" class="g-l-logo-ico"> <svg width="127" height="17" viewbox="0 0 127 22"> <image xlink:href="https://c5.rgstatic.net/m/235107188705592/images/template/brand-header-logo.svg" src="https://c5.rgstatic.net/m/238113351022438/images/template/brand-header-logo.png" width="127" height="17"/> </svg> </a> <div id="rgw33_56ab9fbcdfce3" class="header-login-wrapper js-header-login"> <div class="dropdown-right-align"> <div class="login-signup-container lf"> <a href="https://www.researchgate.net/signup.SignUp.html?ev=su_chnl_index&amp;hdrsu=1&amp;_sg=ymdf-40Xmw6tYYAYZKH2PedNtLRiG7WW_HyZuRqUouryp-5hEqX9y2AKC6uT3EKk" class="dropdown-toggle lf">Join for free</a> </div> <div class="dropdown lf" style="height: 20px;"> <a href="https://www.researchgate.net/application.Login.html" class="js-login-url dropdown-toggle lf">Log in <span class="caret"></span></a> <div class="dropdown-menu"> <div class="header-login-form-wrapper"> <!--[if IE 6]><p class="box-warning" style="margin-bottom: 0;">Sorry, ResearchGate no longer supports the version of Internet Explorer you are using. <a href="http://whatbrowser.org/" rel="nofollow" target="_blank">Update your web browser</a> and then log in. </p><![endif]--> <form method="post" action="https://www.researchgate.net/application.Login.html" class="form-big header-login-form js-login-form" name="loginForm" id="headerLoginForm"> <input type="hidden" name="request_token" value="s0tkb2zmBU4trCLXko53ztlHYH5pOY2U/N4hJ+yq10T2TKjw606a7lzlW1KLziBSBgtknuLOvXgPYDjiiD6Wo7IN/Wn2Te/Xam5vFNKJWrAm7lx6TxL410bb1LGk/e50s2VNdytB85Md/luPcnPCg+YRF01eRmZK2HK8tgws7D/Ph1D0GuhAd+B0+mi1txhUdtHOeMrurUVIQKNyERGh8wpcW2ECirLq2Y2Osui62jnIWhVqqpLYSOAf9rThBSwY2Mt7CPMCi+BHFERrBfP0bengmhFcFpkwCIXR7B2/bcM="/> <input type="hidden" name="urlAfterLogin" value="publication/41781406_A_Unifying_View_of_Sparse_Approximate_Gaussian_Process_Regression"/> <input type="hidden" name="invalidPasswordCount" value="0"/> <input type="hidden" name="headerLogin" value="yes"/> <label for="input-header-login">Email</label> <div class="login-input"> <div class="info-tip-wrapper"> <span class="ico-info js-info"></span> </div> <input type="email" value="" name="login" class="login js-login-input text" id="input-header-login" tabindex="1"/> </div> <div class="clear"></div> <label class="lf" for="input-header-password"> Password </label> <a class="rf forgot-password js-forgot-password" href="application.LostPassword.html">Forgot password?</a> <div class="clear"></div> <input type="password" value="" name="password" class="password js-password-input text" id="input-header-password" tabindex="2"/> <div class="clear"></div> <label class="remember-me" for="headerLoginCookie"> <input type="checkbox" checked="checked" value="yes" name="setLoginCookie" class="lf checkbox" id="headerLoginCookie" tabindex="3"/> Keep me logged in </label> <div class="clear"></div> <input value="Log in" name="loginSubmit" class="btn btn-promote btn-fullwidth btn-large allow-leave js-submit-button" type="submit" tabindex="4"/> </form> <div class="connectors"> <div class="text">or log in with</div> <div class="connector-actions"> <a href="connector/linkedin/" class="li-connect js-li-connect" data-redirect-url="cHVibGljYXRpb24vNDE3ODE0MDZfQV9VbmlmeWluZ19WaWV3X29mX1NwYXJzZV9BcHByb3hpbWF0ZV9HYXVzc2lhbl9Qcm9jZXNzX1JlZ3Jlc3Npb24%3D"> <span class="icon ico-linkedin-round-grey"></span> <span class="icon ico-linkedin-round"></span> </a> <a href="connector/facebook/" class="fb-connect middle js-fb-connect" data-redirect-url="cHVibGljYXRpb24vNDE3ODE0MDZfQV9VbmlmeWluZ19WaWV3X29mX1NwYXJzZV9BcHByb3hpbWF0ZV9HYXVzc2lhbl9Qcm9jZXNzX1JlZ3Jlc3Npb24%3D"> <span class="icon ico-facebook-round-grey"></span> <span class="icon ico-facebook-round"></span> </a> <a href="connector/google/" class="g-connect js-g-connect" data-redirect-url="cHVibGljYXRpb24vNDE3ODE0MDZfQV9VbmlmeWluZ19WaWV3X29mX1NwYXJzZV9BcHByb3hpbWF0ZV9HYXVzc2lhbl9Qcm9jZXNzX1JlZ3Jlc3Npb24%3D"> <span class="icon ico-google-round-grey"></span> <span class="icon ico-google-round"></span> </a> </div> </div> </div> </div> </div> </div> </div> </div> </div> <script type="application/ld+json">
{ "@context" : "http://schema.org",
  "@type" : "Organization",
  "name" : "ResearchGate",
  "url" : "http://www.researchgate.net",
  "logo" : "http://www.researchgate.net/images/template/rg_logo_square_brand.png",
  "sameAs" : [ "https://www.facebook.com/ResearchGate",
    "https://twitter.com/ResearchGate",
    "https://plus.google.com/+researchgate",
    "https://www.linkedin.com/company/researchgate"] 
}
</script> </div> </div><div class="c-signup-bar" id="rgw34_56ab9fbcdfce3"> <div class="banner-contents">   <span class="message">ResearchGate is the professional network for scientists and researchers.</span> <a href="signup.SignUp.html?ev=su_banner" class="btn btn-large btn-promote">Join for free</a>  </div> </div></div>
<script>
rgConfig.backendTime = 1741;
</script>
<script src="//c5.rgstatic.net/m/2277196935388619/javascript/lib/yui3/yui/yui-min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/21832295316281274/javascript/yuiLoaderConfig-min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/23178613132105398/javascript/vendor/babel-core/browser-polyfill.min.js" type="text/javascript"></script>
<script>
(function (){
if (typeof YRG === "undefined") {
var xmlHttpRequest = new XMLHttpRequest();
xmlHttpRequest.open("post", "go.Error.html");
xmlHttpRequest.setRequestHeader("Content-Type", "application/json");
xmlHttpRequest.setRequestHeader("Accept", "application/json"); var loadedScripts = "";
if (window.performance && window.performance.getEntriesByType) {
    var result = [];
    var resources = performance.getEntriesByType("resource");
    for (var i in resources) {
        if (resources.hasOwnProperty(i)) {
            result.push({
                name: resources[i].name,
                duration: resources[i].duration
            });
        }
    }
    loadedScripts += "&loadedScripts=" + encodeURIComponent(JSON.stringify(result));
}
if (typeof YUI === "undefined") {
    loadedScripts += "&yuiLoaded=false";
} else {
    loadedScripts += "&yuiLoaded=true";
}
xmlHttpRequest.send("Type=InformationException&message=" + encodeURIComponent("Error loading YUI") + loadedScripts);
}
})();
</script>
<script>if (typeof YRG !== 'undefined') { YRG.use('rg-base',function(Y){Y.applyConfig({ignore: ["css-rg","css-rg2","css-ie","css-modules-publicprofile"]});Y.use(["rg.core.pagespeed.Monitoring"],function(Y){(function(){Y.rg.createInitialWidget({"data":{"content":{"data":{"profileSmallHeader":{"data":{"profileBadge":{"data":{"profileUrl":"researcher\/46151520_Joaquin_Quinonero-Candela","fullname":"Joaquin Qui\u00f1onero-Candela","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2549355721578\/images\/template\/default\/profile\/profile_default_m.png","profileStats":[{"data":{"impactPoints":"10.09","widgetId":"rgw5_56ab9fbcdfce3"},"id":"rgw5_56ab9fbcdfce3","partials":[],"templateName":"publicliterature\/stubs\/PublicLiteratureAuthorImpactPoints.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicLiteratureAuthorImpactPoints.html?authorUid=46151520","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"publicationCount":8,"widgetId":"rgw6_56ab9fbcdfce3"},"id":"rgw6_56ab9fbcdfce3","partials":[],"templateName":"publicliterature\/stubs\/PublicLiteratureAuthorPublicationCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicLiteratureAuthorPublicationCount.html?authorUid=46151520","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"followerCount":1,"widgetId":"rgw7_56ab9fbcdfce3"},"id":"rgw7_56ab9fbcdfce3","partials":[],"templateName":"publicliterature\/stubs\/PublicLiteratureAuthorFollowerCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicLiteratureAuthorFollowerCount.html?authorUid=46151520","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"widgetId":"rgw4_56ab9fbcdfce3"},"id":"rgw4_56ab9fbcdfce3","partials":[],"templateName":"publicprofile\/stubs\/ProfileBadge.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicLiteratureAuthorBadge.html?authorUid=46151520","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw3_56ab9fbcdfce3"},"id":"rgw3_56ab9fbcdfce3","partials":[],"templateName":"publicprofile\/stubs\/ProfileSmallHeader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicprofile.ProfileSmallHeader.html?publicationUid=41781406","viewClass":null,"yuiModules":["css-modules-publicprofile"],"stylesheets":["modules\/publicprofile.css"],"_isYUI":true},"publication":{"data":{"publicationUid":41781406,"title":"A Unifying View of Sparse Approximate Gaussian Process Regression","journalTitle":"Journal of Machine Learning Research","journalDetailsTooltip":{"data":{"journalTitle":"Journal of Machine Learning Research","journalAbbrev":"J MACH LEARN RES","publisher":false,"issn":"1533-7928","impactFactor":"2.47","fiveYearImpactFactor":"4.77","citedHalfLife":"8.30","immediacyIndex":"0.31","eigenFactor":"0.03","articleInfluence":"3.23","widgetId":"rgw9_56ab9fbcdfce3"},"id":"rgw9_56ab9fbcdfce3","partials":[],"templateName":"publicliterature\/stubs\/JournalInfo.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.JournalInfo.html?issn=1533-7928","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"affiliation":false,"type":"Article","details":{"journalInfos":{"journal":"","publicationDate":"12\/2005;","publicationDateRobot":"2005-12","article":"6.","journalTitle":"Journal of Machine Learning Research","journalUrl":"journal\/1533-7928_Journal_of_Machine_Learning_Research","impactFactor":2.47}},"source":{"sourceUrl":"http:\/\/edoc.mpg.de\/270092","sourceName":"OAI"},"publicationActions":null,"publicationCoins":{"data":{"tags":[{"key":"ctx_ver","value":"Z39.88-2004"},{"key":"rft_val_fmt","value":"info:ofi\/fmt:kev:mtx:journal"},{"key":"rfr_id","value":"info:sid\/researchgate.net:researchgate"},{"key":"rft.atitle","value":"A Unifying View of Sparse Approximate Gaussian Process Regression"},{"key":"rft.title","value":"Journal of Machine Learning Research, v.6, 1935-1959 (2005)"},{"key":"rft.jtitle","value":"Journal of Machine Learning Research, v.6, 1935-1959 (2005)"},{"key":"rft.volume","value":"6"},{"key":"rft.date","value":"2005"},{"key":"rft.issn","value":"1533-7928"},{"key":"rft.au","value":"JQ Quinonero-Candela,C.E. Rasmussen"},{"key":"rft.genre","value":"article"}],"widgetId":"rgw10_56ab9fbcdfce3"},"id":"rgw10_56ab9fbcdfce3","partials":[],"templateName":"publicliterature\/stubs\/PublicationCoins.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationCoins.html?publicationUid=41781406","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationAuthors":{"data":{"publicationUid":41781406,"peopleItems":[{"data":{"authorUrl":"researcher\/46151520_JQ_Quinonero-Candela","authorNameOnPublication":"JQ Quinonero-Candela","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg","imageSize":"s","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"JQ Quinonero-Candela","profile":{"professionalInstitution":{"professionalInstitutionName":false,"professionalInstitutionUrl":null}},"professionalInstitutionName":false,"professionalInstitutionUrl":null,"url":"researcher\/46151520_JQ_Quinonero-Candela","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":true,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":false,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"widgetId":"rgw13_56ab9fbcdfce3"},"id":"rgw13_56ab9fbcdfce3","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAuthorItem.html?entityId=46151520&imageSize=l&enableAuthorInviteButton=0","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"largeTooltip":false,"useRebrandedImageStyle":null,"widgetId":"rgw12_56ab9fbcdfce3"},"id":"rgw12_56ab9fbcdfce3","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorItem.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorItem.html?authorUid=46151520&authorNameOnPublication=JQ%20Quinonero-Candela","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true},{"data":{"authorUrl":"researcher\/43277170_CE_Rasmussen","authorNameOnPublication":"C.E. Rasmussen","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg","imageSize":"s","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"C.E. Rasmussen","profile":{"professionalInstitution":{"professionalInstitutionName":false,"professionalInstitutionUrl":null}},"professionalInstitutionName":false,"professionalInstitutionUrl":null,"url":"researcher\/43277170_CE_Rasmussen","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":true,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":false,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"widgetId":"rgw15_56ab9fbcdfce3"},"id":"rgw15_56ab9fbcdfce3","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAuthorItem.html?entityId=43277170&imageSize=l&enableAuthorInviteButton=0","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"largeTooltip":false,"useRebrandedImageStyle":null,"widgetId":"rgw14_56ab9fbcdfce3"},"id":"rgw14_56ab9fbcdfce3","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorItem.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorItem.html?authorUid=43277170&authorNameOnPublication=C.E.%20Rasmussen","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true}],"hasMore":false,"nextOffset":6,"useRebrandedImageStyle":null,"widgetId":"rgw11_56ab9fbcdfce3"},"id":"rgw11_56ab9fbcdfce3","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorList.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorList.html?publicationUid=41781406&context=pubdetail_authors_xflw&showContactAuthorButton=1","viewClass":"views.publicliterature.PublicationDetailAuthorListView","yuiModules":["rg.views.publicliterature.PublicationDetailAuthorListView"],"stylesheets":[],"_isYUI":true},"publicationAbstract":{"data":{"publicationUid":41781406,"abstract":"<noscript><\/noscript><div>We provide a new unifying view, including all existing proper probabilistic sparse approximations for Gaussian process regression. Our approach relies on expressing the effective prior which the methods are using. This allows new insights to be gained, and highlights the relationship between existing methods. It also allows for a clear theoretically justified ranking of the closeness of the known approximations to the corresponding full GPs. Finally we point directly to designs of new better sparse approximations, combining the best of the existing strategies, within attractive computational constraints.<\/div>","canEdit":false,"isAdmin":false,"isArtifact":false,"showFullAbstract":false,"widgetId":"rgw16_56ab9fbcdfce3"},"id":"rgw16_56ab9fbcdfce3","partials":[],"templateName":"publicliterature\/stubs\/PublicationAbstract.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationAbstract.html?publicationUid=41781406","viewClass":"views.publicliterature.PublicationAbstractView","yuiModules":["rg.views.publicliterature.PublicationAbstractView"],"stylesheets":[],"_isYUI":true},"publicationKeywords":null,"publicationState":null,"isGuest":true,"isAdminEditingAllowed":false,"isArtifact":false,"figureListWidget":null,"previewImage":"https:\/\/i1.rgstatic.net\/publication\/41781406_A_Unifying_View_of_Sparse_Approximate_Gaussian_Process_Regression\/links\/0f316af33829de2215f5a674\/smallpreview.png","nativeAdDisclosure":null,"showFollowPublicationButton":false,"followPublicationPromo":"","widgetId":"rgw8_56ab9fbcdfce3"},"id":"rgw8_56ab9fbcdfce3","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailItem.html","templateExtensions":["generalHelpers"],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailItem.html?publicationUid=41781406&showActionBar=0&showContactAuthorButton=1&showRequestFulltextExperience=0&showNoRgAuthorsRequestFulltextExperience=0&showFollowPublicationPromo=0","viewClass":"views.publicliterature.PublicationDetailItemView","yuiModules":["rg.views.publicliterature.PublicationDetailItemView"],"stylesheets":[],"_isYUI":true},"similarPublications":{"data":{"publicationListItems":[{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":70734799,"url":"researcher\/70734799_Joaquin_Quinonero_Candela","fullname":"Joaquin Qui\u00f1onero Candela","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":43277170,"url":"researcher\/43277170_Carl_Edward_Rasmussen","fullname":"Carl Edward Rasmussen","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Jan 2005","journal":"Journal of Machine Learning Research","showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/220320671_A_Unifying_View_of_Sparse_Approximate_Gaussian_Process_Regression","usePlainButton":true,"publicationUid":220320671,"feedStubs":null,"hasFeedStubs":false,"impactPoints":"2.47","url":"publication\/220320671_A_Unifying_View_of_Sparse_Approximate_Gaussian_Process_Regression","title":"A Unifying View of Sparse Approximate Gaussian Process Regression.","displayTitleAsLink":true,"authors":[{"id":70734799,"url":"researcher\/70734799_Joaquin_Quinonero_Candela","fullname":"Joaquin Qui\u00f1onero Candela","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":43277170,"url":"researcher\/43277170_Carl_Edward_Rasmussen","fullname":"Carl Edward Rasmussen","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["Journal of Machine Learning Research 01\/2005; 6:1939-1959."],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/220320671_A_Unifying_View_of_Sparse_Approximate_Gaussian_Process_Regression","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/220320671_A_Unifying_View_of_Sparse_Approximate_Gaussian_Process_Regression\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw18_56ab9fbcdfce3"},"id":"rgw18_56ab9fbcdfce3","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=220320671","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":72821755,"url":"researcher\/72821755_Valeria_Vitelli","fullname":"Valeria Vitelli","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":8420504,"url":"researcher\/8420504_Enrico_Zio","fullname":"Enrico Zio","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Conference Paper","publicationDate":"Jan 2013","journal":null,"showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/278058976_Approximate_Gaussian_Process_Regression_with_Sparse_Functional_Learning_of_Inducing_Points_for_Components_Condition_Monitoring","usePlainButton":true,"publicationUid":278058976,"feedStubs":null,"hasFeedStubs":false,"impactPoints":false,"url":"publication\/278058976_Approximate_Gaussian_Process_Regression_with_Sparse_Functional_Learning_of_Inducing_Points_for_Components_Condition_Monitoring","title":"Approximate Gaussian Process Regression with Sparse Functional Learning of Inducing Points for Components Condition Monitoring","displayTitleAsLink":true,"authors":[{"id":72821755,"url":"researcher\/72821755_Valeria_Vitelli","fullname":"Valeria Vitelli","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":8420504,"url":"researcher\/8420504_Enrico_Zio","fullname":"Enrico Zio","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["4th IEEE Conference on Prognostics and System Health Management (PHM); 01\/2013"],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Conference Paper","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/278058976_Approximate_Gaussian_Process_Regression_with_Sparse_Functional_Learning_of_Inducing_Points_for_Components_Condition_Monitoring","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/278058976_Approximate_Gaussian_Process_Regression_with_Sparse_Functional_Learning_of_Inducing_Points_for_Components_Condition_Monitoring\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw19_56ab9fbcdfce3"},"id":"rgw19_56ab9fbcdfce3","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=278058976","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":11509338,"url":"researcher\/11509338_Robert_B_Gramacy","fullname":"Robert B. Gramacy","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":46284483,"url":"researcher\/46284483_Jarad_Niemi","fullname":"Jarad Niemi","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2029974425,"url":"researcher\/2029974425_Robin_M_Weiss","fullname":"Robin M. Weiss","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Oct 2013","journal":null,"showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/258082179_Massively_Parallel_Approximate_Gaussian_Process_Regression","usePlainButton":true,"publicationUid":258082179,"feedStubs":null,"hasFeedStubs":false,"impactPoints":false,"url":"publication\/258082179_Massively_Parallel_Approximate_Gaussian_Process_Regression","title":"Massively Parallel Approximate Gaussian Process Regression","displayTitleAsLink":true,"authors":[{"id":11509338,"url":"researcher\/11509338_Robert_B_Gramacy","fullname":"Robert B. Gramacy","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":46284483,"url":"researcher\/46284483_Jarad_Niemi","fullname":"Jarad Niemi","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2029974425,"url":"researcher\/2029974425_Robin_M_Weiss","fullname":"Robin M. Weiss","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["10\/2013; 2(1). DOI:10.1137\/130941912"],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/258082179_Massively_Parallel_Approximate_Gaussian_Process_Regression","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/258082179_Massively_Parallel_Approximate_Gaussian_Process_Regression\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw20_56ab9fbcdfce3"},"id":"rgw20_56ab9fbcdfce3","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=258082179","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"viewClass":"sidebar","widgetId":"rgw17_56ab9fbcdfce3"},"id":"rgw17_56ab9fbcdfce3","partials":[],"templateName":"publicliterature\/stubs\/SimilarPublications.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.SimilarPublications.html?referencePublicationId=41781406&view=sidebar","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationFulltextPreview":null,"publicationResourcesFulltext":{"data":{"publicationUid":41781406,"publicationResourceList":{"data":{"publicationResourceItems":[{"data":{"publicationUid":41781406,"publicationType":"article","linkId":"0f316af33829de2215f5a674","fileName":"A Unifying View of Sparse Approximate Gaussian Process Regression","fileUrl":"http:\/\/lasa.epfl.ch\/teaching\/lectures\/ML_Phd\/readings\/papers\/SparseGP-Quinonero-Candela-Rasmussen05.pdf","name":"epfl.ch","nameUrl":"http:\/\/lasa.epfl.ch\/teaching\/lectures\/ML_Phd\/readings\/papers\/SparseGP-Quinonero-Candela-Rasmussen05.pdf","canRemove":false,"fileIcon":"ico-pub","canPreview":true,"hasPublisherLink":null,"hasMetaData":true,"hide":false,"fulltext":"ico-pub","origin":"publication_list","isLastLink":true,"isUserLink":false,"widgetId":"rgw23_56ab9fbcdfce3"},"id":"rgw23_56ab9fbcdfce3","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceItem.html","templateExtensions":["generalHelpers"],"attrs":{"fileRequiredPublicationTypes":["code","coverPage","experimentFindings","method","negativeResults","presentation","rawData","researchProposal","workingPaper","artifact","dataset"]},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceItem.html?publicationUid=41781406&linkId=0f316af33829de2215f5a674&hide=0&disableJavascript=disableJavascript&useAlternativeTemplate=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"widgetId":"rgw22_56ab9fbcdfce3"},"id":"rgw22_56ab9fbcdfce3","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceList.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceList.html?publicationUid=41781406&limit=3&disableJavascript=disableJavascript&type=fulltextFile","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"resourceCount":1,"hidden":false,"showMore":false,"fulltext":true,"publicationDownloadCount":{"data":{"value":5,"valueFormatted":"5","widgetId":"rgw24_56ab9fbcdfce3"},"id":"rgw24_56ab9fbcdfce3","partials":[],"templateName":"publicliterature\/stubs\/PublicationDownloadCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDownloadCount.html?publicationUid=41781406","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw21_56ab9fbcdfce3"},"id":"rgw21_56ab9fbcdfce3","partials":[],"templateName":"publicliterature\/stubs\/PublicationResources.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResources.html?publicationUid=41781406&type=fulltextFile&disableJavascript=1","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationResourcesAttachments":{"data":{"publicationUid":41781406,"publicationResourceList":{"data":{"publicationResourceItems":[],"widgetId":"rgw26_56ab9fbcdfce3"},"id":"rgw26_56ab9fbcdfce3","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceList.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceList.html?publicationUid=41781406&limit=3&disableJavascript=disableJavascript&type=attachmentFile","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"resourceCount":0,"hidden":true,"showMore":false,"fulltext":false,"publicationDownloadCount":{"data":{"value":5,"valueFormatted":"5","widgetId":"rgw27_56ab9fbcdfce3"},"id":"rgw27_56ab9fbcdfce3","partials":[],"templateName":"publicliterature\/stubs\/PublicationDownloadCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDownloadCount.html?publicationUid=41781406","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw25_56ab9fbcdfce3"},"id":"rgw25_56ab9fbcdfce3","partials":[],"templateName":"publicliterature\/stubs\/PublicationResources.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResources.html?publicationUid=41781406&type=attachmentFile","viewClass":"views.publicliterature.PublicationResourcesView","yuiModules":["rg.views.publicliterature.PublicationResourcesView"],"stylesheets":[],"_isYUI":true},"publicationText":{"data":{"hide":false,"pages":[{"page":1,"text":"Journal of Machine Learning Research 6 (2005) 1939\u20131959Submitted 10\/05; Published 12\/05\nA Unifying View of Sparse\nApproximate Gaussian Process Regression\nJoaquin Qui\u02dc nonero-Candela\nCarl Edward Rasmussen\nMax Planck Institute for Biological Cybernetics\nSpemannstra\u00dfe 38\n72076 T\u00a8 ubingen, Germany\nJQC@TUEBINGEN.MPG.DE\nCARL@TUEBINGEN.MPG.DE\nEditor: Ralf Herbrich\nAbstract\nWe provide a new unifying view, including all existing proper probabilistic sparse approximations\nfor Gaussian process regression. Our approach relies on expressing the effective prior which the\nmethods are using. This allows new insights to be gained, and highlights the relationship between\nexisting methods. It also allows for a clear theoretically justified ranking of the closeness of the\nknown approximations to the corresponding full GPs. Finally we point directly to designs of new\nbetter sparse approximations, combining the best of the existing strategies, within attractive com-\nputational constraints.\nKeywords: Gaussian process, probabilistic regression, sparse approximation, Bayesian committee\nmachine\nRegression models based on Gaussian processes (GPs) are simple to implement, flexible, fully\nprobabilistic models, and thus a powerful tool in many areas of application. Their main limitation\nis that memory requirements and computational demands grow as the square and cube respectively,\nof the number of training cases n, effectively limiting a direct implementation to problems with\nat most a few thousand cases. To overcome the computational limitations numerous authors have\nrecently suggested a wealth of sparse approximations. Common to all these approximation schemes\nis that only a subset of the latent variables are treated exactly, and the remaining variables are given\nsome approximate, but computationally cheaper treatment. However, the published algorithms have\nwidely different motivations, emphasis and exposition, so it is difficult to get an overview (see\nRasmussen and Williams, 2006, chapter 8) of how they relate to each other, and which can be\nexpected to give rise to the best algorithms.\nIn this paper we provide a unifying view of sparse approximations for GP regression. Our\napproach is simple, but powerful: for each algorithm we analyze the posterior, and compute the\neffective prior which it is using. Thus, we reinterpret the algorithms as \u201cexact inference with an\napproximated prior\u201d, rather than the existing (ubiquitous) interpretation \u201capproximate inference\nwith the exact prior\u201d. This approach has the advantage of directly expressing the approximations in\nterms of prior assumptions about the function, which makes the consequences of the approximations\nmuch easier to understand. While our view of the approximations is not the only one possible, it has\nthe advantage of putting all existing probabilistic sparse approximations under one umbrella, thus\nenabling direct comparison and revealing the relation between them.\nIn Section 1 we briefly introduce GP models for regression. In Section 2 we present our uni-\nfying framework and write out the key equations in preparation for the unifying analysis of sparse\nc ?2005 Joaquin Qui\u02dc nonero-Candela and Carl Edward Rasmussen."},{"page":2,"text":"QUI\u02dc NONERO-CANDELA AND RASMUSSEN\nalgorithms in Sections 4-7. The relation of transduction and augmentation to our sparse framework\nis covered in Section 8. All our approximations are written in terms of a new set of inducing vari-\nables. The choice of these variables is itself a challenging problem, and is discussed in Section\n9. We comment on a few special approximations outside our general scheme in Section 10 and\nconclusions are drawn at the end.\n1. Gaussian Processes for Regression\nProbabilistic regression is usually formulated as follows: given a training set D = {(xi,yi),i =\n1,...,n} of n pairs of (vectorial) inputs xiand noisy (real, scalar) outputs yi, compute the predictive\ndistribution of the function values f\u2217(or noisy y\u2217) at test locations x\u2217. In the simplest case (which\nwe deal with here) we assume that the noise is additive, independent and Gaussian, such that the\nrelationship between the (latent) function f(x) and the observed noisy targets y are given by\nyi = f(xi)+\u03b5i,\nwhere\n\u03b5i \u223c N (0, \u03c32\nnoise) ,\n(1)\nwhere \u03c32\nnoiseis the variance of the noise.\nDefinition 1 A Gaussian process (GP) is a collection of random variables, any finite number of\nwhich have consistent1joint Gaussian distributions.\nGaussian process (GP) regression is a Bayesian approach which assumes a GP prior2over functions,\ni.e. assumes a priori that function values behave according to\np(f|x1,x2,...,xn) = N (0, K) ,\n(2)\nwhere f = [f1, f2,..., fn]?is a vector of latent function values, fi= f(xi) and K is a covariance ma-\ntrix, whose entries are given by the covariance function, Kij= k(xi,xj). Note that the GP treats the\nlatent function values fias random variables, indexed by the corresponding input. In the following,\nfor simplicity we will always neglect the explicit conditioning on the inputs; the GP model and all\nexpressions are always conditional on the corresponding inputs. The GP model is concerned only\nwith the conditional of the outputs given the inputs; we do not model anything about the inputs\nthemselves.\nRemark 2 Note, that to adhere to a strict Bayesian formalism, the GP covariance function,3which\ndefines the prior, should not depend on the data (although it can depend on additional parameters).\nAs we will see in later sections, some approximations are strictly equivalent to GPs, while others\nare not. That is, the implied prior may still be multivariate Gaussian, but the covariance function\nmay be different for training and test cases.\nDefinition 3 AGaussianprocessiscalled degenerateiffthecovariancefunctionhasafinitenumber\nof non-zero eigenvalues.\n1. By consistency is meant simply that the random variables obey the usual rules of marginalization, etc.\n2. For notational simplicity we exclusively use zero-mean priors.\n3. The covariance function itself shouldn\u2019t depend on the data, though its value at a specific pair of inputs of course will.\n1940"},{"page":3,"text":"SPARSE APPROXIMATE GAUSSIAN PROCESS REGRESSION\nDegenerate GPs (such as e.g. with polynomial covariance function) correspond to finite linear\n(-in-the-parameters) models, whereas non-degenerate GPs (such as e.g. with squared exponential\nor RBF covariance function) do not. The prior for a finite m dimensional linear model only consid-\ners a universe of at most m linearly independent functions; this may often be too restrictive when\nn ? m. Note however, that non-degeneracy on its own doesn\u2019t guarantee the existence of the \u201cright\nkind\u201d of flexibility for a given particular modelling task. For a more detailed background on GP\nmodels, see for example that of Rasmussen and Williams (2006).\nInference in the GP model is simple: we put a joint GP prior on training and test latent values, f\nand f\u22174, and combine it with the likelihood5p(y|f) using Bayes rule, to obtain the joint posterior\np(f,f\u2217)p(y|f)\np(f,f\u2217|y) =\np(y)\n.\n(3)\nThe final step needed to produce the desired posterior predictive distribution is to marginalize out\nthe unwanted training set latent variables:\np(f\u2217|y) =\nZ\np(f,f\u2217|y)df =\n1\np(y)\nZ\np(y|f)p(f,f\u2217)df ,\n(4)\nor in words: the predictive distribution is the marginal of the renormalized joint prior times the\nlikelihood. The joint GP prior and the independent likelihood are both Gaussian\np(f,f\u2217) = N\n?\n0,\n?Kf,f\nK\u2217,f\nK\u2217,\u2217\nKf,\u2217\n??\n,\nand\np(y|f) = N (f, \u03c32\nnoiseI) ,\n(5)\nwhere K is subscript by the variables between which the covariance is computed (and we use the\nasterisk \u2217 as shorthand for f\u2217) and I is the identity matrix. Since both factors in the integral are\nGaussian, the integral can be evaluated in closed form to give the Gaussian predictive distribution\np(f\u2217|y) = N?K\u2217,f(Kf,f+\u03c32\nsee the relevant Gaussian identity in appendix A. The problem with the above expression is that it\nrequires inversion of a matrix of size n\u00d7n which requires O(n3) operations, where n is the number\nof training cases. Thus, the simple exact implementation can handle problems with at most a few\nthousand training cases.\nnoiseI)\u22121y, K\u2217,\u2217\u2212K\u2217,f(Kf,f+\u03c32\nnoiseI)\u22121Kf,\u2217\n?,\n(6)\n2. A New Unifying View\nWe now seek to modify the joint prior p(f\u2217,f) from (5) in ways which will reduce the computational\nrequirements from (6). Let us first rewrite that prior by introducing an additional set of m latent\nvariables u = [u1,...,um]?, which we call the inducing variables. These latent variables are values\nof the Gaussian process (as also f and f\u2217), corresponding to a set of input locations Xu, which we\ncall the inducing inputs. Whereas the additional latent variables u are always marginalized out in\nthe predictive distribution, the choice of inducing inputs does leave an imprint on the final solution.\n4. We will mostly consider a vector of test cases f\u2217(rather than a single f\u2217).\n5. You may have been expecting the likelihood written as p(y|f\u2217,f) but since the likelihood is conditionally independent\nof everything else given f, this makes no difference.\n1941"},{"page":4,"text":"QUI\u02dc NONERO-CANDELA AND RASMUSSEN\nThe inducing variables will turn out to be generalizations of variables which other authors have re-\nferred to variously as \u201csupport points\u201d, \u201cactive set\u201d or \u201cpseudo-inputs\u201d. Particular sparse algorithms\nchoose the inducing variables in various different ways; some algorithms chose the inducing inputs\nto be a subset of the training set, others not, as we will discuss in Section 9. For now consider any\narbitrary inducing variables.\nDue to the consistency of Gaussian processes, we know that we can recover p(f\u2217,f) by simply\nintegrating (marginalizing) out u from the joint GP prior p(f\u2217,f,u)\np(f\u2217,f) =\nZ\np(f\u2217,f,u)du =\nZ\np(f\u2217,f|u)p(u)du,\nwhere\np(u) = N (0, Ku,u) .\n(7)\nThis is an exact expression. Now, we introduce the fundamental approximation which gives rise\nto almost all sparse approximations. We approximate the joint prior by assuming that f\u2217and f are\nconditionally independent given u, see Figure 1, such that\np(f\u2217,f) ? q(f\u2217,f) =\nZ\nq(f\u2217|u)q(f|u)p(u)du .\n(8)\nThe name inducing variable is motivated by the fact that f and f\u2217can only communicate though\nu, and u therefore induces the dependencies between training and test cases. As we shall detail in\nthe following sections, the different computationally efficient algorithms proposed in the literature\ncorrespond to different additional assumptions about the two approximate inducing conditionals\nq(f|u), q(f\u2217|u) of the integral in (8). It will be useful for future reference to specify here the exact\nexpressions for the two conditionals\ntraining conditional:\np(f|u) = N (Kf,uK\u22121\np(f\u2217|u) =N (K\u2217,uK\u22121\nu,uu, Kf,f\u2212Qf,f) ,\nu,uu, K\u2217,\u2217\u2212Q\u2217,\u2217) ,\n(9a)\ntest conditional: (9b)\nwhere we have introduced the shorthand notation6Qa,b? Ka,uK\u22121\nexpressions in (9) as special (noise free) cases of the standard predictive equation (6) with u playing\nthe role of (noise free) observations. Note that the (positive semi-definite) covariance matrices in (9)\nhave the form K\u2212Q with the following interpretation: the prior covariance K minus a (non-negative\ndefinite) matrixQ quantifyinghow much informationu provides about thevariables in question(for\nf\u2217). We emphasize that all the sparse methods discussed in the paper correspond simply to different\napproximations to the conditionals in (9), and throughout we use the exact likelihood and inducing\nprior\np(y|f) = N (f, \u03c32\nu,uKu,b. We can readily identify the\nnoiseI) ,\nand\np(u) =N (0, Ku,u) .\n(10)\n3. The Subset of Data (SoD) Approximation\nBefore we get started with the more sophisticated approximations, we mention as a baseline method\nthe simplest possible sparse approximation (which doesn\u2019t fall inside our general scheme): use\nonly a subset of the data (SoD). The computational complexity is reduced to O(m3), where m < n.\nWe would not generally expect SoD to be a competitive method, since it would seem impossible\n(even with fairly redundant data and a good choice of the subset) to get a realistic picture of the\n6. Note, that Qa,bdepends on u although this is not explicit in the notation.\n1942"},{"page":5,"text":"SPARSE APPROXIMATE GAUSSIAN PROCESS REGRESSION\n?\n?\n?\n?\n??\n?\n?\n?\n?\n??\nA\nA\nA\nA\nAA\nQ\nQ\nQ\nQ\nQ\nQ\nQ\nQ\nQ\nu\nf1\nf2\nr r r\nfn\nf\u2217\nrr\n?\n?\n?\n?\n??\n?\n?\n?\n?\n??\nA\nA\nA\nA\nAA\nQ\nQ\nQ\nQ\nQ\nQ\nQ\nQ\nQ\nu\nf1\nf2\nr r r\nfn\nf\u2217\nrr\nFigure 1: Graphical model of the relation between the inducing variables u, the training latent func-\ntions values f = [f1,..., fn]?and the test function value f\u2217. The thick horizontal line rep-\nresents a set of fully connected nodes. The observations y1,...,yn,y\u2217(not shown) would\ndangle individually from the corresponding latent values, by way of the exact (factored)\nlikelihood (5). Left graph: the fully connected graph corresponds to the case where\nno approximation is made to the full joint Gaussian process distribution between these\nvariables. The inducing variables u are superfluous in this case, since all latent func-\ntion values can communicate with all others. Right graph: assumption of conditional\nindependence between training and test function values given u. This gives rise to the\nseparation between training and test conditionals from (8). Notice that having cut the\ncommunication path between training and test latent function values, information from f\ncan only be transmitted to f\u2217via the inducing variables u.\nuncertainties, when only a part of the training data is even considered. We include it here mostly as\na baseline against which to compare better sparse approximations.\nIn Figure 5 top, left we see how the SoD method produces wide predictive distributions, when\ntraining on a randomly selected subset of 10 cases. A fair comparison to other methods would\ntake into account that the computational complexity is independent of n as opposed to other more\nadvanced methods. These extra computational resources could be spent in a number of ways,\ne.g. larger m, or an active (rather than random) selection of the m points. In this paper we will\nconcentrate on understanding the theoretical foundations of the various approximations rather than\ninvestigating the necessary heuristics needed to turn the approximation schemes into actually prac-\ntical algorithms.\n4. The Subset of Regressors (SoR) Approximation\nThe Subset of Regressors (SoR) algorithm was given by Silverman (1985), and mentioned again by\nWahba et al. (1999). It was then adapted by Smola and Bartlett (2001) to propose a sparse greedy\napproximation to Gaussian process regression. SoR models are finite linear-in-the-parameters mod-\nels with a particular prior on the weights. For any input x\u2217, the corresponding function value f\u2217is\ngiven by:\nf\u2217 = K\u2217,uwu,\nwith\np(wu) = N (0, K\u22121\nu,u) ,\n(11)\nwhere there is one weight associated to each inducing input in Xu. Note that the covariance matrix\nfor the prior on the weights is the inverse of that on u, such that we recover the exact GP prior on u,\n1943"},{"page":6,"text":"QUI\u02dc NONERO-CANDELA AND RASMUSSEN\nwhich is Gaussian with zero mean and covariance\nu = Ku,uwu \u21d2 ?uu?? = Ku,u?wuw?\nu?Ku,u = Ku,u.\nu,uu we can redefine the SoR model in an\n(12)\nUsing the effective prior on u and the fact that wu= K\u22121\nequivalent, more intuitive way:\nf\u2217 = K\u2217,uK\u22121\nu,uu ,\nwith\nu \u223c N (0, Ku,u) .\n(13)\nWe are now ready to integrate the SoR model in our unifying framework. Given that there is a\ndeterministic relation between any f\u2217and u, the approximate conditional distributions in the integral\nin eq. (8) are given by:\nqSoR(f|u) = N (Kf,uK\u22121\nwith zero conditional covariance, compare to (9). The effective prior implied by the SoR approxi-\nmation is easily obtained from (8), giving\nu,uu, 0) ,\nand\nqSoR(f\u2217|u) = N (K\u2217,uK\u22121\nu,uu, 0) ,\n(14)\nqSoR(f,f\u2217) = N\n?\n0,\n?Qf,f\nQf,\u2217\nQ\u2217,\u2217\nQ\u2217,f\n??\n,\n(15)\nwhere we recall Qa,b? Ka,uK\u22121\nDeterministic Inducing Conditional (DIC) approximation. We see that this approximate prior is\ndegenerate. There are only m degrees of freedom in the model, which implies that only m linearly\nindependent functions can be drawn from the prior. The m+1-th one is a linear combination of the\nprevious. For example, in a very low noise regime, the posterior could be severely constrained by\nonly m training cases.\nThe degeneracy of the prior causes unreasonable predictive distributions. Indeed, the approx-\nimate prior over functions is so restrictive, that given enough data only a very limited family of\nfunctions will be plausible under the posterior, leading to overconfident predictive variances. This\nis a general problem of finite linear models with small numbers of weights (for more details see\nRasmussen and Qui\u02dc nonero-Candela, 2005). Figure 5, top, right panel, illustrates the unreasonable\npredictive uncertainties of the SoR approximation on a toy dataset.7\nThe predictive distribution is obtained by using the SoR approximate prior (15) instead of the\ntrue prior in (4). For each algorithm we give two forms of the predictive distribution, one which is\neasy to interpret, and the other which is economical to compute with:\nu,uKu,b. A more descriptive name for this method, would be the\nqSoR(f\u2217|y) = N?Q\u2217,f(Qf,f+\u03c32\n= N?\u03c3\u22122K\u2217,u\u03a3Ku,fy, K\u2217,u\u03a3Ku,\u2217\nwhere we have defined \u03a3 = (\u03c3\u22122Ku,fKf,u+Ku,u)\u22121. Equation (16a) is readily recognized as the\nregular prediction equation (6), except that the covariance K has everywhere been replaced by Q,\nwhich was already suggested by (15). This corresponds to replacing the covariance function k with\nkSoR(xi,xj)=k(xi,u)K\u22121\nthe following\nnoiseI)\u22121y, Q\u2217,\u2217\u2212Q\u2217,f(Qf,f+\u03c32\n?,\nnoiseI)\u22121Qf,\u2217\n?,\n(16a)\n(16b)\nu,uk(u,xj). The new covariance function has rank (at most) m. Thus we have\n7. Wary of this fact, Smola and Bartlett (2001) propose using the predictive variances of the SoD, or a more accurate\ncomputationally costly alternative (more details are given by Qui\u02dc nonero-Candela, 2004, Chapter 3).\n1944"},{"page":7,"text":"SPARSE APPROXIMATE GAUSSIAN PROCESS REGRESSION\nRemark 4 The SoR approximation is equivalent to exact inference in the degenerate Gaussian\nprocess with covariance function kSoR(xi,xj) = k(xi,u)K\u22121\nThe equivalent (16b) is computationally cheaper, and with (11) in mind, \u03a3 is the covariance of the\nposterior on the weights wu. Note that as opposed to the subset of data method, all training cases\nare taken into account. The computational complexity is O(nm2) initially, and O(m) and O(m2) per\ntest case for the predictive mean and variance respectively.\nu,uk(u,xj).\n5. The Deterministic Training Conditional (DTC) Approximation\nTaking up ideas already contained in the work of Csat\u00b4 o and Opper (2002), Seeger et al. (2003)\nrecently proposed another sparse approximation to Gaussian process regression, which does not\nsuffer from the nonsensical predictive uncertainties of the SoR approximation, but that interestingly\nleads to exactly the same predictive mean. Seeger et al. (2003), who called the method Projected\nLatent Variables (PLV), presented the method as relying on a likelihood approximation, based on\nthe projection f = Kf,uK\u22121\nu,uu:\np(y|f) ? q(y|u) = N (Kf,uK\u22121\nu,uu, \u03c32\nnoiseI) .\n(17)\nThe method has also been called the Projected Process Approximation (PPA) by Rasmussen and\nWilliams (2006, Chapter 8). One way of obtaining an equivalent model is to retain the usual likeli-\nhood, but to impose a deterministic training conditional and the exact test conditional from eq. (9b)\nqDTC(f|u) = N (Kf,uK\u22121\nu,uu,0),\nand\nqDTC(f\u2217|u) = p(f\u2217|u) .\n(18)\nThis reformulation has the advantage of allowing us to stick to our view of exact inference (with\nexact likelihood) with approximate priors. Indeed, under this model the conditional distribution\nof f given u is identical to that of the SoR, given in the left of (14). A systematic name for this\napproximation is the Deterministic Training Conditional (DTC).\nThe fundamental difference with SoR is that DTC uses the exact test conditional (9b) instead of\nthe deterministic relation between f\u2217and u of SoR. The joint prior implied by DTC is given by:\nqDTC(f,f\u2217) = N\n?\n0,\n?Qf,f\nQf,\u2217\nK\u2217,\u2217\nQ\u2217,f\n??\n,\n(19)\nwhich is surprisingly similar to the effective prior implied by the SoR approximation (15). The\nfundamental difference is that under the DTC approximation f\u2217has a prior variance of its own,\ngiven by K\u2217,\u2217. This prior variance reverses the behaviour of the predictive uncertainties, and turns\nthem into sensible ones, see Figure 5 for an illustration.\nThe predictive distribution is now given by:\nqDTC(f\u2217|y) = N (Q\u2217,f(Qf,f+\u03c32\n= N?\u03c3\u22122K\u2217,u\u03a3Ku,fy, K\u2217,\u2217\u2212Q\u2217,\u2217+K\u2217,u\u03a3K?\nwhere again we have defined \u03a3 = (\u03c3\u22122Ku,fKf,u+Ku,u)\u22121as in (16). The predictive mean for the\nDTC is identical to that of the SoR approximation (16), but the predictive variance replaces the Q\u2217,\u2217\nfrom SoR with K\u2217,\u2217(which is larger, since K\u2217,\u2217\u2212Q\u2217,\u2217is positive definite). This added term is the\npredictive variance of the posterior of f\u2217conditioned on u. It grows to the prior variance K\u2217,\u2217as x\u2217\nmoves far from the inducing inputs in Xu.\nnoiseI)\u22121y, K\u2217,\u2217\u2212Q\u2217,f(Qf,f+\u03c32\nnoiseI)\u22121Qf,\u2217\n(20a)\n\u2217,u\n?,\n(20b)\n1945"},{"page":8,"text":"QUI\u02dc NONERO-CANDELA AND RASMUSSEN\n?\n?\n?\n?\n??\n?\n?\n?\n?\n??\nA\nA\nA\nA\nAA\nQ\nQ\nQ\nQ\nQ\nQ\nQ\nQ\nQ\nu\nf1\nf2\nr r r\nfn\nf\u2217\nFigure 2: Graphical model for the FITC approximation. Compared to those in Figure 1, all edges\nbetween latent function values have been removed: the latent function values are con-\nditionally fully independent given the inducing variables u. Although strictly speaking\nthe SoR and DTC approximations could also be represented by this graph, note that both\nfurther assume a deterministic relation between f and u.\nRemark 5 The only difference between the predictive distribution of DTC and SoR is the variance.\nThe predictive variance of DTC is never smaller than that of SoR.\nNote, that since the covariances for training cases and test cases are computed differently, see (19),\nit follows that\nRemark 6 The DTC approximation does not correspond exactly to a Gaussian process,\nas the covariance between latent values depends on whether they are considered training or test\ncases, violating consistency, see Definition 1. The computational complexity has the same order as\nfor SoR.\n6. The Fully Independent Training Conditional (FITC) Approximation\nRecently Snelson and Ghahramani (2006) proposed another likelihood approximation to speed up\nGaussian process regression, which they called Sparse Gaussian Processes using Pseudo-inputs\n(SGPP). While the DTC is based on the likelihood approximation given by (17), the SGPP proposes\na more sophisticated likelihood approximation with a richer covariance\np(y|f) ? q(y|u) = N (Kf,uK\u22121\nu,uu, diag[Kf,f\u2212Qf,f]+\u03c32\nnoiseI) ,\n(21)\nwhere diag[A] is a diagonal matrix whose elements match the diagonal of A. As we did in (18)\nfor the DTC, we provide an alternative equivalent formulation called Fully Independent Training\nConditional (FITC) based on the inducing conditionals:\nqFITC(f|u) =\nn\n\u220f\ni=1\np(fi|u) = N?Kf,uK\u22121\nu,uu, diag[Kf,f\u2212Qf,f]?, and qFITC(f\u2217|u) = p(f\u2217|u). (22)\nWe see that as opposed to SoR and DTC, FITC does not impose a deterministic relation between f\nand u. Instead of ignoring the variance, FITC proposes an approximation to the training conditional\ndistribution of f given u as a further independence assumption. In addition, the exact test conditional\nfrom (9b) is used in (22), although for reasons which will become clear towards the end of this\n1946"},{"page":9,"text":"SPARSE APPROXIMATE GAUSSIAN PROCESS REGRESSION\nsection, we initially consider only a single test case, f\u2217. The corresponding graphical model is given\nin Figure 2. The effective prior implied by the FITC is given by\nqFITC(f, f\u2217) = N\n?\n0,\n?Qf,f\u2212diag[Qf,f\u2212Kf,f]\nQf,\u2217\nK\u2217,\u2217\nQ\u2217,f\n??\n.\n(23)\nNote, that the sole difference between the DTC and FITC is that in the top left corner of the implied\nprior covariance, FITC replaces the approximate covariances of DTC by the exact ones on the\ndiagonal. The predictive distribution is\nqFITC(f\u2217|y) = N?Q\u2217,f(Qf,f+\u039b)\u22121y, K\u2217,\u2217\u2212Q\u2217,f(Qf,f+\u039b)\u22121Qf,\u2217\n= N?K\u2217,u\u03a3Ku,f\u039b\u22121y, K\u2217,\u2217\u2212Q\u2217,\u2217+K\u2217,u\u03a3Ku,\u2217\nwhere we have defined \u03a3 = (Ku,u+Ku,f\u039b\u22121Kf,u)\u22121and \u039b = diag[Kf,f\u2212Qf,f+\u03c32\ntational complexity is identical to that of SoR and DTC.\nSo far we have only considered a single test case. There are two options for joint predictions,\neither 1) use the exact full test conditional from (9b), or 2) extend the additional factorizing as-\nsumption to the test conditional. Although Snelson and Ghahramani (2006) don\u2019t explicitly discuss\njoint predictions, it would seem that they probably intend the second option. Whereas the addi-\ntional independence assumption for the test cases is not really necessary for computational reasons,\nit does affect the nature of the approximation. Under option 1) the training and test covariance are\ncomputed differently, and thus this does not correspond to our strict definition of a GP model, but\n?\n(24a)\n?,\n(24b)\nnoiseI]. The compu-\nRemark 7 Iff the assumption of full independence is extended to the test conditional, the FITC ap-\nproximation is equivalent to exact inference in a non-degenerate Gaussian process with covariance\nfunction kFIC(xi,xj) = kSoR(xi,xj)+\u03b4i,j[k(xi,xj)\u2212kSoR(xi,xj)],\nwhere \u03b4i,jis Kronecker\u2019s delta. A logical name for the method where the conditionals (training and\ntest) are always forced to be fully independent would be the Fully Independent Conditional (FIC)\napproximation. The effective prior implied by FIC is:\nqFIC(f,f\u2217) = N\n?\n0,\n?Qf,f\u2212diag[Qf,f\u2212Kf,f]\nQf,\u2217\nQ\u2217,f\nQ\u2217,\u2217\u2212diag[Q\u2217,\u2217\u2212K\u2217,\u2217]\n??\n.\n(25)\n7. The Partially Independent Training Conditional (PITC) Approximation\nIn the previous section we saw how to improve the DTC approximation by approximating the train-\ning conditional with an independent distribution, i.e. one with a diagonal covariance matrix. In this\nsection we will further improve the approximation (while remaining computationally attractive) by\nextending the training conditional to have a block diagonal covariance:\nqPITC(f|u) = N?Kf,uK\u22121\nwhere blockdiag[A] is a block diagonal matrix (where the blocking structure is not explicitly stated).\nWe represent graphically the PITC approximation in Figure 3. Developing this analogously to the\nFITC approximation from the previous section, we get the joint prior\nu,uu, blockdiag[Kf,f\u2212Qf,f]?,\nand\nqPITC(f\u2217|u) = p(f\u2217|u) .\n(26)\nqPITC(f, f\u2217) = N\n?\n0,\n?Qf,f\u2212blockdiag[Qf,f\u2212Kf,f]\nQf,\u2217\nK\u2217,\u2217\nQ\u2217,f\n??\n,\n(27)\n1947"},{"page":10,"text":"QUI\u02dc NONERO-CANDELA AND RASMUSSEN\n?\n?\n?\n?\n??\n?\n?\n?\n?\n??\nA\nfIk\nA\nA\nA\nAA\nQ\nQ\nQ\nQ\nQ\nQ\nQ\nQ\nQ\nu\nfI1\nfI2\nr r r\nf\u2217\nFigure 3: Graphical representation of the PITC approximation. The set of latent function values fIi\nindexed by the the set of indices Iiis fully connected. The PITC differs from FITC (see\ngraph in Fig. 2) in that conditional independence is now between the k groups of training\nlatent function values. This corresponds to the block diagonal approximation to the true\ntraining conditional given in (26).\nand the predictive distribution is identical to (24), except for the alternative definition of \u039b =\nblockdiag[Kf,f\u2212Qf,f+\u03c32\n(2003, Sect. 3), developing from the original Bayesian committee machine (BCM) by Tresp (2000).\nThe relationship to the FITC was pointed out by Lehel Csat\u00b4 o. The BCM was originally proposed as\na transductive learner (i.e. where the test inputs have to be known before training), and the inducing\ninputs Xuwere chosen to be the test inputs. We discuss transduction in detail in the next section.\nIt is important to realize that the BCM proposes two orthogonal ideas: first, the block diagonal\nstructure of the partially independent training conditional, and second setting the inducing inputs to\nbe the test inputs. These two ideas can be used independently and in Section 8 we propose using\nthe first without the second.\nThe computational complexity of the PITC approximation depends on the blocking structure\nimposed in (26). A reasonable choice, also recommended by Tresp (2000) may be to choose\nk = n\/m blocks, each of size m\u00d7m. The computational complexity remains O(nm2). Since in\nthe PITC model the covariance is computed differently for training and test cases\nnoiseI]. An identical expression was obtained by Schwaighofer and Tresp\nRemark 8 The PITC approximation does not correspond exactly to a Gaussian process.\nThis is because computing covariances requires knowing whether points are from the training- or\ntest-set, (27). One can obtain a Gaussian process from the PITC by extending the partial conditional\nindependence assumption to the test conditional, as we did in Remark 7 for the FITC.\n8. Transduction and Augmentation\nThe idea of transduction is that one should restrict the goal of learning to prediction on a pre-\nspecified set of test cases, rather than trying to learn an entire function (induction) and then evaluate\nit at the test inputs. There may be no universally agreed upon definition of transduction. In this\npaper we use\nDefinition 9 Transduction occurs only if the predictive distribution depends on other test inputs.\nThis operational definition excludes models for which there exist an equivalent inductive counter-\npart. According to this definition, it is irrelevant when the bulk of the computation takes place.\n1948"},{"page":11,"text":"SPARSE APPROXIMATE GAUSSIAN PROCESS REGRESSION\n?\n?\n?\n?\n??\n?\n?\n?\n?\n?\n??\nA\nfIk\nA\nA\nA\nAA\n?\n???????? ?\nfI2\n?\n?\n??\nu\nfI1\nr r r\nf\u2217\nFigure 4: Two views on Augmentation. One view is to see that the test latent function value f\u2217\nis now part of the inducing variables u and therefore has access to the training latent\nfunction values. An equivalent view is to consider that we have dropped the assumption\nof conditional independence between f\u2217and the training latent function values. Even if\nf\u2217has now direct access to each of the training fi, these still need to go through u to\ntalk to each other if they fall in conditionally independent blocks. We have in this figure\ndecided to recycle the graph for PITC from Figure 3 to show that all approximations we\nhave presented can be augmented, irrespective of what the approximation for the training\nconditional is.\nThere are several different possible motivations for transduction: 1) transduction is somehow\neasier than induction (Vapnik, 1995), 2) the test inputs may reveal important information, which\nshould be used during training. This motivation drives models in semi-supervised learning (studied\nmostly in the context of classification) and 3) for approximate algorithms one may be able to limit\nthe discrepancies of the approximation at the test points.\nFor exact GP models it seems that the first reason doesn\u2019t really apply. If you make predictions\nat the test points that are consistent with a GP, then it is trivial inside the GP framework to extend\nthese to any other input points, and in effect we have done induction.\nThe second reason seems more interesting. However, in a standard GP setting, it is a conse-\nquence of the consistency property, see Remark 2, that predictions at one test input are independent\nof the location of any other test inputs. Therefore transduction can not be married with exact GPs:\nRemark 10 Transduction can not occur in exact Gaussian process models.\nWhereas this holds for the usual setting of GPs, it could be different in non-standard situations\nwhere e.g. the covariance function depends on the empirical input densities.\nTransduction can occur in the sparse approximation to GPs, by making the choice of inducing\nvariables depend on the test inputs. The BCM from the previous section, where Xu= X\u2217(where\nX\u2217are the test inputs) is an example of this. Since the inducing variables are connected to all other\nnodes (see Figure 3) we would expect the approximation to be good at u=f\u2217, which is what we care\nabout for predictions, relating to reason 3) above. While this reasoning is sound, it is not necessarily\na sufficient consideration for getting a good model. The model has to be able to simultaneously\nexplain the training targets as well and if the choice of u makes this difficult, the posterior at the\npoints of interest may be distorted. Thus, the choice of u should be governed by the ability to model\nthe conditional of the latents given the inputs, and not solely by the density of the (test) inputs.\nThe main drawback of transduction is that by its nature it doesn\u2019t provide a predictive model\nin the way inductive models do. In the usual GP model one can do the bulk of the computation\n1949"},{"page":12,"text":"QUI\u02dc NONERO-CANDELA AND RASMUSSEN\ninvolved in the predictive distributions (e.g. matrix inversion) before seeing the test cases, enabling\nfast computation of test predictions.\nIt is interesting that whereas other methods spend much effort trying to optimize the inducing\nvariables, the BCM simply uses the test set. The quality of the BCM approximation depends then\non the particular location of the test inputs, upon which one usually does not have any control. We\nnow see that there may be a better method, eliminating the drawback of transduction, namely use\nthe PITC approximation, but choose the u\u2019s carefully (see Section 9), don\u2019t just use the test set.\n8.1 Augmentation\nAn idea closely related to transduction, but not covered by our definition, is augmentation, which\nin contrast to transduction is done individually for each test case. Since in the previous sections,\nwe haven\u2019t assumed anything about u, we can simply augment the set of inducing variables by f\u2217\n(i.e. have one additional inducing variable equal to the current test latent), and see what happens\nin the predictive distributions for the different methods. Let\u2019s first investigate the consequences\nfor the test conditional from (9b). Note, the interpretation of the covariance matrix K\u2217,\u2217\u2212Q\u2217,\u2217\nwas \u201cthe prior covariance minus the information which u provides about f\u2217\u201d. It is clear that the\naugmented u (with f\u2217) provides all possible information about f\u2217, and consequently Q\u2217,\u2217= K\u2217,\u2217.\nAn equivalent view on augmentation is that the assumption of conditional independence between\nf\u2217and f is dropped. This is seen trivially by adding edges between f\u2217and the fiin the graphical\nmodel, Figure 4.\nAugmentation was originally proposed by Rasmussen (2002), and applied in detail to the SoR\nwith RBF covariance by Qui\u02dc nonero-Candela (2004). Because the SoR is a finite linear model, and\nthe basis functions are local (Gaussian bumps), the predictive distributions can be very misleading.\nFor example, when making predictions far away from the center of any basis function, all basis\nfunctions have insignificant magnitudes, and the prediction (averaged over the posterior) will be\nclose to zero, with very small error-bars; this is the opposite of the desired behaviour, where we\nwould expect the error-bars to grow as we move away from the training cases. Here augmentation\nmakes a particularly big difference turning the nonsensical predictive distribution into a reasonable\none, by ensuring that there is always a basis function centered on the test case. Compare the non-\naugmented to the augmented SoR in Figure 5. An analogous Gaussian process based finite linear\nmodel that has recently been healed by augmentation is the relevance vector machine (Rasmussen\nand Qui\u02dc nonero-Candela, 2005).\nAlthough augmentation was initially proposed for a narrow set of circumstances, it is easily\napplied to any of the approximations discussed. Of course, augmentation doesn\u2019t make any sense\nfor an exact, non-degenerate Gaussian process model (a GP with a covariance function that has a\nfeature-space which is infinite dimensional, i.e. with basis functions everywhere).\nRemark 11 A full non-degenerate Gaussian process cannot be augmented,\nsince the corresponding f\u2217would already be connected to all other variables in the graphical model.\nBut augmentation does make sense for sparse approximations to GPs.\nThe more general process view on augmentation has several advantages over the basis function\nview. It is not completely clear from the basis function view, which basis function should be used\nfor augmentation. For example, Rasmussen and Qui\u02dc nonero-Candela (2005) successfully apply aug-\nmentation using basis functions that have a zero contribution at the test location! In the process view\n1950"},{"page":13,"text":"SPARSE APPROXIMATE GAUSSIAN PROCESS REGRESSION\nhowever, it seems clear that one would chose the additional inducing variable to be f\u2217, to minimize\nthe effects of the approximations.\nLet us compute the effective prior for the augmented SoR. Given that f\u2217is in the inducing set,\nthe test conditional is not an approximation and we can rewrite the integral leading to the effective\nprior:\nqASoR(f\u2217,f) =\nIt is interesting to notice that this is also the effective prior that would result from augmenting the\nDTC approximation, since qSoR(f|f\u2217,u) = qDTC(f|f\u2217,u).\nRemark 12 Augmented SoR (ASoR) is equivalent to augmented DTC (ADTC).\nZ\nqSoR(f|f\u2217,u)p(f\u2217,u)du .\n(28)\nAugmented DTC only differs from DTC in the additional presence of f\u2217among the inducing vari-\nables in the training conditional. We can only expect augmented DTC to be a more accurate approx-\nimation than DTC, since adding an additional inducing variable can only help capture information\nfrom y. Therefore\nRemark 13 DTC is a less accurate (but cheaper) approximation than augmented SoR.\nWe saw previously in Section 5 that the DTC approximation does not suffer from the nonsensi-\ncal predictive variances of the SoR. The equivalence between the augmented SoR and augmented\nDTC is another way of seeing how augmentation reverses the misbehaviour of SoR. The predictive\ndistribution of the augmented SoR is obtained by adding f\u2217to u in (20).\nPrediction with an augmented sparse model comes at a higher computational cost, since now f\u2217\ndirectly interacts with all of f and not just with u. For each new test case, updating the augmented \u03a3\nin the predictive equation (for example (20b) for DTC) implies computing the vector matrix product\nK\u2217,fKf,uwith complexity O(nm). This is clearly higher than the O(m) for the mean, and O(m2) for\nthe predictive distribution of all the non-augmented methods we have discussed.\nAugmentation seems to be only really necessary for methods that make a severe approxima-\ntion to the test conditional, like the SoR. For methods that make little or no approximation to the\ntest conditional, it is difficult to predict the degree to which augmentation would help. However,\none can see by giving f\u2217access to all of the training latent function values in f, one would expect\naugmentation to give less under-confident predictive distributions near the training data. Figure 5\nclearly shows that augmented DTC (equivalent to augmented SoR) has a superior predictive dis-\ntribution (both mean and variance) than standard DTC. Note however that in the figure we have\npurposely chosen a too short lengthscale to enhance visualization. Quantitatively, this superiority\nwas experimentally assessed by Qui\u02dc nonero-Candela (2004, Table 3.1). Augmentation hasn\u2019t been\ncompared to the more advanced approximations FITC and PITC, and the figure would change in\nthe more realistic scenario where the inducing inputs and hyperparameters are learnt (Snelson and\nGhahramani, 2006).\nTransductivemethodsliketheBCMcanbeseenasjointaugmentation, andonecouldpotentially\nuse it for any of the methods presented. It seems that the good performance of the BCM could\nessentially stem from augmentation, the presence of the other test inputs in the inducing set being\nprobably of little benefit. Joint augmentation might bring some computational advantage, but won\u2019t\nchange the scaling: note that augmenting m times at a cost of O(nm) apiece implies the same\nO(nm2) total cost as the jointly augmented BCM.\n1951"},{"page":14,"text":"QUI\u02dc NONERO-CANDELA AND RASMUSSEN\n\u221215\u221210\u2212505 1015\n\u22121.5\n\u22121\n\u22120.5\n0\n0.5\n1\n1.5\nSoD\n\u221215 \u221210 \u2212505 10 15\n\u22121.5\n\u22121\n\u22120.5\n0\n0.5\n1\n1.5\nSoR\n\u221215\u221210 \u2212505 1015\n\u22121.5\n\u22121\n\u22120.5\n0\n0.5\n1\n1.5\nDTC\n\u221215 \u221210\u2212505 1015\n\u22121.5\n\u22121\n\u22120.5\n0\n0.5\n1\n1.5\nASoR\/ADTC\n\u221215 \u221210\u2212505 10 15\n\u22121.5\n\u22121\n\u22120.5\n0\n0.5\n1\n1.5\nFITC\n\u221215 \u221210\u2212505 1015\n\u22121.5\n\u22121\n\u22120.5\n0\n0.5\n1\n1.5\nPITC\nFigure 5: Toy example with identical covariance function and hyperparameters. The squared ex-\nponential covariance function is used, and a slightly too short lengthscale is chosen on\npurpose to emphasize the different behaviour of the predictive uncertainties. The dots\nare the training points, the crosses are the targets corresponding to the inducing inputs,\nrandomly selected from the training set. The solid line is the mean of the predictive\ndistribution, and the dotted lines show the 95% confidence interval of the predictions.\nAugmented DTC (ADTC) is equivalent to augmented SoR (ASoR), see Remark 12.\n1952"},{"page":15,"text":"SPARSE APPROXIMATE GAUSSIAN PROCESS REGRESSION\n9. On the Choice of the Inducing Variables\nWe have until now assumed that the inducing inputs Xuwere given. Traditionally, sparse models\nhave very often been built upon a carefully chosen subset of the training inputs. This concept is\nprobably best exemplified in the popular support vector machine (Cortes and Vapnik, 1995). In\nsparse Gaussian processes it has also been suggested to select the inducing inputs Xufrom among\nthe training inputs. Since this involves a prohibitive combinatorial optimization, greedy optimiza-\ntion approaches have been suggested using various selection criteria like online learning (Csat\u00b4 o and\nOpper, 2002), greedy posterior maximization (Smola and Bartlett, 2001), maximum information\ngain (Seeger et al., 2003), matching pursuit (Keerthi and Chu, 2006), and probably more. As dis-\ncussed in the previous section, selecting the inducing inputs from among the test inputs has also\nbeen considered in transductive settings. Recently, Snelson and Ghahramani (2006) have proposed\nto relax the constraint that the inducing variables must be a subset of training\/test cases, turning the\ndiscrete selection problem into one of continuous optimization. One may hope that finding a good\nsolution is easier in the continuous than the discrete case, although finding the global optimum is\nintractable in both cases. And perhaps the less restrictive choice can lead to better performance in\nvery sparse models.\nWhich optimality criterion should be used to set the inducing inputs? Departing from a fully\nBayesian treatment which would involve defining priors on Xu, one could maximize the marginal\nlikelihood (also called the evidence) with respect to Xu, an approach also followed by Snelson and\nGhahramani (2006). Each of the approximate methods proposed involves a different effective prior,\nand hence its own particular effective marginal likelihood conditioned on the inducing inputs\nq(y|Xu) =\nZZ\np(y|f)q(f|u)p(u|Xu)dudf =\nZ\np(y|f)q(f|Xu)df ,\n(29)\nwhich of course is independent of the test conditional. We have in the above equation explicitly\nconditioned on the inducing inputs Xu. Using Gaussian identities, the effective marginal likelihood\nis very easily obtained by adding a ridge \u03c32\nprior on f. Using the appropriate definitions of \u039b, the log marginal likelihood becomes\nnoiseI (from the likelihood) to the covariance of effective\nlogq(y|Xu) = \u22121\n2log|Qf,f+\u039b|\u22121\nnoiseI, \u039bFITC= diag[Kf,f\u2212Qf,f]+\u03c32\nnoiseI. The computational cost of the marginal likelihood is O(nm2) for all methods, that of\nits gradient with respect to one element of Xuis O(nm). This of course implies that the complexity\nof computing the gradient wrt. to the whole of Xuis O(dnm2), where d is the dimension of the input\nspace.\nIt has been proposed to maximize the effective posterior instead of the effective marginal likeli-\nhood (Smola and Bartlett, 2001). However this is potentially dangerous and can lead to overfitting.\nMaximizing the whole evidence instead is sound and comes at an identical computational cost (for\na deeper analysis see Qui\u02dc nonero-Candela, 2004, Sect. 3.3.5 and Fig. 3.2).\nThe marginal likelihood has traditionally been used to learn the hyperparameters of GPs in the\nnon fully Bayesian treatment (see for example Williams and Rasmussen, 1996). For the sparse\napproximations presented here, once you are learning Xuit is straightforward to allow for learning\nhyperparameters (of the covariance function) during the same optimization, and there is no need\nto interleave optimization of u with learning of the hyperparameters as it has been proposed for\nexample by Seeger et al. (2003).\n2y?(Qf,f+\u039b)\u22121y\u2212n\nnoiseI, and \u039bPITC= blockdiag[Kf,f\u2212\n2log(2\u03c0) ,\n(30)\nwhere \u039bSoR= \u039bDTC= \u03c32\nQf,f]+\u03c32\n1953"},{"page":16,"text":"QUI\u02dc NONERO-CANDELA AND RASMUSSEN\n10. Other Methods\nIn this section we briefly mention two approximations which don\u2019t fit in our unifying scheme,\nsince one doesn\u2019t correspond to a proper probabilistic model, and the other one uses a particular\nconstruction for the covariance function, rather than allowing any general covariance function.\n10.1 The Nystr\u00a8 om Approximation\nThe Nystr\u00a8 om Approximation for speeding up GP regression was originally proposed by Williams\nand Seeger (2001), and then questioned by Williams et al. (2002). Like SoR and DTC, the Nystr\u00a8 om\nApproximation for GP regression approximates the prior covariance of f by Qf,f. However, unlike\nthese methods, the Nystr\u00a8 om Approximation is not based on a generative probabilistic model. The\npriorcovariancebetween f\u2217andfistakentobeexact, whichisinconsistent withthepriorcovariance\non f:\nq(f,f\u2217) = N\n?\n0,\n?Qf,f\nKf,\u2217\nK\u2217,\u2217\nK\u2217,f\n??\n.\n(31)\nAs a result we cannot derive this method from our unifying framework, nor represent it with a\ngraphical model. Worse, the resulting prior covariance matrix is not even guaranteed to be positive\ndefinite, allowing the predictive variances to be negative. Notice that replacing Kf,\u2217by Qf,\u2217in (31)\nis enough to make the prior covariance positive definite, and one obtains the DTC approximation.\nRemark 14 The Nystr\u00a8 om Approximation does not correspond to a well-formed probabilistic model.\nIgnoring any quibbles about positive definiteness, the predictive distribution of the Nystr\u00a8 om Ap-\nproximation is given by:\np(f\u2217|y) = N?K?\nf,\u2217[Qf,f+\u03c32\nnoiseI]\u22121y, K\u2217,\u2217\u2212K?\nf,\u2217[Qf,f+\u03c32\nnoiseI]\u22121Kf,\u2217\n?,\n(32)\nbut the predictive variance is not guaranteed to be positive. The computational cost is O(nm2).\n10.2 The Relevance Vector Machine\nThe relevance vector machine, introduced by Tipping (2001), is a finite linear model with an in-\ndependent Gaussian prior imposed on the weights. For any input x\u2217, the corresponding function\noutput is given by:\nf\u2217 = \u03c6\u2217w ,\nwhere \u03c6\u2217= [\u03c61(x),...,\u03c6m(x)] is the (row) vector of responses of the m basis functions, and A =\ndiag(\u03b11,...,\u03b1m) is the diagonal matrix of joint prior precisions (inverse variances) of the weights.\nThe \u03b1iare learnt by maximizing the RVM evidence (obtained by also assuming Gaussian additive\niid. noise, see (1)), and for the typical case of rich enough sets of basis functions many of the\nprecisions go to infinity effectively pruning out the corresponding weights (for a very interesting\nanalysis see Wipf et al., 2004). The RVM is thus a sparse method and the surviving basis functions\nare called relevance vectors.\nNote that since the RVM is a finite linear model with Gaussian priors on the weights, it can be\nseen as a Gaussian process:\nwith\np(w|A) = N (0,A) ,\n(33)\nRemark 15 The RVM is equivalent to a degenerate Gaussian process with covariance function\nkRVM(xi,xj) = \u03c6iA\u22121\u03c6?\nj=\u2211m\nk=1\u03b1\u22121\nk\u03c6k(xi)\u03c6k(xj),\n1954"},{"page":17,"text":"SPARSE APPROXIMATE GAUSSIAN PROCESS REGRESSION\nMethod\nq(f\u2217|u)\nexact\nq(f|u)\nexact\njoint prior covariance\n?Kf,f\nK\u2217,f\n?Qf,f\nQ\u2217,f\n?Qf,f\nQ\u2217,f\n?Qf,f\u2212diag[Qf,f\u2212Kf,f]\nQ\u2217,f\n?Qf,f\u2212blokdiag[Qf,f\u2212Kf,f]\nQ\u2217,f\nGP?\n\u221a\nGP\nKf,\u2217\nK\u2217,\u2217\nQf,\u2217\nQ\u2217,\u2217\nQf,\u2217\nK\u2217,\u2217\n?\n?\n?\nSoRdeterm.determ.\n\u221a\nDTC exact determ.\nFITC(exact)fully indep.\nQf,\u2217\nK\u2217,\u2217\nQf,\u2217\nK\u2217,\u2217\n?\n(\u221a)\nPITCexactpartially indep.\n?\nTable 1: Summary of the way approximations are built. All these methods are detailed in the previ-\noussections. Theinitialcostandthatofthemeanandvariancepertestcasearerespectively\nn2, n and n2for the exact GP, and nm2, m and m2for all other methods. The \u201cGP?\u201d column\nindicates whether the approximation is equivalent to a GP. For FITC see Remark 7.\nas was also pointed out by Tipping (2001, eq. (59)). Whereas all sparse approximations we have\npresented until now are totally independent of the choice of covariance function, for the RVM\nthis choice is restricted to covariance functions that can be expressed as finite expansions in terms\nof some basis functions. Being degenerate GPs in exactly the same way as the SoR (presented\nin Section 4), the RVM does also suffer from unreasonable predictive variances. Rasmussen and\nQui\u02dc nonero-Candela (2005) show that the predictive distributions of RVMs can also be healed by\naugmentation, see Section 8. Once the \u03b1ihave been learnt, denoting by m the number of surviving\nrelevance vectors, the complexity of computing the predictive distribution of the RVM is O(m) for\nmean and O(m2) for the variance.\nRVMs are often used with radial basis functions centered on the training inputs. One potentially\ninterestingextensiontotheRVMwouldbetolearnthelocationsofthecentersofthebasisfunctions,\nin the same way as proposed by Snelson and Ghahramani (2006) for the FITC approximation, see\nSection 6. This is a curious reminiscence of learning the centers in RBF Networks.\n11. Conclusions\nWe have provided a unifying framework for sparse approximations to Gaussian processes for regres-\nsion. Our approach consists of two steps, first 1) we recast the approximation in terms of approx-\nimations to the prior, and second 2) we introduce inducing variables u and the idea of conditional\nindependence given u. We recover all existing sparse methods by making further simplifications of\nthe covariances of the training and test conditionals, see Table 1 for a summary.\nPrevious methods were presented based on different approximation paradigms (e.g. likelihood\napproximations, projection methods, matrix approximations, minimization of Kullback-Leibler di-\nvergence, etc), making direct comparison difficult. Under our unifying view we deconstruct meth-\nods, making it clear which building blocks they are based upon. For example, the SGPP by Snelson\n1955"},{"page":18,"text":"QUI\u02dc NONERO-CANDELA AND RASMUSSEN\nand Ghahramani (2006) contains two ideas, 1) a likelihood approximation and 2) the idea of varying\nthe inducing inputs continuously; these two ideas could easily be used independently, and incorpo-\nrated in other methods. Similarly, the BCM by Tresp (2000) contains two independent ideas 1) a\nblock diagonal assumption, and 2) the (transductive) idea of choosing the test inputs as the induc-\ning variables. Finally we note that although all three ideas of 1) transductively setting u = f\u2217, 2)\naugmentation and 3) continuous optimization of Xuhave been proposed in very specific settings, in\nfact they are completely general ideas, which can be applied to any of the approximation schemes\nconsidered.\nWe have ranked the approximation according to how close they are to the corresponding full\nGP. However, the performance in practical situations may not always follow this theoretical ranking\nsince the approximations might exhibit properties (not present in the full GP) which may be par-\nticularly suitable for specific datasets. This may make the interpretation of empirical comparisons\nchallenging. A further complication arises when adding the necessary heuristics for turning the\ntheoretical constructs into practical algorithms. We have not described full algorithms in this paper,\nbut are currently working on a detailed empirical study (in preparation, see also Rasmussen and\nWilliams, 2006, chapter 8).\nWe note that the order of the computational complexity is identical for all the methods consid-\nered, O(nm2). This highlights that there is no computational excuse for using gross approximations,\nsuch as assuming deterministic relationships, in particular one should probably think twice before\nusing SoR or even DTC. Although augmentation has attractive predictive properties, it is com-\nputationally expensive. It remains unclear whether augmentation could be beneficial on a fixed\ncomputational budget.\nWe have only considered the simpler case of regression in this paper, but sparseness is also com-\nmonly sought in classification settings. It should not be difficult to cast probabilistic approximation\nmethods such as Expectation Propagation (EP) or the Laplace method (for a comparison, see Kuss\nand Rasmussen, 2005) into our unifying framework.\nOuranalysissuggeststhatanewinterestingapproximationwouldcomefromcombiningthebest\npossible approximation (PITC) with the most powerful selection method for the inducing inputs.\nThis would correspond to a non-transductive version of the BCM. We would evade the necessity of\nknowing the test set before doing the bulk of the computation, and we could hope to supersede the\nsuperior performance reported by Snelson and Ghahramani (2006) for very sparse approximations.\nAcknowledgments\nThankstoNeilLawrenceforarrangingthe2005GaussianProcessRoundTablemeetinginSheffield,\nwhich provided much inspiration to this paper. Special thanks to Olivier Chapelle, Lehel Csat\u00b4 o,\nZoubin Ghahramani, Matthias Seeger, Ed Snelson and Chris Williams for helpful discussions, and\nto three anonymous reviewers. Both authors were supported by the German Research Council\n(DFG) through grant RA 1030\/1. This work was supported in part by the IST Programme of the\nEuropean Community, under the PASCAL Network of Excellence, IST-2002-506778.\n1956"},{"page":19,"text":"SPARSE APPROXIMATE GAUSSIAN PROCESS REGRESSION\nAppendix A. Gaussian and Matrix Identities\nIn this appendix we provide identities used to manipulate matrices and Gaussian distributions\nthroughout the paper. Let x and y be jointly Gaussian\n?x\ny\n?\n\u223c N\n??\u00b5x\n\u00b5y\n?\n,\n?\nAC\nBC?\n??\n,\n(34)\nthen the marginal and the conditional are given by\nx \u223c N (\u00b5x, A) ,\nand\nx|y \u223c N?\u00b5x+CB\u22121(y\u2212\u00b5y), A\u2212CB\u22121C??\n(35)\nAlso, the product of a Gaussian in x with a Gaussian in a linear projection Px is again a Gaussian,\nalthough unnormalized\nN (x|a,A)N (Px|b,B) = zcN (x|c,C) ,\nwhere\nC =\n?A\u22121+P?B\u22121P?\u22121,\nThe normalizing constant zcis gaussian in the means a and b of the two Gaussians:\n(36)\nc = C?A\u22121a+P?B\u22121b?.\nzc = (2\u03c0)\u2212m\n2|B+PAP?|\u22121\n2exp\n?\n\u22121\n2(b\u2212Pa)??B+PAP??\u22121(b\u2212Pa)\n?\n.\n(37)\nThe matrix inversion lemma, also known as the Woodbury, Sherman & Morrison formula states\nthat:\n(Z+UWV?)\u22121= Z\u22121\u2212Z\u22121U(W\u22121+V?Z\u22121U)\u22121V?Z\u22121,\nassuming the relevant inverses all exist. Here Z is n\u00d7n, W is m\u00d7m and U and V are both of size\nn\u00d7m; consequently if Z\u22121is known, and a low rank (ie. m < n) perturbation are made to Z as in\nleft hand side of eq. (38), considerable speedup can be achieved.\n(38)\nReferences\nCorinna Cortes and Vladimir Vapnik. Support-vector network. Machine Learning, 20(3):273\u2013297,\n1995.\nLehel Csat\u00b4 o and Manfred Opper. Sparse online Gaussian processes. Neural Computation, 14(3):\n641\u2013669, 2002.\nSathiya Keerthi and Wei Chu. A Matching Pursuit approach to sparse Gaussian process regression.\nIn Y. Weiss, B. Sch\u00a8 olkopf, and J. Platt, editors, Advances in Neural Information Processing\nSystems 18, Cambridge, Massachussetts, 2006. The MIT Press.\nMalte Kuss and Carl Edward Rasmussen. Assessing approximate inference for binary Gaussian\nprocess classification. Journal of Machine Learning Research, pages 1679\u20131704, 2005.\nJoaquin Qui\u02dc nonero-Candela. Learning with Uncertainty \u2013 Gaussian Processes and Relevance Vec-\ntor Machines. PhD thesis, Technical University of Denmark, Lyngby, Denmark, 2004.\nCarl Edward Rasmussen. Reduced rank Gaussian process learning. Technical report, Gatsby Com-\nputational Neuroscience Unit, UCL, 2002.\n1957"},{"page":20,"text":"QUI\u02dc NONERO-CANDELA AND RASMUSSEN\nCarl Edward Rasmussen and Joaquin Qui\u02dc nonero-Candela. Healing the relevance vector machine by\naugmentation. In International Conference on Machine Learning, 2005.\nCarlEdwardRasmussenandChristopherK.I.Williams. GaussianProcessesforMachineLearning.\nThe MIT press, 2006.\nAnton Schwaighofer and Volker Tresp. Transductive and inductive methods for approximate Gaus-\nsian process regression. In Suzanna Becker, Sebastian Thrun, and Klaus Obermayer, editors,\nAdvances in Neural Information Processing Systems 15, pages 953\u2013960, Cambridge, Massachus-\nsetts, 2003. The MIT Press.\nMatthias Seeger, Christopher K. I. Williams, and Neil Lawrence. Fast forward selection to speed up\nsparse Gaussian process regression. In Christopher M. Bishop and Brendan J. Frey, editors, Ninth\nInternational Workshop on Artificial Intelligence and Statistics. Society for Artificial Intelligence\nand Statistics, 2003.\nBernhard W. Silverman. Some aspects of the spline smoothing approach to non-parametric regres-\nsion curve fitting. J. Roy. Stat. Soc. B, 47(1):1\u201352, 1985. (with discussion).\nAlexander J. Smola and Peter L. Bartlett. Sparse greedy Gaussian process regression. In Todd K.\nLeen, Thomas G. Dietterich, and Volker Tresp, editors, Advances in Neural Information Process-\ning Systems 13, pages 619\u2013625, Cambridge, Massachussetts, 2001. The MIT Press.\nEdward Snelson and Zoubin Ghahramani. Sparse Gaussian processes using pseudo-inputs. In\nY. Weiss, B. Sch\u00a8 olkopf, and J. Platt, editors, Advances in Neural Information Processing Systems\n18, Cambridge, Massachussetts, 2006. The MIT Press.\nMichael E. Tipping. Sparse Bayesian learning and the Relevance Vector Machine. Journal of\nMachine Learning Research, 1:211\u2013244, 2001.\nVolker Tresp. A Bayesian committee machine. Neural Computation, 12(11):2719\u20132741, 2000.\nVladimir N. Vapnik. The Nature of Statistical Learning Theory. Springer Verlag, 1995.\nGrace Wahba, Xiwu Lin, Fangyu Gao, Dong Xiang, Ronald Klein, and Barbara Klein. The bias-\nvariance tradeoff and the randomized GACV. In Michael S. Kerns, Sara A. Solla, and David A.\nCohn, editors, Advances in Neural Information Processing Systems 11, pages 620\u2013626, Cam-\nbridge, Massachussetts, 1999. The MIT Press.\nChristopher K. I. Williams and Carl Edward Rasmussen. Gaussian processes for regression. In\nDavid S. Touretzky, Michael C. Mozer, and Michael E. Hasselmo, editors, Advances in Neural\nInformation Processing Systems 8, pages 514\u2013520, Cambridge, Massachussetts, 1996. The MIT\nPress.\nChristopher K. I. Williams, Carl Edward Rasmussen, Anton Schwaighofer, and Volker Tresp. Ob-\nservations of the Nystr\u00a8 om method for Gaussiam process prediction. Technical report, University\nof Edinburgh, Edinburgh, Scotland, 2002.\n1958"},{"page":21,"text":"SPARSE APPROXIMATE GAUSSIAN PROCESS REGRESSION\nChristopher K. I. Williams and Mathias Seeger. Using the Nystr\u00a8 om method to speed up kernel\nmachines. In Todd K. Leen, Thomas G. Dietterich, and Volker Tresp, editors, Advances in Neural\nInformation Processing Systems 13, pages 682\u2013688, Cambridge, Massachussetts, 2001. The MIT\nPress.\nDavid Wipf, Jason Palmer, and Bhaskar Rao. Perspectives on sparse Bayesian learning. In Sebas-\ntian Thrun, Lawrence Saul, and Bernhard Sch\u00a8 olkopf, editors, Advances in Neural Information\nProcessing Systems 16, Cambridge, Massachussetts, 2004. The MIT Press.\n1959"}],"widgetId":"rgw28_56ab9fbcdfce3"},"id":"rgw28_56ab9fbcdfce3","partials":[],"templateName":"publicliterature\/stubs\/PublicationText.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationText.html?publicationUid=41781406&hide=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationDetailAd":{"data":{"googleDfpSlot":null,"widgetId":"rgw29_56ab9fbcdfce3"},"id":"rgw29_56ab9fbcdfce3","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAd.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAd.html?publicationUid=41781406&slotId=336x280_Publications_ATF_Right&collapseSlotMode=never&fallbackContainerEnabled=1","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationRelations":null,"publicationRelationsReverse":null,"publicationUid":41781406,"showSignUpDialog":false,"selectNewSignUpDialog":false,"publicationQuestions":null,"publicationCitations":null,"publicationReviewPromo":null,"publicationUsedInReviews":null,"publicationPdfJsReader":null,"useFulltextOptimizedLayout":false,"publicationActions":null,"requestFulltextPromo":null,"currentUrl":"publication\/41781406_A_Unifying_View_of_Sparse_Approximate_Gaussian_Process_Regression","isLeaderboardAd":false,"enableStickyBox":null,"googleDfpSlotMobileBottom":null,"fullTextExitPopup":null,"showExitPopupDialog":false,"widgetId":"rgw2_56ab9fbcdfce3"},"id":"rgw2_56ab9fbcdfce3","partials":{"romeo_legal_notice":"publicliterature\/stubs\/partials\/romeo_legal_notice.html"},"templateName":"publicliterature\/stubs\/PublicPublicationDetails_NewLayout.html","templateExtensions":["generalHelpers"],"attrs":{"publicationUid":41781406},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicPublicationDetailsOld.html?publicationUid=41781406&isTestOldDesign=0","viewClass":"views.publicliterature.PublicPublicationDetailsOldView","yuiModules":["rg.views.publicliterature.PublicPublicationDetailsOldView"],"stylesheets":[],"_isYUI":true},"widgetId":"rgw1_56ab9fbcdfce3"},"id":"rgw1_56ab9fbcdfce3","partials":[],"templateName":"publicliterature\/stubs\/PublicPublicationDetails.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicPublicationDetails.html","viewClass":"views.publicliterature.PublicPublicationDetailsView","yuiModules":["rg.views.publicliterature.PublicPublicationDetailsView"],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"uaClass":"","headPrefix":[],"rootUrl":"https:\/\/www.researchgate.net\/","requestToken":"fWkduFcsVRqSX8O0L21a3Sfw0zutc9XwdU6oy1rZwMObNDpWyz35jOXKNbH9hkw\/brV6TYISQyyaVEXVk3iJa8huLqfvcozMnolkfzlsT1rouGo\/J34E7Iq\/rqv9bgBKCfPYMUWtYHn2fXbg5tPQ1VXimI91NNi66iqRf10ScxQc6rDKv37XT5vp5vITC55\/eguktBUMngUO+LbUL7mnquTui9H5ufn47Jn7wJj7a83y+P3t0KGBMmAhNn4eWVtNxVP6tB+Q9Bo4xJtrts2x11ptmrg7jwgmu2kL7V41mm0=","faviconCdnUrl":"https:\/\/c5.rgstatic.net\/m\/2390829798215018\/images\/favicon.ico","headerOutput":"<noscript><\/noscript><link rel=\"canonical\" href=\"https:\/\/www.researchgate.net\/publication\/41781406_A_Unifying_View_of_Sparse_Approximate_Gaussian_Process_Regression\" \/>\n<link rel=\"dns-prefetch\" href=\"\/\/c5.rgstatic.net\" \/>\n<link rel=\"dns-prefetch\" href=\"\/\/i1.rgstatic.net\" \/>\n<meta property=\"twitter:card\" content=\"summary\" \/>\n<meta property=\"twitter:site\" content=\"@ResearchGate\" \/>\n<meta property=\"og:title\" content=\"A Unifying View of Sparse Approximate Gaussian Process Regression\" \/>\n<meta property=\"og:description\" content=\"We provide a new unifying view, including all existing proper probabilistic sparse approximations for Gaussian process regression. Our approach relies on expressing the effective prior which the...\" \/>\n<meta property=\"og:site_name\" content=\"ResearchGate\" \/>\n<meta property=\"og:image\" content=\"https:\/\/i1.rgstatic.net\/publication\/41781406_A_Unifying_View_of_Sparse_Approximate_Gaussian_Process_Regression\/links\/0f316af33829de2215f5a674\/smallpreview.png\" \/>\n<meta property=\"og:url\" content=\"https:\/\/www.researchgate.net\/publication\/41781406_A_Unifying_View_of_Sparse_Approximate_Gaussian_Process_Regression\" \/>\n<meta property=\"rg:id\" content=\"PB:41781406\" \/>\n<meta name=\"DC.identifier\" scheme=\"DCTERMS.URI\" content=\"http:\/\/dx.doi.org\/\" \/>\n<meta name=\"gs_meta_revision\" content=\"1.1\" \/>\n<meta name=\"citation_title\" content=\"A Unifying View of Sparse Approximate Gaussian Process Regression\" \/>\n<meta name=\"citation_author\" content=\"JQ Quinonero-Candela\" \/>\n<meta name=\"citation_author\" content=\"C.E. Rasmussen\" \/>\n<meta name=\"citation_publication_date\" content=\"2005\/12\/01\" \/>\n<meta name=\"citation_journal_title\" content=\"Journal of Machine Learning Research\" \/>\n<meta name=\"citation_issn\" content=\"1533-7928\" \/>\n<meta name=\"citation_volume\" content=\"6\" \/>\n<meta name=\"citation_abstract_html_url\" content=\"https:\/\/www.researchgate.net\/publication\/41781406_A_Unifying_View_of_Sparse_Approximate_Gaussian_Process_Regression\" \/>\n<meta name=\"citation_fulltext_html_url\" content=\"https:\/\/www.researchgate.net\/publication\/41781406_A_Unifying_View_of_Sparse_Approximate_Gaussian_Process_Regression\" \/>\n<meta name=\"viewport\" content=\"width=device-width,initial-scale=1\" \/>\n<link href=\"\/\/c5.rgstatic.net\/m\/22664197317151888\/styles\/rg.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/21004998181197492\/styles\/rg2.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<!--[if lt IE 9]><link href=\"\/\/c5.rgstatic.net\/m\/238176252723686\/styles\/ie.css\" type=\"text\/css\" rel=\"stylesheet\"\/><![endif]-->\n<link href=\"\/\/c5.rgstatic.net\/m\/217752362214895\/styles\/modules\/publicprofile.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<script src=\"\/\/c5.rgstatic.net\/m\/2321000301012716\/javascript\/vendor\/webfontloader\/webfontloader.js\" type=\"text\/javascript\"><\/script>\n <script>(function(i,s,o,g,r,a,m){i[\"GoogleAnalyticsObject\"]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,\"script\",\"\/\/www.google-analytics.com\/analytics.js\",\"ga\");\n ga(\"create\",\"UA-58591210-1\");ga(\"set\",\"anonymizeIp\",true);ga('set', 'dimension1', 'publication slurped');ga('set', 'dimension2', 'Article');ga('set', 'dimension3', 'Logged out');ga('set', 'dimension4', 'https');ga(\"send\",\"pageview\");<\/script>\n","webfont":"<noscript><\/noscript><script> WebFontConfig = { custom: { families: ['source_sans_pro_italic', 'source_sans_pro_bold', 'source_sans_pro', 'martel'], urls : ['\/\/c5.rgstatic.net\/m\/231392577336386\/styles\/fonts.css'] } }; WebFont.load(WebFontConfig); <\/script>\n","correlationId":"rgreq-8ca8b9fb-ad6a-4db4-b63e-46e2ab5fca3b","accountId":null,"module":"publicliterature","action":"publicliterature.PublicPublicationDetails","page":"publicationDetail","product":"publications","backendTime":1723,"continent":"Asia","stylesHome":"\/\/c5.rgstatic.net\/m\/","staticHost":"c5.rgstatic.net","useEarlyFlush":false,"longRunningRequestIdentifier":"LongRunningRequest.publicliterature.PublicPublicationDetails","longRunningRequestFp":"e9e5bbe1366c7ee8c8e41d02f793c884ac9be19b","widgetId":"rgw30_56ab9fbcdfce3"},"id":"rgw30_56ab9fbcdfce3","partials":[],"templateName":"application\/stubs\/StaticHeader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.StaticHeader.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){
            Y.rg.core.pagespeed.Monitoring.monitorPage("\/\/glassmoni.researchgate.net", "publicliterature.PublicPublicationDetails.run.html.loggedOut.get", "59de9668d07aeb77ab4de5f24d382b5d199d2437", "rgreq-8ca8b9fb-ad6a-4db4-b63e-46e2ab5fca3b", "7107b82799c321cd9c7b2c50b09b7cbb5e9ee8e1");
        
            Y.rg.core.pagespeed.Monitoring.monitorPage("\/\/glassmoni.researchgate.net", "publicationDetail.loggedOut", "ed1993d9e20f6cefa83edacaa24401a18c071aea", "rgreq-8ca8b9fb-ad6a-4db4-b63e-46e2ab5fca3b", "7107b82799c321cd9c7b2c50b09b7cbb5e9ee8e1");
        })();
(function(){Y.rg.createInitialWidget({"data":{"year":"2016","inlinePromo":null,"isAdmin":false,"contactUrl":"https:\/\/www.researchgate.net\/contact","aboutUsUrl":"https:\/\/www.researchgate.net\/about","widgetId":"rgw31_56ab9fbcdfce3"},"id":"rgw31_56ab9fbcdfce3","partials":[],"templateName":"application\/stubs\/DefaultFooter.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.DefaultFooter.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"headerLogin":{"data":{"urlAfterLogin":"publication\/41781406_A_Unifying_View_of_Sparse_Approximate_Gaussian_Process_Regression","requestToken":"s0tkb2zmBU4trCLXko53ztlHYH5pOY2U\/N4hJ+yq10T2TKjw606a7lzlW1KLziBSBgtknuLOvXgPYDjiiD6Wo7IN\/Wn2Te\/Xam5vFNKJWrAm7lx6TxL410bb1LGk\/e50s2VNdytB85Md\/luPcnPCg+YRF01eRmZK2HK8tgws7D\/Ph1D0GuhAd+B0+mi1txhUdtHOeMrurUVIQKNyERGh8wpcW2ECirLq2Y2Osui62jnIWhVqqpLYSOAf9rThBSwY2Mt7CPMCi+BHFERrBfP0bengmhFcFpkwCIXR7B2\/bcM=","loginUrl":"https:\/\/www.researchgate.net\/application.Login.html","signupUrl":"https:\/\/www.researchgate.net\/signup.SignUp.html?ev=su_chnl_index&hdrsu=1&_sg=ymdf-40Xmw6tYYAYZKH2PedNtLRiG7WW_HyZuRqUouryp-5hEqX9y2AKC6uT3EKk","encodedUrlAfterLogin":"cHVibGljYXRpb24vNDE3ODE0MDZfQV9VbmlmeWluZ19WaWV3X29mX1NwYXJzZV9BcHByb3hpbWF0ZV9HYXVzc2lhbl9Qcm9jZXNzX1JlZ3Jlc3Npb24%3D","signupCallToAction":"Join for free","widgetId":"rgw33_56ab9fbcdfce3"},"id":"rgw33_56ab9fbcdfce3","partials":{"partial":"application\/stubs\/partials\/headerLoginDefault.html"},"templateName":"application\/stubs\/HeaderLogin.html","templateExtensions":[],"attrs":{"goal":"milestoneHeaderLoginSeen"},"widgetUrl":"https:\/\/www.researchgate.net\/application.HeaderLogin.html","viewClass":"views.application.HeaderLoginView","yuiModules":["rg.views.application.HeaderLoginView"],"stylesheets":[],"_isYUI":true},"cookieConsent":null,"logoSvgSrc":"https:\/\/c5.rgstatic.net\/m\/235107188705592\/images\/template\/brand-header-logo.svg","logoFallbackSrc":"https:\/\/c5.rgstatic.net\/m\/238113351022438\/images\/template\/brand-header-logo.png","widgetId":"rgw32_56ab9fbcdfce3"},"id":"rgw32_56ab9fbcdfce3","partials":{"schemaSocialProfiles":"application\/stubs\/partials\/schemaSocialProfiles.html"},"templateName":"application\/stubs\/HeaderLoggedOut.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.HeaderLoggedOut.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"logEvent":"su_banner","specialCopy":false,"widgetId":"rgw34_56ab9fbcdfce3"},"id":"rgw34_56ab9fbcdfce3","partials":[],"templateName":"application\/stubs\/LoggedOutBanner.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.LoggedOutBanner.html","viewClass":"views.application.LoggedOutBannerView","yuiModules":["rg.views.application.LoggedOutBannerView"],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.core.util.ParameterFilter.filter(["ev","cp","ch","ref","dbw","pli","loginT","uid","claimChannel","enrichId","enrichSource","utm_source","utm_medium","utm_campaign","el","ci"]);})();
});}); } else { throw 'YRG was not loaded when attaching widgets'; }</script><script> dataLayer = [{"pageCategory":"publication slurped","publicationType":"Article","eventCategory":"Publication page"}]; </script> <noscript><iframe src="//www.googletagmanager.com/ns.html?id=GTM-MKVKH7" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-MKVKH7');</script><script>(function(e){function n(n,t,o,a){"use strict";var i=e.document.createElement("link"),r=t||e.document.getElementsByTagName("script")[0],d=e.document.styleSheets;return i.rel="stylesheet",i.href=n,i.media="only x",a&&(i.onload=a),r.parentNode.insertBefore(i,r),i.onloadcssdefined=function(e){for(var t,o=0;d.length>o;o++)d[o].href&&d[o].href.indexOf(n)>-1&&(t=!0);t?e():setTimeout(function(){i.onloadcssdefined(e)})},i.onloadcssdefined(function(){i.media=o||"all"}),i}function t(e,n){e.onload=function(){e.onload=null,n&&n.call(e)},"isApplicationInstalled"in navigator&&"onloadcssdefined"in e&&e.onloadcssdefined(n)}var o=function(a,i){"use strict";if(a&&3===a.length){var r=e.Image,d=!(!document.createElementNS||!document.createElementNS("http://www.w3.org/2000/svg","svg").createSVGRect||!document.implementation.hasFeature("http://www.w3.org/TR/SVG11/feature#Image","1.1")||e.opera&&-1===navigator.userAgent.indexOf("Chrome")||-1!==navigator.userAgent.indexOf("Series40")),c=new r;c.onerror=function(){o.method="png",o.href=a[2],n(a[2])},c.onload=function(){var e=1===c.width&&1===c.height,r=a[e&&d?0:e?1:2];o.method=e&&d?"svg":e?"datapng":"png",o.href=r,t(n(r),i)},c.src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///ywAAAAAAQABAAACAUwAOw==",document.documentElement.className+=" grunticon"}};o.loadCSS=n,o.onloadCSS=t,e.grunticon=o})(this);grunticon(["https://c5.rgstatic.net/c/o1q2er/styles/icons/_header-ico.svg.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_header-ico.png.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_header-ico.fallback.scss"]);grunticon(["https://c5.rgstatic.net/c/o1q2er/styles/icons/_admin-ico.svg.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_admin-ico.png.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_admin-ico.fallback.scss"]);grunticon(["https://c5.rgstatic.net/c/o1q2er/styles/icons/_ico.svg.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_ico.png.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_ico.fallback.scss"]);</script></body>
</html>
