<!DOCTYPE html> <html lang="en" class="" id="rgw52_56ab199beedce"> <head > <meta charset="utf-8"/> <meta http-equiv="content-type" content="text/html; charset=UTF-8"/> <meta name="Rg-Request-Token" id="Rg-Request-Token" content="/QeBWSyALRD3ffexEjuLkmjcgCwZnzls7aVGjeVKyaSU4CnNjeIuXYZGEkjup3U5OalIXXOEVFMLk1nnLnh9YxqSNtH1ZxrPapv3L5TX9qm7dTADYCGslsiv70BrlfVqGBtqk9QDs0qbg9wM/107X25Hm/ooWlW+teZN8OUP40N3y2hUYHogbyKwkt7EfCH1GqxTDAhmp9cUzYBrsm3JLBpMyzA2KY264fMyF//q+UVTItdEI3bSMgqye9PHCQsjR1xai0C9G4k8C2TkGjkQPlBwzONflKWm30npodTvpJA="/> <meta http-equiv="expires" content="0"/> <link rel="apple-touch-icon" sizes="57x57" href="https://www.researchgate.net/apple-touch-icon-57x57.png"> <link rel="apple-touch-icon" sizes="60x60" href="https://www.researchgate.net/apple-touch-icon-60x60.png"> <link rel="apple-touch-icon" sizes="72x72" href="https://www.researchgate.net/apple-touch-icon-72x72.png"> <link rel="apple-touch-icon" sizes="76x76" href="https://www.researchgate.net/apple-touch-icon-76x76.png"> <link rel="apple-touch-icon" sizes="114x114" href="https://www.researchgate.net/apple-touch-icon-114x114.png"> <link rel="apple-touch-icon" sizes="120x120" href="https://www.researchgate.net/apple-touch-icon-120x120.png"> <link rel="apple-touch-icon" sizes="144x144" href="https://www.researchgate.net/apple-touch-icon-144x144.png"> <link rel="apple-touch-icon" sizes="152x152" href="https://www.researchgate.net/apple-touch-icon-152x152.png"> <link rel="apple-touch-icon" sizes="180x180" href="https://www.researchgate.net/apple-touch-icon-180x180.png"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-32x32.png" sizes="32x32"> <link rel="icon" type="image/png" href="https://www.researchgate.net/android-chrome-192x192.png" sizes="192x192"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-96x96.png" sizes="96x96"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-16x16.png" sizes="16x16"> <link rel="shortcut icon" type="image/x-icon" href="https://c5.rgstatic.net/m/2390829798215018/images/favicon.ico"/> <link rel="manifest" href="https://www.researchgate.net/manifest.json"> <meta name="msapplication-TileColor" content="#da532c"> <meta name="msapplication-TileImage" content="https://www.researchgate.net/mstile-144x144.png"> <meta name="theme-color" content="#444444"> <link rel="search" type="application/opensearchdescription+xml" title="ResearchGate search" href="https://www.researchgate.net/application.DownloadOpenSearchPlugin.html"/> <link rel="meta" type="application/rdf+xml" title="ICRA labels" href="https://www.researchgate.net/application.DownloadLabels.html"/> <link rel="http://oexchange.org/spec/0.8/rel/related-target" type="application/xrd+xml" href="https://www.researchgate.net/application.DownloadOExchange.html"/> <base href="https://www.researchgate.net/"/> <script>
    var rgConfig = {
        correlationId: "rgreq-41845642-763e-4f0e-b38c-398f980447be",
        accountId: "",
        module: "publicliterature",
        action: "publicliterature.PublicPublicationDetails",
        page: "publicationDetail",
        product: "publications",
        continent: "Asia",
        stylesHome: "//c5.rgstatic.net/m/",
        staticHost: "c5.rgstatic.net",
        longRunningRequestIdentifier: "LongRunningRequest.publicliterature.PublicPublicationDetails",
        longRunningRequestFp: "e9e5bbe1366c7ee8c8e41d02f793c884ac9be19b"
    };
    window.rootUrl = "https://www.researchgate.net/";
</script> <link rel="canonical" href="https://www.researchgate.net/publication/221345210_Beam_sampling_for_the_infinite_hidden_Markov_model" />
<link rel="dns-prefetch" href="//c5.rgstatic.net" />
<link rel="dns-prefetch" href="//i1.rgstatic.net" />
<meta property="twitter:card" content="summary" />
<meta property="twitter:site" content="@ResearchGate" />
<meta property="og:title" content="Beam sampling for the infinite hidden Markov model" />
<meta property="og:description" content="The innite hidden Markov model is a non- parametric extension of the widely used hid- den Markov model. Our paper introduces a new inference algorithm for the innite Hidden Markov model called..." />
<meta property="og:site_name" content="ResearchGate" />
<meta property="og:image" content="https://i1.rgstatic.net/publication/221345210_Beam_sampling_for_the_infinite_hidden_Markov_model/links/00463525dba898f504000000/smallpreview.png" />
<meta property="og:url" content="https://www.researchgate.net/publication/221345210_Beam_sampling_for_the_infinite_hidden_Markov_model" />
<meta property="rg:id" content="PB:221345210" />
<meta name="DC.identifier" scheme="DCTERMS.URI" content="http://dx.doi.org/10.1145/1390156.1390293" />
<meta name="gs_meta_revision" content="1.1" />
<meta name="citation_title" content="Beam sampling for the infinite hidden Markov model" />
<meta name="citation_author" content="Jurgen Van Gael" />
<meta name="citation_author" content="Yunus Saatci" />
<meta name="citation_author" content="Yee Whye Teh" />
<meta name="citation_author" content="Zoubin Ghahramani" />
<meta name="citation_conference_title" content="Machine Learning, Proceedings of the Twenty-Fifth International Conference (ICML 2008), Helsinki, Finland, June 5-9, 2008" />
<meta name="citation_publication_date" content="2008/01/01" />
<meta name="citation_firstpage" content="1088" />
<meta name="citation_lastpage" content="1095" />
<meta name="citation_doi" content="10.1145/1390156.1390293" />
<meta name="citation_pdf_url" content="https://www.researchgate.net/profile/Yunus_Saatchi/publication/221345210_Beam_sampling_for_the_infinite_hidden_Markov_model/links/00463525dba898f504000000.pdf" />
<meta name="citation_abstract_html_url" content="https://www.researchgate.net/publication/221345210_Beam_sampling_for_the_infinite_hidden_Markov_model" />
<meta name="citation_fulltext_html_url" content="https://www.researchgate.net/publication/221345210_Beam_sampling_for_the_infinite_hidden_Markov_model" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<link href="//c5.rgstatic.net/m/22664197317151888/styles/rg.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/21004998181197492/styles/rg2.css" type="text/css" rel="stylesheet"/>
<!--[if lt IE 9]><link href="//c5.rgstatic.net/m/238176252723686/styles/ie.css" type="text/css" rel="stylesheet"/><![endif]-->
<link href="//c5.rgstatic.net/m/217752362214895/styles/modules/publicprofile.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/215868066921738/styles/pow/publicliterature/FigureList.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/21993347442549/styles/pow/publicliterature/FollowPublicationPromo.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/282514599719602/styles/pow/application/PdfJsReader.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/23819663151220/styles/pow/publicliterature/PublicationInlineReader.css" type="text/css" rel="stylesheet"/>
<script src="//c5.rgstatic.net/m/2321000301012716/javascript/vendor/webfontloader/webfontloader.js" type="text/javascript"></script>
 <script>(function(i,s,o,g,r,a,m){i["GoogleAnalyticsObject"]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,"script","//www.google-analytics.com/analytics.js","ga");
 ga("create","UA-58591210-1");ga("set","anonymizeIp",true);ga('set', 'dimension1', 'publication full-text');ga('set', 'dimension2', 'Conference Paper');ga('set', 'dimension3', 'Logged out');ga('set', 'dimension4', 'https');ga("send","pageview");</script>
  <script> WebFontConfig = { custom: { families: ['source_sans_pro_italic', 'source_sans_pro_bold', 'source_sans_pro', 'martel'], urls : ['//c5.rgstatic.net/m/231392577336386/styles/fonts.css'] } }; WebFont.load(WebFontConfig); </script><noscript></noscript>

<title>Beam sampling for the infinite hidden Markov model (PDF Download Available)</title>
<meta name="description" content="Official Full-Text Publication: Beam sampling for the infinite hidden Markov model on ResearchGate, the professional network for scientists."/>
<meta name="keywords" content="scientific network, scientific platform, scientific community, research partner, research collaboration, journal articles, international collaboration, find researcher, lifescience researcher, interdisciplinary research, research collaboration"/>
</head>
<body class="use-svg-icons logged-out">
<div id="page-container">
<script type="text/javascript">var googletag = googletag || {}; googletag.cmd = googletag.cmd || [];
(function() { var gads = document.createElement("script"); gads.async = true; gads.type = "text/javascript"; var useSSL = "https:" == document.location.protocol; gads.src = (useSSL ? "https:" : "http:") + "//www.googletagservices.com/tag/js/gpt.js"; var node =document.getElementsByTagName("script")[0]; node.parentNode.insertBefore(gads, node); })();</script><div id="main" class="logged-out-header-support">
<div id="content" class="">

<noscript>
<div class="c-box-warning full-width-element" style="text-align: center; ">
    <div style="margin: auto; padding:10px;" class="container">
        <b>For full functionality of ResearchGate it is necessary to enable JavaScript.
            Here are the <a href="http://www.enable-javascript.com/" rel="nofollow" target="_blank">
                instructions how to enable JavaScript in your web browser</a>.</b>
    </div>
</div>
</noscript>

<div id="rgw1_56ab199beedce" itemscope itemtype="http://schema.org/ScholarlyArticle"><div class="publication-wrapper publication-wrapper-onecol" id="rgw2_56ab199beedce" itemscope itemtype="http://schema.org/ScholarlyArticle"> <div class="c-col-content"> <div class="c-content"> <div class="clearfix">  <div class="publication-header"> <div id="rgw5_56ab199beedce">  <div class="type-label"> Conference Paper   </div> <span class="Z3988" title="ctx_ver=Z39.88-2004&rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&rfr_id=info%3Asid%2Fresearchgate.net%3Aresearchgate&rft_id=info%3Adoi%2F10.1145%2F1390156.1390293&rft.atitle=Beam%20sampling%20for%20the%20infinite%20hidden%20Markov%20model&rft.title=Proceedings%20of%20the%2025th%20International%20Conference%20on%20Machine%20Learning&rft.jtitle=Proceedings%20of%20the%2025th%20International%20Conference%20on%20Machine%20Learning&rft.date=2008&rft.pages=1088-1095&rft.au=Jurgen%20Van%20Gael%2CYunus%20Saatci%2CYee%20Whye%20Teh%2CZoubin%20Ghahramani&rft.genre=inProceedings"></span> <h1 class="pub-title" itemprop="name">Beam sampling for the infinite hidden Markov model</h1> <meta itemprop="headline" content="Beam sampling for the infinite hidden Markov model">  <meta itemprop="image" content="https://i1.rgstatic.net/publication/221345210_Beam_sampling_for_the_infinite_hidden_Markov_model/links/00463525dba898f504000000/smallpreview.png">  <div id="rgw7_56ab199beedce" class="publication-detail-author-list"> <div> <ul class="clearfix js-people-list">  <li id="rgw8_56ab199beedce"> <a href="researcher/69831654_Jurgen_Van_Gael" class="pub-detail-item author-item" itemprop="author" itemscope itemtype="http://schema.org/Person"> <div class="indent-left"> <div class="people-img">  <img src="https://c5.rgstatic.net/m/2951093203564/images/template/default/profile/profile_default_s.jpg" title="Jurgen Van Gael" alt="Jurgen Van Gael" height="20px" width="20px" style="height: 20px;"/>  </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Jurgen Van Gael</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item   not-claimed " id="rgw9_56ab199beedce">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="researcher/69831654_Jurgen_Van_Gael"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="Jurgen Van Gael" alt="Jurgen Van Gael" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">       </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="researcher/69831654_Jurgen_Van_Gael" class="display-name">Jurgen Van Gael</a>    </h5> <div class="truncate-single-line meta">   </div>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>  <li id="rgw10_56ab199beedce" itemprop="author" itemscope itemtype="http://schema.org/Person"> <a itemprop="sameAs" href="profile/Yunus_Saatchi" class="pub-detail-item account-item"> <div class="indent-left"> <div class="people-img"> <img  src="https://i1.rgstatic.net/ii/profile.image/AS%3A272816591339520%401442055952095_m/Yunus_Saatchi.png" title="Yunus Saatchi" alt="Yunus Saatchi" height="20px" width="20px" style="height: 20px;"/> </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Yunus Saatchi</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item  remove-action-indent   " id="rgw11_56ab199beedce" data-account-key="Yunus_Saatchi">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="profile/Yunus_Saatchi"> <img class="lazyload" data-src="https://i1.rgstatic.net/ii/profile.image/AS%3A272816591339520%401442055952095_l/Yunus_Saatchi.png" title="Yunus Saatchi" alt="Yunus Saatchi" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">     </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="profile/Yunus_Saatchi" class="display-name">Yunus Saatchi</a>    </h5> <div class="truncate-single-line meta">   <a class="meta ga-top-coauthor-institution" href="institution/University_of_Cambridge" title="University of Cambridge">University of Cambridge</a>     </div>  <a href="javascript:" class="btn btn-promote btn-large people-item-contact-author js-contact-author">Message author</a>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>  <li id="rgw12_56ab199beedce"> <a href="researcher/9164246_Yee_Whye_Teh" class="pub-detail-item author-item" itemprop="author" itemscope itemtype="http://schema.org/Person"> <div class="indent-left"> <div class="people-img">  <img src="https://c5.rgstatic.net/m/2951093203564/images/template/default/profile/profile_default_s.jpg" title="Yee Whye Teh" alt="Yee Whye Teh" height="20px" width="20px" style="height: 20px;"/>  </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Yee Whye Teh</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item   not-claimed " id="rgw13_56ab199beedce">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="researcher/9164246_Yee_Whye_Teh"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="Yee Whye Teh" alt="Yee Whye Teh" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">       </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="researcher/9164246_Yee_Whye_Teh" class="display-name">Yee Whye Teh</a>    </h5> <div class="truncate-single-line meta">   </div>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>  <li id="rgw14_56ab199beedce"> <a href="researcher/8159937_Zoubin_Ghahramani" class="pub-detail-item author-item" itemprop="author" itemscope itemtype="http://schema.org/Person"> <div class="indent-left"> <div class="people-img">  <img src="https://c5.rgstatic.net/m/2951093203564/images/template/default/profile/profile_default_s.jpg" title="Zoubin Ghahramani" alt="Zoubin Ghahramani" height="20px" width="20px" style="height: 20px;"/>  </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Zoubin Ghahramani</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item   not-claimed " id="rgw15_56ab199beedce">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="researcher/8159937_Zoubin_Ghahramani"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="Zoubin Ghahramani" alt="Zoubin Ghahramani" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">       </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="researcher/8159937_Zoubin_Ghahramani" class="display-name">Zoubin Ghahramani</a>    </h5> <div class="truncate-single-line meta">   </div>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>   </ul> <div class="js-loading"></div>  </div> </div> <div class="pub-details js-pub-details">      DOI:&nbsp;10.1145/1390156.1390293     Conference: Machine Learning, Proceedings of the Twenty-Fifth International Conference (ICML 2008), Helsinki, Finland, June 5-9, 2008      <div class="pub-source"> Source: <a href="http://dblp.uni-trier.de/db/conf/icml/icml2008.html#GaelSTG08" rel="nofollow">DBLP</a> </div>  </div> <div id="rgw16_56ab199beedce" class="pub-abstract">  <div class="clearfix">   <div style="max-height: 54px;" class="js-expander-container js-expander-collapsed">  <p itemprop="description"> <strong>ABSTRACT</strong> <div>The innite hidden Markov model is a non- parametric extension of the widely used hid- den Markov model. Our paper introduces a new inference algorithm for the innite Hidden Markov model called beam sam- pling. Beam sampling combines slice sam- pling, which limits the number of states con- sidered at each time step to a nite number, with dynamic programming, which samples whole state trajectories eciently. Our algo- rithm typically outperforms the Gibbs sam- pler and is more robust. We present appli- cations of iHMM inference using the beam sampler on changepoint detection and text prediction problems.</div> </p>  </div>  </div>   </div>     <div id="rgw17_56ab199beedce" class="figure-carousel"> <div class="carousel-hd"> Figures in this publication </div> <div class="carousel-bd"> <ul class="clearfix">  <li> <a href="/figure/221345210_fig1_Figure-6-The-left-plots-show-how-frequent-two-datapoints-were-in-the-same-cluster" class=" fig-frame js-click-link "  rel="tooltip" data-tooltip="Figure 6. The left plots show how frequent two datapoints were in the..." data-key="221345210_fig1_Figure-6-The-left-plots-show-how-frequent-two-datapoints-were-in-the-same-cluster"> <img class="fig" src="https://www.researchgate.net/profile/Yunus_Saatchi/publication/221345210/figure/fig1/Figure-6-The-left-plots-show-how-frequent-two-datapoints-were-in-the-same-cluster_small.png" alt="Figure 6. The left plots show how frequent two datapoints were in the..." title="Figure 6. The left plots show how frequent two datapoints were in the..."/> </a> </li>  </ul> </div> </div> <div class="action-container"> <div id="rgw18_56ab199beedce" class="follow-publication-promo"> <table> <tr> <td class="follow-publication-promo-text-cell"> <p>Get notified about updates to this publication</p> <a class="btn btn-large btn-promote js-follow-publication ga-follow-publication-new-promo">Follow publication</a> </td> <td> <div class="follow-publication-publication-image"></div> </td> </tr> </table> </div>  <div class="clear"></div> <div class="share-dialog-container" style="display: none;">  </div> </div> </div> <div style="margin-left: -20px; margin-right: -20px;">  </div> </div>  <div class="publication-detail-dfp-container rf"> <div id="rgw32_56ab199beedce">  </div> </div>  </div>  <div class="clearfix"> <div class="pdf-js-container clearfix " id="rgw44_56ab199beedce">  <div class="pdf-js-header js-sticky-header clear">  <a class="blue-link js-download rf btn btn-promote" href="https://www.researchgate.net/profile/Yunus_Saatchi/publication/221345210_Beam_sampling_for_the_infinite_hidden_Markov_model/links/00463525dba898f504000000.pdf?inViewer=0&amp;pdfJsDownload=0&amp;origin=publication_detail">Download full-text</a>  <h3>Full-text</h3> <span class="publication-info">  <span class="js-doi-container" style="display: none;"> DOI: <span class="js-doi"></span> &middot; </span> Available from: <a class="js-name" href="profile/Yunus_Saatchi">Yunus Saatchi</a>   </span>  </div>  <div class="social-share-container"><div id="rgw46_56ab199beedce" class="social-share js-social-share"> <div class="social-share-heading">Share</div>  <a id="rgw47_56ab199beedce" href="javascript:" title="Share on Facebook" class="link-nostyle js-share-item share-icon "  data-url="http://www.facebook.com/share.php?u={{url}}{{#title}}&amp;t={{title}}{{/title}}" data-width="600" data-height="350" data-name="Facebook"> <span class="share-icon ico-share-facebook-round reset-background ga-share-blog-facebook"></span> </a>  <a id="rgw48_56ab199beedce" href="javascript:" title="Share on Twitter" class="link-nostyle js-share-item share-icon "  data-url="http://twitter.com/intent/tweet?text={{#title}}{{title}}: {{/title}}{{url}}&amp;via=researchgate" data-width="600" data-height="350" data-name="Twitter"> <span class="share-icon ico-share-twitter-round reset-background ga-share-blog-twitter"></span> </a>  <a id="rgw49_56ab199beedce" href="javascript:" title="Share on Google+" class="link-nostyle js-share-item share-icon "  data-url="https://plus.google.com/share?url={{url}}" data-width="600" data-height="600" data-name="Google+"> <span class="share-icon ico-share-gplus-round reset-background ga-share-blog-gplus"></span> </a>  <a id="rgw50_56ab199beedce" href="javascript:" title="Share on LinkedIn" class="link-nostyle js-share-item share-icon "  data-url="http://www.linkedin.com/shareArticle?mini=true&amp;url={{url}}{{#title}}&amp;title={{title}}{{/title}}&amp;source=ResearchGate" data-width="520" data-height="570" data-name="LinkedIn"> <span class="share-icon ico-share-linkedin-round reset-background ga-share-blog-linkedin"></span> </a>  <a id="rgw51_56ab199beedce" href="javascript:" title="Share on Reddit" class="link-nostyle js-share-item share-icon "  data-url="https://www.reddit.com/submit?url={{url}}{{#title}}&amp;title={{title}}{{/title}}" data-width="600" data-height="600" data-name="Reddit"> <span class="share-icon ico-share-reddit reset-background ga-share-blog-reddit"></span> </a>  </div></div>    <iframe id="rgw45_56ab199beedce" src="https://www.researchgate.net/c/o1o9o3/javascript/lib/pdfjs/web/viewer.html?file=https%3A%2F%2Fwww.researchgate.net%2Fprofile%2FYunus_Saatchi%2Fpublication%2F221345210_Beam_sampling_for_the_infinite_hidden_Markov_model%2Flinks%2F00463525dba898f504000000.pdf%3FinViewer%3D1%26pdfJsDownload%3D1%26origin%3Dpublication_detail" allowfullscreen frameborder="0" style="width: 100%; height: 100%; box-sizing: border-box;"></iframe>    </div> <noscript> <div id="rgw31_56ab199beedce"  itemprop="articleBody">  <p>Page 1</p> <p>Beam Sampling for the Infinite Hidden Markov Model<br />Jurgen Van Gael<br />Yunus Saatci<br />Department of Engineering, University of Cambridge, Cambridge CB2 1PZ, UK<br />jv279@cam.ac.uk<br />ys267@cam.ac.uk<br />Yee Whye Teh<br />Gatsby Computational Neuroscience Unit, University College London, WC1N 3AR, UK<br />ywteh@gatsby.ucl.ac.uk<br />Zoubin Ghahramani<br />Department of Engineering, University of Cambridge, Cambridge CB2 1PZ, UK<br />zoubin@eng.cam.ac.uk<br />Abstract<br />The infinite hidden Markov model is a non-<br />parametric extension of the widely used hid-<br />den Markov model.<br />a new inference algorithm for the infinite<br />Hidden Markov model called beam sam-<br />pling. Beam sampling combines slice sam-<br />pling, which limits the number of states con-<br />sidered at each time step to a finite number,<br />with dynamic programming, which samples<br />whole state trajectories efficiently. Our algo-<br />rithm typically outperforms the Gibbs sam-<br />pler and is more robust. We present appli-<br />cations of iHMM inference using the beam<br />sampler on changepoint detection and text<br />prediction problems.<br />Our paper introduces<br />1. Introduction<br />The hidden Markov model (HMM) (Rabiner, 1989) is<br />one of the most widely used models in machine learn-<br />ing and statistics for sequential or time series data.<br />The HMM consists of a hidden state sequence with<br />Markov dynamics, and independent observations at<br />each time given the corresponding state. There are<br />three learning related tasks associated with the HMM:<br />inference of the hidden state sequence, learning of the<br />parameters, and selection of the right model size.<br />Inference for the hidden state trajectory can be<br />performed exactly using the forward-backward algo-<br />rithm (Rabiner, 1989), a dynamic programming algo-<br />rithm with O(TK2) computational costs where T is<br />the number of time steps and K number of states.<br />Appearing in Proceedings of the 25thInternational Confer-<br />ence on Machine Learning, Helsinki, Finland, 2008. Copy-<br />right 2008 by the author(s)/owner(s).<br />The standard approach to learning uses the Baum-<br />Welch algorithm, a special instance of the EM al-<br />gorithm (Dempster et al., 1977) which produces (lo-<br />cally) maximum likelihood (ML) parameters.<br />ML learning of parameters can potentially lead to over-<br />fitting if the model size is inappropriate for the amount<br />of data available. This can be partially mitigated us-<br />ing a more fully Bayesian learning procedure, e.g. using<br />variational approximations (MacKay, 1997) or Markov<br />chain Monte Carlo (MCMC) sampling (Scott, 2002).<br />Such Bayesian approaches also produce estimates of<br />the marginal probability of data, which can be used to<br />select for the appropriate model size (or to average over<br />model sizes if ones desires a more Bayesian analysis).<br />Such model selection procedures can be computation-<br />ally expensive since multiple HMMs of different sizes<br />need to be explored.<br />Such<br />A new twist on the problem of model selection has<br />emerged in recent years with the increasing popu-<br />larity of nonparametric Bayesian models. These are<br />models of infinite capacity, a finite portion of which<br />will be used to model a finite amount of observed<br />data. The idea of searching/averaging over the space<br />of finite models is replaced with Bayesian inference<br />over the size of submodel used to explain data. Ex-<br />amples of successful applications of nonparametric<br />Bayesian methods include Gaussian Processes (Ras-<br />mussen &amp; Williams, 2005) for regression and classifi-<br />cation, Dirichlet Process (DP) mixture models (Es-<br />cobar &amp; West, 1995; Rasmussen, 2000) for cluster-<br />ing heterogeneous data and density estimation, Indian<br />Buffet Processes for latent factor analysis (Griffiths<br />&amp; Ghahramani, 2006), and defining distributions over<br />non-trivial combinatorial objects such as trees (Teh<br />et al., 2008).<br />The Infinite Hidden Markov Model (iHMM), otherwise<br />known as the HDP-HMM, (Beal et al., 2002) is a non-</p>  <p>Page 2</p> <p>Beam Sampling for the Infinite Hidden Markov Model<br />parametric Bayesian extension of the HMM with an<br />infinite number of hidden states. Exact Bayesian in-<br />ference for the iHMM is intractable. Specifically, given<br />a particular setting of the parameters the forward-<br />backward algorithm cannot be applied since the num-<br />ber of states K is infinite, while with the parameters<br />marginalized out all hidden state variables will be cou-<br />pled and the forward-backward algorithm cannot be<br />applied either. Currently the only approximate in-<br />ference algorithm available is Gibbs sampling, where<br />individual hidden state variables are resampled condi-<br />tioned on all other variables (Teh et al., 2006). Unfor-<br />tunately convergence of Gibbs sampling is notoriously<br />slow in the HMM setting due to the strong dependen-<br />cies between consecutive time steps often exhibited by<br />time series data (Scott, 2002).<br />In this paper we propose a new sampler for the iHMM<br />called beam sampling. Beam sampling combines two<br />ideas—slice sampling and dynamic programming—to<br />sample whole state trajectories efficiently.<br />plication of slice sampling (Neal, 2003) is inspired<br />by (Walker, 2007), who used it to limit the number<br />of clusters considered when sampling assignment vari-<br />ables in DP mixtures to a finite number. We apply<br />slice sampling to limit to a finite number the states<br />considered in each time step of the iHMM, so that dy-<br />namic programming can be used to sample whole state<br />trajectories efficiently. We call our proposal beam<br />sampling due to its similarity to beam search, a heuris-<br />tic procedure for finding the maximum a posteriori<br />trajectory given observations in non-linear dynamical<br />systems. The underlying idea in both is to limit the<br />search to a small number of states so that a good tra-<br />jectory can be found using reasonable computational<br />resources. However, ours is a MCMC sampling method<br />with guaranteed convergence to the true posterior.<br />Our ap-<br />We first present a self-contained description of the<br />iHMM using the Hierarchical Dirichlet process (HDP)<br />formalism (Teh et al., 2006) in Section 2, followed<br />by a discussion of Gibbs sampling in Section 3. We<br />introduce beam sampling in Section 4 and compare<br />it against Gibbs sampling on both artificial and real<br />datasets in Section 5. We find that beam sampling<br />is (1) at least as fast if not faster than Gibbs sam-<br />pling; (2) more robust than Gibbs sampling as its<br />performance is not as dependent on initialization and<br />hyperparameter choice; (3) handles non-conjugacy in<br />the model more naturally; (4) straightforward to im-<br />plement. We conclude in Section 6 with a discus-<br />sion and suggestions for other cases in which beam<br />sampling might prove useful.<br />able from http://mlg.eng.cam.ac.uk/jurgen to encour-<br />age more widespread adoption of the iHMM and the<br />beam sampler.<br />All software is avail-<br />2. The Infinite Hidden Markov Model<br />We start this section by describing the finite HMM,<br />then taking the infinite limit to obtain an intuition<br />for the infinite HMM, followed by a more precise def-<br />inition. A finite HMM consists of a hidden state se-<br />quence s = (s1,s2,...,sT) and a corresponding ob-<br />servation sequence y = (y1,y2,...,yT). Each state<br />variable stcan take on a finite number of states, say<br />1...K. Transitions between states are governed by<br />Markov dynamics parameterized by the transition ma-<br />trix π, where πij= p(st= j|st−1= i), while the ini-<br />tial state probabilities are π0i= p(s1= i). For each<br />state st ∈ {1...K} there is a parameter φstwhich<br />parametrizes the observation likelihood for that state:<br />yt|st∼ F(φst). Given the parameters {π0,π,φ,K} of<br />the HMM, the joint distribution over hidden states s<br />and observations y can be written (with s0= 0):<br />p(s,y|π0,π,φ,K) =<br />T?<br />t=1<br />p(st|st−1)p(yt|st)<br />We complete the Bayesian description by specifying<br />the priors. Let the observation parameters φ be iid<br />drawn from a prior distribution H.<br />ther prior knowledge on the state sequence, the typical<br />prior for the transition (and initial) probabilities are<br />symmetric Dirichlet distributions.<br />With no fur-<br />A na¨ ıve way to obtain a nonparametric HMM with an<br />infinite number of states might be to use symmetric<br />Dirichlet priors over the transition probabilities with<br />parameter α/K and take K → ∞. Such an approach<br />has been successfully used to derive DP mixture mod-<br />els (Rasmussen, 2000) but unfortunately does not work<br />in the HMM context. The subtle reason is that there<br />is no coupling across transitions out of different states<br />since the transition probabilities are given indepen-<br />dent priors (Beal et al., 2002). To introduce coupling<br />across transitions, one may use a hierarchical Bayesian<br />formalism where the Dirichlet priors have shared pa-<br />rameters and given a higher level prior, e.g.<br />πk∼ Dirichlet(αβ),<br />β ∼ Dirichlet(γ/K ...γ/K)<br />where πkare transition probabilities out of state k and<br />β are the shared prior parameters. As K → ∞, the hi-<br />erarchical prior (1) approaches (with some alterations)<br />a hierarchical Dirichlet process (Teh et al., 2006).<br />(1)<br />A hierarchical Dirichlet process (HDP) is a set of<br />Dirichlet processes (DPs) coupled through a shared<br />random base measure which is itself drawn from a<br />DP (Teh et al., 2006).<br />DP(α,G0) with shared base measure G0, which can<br />be understood as the mean of Gk, and concentration<br />parameter α &gt; 0, which governs variability around G0,<br />Specifically, each Gk ∼</p>  <p>Page 3</p> <p>Beam Sampling for the Infinite Hidden Markov Model<br />Figure 1. iHMM Graphical Model<br />with small α implying greater variability. The shared<br />base measure is itself given a DP prior: G0∼ DP(γ,H)<br />with H a global base measure. The stick-breaking con-<br />struction for HDPs shows that the random measures<br />can be expressed as follows: G0=?∞<br />breaking construction for DPs (Sethuraman, 1994),<br />πk∼ DP(α,β), and each φk? ∼ H independently.<br />Identifying each Gkas describing both the transition<br />probabilities πkk? from state k to k?and the emis-<br />sion distributions parametrized by φk?, we can now<br />formally define the iHMM as follows:<br />k?=1βk?δφk?and<br />Gk=?∞<br />k?=1πkk?δφk?, where β ∼ GEM(γ) is the stick-<br />β ∼ GEM(γ),<br />st|st−1∼ Multinomial(πst−1),<br />The graphical model corresponding to this hierarchical<br />model is shown in figure 1. Thus βk? is the prior mean<br />for transition probabilities leading into state k?, and α<br />governs the variability around the prior mean. If we fix<br />β = (1<br />and the remaining are 0, then transition probabilities<br />into state k?will be non-zero only if k?∈ {1...K}, and<br />we recover the Bayesian HMM of (MacKay, 1997).<br />πk|β ∼ DP(α,β),φk∼ H, (2)<br />yt|st∼ F(φst). (3)<br />K...1<br />K,0,0...) where the first K entries are<br />1<br />K<br />Finally we place priors over the hyperparameters α<br />and γ. A common solution, when we do not have<br />strong beliefs about the hyperparameters, is to use<br />gamma hyperpriors: α ∼ Gamma(aα,bα) and γ ∼<br />Gamma(aγ,bγ). (Teh et al., 2006) describe how these<br />hyperparameters can be sampled efficiently, and we<br />will use this in the experiments to follow.<br />3. The Gibbs Sampler<br />The Gibbs sampler was the first sampling algorithm<br />for the iHMM that converges to the true posterior.<br />One proposal builds on the direct assignment sampling<br />scheme for the HDP in (Teh et al., 2006) by marginal-<br />izing out the hidden variables π,φ from (2), (3) and<br />ignoring the ordering of states implicit in β. Thus we<br />only need to sample the hidden trajectory s, the base<br />DP parameters β and the hyperparameters α, γ. Sam-<br />pling β,α,γ is exactly the same as for the HDP so we<br />refer to (Teh et al., 2006) for details.<br />In order to resample st, we need to compute the prob-<br />ability p(st|s−t,β,y,α,H) ∝ p(yt|st,s−t,y−t,H) ·<br />p(st|s−t,β,α).<br />ditionallikelihoodof<br />yt<br />?p(yt|st,φst)p(φst|s−t,y−t,H)dφst. This is easy to<br />F from equations (2) and<br />the second factor we can use the fact that the hid-<br />den state sequence is Markov. Let nijbe the number<br />of transitions from state i to state j excluding time<br />steps t − 1 and t. Let n·i,ni·be the number of tran-<br />sitions in and out of state i. Finally, let K be the<br />number of distinct states in s−t. Then we have that1<br />p(st= k|s−t,β,α) ∝<br />(nst−1,k+ αβk)<br />nk·+α<br />(nst−1,k+ αβk)<br />nk·+1+α<br />(nst−1,k+ αβk)<br />nk·+1+α<br />αβkβst+1<br />Thefirst factor<br />given<br />isthe<br />and<br />con-<br />H:<br />s,<br />y<br />compute when the base distribution H and likelihood<br />(3) are conjugate.For<br />nk,st+1+αβst+1<br />if k ≤ K, k ?= st−1<br />if k = st−1= st+1<br />if k = st−1?= st+1<br />if k = K + 1.<br />nk,st+1+1+αβst+1<br />nk,st+1+αβst+1<br />For each 1 ≤ t ≤ T we need to compute O(K)<br />probabilities, hence the Gibbs sampler has an O(TK)<br />computational complexity. Non-conjugate models can<br />be handled using more sophisticated sampling tech-<br />niques. In our experiments below, we used algorithm<br />8 from (Neal, 2000).<br />The Gibbs sampler’s success is due to its straightfor-<br />ward implementation. However, it suffers from one<br />major drawback: sequential and time series data are<br />likely to be strongly correlated. For example, if we<br />know the value of a stock at time t then we can be<br />reasonably sure that it will be similar at time t+1. As<br />is well known, this is a situation which is far from ideal<br />for the Gibbs sampler: strong correlations in the hid-<br />den states will make it unlikely that individual updates<br />to st can cause large blocks within s to be changed.<br />We will now introduce the beam sampler which does<br />not suffer from this slow mixing behavior by sampling<br />the whole sequence s in one go.<br />4. The Beam Sampler<br />The forward-backward algorithm does not apply to<br />the iHMM because the number of states, and hence<br />the number of potential state trajectories, are infinite.<br />The idea of beam sampling is to introduce auxiliary<br />variables u such that conditioned on u the number<br />of trajectories with positive probability is finite. Now<br />dynamic programming can be used to compute the<br />conditional probabilities of each of these trajectories<br />and thus sample whole trajectories efficiently. These<br />1Recall that we ignored the ordering of states in β. In<br />this representation the K distinct states in s are labeled<br />1...K and K + 1 denotes a new state.</p>  <p>Page 4</p> <p>Beam Sampling for the Infinite Hidden Markov Model<br />Figure 2. The auxiliary variable u partitions the probabil-<br />ity distribution π (vertical bars) into a set of entries less<br />than u and a set of entries larger than u.<br />auxiliary variables do not change the marginal distri-<br />bution over other variables hence MCMC sampling will<br />converge to the true posterior. This idea of using aux-<br />iliary variables to limit computation costs is inspired<br />by (Walker, 2007), who applied it to limit the number<br />of components in a DP mixture model that need be<br />considered during sampling.<br />As opposed to the sampler in the previous section,<br />the beam sampler does not marginalize out π nor φ.<br />Specifically, the beam sampler iteratively samples the<br />auxiliary variables u, the trajectory s, the transition<br />probabilities π, the shared DP parameters β and the<br />hyperparameters α and γ conditioned on all other vari-<br />ables. In the following, we shall describe in more detail<br />how to sample each set of variables, as well as how the<br />auxiliary variables allow dynamic programming to be<br />carried out over a finite number of trajectories without<br />approximations.<br />Sampling u:<br />iary variable ut with conditional distribution ut ∼<br />Uniform(0,πst−1st) depending on π, st−1and st.<br />Sampling s: we sample the whole trajectory s given<br />the auxiliary variables u and other variables using a<br />form of forward filtering-backward sampling. The im-<br />portant observation here is that only trajectories s<br />with πst−1st≥ utfor all t will have non-zero probabil-<br />ity given u. There are only finitely many such trajec-<br />tories2and as a result we can compute the conditional<br />distribution over all such trajectories efficiently using<br />dynamic programming.<br />for each t we introduce an auxil-<br />First note that the probability density for ut is<br />p(ut|st−1,st,π) =<br />if condition C is true and 0 otherwise. We compute<br />p(st|y1:t,u1:t) for all t as follows (we omitted the ad-<br />2To see this, note that ut &gt; 0 with probability 1 for each<br />t, since each πkk? &gt; 0 with probability 1. Given the auxil-<br />iary variable ut, note further that for each possible value of<br />st−1, ut partitions the set of transition probabilities out of<br />state st−1 into two sets: a finite set with πst−1k &gt; ut and<br />an infinite set with πst−1k &lt; ut, as illustrated in figure 2.<br />Thus we can recursively show that for t = 1,2...T the set<br />of trajectories s1:t with all πst?−1st?&gt; ut is finite.<br />I(0&lt;ut&lt;πst−1,st)<br />πst−1,st<br />, where I(C) = 1<br />ditional conditioning variables π and φ for clarity):<br />p(st|y1:t,u1:t)<br />∝p(st,ut,yt|y1:t−1,u1:t−1),<br />=<br />p(yt|st)p(ut|st,st−1)p(st|st−1)<br />?<br />st−1<br />p(st−1|y1:t−1,u1:t−1),<br />=p(yt|st)<br />st−1<br />=p(yt|st)<br />st−1:ut&lt;πst−1,st<br />?<br />I(ut&lt; πst−1,st)p(st−1|y1:t−1,u1:t−1),<br />?<br />Note that we only need to compute (4) for the finitely<br />many st values belonging to some trajectory with<br />positive probability. Further, although the sum over<br />st−1 is technically a sum over an infinite number of<br />terms, the auxiliary variable uttruncates this summa-<br />tion to the finitely many st−1’s that satisfy both con-<br />straints πst−1,st&gt; ut and p(st−1|y1:t−1,u1:t−1) &gt; 0.<br />Finally, to sample the whole trajectory s, we sam-<br />ple sT from p(sT|y1:T,u1:T) and perform a backward<br />pass where we sample st given the sample for st+1:<br />p(st|st+1,y1:T,u1:T) ∝ p(st|y1:t,u1:t)p(st+1|st,ut+1).<br />Sampling π, φ, β:<br />these follow directly from the<br />theory of HDPs (Teh et al., 2006), but we briefly de-<br />scribe these for completeness.<br />p(st−1|y1:t−1,u1:t−1).<br />(4)<br />Let nij be the number of times state i transi-<br />tions to state j in the trajectory s, where i,j ∈<br />{1...K}, K is the number of distinct states in s,<br />and these states have been relabeled 1...K. Merg-<br />ing the infinitely many states not represented in<br />s into one state, the conditional distribution of<br />(πk1...πkK,?∞<br />Dirichlet?nk1+ αβ1...nkK+ αβK,α?∞<br />To sample β we introduce a further set of auxiliary<br />variables mijwhich are independent with conditional<br />distributions<br />k?=K+1πkk?) given its Markov blanket<br />s,β, α is<br />i=K+1βi<br />?,<br />p(mij= m|s,β,α) ∝ S(nij,m)(αβj)m,<br />where S(·,·) denotes Stirling numbers of the first kind.<br />The shared DP parameter (β1...,βK,?∞<br />Dirichlet(m·1...m·K,γ),<br />where m·k=?K<br />Finally, each φkis independent of others conditional on<br />s, y and their prior distribution H, i.e. p(φ|s,y,H) =<br />k?=K+1βk?)<br />has conditional distribution<br />k?=1mk?k. (Teh et al., 2006; Antoniak,<br />1974) gives more details.</p>  <p>Page 5</p> <p>Beam Sampling for the Infinite Hidden Markov Model<br />0 50010001500<br /> <br />0<br />0.2<br />0.4<br />0.6<br />0.8<br />1<br />Iterations<br />p(Error)<br /> <br /> <br />Gibbs Vague<br />Gibbs Strong<br />Gibbs Fixed<br />Beam Vague<br />Beam Strong<br />Beam Fixed<br />0 20406080 100<br />0<br />5<br />10<br />Iterations<br /># transitions<br /> <br />Beam Vague<br />Beam Strong<br />Beam Fixed<br />Figure 3. iHMM performance on strong negatively corre-<br />lated data. The top plot shows the error of the Gibbs and<br />beam sampler for the first 1500 iterations averaged over<br />20 runs. The bottom plot shows the average number of<br />previous states considered in equation (4) for the first 100<br />iterations of the beam sampler.<br />?<br />be sampled efficiently. Otherwise we may resort to<br />Metropolis-Hastings or other approaches. Note that in<br />the non-conjugate case this is simpler than for Gibbs<br />sampling. In the experimental section, we describe an<br />application where the base distribution and likelihood<br />are non-conjugate.<br />kp(φk|s,y,H).<br />conjugate to the data distribution F each φk can<br />When the base distribution H is<br />To conclude our discussion of the beam sampler, it<br />is useful to point out that there is nothing special<br />about sampling ut from the uniform distribution on<br />[0,πst−1,st]: by choosing a distribution over [0,πst,st−1]<br />with higher mass near smaller values of ut, we will al-<br />low more trajectories to have positive probability and<br />hence considered by the forward filtering-backward<br />sampling algorithm. Although this will typically im-<br />prove mixing time, it also comes at additional compu-<br />tational cost. This brings us to the issue of the com-<br />putational cost of the beam sampler: since for each<br />timestep and each state assignment we need to sum<br />over all represented previous states, the worst case<br />complexity is O(TK2). However, the sum in (4) is only<br />over previous states for which the transition probabil-<br />ity is larger than ut; this means that in practice we<br />might only need to sum over a few previous states.<br />In our experiments below, we will give some empirical<br />evidence for this “average case” behavior. Further, we<br />have found that the drastically improved mixing of the<br />beam sampler more than made up for the additional<br />cost over Gibbs sampling. Finally, although we did not<br />find any advantage doing so, it is certainly possible to<br />interleave the beam sampler and the Gibbs sampler.<br />0100 200<br />0<br />0.25<br />0.5<br />0.75<br />1<br />0.750<br />0 100200<br />0<br />0.25<br />0.5<br />0.75<br />1<br />0.950<br />0 100200<br />0<br />0.25<br />0.5<br />0.75<br />1<br />0.999<br />0 100200<br />0<br />0.25<br />0.5<br />0.75<br />1<br />0.750<br />0100200<br />0<br />0.25<br />0.5<br />0.75<br />1<br />0.950<br />0100200<br />0<br />0.25<br />0.5<br />0.75<br />1<br />0.999<br />Figure 4. iHMM error on increasing positively correlated<br />data. The blue curve shows the beam sampler while the red<br />curve shows the Gibbs sampler performance. The dotted<br />line show the one standard deviation error bars.<br />5. Experiments<br />We evaluate the beam sampler on two artificial and<br />two real datasets to illustrate the following properties:<br />(1) the beam sampler mixes in much fewer iterations<br />than the Gibbs sampler; (2) the actual complexity per<br />iteration of the beam sampler is only marginally more<br />than the Gibbs sampler; (3) the beam sampler mixes<br />well regardless of strong correlations in the data; (4)<br />the beam sampler is more robust with respect to vary-<br />ing initialization and prior distribution; (5) the beam<br />sampler handles non conjugate models naturally; (6)<br />the iHMM is a viable alternative to the finite HMM.<br />All datasets and a Matlab version of our software are<br />available at http://mlg.eng.cam.ac.uk/jurgen.<br />5.1. Artificial Data<br />Our first experiment compares the performance of the<br />iHMM on a sequence of length 800 generated by a 4<br />state HMM. The hidden state sequence was almost<br />cyclic (1-2-3-4-1-2-3-...) with a 1% probability of self<br />transition: i.o.w the true distribution of hidden states<br />is strong negatively correlated. We use a multinomial<br />output distribution with the following emission matrix<br /><br /><br />Next we run the Gibbs and beam sampler 20 times<br />from a random initialization with every state randomly<br />chosen between 1 and 20. We test the performance<br />of both samplers using three different hyperparame-<br />ter settings: (1) vague gamma hyperpriors for α and<br /><br />0.00.50.5<br />0.6666<br />0.5<br />0.3333<br />0.1666<br />0.0<br />0.3333<br />0.1666<br />0.5<br />0.3333<br /><br />.<br /></p>  <p>Page 6</p> <p>Beam Sampling for the Infinite Hidden Markov Model<br />5001000150020002500300035004000<br />−4<br />−2<br />0<br />2<br />x 10<br />4<br />NMR Response<br />Measurement #<br />Figure 5. The 40’th sample of the beam sampler with every state represented by a different color on the well-log dataset.<br />γ (Gamma(1,1) and Gamma(2,1) respectively); (2)<br />strong gamma hyperpriors for α and γ (Gamma(6,15)<br />and Gamma(16,4) respectively); (3) fixed hyperparam-<br />eters α = 0.4,γ = 3.8. The latter were chosen using<br />the values the beam and Gibbs samplers converged to.<br />At every iteration, we greedily compute an assignment<br />of sample states to true states to maximize overlap and<br />use the resulting Hamming distance as our error mea-<br />sure. The top plot in figure 3 clearly shows that the<br />beam sampler discovers the underlying structure much<br />faster than the Gibbs sampler. Also, the beam sam-<br />pler is insensitive to the prior while the performance<br />of the Gibbs sampler becomes worse as we strengthen<br />our prior beliefs. The bottom plot of figure 3 shows<br />how many states are summed over in equation (4) av-<br />eraged per timestep, per state. We find that after only<br />about 20 iterations, the beam sampler on average con-<br />siders a little more than one state. This implies that<br />the actual complexity of the beam sampler is closer<br />to O(TK) rather than the worst case complexity of<br />O(TK2). Although this behavior is dependent on the<br />choice of distribution for the auxiliary variable utand<br />the sparsity of the transition matrix, we have verified<br />that this behavior is consistent also for larger iHMM’s.<br />Our second experiment illustrates the performance of<br />the beam sampler on data generated from HMM’s<br />with increasing positive correlation between the hid-<br />den states. We generated sequences of length 4000<br />from a 4 state HMM with self-transition probabilities<br />increasing from 0.75 to 0.95 and finally 0.999. In one<br />experiment (top plot of figure 4) we generated nor-<br />mal distributed observation from an informative out-<br />put model with means −2.0,4.0,1.0,−0.5 and stan-<br />dard deviation 0.5, in another experiment (bottom<br />plot of figure 4) we generated normal distributed ob-<br />servations from a less informative output model with<br />means −1.0,0.5,−0.5,0.0 and standard deviation 0.5.<br />We initialize the experiment as above and set the base<br />distribution for the state means to be a 0 mean normal<br />with 2.0 standard deviation. Then, we greedily com-<br />pute the error compared to ground truth and average<br />the results over 60 different random starting positions.<br />The top row shows that with an informative prior,<br />both the Gibbs and beam sampler can reduce the ini-<br />tial error by at least 50% independent of the correla-<br />tion between hidden states. When the output model<br />is less informative however and there is little corre-<br />lation between the hidden states, the learning prob-<br />lem is hardest: the lower left plot shows that both<br />the beam and Gibbs sampler discover structure only<br />slowly. When the correlation increases, the learning<br />problem should become easier. However, as the lower<br />right plot shows, although the beam sampler mixes in-<br />creasingly well, the Gibbs sampler suffers from slow<br />random walk behavior.<br />5.2. Well Data<br />The next experiment illustrates the performance of<br />the iHMM on a changepoint detection problem. The<br />data consists of 4050 noisy measurements of nuclear-<br />response of rock strata obtained via lowering a probe<br />through a bore-hole. Figure 5 illustrates this datasets.<br />The data has been previously analyzed in (Ruanaidh<br />&amp; Fitzgerald, 1996) by eliminating the forty great-<br />est outliers and running a changepoint detection algo-<br />rithm with a fixed number of changepoints. This ap-<br />proach works well as this one-dimensional dataset can<br />be inspected visually to make a decision on whether<br />to throw away datapoints and get a rough idea for<br />the number of changepoints. However, we believe that<br />with a nonparametric model, we can automatically<br />adapt the number of changepoints. Moreover, by set-<br />ting up a noise model with fat tails, we hope to auto-<br />matically handle the outlier problem.<br />We model the mean of the nuclear-response for every<br />segment. First we normalize the data to have zero<br />mean; then we specify a zero mean normal distribu-<br />tion for the base distribution H. We choose the vari-<br />ance of this normal to be the empirical variance of the<br />dataset. For the output model, we let F correspond<br />to a Student-t distribution with ν = 1, also known<br />as the Cauchy distribution. We set the scale parame-<br />ter for the Cauchy distribution to twice the empirical<br />standard deviation for the dataset. Since the Cauchy<br />likelihood is not conjugate with respect to the nor-<br />mal base distribution, we modified the Gibbs sampler<br />based on algorithm 8 in (Neal, 2000). We use the aux-</p>  <p>Page 7</p> <p>Beam Sampling for the Infinite Hidden Markov Model<br />Figure 6. The left plots show how frequent two datapoints<br />were in the same cluster averaged over the first 5 samples.<br />The right plots show how frequently two datapoints were<br />in the same cluster averaged over the last 30 samples.<br />iliary variable sampling scheme discussed in (Gelman<br />et al., 2004) to resample the segment means.<br />Figure 5 shows the results of one sample from the beam<br />sampler: the iHMM segments the dataset reasonably<br />well and robustly handles the outliers. To compare the<br />Gibbs and beam samplers, we compute 50 samples af-<br />ter a burnin of 5000 iterations with 1000 iterations in<br />between each sample. For every pair of datapoints we<br />compute the probability that they are in the same seg-<br />ment, averaged over the first five samples (left plots in<br />figure 6) and the last thirty samples (right plots in<br />figure 6). First, note that after the first 10000 itera-<br />tions, the Gibbs sampler hasn’t discovered any struc-<br />ture while the beam sampler has. This supports our<br />claim that the beam sampler mixes faster than the<br />Gibbs sampler. Moreover, we expect that the Gibbs<br />sampler will have trouble to reassign the state assign-<br />ment for whole segments because of slow random walk<br />behavior. The beam sampler on the other hand re-<br />samples whole hidden state sequences and should be<br />able to reassign whole segments more easily. The right<br />plots of figure 6 confirm our expectation: a careful in-<br />spection of both plots shows that the Gibbs sampler<br />is visually more black-white indicating that either two<br />datapoints are always in the same cluster or never in<br />the same cluster; the beam sampler, on the other hand,<br />has gray areas which indicate that it averages over dif-<br />ferent assignments of the segments: e.g. the Gibbs plot<br />(upper right) suggests that the leftmost segment and<br />rightmost segment are always in the same state, while<br />the beam sampler plot (bottom right) indicates that<br />only part of the time, the left and rightmost segments<br />are in the same state (90% of the time).<br />5.3. Alice in Wonderland<br />Another application domain for HMMs is the area of<br />text prediction. One such task is that of predicting<br />sequences of letters in text taken from Alice’s Adven-<br />tures in Wonderland. We compare the performance of<br />a finite HMM trained using variational Bayes (as de-<br />scribed in (MacKay, 1997)) with two iHMMs trained<br />using beam sampling and Gibbs sampling. Both sam-<br />plers had a burn-in of 1000 iterations and an additional<br />10000 iterations to collect 50 samples of hidden state<br />sequences from the posterior (i.e. we sample every 200<br />iterations).<br />The training data for each HMM (whether finite or<br />infinite) was taken to be a single sequence of 1000<br />characters from the first chapter of the book. There<br />were 31 different observation symbols (26 letters ignor-<br />ing case plus space and basic punctuation characters).<br />The test data was taken to be the subsequent 4000<br />characters from the same chapter. For all finite HMMs<br />we analyzed performance on models with the number<br />of hidden states ranging from 1 to 50. For VB, we<br />note that the true predictive distribution is intractable<br />to compute. Therefore, we used the posterior param-<br />eter distributions to sample 50 candidate parameter<br />settings, and used these to compute an approximate<br />predictive log-likelihood.<br />pled 50 hidden state sequences from the stationary<br />distribution after convergence and used these samples<br />to compute an approximate predictive log-likelihood.<br />For the VB-HMM we set the prior pseudo-counts for<br />the transition matrix to 4/K across all states and<br />the prior pseudo-counts for the emission matrix to 0.3<br />across all symbols. Accordingly, we set the hyperprior<br />for the iHMMs such that aα = 4 and bα = 1 and<br />H ∼ Dirichlet(()0.3,···0.3). The results for VB and<br />the iHMMs were averaged over 50 and 20 independent<br />For the iHMMs, we sam-<br />10 20 30 40 50<br />−1.16<br />−1.14<br />−1.12<br />−1.1<br />−1.08<br />−1.06x 10<br />4<br />Number of hidden states (K)<br />Predictive Log−likelihood<br /> <br /> <br />iHMMs<br />VB−HMM<br />Figure 7. Comparing VB-HMM with the iHMM.</p>  <p>Page 8</p> <p>Beam Sampling for the Infinite Hidden Markov Model<br />runs respectively. The plot includes error bars corre-<br />sponding to 2 standard deviations.<br />Figure 7 illustrates the estimated predictive log-<br />likelihoods for the finite VB-HMM and the two iHMMs<br />trained using beam and Gibbs sampling. We find that<br />the iHMMs have superior predictive power when com-<br />pared to the VB-HMM, even when we select the best<br />number of hidden states (around K = 16). Both the<br />iHMMs converged to a posterior distribution over hid-<br />den state sequences with around 16 states, showing<br />that nonparametric Bayesian techniques are an effec-<br />tive way to handle model selection. The final perfor-<br />mance of the Gibbs and beam sampler were not found<br />to be significantly different as we set the number of<br />iterations high enough to ensure that both algorithms<br />converge. Indeed, the aim of this experiment is not to<br />compare the performance of individuals iHMM sam-<br />pling schemes, rather, it is to further illustrate the rel-<br />ative effectiveness of using models of infinite capacity.<br />6. Conclusion<br />In this paper we introduced the beam sampler, a new<br />inference algorithm for the iHMM that draws inspi-<br />ration from slice sampling and dynamic programming<br />to sample whole hidden state trajectories efficiently.<br />We showed that the beam sampler is a more robust<br />sampling algorithm than the Gibbs sampler. We be-<br />lieve that the beam sampler is the algorithm of choice<br />for iHMM inference because it converges faster than<br />the Gibbs sampler and is straightforward to imple-<br />ment.Moreover, it conveniently allows us to learn<br />non-conjugate models. To encourage adoption of the<br />iHMM as an alternative to HMM learning, we have<br />made the software and datasets used in this paper<br />available at http://mlg.eng.cam.ac.uk/jurgen.<br />The beam sampler idea is flexible enough to do in-<br />ference for various extensions of the iHMM: our cur-<br />rent work involves an adaptation of the beam sampler<br />to an extension of the iHMM that handles inputs, ef-<br />fectively resulting in a nonparametric generalization<br />of the input-output HMM (Bengio &amp; Frasconi, 1995).<br />We believe this is a promising model for nonparamet-<br />ric Bayesian learning of POMDPs. Another project<br />currently underway is to use the beam sampler for ef-<br />ficiently learning finite, but very large hidden Markov<br />models. Finally, we are exploring the possibilities of<br />using the embedded HMM construction (Neal et al.,<br />2004) as an alternative for the beam sampler for effi-<br />cient inference in the iHMM.<br />Acknowledgements<br />We would like to thank the anonymous reviewers for their<br />helpful comments. JVG is supported by a Microsoft Re-<br />search PhD scholarship; ZG is also in the Machine Learning<br />Department, CMU.<br />References<br />Antoniak, C. E. (1974).<br />with applications to bayesian nonparametric problems.<br />The Annals of Statistics, 2, 1152–1174.<br />Mixtures of dirichlet processes<br />Beal, M. J., Ghahramani, Z., &amp; Rasmussen, C. E. (2002).<br />The infinite hidden markov model. NIPS, 14.<br />Bengio, Y., &amp; Frasconi, P. (1995). An input output hmm<br />architecture. NIPS, 7.<br />Dempster, A. P., Laird, N. M., &amp; Rubin, D. B. (1977).<br />Maximum likelihood from incomplete data via the em<br />algorithm. Journal of the Royal Statistical Society. Se-<br />ries B (Methodological), 39, 1–38.<br />Escobar, M. D., &amp; West, M. (1995). Bayesian density es-<br />timation and inference using mixtures. Journal of the<br />American Statistical Association, 90, 577–588.<br />Gelman, A., Carlin, J. B., Stern, H. S., &amp; Rubin, D. B.<br />(2004). Bayesian data analysis. CRC Press. 2rev ed<br />edition.<br />Griffiths, T. L., &amp; Ghahramani, Z. (2006). Infinite latent<br />feature models and the indian buffet process. NIPS, 18.<br />MacKay, D. J. C. (1997). Ensemble learning for hidden<br />markov models. Technical report, Cavendish Laboratory,<br />University of Cambridge, 1997.<br />Neal, R. M. (2000). Markov chain sampling methods for<br />dirichlet process mixture models. Journal of Computa-<br />tional and Graphical Statistics, 9, 249–265.<br />Neal, R. M. (2003). Slice sampling. The Annals of Statis-<br />tics, 31, 705–741.<br />Neal, R. M., Beal, M. J., &amp; Roweis, S. T. (2004). Inferring<br />state sequences for non-linear systems with embedded<br />hidden markov models. NIPS, 16.<br />Rabiner, L. R. (1989). A tutorial on hidden markov models<br />and selected applications inspeech recognition. Proceed-<br />ings of the IEEE, 77, 257–286.<br />Rasmussen, C. E. (2000). The infinite gaussian mixture<br />model. NIPS, 12.<br />Rasmussen, C. E., &amp; Williams, C. K. I. (2005). Gaussian<br />processes for machine learning. The MIT Press.<br />Ruanaidh, J., &amp; Fitzgerald, W. J. (1996).<br />bayesian methods applied to signal processing. Springer-<br />Verlag New York Inc.<br />Numerical<br />Scott, S. L. (2002). Bayesian methods for hidden Markov<br />models: Recursive computing in the 21st century. Jour-<br />nal of the American Statistical Association, 97, 337–351.<br />Sethuraman, J. (1994). A constructive definition of dirich-<br />let priors. Statistica Sinica, 4, 639–650.<br />Teh, Y. W., III, H. D., &amp; Roy, D. (2008). Bayesian ag-<br />glomerative clustering with coalescents. NIPS, 20.<br />Teh, Y. W., Jordan, M. I., Beal, M. J., &amp; Blei, D. M.<br />(2006). Hierarchical dirichlet processes. Journal of the<br />American Statistical Association, 101, 1566–1581.<br />Walker, S. G. (2007). Sampling the dirichlet mixture model<br />with slices. Communications in Statistics - Simulation<br />and Computation, 36, 45.</p>  <a href="https://www.researchgate.net/profile/Yunus_Saatchi/publication/221345210_Beam_sampling_for_the_infinite_hidden_Markov_model/links/00463525dba898f504000000.pdf">Download full-text</a> </div> <div id="rgw23_56ab199beedce" class="c-box pub-resource-container js-toggle" style=""> <h4 class="lf js-expand-list"><small><a href="javascript:" class="lf">View other sources <span class="ico-expand-list"></span></a></small></h4> <h4 class="lf js-collapse-list hidden"><small><a href="javascript:" class="lf">Hide other sources <span class="ico-collapse-list"></span></a></small></h4> <div class="clear"></div> <div class="scroll-wrapper hidden"> <ul class="files-list c-list" id="rgw24_56ab199beedce">  <li class="c-list-item pub-resource-item"  data-type="fulltext" id="rgw25_56ab199beedce"> <span class="ico-pub"></span> <div class="file-content"> <div class="download"> <a href="profile/Yunus_Saatchi/publication/221345210_Beam_sampling_for_the_infinite_hidden_Markov_model/links/00463525dba898f504000000.pdf" class="publication-viewer" title="00463525dba898f504000000.pdf">00463525dba898f504000000.pdf</a> </div>  <div class="details">  <span> Available from <a href="profile/Yunus_Saatchi">Yunus Saatchi</a> &middot; May 28, 2014 </span>   </div>    </div> </li>  <li class="c-list-item pub-resource-item"  data-type="fulltext" id="rgw26_56ab199beedce"> <span class="ico-pub"></span> <div class="file-content"> <div class="download"> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.140.1680&amp;amp;rep=rep1&amp;amp;type=pdf" target="_blank" rel="nofollow" class="publication-viewer" title="Beam sampling for the infinite hidden Markov model">Beam sampling for the infinite hidden Markov model</a> </div>  <div class="details">   Available from <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.140.1680&amp;amp;rep=rep1&amp;amp;type=pdf" target="_blank" rel="nofollow">psu.edu</a>  </div>    </div> </li>  </ul> </div> </div> </noscript> <div class="clearfix"> <div class="action-container">  </div> <div class="pub-legal"> Data provided are for informational purposes only. Although carefully collected, accuracy cannot be guaranteed. The impact factor represents a rough estimation of the journal's impact factor and does not reflect the actual current impact factor. Publisher conditions are provided by RoMEO. Differing provisions from the publisher's actual policy or licence agreement may be applicable. </div>  <div id="rgw33_56ab199beedce" class="citations-container"> <div class="tab-container"> <ul class="tab-list"> <li class="lf tab-item  js-citations"> <a href="javascript:void(0);" class="tab-link"> References  </small> </a> </li>  <li class="lf tab-item tab-item-active js-cited-in js-cited-in-tooltip"> <a href="javascript:void(0);" class="tab-link"> Cited In <small> (77) </small> </a> </li>    <li class="rf"> <div class="dropdown js-citations-sorter dropdown-right-align" style="position: relative; bottom: -1px;display:none;"> <a href="javascript:void(0);" class="dropdown-toggle"> Sorted by: <strong class="js-current-sorting"> Order of availability  </strong> <span class="caret"></span> </a> <ul class="dropdown-menu"> <li><a href="javascript:void(0);" data-sort="normal">Order of availability</a></li> <li><a href="javascript:void(0);" data-sort="original">Appearance in publication</a></li> </ul> </div> </li>  </ul> <div class="tab-section tab-section-active js-citations-list-container"> <div id="rgw34_56ab199beedce" class="pub-citations-list">  <ul class="c-list">  <li class="c-list-item li-publication   includes-citation-list"  id="rgw35_56ab199beedce" >  <div class="indent-left">  <div id="rgw36_56ab199beedce" class="js-publication-item-fulltext fulltext-thumb">    <a class="publication-preview ga-publication-viewer js-publication-item-fulltext-content" href="publication/263582646_Infinite_Structured_Hidden_Semi-Markov_Models">       </a>   <div class="preview-source-info"> <a class="details js-show-source ga-source-url" href="profile/Jonathan_Huggins" >Source</a>  <div class="tooltip-content" style="display: none"> Available from: Jonathan H Huggins </div> </div>   </div>  </div>  <div class="indent-right">      </div>  <ul class="citation-contexts" id="rgw37_56ab199beedce">  <li class="citation-context-item"> "Inference in the two models is different: PPM inference is performed using a O(T 2 ) dynamic programming approach [5] which exactly computes the map partition (and implicitly the partition cardinality K and per-segment observation parameter distributions). There is an approximate inference algorithm which scales like our O(T ) approach [5], but it does not have the kinds of asymptotic convergence guarantees the auxiliary variable slice sampling approach does [31] " </li>  </ul>   <div  style="margin-top: -2px">  <h5 class="pub-type-and-title">  <span class="publication-type">Article:</span>    <a class="js-publication-title-link js-go-to-publication ga-publication-item" href="publication/263582646_Infinite_Structured_Hidden_Semi-Markov_Models"> <span class="publication-title js-publication-title">Infinite Structured Hidden Semi-Markov Models</span> </a>     </h5>  </div>    <div class="authors">     <a href="researcher/2033083818_Jonathan_H_Huggins" class="authors js-author-name ga-publications-authors">Jonathan H. Huggins</a> &middot;     <a href="researcher/70496072_Frank_Wood" class="authors js-author-name ga-publications-authors">Frank Wood</a>      </div>        <div class="abstract"> <span class="shorten"> <a href="javascript:" class="js-toggle-abstract">[Show abstract]</a> </span> <span class="full"> <a href="javascript:" class="js-toggle-abstract">[Hide abstract]</a><br/>  <strong>ABSTRACT:</strong> This paper reviews recent advances in Bayesian nonparametric techniques for
constructing and performing inference in infinite hidden Markov models. We
focus on variants of Bayesian nonparametric hidden Markov models that enhance a
posteriori state-persistence in particular. This paper also introduces a new
Bayesian nonparametric framework for generating left-to-right and other
structured, explicit-duration infinite hidden Markov models that we call the
infinite structured hidden semi-Markov model. </span> </div>    <div class="publication-meta publication-meta">   <span class="ico-publication-fulltext reset-background"></span> Full-text   &middot; Article &middot; Jun 2014  </div>        <div class="publication-actions"> <div class="btn-group">  <a class="btn btn-plain action-download primary  open-viewer" href="profile/Jonathan_Huggins/publication/263582646_Infinite_Structured_Hidden_Semi-Markov_Models/links/54cba2260cf24601c08819ac.pdf?origin=publication_list">  <span class="js-btn-label">Download</span> </a>    </div> </div>      </li>  <li class="c-list-item li-publication   includes-citation-list"  id="rgw38_56ab199beedce" >  <div class="indent-left">  <div id="rgw39_56ab199beedce" class="js-publication-item-fulltext fulltext-thumb">    <a class="publication-preview ga-publication-viewer js-publication-item-fulltext-content" href="publication/269164447_Pattern_discovery_in_continuous_speech_using_Block_Diagonal_Infinite_HMM">       </a>   <div class="preview-source-info"> <a class="details js-show-source ga-source-url" href="profile/Giampiero_Salvi" >Source</a>  <div class="tooltip-content" style="display: none"> Available from: Giampiero Salvi </div> </div>   </div>  </div>  <div class="indent-right">      </div>  <ul class="citation-contexts" id="rgw40_56ab199beedce">  <li class="citation-context-item"> "The method, as implemented for this paper, uses the Beam Sampling algorithm described in [4] to sample a hidden Markov model, and the method described in chapter 4 of [3] to sample an appropriate block configuration for this model. The beam sampling method was chosen due to its speed of inference relative to the traditional approach [24], the difference being that [4] introduces a way of sampling a statepath for the iHMM using a dynamic programming algorithm, similarly to the way a traditional HMM is commonly trained. Using the dynamic programming algorithm, the state path is Fig. 1: Graphical depiction of BDiHMM model[3] sampled as a whole rather than as many individual parameters as would otherwise be the case with Gibbs sampling. " </li>  </ul>   <div  style="margin-top: -2px">  <h5 class="pub-type-and-title">  <span class="publication-type">Conference Paper:</span>    <a class="js-publication-title-link js-go-to-publication ga-publication-item" href="publication/269164447_Pattern_discovery_in_continuous_speech_using_Block_Diagonal_Infinite_HMM"> <span class="publication-title js-publication-title">Pattern discovery in continuous speech using Block Diagonal Infinite HMM</span> </a>     </h5>  </div>    <div class="authors">     <a href="researcher/2059751469_Niklas_Vanhainen" class="authors js-author-name ga-publications-authors">Niklas Vanhainen</a> &middot;     <a href="researcher/8648081_Giampiero_Salvi" class="authors js-author-name ga-publications-authors">Giampiero Salvi</a>      </div>        <div class="abstract"> <span class="shorten"> <a href="javascript:" class="js-toggle-abstract">[Show abstract]</a> </span> <span class="full"> <a href="javascript:" class="js-toggle-abstract">[Hide abstract]</a><br/>  <strong>ABSTRACT:</strong> We propose the application of a recently introduced inference method, the Block Diagonal Infinite Hidden Markov Model (BDiHMM), to the problem of learning the topology of a Hidden Markov Model (HMM) from continuous speech in an unsupervised way. We test the method on the TiDigits continuous digit database and analyse the emerging patterns corresponding to the blocks of states inferred by the model. We show how the complexity of these patterns increases with the amount of observations and number of speakers. We also show that the patterns correspond to sub-word units that constitute stable and discriminative representations of the words contained in the speech material. </span> </div>    <div class="publication-meta publication-meta">   <span class="ico-publication-fulltext reset-background"></span> Full-text   &middot; Conference Paper &middot; May 2014  </div>        <div class="publication-actions"> <div class="btn-group">  <a class="btn btn-plain action-download primary  open-viewer" href="profile/Giampiero_Salvi/publication/269164447_Pattern_discovery_in_continuous_speech_using_Block_Diagonal_Infinite_HMM/links/5565cfed08aec4b0f48696b2.pdf?origin=publication_list">  <span class="js-btn-label">Download</span> </a>    </div> </div>      </li>  <li class="c-list-item li-publication   includes-citation-list"  id="rgw41_56ab199beedce" >  <div class="indent-left">  <div id="rgw42_56ab199beedce" class="js-publication-item-fulltext fulltext-thumb">    <a class="publication-preview ga-publication-viewer js-publication-item-fulltext-content" href="publication/260428846_Modeling_the_Complex_Dynamics_and_Changing_Correlations_of_Epileptic_Events">       </a>   <div class="preview-source-info"> <a class="details js-show-source ga-source-url" href="profile/Brian_Litt" >Source</a>  <div class="tooltip-content" style="display: none"> Available from: Brian Litt </div> </div>   </div>  </div>  <div class="indent-right">      </div>  <ul class="citation-contexts" id="rgw43_56ab199beedce">  <li class="citation-context-item"> "Other work has explored nonparametric modeling of multiple time series. The infinite factorial HMM of Van Gael et al. [9] considers an infinite collection of chains each with a binary state space. The infinite hierarchical HMM [10] also involves infinitely many chains with finite state spaces, but with constrained transitions between the chains in a top down fashion. " </li>  </ul>   <div  style="margin-top: -2px">  <h5 class="pub-type-and-title">  <span class="publication-type">Article:</span>    <a class="js-publication-title-link js-go-to-publication ga-publication-item" href="publication/260428846_Modeling_the_Complex_Dynamics_and_Changing_Correlations_of_Epileptic_Events"> <span class="publication-title js-publication-title">Modeling the Complex Dynamics and Changing Correlations of Epileptic Events</span> </a>     </h5>  </div>    <div class="authors">     <a href="researcher/71067565_Drausin_F_Wulsin" class="authors js-author-name ga-publications-authors">Drausin F. Wulsin</a> &middot;     <a href="researcher/44211050_Emily_B_Fox" class="authors js-author-name ga-publications-authors">Emily B. Fox</a> &middot;     <a href="researcher/39899419_Brian_Litt" class="authors js-author-name ga-publications-authors">Brian Litt</a>      </div>        <div class="abstract"> <span class="shorten"> <a href="javascript:" class="js-toggle-abstract">[Show abstract]</a> </span> <span class="full"> <a href="javascript:" class="js-toggle-abstract">[Hide abstract]</a><br/>  <strong>ABSTRACT:</strong> Patients with epilepsy can manifest short, sub-clinical epileptic &quot;bursts&quot; in
addition to full-blown clinical seizures. We believe the relationship between
these two classes of events---something not previously studied
quantitatively---could yield important insights into the nature and intrinsic
dynamics of seizures. A goal of our work is to parse these complex epileptic
events into distinct dynamic regimes. A challenge posed by the intracranial EEG
(iEEG) data we study is the fact that the number and placement of electrodes
can vary between patients. We develop a Bayesian nonparametric Markov switching
process that allows for (i) shared dynamic regimes between a variable numbers
of channels, (ii) asynchronous regime-switching, and (iii) an unknown
dictionary of dynamic regimes. We encode a sparse and changing set of
dependencies between the channels using a Markov-switching Gaussian graphical
model for the innovations process driving the channel dynamics and demonstrate
the importance of this model in parsing and out-of-sample predictions of iEEG
data. We show that our model produces intuitive state assignments that can help
automate clinical analysis of seizures and enable the comparison of
sub-clinical bursts and full clinical seizures. </span> </div>    <div class="publication-meta publication-meta">   <span class="ico-publication-fulltext reset-background"></span> Full-text   &middot; Article &middot; Feb 2014  &middot; Artificial Intelligence  </div>        <div class="publication-actions"> <div class="btn-group">  <a class="btn btn-plain action-download primary  open-viewer" href="profile/Brian_Litt/publication/260428846_Modeling_the_Complex_Dynamics_and_Changing_Correlations_of_Epileptic_Events/links/55ae311f08ae98e661a56334?origin=publication_list">  <span class="js-btn-label">Download</span> </a>    </div> </div>      </li>  </ul>    <a class="show-more-rebranded js-show-more rf text-gray-lighter">Show more</a> <span class="ajax-loading-small list-loading" style="display: none"></span>  <div class="clearfix"></div>  <div class="publication-detail-sidebar-legal">Note: This list is based on the publications in our database and might not be exhaustive.</div> <div class="clearfix"></div>  </div> </div> </div> </div> </div> </div> <div class="clearfix">     <div id="rgw28_56ab199beedce" class="c-box pub-resource-container js-toggle" style="display: none;"> <h4 class="lf js-expand-list"><small><a href="javascript:" class="lf">View other sources <span class="ico-expand-list"></span></a></small></h4> <h4 class="lf js-collapse-list hidden"><small><a href="javascript:" class="lf">Hide other sources <span class="ico-collapse-list"></span></a></small></h4> <div class="clear"></div> <div class="scroll-wrapper hidden"> <ul class="files-list c-list" id="rgw29_56ab199beedce">  </ul> </div> </div>   <div id="rgw19_56ab199beedce" class="similar-publications"> <h2>Similar Publications</h2> <ul class="list-bordered">  <li class="c-list-item li-publication-teaser" id="rgw20_56ab199beedce"> <div> <h5> <a href="publication/288830820_Reciprocal_Markov_Modeling_of_Feedback_Mechanisms_Between_Emotion_and_Dietary_Choice_Using_Experience-Sampling_Data" class="color-inherit ga-similar-publication-title"><span class="publication-title">Reciprocal Markov Modeling of Feedback Mechanisms Between Emotion and Dietary Choice Using Experience-Sampling Data</span></a>  </h5>  <div class="authors"> <a href="researcher/12337129_Ji_Lu" class="authors ga-similar-publication-author">Ji Lu</a>, <a href="researcher/2091628807_Junhao_Pan" class="authors ga-similar-publication-author">Junhao Pan</a>, <a href="researcher/15249177_Qiang_Zhang" class="authors ga-similar-publication-author">Qiang Zhang</a>, <a href="researcher/39392534_Laurette_Dube" class="authors ga-similar-publication-author">Laurette Dubé</a>, <a href="researcher/44198863_Edward_H_Ip" class="authors ga-similar-publication-author">Edward H Ip</a>  </div>  </div> <div class="clear"></div> </li>  <li class="c-list-item li-publication-teaser" id="rgw21_56ab199beedce"> <div> <h5> <a href="publication/282059895_A_comparison_of_Hidden_Markov_and_Semi-Markov_modeling_for_a_deterioration_system_subject_to_vibration_monitoring" class="color-inherit ga-similar-publication-title"><span class="publication-title">A comparison of Hidden Markov and Semi-Markov modeling for a deterioration system subject to vibration monitoring</span></a>  </h5>  <div class="authors"> <a href="researcher/2081458093_C_Lin" class="authors ga-similar-publication-author">C. Lin</a>, <a href="researcher/6213323_V_Makis" class="authors ga-similar-publication-author">V. Makis</a>  </div>  </div> <div class="clear"></div> </li>  <li class="c-list-item li-publication-teaser" id="rgw22_56ab199beedce"> <div> <h5> <a href="publication/281911384_Phoneme_modeling_for_speech_recognition_in_Kannada_using_Hidden_Markov_Model" class="color-inherit ga-similar-publication-title"><span class="publication-title">Phoneme modeling for speech recognition in Kannada using Hidden Markov Model</span></a>  </h5>  <div class="authors"> <a href="researcher/2081268772_P_Kannadaguli" class="authors ga-similar-publication-author">P. Kannadaguli</a>, <a href="researcher/2081258630_A_Thalengala" class="authors ga-similar-publication-author">A. Thalengala</a>  </div>  </div> <div class="clear"></div> </li>  </ul> </div> </div> </div> </div> </div></div></div>
<div class="clear"></div><div id="rgw53_56ab199beedce" class="default-footer"> <div id="footer" class="clearfix"> <span class="footer-left"> &copy; 2008&dash;2016 researchgate.net. All rights reserved. </span> <span class="footer-right"> <a href="https://www.researchgate.net/about">About us</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="https://www.researchgate.net/contact">Contact us</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="careers">Careers</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="developers">Developers</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="blog" target="_blank">News</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="application.PrivacyPolicy.html">Privacy</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="application.TermsAndConditions.html">Terms</a> <span class="footer-link-separator" style="padding: 0 5px;">&nbsp;|&nbsp;</span> <a href="advertising?_ref=ft">Advertising</a> <span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="recruiters?_ref=ft">Recruiting</a> </span> </div>  </div></div>
<div id="rgw54_56ab199beedce">  <div class="header-wrapper-logged-out"> <div id="header"> <div class="header-content"> <a href="" class="g-l-logo"> <svg width="149" height="19"> <image xlink:href="https://c5.rgstatic.net/m/235107188705592/images/template/brand-header-logo.svg" src="https://c5.rgstatic.net/m/238113351022438/images/template/brand-header-logo.png" width="149" height="19"/> </svg> </a> <a href="" class="g-l-logo-ico"> <svg width="127" height="17" viewbox="0 0 127 22"> <image xlink:href="https://c5.rgstatic.net/m/235107188705592/images/template/brand-header-logo.svg" src="https://c5.rgstatic.net/m/238113351022438/images/template/brand-header-logo.png" width="127" height="17"/> </svg> </a> <div id="rgw55_56ab199beedce" class="header-login-wrapper js-header-login"> <div class="dropdown-right-align"> <div class="login-signup-container lf"> <a href="https://www.researchgate.net/signup.SignUp.html?ev=su_chnl_index&amp;hdrsu=1&amp;_sg=qm74FON7ueWQx8UoBL5eeD5tVvbvyMiJ9s16C9FifKaCv5VQO71YJiAtvMJQkz6q" class="dropdown-toggle lf">Join for free</a> </div> <div class="dropdown lf" style="height: 20px;"> <a href="https://www.researchgate.net/application.Login.html" class="js-login-url dropdown-toggle lf">Log in <span class="caret"></span></a> <div class="dropdown-menu"> <div class="header-login-form-wrapper"> <!--[if IE 6]><p class="box-warning" style="margin-bottom: 0;">Sorry, ResearchGate no longer supports the version of Internet Explorer you are using. <a href="http://whatbrowser.org/" rel="nofollow" target="_blank">Update your web browser</a> and then log in. </p><![endif]--> <form method="post" action="https://www.researchgate.net/application.Login.html" class="form-big header-login-form js-login-form" name="loginForm" id="headerLoginForm"> <input type="hidden" name="request_token" value="JYST0jiUy7U7nzQOjjyPlYl9Wv3p8CBowwbIipjZ41G7nZ1UCLD7ZdJbQzmwWe5+19fbzB8qQSadEXPWyigtaiEwt73qlprd+fSnwcqMIwP5CrZZ9emA4p3nQrjNgMwBhe/fyhseeUF7kccHzI2aFuC8S2JsMZjxCo/hSlPTJqFNeQLxbGdxbkv2IbpvAB/j/ePV5c0ug4VH1SBfEHVsMvqOlE35fWf5/fr8r7zeoI1wPveTjPY+LZcVTUBPKgUl6Y6ILnKdNpcQ7mKR29DWDkS5ppoATINibVEMQMslXjg="/> <input type="hidden" name="urlAfterLogin" value="publication/221345210_Beam_sampling_for_the_infinite_hidden_Markov_model"/> <input type="hidden" name="invalidPasswordCount" value="0"/> <input type="hidden" name="headerLogin" value="yes"/> <label for="input-header-login">Email</label> <div class="login-input"> <div class="info-tip-wrapper"> <span class="ico-info js-info"></span> </div> <input type="email" value="" name="login" class="login js-login-input text" id="input-header-login" tabindex="1"/> </div> <div class="clear"></div> <label class="lf" for="input-header-password"> Password </label> <a class="rf forgot-password js-forgot-password" href="application.LostPassword.html">Forgot password?</a> <div class="clear"></div> <input type="password" value="" name="password" class="password js-password-input text" id="input-header-password" tabindex="2"/> <div class="clear"></div> <label class="remember-me" for="headerLoginCookie"> <input type="checkbox" checked="checked" value="yes" name="setLoginCookie" class="lf checkbox" id="headerLoginCookie" tabindex="3"/> Keep me logged in </label> <div class="clear"></div> <input value="Log in" name="loginSubmit" class="btn btn-promote btn-fullwidth btn-large allow-leave js-submit-button" type="submit" tabindex="4"/> </form> <div class="connectors"> <div class="text">or log in with</div> <div class="connector-actions"> <a href="connector/linkedin/" class="li-connect js-li-connect" data-redirect-url="cHVibGljYXRpb24vMjIxMzQ1MjEwX0JlYW1fc2FtcGxpbmdfZm9yX3RoZV9pbmZpbml0ZV9oaWRkZW5fTWFya292X21vZGVs"> <span class="icon ico-linkedin-round-grey"></span> <span class="icon ico-linkedin-round"></span> </a> <a href="connector/facebook/" class="fb-connect middle js-fb-connect" data-redirect-url="cHVibGljYXRpb24vMjIxMzQ1MjEwX0JlYW1fc2FtcGxpbmdfZm9yX3RoZV9pbmZpbml0ZV9oaWRkZW5fTWFya292X21vZGVs"> <span class="icon ico-facebook-round-grey"></span> <span class="icon ico-facebook-round"></span> </a> <a href="connector/google/" class="g-connect js-g-connect" data-redirect-url="cHVibGljYXRpb24vMjIxMzQ1MjEwX0JlYW1fc2FtcGxpbmdfZm9yX3RoZV9pbmZpbml0ZV9oaWRkZW5fTWFya292X21vZGVs"> <span class="icon ico-google-round-grey"></span> <span class="icon ico-google-round"></span> </a> </div> </div> </div> </div> </div> </div> </div> </div> </div> <script type="application/ld+json">
{ "@context" : "http://schema.org",
  "@type" : "Organization",
  "name" : "ResearchGate",
  "url" : "http://www.researchgate.net",
  "logo" : "http://www.researchgate.net/images/template/rg_logo_square_brand.png",
  "sameAs" : [ "https://www.facebook.com/ResearchGate",
    "https://twitter.com/ResearchGate",
    "https://plus.google.com/+researchgate",
    "https://www.linkedin.com/company/researchgate"] 
}
</script> </div> </div><div class="c-signup-bar" id="rgw56_56ab199beedce"> <div class="banner-contents">   <span class="message">ResearchGate is the professional network for scientists and researchers.</span> <a href="signup.SignUp.html?ev=su_banner" class="btn btn-large btn-promote">Join for free</a>  </div> </div></div>
<script>
rgConfig.backendTime = 525;
</script>
<script src="//c5.rgstatic.net/m/2277196935388619/javascript/lib/yui3/yui/yui-min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/2448732603281275/javascript/yuiLoaderConfig-min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/23178613132105398/javascript/vendor/babel-core/browser-polyfill.min.js" type="text/javascript"></script>
<script>
(function (){
if (typeof YRG === "undefined") {
var xmlHttpRequest = new XMLHttpRequest();
xmlHttpRequest.open("post", "go.Error.html");
xmlHttpRequest.setRequestHeader("Content-Type", "application/json");
xmlHttpRequest.setRequestHeader("Accept", "application/json"); var loadedScripts = "";
if (window.performance && window.performance.getEntriesByType) {
    var result = [];
    var resources = performance.getEntriesByType("resource");
    for (var i in resources) {
        if (resources.hasOwnProperty(i)) {
            result.push({
                name: resources[i].name,
                duration: resources[i].duration
            });
        }
    }
    loadedScripts += "&loadedScripts=" + encodeURIComponent(JSON.stringify(result));
}
if (typeof YUI === "undefined") {
    loadedScripts += "&yuiLoaded=false";
} else {
    loadedScripts += "&yuiLoaded=true";
}
xmlHttpRequest.send("Type=InformationException&message=" + encodeURIComponent("Error loading YUI") + loadedScripts);
}
})();
</script>
<script>if (typeof YRG !== 'undefined') { YRG.use('rg-base',function(Y){Y.applyConfig({ignore: ["css-rg","css-rg2","css-ie","css-modules-publicprofile","css-pow-publicliterature-FigureList","css-pow-publicliterature-FollowPublicationPromo","css-pow-application-PdfJsReader","css-pow-publicliterature-PublicationInlineReader"]});Y.use(["rg.core.pagespeed.Monitoring"],function(Y){(function(){Y.rg.createInitialWidget({"data":{"content":{"data":{"profileSmallHeader":{"data":{"profileBadge":{"data":{"fullname":"Yunus Saatchi","imageUrl":"https:\/\/i1.rgstatic.net\/ii\/profile.image\/AS%3A272816591339520%401442055952095_m\/Yunus_Saatchi.png","profileStats":[],"profileFollowButton":null,"profileReputationScoreNumber":null,"profileUrl":"profile\/Yunus_Saatchi","institution":"University of Cambridge","institutionUrl":false,"widgetId":"rgw4_56ab199beedce"},"id":"rgw4_56ab199beedce","partials":[],"templateName":"publicprofile\/stubs\/ProfileBadge.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicprofile.ProfileBadge.html?accountId=3315011","viewClass":null,"yuiModules":["css-modules-publicprofile"],"stylesheets":["modules\/publicprofile.css"],"_isYUI":true},"widgetId":"rgw3_56ab199beedce"},"id":"rgw3_56ab199beedce","partials":[],"templateName":"publicprofile\/stubs\/ProfileSmallHeader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicprofile.ProfileSmallHeader.html?publicationUid=221345210","viewClass":null,"yuiModules":["css-modules-publicprofile"],"stylesheets":["modules\/publicprofile.css"],"_isYUI":true},"publication":{"data":{"publicationUid":221345210,"title":"Beam sampling for the infinite hidden Markov model","journalTitle":false,"journalDetailsTooltip":false,"affiliation":false,"type":"Conference Paper","details":{"doi":"10.1145\/1390156.1390293","conferenceInfos":"Conference: Machine Learning, Proceedings of the Twenty-Fifth International Conference (ICML 2008), Helsinki, Finland, June 5-9, 2008"},"source":{"sourceUrl":"http:\/\/dblp.uni-trier.de\/db\/conf\/icml\/icml2008.html#GaelSTG08","sourceName":"DBLP"},"publicationActions":null,"publicationCoins":{"data":{"tags":[{"key":"ctx_ver","value":"Z39.88-2004"},{"key":"rft_val_fmt","value":"info:ofi\/fmt:kev:mtx:journal"},{"key":"rfr_id","value":"info:sid\/researchgate.net:researchgate"},{"key":"rft_id","value":"info:doi\/10.1145\/1390156.1390293"},{"key":"rft.atitle","value":"Beam sampling for the infinite hidden Markov model"},{"key":"rft.title","value":"Proceedings of the 25th International Conference on Machine Learning"},{"key":"rft.jtitle","value":"Proceedings of the 25th International Conference on Machine Learning"},{"key":"rft.date","value":"2008"},{"key":"rft.pages","value":"1088-1095"},{"key":"rft.au","value":"Jurgen Van Gael,Yunus Saatci,Yee Whye Teh,Zoubin Ghahramani"},{"key":"rft.genre","value":"inProceedings"}],"widgetId":"rgw6_56ab199beedce"},"id":"rgw6_56ab199beedce","partials":[],"templateName":"publicliterature\/stubs\/PublicationCoins.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationCoins.html?publicationUid=221345210","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationAuthors":{"data":{"publicationUid":221345210,"peopleItems":[{"data":{"authorUrl":"researcher\/69831654_Jurgen_Van_Gael","authorNameOnPublication":"Jurgen Van Gael","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg","imageSize":"s","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Jurgen Van Gael","profile":{"professionalInstitution":{"professionalInstitutionName":false,"professionalInstitutionUrl":null}},"professionalInstitutionName":false,"professionalInstitutionUrl":null,"url":"researcher\/69831654_Jurgen_Van_Gael","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":true,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":false,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"widgetId":"rgw9_56ab199beedce"},"id":"rgw9_56ab199beedce","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAuthorItem.html?entityId=69831654&imageSize=l&enableAuthorInviteButton=0","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"largeTooltip":false,"useRebrandedImageStyle":null,"widgetId":"rgw8_56ab199beedce"},"id":"rgw8_56ab199beedce","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorItem.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorItem.html?authorUid=69831654&authorNameOnPublication=Jurgen%20Van%20Gael","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true},{"data":{"authorNameOnPublication":"Yunus Saatchi","accountUrl":"profile\/Yunus_Saatchi","accountKey":"Yunus_Saatchi","imageUrl":"https:\/\/i1.rgstatic.net\/ii\/profile.image\/AS%3A272816591339520%401442055952095_m\/Yunus_Saatchi.png","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Yunus Saatchi","profile":{"professionalInstitution":{"professionalInstitutionName":"University of Cambridge","professionalInstitutionUrl":"institution\/University_of_Cambridge"}},"professionalInstitutionName":"University of Cambridge","professionalInstitutionUrl":"institution\/University_of_Cambridge","url":"profile\/Yunus_Saatchi","imageUrl":"https:\/\/i1.rgstatic.net\/ii\/profile.image\/AS%3A272816591339520%401442055952095_l\/Yunus_Saatchi.png","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":false,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":true,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"accountKey":"Yunus_Saatchi","hasInfoPopup":false,"hasTeaserPopup":true,"showContactAuthorButton":true,"widgetId":"rgw11_56ab199beedce"},"id":"rgw11_56ab199beedce","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAccountItem.html?entityId=3315011&enableUnfollow=0&imageSize=l&enableFollowButton=0&showContactAuthorButton=1","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"accountInstitution":"University of Cambridge","score":null,"largeTooltip":false,"useRebrandedImageStyle":null,"authorCount":4,"accountCount":1,"publicationUid":221345210,"widgetId":"rgw10_56ab199beedce"},"id":"rgw10_56ab199beedce","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAccountItem.html","templateExtensions":[],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAccountItem.html?accountId=3315011&context=pubdetail_authors_xflw&showContactAuthorButton=1&authorCount=4&accountCount=1&publicationUid=221345210","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true},{"data":{"authorUrl":"researcher\/9164246_Yee_Whye_Teh","authorNameOnPublication":"Yee Whye Teh","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg","imageSize":"s","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Yee Whye Teh","profile":{"professionalInstitution":{"professionalInstitutionName":false,"professionalInstitutionUrl":null}},"professionalInstitutionName":false,"professionalInstitutionUrl":null,"url":"researcher\/9164246_Yee_Whye_Teh","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":true,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":false,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"widgetId":"rgw13_56ab199beedce"},"id":"rgw13_56ab199beedce","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAuthorItem.html?entityId=9164246&imageSize=l&enableAuthorInviteButton=0","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"largeTooltip":false,"useRebrandedImageStyle":null,"widgetId":"rgw12_56ab199beedce"},"id":"rgw12_56ab199beedce","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorItem.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorItem.html?authorUid=9164246&authorNameOnPublication=Yee%20Whye%20Teh","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true},{"data":{"authorUrl":"researcher\/8159937_Zoubin_Ghahramani","authorNameOnPublication":"Zoubin Ghahramani","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg","imageSize":"s","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Zoubin Ghahramani","profile":{"professionalInstitution":{"professionalInstitutionName":false,"professionalInstitutionUrl":null}},"professionalInstitutionName":false,"professionalInstitutionUrl":null,"url":"researcher\/8159937_Zoubin_Ghahramani","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":true,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":false,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"widgetId":"rgw15_56ab199beedce"},"id":"rgw15_56ab199beedce","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAuthorItem.html?entityId=8159937&imageSize=l&enableAuthorInviteButton=0","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"largeTooltip":false,"useRebrandedImageStyle":null,"widgetId":"rgw14_56ab199beedce"},"id":"rgw14_56ab199beedce","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorItem.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorItem.html?authorUid=8159937&authorNameOnPublication=Zoubin%20Ghahramani","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true}],"hasMore":false,"nextOffset":6,"useRebrandedImageStyle":null,"widgetId":"rgw7_56ab199beedce"},"id":"rgw7_56ab199beedce","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorList.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorList.html?publicationUid=221345210&context=pubdetail_authors_xflw&showContactAuthorButton=1","viewClass":"views.publicliterature.PublicationDetailAuthorListView","yuiModules":["rg.views.publicliterature.PublicationDetailAuthorListView"],"stylesheets":[],"_isYUI":true},"publicationAbstract":{"data":{"publicationUid":221345210,"abstract":"<noscript><\/noscript><div>The innite hidden Markov model is a non- parametric extension of the widely used hid- den Markov model. Our paper introduces a new inference algorithm for the innite Hidden Markov model called beam sam- pling. Beam sampling combines slice sam- pling, which limits the number of states con- sidered at each time step to a nite number, with dynamic programming, which samples whole state trajectories eciently. Our algo- rithm typically outperforms the Gibbs sam- pler and is more robust. We present appli- cations of iHMM inference using the beam sampler on changepoint detection and text prediction problems.<\/div>","canEdit":false,"isAdmin":false,"isArtifact":false,"showFullAbstract":false,"widgetId":"rgw16_56ab199beedce"},"id":"rgw16_56ab199beedce","partials":[],"templateName":"publicliterature\/stubs\/PublicationAbstract.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationAbstract.html?publicationUid=221345210","viewClass":"views.publicliterature.PublicationAbstractView","yuiModules":["rg.views.publicliterature.PublicationAbstractView"],"stylesheets":[],"_isYUI":true},"publicationKeywords":null,"publicationState":null,"isGuest":true,"isAdminEditingAllowed":false,"isArtifact":false,"figureListWidget":{"data":{"figures":[{"imageUrl":"https:\/\/www.researchgate.net\/profile\/Yunus_Saatchi\/publication\/221345210\/figure\/fig1\/Figure-6-The-left-plots-show-how-frequent-two-datapoints-were-in-the-same-cluster.png","previewImageUrl":"https:\/\/www.researchgate.net\/profile\/Yunus_Saatchi\/publication\/221345210\/figure\/fig1\/Figure-6-The-left-plots-show-how-frequent-two-datapoints-were-in-the-same-cluster_small.png","figureUrl":"\/figure\/221345210_fig1_Figure-6-The-left-plots-show-how-frequent-two-datapoints-were-in-the-same-cluster","selected":false,"title":"Figure 6. The left plots show how frequent two datapoints were in the...","key":"221345210_fig1_Figure-6-The-left-plots-show-how-frequent-two-datapoints-were-in-the-same-cluster"}],"readerDocId":"6973361","linkBehaviour":"dialog","isDialog":true,"headerText":"Figures in this publication","isNewPublicationDesign":false,"widgetId":"rgw17_56ab199beedce"},"id":"rgw17_56ab199beedce","partials":[],"templateName":"publicliterature\/stubs\/FigureList.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.FigureList.html?readerDocId=6973361&isDialog=1&linkBehaviour=dialog","viewClass":"views.publicliterature.FigureListView","yuiModules":["rg.views.publicliterature.FigureListView","css-pow-publicliterature-FigureList"],"stylesheets":["pow\/publicliterature\/FigureList.css"],"_isYUI":true},"previewImage":"https:\/\/i1.rgstatic.net\/publication\/221345210_Beam_sampling_for_the_infinite_hidden_Markov_model\/links\/00463525dba898f504000000\/smallpreview.png","nativeAdDisclosure":null,"showFollowPublicationButton":false,"followPublicationPromo":{"data":{"widgetId":"rgw18_56ab199beedce"},"id":"rgw18_56ab199beedce","partials":[],"templateName":"publicliterature\/stubs\/FollowPublicationPromo.html","templateExtensions":[],"attrs":{"context":null,"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.FollowPublicationPromo.html","viewClass":null,"yuiModules":["css-pow-publicliterature-FollowPublicationPromo"],"stylesheets":["pow\/publicliterature\/FollowPublicationPromo.css"],"_isYUI":true},"widgetId":"rgw5_56ab199beedce"},"id":"rgw5_56ab199beedce","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailItem.html","templateExtensions":["generalHelpers"],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailItem.html?publicationUid=221345210&showActionBar=0&showContactAuthorButton=1&showRequestFulltextExperience=0&showNoRgAuthorsRequestFulltextExperience=0&showFollowPublicationPromo=1","viewClass":"views.publicliterature.PublicationDetailItemView","yuiModules":["rg.views.publicliterature.PublicationDetailItemView"],"stylesheets":[],"_isYUI":true},"similarPublications":{"data":{"publicationListItems":[{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore","clickThrough":"experimentMilestoneClickedToPublicationFromReferenceWithNoFulltext","clickThroughWithContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":12337129,"url":"researcher\/12337129_Ji_Lu","fullname":"Ji Lu","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2091628807,"url":"researcher\/2091628807_Junhao_Pan","fullname":"Junhao Pan","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":15249177,"url":"researcher\/15249177_Qiang_Zhang","fullname":"Qiang Zhang","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":{"id":39392534,"url":"researcher\/39392534_Laurette_Dube","fullname":"Laurette Dub\u00e9","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},"surplusAuthors":1,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Dec 2015","journal":"Multivariate Behavioral Research","showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/288830820_Reciprocal_Markov_Modeling_of_Feedback_Mechanisms_Between_Emotion_and_Dietary_Choice_Using_Experience-Sampling_Data","usePlainButton":true,"publicationUid":288830820,"feedStubs":null,"hasFeedStubs":false,"impactPoints":"2.48","url":"publication\/288830820_Reciprocal_Markov_Modeling_of_Feedback_Mechanisms_Between_Emotion_and_Dietary_Choice_Using_Experience-Sampling_Data","title":"Reciprocal Markov Modeling of Feedback Mechanisms Between Emotion and Dietary Choice Using Experience-Sampling Data","displayTitleAsLink":true,"authors":[{"id":12337129,"url":"researcher\/12337129_Ji_Lu","fullname":"Ji Lu","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2091628807,"url":"researcher\/2091628807_Junhao_Pan","fullname":"Junhao Pan","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":15249177,"url":"researcher\/15249177_Qiang_Zhang","fullname":"Qiang Zhang","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":39392534,"url":"researcher\/39392534_Laurette_Dube","fullname":"Laurette Dub\u00e9","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":44198863,"url":"researcher\/44198863_Edward_H_Ip","fullname":"Edward H Ip","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["Multivariate Behavioral Research 12\/2015; 50(6):584-599. DOI:10.1080\/00273171.2015.1033510"],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/288830820_Reciprocal_Markov_Modeling_of_Feedback_Mechanisms_Between_Emotion_and_Dietary_Choice_Using_Experience-Sampling_Data","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/288830820_Reciprocal_Markov_Modeling_of_Feedback_Mechanisms_Between_Emotion_and_Dietary_Choice_Using_Experience-Sampling_Data\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw20_56ab199beedce"},"id":"rgw20_56ab199beedce","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=288830820","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore","clickThrough":"experimentMilestoneClickedToPublicationFromReferenceWithNoFulltext","clickThroughWithContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":2081458093,"url":"researcher\/2081458093_C_Lin","fullname":"C. Lin","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":6213323,"url":"researcher\/6213323_V_Makis","fullname":"V. Makis","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"May 2015","journal":"International Journal of Performability Engineering","showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/282059895_A_comparison_of_Hidden_Markov_and_Semi-Markov_modeling_for_a_deterioration_system_subject_to_vibration_monitoring","usePlainButton":true,"publicationUid":282059895,"feedStubs":null,"hasFeedStubs":false,"impactPoints":false,"url":"publication\/282059895_A_comparison_of_Hidden_Markov_and_Semi-Markov_modeling_for_a_deterioration_system_subject_to_vibration_monitoring","title":"A comparison of Hidden Markov and Semi-Markov modeling for a deterioration system subject to vibration monitoring","displayTitleAsLink":true,"authors":[{"id":2081458093,"url":"researcher\/2081458093_C_Lin","fullname":"C. Lin","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":6213323,"url":"researcher\/6213323_V_Makis","fullname":"V. Makis","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["International Journal of Performability Engineering 05\/2015; 11(3):213-228."],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/282059895_A_comparison_of_Hidden_Markov_and_Semi-Markov_modeling_for_a_deterioration_system_subject_to_vibration_monitoring","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/282059895_A_comparison_of_Hidden_Markov_and_Semi-Markov_modeling_for_a_deterioration_system_subject_to_vibration_monitoring\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw21_56ab199beedce"},"id":"rgw21_56ab199beedce","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=282059895","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore","clickThrough":"experimentMilestoneClickedToPublicationFromReferenceWithNoFulltext","clickThroughWithContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":2081268772,"url":"researcher\/2081268772_P_Kannadaguli","fullname":"P. Kannadaguli","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2081258630,"url":"researcher\/2081258630_A_Thalengala","fullname":"A. Thalengala","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Apr 2015","journal":null,"showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/281911384_Phoneme_modeling_for_speech_recognition_in_Kannada_using_Hidden_Markov_Model","usePlainButton":true,"publicationUid":281911384,"feedStubs":null,"hasFeedStubs":false,"impactPoints":false,"url":"publication\/281911384_Phoneme_modeling_for_speech_recognition_in_Kannada_using_Hidden_Markov_Model","title":"Phoneme modeling for speech recognition in Kannada using Hidden Markov Model","displayTitleAsLink":true,"authors":[{"id":2081268772,"url":"researcher\/2081268772_P_Kannadaguli","fullname":"P. Kannadaguli","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2081258630,"url":"researcher\/2081258630_A_Thalengala","fullname":"A. Thalengala","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":[],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/281911384_Phoneme_modeling_for_speech_recognition_in_Kannada_using_Hidden_Markov_Model","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/281911384_Phoneme_modeling_for_speech_recognition_in_Kannada_using_Hidden_Markov_Model\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw22_56ab199beedce"},"id":"rgw22_56ab199beedce","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=281911384","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"viewClass":"sidebar","widgetId":"rgw19_56ab199beedce"},"id":"rgw19_56ab199beedce","partials":[],"templateName":"publicliterature\/stubs\/SimilarPublications.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.SimilarPublications.html?referencePublicationId=221345210&view=sidebar","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationFulltextPreview":null,"publicationResourcesFulltext":{"data":{"publicationUid":221345210,"publicationResourceList":{"data":{"publicationResourceItems":[{"data":{"publicationUid":221345210,"publicationType":"inProceedings","linkId":"00463525dba898f504000000","fileName":"00463525dba898f504000000.pdf","fileUrl":"profile\/Yunus_Saatchi\/publication\/221345210_Beam_sampling_for_the_infinite_hidden_Markov_model\/links\/00463525dba898f504000000.pdf","name":"Yunus Saatchi","nameUrl":"profile\/Yunus_Saatchi","canRemove":false,"fileIcon":"ico-pub","canPreview":true,"hasPublisherLink":null,"hasMetaData":true,"hide":false,"fulltext":"ico-pub","origin":"publication_list","isLastLink":false,"isUserLink":true,"uploadDate":"May 28, 2014","fileSize":"470.27 KB","widgetId":"rgw25_56ab199beedce"},"id":"rgw25_56ab199beedce","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceItem.html","templateExtensions":["generalHelpers"],"attrs":{"fileRequiredPublicationTypes":["code","coverPage","experimentFindings","method","negativeResults","presentation","rawData","researchProposal","workingPaper","artifact","dataset"]},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceItem.html?publicationUid=221345210&linkId=00463525dba898f504000000&hide=0&disableJavascript=disableJavascript&useAlternativeTemplate=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"publicationUid":221345210,"publicationType":"inProceedings","linkId":"0ff749830cf25dfdcf514d9e","fileName":"Beam sampling for the infinite hidden Markov model","fileUrl":"http:\/\/citeseerx.ist.psu.edu\/viewdoc\/download?doi=10.1.1.140.1680&amp;rep=rep1&amp;type=pdf","name":"psu.edu","nameUrl":"http:\/\/citeseerx.ist.psu.edu\/viewdoc\/download?doi=10.1.1.140.1680&amp;rep=rep1&amp;type=pdf","canRemove":false,"fileIcon":"ico-pub","canPreview":true,"hasPublisherLink":null,"hasMetaData":true,"hide":false,"fulltext":"ico-pub","origin":"publication_list","isLastLink":false,"isUserLink":false,"widgetId":"rgw26_56ab199beedce"},"id":"rgw26_56ab199beedce","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceItem.html","templateExtensions":["generalHelpers"],"attrs":{"fileRequiredPublicationTypes":["code","coverPage","experimentFindings","method","negativeResults","presentation","rawData","researchProposal","workingPaper","artifact","dataset"]},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceItem.html?publicationUid=221345210&linkId=0ff749830cf25dfdcf514d9e&hide=0&disableJavascript=disableJavascript&useAlternativeTemplate=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"widgetId":"rgw24_56ab199beedce"},"id":"rgw24_56ab199beedce","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceList.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceList.html?publicationUid=221345210&limit=3&disableJavascript=disableJavascript&type=fulltextFile","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"resourceCount":2,"hidden":false,"showMore":false,"fulltext":true,"publicationDownloadCount":{"data":{"value":47,"valueFormatted":"47","widgetId":"rgw27_56ab199beedce"},"id":"rgw27_56ab199beedce","partials":[],"templateName":"publicliterature\/stubs\/PublicationDownloadCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDownloadCount.html?publicationUid=221345210","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw23_56ab199beedce"},"id":"rgw23_56ab199beedce","partials":[],"templateName":"publicliterature\/stubs\/PublicationResources.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResources.html?publicationUid=221345210&type=fulltextFile&disableJavascript=1","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationResourcesAttachments":{"data":{"publicationUid":221345210,"publicationResourceList":{"data":{"publicationResourceItems":[],"widgetId":"rgw29_56ab199beedce"},"id":"rgw29_56ab199beedce","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceList.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceList.html?publicationUid=221345210&limit=3&disableJavascript=disableJavascript&type=attachmentFile","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"resourceCount":0,"hidden":true,"showMore":false,"fulltext":false,"publicationDownloadCount":{"data":{"value":47,"valueFormatted":"47","widgetId":"rgw30_56ab199beedce"},"id":"rgw30_56ab199beedce","partials":[],"templateName":"publicliterature\/stubs\/PublicationDownloadCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDownloadCount.html?publicationUid=221345210","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw28_56ab199beedce"},"id":"rgw28_56ab199beedce","partials":[],"templateName":"publicliterature\/stubs\/PublicationResources.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResources.html?publicationUid=221345210&type=attachmentFile","viewClass":"views.publicliterature.PublicationResourcesView","yuiModules":["rg.views.publicliterature.PublicationResourcesView"],"stylesheets":[],"_isYUI":true},"publicationText":{"data":{"hide":false,"pages":[{"page":1,"text":"Beam Sampling for the Infinite Hidden Markov Model\nJurgen Van Gael\nYunus Saatci\nDepartment of Engineering, University of Cambridge, Cambridge CB2 1PZ, UK\njv279@cam.ac.uk\nys267@cam.ac.uk\nYee Whye Teh\nGatsby Computational Neuroscience Unit, University College London, WC1N 3AR, UK\nywteh@gatsby.ucl.ac.uk\nZoubin Ghahramani\nDepartment of Engineering, University of Cambridge, Cambridge CB2 1PZ, UK\nzoubin@eng.cam.ac.uk\nAbstract\nThe infinite hidden Markov model is a non-\nparametric extension of the widely used hid-\nden Markov model.\na new inference algorithm for the infinite\nHidden Markov model called beam sam-\npling. Beam sampling combines slice sam-\npling, which limits the number of states con-\nsidered at each time step to a finite number,\nwith dynamic programming, which samples\nwhole state trajectories efficiently. Our algo-\nrithm typically outperforms the Gibbs sam-\npler and is more robust. We present appli-\ncations of iHMM inference using the beam\nsampler on changepoint detection and text\nprediction problems.\nOur paper introduces\n1. Introduction\nThe hidden Markov model (HMM) (Rabiner, 1989) is\none of the most widely used models in machine learn-\ning and statistics for sequential or time series data.\nThe HMM consists of a hidden state sequence with\nMarkov dynamics, and independent observations at\neach time given the corresponding state. There are\nthree learning related tasks associated with the HMM:\ninference of the hidden state sequence, learning of the\nparameters, and selection of the right model size.\nInference for the hidden state trajectory can be\nperformed exactly using the forward-backward algo-\nrithm (Rabiner, 1989), a dynamic programming algo-\nrithm with O(TK2) computational costs where T is\nthe number of time steps and K number of states.\nAppearing in Proceedings of the 25thInternational Confer-\nence on Machine Learning, Helsinki, Finland, 2008. Copy-\nright 2008 by the author(s)\/owner(s).\nThe standard approach to learning uses the Baum-\nWelch algorithm, a special instance of the EM al-\ngorithm (Dempster et al., 1977) which produces (lo-\ncally) maximum likelihood (ML) parameters.\nML learning of parameters can potentially lead to over-\nfitting if the model size is inappropriate for the amount\nof data available. This can be partially mitigated us-\ning a more fully Bayesian learning procedure, e.g. using\nvariational approximations (MacKay, 1997) or Markov\nchain Monte Carlo (MCMC) sampling (Scott, 2002).\nSuch Bayesian approaches also produce estimates of\nthe marginal probability of data, which can be used to\nselect for the appropriate model size (or to average over\nmodel sizes if ones desires a more Bayesian analysis).\nSuch model selection procedures can be computation-\nally expensive since multiple HMMs of different sizes\nneed to be explored.\nSuch\nA new twist on the problem of model selection has\nemerged in recent years with the increasing popu-\nlarity of nonparametric Bayesian models. These are\nmodels of infinite capacity, a finite portion of which\nwill be used to model a finite amount of observed\ndata. The idea of searching\/averaging over the space\nof finite models is replaced with Bayesian inference\nover the size of submodel used to explain data. Ex-\namples of successful applications of nonparametric\nBayesian methods include Gaussian Processes (Ras-\nmussen & Williams, 2005) for regression and classifi-\ncation, Dirichlet Process (DP) mixture models (Es-\ncobar & West, 1995; Rasmussen, 2000) for cluster-\ning heterogeneous data and density estimation, Indian\nBuffet Processes for latent factor analysis (Griffiths\n& Ghahramani, 2006), and defining distributions over\nnon-trivial combinatorial objects such as trees (Teh\net al., 2008).\nThe Infinite Hidden Markov Model (iHMM), otherwise\nknown as the HDP-HMM, (Beal et al., 2002) is a non-"},{"page":2,"text":"Beam Sampling for the Infinite Hidden Markov Model\nparametric Bayesian extension of the HMM with an\ninfinite number of hidden states. Exact Bayesian in-\nference for the iHMM is intractable. Specifically, given\na particular setting of the parameters the forward-\nbackward algorithm cannot be applied since the num-\nber of states K is infinite, while with the parameters\nmarginalized out all hidden state variables will be cou-\npled and the forward-backward algorithm cannot be\napplied either. Currently the only approximate in-\nference algorithm available is Gibbs sampling, where\nindividual hidden state variables are resampled condi-\ntioned on all other variables (Teh et al., 2006). Unfor-\ntunately convergence of Gibbs sampling is notoriously\nslow in the HMM setting due to the strong dependen-\ncies between consecutive time steps often exhibited by\ntime series data (Scott, 2002).\nIn this paper we propose a new sampler for the iHMM\ncalled beam sampling. Beam sampling combines two\nideas\u2014slice sampling and dynamic programming\u2014to\nsample whole state trajectories efficiently.\nplication of slice sampling (Neal, 2003) is inspired\nby (Walker, 2007), who used it to limit the number\nof clusters considered when sampling assignment vari-\nables in DP mixtures to a finite number. We apply\nslice sampling to limit to a finite number the states\nconsidered in each time step of the iHMM, so that dy-\nnamic programming can be used to sample whole state\ntrajectories efficiently. We call our proposal beam\nsampling due to its similarity to beam search, a heuris-\ntic procedure for finding the maximum a posteriori\ntrajectory given observations in non-linear dynamical\nsystems. The underlying idea in both is to limit the\nsearch to a small number of states so that a good tra-\njectory can be found using reasonable computational\nresources. However, ours is a MCMC sampling method\nwith guaranteed convergence to the true posterior.\nOur ap-\nWe first present a self-contained description of the\niHMM using the Hierarchical Dirichlet process (HDP)\nformalism (Teh et al., 2006) in Section 2, followed\nby a discussion of Gibbs sampling in Section 3. We\nintroduce beam sampling in Section 4 and compare\nit against Gibbs sampling on both artificial and real\ndatasets in Section 5. We find that beam sampling\nis (1) at least as fast if not faster than Gibbs sam-\npling; (2) more robust than Gibbs sampling as its\nperformance is not as dependent on initialization and\nhyperparameter choice; (3) handles non-conjugacy in\nthe model more naturally; (4) straightforward to im-\nplement. We conclude in Section 6 with a discus-\nsion and suggestions for other cases in which beam\nsampling might prove useful.\nable from http:\/\/mlg.eng.cam.ac.uk\/jurgen to encour-\nage more widespread adoption of the iHMM and the\nbeam sampler.\nAll software is avail-\n2. The Infinite Hidden Markov Model\nWe start this section by describing the finite HMM,\nthen taking the infinite limit to obtain an intuition\nfor the infinite HMM, followed by a more precise def-\ninition. A finite HMM consists of a hidden state se-\nquence s = (s1,s2,...,sT) and a corresponding ob-\nservation sequence y = (y1,y2,...,yT). Each state\nvariable stcan take on a finite number of states, say\n1...K. Transitions between states are governed by\nMarkov dynamics parameterized by the transition ma-\ntrix \u03c0, where \u03c0ij= p(st= j|st\u22121= i), while the ini-\ntial state probabilities are \u03c00i= p(s1= i). For each\nstate st \u2208 {1...K} there is a parameter \u03c6stwhich\nparametrizes the observation likelihood for that state:\nyt|st\u223c F(\u03c6st). Given the parameters {\u03c00,\u03c0,\u03c6,K} of\nthe HMM, the joint distribution over hidden states s\nand observations y can be written (with s0= 0):\np(s,y|\u03c00,\u03c0,\u03c6,K) =\nT?\nt=1\np(st|st\u22121)p(yt|st)\nWe complete the Bayesian description by specifying\nthe priors. Let the observation parameters \u03c6 be iid\ndrawn from a prior distribution H.\nther prior knowledge on the state sequence, the typical\nprior for the transition (and initial) probabilities are\nsymmetric Dirichlet distributions.\nWith no fur-\nA na\u00a8 \u0131ve way to obtain a nonparametric HMM with an\ninfinite number of states might be to use symmetric\nDirichlet priors over the transition probabilities with\nparameter \u03b1\/K and take K \u2192 \u221e. Such an approach\nhas been successfully used to derive DP mixture mod-\nels (Rasmussen, 2000) but unfortunately does not work\nin the HMM context. The subtle reason is that there\nis no coupling across transitions out of different states\nsince the transition probabilities are given indepen-\ndent priors (Beal et al., 2002). To introduce coupling\nacross transitions, one may use a hierarchical Bayesian\nformalism where the Dirichlet priors have shared pa-\nrameters and given a higher level prior, e.g.\n\u03c0k\u223c Dirichlet(\u03b1\u03b2),\n\u03b2 \u223c Dirichlet(\u03b3\/K ...\u03b3\/K)\nwhere \u03c0kare transition probabilities out of state k and\n\u03b2 are the shared prior parameters. As K \u2192 \u221e, the hi-\nerarchical prior (1) approaches (with some alterations)\na hierarchical Dirichlet process (Teh et al., 2006).\n(1)\nA hierarchical Dirichlet process (HDP) is a set of\nDirichlet processes (DPs) coupled through a shared\nrandom base measure which is itself drawn from a\nDP (Teh et al., 2006).\nDP(\u03b1,G0) with shared base measure G0, which can\nbe understood as the mean of Gk, and concentration\nparameter \u03b1 > 0, which governs variability around G0,\nSpecifically, each Gk \u223c"},{"page":3,"text":"Beam Sampling for the Infinite Hidden Markov Model\nFigure 1. iHMM Graphical Model\nwith small \u03b1 implying greater variability. The shared\nbase measure is itself given a DP prior: G0\u223c DP(\u03b3,H)\nwith H a global base measure. The stick-breaking con-\nstruction for HDPs shows that the random measures\ncan be expressed as follows: G0=?\u221e\nbreaking construction for DPs (Sethuraman, 1994),\n\u03c0k\u223c DP(\u03b1,\u03b2), and each \u03c6k? \u223c H independently.\nIdentifying each Gkas describing both the transition\nprobabilities \u03c0kk? from state k to k?and the emis-\nsion distributions parametrized by \u03c6k?, we can now\nformally define the iHMM as follows:\nk?=1\u03b2k?\u03b4\u03c6k?and\nGk=?\u221e\nk?=1\u03c0kk?\u03b4\u03c6k?, where \u03b2 \u223c GEM(\u03b3) is the stick-\n\u03b2 \u223c GEM(\u03b3),\nst|st\u22121\u223c Multinomial(\u03c0st\u22121),\nThe graphical model corresponding to this hierarchical\nmodel is shown in figure 1. Thus \u03b2k? is the prior mean\nfor transition probabilities leading into state k?, and \u03b1\ngoverns the variability around the prior mean. If we fix\n\u03b2 = (1\nand the remaining are 0, then transition probabilities\ninto state k?will be non-zero only if k?\u2208 {1...K}, and\nwe recover the Bayesian HMM of (MacKay, 1997).\n\u03c0k|\u03b2 \u223c DP(\u03b1,\u03b2),\u03c6k\u223c H, (2)\nyt|st\u223c F(\u03c6st). (3)\nK...1\nK,0,0...) where the first K entries are\n1\nK\nFinally we place priors over the hyperparameters \u03b1\nand \u03b3. A common solution, when we do not have\nstrong beliefs about the hyperparameters, is to use\ngamma hyperpriors: \u03b1 \u223c Gamma(a\u03b1,b\u03b1) and \u03b3 \u223c\nGamma(a\u03b3,b\u03b3). (Teh et al., 2006) describe how these\nhyperparameters can be sampled efficiently, and we\nwill use this in the experiments to follow.\n3. The Gibbs Sampler\nThe Gibbs sampler was the first sampling algorithm\nfor the iHMM that converges to the true posterior.\nOne proposal builds on the direct assignment sampling\nscheme for the HDP in (Teh et al., 2006) by marginal-\nizing out the hidden variables \u03c0,\u03c6 from (2), (3) and\nignoring the ordering of states implicit in \u03b2. Thus we\nonly need to sample the hidden trajectory s, the base\nDP parameters \u03b2 and the hyperparameters \u03b1, \u03b3. Sam-\npling \u03b2,\u03b1,\u03b3 is exactly the same as for the HDP so we\nrefer to (Teh et al., 2006) for details.\nIn order to resample st, we need to compute the prob-\nability p(st|s\u2212t,\u03b2,y,\u03b1,H) \u221d p(yt|st,s\u2212t,y\u2212t,H) \u00b7\np(st|s\u2212t,\u03b2,\u03b1).\nditionallikelihoodof\nyt\n?p(yt|st,\u03c6st)p(\u03c6st|s\u2212t,y\u2212t,H)d\u03c6st. This is easy to\nF from equations (2) and\nthe second factor we can use the fact that the hid-\nden state sequence is Markov. Let nijbe the number\nof transitions from state i to state j excluding time\nsteps t \u2212 1 and t. Let n\u00b7i,ni\u00b7be the number of tran-\nsitions in and out of state i. Finally, let K be the\nnumber of distinct states in s\u2212t. Then we have that1\np(st= k|s\u2212t,\u03b2,\u03b1) \u221d\n(nst\u22121,k+ \u03b1\u03b2k)\nnk\u00b7+\u03b1\n(nst\u22121,k+ \u03b1\u03b2k)\nnk\u00b7+1+\u03b1\n(nst\u22121,k+ \u03b1\u03b2k)\nnk\u00b7+1+\u03b1\n\u03b1\u03b2k\u03b2st+1\nThefirst factor\ngiven\nisthe\nand\ncon-\nH:\ns,\ny\ncompute when the base distribution H and likelihood\n(3) are conjugate.For\nnk,st+1+\u03b1\u03b2st+1\nif k \u2264 K, k ?= st\u22121\nif k = st\u22121= st+1\nif k = st\u22121?= st+1\nif k = K + 1.\nnk,st+1+1+\u03b1\u03b2st+1\nnk,st+1+\u03b1\u03b2st+1\nFor each 1 \u2264 t \u2264 T we need to compute O(K)\nprobabilities, hence the Gibbs sampler has an O(TK)\ncomputational complexity. Non-conjugate models can\nbe handled using more sophisticated sampling tech-\nniques. In our experiments below, we used algorithm\n8 from (Neal, 2000).\nThe Gibbs sampler\u2019s success is due to its straightfor-\nward implementation. However, it suffers from one\nmajor drawback: sequential and time series data are\nlikely to be strongly correlated. For example, if we\nknow the value of a stock at time t then we can be\nreasonably sure that it will be similar at time t+1. As\nis well known, this is a situation which is far from ideal\nfor the Gibbs sampler: strong correlations in the hid-\nden states will make it unlikely that individual updates\nto st can cause large blocks within s to be changed.\nWe will now introduce the beam sampler which does\nnot suffer from this slow mixing behavior by sampling\nthe whole sequence s in one go.\n4. The Beam Sampler\nThe forward-backward algorithm does not apply to\nthe iHMM because the number of states, and hence\nthe number of potential state trajectories, are infinite.\nThe idea of beam sampling is to introduce auxiliary\nvariables u such that conditioned on u the number\nof trajectories with positive probability is finite. Now\ndynamic programming can be used to compute the\nconditional probabilities of each of these trajectories\nand thus sample whole trajectories efficiently. These\n1Recall that we ignored the ordering of states in \u03b2. In\nthis representation the K distinct states in s are labeled\n1...K and K + 1 denotes a new state."},{"page":4,"text":"Beam Sampling for the Infinite Hidden Markov Model\nFigure 2. The auxiliary variable u partitions the probabil-\nity distribution \u03c0 (vertical bars) into a set of entries less\nthan u and a set of entries larger than u.\nauxiliary variables do not change the marginal distri-\nbution over other variables hence MCMC sampling will\nconverge to the true posterior. This idea of using aux-\niliary variables to limit computation costs is inspired\nby (Walker, 2007), who applied it to limit the number\nof components in a DP mixture model that need be\nconsidered during sampling.\nAs opposed to the sampler in the previous section,\nthe beam sampler does not marginalize out \u03c0 nor \u03c6.\nSpecifically, the beam sampler iteratively samples the\nauxiliary variables u, the trajectory s, the transition\nprobabilities \u03c0, the shared DP parameters \u03b2 and the\nhyperparameters \u03b1 and \u03b3 conditioned on all other vari-\nables. In the following, we shall describe in more detail\nhow to sample each set of variables, as well as how the\nauxiliary variables allow dynamic programming to be\ncarried out over a finite number of trajectories without\napproximations.\nSampling u:\niary variable ut with conditional distribution ut \u223c\nUniform(0,\u03c0st\u22121st) depending on \u03c0, st\u22121and st.\nSampling s: we sample the whole trajectory s given\nthe auxiliary variables u and other variables using a\nform of forward filtering-backward sampling. The im-\nportant observation here is that only trajectories s\nwith \u03c0st\u22121st\u2265 utfor all t will have non-zero probabil-\nity given u. There are only finitely many such trajec-\ntories2and as a result we can compute the conditional\ndistribution over all such trajectories efficiently using\ndynamic programming.\nfor each t we introduce an auxil-\nFirst note that the probability density for ut is\np(ut|st\u22121,st,\u03c0) =\nif condition C is true and 0 otherwise. We compute\np(st|y1:t,u1:t) for all t as follows (we omitted the ad-\n2To see this, note that ut > 0 with probability 1 for each\nt, since each \u03c0kk? > 0 with probability 1. Given the auxil-\niary variable ut, note further that for each possible value of\nst\u22121, ut partitions the set of transition probabilities out of\nstate st\u22121 into two sets: a finite set with \u03c0st\u22121k > ut and\nan infinite set with \u03c0st\u22121k < ut, as illustrated in figure 2.\nThus we can recursively show that for t = 1,2...T the set\nof trajectories s1:t with all \u03c0st?\u22121st?> ut is finite.\nI(0<ut<\u03c0st\u22121,st)\n\u03c0st\u22121,st\n, where I(C) = 1\nditional conditioning variables \u03c0 and \u03c6 for clarity):\np(st|y1:t,u1:t)\n\u221dp(st,ut,yt|y1:t\u22121,u1:t\u22121),\n=\np(yt|st)p(ut|st,st\u22121)p(st|st\u22121)\n?\nst\u22121\np(st\u22121|y1:t\u22121,u1:t\u22121),\n=p(yt|st)\nst\u22121\n=p(yt|st)\nst\u22121:ut<\u03c0st\u22121,st\n?\nI(ut< \u03c0st\u22121,st)p(st\u22121|y1:t\u22121,u1:t\u22121),\n?\nNote that we only need to compute (4) for the finitely\nmany st values belonging to some trajectory with\npositive probability. Further, although the sum over\nst\u22121 is technically a sum over an infinite number of\nterms, the auxiliary variable uttruncates this summa-\ntion to the finitely many st\u22121\u2019s that satisfy both con-\nstraints \u03c0st\u22121,st> ut and p(st\u22121|y1:t\u22121,u1:t\u22121) > 0.\nFinally, to sample the whole trajectory s, we sam-\nple sT from p(sT|y1:T,u1:T) and perform a backward\npass where we sample st given the sample for st+1:\np(st|st+1,y1:T,u1:T) \u221d p(st|y1:t,u1:t)p(st+1|st,ut+1).\nSampling \u03c0, \u03c6, \u03b2:\nthese follow directly from the\ntheory of HDPs (Teh et al., 2006), but we briefly de-\nscribe these for completeness.\np(st\u22121|y1:t\u22121,u1:t\u22121).\n(4)\nLet nij be the number of times state i transi-\ntions to state j in the trajectory s, where i,j \u2208\n{1...K}, K is the number of distinct states in s,\nand these states have been relabeled 1...K. Merg-\ning the infinitely many states not represented in\ns into one state, the conditional distribution of\n(\u03c0k1...\u03c0kK,?\u221e\nDirichlet?nk1+ \u03b1\u03b21...nkK+ \u03b1\u03b2K,\u03b1?\u221e\nTo sample \u03b2 we introduce a further set of auxiliary\nvariables mijwhich are independent with conditional\ndistributions\nk?=K+1\u03c0kk?) given its Markov blanket\ns,\u03b2, \u03b1 is\ni=K+1\u03b2i\n?,\np(mij= m|s,\u03b2,\u03b1) \u221d S(nij,m)(\u03b1\u03b2j)m,\nwhere S(\u00b7,\u00b7) denotes Stirling numbers of the first kind.\nThe shared DP parameter (\u03b21...,\u03b2K,?\u221e\nDirichlet(m\u00b71...m\u00b7K,\u03b3),\nwhere m\u00b7k=?K\nFinally, each \u03c6kis independent of others conditional on\ns, y and their prior distribution H, i.e. p(\u03c6|s,y,H) =\nk?=K+1\u03b2k?)\nhas conditional distribution\nk?=1mk?k. (Teh et al., 2006; Antoniak,\n1974) gives more details."},{"page":5,"text":"Beam Sampling for the Infinite Hidden Markov Model\n0 50010001500\n \n0\n0.2\n0.4\n0.6\n0.8\n1\nIterations\np(Error)\n \n \nGibbs Vague\nGibbs Strong\nGibbs Fixed\nBeam Vague\nBeam Strong\nBeam Fixed\n0 20406080 100\n0\n5\n10\nIterations\n# transitions\n \nBeam Vague\nBeam Strong\nBeam Fixed\nFigure 3. iHMM performance on strong negatively corre-\nlated data. The top plot shows the error of the Gibbs and\nbeam sampler for the first 1500 iterations averaged over\n20 runs. The bottom plot shows the average number of\nprevious states considered in equation (4) for the first 100\niterations of the beam sampler.\n?\nbe sampled efficiently. Otherwise we may resort to\nMetropolis-Hastings or other approaches. Note that in\nthe non-conjugate case this is simpler than for Gibbs\nsampling. In the experimental section, we describe an\napplication where the base distribution and likelihood\nare non-conjugate.\nkp(\u03c6k|s,y,H).\nconjugate to the data distribution F each \u03c6k can\nWhen the base distribution H is\nTo conclude our discussion of the beam sampler, it\nis useful to point out that there is nothing special\nabout sampling ut from the uniform distribution on\n[0,\u03c0st\u22121,st]: by choosing a distribution over [0,\u03c0st,st\u22121]\nwith higher mass near smaller values of ut, we will al-\nlow more trajectories to have positive probability and\nhence considered by the forward filtering-backward\nsampling algorithm. Although this will typically im-\nprove mixing time, it also comes at additional compu-\ntational cost. This brings us to the issue of the com-\nputational cost of the beam sampler: since for each\ntimestep and each state assignment we need to sum\nover all represented previous states, the worst case\ncomplexity is O(TK2). However, the sum in (4) is only\nover previous states for which the transition probabil-\nity is larger than ut; this means that in practice we\nmight only need to sum over a few previous states.\nIn our experiments below, we will give some empirical\nevidence for this \u201caverage case\u201d behavior. Further, we\nhave found that the drastically improved mixing of the\nbeam sampler more than made up for the additional\ncost over Gibbs sampling. Finally, although we did not\nfind any advantage doing so, it is certainly possible to\ninterleave the beam sampler and the Gibbs sampler.\n0100 200\n0\n0.25\n0.5\n0.75\n1\n0.750\n0 100200\n0\n0.25\n0.5\n0.75\n1\n0.950\n0 100200\n0\n0.25\n0.5\n0.75\n1\n0.999\n0 100200\n0\n0.25\n0.5\n0.75\n1\n0.750\n0100200\n0\n0.25\n0.5\n0.75\n1\n0.950\n0100200\n0\n0.25\n0.5\n0.75\n1\n0.999\nFigure 4. iHMM error on increasing positively correlated\ndata. The blue curve shows the beam sampler while the red\ncurve shows the Gibbs sampler performance. The dotted\nline show the one standard deviation error bars.\n5. Experiments\nWe evaluate the beam sampler on two artificial and\ntwo real datasets to illustrate the following properties:\n(1) the beam sampler mixes in much fewer iterations\nthan the Gibbs sampler; (2) the actual complexity per\niteration of the beam sampler is only marginally more\nthan the Gibbs sampler; (3) the beam sampler mixes\nwell regardless of strong correlations in the data; (4)\nthe beam sampler is more robust with respect to vary-\ning initialization and prior distribution; (5) the beam\nsampler handles non conjugate models naturally; (6)\nthe iHMM is a viable alternative to the finite HMM.\nAll datasets and a Matlab version of our software are\navailable at http:\/\/mlg.eng.cam.ac.uk\/jurgen.\n5.1. Artificial Data\nOur first experiment compares the performance of the\niHMM on a sequence of length 800 generated by a 4\nstate HMM. The hidden state sequence was almost\ncyclic (1-2-3-4-1-2-3-...) with a 1% probability of self\ntransition: i.o.w the true distribution of hidden states\nis strong negatively correlated. We use a multinomial\noutput distribution with the following emission matrix\n\uf8ee\n\uf8f0\nNext we run the Gibbs and beam sampler 20 times\nfrom a random initialization with every state randomly\nchosen between 1 and 20. We test the performance\nof both samplers using three different hyperparame-\nter settings: (1) vague gamma hyperpriors for \u03b1 and\n\uf8ef\n0.00.50.5\n0.6666\n0.5\n0.3333\n0.1666\n0.0\n0.3333\n0.1666\n0.5\n0.3333\n\uf8f9\n\uf8fb.\n\uf8fa"},{"page":6,"text":"Beam Sampling for the Infinite Hidden Markov Model\n5001000150020002500300035004000\n\u22124\n\u22122\n0\n2\nx 10\n4\nNMR Response\nMeasurement #\nFigure 5. The 40\u2019th sample of the beam sampler with every state represented by a different color on the well-log dataset.\n\u03b3 (Gamma(1,1) and Gamma(2,1) respectively); (2)\nstrong gamma hyperpriors for \u03b1 and \u03b3 (Gamma(6,15)\nand Gamma(16,4) respectively); (3) fixed hyperparam-\neters \u03b1 = 0.4,\u03b3 = 3.8. The latter were chosen using\nthe values the beam and Gibbs samplers converged to.\nAt every iteration, we greedily compute an assignment\nof sample states to true states to maximize overlap and\nuse the resulting Hamming distance as our error mea-\nsure. The top plot in figure 3 clearly shows that the\nbeam sampler discovers the underlying structure much\nfaster than the Gibbs sampler. Also, the beam sam-\npler is insensitive to the prior while the performance\nof the Gibbs sampler becomes worse as we strengthen\nour prior beliefs. The bottom plot of figure 3 shows\nhow many states are summed over in equation (4) av-\neraged per timestep, per state. We find that after only\nabout 20 iterations, the beam sampler on average con-\nsiders a little more than one state. This implies that\nthe actual complexity of the beam sampler is closer\nto O(TK) rather than the worst case complexity of\nO(TK2). Although this behavior is dependent on the\nchoice of distribution for the auxiliary variable utand\nthe sparsity of the transition matrix, we have verified\nthat this behavior is consistent also for larger iHMM\u2019s.\nOur second experiment illustrates the performance of\nthe beam sampler on data generated from HMM\u2019s\nwith increasing positive correlation between the hid-\nden states. We generated sequences of length 4000\nfrom a 4 state HMM with self-transition probabilities\nincreasing from 0.75 to 0.95 and finally 0.999. In one\nexperiment (top plot of figure 4) we generated nor-\nmal distributed observation from an informative out-\nput model with means \u22122.0,4.0,1.0,\u22120.5 and stan-\ndard deviation 0.5, in another experiment (bottom\nplot of figure 4) we generated normal distributed ob-\nservations from a less informative output model with\nmeans \u22121.0,0.5,\u22120.5,0.0 and standard deviation 0.5.\nWe initialize the experiment as above and set the base\ndistribution for the state means to be a 0 mean normal\nwith 2.0 standard deviation. Then, we greedily com-\npute the error compared to ground truth and average\nthe results over 60 different random starting positions.\nThe top row shows that with an informative prior,\nboth the Gibbs and beam sampler can reduce the ini-\ntial error by at least 50% independent of the correla-\ntion between hidden states. When the output model\nis less informative however and there is little corre-\nlation between the hidden states, the learning prob-\nlem is hardest: the lower left plot shows that both\nthe beam and Gibbs sampler discover structure only\nslowly. When the correlation increases, the learning\nproblem should become easier. However, as the lower\nright plot shows, although the beam sampler mixes in-\ncreasingly well, the Gibbs sampler suffers from slow\nrandom walk behavior.\n5.2. Well Data\nThe next experiment illustrates the performance of\nthe iHMM on a changepoint detection problem. The\ndata consists of 4050 noisy measurements of nuclear-\nresponse of rock strata obtained via lowering a probe\nthrough a bore-hole. Figure 5 illustrates this datasets.\nThe data has been previously analyzed in (Ruanaidh\n& Fitzgerald, 1996) by eliminating the forty great-\nest outliers and running a changepoint detection algo-\nrithm with a fixed number of changepoints. This ap-\nproach works well as this one-dimensional dataset can\nbe inspected visually to make a decision on whether\nto throw away datapoints and get a rough idea for\nthe number of changepoints. However, we believe that\nwith a nonparametric model, we can automatically\nadapt the number of changepoints. Moreover, by set-\nting up a noise model with fat tails, we hope to auto-\nmatically handle the outlier problem.\nWe model the mean of the nuclear-response for every\nsegment. First we normalize the data to have zero\nmean; then we specify a zero mean normal distribu-\ntion for the base distribution H. We choose the vari-\nance of this normal to be the empirical variance of the\ndataset. For the output model, we let F correspond\nto a Student-t distribution with \u03bd = 1, also known\nas the Cauchy distribution. We set the scale parame-\nter for the Cauchy distribution to twice the empirical\nstandard deviation for the dataset. Since the Cauchy\nlikelihood is not conjugate with respect to the nor-\nmal base distribution, we modified the Gibbs sampler\nbased on algorithm 8 in (Neal, 2000). We use the aux-"},{"page":7,"text":"Beam Sampling for the Infinite Hidden Markov Model\nFigure 6. The left plots show how frequent two datapoints\nwere in the same cluster averaged over the first 5 samples.\nThe right plots show how frequently two datapoints were\nin the same cluster averaged over the last 30 samples.\niliary variable sampling scheme discussed in (Gelman\net al., 2004) to resample the segment means.\nFigure 5 shows the results of one sample from the beam\nsampler: the iHMM segments the dataset reasonably\nwell and robustly handles the outliers. To compare the\nGibbs and beam samplers, we compute 50 samples af-\nter a burnin of 5000 iterations with 1000 iterations in\nbetween each sample. For every pair of datapoints we\ncompute the probability that they are in the same seg-\nment, averaged over the first five samples (left plots in\nfigure 6) and the last thirty samples (right plots in\nfigure 6). First, note that after the first 10000 itera-\ntions, the Gibbs sampler hasn\u2019t discovered any struc-\nture while the beam sampler has. This supports our\nclaim that the beam sampler mixes faster than the\nGibbs sampler. Moreover, we expect that the Gibbs\nsampler will have trouble to reassign the state assign-\nment for whole segments because of slow random walk\nbehavior. The beam sampler on the other hand re-\nsamples whole hidden state sequences and should be\nable to reassign whole segments more easily. The right\nplots of figure 6 confirm our expectation: a careful in-\nspection of both plots shows that the Gibbs sampler\nis visually more black-white indicating that either two\ndatapoints are always in the same cluster or never in\nthe same cluster; the beam sampler, on the other hand,\nhas gray areas which indicate that it averages over dif-\nferent assignments of the segments: e.g. the Gibbs plot\n(upper right) suggests that the leftmost segment and\nrightmost segment are always in the same state, while\nthe beam sampler plot (bottom right) indicates that\nonly part of the time, the left and rightmost segments\nare in the same state (90% of the time).\n5.3. Alice in Wonderland\nAnother application domain for HMMs is the area of\ntext prediction. One such task is that of predicting\nsequences of letters in text taken from Alice\u2019s Adven-\ntures in Wonderland. We compare the performance of\na finite HMM trained using variational Bayes (as de-\nscribed in (MacKay, 1997)) with two iHMMs trained\nusing beam sampling and Gibbs sampling. Both sam-\nplers had a burn-in of 1000 iterations and an additional\n10000 iterations to collect 50 samples of hidden state\nsequences from the posterior (i.e. we sample every 200\niterations).\nThe training data for each HMM (whether finite or\ninfinite) was taken to be a single sequence of 1000\ncharacters from the first chapter of the book. There\nwere 31 different observation symbols (26 letters ignor-\ning case plus space and basic punctuation characters).\nThe test data was taken to be the subsequent 4000\ncharacters from the same chapter. For all finite HMMs\nwe analyzed performance on models with the number\nof hidden states ranging from 1 to 50. For VB, we\nnote that the true predictive distribution is intractable\nto compute. Therefore, we used the posterior param-\neter distributions to sample 50 candidate parameter\nsettings, and used these to compute an approximate\npredictive log-likelihood.\npled 50 hidden state sequences from the stationary\ndistribution after convergence and used these samples\nto compute an approximate predictive log-likelihood.\nFor the VB-HMM we set the prior pseudo-counts for\nthe transition matrix to 4\/K across all states and\nthe prior pseudo-counts for the emission matrix to 0.3\nacross all symbols. Accordingly, we set the hyperprior\nfor the iHMMs such that a\u03b1 = 4 and b\u03b1 = 1 and\nH \u223c Dirichlet(()0.3,\u00b7\u00b7\u00b70.3). The results for VB and\nthe iHMMs were averaged over 50 and 20 independent\nFor the iHMMs, we sam-\n10 20 30 40 50\n\u22121.16\n\u22121.14\n\u22121.12\n\u22121.1\n\u22121.08\n\u22121.06x 10\n4\nNumber of hidden states (K)\nPredictive Log\u2212likelihood\n \n \niHMMs\nVB\u2212HMM\nFigure 7. Comparing VB-HMM with the iHMM."},{"page":8,"text":"Beam Sampling for the Infinite Hidden Markov Model\nruns respectively. The plot includes error bars corre-\nsponding to 2 standard deviations.\nFigure 7 illustrates the estimated predictive log-\nlikelihoods for the finite VB-HMM and the two iHMMs\ntrained using beam and Gibbs sampling. We find that\nthe iHMMs have superior predictive power when com-\npared to the VB-HMM, even when we select the best\nnumber of hidden states (around K = 16). Both the\niHMMs converged to a posterior distribution over hid-\nden state sequences with around 16 states, showing\nthat nonparametric Bayesian techniques are an effec-\ntive way to handle model selection. The final perfor-\nmance of the Gibbs and beam sampler were not found\nto be significantly different as we set the number of\niterations high enough to ensure that both algorithms\nconverge. Indeed, the aim of this experiment is not to\ncompare the performance of individuals iHMM sam-\npling schemes, rather, it is to further illustrate the rel-\native effectiveness of using models of infinite capacity.\n6. Conclusion\nIn this paper we introduced the beam sampler, a new\ninference algorithm for the iHMM that draws inspi-\nration from slice sampling and dynamic programming\nto sample whole hidden state trajectories efficiently.\nWe showed that the beam sampler is a more robust\nsampling algorithm than the Gibbs sampler. We be-\nlieve that the beam sampler is the algorithm of choice\nfor iHMM inference because it converges faster than\nthe Gibbs sampler and is straightforward to imple-\nment.Moreover, it conveniently allows us to learn\nnon-conjugate models. To encourage adoption of the\niHMM as an alternative to HMM learning, we have\nmade the software and datasets used in this paper\navailable at http:\/\/mlg.eng.cam.ac.uk\/jurgen.\nThe beam sampler idea is flexible enough to do in-\nference for various extensions of the iHMM: our cur-\nrent work involves an adaptation of the beam sampler\nto an extension of the iHMM that handles inputs, ef-\nfectively resulting in a nonparametric generalization\nof the input-output HMM (Bengio & Frasconi, 1995).\nWe believe this is a promising model for nonparamet-\nric Bayesian learning of POMDPs. Another project\ncurrently underway is to use the beam sampler for ef-\nficiently learning finite, but very large hidden Markov\nmodels. Finally, we are exploring the possibilities of\nusing the embedded HMM construction (Neal et al.,\n2004) as an alternative for the beam sampler for effi-\ncient inference in the iHMM.\nAcknowledgements\nWe would like to thank the anonymous reviewers for their\nhelpful comments. JVG is supported by a Microsoft Re-\nsearch PhD scholarship; ZG is also in the Machine Learning\nDepartment, CMU.\nReferences\nAntoniak, C. E. (1974).\nwith applications to bayesian nonparametric problems.\nThe Annals of Statistics, 2, 1152\u20131174.\nMixtures of dirichlet processes\nBeal, M. J., Ghahramani, Z., & Rasmussen, C. E. (2002).\nThe infinite hidden markov model. NIPS, 14.\nBengio, Y., & Frasconi, P. (1995). An input output hmm\narchitecture. NIPS, 7.\nDempster, A. P., Laird, N. M., & Rubin, D. B. (1977).\nMaximum likelihood from incomplete data via the em\nalgorithm. Journal of the Royal Statistical Society. Se-\nries B (Methodological), 39, 1\u201338.\nEscobar, M. D., & West, M. (1995). Bayesian density es-\ntimation and inference using mixtures. Journal of the\nAmerican Statistical Association, 90, 577\u2013588.\nGelman, A., Carlin, J. B., Stern, H. S., & Rubin, D. B.\n(2004). Bayesian data analysis. CRC Press. 2rev ed\nedition.\nGriffiths, T. L., & Ghahramani, Z. (2006). Infinite latent\nfeature models and the indian buffet process. NIPS, 18.\nMacKay, D. J. C. (1997). Ensemble learning for hidden\nmarkov models. Technical report, Cavendish Laboratory,\nUniversity of Cambridge, 1997.\nNeal, R. M. (2000). Markov chain sampling methods for\ndirichlet process mixture models. Journal of Computa-\ntional and Graphical Statistics, 9, 249\u2013265.\nNeal, R. M. (2003). Slice sampling. The Annals of Statis-\ntics, 31, 705\u2013741.\nNeal, R. M., Beal, M. J., & Roweis, S. T. (2004). Inferring\nstate sequences for non-linear systems with embedded\nhidden markov models. NIPS, 16.\nRabiner, L. R. (1989). A tutorial on hidden markov models\nand selected applications inspeech recognition. Proceed-\nings of the IEEE, 77, 257\u2013286.\nRasmussen, C. E. (2000). The infinite gaussian mixture\nmodel. NIPS, 12.\nRasmussen, C. E., & Williams, C. K. I. (2005). Gaussian\nprocesses for machine learning. The MIT Press.\nRuanaidh, J., & Fitzgerald, W. J. (1996).\nbayesian methods applied to signal processing. Springer-\nVerlag New York Inc.\nNumerical\nScott, S. L. (2002). Bayesian methods for hidden Markov\nmodels: Recursive computing in the 21st century. Jour-\nnal of the American Statistical Association, 97, 337\u2013351.\nSethuraman, J. (1994). A constructive definition of dirich-\nlet priors. Statistica Sinica, 4, 639\u2013650.\nTeh, Y. W., III, H. D., & Roy, D. (2008). Bayesian ag-\nglomerative clustering with coalescents. NIPS, 20.\nTeh, Y. W., Jordan, M. I., Beal, M. J., & Blei, D. M.\n(2006). Hierarchical dirichlet processes. Journal of the\nAmerican Statistical Association, 101, 1566\u20131581.\nWalker, S. G. (2007). Sampling the dirichlet mixture model\nwith slices. Communications in Statistics - Simulation\nand Computation, 36, 45."}],"fullTextUrl":"https:\/\/www.researchgate.net\/profile\/Yunus_Saatchi\/publication\/221345210_Beam_sampling_for_the_infinite_hidden_Markov_model\/links\/00463525dba898f504000000.pdf","widgetId":"rgw31_56ab199beedce"},"id":"rgw31_56ab199beedce","partials":[],"templateName":"publicliterature\/stubs\/PublicationText.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationText.html?publicationUid=221345210&hide=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationDetailAd":{"data":{"googleDfpSlot":null,"widgetId":"rgw32_56ab199beedce"},"id":"rgw32_56ab199beedce","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAd.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAd.html?publicationUid=221345210&slotId=336x280_Publications_ATF_Right&collapseSlotMode=never&fallbackContainerEnabled=1","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationRelations":null,"publicationRelationsReverse":null,"publicationUid":221345210,"showSignUpDialog":false,"selectNewSignUpDialog":false,"publicationQuestions":null,"publicationCitations":{"data":{"publicationUid":221345210,"publicationCitationsList":{"data":{"citationItems":[{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore","clickThrough":"experimentMilestoneClickedToPublicationFromCitationWithFulltext","clickThroughWithContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextSlurp","nextPublicationViewId":null,"authorsPartOne":[{"id":2033083818,"url":"researcher\/2033083818_Jonathan_H_Huggins","fullname":"Jonathan H. Huggins","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":70496072,"url":"researcher\/70496072_Frank_Wood","fullname":"Frank Wood","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":[["includes-citation-list"]],"isFulltext":true,"isSlurp":false,"isNoText":false,"publicationType":"Article","publicationDate":"Jun 2014","journal":null,"showEnrichedPublicationItem":false,"citationCount":1,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/263582646_Infinite_Structured_Hidden_Semi-Markov_Models","usePlainButton":true,"publicationUid":263582646,"feedStubs":null,"hasFeedStubs":false,"impactPoints":false,"url":"publication\/263582646_Infinite_Structured_Hidden_Semi-Markov_Models","title":"Infinite Structured Hidden Semi-Markov Models","displayTitleAsLink":true,"authors":[{"id":2033083818,"url":"researcher\/2033083818_Jonathan_H_Huggins","fullname":"Jonathan H. Huggins","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":70496072,"url":"researcher\/70496072_Frank_Wood","fullname":"Frank Wood","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":[],"abstract":"This paper reviews recent advances in Bayesian nonparametric techniques for\nconstructing and performing inference in infinite hidden Markov models. We\nfocus on variants of Bayesian nonparametric hidden Markov models that enhance a\nposteriori state-persistence in particular. This paper also introduces a new\nBayesian nonparametric framework for generating left-to-right and other\nstructured, explicit-duration infinite hidden Markov models that we call the\ninfinite structured hidden semi-Markov model.","description":false,"swapJournalAndAuthorPositions":false,"showAbstract":true,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/263582646_Infinite_Structured_Hidden_Semi-Markov_Models","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":true,"actions":[{"type":"download","text":"Download","url":"profile\/Jonathan_Huggins\/publication\/263582646_Infinite_Structured_Hidden_Semi-Markov_Models\/links\/54cba2260cf24601c08819ac.pdf?origin=publication_list","active":false,"primary":true,"extraClass":"open-viewer","icon":null,"data":[]}],"actionWidgets":[],"publicationItemFulltext":{"data":{"isDataset":false,"isResearch":false,"isFulltext":true,"source":{"isPreview":false,"sourceUrl":"profile\/Jonathan_Huggins","sourceName":"Jonathan H Huggins","hasSourceUrl":true},"publicationUid":263582646,"publicationUrl":"publication\/263582646_Infinite_Structured_Hidden_Semi-Markov_Models","eventCode":"","citationCount":0,"additionalContentWidgets":[],"disableViewer":true,"showLoggedOutRequestButton":false,"context":null,"previewUrl":"https:\/\/i1.rgstatic.net\/publication\/263582646_Infinite_Structured_Hidden_Semi-Markov_Models\/links\/54cba2260cf24601c08819ac\/smallpreview.png","linkId":"54cba2260cf24601c08819ac","origin":"publication_list","showRequestCount":false,"publish":false,"request":false,"showAction":false,"displayAsLink":true,"documentViewerUrl":"publicliterature.PublicLiteratureDocumentViewer.html?publicationId=263582646&reference=54cba2260cf24601c08819ac&eventCode=&origin=publication_list","widgetId":"rgw36_56ab199beedce"},"id":"rgw36_56ab199beedce","partials":[],"templateName":"publicliterature\/stubs\/PublicationItemFulltext.html","templateExtensions":["generalHelpers"],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItemFulltext.html?publicationUid=263582646&showAction=1&eventCode=&hideSource=0&displayAsLink=1&showPublishAsSelectFile=0","viewClass":"views.publicliterature.PublicationItemFulltextView","yuiModules":["rg.views.publicliterature.PublicationItemFulltextView"],"stylesheets":[],"_isYUI":true},"linkId":"54cba2260cf24601c08819ac","context":null,"contextId":null,"eventCode":"","isCitation":true,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":221345210,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/263582646_Infinite_Structured_Hidden_Semi-Markov_Models\/review","additionalRightSideTopWidgets":[{"data":{"citationContexts":["Inference in the two models is different: PPM inference is performed using a O(T 2 ) dynamic programming approach [5] which exactly computes the map partition (and implicitly the partition cardinality K and per-segment observation parameter distributions). There is an approximate inference algorithm which scales like our O(T ) approach [5], but it does not have the kinds of asymptotic convergence guarantees the auxiliary variable slice sampling approach does [31] "],"widgetId":"rgw37_56ab199beedce"},"id":"rgw37_56ab199beedce","partials":[],"templateName":"publicliterature\/stubs\/PublicationItemCitationContexts.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItemCitationContexts.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":true,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read full-text","widgetId":"rgw35_56ab199beedce"},"id":"rgw35_56ab199beedce","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":true,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItem.html?showEnrichedPublicationItem=0&showRequestButton=1&publicationUid=263582646&additionalCssClasses%5B0%5D=includes-citation-list&citationContextItemVersion=old&isIncomingCitation=1","viewClass":"views.publicliterature.PublicationItemView","yuiModules":["rg.views.publicliterature.PublicationItemView"],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore","clickThrough":"experimentMilestoneClickedToPublicationFromCitationWithFulltext","clickThroughWithContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":2059751469,"url":"researcher\/2059751469_Niklas_Vanhainen","fullname":"Niklas Vanhainen","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":8648081,"url":"researcher\/8648081_Giampiero_Salvi","fullname":"Giampiero Salvi","last":true,"imageUrl":"https:\/\/i1.rgstatic.net\/ii\/profile.image\/AS%3A288790896758784%401445864523944_m"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":[["includes-citation-list"]],"isFulltext":true,"isSlurp":false,"isNoText":false,"publicationType":"Conference Paper","publicationDate":"May 2014","journal":null,"showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/269164447_Pattern_discovery_in_continuous_speech_using_Block_Diagonal_Infinite_HMM","usePlainButton":true,"publicationUid":269164447,"feedStubs":null,"hasFeedStubs":false,"impactPoints":false,"url":"publication\/269164447_Pattern_discovery_in_continuous_speech_using_Block_Diagonal_Infinite_HMM","title":"Pattern discovery in continuous speech using Block Diagonal Infinite HMM","displayTitleAsLink":true,"authors":[{"id":2059751469,"url":"researcher\/2059751469_Niklas_Vanhainen","fullname":"Niklas Vanhainen","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":8648081,"url":"researcher\/8648081_Giampiero_Salvi","fullname":"Giampiero Salvi","last":true,"imageUrl":"https:\/\/i1.rgstatic.net\/ii\/profile.image\/AS%3A288790896758784%401445864523944_m"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["ICASSP 2014 - 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP); 05\/2014"],"abstract":"We propose the application of a recently introduced inference method, the Block Diagonal Infinite Hidden Markov Model (BDiHMM), to the problem of learning the topology of a Hidden Markov Model (HMM) from continuous speech in an unsupervised way. We test the method on the TiDigits continuous digit database and analyse the emerging patterns corresponding to the blocks of states inferred by the model. We show how the complexity of these patterns increases with the amount of observations and number of speakers. We also show that the patterns correspond to sub-word units that constitute stable and discriminative representations of the words contained in the speech material.","description":false,"swapJournalAndAuthorPositions":false,"showAbstract":true,"type":"Conference Paper","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/269164447_Pattern_discovery_in_continuous_speech_using_Block_Diagonal_Infinite_HMM","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":true,"actions":[{"type":"download","text":"Download","url":"profile\/Giampiero_Salvi\/publication\/269164447_Pattern_discovery_in_continuous_speech_using_Block_Diagonal_Infinite_HMM\/links\/5565cfed08aec4b0f48696b2.pdf?origin=publication_list","active":false,"primary":true,"extraClass":"open-viewer","icon":null,"data":[]}],"actionWidgets":[],"publicationItemFulltext":{"data":{"isDataset":false,"isResearch":false,"isFulltext":true,"source":{"isPreview":false,"sourceUrl":"profile\/Giampiero_Salvi","sourceName":"Giampiero Salvi","hasSourceUrl":true},"publicationUid":269164447,"publicationUrl":"publication\/269164447_Pattern_discovery_in_continuous_speech_using_Block_Diagonal_Infinite_HMM","eventCode":"","citationCount":0,"additionalContentWidgets":[],"disableViewer":true,"showLoggedOutRequestButton":false,"context":null,"previewUrl":"https:\/\/i1.rgstatic.net\/publication\/269164447_Pattern_discovery_in_continuous_speech_using_Block_Diagonal_Infinite_HMM\/links\/5565cfed08aec4b0f48696b2\/smallpreview.png","linkId":"5565cfed08aec4b0f48696b2","origin":"publication_list","showRequestCount":false,"publish":false,"request":false,"showAction":false,"displayAsLink":true,"documentViewerUrl":"publicliterature.PublicLiteratureDocumentViewer.html?publicationId=269164447&reference=5565cfed08aec4b0f48696b2&eventCode=&origin=publication_list","widgetId":"rgw39_56ab199beedce"},"id":"rgw39_56ab199beedce","partials":[],"templateName":"publicliterature\/stubs\/PublicationItemFulltext.html","templateExtensions":["generalHelpers"],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItemFulltext.html?publicationUid=269164447&showAction=1&eventCode=&hideSource=0&displayAsLink=1&showPublishAsSelectFile=0","viewClass":"views.publicliterature.PublicationItemFulltextView","yuiModules":["rg.views.publicliterature.PublicationItemFulltextView"],"stylesheets":[],"_isYUI":true},"linkId":"5565cfed08aec4b0f48696b2","context":null,"contextId":null,"eventCode":"","isCitation":true,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":221345210,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/269164447_Pattern_discovery_in_continuous_speech_using_Block_Diagonal_Infinite_HMM\/review","additionalRightSideTopWidgets":[{"data":{"citationContexts":["The method, as implemented for this paper, uses the Beam Sampling algorithm described in [4] to sample a hidden Markov model, and the method described in chapter 4 of [3] to sample an appropriate block configuration for this model. The beam sampling method was chosen due to its speed of inference relative to the traditional approach [24], the difference being that [4] introduces a way of sampling a statepath for the iHMM using a dynamic programming algorithm, similarly to the way a traditional HMM is commonly trained. Using the dynamic programming algorithm, the state path is Fig. 1: Graphical depiction of BDiHMM model[3] sampled as a whole rather than as many individual parameters as would otherwise be the case with Gibbs sampling. "],"widgetId":"rgw40_56ab199beedce"},"id":"rgw40_56ab199beedce","partials":[],"templateName":"publicliterature\/stubs\/PublicationItemCitationContexts.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItemCitationContexts.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":true,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read full-text","widgetId":"rgw38_56ab199beedce"},"id":"rgw38_56ab199beedce","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":true,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItem.html?showEnrichedPublicationItem=0&showRequestButton=1&publicationUid=269164447&additionalCssClasses%5B0%5D=includes-citation-list&citationContextItemVersion=old&isIncomingCitation=1","viewClass":"views.publicliterature.PublicationItemView","yuiModules":["rg.views.publicliterature.PublicationItemView"],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore","clickThrough":"experimentMilestoneClickedToPublicationFromCitationWithFulltext","clickThroughWithContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextSlurp","nextPublicationViewId":null,"authorsPartOne":[{"id":71067565,"url":"researcher\/71067565_Drausin_F_Wulsin","fullname":"Drausin F. Wulsin","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":44211050,"url":"researcher\/44211050_Emily_B_Fox","fullname":"Emily B. Fox","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":39899419,"url":"researcher\/39899419_Brian_Litt","fullname":"Brian Litt","last":true,"imageUrl":"https:\/\/i1.rgstatic.net\/ii\/profile.image\/AS%3A321557774176256%401453676755011_m"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":[["includes-citation-list"]],"isFulltext":true,"isSlurp":false,"isNoText":false,"publicationType":"Article","publicationDate":"Feb 2014","journal":"Artificial Intelligence","showEnrichedPublicationItem":false,"citationCount":2,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/260428846_Modeling_the_Complex_Dynamics_and_Changing_Correlations_of_Epileptic_Events","usePlainButton":true,"publicationUid":260428846,"feedStubs":null,"hasFeedStubs":false,"impactPoints":"3.37","url":"publication\/260428846_Modeling_the_Complex_Dynamics_and_Changing_Correlations_of_Epileptic_Events","title":"Modeling the Complex Dynamics and Changing Correlations of Epileptic Events","displayTitleAsLink":true,"authors":[{"id":71067565,"url":"researcher\/71067565_Drausin_F_Wulsin","fullname":"Drausin F. Wulsin","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":44211050,"url":"researcher\/44211050_Emily_B_Fox","fullname":"Emily B. Fox","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":39899419,"url":"researcher\/39899419_Brian_Litt","fullname":"Brian Litt","last":true,"imageUrl":"https:\/\/i1.rgstatic.net\/ii\/profile.image\/AS%3A321557774176256%401453676755011_m"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["Artificial Intelligence 02\/2014; 216. DOI:10.1016\/j.artint.2014.05.006"],"abstract":"Patients with epilepsy can manifest short, sub-clinical epileptic \"bursts\" in\naddition to full-blown clinical seizures. We believe the relationship between\nthese two classes of events---something not previously studied\nquantitatively---could yield important insights into the nature and intrinsic\ndynamics of seizures. A goal of our work is to parse these complex epileptic\nevents into distinct dynamic regimes. A challenge posed by the intracranial EEG\n(iEEG) data we study is the fact that the number and placement of electrodes\ncan vary between patients. We develop a Bayesian nonparametric Markov switching\nprocess that allows for (i) shared dynamic regimes between a variable numbers\nof channels, (ii) asynchronous regime-switching, and (iii) an unknown\ndictionary of dynamic regimes. We encode a sparse and changing set of\ndependencies between the channels using a Markov-switching Gaussian graphical\nmodel for the innovations process driving the channel dynamics and demonstrate\nthe importance of this model in parsing and out-of-sample predictions of iEEG\ndata. We show that our model produces intuitive state assignments that can help\nautomate clinical analysis of seizures and enable the comparison of\nsub-clinical bursts and full clinical seizures.","description":false,"swapJournalAndAuthorPositions":false,"showAbstract":true,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/260428846_Modeling_the_Complex_Dynamics_and_Changing_Correlations_of_Epileptic_Events","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":true,"actions":[{"type":"download","text":"Download","url":"profile\/Brian_Litt\/publication\/260428846_Modeling_the_Complex_Dynamics_and_Changing_Correlations_of_Epileptic_Events\/links\/55ae311f08ae98e661a56334?origin=publication_list","active":false,"primary":true,"extraClass":"open-viewer","icon":null,"data":[]}],"actionWidgets":[],"publicationItemFulltext":{"data":{"isDataset":false,"isResearch":false,"isFulltext":true,"source":{"isPreview":false,"sourceUrl":"profile\/Brian_Litt","sourceName":"Brian Litt","hasSourceUrl":true},"publicationUid":260428846,"publicationUrl":"publication\/260428846_Modeling_the_Complex_Dynamics_and_Changing_Correlations_of_Epileptic_Events","eventCode":"","citationCount":0,"additionalContentWidgets":[],"disableViewer":true,"showLoggedOutRequestButton":false,"context":null,"previewUrl":"https:\/\/i1.rgstatic.net\/publication\/260428846_Modeling_the_Complex_Dynamics_and_Changing_Correlations_of_Epileptic_Events\/links\/55ae311f08ae98e661a56334\/smallpreview.png","linkId":"55ae311f08ae98e661a56334","origin":"publication_list","showRequestCount":false,"publish":false,"request":false,"showAction":false,"displayAsLink":true,"documentViewerUrl":"publicliterature.PublicLiteratureDocumentViewer.html?publicationId=260428846&reference=55ae311f08ae98e661a56334&eventCode=&origin=publication_list","widgetId":"rgw42_56ab199beedce"},"id":"rgw42_56ab199beedce","partials":[],"templateName":"publicliterature\/stubs\/PublicationItemFulltext.html","templateExtensions":["generalHelpers"],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItemFulltext.html?publicationUid=260428846&showAction=1&eventCode=&hideSource=0&displayAsLink=1&showPublishAsSelectFile=0","viewClass":"views.publicliterature.PublicationItemFulltextView","yuiModules":["rg.views.publicliterature.PublicationItemFulltextView"],"stylesheets":[],"_isYUI":true},"linkId":"55ae311f08ae98e661a56334","context":null,"contextId":null,"eventCode":"","isCitation":true,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":221345210,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/260428846_Modeling_the_Complex_Dynamics_and_Changing_Correlations_of_Epileptic_Events\/review","additionalRightSideTopWidgets":[{"data":{"citationContexts":["Other work has explored nonparametric modeling of multiple time series. The infinite factorial HMM of Van Gael et al. [9] considers an infinite collection of chains each with a binary state space. The infinite hierarchical HMM [10] also involves infinitely many chains with finite state spaces, but with constrained transitions between the chains in a top down fashion. "],"widgetId":"rgw43_56ab199beedce"},"id":"rgw43_56ab199beedce","partials":[],"templateName":"publicliterature\/stubs\/PublicationItemCitationContexts.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItemCitationContexts.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":true,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read full-text","widgetId":"rgw41_56ab199beedce"},"id":"rgw41_56ab199beedce","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":true,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItem.html?showEnrichedPublicationItem=0&showRequestButton=1&publicationUid=260428846&additionalCssClasses%5B0%5D=includes-citation-list&citationContextItemVersion=old&isIncomingCitation=1","viewClass":"views.publicliterature.PublicationItemView","yuiModules":["rg.views.publicliterature.PublicationItemView"],"stylesheets":[],"_isYUI":true}],"hasCitations":true,"isPublicationAuthor":false,"isPublicationVisitor":false,"publicationUid":221345210,"publicationLink":"publication\/221345210_Beam_sampling_for_the_infinite_hidden_Markov_model","hasShowMore":true,"newOffset":3,"pageSize":10,"widgetId":"rgw34_56ab199beedce"},"id":"rgw34_56ab199beedce","partials":[],"templateName":"publicliterature\/stubs\/PublicationIncomingCitationsList.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationIncomingCitationsList.html?publicationUid=221345210&citedInPage=1&swapJournalAndAuthorPositions=0&showAbstract=1&showType=1&showPublicationPreview=1&totalCount=77","viewClass":"views.publicliterature.PublicationIncomingCitationsListView","yuiModules":["rg.views.publicliterature.PublicationIncomingCitationsListView"],"stylesheets":[],"_isYUI":true},"hasCitations":false,"citationsCount":0,"hasIncomingCitations":true,"incomingCitationsCount":77,"showCitationsSorter":true,"showAbstract":true,"showType":true,"showPublicationPreview":true,"swapJournalAndAuthorPositions":false,"sort":"","sortOriginal":false,"citationList":"incoming","showsIncoming":true,"showSorting":false,"usePlainButton":null,"useEnrichedContext":null,"widgetId":"rgw33_56ab199beedce"},"id":"rgw33_56ab199beedce","partials":[],"templateName":"publicliterature\/stubs\/PublicationCitations.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationCitations.html?publicationUid=221345210&citationList=&citedInPage=1&sort=","viewClass":"views.publicliterature.PublicationCitationsView","yuiModules":["rg.views.publicliterature.PublicationCitationsView"],"stylesheets":[],"_isYUI":true},"publicationReviewPromo":null,"publicationUsedInReviews":null,"publicationPdfJsReader":{"data":{"isPreview":false,"licenseUrl":null,"licenseInfo":null,"defaultLinkData":{"linkId":"00463525dba898f504000000","name":"Yunus Saatchi","date":null,"nameLink":"profile\/Yunus_Saatchi","filename":"","downloadLink":"https:\/\/www.researchgate.net\/profile\/Yunus_Saatchi\/publication\/221345210_Beam_sampling_for_the_infinite_hidden_Markov_model\/links\/00463525dba898f504000000.pdf?inViewer=0&pdfJsDownload=0&origin=publication_detail","viewerUrl":"https:\/\/www.researchgate.net\/profile\/Yunus_Saatchi\/publication\/221345210_Beam_sampling_for_the_infinite_hidden_Markov_model\/links\/00463525dba898f504000000.pdf?inViewer=1&pdfJsDownload=1&origin=publication_detail","downloadHash":"975ad239fe006a6a08c9ca60e0d9e680","showFileSizeNote":false,"fileSize":"470.27 KB","noFollow":false,"isDefault":true,"doi":null},"displayableLinks":[{"linkId":"00463525dba898f504000000","name":"Yunus Saatchi","date":null,"nameLink":"profile\/Yunus_Saatchi","filename":"","downloadLink":"https:\/\/www.researchgate.net\/profile\/Yunus_Saatchi\/publication\/221345210_Beam_sampling_for_the_infinite_hidden_Markov_model\/links\/00463525dba898f504000000.pdf?inViewer=0&pdfJsDownload=0&origin=publication_detail","viewerUrl":"https:\/\/www.researchgate.net\/profile\/Yunus_Saatchi\/publication\/221345210_Beam_sampling_for_the_infinite_hidden_Markov_model\/links\/00463525dba898f504000000.pdf?inViewer=1&pdfJsDownload=1&origin=publication_detail","downloadHash":"975ad239fe006a6a08c9ca60e0d9e680","showFileSizeNote":false,"fileSize":"470.27 KB","noFollow":false,"isDefault":true,"doi":null}],"hasDisplayableLinks":false,"reader":{"data":{"pdfCommentsActive":false,"publicationType":"Conference Paper","onlyRenderFirstPage":false,"readMoreExperimentGoal":"goalPublicationPdfClicksReadMore","readMoreExperimentViewId":null,"comments":null,"figures":[{"props":{"position":"float","orientation":"portrait","coords":"pag:7:rect:55.44,278.42,234.01,40.84","ordinal":"6"},"assetId":"AS:305512349487108@1449851228782"}],"figureAssetIds":["AS:305512349487108@1449851228782"],"figureOverlayUrls":{"clickOnOverlay":"publication.PublicationFigures.html?_sg=jVuyU56itdioy_UawxIT380J5r_UDzzv1m2iObTgilki63VAzcbJ7eRcW2M2HtwkLrXm0hKr6LX1Mr5UknlXLA.N6ciV2-mflSMO0zTAueP3Xah0XFWE-WT8lyrwPVbvAOjErFrrybqwo7sPAiRRp2TUaHKN1LY7IBBv4kNMGzmmw","clickOnPill":"publication.PublicationFigures.html?_sg=uw-cxfnp4Y4H4gbj2ZgHHRp6fyg_v-rs2WhhLfnTactN277fjrszQqLLaicL2yxQiLftlFGEXGObXxyePqN-aA.OHrYGhpCB7c5ZEQjWTQrOkveoGSZSienrSe-01BWxxpDJpCLA6h8Oy7k16o3_UpVQYouy-55U2zrPfZ_uxOQUQ"},"canSelect":false,"javascriptPath":"https:\/\/www.researchgate.net\/c\/o1o9o3\/","downloadUrl":"https%3A%2F%2Fwww.researchgate.net%2Fprofile%2FYunus_Saatchi%2Fpublication%2F221345210_Beam_sampling_for_the_infinite_hidden_Markov_model%2Flinks%2F00463525dba898f504000000.pdf%3FinViewer%3D1%26pdfJsDownload%3D1%26origin%3Dpublication_detail","viewerUrl":"https:\/\/www.researchgate.net\/c\/o1o9o3\/javascript\/lib\/pdfjs\/web\/viewer.html","commentEndpoint":"https:\/\/www.researchgate.net\/rgformat\/api\/comment","experimentEndpoint":"https:\/\/www.researchgate.net\/rgformat\/api\/experiment?key=LmCFUNEqnH6K-cexUPu6NnLU52PRa2ieVsCpy5NduOPS4xlqZfAQTsyVvC4HZxRIKaV380hzfa6bHoBd7_suwQ","urlHash":"00d33d543bc3a73ed1844f1a4fab9713","downloadTrackUrl":"application.PdfJsReader.ajaxTrackDownload.html?msrp=eHsDQUNaH-vqd2yV6jFIFuyvMbaNG-mOUtKJ3JamVKoJmssIkSJen6lF6wZTNMjsLJfoEf37RCDQo7t26sk-BynpyIUr3sIB-Oep1CnQM1Q.wt_yrLCSJmC_-sJBcMh4vvTmnZqKxYtlcHMCnPfnecTgRCSQhPt8lJw8U5PZ8VPSKftCH3XUvWzvJcFp_wHreg.2QArG4euGEZrvCZ-0a0RPL4v1Gm30Orp3k3PXBdqJc79__YB3S_yvgKSRvR0sl_uYUwsQQDWayz6CT179sOMUg","viewportMilestoneTrackUrl":"application.PdfJsReader.ajaxTrackViewportMilestone.html","linkId":"00463525dba898f504000000","trackedDownloads":{"00463525dba898f504000000":{"v":false,"d":false}},"assetId":"AS:101790578118680@1401280173693","readerDocId":"6973361","assetType":"fulltext","interactionType":{"comment":"comment","highlight":"highlight"},"publicationUid":221345210,"commentCursorPromo":null,"widgetId":"rgw45_56ab199beedce"},"id":"rgw45_56ab199beedce","partials":[],"templateName":"application\/stubs\/PdfJsReader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PdfJsReader.html?fileHref=https%3A%2F%2Fwww.researchgate.net%2Fprofile%2FYunus_Saatchi%2Fpublication%2F221345210_Beam_sampling_for_the_infinite_hidden_Markov_model%2Flinks%2F00463525dba898f504000000.pdf%3FinViewer%3D1%26pdfJsDownload%3D1%26origin%3Dpublication_detail&assetId=AS%3A101790578118680%401401280173693&publicationUid=221345210&linkId=00463525dba898f504000000&onlyShowFirstPage=0","viewClass":null,"yuiModules":["css-pow-application-PdfJsReader"],"stylesheets":["pow\/application\/PdfJsReader.css"],"_isYUI":true},"showHeader":true,"title":"Beam sampling for the infinite hidden Markov model","publicationType":"Conference Paper","downloadTrackUrl":"publicliterature.PublicationInlineReader.ajaxTrackDownload.html?msrp=jG_s8ZdjHuqX24GBBugRqe8wSa5LIQkvRDQQDGNeZQ3zRsNbLWrR984UytwD-4woY4l3CMPaQIp2_cmCG8nMjHpPLl1T72mZFT_lUSLPmPg.FbLja-H9iCMJbNu8OHAK_cw95WRbFIfcIj33-p_mxf4jkIftKbnekiIApgbOZ03oqSI6SgnhWJYj_UYFJ6t0og.YJUTYQiicxYKD_cfdxuc9cTZ024aXUe5rNY16tRZSKysl_9DBaJoE42i5DfVBtqy2UXewQXGGV1gbmVuwsdyIQ","publicationUid":221345210,"trackedDownloads":{"00463525dba898f504000000":{"v":false,"d":false}},"inlinePdf":false,"publicationComments":null,"showDownloadButton":true,"socialShare":{"data":{"shareItems":[{"data":{"name":"Facebook","url":"http:\/\/www.facebook.com\/share.php?u={{url}}{{#title}}&t={{title}}{{\/title}}","width":600,"height":350,"useUtmTags":true,"utmSource":"facebook","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareFacebook.ajaxTrackSocialShare.html","widgetId":"rgw47_56ab199beedce"},"id":"rgw47_56ab199beedce","partials":{"shareIcon":"application\/stubs\/partials\/shareFacebookBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareFacebook.html?provider=Facebook&shareIcon=shareIconBlog&utmSource=facebook&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"Twitter","url":"http:\/\/twitter.com\/intent\/tweet?text={{#title}}{{title}}: {{\/title}}{{url}}&via=researchgate","width":600,"height":350,"useUtmTags":true,"utmSource":"twitter","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareTwitter.ajaxTrackSocialShare.html","widgetId":"rgw48_56ab199beedce"},"id":"rgw48_56ab199beedce","partials":{"shareIcon":"application\/stubs\/partials\/shareTwitterBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareTwitter.html?provider=Twitter&shareIcon=shareIconBlog&utmSource=twitter&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"Google+","url":"https:\/\/plus.google.com\/share?url={{url}}","width":600,"height":600,"useUtmTags":true,"utmSource":"googleplus","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareGooglePlus.ajaxTrackSocialShare.html","widgetId":"rgw49_56ab199beedce"},"id":"rgw49_56ab199beedce","partials":{"shareIcon":"application\/stubs\/partials\/shareGooglePlusBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareGooglePlus.html?provider=Google%2B&shareIcon=shareIconBlog&utmSource=googleplus&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"LinkedIn","url":"http:\/\/www.linkedin.com\/shareArticle?mini=true&url={{url}}{{#title}}&title={{title}}{{\/title}}&source=ResearchGate","width":520,"height":570,"useUtmTags":true,"utmSource":"linkedin","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareLinkedIn.ajaxTrackSocialShare.html","widgetId":"rgw50_56ab199beedce"},"id":"rgw50_56ab199beedce","partials":{"shareIcon":"application\/stubs\/partials\/shareLinkedInBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareLinkedIn.html?provider=LinkedIn&shareIcon=shareIconBlog&utmSource=linkedin&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"Reddit","url":"https:\/\/www.reddit.com\/submit?url={{url}}{{#title}}&title={{title}}{{\/title}}","width":600,"height":600,"useUtmTags":true,"utmSource":"reddit","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareReddit.ajaxTrackSocialShare.html","widgetId":"rgw51_56ab199beedce"},"id":"rgw51_56ab199beedce","partials":{"shareIcon":"application\/stubs\/partials\/shareRedditBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareReddit.html?provider=Reddit&shareIcon=shareIconBlog&utmSource=reddit&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true}],"widgetId":"rgw46_56ab199beedce"},"id":"rgw46_56ab199beedce","partials":[],"templateName":"application\/stubs\/SocialShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.SocialShare.html?campaign=shareFullTextPublication&trackClick=1&shareIcon=shareIconBlog","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw44_56ab199beedce"},"id":"rgw44_56ab199beedce","partials":[],"templateName":"publicliterature\/stubs\/PublicationInlineReader.html","templateExtensions":["generalHelpers"],"attrs":{"showFulltextDownloadedSignupDialog":true,"preSignUpDialogContext":null,"requestFulltext":false},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationInlineReader.html","viewClass":"views.publicliterature.PublicationInlineReaderView","yuiModules":["rg.views.publicliterature.PublicationInlineReaderView","css-pow-publicliterature-PublicationInlineReader"],"stylesheets":["pow\/publicliterature\/PublicationInlineReader.css"],"_isYUI":true},"useFulltextOptimizedLayout":false,"publicationActions":null,"requestFulltextPromo":null,"currentUrl":"publication\/221345210_Beam_sampling_for_the_infinite_hidden_Markov_model","isLeaderboardAd":false,"enableStickyBox":null,"googleDfpSlotMobileBottom":null,"fullTextExitPopup":null,"showExitPopupDialog":false,"widgetId":"rgw2_56ab199beedce"},"id":"rgw2_56ab199beedce","partials":{"romeo_legal_notice":"publicliterature\/stubs\/partials\/romeo_legal_notice.html"},"templateName":"publicliterature\/stubs\/PublicPublicationDetails_NewLayout.html","templateExtensions":["generalHelpers"],"attrs":{"publicationUid":221345210},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicPublicationDetailsOld.html?publicationUid=221345210&isTestOldDesign=0","viewClass":"views.publicliterature.PublicPublicationDetailsOldView","yuiModules":["rg.views.publicliterature.PublicPublicationDetailsOldView"],"stylesheets":[],"_isYUI":true},"widgetId":"rgw1_56ab199beedce"},"id":"rgw1_56ab199beedce","partials":[],"templateName":"publicliterature\/stubs\/PublicPublicationDetails.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicPublicationDetails.html","viewClass":"views.publicliterature.PublicPublicationDetailsView","yuiModules":["rg.views.publicliterature.PublicPublicationDetailsView"],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"uaClass":"","headPrefix":[],"rootUrl":"https:\/\/www.researchgate.net\/","requestToken":"\/QeBWSyALRD3ffexEjuLkmjcgCwZnzls7aVGjeVKyaSU4CnNjeIuXYZGEkjup3U5OalIXXOEVFMLk1nnLnh9YxqSNtH1ZxrPapv3L5TX9qm7dTADYCGslsiv70BrlfVqGBtqk9QDs0qbg9wM\/107X25Hm\/ooWlW+teZN8OUP40N3y2hUYHogbyKwkt7EfCH1GqxTDAhmp9cUzYBrsm3JLBpMyzA2KY264fMyF\/\/q+UVTItdEI3bSMgqye9PHCQsjR1xai0C9G4k8C2TkGjkQPlBwzONflKWm30npodTvpJA=","faviconCdnUrl":"https:\/\/c5.rgstatic.net\/m\/2390829798215018\/images\/favicon.ico","headerOutput":"<noscript><\/noscript><link rel=\"canonical\" href=\"https:\/\/www.researchgate.net\/publication\/221345210_Beam_sampling_for_the_infinite_hidden_Markov_model\" \/>\n<link rel=\"dns-prefetch\" href=\"\/\/c5.rgstatic.net\" \/>\n<link rel=\"dns-prefetch\" href=\"\/\/i1.rgstatic.net\" \/>\n<meta property=\"twitter:card\" content=\"summary\" \/>\n<meta property=\"twitter:site\" content=\"@ResearchGate\" \/>\n<meta property=\"og:title\" content=\"Beam sampling for the infinite hidden Markov model\" \/>\n<meta property=\"og:description\" content=\"The innite hidden Markov model is a non- parametric extension of the widely used hid- den Markov model. Our paper introduces a new inference algorithm for the innite Hidden Markov model called...\" \/>\n<meta property=\"og:site_name\" content=\"ResearchGate\" \/>\n<meta property=\"og:image\" content=\"https:\/\/i1.rgstatic.net\/publication\/221345210_Beam_sampling_for_the_infinite_hidden_Markov_model\/links\/00463525dba898f504000000\/smallpreview.png\" \/>\n<meta property=\"og:url\" content=\"https:\/\/www.researchgate.net\/publication\/221345210_Beam_sampling_for_the_infinite_hidden_Markov_model\" \/>\n<meta property=\"rg:id\" content=\"PB:221345210\" \/>\n<meta name=\"DC.identifier\" scheme=\"DCTERMS.URI\" content=\"http:\/\/dx.doi.org\/10.1145\/1390156.1390293\" \/>\n<meta name=\"gs_meta_revision\" content=\"1.1\" \/>\n<meta name=\"citation_title\" content=\"Beam sampling for the infinite hidden Markov model\" \/>\n<meta name=\"citation_author\" content=\"Jurgen Van Gael\" \/>\n<meta name=\"citation_author\" content=\"Yunus Saatci\" \/>\n<meta name=\"citation_author\" content=\"Yee Whye Teh\" \/>\n<meta name=\"citation_author\" content=\"Zoubin Ghahramani\" \/>\n<meta name=\"citation_conference_title\" content=\"Machine Learning, Proceedings of the Twenty-Fifth International Conference (ICML 2008), Helsinki, Finland, June 5-9, 2008\" \/>\n<meta name=\"citation_publication_date\" content=\"2008\/01\/01\" \/>\n<meta name=\"citation_firstpage\" content=\"1088\" \/>\n<meta name=\"citation_lastpage\" content=\"1095\" \/>\n<meta name=\"citation_doi\" content=\"10.1145\/1390156.1390293\" \/>\n<meta name=\"citation_pdf_url\" content=\"https:\/\/www.researchgate.net\/profile\/Yunus_Saatchi\/publication\/221345210_Beam_sampling_for_the_infinite_hidden_Markov_model\/links\/00463525dba898f504000000.pdf\" \/>\n<meta name=\"citation_abstract_html_url\" content=\"https:\/\/www.researchgate.net\/publication\/221345210_Beam_sampling_for_the_infinite_hidden_Markov_model\" \/>\n<meta name=\"citation_fulltext_html_url\" content=\"https:\/\/www.researchgate.net\/publication\/221345210_Beam_sampling_for_the_infinite_hidden_Markov_model\" \/>\n<meta name=\"viewport\" content=\"width=device-width,initial-scale=1\" \/>\n<link href=\"\/\/c5.rgstatic.net\/m\/22664197317151888\/styles\/rg.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/21004998181197492\/styles\/rg2.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<!--[if lt IE 9]><link href=\"\/\/c5.rgstatic.net\/m\/238176252723686\/styles\/ie.css\" type=\"text\/css\" rel=\"stylesheet\"\/><![endif]-->\n<link href=\"\/\/c5.rgstatic.net\/m\/217752362214895\/styles\/modules\/publicprofile.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/215868066921738\/styles\/pow\/publicliterature\/FigureList.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/21993347442549\/styles\/pow\/publicliterature\/FollowPublicationPromo.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/282514599719602\/styles\/pow\/application\/PdfJsReader.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/23819663151220\/styles\/pow\/publicliterature\/PublicationInlineReader.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<script src=\"\/\/c5.rgstatic.net\/m\/2321000301012716\/javascript\/vendor\/webfontloader\/webfontloader.js\" type=\"text\/javascript\"><\/script>\n <script>(function(i,s,o,g,r,a,m){i[\"GoogleAnalyticsObject\"]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,\"script\",\"\/\/www.google-analytics.com\/analytics.js\",\"ga\");\n ga(\"create\",\"UA-58591210-1\");ga(\"set\",\"anonymizeIp\",true);ga('set', 'dimension1', 'publication full-text');ga('set', 'dimension2', 'Conference Paper');ga('set', 'dimension3', 'Logged out');ga('set', 'dimension4', 'https');ga(\"send\",\"pageview\");<\/script>\n","webfont":"<noscript><\/noscript><script> WebFontConfig = { custom: { families: ['source_sans_pro_italic', 'source_sans_pro_bold', 'source_sans_pro', 'martel'], urls : ['\/\/c5.rgstatic.net\/m\/231392577336386\/styles\/fonts.css'] } }; WebFont.load(WebFontConfig); <\/script>\n","correlationId":"rgreq-41845642-763e-4f0e-b38c-398f980447be","accountId":null,"module":"publicliterature","action":"publicliterature.PublicPublicationDetails","page":"publicationDetail","product":"publications","backendTime":507,"continent":"Asia","stylesHome":"\/\/c5.rgstatic.net\/m\/","staticHost":"c5.rgstatic.net","useEarlyFlush":false,"longRunningRequestIdentifier":"LongRunningRequest.publicliterature.PublicPublicationDetails","longRunningRequestFp":"e9e5bbe1366c7ee8c8e41d02f793c884ac9be19b","widgetId":"rgw52_56ab199beedce"},"id":"rgw52_56ab199beedce","partials":[],"templateName":"application\/stubs\/StaticHeader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.StaticHeader.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){
            Y.rg.core.pagespeed.Monitoring.monitorPage("\/\/glassmoni.researchgate.net", "publicliterature.PublicPublicationDetails.run.html.loggedOut.get", "59de9668d07aeb77ab4de5f24d382b5d199d2437", "rgreq-41845642-763e-4f0e-b38c-398f980447be", "05a1ec953344a671dd09fea5d893f9ff6334907a");
        
            Y.rg.core.pagespeed.Monitoring.monitorPage("\/\/glassmoni.researchgate.net", "publicationDetail.loggedOut", "ed1993d9e20f6cefa83edacaa24401a18c071aea", "rgreq-41845642-763e-4f0e-b38c-398f980447be", "05a1ec953344a671dd09fea5d893f9ff6334907a");
        })();
(function(){Y.rg.createInitialWidget({"data":{"year":"2016","inlinePromo":null,"isAdmin":false,"contactUrl":"https:\/\/www.researchgate.net\/contact","aboutUsUrl":"https:\/\/www.researchgate.net\/about","widgetId":"rgw53_56ab199beedce"},"id":"rgw53_56ab199beedce","partials":[],"templateName":"application\/stubs\/DefaultFooter.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.DefaultFooter.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"headerLogin":{"data":{"urlAfterLogin":"publication\/221345210_Beam_sampling_for_the_infinite_hidden_Markov_model","requestToken":"JYST0jiUy7U7nzQOjjyPlYl9Wv3p8CBowwbIipjZ41G7nZ1UCLD7ZdJbQzmwWe5+19fbzB8qQSadEXPWyigtaiEwt73qlprd+fSnwcqMIwP5CrZZ9emA4p3nQrjNgMwBhe\/fyhseeUF7kccHzI2aFuC8S2JsMZjxCo\/hSlPTJqFNeQLxbGdxbkv2IbpvAB\/j\/ePV5c0ug4VH1SBfEHVsMvqOlE35fWf5\/fr8r7zeoI1wPveTjPY+LZcVTUBPKgUl6Y6ILnKdNpcQ7mKR29DWDkS5ppoATINibVEMQMslXjg=","loginUrl":"https:\/\/www.researchgate.net\/application.Login.html","signupUrl":"https:\/\/www.researchgate.net\/signup.SignUp.html?ev=su_chnl_index&hdrsu=1&_sg=qm74FON7ueWQx8UoBL5eeD5tVvbvyMiJ9s16C9FifKaCv5VQO71YJiAtvMJQkz6q","encodedUrlAfterLogin":"cHVibGljYXRpb24vMjIxMzQ1MjEwX0JlYW1fc2FtcGxpbmdfZm9yX3RoZV9pbmZpbml0ZV9oaWRkZW5fTWFya292X21vZGVs","signupCallToAction":"Join for free","widgetId":"rgw55_56ab199beedce"},"id":"rgw55_56ab199beedce","partials":{"partial":"application\/stubs\/partials\/headerLoginDefault.html"},"templateName":"application\/stubs\/HeaderLogin.html","templateExtensions":[],"attrs":{"goal":"milestoneHeaderLoginSeen"},"widgetUrl":"https:\/\/www.researchgate.net\/application.HeaderLogin.html","viewClass":"views.application.HeaderLoginView","yuiModules":["rg.views.application.HeaderLoginView"],"stylesheets":[],"_isYUI":true},"cookieConsent":null,"logoSvgSrc":"https:\/\/c5.rgstatic.net\/m\/235107188705592\/images\/template\/brand-header-logo.svg","logoFallbackSrc":"https:\/\/c5.rgstatic.net\/m\/238113351022438\/images\/template\/brand-header-logo.png","widgetId":"rgw54_56ab199beedce"},"id":"rgw54_56ab199beedce","partials":{"schemaSocialProfiles":"application\/stubs\/partials\/schemaSocialProfiles.html"},"templateName":"application\/stubs\/HeaderLoggedOut.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.HeaderLoggedOut.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"logEvent":"su_banner","specialCopy":false,"widgetId":"rgw56_56ab199beedce"},"id":"rgw56_56ab199beedce","partials":[],"templateName":"application\/stubs\/LoggedOutBanner.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.LoggedOutBanner.html","viewClass":"views.application.LoggedOutBannerView","yuiModules":["rg.views.application.LoggedOutBannerView"],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.core.util.ParameterFilter.filter(["ev","cp","ch","ref","dbw","pli","loginT","uid","claimChannel","enrichId","enrichSource","utm_source","utm_medium","utm_campaign","el","ci"]);})();
});}); } else { throw 'YRG was not loaded when attaching widgets'; }</script><script> dataLayer = [{"pageCategory":"publication full-text","publicationType":"Conference Paper","eventCategory":"Publication page"}]; </script> <noscript><iframe src="//www.googletagmanager.com/ns.html?id=GTM-MKVKH7" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-MKVKH7');</script><script>(function(e){function n(n,t,o,a){"use strict";var i=e.document.createElement("link"),r=t||e.document.getElementsByTagName("script")[0],d=e.document.styleSheets;return i.rel="stylesheet",i.href=n,i.media="only x",a&&(i.onload=a),r.parentNode.insertBefore(i,r),i.onloadcssdefined=function(e){for(var t,o=0;d.length>o;o++)d[o].href&&d[o].href.indexOf(n)>-1&&(t=!0);t?e():setTimeout(function(){i.onloadcssdefined(e)})},i.onloadcssdefined(function(){i.media=o||"all"}),i}function t(e,n){e.onload=function(){e.onload=null,n&&n.call(e)},"isApplicationInstalled"in navigator&&"onloadcssdefined"in e&&e.onloadcssdefined(n)}var o=function(a,i){"use strict";if(a&&3===a.length){var r=e.Image,d=!(!document.createElementNS||!document.createElementNS("http://www.w3.org/2000/svg","svg").createSVGRect||!document.implementation.hasFeature("http://www.w3.org/TR/SVG11/feature#Image","1.1")||e.opera&&-1===navigator.userAgent.indexOf("Chrome")||-1!==navigator.userAgent.indexOf("Series40")),c=new r;c.onerror=function(){o.method="png",o.href=a[2],n(a[2])},c.onload=function(){var e=1===c.width&&1===c.height,r=a[e&&d?0:e?1:2];o.method=e&&d?"svg":e?"datapng":"png",o.href=r,t(n(r),i)},c.src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///ywAAAAAAQABAAACAUwAOw==",document.documentElement.className+=" grunticon"}};o.loadCSS=n,o.onloadCSS=t,e.grunticon=o})(this);grunticon(["https://c5.rgstatic.net/c/o1o9o3/styles/icons/_header-ico.svg.css", "https://c5.rgstatic.net/c/o1o9o3/styles/icons/_header-ico.png.css", "https://c5.rgstatic.net/c/o1o9o3/styles/icons/_header-ico.fallback.scss"]);grunticon(["https://c5.rgstatic.net/c/o1o9o3/styles/icons/_admin-ico.svg.css", "https://c5.rgstatic.net/c/o1o9o3/styles/icons/_admin-ico.png.css", "https://c5.rgstatic.net/c/o1o9o3/styles/icons/_admin-ico.fallback.scss"]);grunticon(["https://c5.rgstatic.net/c/o1o9o3/styles/icons/_ico.svg.css", "https://c5.rgstatic.net/c/o1o9o3/styles/icons/_ico.png.css", "https://c5.rgstatic.net/c/o1o9o3/styles/icons/_ico.fallback.scss"]);</script></body>
</html>
