<!DOCTYPE html> <html lang="en" class="" id="rgw35_56aba22853fca"> <head > <meta charset="utf-8"/> <meta http-equiv="content-type" content="text/html; charset=UTF-8"/> <meta name="Rg-Request-Token" id="Rg-Request-Token" content="7CWDssMOKkaTt2nRNzoaUz5VXDPHm/b0g/5DjZpp8jqBma5lC1PjeDIAPRtdDxI9rYEPZ7IS8ZKDaNAcsAW0bnwIzHgsG37SxOET3ghlwz6LG8o1ieilHw5dzu5usCefjna8O8jNkzkdzatS09kOyjun28FZTY50AsXtv3fsrhOQxx7UIYQS3c0W+/HW0Ep8yGjnUh8sf2z4EY+NR+1pyjByebvPoJxo27elx/OfG2sukWhD2zMD2MJFQCbSSRpLsumlf5fGhNMTaevMc99sDc7R8wmbij15D7yP84sNQlg="/> <meta http-equiv="expires" content="0"/> <link rel="apple-touch-icon" sizes="57x57" href="https://www.researchgate.net/apple-touch-icon-57x57.png"> <link rel="apple-touch-icon" sizes="60x60" href="https://www.researchgate.net/apple-touch-icon-60x60.png"> <link rel="apple-touch-icon" sizes="72x72" href="https://www.researchgate.net/apple-touch-icon-72x72.png"> <link rel="apple-touch-icon" sizes="76x76" href="https://www.researchgate.net/apple-touch-icon-76x76.png"> <link rel="apple-touch-icon" sizes="114x114" href="https://www.researchgate.net/apple-touch-icon-114x114.png"> <link rel="apple-touch-icon" sizes="120x120" href="https://www.researchgate.net/apple-touch-icon-120x120.png"> <link rel="apple-touch-icon" sizes="144x144" href="https://www.researchgate.net/apple-touch-icon-144x144.png"> <link rel="apple-touch-icon" sizes="152x152" href="https://www.researchgate.net/apple-touch-icon-152x152.png"> <link rel="apple-touch-icon" sizes="180x180" href="https://www.researchgate.net/apple-touch-icon-180x180.png"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-32x32.png" sizes="32x32"> <link rel="icon" type="image/png" href="https://www.researchgate.net/android-chrome-192x192.png" sizes="192x192"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-96x96.png" sizes="96x96"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-16x16.png" sizes="16x16"> <link rel="shortcut icon" type="image/x-icon" href="https://c5.rgstatic.net/m/2390829798215018/images/favicon.ico"/> <link rel="manifest" href="https://www.researchgate.net/manifest.json"> <meta name="msapplication-TileColor" content="#da532c"> <meta name="msapplication-TileImage" content="https://www.researchgate.net/mstile-144x144.png"> <meta name="theme-color" content="#444444"> <link rel="search" type="application/opensearchdescription+xml" title="ResearchGate search" href="https://www.researchgate.net/application.DownloadOpenSearchPlugin.html"/> <link rel="meta" type="application/rdf+xml" title="ICRA labels" href="https://www.researchgate.net/application.DownloadLabels.html"/> <link rel="http://oexchange.org/spec/0.8/rel/related-target" type="application/xrd+xml" href="https://www.researchgate.net/application.DownloadOExchange.html"/> <base href="https://www.researchgate.net/"/> <script>
    var rgConfig = {
        correlationId: "rgreq-73d2e9fc-b6a8-4ff6-9412-bef193e05946",
        accountId: "",
        module: "publicliterature",
        action: "publicliterature.PublicPublicationDetails",
        page: "publicationDetail",
        product: "publications",
        continent: "Asia",
        stylesHome: "//c5.rgstatic.net/m/",
        staticHost: "c5.rgstatic.net",
        longRunningRequestIdentifier: "LongRunningRequest.publicliterature.PublicPublicationDetails",
        longRunningRequestFp: "e9e5bbe1366c7ee8c8e41d02f793c884ac9be19b"
    };
    window.rootUrl = "https://www.researchgate.net/";
</script> <link rel="canonical" href="https://www.researchgate.net/publication/220514418_Surrogate-assisted_evolutionary_computation_Recent_advances_and_future_challenges" />
<link rel="dns-prefetch" href="//c5.rgstatic.net" />
<link rel="dns-prefetch" href="//i1.rgstatic.net" />
<meta property="twitter:card" content="summary" />
<meta property="twitter:site" content="@ResearchGate" />
<meta property="og:title" content="Surrogate-assisted evolutionary computation: Recent advances and future challenges" />
<meta property="og:description" content="Surrogate-assisted, or meta-model based evolutionary computation uses efficient computational models, often known as surrogates or meta-models, for approximating the fitness function in..." />
<meta property="og:site_name" content="ResearchGate" />
<meta property="og:image" content="https://i1.rgstatic.net/publication/220514418_Surrogate-assisted_evolutionary_computation_Recent_advances_and_future_challenges/links/563e857b08ae45b5d28c5bc8/smallpreview.png" />
<meta property="og:url" content="https://www.researchgate.net/publication/220514418_Surrogate-assisted_evolutionary_computation_Recent_advances_and_future_challenges" />
<meta property="rg:id" content="PB:220514418" />
<meta name="DC.identifier" scheme="DCTERMS.URI" content="http://dx.doi.org/10.1016/j.swevo.2011.05.001" />
<meta name="gs_meta_revision" content="1.1" />
<meta name="citation_title" content="Surrogate-assisted evolutionary computation: Recent advances and future challenges" />
<meta name="citation_author" content="Yaochu Jin" />
<meta name="citation_publication_date" content="2011/06/01" />
<meta name="citation_journal_title" content="Swarm and Evolutionary Computation" />
<meta name="citation_issn" content="2210-6502" />
<meta name="citation_volume" content="1" />
<meta name="citation_issue" content="2" />
<meta name="citation_firstpage" content="61" />
<meta name="citation_lastpage" content="70" />
<meta name="citation_doi" content="10.1016/j.swevo.2011.05.001" />
<meta name="citation_pdf_url" content="https://www.researchgate.net/profile/Yaochu_Jin/publication/220514418_Surrogate-assisted_evolutionary_computation_Recent_advances_and_future_challenges/links/563e857b08ae45b5d28c5bc8.pdf" />
<meta name="citation_abstract_html_url" content="https://www.researchgate.net/publication/220514418_Surrogate-assisted_evolutionary_computation_Recent_advances_and_future_challenges" />
<meta name="citation_fulltext_html_url" content="https://www.researchgate.net/publication/220514418_Surrogate-assisted_evolutionary_computation_Recent_advances_and_future_challenges" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<link href="//c5.rgstatic.net/m/22664197317151888/styles/rg.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/21004998181197492/styles/rg2.css" type="text/css" rel="stylesheet"/>
<!--[if lt IE 9]><link href="//c5.rgstatic.net/m/238176252723686/styles/ie.css" type="text/css" rel="stylesheet"/><![endif]-->
<link href="//c5.rgstatic.net/m/217752362214895/styles/modules/publicprofile.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/215868066921738/styles/pow/publicliterature/FigureList.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/21993347442549/styles/pow/publicliterature/FollowPublicationPromo.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/282514599719602/styles/pow/application/PdfJsReader.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/23819663151220/styles/pow/publicliterature/PublicationInlineReader.css" type="text/css" rel="stylesheet"/>
<script src="//c5.rgstatic.net/m/2321000301012716/javascript/vendor/webfontloader/webfontloader.js" type="text/javascript"></script>
 <script>(function(i,s,o,g,r,a,m){i["GoogleAnalyticsObject"]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,"script","//www.google-analytics.com/analytics.js","ga");
 ga("create","UA-58591210-1");ga("set","anonymizeIp",true);ga('set', 'dimension1', 'publication full-text');ga('set', 'dimension2', 'Article');ga('set', 'dimension3', 'Logged out');ga('set', 'dimension4', 'https');ga("send","pageview");</script>
  <script> WebFontConfig = { custom: { families: ['source_sans_pro_italic', 'source_sans_pro_bold', 'source_sans_pro', 'martel'], urls : ['//c5.rgstatic.net/m/231392577336386/styles/fonts.css'] } }; WebFont.load(WebFontConfig); </script><noscript></noscript>

<title>Surrogate-assisted evolutionary computation: Recent advances and future challenges (PDF Download Available)</title>
<meta name="description" content="Official Full-Text Publication: Surrogate-assisted evolutionary computation: Recent advances and future challenges on ResearchGate, the professional network for scientists."/>
<meta name="keywords" content="scientific network, scientific platform, scientific community, research partner, research collaboration, journal articles, international collaboration, find researcher, lifescience researcher, interdisciplinary research, research collaboration"/>
</head>
<body class="use-svg-icons logged-out">
<div id="page-container">
<script type="text/javascript">var googletag = googletag || {}; googletag.cmd = googletag.cmd || [];
(function() { var gads = document.createElement("script"); gads.async = true; gads.type = "text/javascript"; var useSSL = "https:" == document.location.protocol; gads.src = (useSSL ? "https:" : "http:") + "//www.googletagservices.com/tag/js/gpt.js"; var node =document.getElementsByTagName("script")[0]; node.parentNode.insertBefore(gads, node); })();</script><div id="main" class="logged-out-header-support">
<div id="content" class="">

<noscript>
<div class="c-box-warning full-width-element" style="text-align: center; ">
    <div style="margin: auto; padding:10px;" class="container">
        <b>For full functionality of ResearchGate it is necessary to enable JavaScript.
            Here are the <a href="http://www.enable-javascript.com/" rel="nofollow" target="_blank">
                instructions how to enable JavaScript in your web browser</a>.</b>
    </div>
</div>
</noscript>

<div id="rgw1_56aba22853fca" itemscope itemtype="http://schema.org/ScholarlyArticle"><div class="publication-wrapper publication-wrapper-onecol" id="rgw2_56aba22853fca" itemscope itemtype="http://schema.org/ScholarlyArticle"> <div class="c-col-content"> <div class="c-content"> <div class="clearfix">  <div class="publication-header"> <div id="rgw5_56aba22853fca">  <div class="type-label"> Article   </div> <span class="Z3988" title="ctx_ver=Z39.88-2004&rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&rfr_id=info%3Asid%2Fresearchgate.net%3Aresearchgate&rft_id=info%3Adoi%2F10.1016%2Fj.swevo.2011.05.001&rft.atitle=Surrogate-assisted%20evolutionary%20computation%3A%20Recent%20advances%20and%20future%20challenges&rft.title=Swarm%20and%20Evolutionary%20Computation&rft.jtitle=Swarm%20and%20Evolutionary%20Computation&rft.volume=1&rft.issue=2&rft.date=2011&rft.pages=61-70&rft.issn=2210-6502&rft.au=Yaochu%20Jin&rft.genre=article"></span> <h1 class="pub-title" itemprop="name">Surrogate-assisted evolutionary computation: Recent advances and future challenges</h1> <meta itemprop="headline" content="Surrogate-assisted evolutionary computation: Recent advances and future challenges">  <meta itemprop="image" content="https://i1.rgstatic.net/publication/220514418_Surrogate-assisted_evolutionary_computation_Recent_advances_and_future_challenges/links/563e857b08ae45b5d28c5bc8/smallpreview.png">  <div id="rgw8_56aba22853fca" class="publication-detail-author-list"> <div> <ul class="clearfix js-people-list">  <li id="rgw9_56aba22853fca" itemprop="author" itemscope itemtype="http://schema.org/Person"> <a itemprop="sameAs" href="profile/Yaochu_Jin" class="pub-detail-item account-item"> <div class="indent-left"> <div class="people-img"> <img  src="https://i1.rgstatic.net/ii/profile.image/AS%3A272587116773382%401442001241796_m/Yaochu_Jin.png" title="Yaochu Jin" alt="Yaochu Jin" height="20px" width="20px" style="height: 20px;"/> </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Yaochu Jin</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item  remove-action-indent   " id="rgw10_56aba22853fca" data-account-key="Yaochu_Jin">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="profile/Yaochu_Jin"> <img class="lazyload" data-src="https://i1.rgstatic.net/ii/profile.image/AS%3A272587116773382%401442001241796_l/Yaochu_Jin.png" title="Yaochu Jin" alt="Yaochu Jin" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">     </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="profile/Yaochu_Jin" class="display-name">Yaochu Jin</a>    </h5> <div class="truncate-single-line meta">   <a class="meta ga-top-coauthor-institution" href="institution/University_of_Surrey" title="University of Surrey">University of Surrey</a>     </div>  <a href="javascript:" class="btn btn-promote btn-large people-item-contact-author js-contact-author">Message author</a>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>   </ul> <div class="js-loading"></div>  </div> </div> <div class="pub-details js-pub-details">      <span itemprop="isPartOf" itemscope itemtype="http://schema.org/Periodical"> <a itemprop="sameAs" href="journal/2210-6502_Swarm_and_Evolutionary_Computation"><span itemprop="name">Swarm and Evolutionary Computation</span></a> </span>        <meta itemprop="datePublished" content="2011-06">  06/2011;  1(2):61-70.    DOI:&nbsp;10.1016/j.swevo.2011.05.001           <div class="pub-source"> Source: <a href="http://dblp.uni-trier.de/db/journals/swevo/swevo1.html#Jin11" rel="nofollow">DBLP</a> </div>  </div> <div id="rgw11_56aba22853fca" class="pub-abstract">  <div class="clearfix">   <div style="max-height: 54px;" class="js-expander-container js-expander-collapsed">  <p itemprop="description"> <strong>ABSTRACT</strong> <div>Surrogate-assisted, or meta-model based evolutionary computation uses efficient computational models, often known as surrogates or meta-models, for approximating the fitness function in evolutionary algorithms. Research on surrogate-assisted evolutionary computation began over a decade ago and has received considerably increasing interest in recent years. Very interestingly, surrogate-assisted evolutionary computation has found successful applications not only in solving computationally expensive single- or multi-objective optimization problems, but also in addressing dynamic optimization problems, constrained optimization problems and multi-modal optimization problems. This paper provides a concise overview of the history and recent developments in surrogate-assisted evolutionary computation and suggests a few future trends in this research area.</div> </p>  </div>  </div>   </div>     <div id="rgw12_56aba22853fca" class="figure-carousel"> <div class="carousel-hd"> Figures in this publication </div> <div class="carousel-bd"> <ul class="clearfix">  <li> <a href="/figure/220514418_fig1_Fig-4-Examples-of-surrogates-that-have-a-large-approximation-error-but-are-adequately" class=" fig-frame js-click-link "  rel="tooltip" data-tooltip="Fig. 4. Examples of surrogates that have a large approximation error..." data-key="220514418_fig1_Fig-4-Examples-of-surrogates-that-have-a-large-approximation-error-but-are-adequately"> <img class="fig" src="https://www.researchgate.net/profile/Yaochu_Jin/publication/220514418/figure/fig1/Fig-4-Examples-of-surrogates-that-have-a-large-approximation-error-but-are-adequately_small.png" alt="Fig. 4. Examples of surrogates that have a large approximation error..." title="Fig. 4. Examples of surrogates that have a large approximation error..."/> </a> </li>  <li> <a href="/figure/220514418_fig2_Fig-5-An-illustration-of-learning-iterative-fitness-evolutionary-process-using" class=" fig-frame js-click-link "  rel="tooltip" data-tooltip="Fig. 5. An illustration of learning iterative fitness evolutionary..." data-key="220514418_fig2_Fig-5-An-illustration-of-learning-iterative-fitness-evolutionary-process-using"> <img class="fig" src="https://www.researchgate.net/profile/Yaochu_Jin/publication/220514418/figure/fig2/Fig-5-An-illustration-of-learning-iterative-fitness-evolutionary-process-using_small.png" alt="Fig. 5. An illustration of learning iterative fitness evolutionary..." title="Fig. 5. An illustration of learning iterative fitness evolutionary..."/> </a> </li>  </ul> </div> </div> <div class="action-container"> <div id="rgw13_56aba22853fca" class="follow-publication-promo"> <table> <tr> <td class="follow-publication-promo-text-cell"> <p>Get notified about updates to this publication</p> <a class="btn btn-large btn-promote js-follow-publication ga-follow-publication-new-promo">Follow publication</a> </td> <td> <div class="follow-publication-publication-image"></div> </td> </tr> </table> </div>  <div class="clear"></div> <div class="share-dialog-container" style="display: none;">  </div> </div> </div> <div style="margin-left: -20px; margin-right: -20px;">  </div> </div>  <div class="publication-detail-dfp-container rf"> <div id="rgw26_56aba22853fca">  </div> </div>  </div>  <div class="clearfix"> <div class="pdf-js-container clearfix " id="rgw27_56aba22853fca">  <div class="pdf-js-header js-sticky-header clear">  <a class="blue-link js-download rf btn btn-promote" href="https://www.researchgate.net/profile/Yaochu_Jin/publication/220514418_Surrogate-assisted_evolutionary_computation_Recent_advances_and_future_challenges/links/563e857b08ae45b5d28c5bc8.pdf?inViewer=0&amp;pdfJsDownload=0&amp;origin=publication_detail">Download full-text</a>  <h3>Full-text</h3> <span class="publication-info">  <span class="js-doi-container" style="display: none;"> DOI: <span class="js-doi"></span> &middot; </span> Available from: <a class="js-name" href="profile/Yaochu_Jin">Yaochu Jin</a>, <span class="js-publication-date"> Nov 07, 2015 </span>   </span>  </div>  <div class="social-share-container"><div id="rgw29_56aba22853fca" class="social-share js-social-share"> <div class="social-share-heading">Share</div>  <a id="rgw30_56aba22853fca" href="javascript:" title="Share on Facebook" class="link-nostyle js-share-item share-icon "  data-url="http://www.facebook.com/share.php?u={{url}}{{#title}}&amp;t={{title}}{{/title}}" data-width="600" data-height="350" data-name="Facebook"> <span class="share-icon ico-share-facebook-round reset-background ga-share-blog-facebook"></span> </a>  <a id="rgw31_56aba22853fca" href="javascript:" title="Share on Twitter" class="link-nostyle js-share-item share-icon "  data-url="http://twitter.com/intent/tweet?text={{#title}}{{title}}: {{/title}}{{url}}&amp;via=researchgate" data-width="600" data-height="350" data-name="Twitter"> <span class="share-icon ico-share-twitter-round reset-background ga-share-blog-twitter"></span> </a>  <a id="rgw32_56aba22853fca" href="javascript:" title="Share on Google+" class="link-nostyle js-share-item share-icon "  data-url="https://plus.google.com/share?url={{url}}" data-width="600" data-height="600" data-name="Google+"> <span class="share-icon ico-share-gplus-round reset-background ga-share-blog-gplus"></span> </a>  <a id="rgw33_56aba22853fca" href="javascript:" title="Share on LinkedIn" class="link-nostyle js-share-item share-icon "  data-url="http://www.linkedin.com/shareArticle?mini=true&amp;url={{url}}{{#title}}&amp;title={{title}}{{/title}}&amp;source=ResearchGate" data-width="520" data-height="570" data-name="LinkedIn"> <span class="share-icon ico-share-linkedin-round reset-background ga-share-blog-linkedin"></span> </a>  <a id="rgw34_56aba22853fca" href="javascript:" title="Share on Reddit" class="link-nostyle js-share-item share-icon "  data-url="https://www.reddit.com/submit?url={{url}}{{#title}}&amp;title={{title}}{{/title}}" data-width="600" data-height="600" data-name="Reddit"> <span class="share-icon ico-share-reddit reset-background ga-share-blog-reddit"></span> </a>  </div></div>    <iframe id="rgw28_56aba22853fca" src="https://www.researchgate.net/c/o1q2er/javascript/lib/pdfjs/web/viewer.html?file=https%3A%2F%2Fwww.researchgate.net%2Fprofile%2FYaochu_Jin%2Fpublication%2F220514418_Surrogate-assisted_evolutionary_computation_Recent_advances_and_future_challenges%2Flinks%2F563e857b08ae45b5d28c5bc8.pdf%3FinViewer%3D1%26pdfJsDownload%3D1%26origin%3Dpublication_detail" allowfullscreen frameborder="0" style="width: 100%; height: 100%; box-sizing: border-box;"></iframe>    </div> <noscript> <div id="rgw25_56aba22853fca"  itemprop="articleBody">  <p>Page 1</p> <p>Swarm and Evolutionary Computation 1 (2011) 61–70<br />Contents lists available at ScienceDirect<br />Swarm and Evolutionary Computation<br />journal homepage: www.elsevier.com/locate/swevo<br />Survey paper<br />Surrogate-assisted evolutionary computation: Recent advances and<br />future challenges<br />Yaochu Jin<br />Department of Computing, University of Surrey, Guildford, Surrey, GU2 7XH, UK<br />a r t i c l ei n f o<br />Article history:<br />Received 6 February 2011<br />Received in revised form<br />20 April 2011<br />Accepted 14 May 2011<br />Available online 6 June 2011<br />Keywords:<br />Evolutionary computation<br />Surrogates<br />Meta-models<br />Machine learning<br />Expensive optimization problems<br />Model management<br />a b s t r a c t<br />Surrogate-assisted, or meta-model based evolutionary computation uses efficient computational models,<br />often known as surrogates or meta-models, for approximating the fitness function in evolutionary<br />algorithms. Research on surrogate-assisted evolutionary computation began over a decade ago and<br />has received considerably increasing interest in recent years. Very interestingly, surrogate-assisted<br />evolutionary computation has found successful applications not only in solving computationally<br />expensive single- or multi-objective optimization problems, but also in addressing dynamic optimization<br />problems, constrained optimization problems and multi-modal optimization problems. This paper<br />provides a concise overview of the history and recent developments in surrogate-assisted evolutionary<br />computation and suggests a few future trends in this research area.<br />© 2011 Elsevier B.V. All rights reserved.<br />1. Introduction<br />In most evolutionary algorithms, it is often implicitly assumed<br />that there exists a means for evaluating the fitness value of<br />all individuals in a population. In general, the fitness value<br />of an individual can be computed using an explicit fitness<br />function, a computational simulation, or an experiment. In<br />practice, however, fitness evaluations may become non-trivial.<br />Such situations typically occur when evolutionary algorithms are<br />employed to solve expensive optimization problems, where either<br />the computational simulation for each fitness evaluation is highly<br />time-consuming, or the experiments for fitness estimation are<br />prohibitivelycostly,orananalyticalfunctionforfitnessevaluations<br />simply does not exist.<br />Surrogate-assisted evolutionary computation was mainly<br />motivated from reducing computational time in evolutionary op-<br />timization of expensive problems, such as aerodynamic design op-<br />timization [1] or drug design [2], where complex computational<br />simulations are involved.<br />In principle, surrogates should be used together with the<br />real fitness function, as long as such a fitness function exists to<br />prevent the evolutionary algorithm from being misled by a false<br />minimum introduced by the surrogates [3]. A strategy for properly<br />using the surrogates is often known as model management or<br />evolution control. In surrogate-assisted evolutionary optimization<br />E-mail address: yaochu.jin@surrey.ac.uk.<br />of expensive problems, in particular when the problems are<br />of high-dimension, the development of a model management<br />strategy remains a challenging research topic.<br />The remainder of the paper is organized as follows. Section 2<br />takes a brief look back at the history of surrogate-assisted evolu-<br />tionary computation starting from the late 1990s. Representative<br />model management strategies are discussed in Section 3, which<br />distinguish themselves into managing a single surrogate, homo-<br />geneous multiple surrogates, and heterogeneous multiple surro-<br />gates. Application of surrogates to addressing problems other than<br />expensive optimization in evolutionary computation is presented<br />inSection4.Applicationexamplesofmeta-modelbasedevolution-<br />ary optimization are briefly accounted in Section 5. A few promis-<br />ing yet challenging research topics are suggested in Section 4. The<br />paper concludes with a brief summary in Section 7.<br />2. A brief look back<br />Research on evolutionary optimization using approximate<br />fitness evaluations was first reported in the mid-1980s [4],<br />and sporadic yet increasing research results on evolutionary<br />optimization using computational models for fitness estimation<br />appeared after the mid-1990s [5–9]. The first event devoted to<br />research on using surrogates in evolutionary optimization was<br />a workshop held in 2002 within the Genetic and Evolutionary<br />Computation Conference (GECCO) [10]. Since then, a series of<br />special sessions and workshops have been organized on the major<br />conferences including GECCO and IEEE Congress on Evolutionary<br />2210-6502/$ – see front matter © 2011 Elsevier B.V. All rights reserved.<br />doi:10.1016/j.swevo.2011.05.001</p>  <p>Page 2</p> <p>62<br />Y. Jin / Swarm and Evolutionary Computation 1 (2011) 61–70<br />Computation, and journal special issues have also been edited.<br />An overview of the research on surrogated-assisted evolutionary<br />optimization reported in various fields was first presented in<br />a conference paper [11], and then a journal paper in a special<br />issue [12]. A first tutorial on fitness approximation on evolutionary<br />optimization was given at the GECCO in 2005. Most recently, an<br />edited book on the use of surrogates in evolutionary computation<br />was also published [13].<br />In the review paper [12], the importance of managing<br />surrogates was emphasized for the first time to prevent the<br />evolutionary algorithms from being misled to a false optimum<br />that can be introduced in a surrogate. In that review, methods for<br />managing surrogates in evolutionary computation were divided<br />into three categories, namely, individual-based, generation-based<br />and population-based strategies. A variety of computational<br />models, including polynomials (also known as response surface<br />methodologies in the field of traditional design optimization),<br />Gaussian processes (also known as Kriging in traditional design<br />optimization), neural networks, together with data sampling<br />techniques such as design of experiments, active learning and<br />boosting were also presented. Practically, fitness inheritance from<br />parents or fitness imitation from siblings [14–16] can be seen as<br />a sort of simplified yet effective interpolation technique. General<br />issues such as the global and local approximation, approximation<br />of nonlinear constraints and the use of multiple surrogates having<br />various fidelities were discussed. Theoretical analysis of the<br />convergence properties was also raised.<br />Since the review paper [12], very encouraging research<br />progresses have been made in many of the areas, whereas<br />some issues remain unsolved, in particular with respect to a<br />rigorous theoretical support for the benefit for using surrogates<br />in evolutionary computation. Note that this paper focuses on<br />surrogates in evolutionary computation. Readers interested in<br />recent developments of surrogate-assisted design and analysis<br />methods are referred to [17,18].<br />The next section provides a brief overview of recent advances<br />in the research on surrogate-assisted evolutionary optimization,<br />emphasizing on the progresses made after the review paper [12].<br />Research on using surrogates beyond solving expensive problems<br />is discussed in Section 4. A few challenging topics for future<br />research are suggested in Section 6. A summary of the paper is<br />given in Section 7.<br />3. Strategies for managing surrogates<br />In most real-world optimization problems, no analytical<br />fitness function exists for accurately evaluating the fitness of<br />a candidate solution. Instead, there are only more accurate<br />and less accurate fitness estimation methods, which often<br />trade off accuracy with computational costs, as illustrated in<br />Fig. 1. For example, in evolutionary optimization of aerodynamic<br />structures [1], wind tunnel experiments may provide the most<br />accurate estimation of the quality of candidate designs. The cost<br />of such experiments is often prohibitively high. In addition, three-<br />dimensional (3-D) computational fluid dynamic (CFD) simulations<br />using Navier–Stokes equations may provide very accurate fitness<br />evaluations. Unfortunately, such CFD simulations are highly time-<br />consuming,whichcantakehoursorevendaysforonesinglefitness<br />evaluation. Computationally more efficient simulations can be<br />achieved by 2-D full simulations or even incomplete simulations.<br />By incomplete simulation, we mean that a simulation process is<br />stopped before it converges. The computationally most efficient<br />way for estimating fitness is the use of machine learning models,<br />i.e., surrogates. Note, however that this graphic only shows a<br />simplified version of actual levels of accuracy.<br />Fig. 1.<br />and computational cost. Usually, high-fidelity fitness evaluations are more time-<br />consuming. By contrast, low-fidelity fitness evaluations are often less time-<br />consuming.<br />An illustration of a trade-off between fidelity (approximation accuracy)<br />In the research of surrogate-assisted evolutionary optimiza-<br />tion, most algorithms have been developed based on benchmark<br />problems, where it is assumed that fully accurate fitness evalu-<br />ations can be provided. Such fitness functions are often termed<br />‘‘real fitness function’’ or ‘‘original fitness function’’. In the follow-<br />ing, we use surrogates for denoting computational models con-<br />structed with data, whereas other approximate fitness techniques<br />such as full or incomplete 2-D CFD simulations are called prob-<br />lem approximations as termed in [12]. In addition, we do not dis-<br />tinguish between surrogate-assisted single objective optimization<br />and surrogate-assisted multi-objective optimization if the method<br />for model management does not differ.<br />In the early work on surrogate-assisted evolutionary opti-<br />mization, the evolutionary search is based solely on a surrogate,<br />assuming that the surrogate can provide sufficiently accurate fit-<br />ness evaluations. However, such assumptions can give rise to seri-<br />ous problems if the surrogate introduces optima that do not exist<br />in the original optimization problem. This issue was first explic-<br />itly raised in [3] to stress the importance of model management in<br />surrogate-assisted evolutionary optimization, mainly by using the<br />surrogate together with the real fitness function.<br />Surrogates can be applied to almost all operations of evolution-<br />ary algorithms, such as population initialization, cross-over, mu-<br />tation, local search and fitness evaluations, as illustrated in Fig. 2.<br />For instance, a surrogate can be used for filtering out poor solu-<br />tions in population initialization, crossover [19] or mutation [20].<br />The use of surrogates in initialization, mutation or crossover [21]<br />can reduce the randomness in the genetic operators, thus termed<br />informed operators. Most recently, a similar approach is adopted<br />for multi-objective optimization [22], where a single, aggregated<br />meta-model is built to pre-screen candidate solutions before fit-<br />ness evaluation. The requirement on the quality of surrogates is<br />minimum, as an estimated fitness that is better than a random<br />guess is adequate.<br />Techniques for managing surrogates for fitness evaluations<br />can generally be divided into individual-based, generation-based<br />and population-based [12]. By generation-based, we mean that<br />surrogates are used for fitness evaluations in some of the<br />generations, while in the rest of the generations, the real fitness<br />function is used [8,23,24,7]. By contrast, in individual-based model<br />management techniques, the real-fitness function is used for<br />fitness evaluations for some of the individuals in a generation<br />[25,3,23]. In population-based approaches, more than one sub-<br />population co-evolves, each using its own surrogate for fitness</p>  <p>Page 3</p> <p>Y. Jin / Swarm and Evolutionary Computation 1 (2011) 61–70<br />63<br />Fig. 2. A diagram for an evolutionary algorithm for optimization of a turbine blade.<br />A star denotes an evolutionary operation where a surrogate can be helpful.<br />evaluations. Migration of individuals from one sub-population to<br />another is allowed.<br />A strategy closely related to the above methods is the<br />pre-selection strategy [26]. Pre-selection does not exactly fall<br />in individual-based strategies. Assume the population size is<br />λ. In pre-selection, an initial offspring population contains λ′<br />individuals, where λ′&gt; λ are produced in each generation. Then,<br />allλ′offspringindividualsareevaluatedusingthesurrogate.Based<br />on the fitness value obtained using the surrogate, only λ offspring<br />are kept and re-evaluated using the original fitness function.<br />A main difference between individual-based strategies and pre-<br />selection here is that in pre-selection, selection is always based<br />on the real fitness value whereas in individual-based methods,<br />selectionmaybeconductedpartlybasedonfitnessvaluesfromthe<br />surrogate.<br />The main steps of one specific individual-based model manage-<br />ment method, termed best strategy, and the pre-selection method<br />for a (µ, λ) evolution strategy, (µ, λ)-ES, are illustrated in Fig. 3 (a)<br />and (b), respectively. In a (µ, λ)-ES using best strategy, all λ off-<br />spring are first evaluated using the surrogate. Then, λ⋆≤ λ best<br />individuals according to the surrogate are re-evaluated using the<br />expensive real fitness function. As a result, it can happen that the<br />fitness value of some of the selected µ parents is based on the sur-<br />rogate. Contrary to that, in a (µ, λ)-ES using pre-selection, λ⋆≥ λ<br />offspring are generated and then evaluated using the surrogate.<br />Then, λ best individuals are re-evaluated using the expensive real<br />fitness function. Consequently, all the selected µ parents for the<br />next generation are evaluated by the real fitness function.<br />A large category of surrogate-assisted evolutionary algorithms<br />use surrogates in local search only for both single [27,28] and<br />multi-objective optimization [29]. In this case, sophisticated<br />model management methods developed in traditional design<br />optimization [30], such as the trust-region method [31] can be<br />directly employed.<br />Recently, surrogates have also been used in stochastic search<br />methods other than evolutionary algorithms, such as surrogate-<br />assisted simulated annealing [32] or surrogate-assisted artificial<br />immune systems [33].<br />In the following, we discuss a few interesting ideas for model<br />management, which are divided into two major categories — use<br />of a single surrogate and multiple surrogates.<br />3.1. Managing a single surrogate<br />The essential question to answer in surrogate-assisted evolu-<br />tionary computation is which individuals should be chosen to be<br />evaluated or re-evaluated using the real fitness function. As we<br />a<br />b<br />Fig. 3. Two individual-based model management strategies. (a) Best strategy, and<br />(b) Pre-selection strategy.<br />assume fitness evaluations using the real fitness function is time-<br />consuming, the next question is how to adapt the number of in-<br />dividuals to be evaluated with the real fitness function so that the<br />time for fitness evaluations can be reduced as much as possible,<br />while the evolutionary algorithm can still find the global optimum.<br />In the following, we discuss a few issues related to the answer to<br />the above questions.<br />3.1.1. Criteria for choosing individuals for re-evaluation<br />The most straightforward idea is to evaluate those individuals<br />that potentially have a good fitness value and the higher the<br />approximation accuracy, the more often the surrogate can be<br />used [3,23]. A slightly different idea is that representative<br />individuals can be chosen for re-evaluation by clustering the<br />population into a number of crisp or fuzzy clusters. The individual<br />closest to each cluster center [34,15,35] or the best individual in<br />each cluster [36,37] can be chosen for re-evaluation.<br />Ithasalsobeensuggestedthatindividualshavingalargedegree<br />of uncertainty in approximation can be good candidates for re-<br />evaluation [25,26]. This idea can be justified by two arguments.<br />First, a large degree of uncertainty in approximation of the<br />individuals indicates that the fitness landscape around these<br />solutions has not been well explored and therefore may provide<br />a good chance of finding a better solution. Second, re-evaluation<br />of these solutions may be the most effective in improving the</p>  <p>Page 4</p> <p>64<br />Y. Jin / Swarm and Evolutionary Computation 1 (2011) 61–70<br />Fig. 4.<br />adequately good for evolutionary search. Solid curves denote the original function<br />and dashed curves are their approximation.<br />Examples of surrogates that have a large approximation error but are<br />approximation accuracy of the surrogate, similar to the idea of<br />active learning [38].<br />Theestimationoftheapproximationerrorcanbeachievedwith<br />different methods. In [25], the degree of uncertainty is roughly set<br />to be inversely proportional to the average distance to the closest<br />data samples used for constructing the surrogate. Alternatively, an<br />ensemble can be used for estimating the variance of the individual<br />estimates given by an ensemble of surrogates. The most often<br />used surrogate model for estimating model uncertainties is the<br />Gaussian processes [39], also known as the Kriging model [40].<br />Unlike deterministic models, Gaussian processes provide an<br />estimate of the fitness (mean) together with an estimate of the<br />uncertainty (variance), which is a statistically sound boundary<br />of the uncertainty in fitness estimation. Due to this property,<br />Gaussianprocesseshaveincreasinglybeenemployedassurrogates<br />in evolutionary single- and multi-objective optimization [41–44].<br />Note however, the computational cost for constructing Gaussian<br />processes itself can be very high when the number of samples used<br />is large and online learning of the Gaussian processes is non-trivial<br />when new samples are available.<br />3.1.2. Metrics for evaluating surrogates and adaptation<br />Not much attention has been paid to adapting the frequency<br />of using the surrogates. In [45], the model quality is estimated by<br />calculating the average approximation error after re-evaluation,<br />which is used to adapt the frequency of using the surrogate in a<br />generation-based model management method. Based on empirical<br />observations that large approximation errors must not mislead<br />the evolutionary search, see e.g., Fig. 4, a few metrics other than<br />approximation error have been proposed in [46,45] in evaluating<br />the quality of surrogates. In the following, we present a few<br />performance measures for surrogates in great detail.<br />The most common measure for model quality or model fidelity<br />is the mean squared error between the individual’s real fitness<br />value and the predicted fitness by the meta-model. However, from<br />the evolutionary perspective, selecting the right individuals for<br />the next generation is the main concern. For instance in Fig. 4,<br />the quality of the surrogate is poor in terms of approximation<br />accuracy. However, an evolutionary algorithm searching on the<br />surrogate only will nevertheless find the right optimum. Consider<br />(µ,λ)-selection with λ ≥ 2µ, which is of particular relevance<br />in evolutionary optimization of complex real-world problems, the<br />number of individuals that have been selected correctly using the<br />surrogate can be obtained by:<br />ρ(sel.)=ξ − ⟨ξ⟩<br />µ − ⟨ξ⟩,<br />(1)<br />where ξ (0 ≤ ξ<br />individuals, i.e., the number of individuals that would have also<br />been selected if the real fitness function was used for fitness<br />≤ µ) is the number of correctly selected<br />evaluations. The expectation<br />µ<br />⟨ξ⟩ =<br />µ<br />−<br />m=0<br />m<br />m<br /><br />λ−µ<br />µ−m<br />λ<br />µ<br /><br /><br />=µ2<br />λ<br />(2)<br />of ξ in case random selection is used as a normalization in (1). It<br />can be seen that if all µ parent individuals are selected correctly,<br />the measure reaches its maximum of ρ(sel.)= 1, and that negative<br />values indicate that the selection based on the surrogate is worse<br />than a random selection.<br />The measure ρ(sel.)only evaluates the absolute number of<br />correctly selected individuals. If ρ(sel.)&lt; 1, the measure does<br />not indicate whether the (µ + 1)-th or the worst offspring<br />individual has been selected, which may have significant influence<br />on the evolutionary process. Therefore, the measure ρ(sel.)can be<br />extended to include the rank of the selected individuals, calculated<br />based on the real fitness function. A surrogate is assumed to be<br />good, if the rank of the selected individuals based on the model<br />is above-average according to the rank based on the real fitness<br />function.<br />Thedefinitionoftheextendedmeasureρ(∼sel.)isasfollows:The<br />surrogate achieves a grade of λ − m, if the m-th best individual<br />based on the real fitness function is selected. Thus, the quality of<br />the surrogate can be indicated by summing up the grades of the<br />selected individuals, which is denoted by π. It is obvious that π<br />reaches its maximum, if all µ individuals are selected correctly:<br />−<br />= µ<br />2<br />π(max.)=<br />µ<br />m=1<br />(λ − m)<br /><br />λ −µ + 1<br /><br />.<br />(3)<br />Similar to (1) the measure ρ(∼sel.)is defined by transforming π<br />linearly, using the maximum π(max.)as well as the expectation<br />⟨π⟩ =µλ<br />π − ⟨π⟩<br />π(max.)− ⟨π⟩.<br />Besides these two problem-dependent measures for evaluating<br />the quality of the surrogate, two established measures – the<br />rank correlation and the (continuous) correlation – partially fit<br />the requirements formulated above. The rank correlation can be<br />expressed by<br />2for the case of a purely random selection:<br />ρ(∼sel.)=<br />(4)<br />ρ(rank)= 1 −<br />is a measure for the monotonic relation between the ranks of two<br />variables.Inourcase,dlisthedifferencebetweentheranksofthel-<br />thoffspringindividualbasedontheoriginalfitnessfunctionandon<br />the approximate model. The range ofρ(rank)is the interval[−1;1].<br />The higher the value ofρ(rank), the stronger the monotonic relation<br />with a positive slope between the ranks of the two variables.<br />In contrast to ρ(∼sel.), the rank correlation does not only take<br />the ranking of the selected individuals, but also the ranks of all<br />individuals into account.<br />A slightly different quality measure can be defined by<br />calculatingthe(continuous)correlationbetweenthesurrogateand<br />the original fitness function.<br />Using the selection-based criterion [45] for evaluating surro-<br />gates, an adaptation scheme has been suggested for adapting the<br />6<br />λ ∑<br />l=0<br />d2<br />l<br />λ(λ2− 1),<br />(5)</p>  <p>Page 5</p> <p>Y. Jin / Swarm and Evolutionary Computation 1 (2011) 61–70<br />65<br />Fig. 5.<br />recurrent neural networks for predicting converged fitness value.<br />An illustration of learning iterative fitness evolutionary process using<br />numberofindividualstobeevaluatedusingthesurrogate(λ′)[47].<br />It has been shown that λ′increases as the evolution proceeds, in-<br />dicating that the quality of the surrogates improves. Interestingly,<br />when noise is introduced into the fitness data samples, λ′first de-<br />creases and then increases again. The various selection based cri-<br />teria suggested in [45] have been benchmarked for adapting the<br />number of individuals to be re-evaluated by the real fitness func-<br />tion [37]. The results, however, failed to show a clear advantage of<br />any particular criterion.<br />3.1.3. Improving approximation accuracy<br />Although approximation quality is not the only criterion for<br />surrogates for fitness prediction in evolutionary optimization,<br />improving its approximation quality is desirable. Much work has<br />been reported along this line. For example, in [3,23], regularization<br />of the neural network model has been suggested to alleviate<br />overfitting. Structure and parameter optimization of the surrogate<br />can co-evolve with the original optimization problem [46,48].<br />One of the main difficulties in improving the approximation<br />accuracycanbeattributedtothehigh-dimensionalityinthedesign<br />space. To overcome this difficulty, the surrogate can be built up<br />in a new space of a lower dimension using dimension reduction<br />techniques [49,50].<br />It is noticed that in many expensive optimization problems,<br />the fitness evaluation often consists of an iterative computation<br />process, such as the numerical solution of differential equations<br />in computational fluid dynamics simulations. In such cases,<br />many intermediate data will be produced before the simulation<br />converges. Such intermediate data can also be used for training<br />a surrogate in the first iterations and then the surrogate can be<br />used for predicting the converged fitness [51]. An example of such<br />a process is illustrated in Fig. 5.<br />3.2. Managing multiple surrogates<br />Methods for multiple surrogates in evolutionary optimization<br />distinguish themselves in type and fidelity of the surrogates. For<br />example, a neural network ensemble has been used in [34], where<br />all ensemble members are of the same type of feed-forward neural<br />networks. Alternatively, multiple surrogates of different types,<br />suchaspolynomials,supportvectormachinesandneuralnetworks<br />can be used [52].<br />A step further is to use surrogates of different fidelities.<br />Surrogatesofdifferentfidelitiescanbeobtainedbyusingmodelsof<br />different complexities or different data sets. For instance, different<br />types of training samples used for constructing the surrogates<br />can be generated from different problem approximations, such as<br />wind-tunnel experiments, 3-D or 2-D CFD simulations. Another<br />wayofgeneratingsurrogatesofheterogeneousfidelityistocontrol<br />thecomplexityofthesurrogatesexplicitly,e.g.,byusingadifferent<br />numberoftrainingsamplesorbycontrollingthemodelcomplexity<br />with regularized learning [3] or a Pareto-based multi-objective<br />learning method [53].<br />In the following, we discuss the use of multiple surrogates in<br />evolutionary optimization by dividing the methods into homoge-<br />neous and heterogeneous multiple surrogates. By homogeneous<br />multiple surrogates, the fidelity of the surrogates are not explic-<br />itly controlled, even if different types of surrogates are used. On<br />the contrary, heterogeneous surrogates vary in their fidelity due to<br />an explicit control in model complexity or training data.<br />3.2.1. Homogeneous multiple surrogates<br />Use of ensembles for fitness approximation was suggested<br />in [34], where it was shown that neural network ensembles<br />can improve the performance of surrogate-assisted evolutionary<br />optimization in two aspects. First, ensembles can improve the<br />quality in fitness prediction. Second, the variance of the predicted<br />fitness of the ensemble members can help identify large prediction<br />errors so that false optima can be avoided.<br />The benefit of using multiple surrogates has also been shown<br />empirically in many papers [54,55,52]. In this category of research,<br />no explicit control of fidelity of the multiple surrogates is<br />employed. For example in [56,57] multiple surrogates such as<br />Kriging, polynomials, radial-basis-function networks (RBFN), and<br />weightedaverageensembleareusedtodemonstratetheimproved<br />robustness of optimization. Polynomial and RBFN surrogates are<br />employed for multiobjective optimization and it was shown that<br />each of the models performs better in different regions of the<br />Pareto front.<br />Multiple surrogates have been used in evolutionary multi-<br />objective optimization [58]. In that work, a co-evolutionary<br />genetic algorithm for multiple-objective optimization based on<br />surrogates was introduced. After some fixed search intervals, the<br />surrogates that approximate different objectives are exchanged<br />and shared among multiple sub-populations of genetic algorithms.<br />Spatiallydistributedmultiplesurrogateshavebeenusedforfitness<br />approximation in multi-objective optimization [59].<br />3.2.2. Heterogeneous multiple surrogates<br />As illustrated in Fig. 1, in many real-world optimization<br />problems, various problem approximation techniques can be<br />employed. For example, in aerodynamic optimization 3-D or 2-D<br />numerical simulations can be used for estimating the quality of the<br />designs in addition to wind tunnel experiments. In more extreme<br />situations, incomplete simulations can also be used, where a<br />numerical simulation is stopped earlier to reduce computation<br />time. Data from all these different processes can also be applied<br />for building up surrogates.<br />The motivation of explicitly controlling the fidelity of the<br />surrogates can also be justified by taking the computational costs<br />of constructing surrogates into account. To reduce the cost for<br />building up surrogates, it makes good sense to use surrogates of a<br />lower fidelity that can be obtained with less cost in the early stage<br />of evolutionary optimization. Another more tricky motivation is to<br />take advantage of approximation errors introduced by surrogates,<br />hoping to smoothen a rugged fitness landscape, or to increase the<br />diversity of the population, or simply to use data from incomplete<br />simulations.<br />Early work that uses heterogeneous multiple surrogates was<br />reportedin[60,61],whereapopulation-basedmodelmanagement<br />strategy is used. In both papers, three sub-populations are used,</p>  <p>Page 6</p> <p>66<br />Y. Jin / Swarm and Evolutionary Computation 1 (2011) 61–70<br />each using a surrogate for fitness evaluations. In [60], individuals<br />from a sub-population that use a surrogate of lower fidelity are<br />allowed to migrate to the sub-population that uses a surrogate of<br />higher fidelity. The method presented in [61] is a minor variant<br />of [60], where migration is allowed between all sub-populations.<br />Oneapproachtoreducingthecomputationalcostforconstruct-<br />ing surrogates is to use coarse surrogates (of lower fidelity) in<br />the early stage of the optimization and increase the quality of the<br />surrogate gradually as the search proceeds [6]. This idea of using<br />coarse-to-fine surrogates has been introduced into a surrogate-<br />assisted evolutionary search in [42,62], where surrogates are used<br />for evolutionary multi-objective optimization.<br />A more subtle way to control the fidelity of surrogates is to<br />use surrogates of a sufficiently good fidelity based on a correlation<br />based measure [63]. The fidelity control strategy was applied<br />to a memetic algorithm in which the local search is based on<br />surrogates of a changing fidelity. The proposed method was<br />evaluated empirically on an aerodynamic airfoil design problem<br />and demonstrated that the use of a dynamic fidelity is able to<br />improve the search speed.<br />The idea of taking advantage of approximation errors intro-<br />ducedbysurrogateswasfurtherexploitedin[64].Inthatwork,two<br />types of surrogates are used in the local search of an evolutionary<br />multi-objective optimization: One for getting a reliable local<br />prediction and the other for a higher degree of diversity. Empir-<br />ical results show that an evolutionary search based on hetero-<br />geneous multiple models can considerably improve the search<br />performance, compared to surrogate-assisted evolutionary algo-<br />rithms that use a single surrogate or homogeneous multiple<br />surrogates. Interestingly enough, the proposed algorithm also out-<br />performs its counterpart that uses an artificial perfect surrogate.<br />Detailed analysis of the search processes confirmed the hypothe-<br />sis that controlled approximation errors introduced by surrogates<br />canspeedupthesearchprocessinbothsingle-andmulti-objective<br />optimization.<br />3.3. Which model management strategy?<br />As we discussed above, surrogates can be used in population<br />initialization, crossover, mutation and preselection to pre-screen<br />candidatesolutions.Theadvantageoftheserelativelyconservative<br />approaches to using surrogates is that they are less likely to<br />mislead the search process. One concern might be that they may<br />cause premature convergence. It is also less risky if a surrogate is<br />used in a local search of memetic algorithms. The common feature<br />of these approaches is that all individuals have been re-evaluated<br />using the original fitness function before selection.<br />In addition, among the model management strategies, the<br />individual-based model management may be more suited for<br />steady state evolution, or generational evolution implemented on<br />a single machine. By contrast, population-based and generation-<br />based model management is better for parallel implementation on<br />heterogeneous machines having different speeds. An optimization<br />strategy may be desirable when multi-level surrogates having<br />differentcomputationalcomplexitiesareusedonmachineshaving<br />different computational powers.<br />4. Beyond evolutionary optimization of expensive problems<br />In addition to reducing the computation time in evolutionary<br />optimization of expensive problems, surrogates can be useful in<br />addressing other problems in evolutionary computation, such as<br />the use of surrogates for reducing fitness evaluations in search of<br />robust optimal solutions [65]. In addition, surrogates have been<br />found helpful in improving the efficiency of evolutionary algo-<br />rithms for solving optimization with noisy fitness evaluations [66]<br />or for solving multi-modal optimization with a very rugged fit-<br />ness landscape [6,67], where the purpose of using a surrogate is<br />to smoothen the fitness landscape.<br />4.1. Surrogates in interactive evolutionary computation<br />In interactive evolutionary computation, the fitness value of<br />each individual is evaluated by human user subjectively [68].<br />Human fitness evaluations are necessary where no fitness function<br />is available. For instance, when evolutionary algorithms are used<br />for aesthetic product design or art design. One main challenge of<br />interactiveevolutionarycomputationistheissueofhumanfatigue.<br />To address this problem to a certain degree, surrogates can be used<br />to replace in part human evaluations. The main idea is to use a<br />machine learning model to predict the fitness value the human<br />may assign to a design based on history data [69–71].<br />4.2. Surrogated-assisted evolution for solving dynamic optimization<br />Evolutionary optimization of dynamic optimization problems<br />has become a popular research topic recently [12]. The primary<br />goal is to develop an evolutionary search strategy that can follow a<br />moving optimum or a moving Pareto front. To this end, a certain<br />degree of diversity in the population should be maintained or<br />a memory mechanism must be embedded in the evolutionary<br />algorithm.Memorymechanismsincludesub-populations,archives<br />of optimal solutions found so far, or multiploidy in genetic<br />representation.<br />In addition to memory and diversity based strategies, antici-<br />pation and prediction of the change in the fitness function can<br />be helpful in solving dynamic problems more efficiently. In such<br />strategies, a surrogate can be helpful in learning the changing fit-<br />ness function [72–74].<br />4.3. Surrogates for robust optimization<br />In evolutionary optimization of real-world problems, one is<br />concerned not only with the performance of the obtained optimal<br />solution, but also the sensitivity of the performance to small<br />changesinthedesignvariablesorintheenvironment.Ifanoptimal<br />solution is insensitive to such changes, the solution is known as<br />robust optimization.<br />To obtain robust optimal solutions using evolutionary algo-<br />rithms, either implicit averaging or explicit averaging can be<br />used [12], wherein an assumption on the probability distribution<br />of the noise is often made. By contrast, one can predefine the al-<br />lowed performance decrease and then search for an optimum that<br />has the maximum tolerance of changes in the design variables,<br />which is termed inverse robust optimization [75]. In both explicit<br />averaging based or inverse robust optimization, additional fitness<br />evaluations are needed. To enhance the efficiency, some of these<br />additional fitness evaluations can be done based on a surrogate<br />[76–78].<br />4.4. Surrogates for constrained optimization<br />Many optimization problems are subject to constraints. To<br />judge if a candidate solution is feasible, the constraint functions<br />need to be frequently evaluated. Therefore, if the evaluations<br />of constraint functions are time-consuming, it is desirable to<br />replace the constraint functions with computationally efficient<br />approximate models [79].<br />In some real-world applications, an explicit constraint is not<br />available. For example in aerodynamic optimization, some of the<br />candidate designs may result in unstable computational fluid<br />dynamic (CFD) simulations. In order to reduce the number of<br />unnecessary, time-consuming CFD simulations, it is very helpful<br />to judge whether a solution is feasible (e.g., converges in a CFD<br />simulation) before it is evaluated in a CFD simulation. Surrogates<br />can be used for this purpose [80,81].<br />An interesting idea of using surrogates in constrained opti-<br />mization has been recently reported in [82], where surrogates are</p>  <p>Page 7</p> <p>Y. Jin / Swarm and Evolutionary Computation 1 (2011) 61–70<br />67<br />a<br />b<br />c<br />Fig. 6.<br />evolutionary search [82]. (a) The true feasible region (shaded), which consists of<br />three separate sub-regions. (b) A linear approximation of the original constraints<br />by using two data points, resulting in an enlarged single feasible region. (c) A more<br />accurateapproximationoftheconstraintfunctionsandtheresultingfeasibleregion<br />is close to real one.<br />An illustrative example of manipulating the constraints to facilitate<br />applied to manipulate the shape and size of the feasible region to<br />easethesolutionofhighlyconstrainedoptimizationproblems.The<br />basic idea is to deliberately enlarge the feasible region by build-<br />ing up a very simple surrogate for each constraint function. As the<br />evolutionary optimization proceeds, the complexity of the surro-<br />gates increases gradually so that the approximated feasible region<br />can converge to the real feasible region. An illustration of this ba-<br />sic idea is given in Fig. 6. Simulation results on a set of benchmark<br />problems and a few structural design problems demonstrated that<br />the idea works well. Genetic programming based generation of in-<br />creasingly complex surrogates has also been reported [83].<br />5. Real-world applications<br />Surrogate-assisted<br />application driven. Thus, the effectiveness of surrogate-assisted<br />evolutionaryoptimizationis more<br />evolutionary algorithms need to be demonstrated in real-world<br />applications. One intensively researched area is surrogate-assisted<br />design optimization, such as turbine blades [9,23,84,85], air-<br />foils [27,86], forging [87], vehicle crash tests [88], multi-processor<br />systems-on-chip design [89] and injection systems [90]. Other ap-<br />plications include drug design [2], protein design [5], hydroinfor-<br />matics [91] and evolutionary robotics [92]. We must note that<br />not many substantial successful applications of meta-model based<br />evolutionary optimization have been reported, which, however<br />doesnotnecessarilymeannosuchworkhasbeendone.Somework<br />carried out in industry has not been published. We also want to<br />note that meta-model based evolutionary optimization has been<br />included in a few commercial design software tools.<br />6. Future challenges<br />Surrogate-assisted evolutionary computation has achieved<br />considerable advances over the past decade, not only in algorithm<br />design, but also in real-world applications. Nevertheless, many<br />challenges remain to be addressed. In the following, we discuss a<br />fewofthesechallengesandhopethatthesediscussionswilltrigger<br />more research efforts devoted to approaching these challenges.<br />6.1. Theoretic work<br />A wide range of trust-region methods have shown to converge<br />to the global optimum [93] when a gradient-based method is<br />used to search on the surrogate. Unfortunately, a convergence<br />proof for surrogate-assisted evolutionary algorithms to the global<br />optimum or to a local optimum is not straightforward, as a proof<br />of any stochastic search algorithm to a global optimum is non-<br />trivial. Meanwhile, approximation errors introduced by surrogates<br />can usually neither be described by a Gaussian nor a uniform<br />distribution, which makes a quantitative analysis of the search<br />dynamics on a surrogate very difficult, if not impossible.<br />If we go one step back, we may raise the question of whether<br />we can guarantee that a surrogate-assisted evolutionary algorithm<br />converges faster than its counterpart without using a surrogate<br />using the same number of expensive fitness evaluations. Again, no<br />theoretical work has been reported to show this.<br />6.2. Multi-level, multi-fidelity heterogeneous surrogates<br />Use of multi-level, multi-fidelity surrogates has already been<br />suggested in [12]. The heterogeneity can include the model type of<br />the surrogates and the degree of fidelity (modeling accuracy). On<br />the one hand, various surrogates, ranging from the deterministic<br />linear model (e.g., linear interpolation) to nonlinear models<br />(e.g. feedforward neural networks, support vector machines)<br />and to stochastic models, such as Gaussian processes (Kriging)<br />and to dynamic models such as recurrent neural networks.<br />Meanwhile, multi-fidelity models can be used either by using data<br />from different problem approximations (e.g., 2D Navier–Stokes<br />simulations and 3D Navier–Stokes simulations) or experiments,<br />or different degrees of incomplete simulations, or by deliberately<br />controlling the complexity of the models.<br />When heterogeneous surrogates are used, the computational<br />times for fitness evaluations using different models can be very<br />different. To further improve the computational efficiency of<br />the whole evolutionary process, non-generational evolutionary<br />algorithms with grid-based or asynchronous computing structure<br />may be preferred [86,56].<br />6.3. Surrogate-assisted combinatorial optimization<br />Surrogate-assisted evolutionary algorithms have been studied<br />extensively for continuous optimization. In real-world applica-<br />tions, however, there are also many computationally intensive<br />combinatorial optimization problems, such as job shop scheduling</p>  <p>Page 8</p> <p>68<br />Y. Jin / Swarm and Evolutionary Computation 1 (2011) 61–70<br />and wireless network or mobile sensor network optimization. In<br />such cases, discrete modeling techniques must be employed, e.g.,<br />binary neural networks [94]. In [95], an RNF neural network is ap-<br />plied to assist a mixed integer evolution strategy for intravascu-<br />lar ultrasound image analysis [95]. Recently, an integrated Kriging<br />model is used for mobile network optimization [96].<br />6.4. Surrogate-assisted dynamic optimization<br />If an expensive optimization is time-varying, evolutionary<br />algorithms for solving dynamic optimization problems must be<br />adopted to track the moving optima or moving Pareto front [97].<br />Practically, an optimal solution that is robust over time may be<br />more preferred [74]. In either case, the surrogate must be updated<br />online. Therefore, it may be of interest to introduce incremental<br />learning techniques [98] for efficient online learning when the<br />objective functions change over time.<br />6.5. Rigorous benchmarking and test problems<br />Although many surrogate-assisted evolutionary algorithms<br />have been proposed and demonstrated to be more efficient than<br />their counterpart without using a surrogate, no rigorous compar-<br />ative studies on surrogate-assisted evolutionary algorithms have<br />been reported. This may be attributed to two reasons. First, no<br />widely accepted performance index for benchmarking surrogate-<br />assisted evolutionary algorithms has been suggested. Second, no<br />benchmarkproblemsdedicatedtosurrogate-assistedevolutionary<br />algorithms have been proposed. Most work on surrogate-assisted<br />evolutionary algorithms uses either standard test functions such<br />as the Ackley function [99] or specific real-world applications for<br />empirical evaluations. However, design of test problems relevant<br />to real-world applications is non-trivial. Ideally, such test prob-<br />lemsshouldreflectthemajordifficultiesinreal-worldapplications<br />yet tractable for intensive empirical comparisons. As indicated<br />in [1], expensive optimization problems such as aerodynamic de-<br />sign optimization not only involve highly time-consuming fitness<br />evaluations, the fitness landscape is often multi-modal as well. In<br />addition, the CFD simulations may be unstable, resulting in many<br />isolated infeasible solutions. Finally, the design space is very high<br />and geometry representation may be critical for the efficiency of<br />the whole evolutionary design optimization.<br />7. Summary<br />Surrogate-assisted evolutionary algorithms are motivated from<br />real-world applications. As evolutionary algorithms are increas-<br />ingly applied to solving complex problems, research interests in<br />surrogate-assisted evolutionary algorithms have considerably in-<br />creased in recent years. This paper provides a brief overview of<br />recent advances in this research area and suggests a few chal-<br />lenging issues that remain to be resolved in the future. We ex-<br />pect that successful resolution of these challenges heavily depends<br />on the progress in both optimization and learning, and new com-<br />puting techniques such as grid computing [100] and cloud com-<br />puting [101], with which more computing resources will be made<br />available to common users via computer networks.<br />References<br />[1] Y. Jin, B. Sendhoff, A systems approach to evolutionary multi-objective struc-<br />tural optimization and beyond, IEEE Computational Intelligence Magazine 4<br />(3) (2009) 62–76.<br />[2] D. Douguet, e-LEA3D: A computational-aided drug design web server,<br />Nucleic Acids Research 38 (2010) w615–w621.<br />[3] Y. Jin, M. Olhofer, B. Sendhoff, On evolutionary optimization with approxi-<br />mate fitness functions, in: Genetic and Evolutionary Computation Congress,<br />2000, pp. 786–793.<br />[4] J.J. Grefenstette, J.M. Fitzpatrick, Genetic search with approximate fitness<br />evaluations, in: Proceedings of the International Conference on Genetic<br />Algorithms and Their Applications, 1985, pp. 112–120.<br />[5] G. Schneider, J. Schuchhardt, P. Wrede, Artificial neural networks and<br />simulated molecular evolution are potential tools for sequence-oriented<br />protein design, CABIOS 10 (6) (1994) 635–645.<br />[6] D. Yang, S.J. Flockton, Evolutionary algorithms with a coarse-to-fine function<br />smoothing, in: IEEE International Conference on Evolutionary Computation,<br />1995, pp. 657–662.<br />[7] A. Ratle, Accelerating the convergence of evolutionary algorithms by fitness<br />landscape approximation, in: Parallel Problem Solving from Nature, 1998,<br />pp. 87–96.<br />[8] L. Bull, On model-based evolutionary computation, Soft Computing 3 (1999)<br />76–82.<br />[9] S. Pierret, Turbomachinery blade design using a Navier–Stokes solver and<br />artificial neural network, ASME Journal of Turbomachinery 121 (3) (1999)<br />326–332.<br />[10] Y. Jin, S.J. Louis, K.M. Rasheed, Approximation and learning in evolutionary<br />computation. GECCO Workshop, July 2002.<br />[11] Y. Jin, B. Sendhoff, Fitness approximation in evolutionary computation —<br />a survey, in: Genetic and Evolutionary Computation Conference, 2002,<br />pp. 1105–1112.<br />[12] Y. Jin, A comprehensive survey of fitness approximation in evolutionary<br />computation, Soft Computing 9 (1) (2005) 3–12.<br />[13] Y.Tenne,C.-K.Goh(Eds.),ComputationalIntelligenceinExpensiveOptimiza-<br />tion Problems, Springer, 2009.<br />[14] M.M. Davarynejad, C.W. Ahn, J. Vranckena, J. van den Berga, C.A. Coello<br />Coello, Evolutionary hidden information detection by granulation-based<br />fitness approximation, Applied Soft Computing 10 (3) (2010) 719–729.<br />[15] H.S. Kim, S.B. Cho, An efficient genetic algorithms with less fitness evaluation<br />by clustering, in: Congress on Evolutionary Computation, 2001, pp. 887–894.<br />[16] M. Salami, T. Hendtlass, The fast evaluation strategy for evolvable hardware,<br />Genetic Programming and Evolvable Machines 6 (2) (2005) 139–162.<br />[17] A. Forrester, A. Sobester, A. Keane, Engineering Design via Surrogate<br />Modelling: A Practical Guide, John Wiley &amp; Sons, 2008.<br />[18] J.P.C. Kleijnen, Design and analysis of simulation experiments, in: Interna-<br />tional Series in Operations Research &amp; Management Science, Springer, 2009.<br />[19] K. Anderson, Y. Hsu, Genetic crossover strategy using an approximation<br />concept, in: IEEE Congress on Evolutionary Computation, 1999, pp. 527–533.<br />[20] K. Abboud, M. Schoenauer, Surrogate deterministic mutation: Preliminary<br />results, in: Artificial Evolution, in: LNCS, 2002, pp. 919–954.<br />[21] K. Rasheed, H. Hirsh, Informed operators: speeding up genetic-algorithm-<br />based design optimization using reduced models, in: Genetic and Evolution-<br />ary Computation Conference, Morgan Kaufmann, 2000, pp. 628–635.<br />[22] I. Loshchilov, M. Schoenauer, S. Sebag, A mono surrogate for multiobjective<br />optimization, in: Genetic and Evolutionary Computation Conference, 2010,<br />pp. 471–478.<br />[23] Y. Jin, M. Olhofer, B. Sendhoff, A framework for evolutionary optimization<br />with approximate fitness functions, IEEE Transactions on Evolutionary<br />Computation 6 (5) (2002) 481–494.<br />[24] D. Lim, Y.-S. Ong, Y. Jin, B. Sendhoff, Trusted evolutionary algorithms, in: IEEE<br />Congress on Evolutionary Computation, 2006, pp. 456–463.<br />[25] J. Branke, C. Schmidt, Fast convergence by means of fitness estimation, Soft<br />Computing 9 (1) (2005) 13–20.<br />[26] M. Emmerich, A. Giotis, M. Uezdenir, T. Baeck, K. Giannakoglou, Metamodel-<br />assisted evolution strategies, in: Parallel Problem Solving from Nature,<br />in: LNCS, Springer, 2002, pp. 371–380.<br />[27] Y.S. Ong, P.B. Nair, A.J. Keane, Evolutionary optimization of computationally<br />expensive problems via surrogate modeling, AIAA Journal 41 (4) (2003)<br />687–696.<br />[28] Z. Zhou, Y.-S. Ong, M.-H. Lim, B.-S. Lee, Memetic algorithm using multi-<br />surrogates for computationally expensive optimization problems, Soft<br />Computing 11 (10) (2007) 957–971.<br />[29] S.Z. Martinez, C.A. Coello Coello, A memetic algorithm with non gradient-<br />based local search assisted by a meta-model, in: Parallel Problem Solving<br />from Nature, in: LNCS, Springer, 2010, pp. 576–585.<br />[30] J.-F.M. Barthelemy, Approximation concepts for optimum structural design<br />— A review, Structural Optimization 5 (1993) 129–144.<br />[31] M. Celis, J.E. Dennis, R.A. Tapia, A trust region strategy for nonlinear equality<br />constrained optimization, in: P. Boggs, R. Byrd, R. Schnabel (Eds.), Numerical<br />Optimization 1984, SIAM, Philadelphia, 1985, pp. 71–82.<br />[32] H.K. Singh, T. Ray, W. Smith, Surrogate assisted simulated annealing<br />(SASA) for constrained multi-objective optimization, in: IEEE Congress on<br />Evolutionary Computation, 2010, pp. 1–8.<br />[33] H.S. Bernardino, H.J.C. Barbosa, L.G. Fonseca, A faster clonal selection<br />algorithm for expensive optimization problems, in: Artificial Immune<br />Systems, Springer, 2010, pp. 130–143.<br />[34] Y. Jin, B. Sendhoff, Reducing fitness evaluations using clustering techniques<br />and neural network ensembles, in: Genetic and Evolutionary Computation<br />Conference, 2004, pp. 688–699.<br />[35] F. Mota, F. Gomide, Fuzzy clustering in fitness estimation models for genetic<br />algorithms and applications, in: IEEE International Conference on Fuzzy<br />Systems, 2006, pp. 1388–1395.<br />[36] L. Graening, Y. Jin, B. Sendhoff, Efficient evolutionary optimization using<br />individual-based evolution control and neural networks: A comparative<br />study, in: European Symposium on Artificial Neural Networks, 2005,<br />pp. 273–278.</p>  <p>Page 9</p> <p>Y. Jin / Swarm and Evolutionary Computation 1 (2011) 61–70<br />69<br />[37] L. Graening,<br />Meta-models<br />Three-dimensional Blade Optimization, Springer, 2007, pp. 225–250<br />(chapter 6).<br />[38] S. Tong, Active learning: theory and applications. Ph.D. Thesis, Department of<br />Computer Science, Stanford University, 2001.<br />[39] D.J.C. MacKay, Introduction to gaussian processes, in: C.M. Bishop (Ed.),<br />Neural Networks and Machine Learning, Springer, 1998, pp. 133–165.<br />[40] J. Sacks, W.J. Welch, T.J. Mitchell, H.P. Wynn, Design and analysis of computer<br />experiments, Statistical Science 4 (1989) 409–435.<br />[41] D. Buche, N.N. Schraudolph, P. Koumoutsakos, Accelerating evolutionary<br />algorithms with gaussian process fitness function models, IEEE Transactions<br />on Systems, Man, and Cybernetics, Part C: Applications and Reviews 35 (2)<br />(2005) 183–194.<br />[42] M. Emmerich, K.C. Giannakoglou, B. Naujoks, Single- and multiobjective<br />evolutionary optimization assisted by gaussian random field metamodels,<br />IEEE Transactions on Evolutionary Computation 10 (4) (2006) 421–439.<br />[43] J.Knowles,Parego:ahybridalgorithmwithon-linelandscapeapproximation<br />for expensive multiobjective optimization problems, IEEE Transactions on<br />Evolutionary Optimization 10 (1) (2006) 50–66.<br />[44] Q. Zhang, W. Liu, E. Tsang, B. Virginas, Expensive multiobjective optimization<br />by MOEA/D with gaussian process model, IEEE Transactions on Evolutionary<br />Computation 14 (3) (2010) 456–474.<br />[45] Y. Jin, M. Huesken, B. Sendhoff, Quality measures for approximate models in<br />evolutionary computation, in: Proceedings of GECCO Workshops: Workshop<br />on Adaptation, Learning and Approximation in Evolutionary Computation,<br />2003, pp. 170–174.<br />[46] M. Huesken, Y. Jin, B. Sendhoff, Structure optimization of neural networks for<br />aerodynamic optimization, Soft Computing 9 (1) (2005) 21–28.<br />[47] H. Ulmer, F. Streichert, A. Zell, Evolution strategies with controlled model<br />assistance, in: Congress on Evolutionary Computation, 2004, pp. 1569–1576.<br />[48] M. Schmidt, H. Lipson, Coevolution of fitness predictors, IEEE Transactions on<br />Evolutionary Computation 12 (6) (2008) 736–749.<br />[49] Y. Tenne, K. Izui, S. Nishiwaki, Dimensionality-reduction frameworks<br />for computationally expensive problems, IEEE Congress on Evolutionary<br />Computation, 2010, pp. 1–8.<br />[50] Z. Zhou, Y.S. Ong, P.B. Nair, A.J. Keane, K.Y. Lum, Combining global and local<br />surrogate models to accelerate evolutionary optimization, IEEE Transactions<br />on Systems, Man, and Cybernetics, Part C: Applications and Reviews 37 (1)<br />(2007) 66–76.<br />[51] Y. Cao, Y. Jin, M. Kowalczykiewicz, B. Sendhoff, Prediction of convergence dy-<br />namics of design performance using differential recurrent neural networks,<br />in: International Joint Conference on Neural Networks, 2008, pp. 529–534.<br />[52] Y. Tenne, S.W. Armfield, A framework for memetic optimization using<br />variableglobalandlocalsurrogatemodels,SoftComputing13(2009)81–793.<br />[53] Y. Jin, B. Sendhoff, Pareto-based multi-objective machine learning: an<br />overview and case studies, IEEE Transactions on Systems, Man, and<br />Cybernetics, Part C: Applications and Reviews 38 (3) (2008) 397–415.<br />[54] T. Goel, R.T. Haftka, W. Shyy, N.V. Queipo, Ensemble of surrogates, Structural<br />and Multidisciplinary Optimization 33 (3) (2007) 199–216.<br />[55] E. Sanchez, S. Pintos, N.V. Queipo, Toward an optimal ensemble of<br />kernel-based approximations with engineering applications, Structural and<br />Multidisciplinary Optimization 36 (3) (2008) 247–261.<br />[56] D. Lim, Y.S. Ong, Y. Jin, B. Sendhoff, A study on metamodeling techniques,<br />ensembles, and multi-surrogates in evolutionary computation, in: Genetic<br />and Evolutionary Computation Conference, 2007, pp. 1288–1295.<br />[57] A. Samad, K.-Y. Kim, Multiple surrogate modeling for axial compressor blade<br />shape optimization, Journal of Propulsion Power 24 (2) (2008) 302–310.<br />[58] D. Chafekar, L. Shi, K. Rasheed, J. Xuan, Constrained multi-objective ga<br />optimization using reduced models, IEEE Transactions on Systems, Man and<br />Cybernetics, Part C: Applications and Reviews 35 (2) (2005) 261–265.<br />[59] A. Isaacs, T. Ray, W. Smith, An evolutionary algorithm with spatially<br />distributedsurrogatesformultiobjectiveoptimization,in:The3rdAustralian<br />Conference on Progress in Artificial Life, 2007, pp. 257–268.<br />[60] D. Eby, R. Averill, W. Punch, E. Goodman, Evaluation of injection island model<br />ga performance on flywheel design optimization, in: Third Conference on<br />Adaptive Computing in Design and Manufacturing, 1998, pp. 121–136.<br />[61] M. Sefrioui, J. Periaux, A hierarchical genetic algorithm using multiple<br />models for optimization, in: Parallel Problem Solving from Nature, 2000,<br />pp. 879–888.<br />[62] P.K.S. Nain, K. Deb, Computationally effective search and optimization<br />procedure using coarse to fine approximation, in: IEEE Congress on<br />Evolutionary Computation, 2003, pp. 2081–2088.<br />[63] D. Lim, Y.S. Ong, Y. Jin, B. Sendhoff, Evolutionary optimization with dynamic<br />fidelity computational models, in: International Conference on Intelligent<br />Computing, in: LNCS, Springer, 2008, pp. 235–242.<br />[64] D. Lim, Y. Jin, Y.S. Ong, B. Sendhoff, Generalizing surrogate-assisted<br />evolutionary computation, IEEE Transactions on Evolutionary Computation<br />14 (3) (2010) 329–355.<br />[65] J. Branke, Creating robust solutions by means of evolutionary algorithms,<br />in: Parallel Problem Solving from Nature, in: LNCS, Springer, 1998,<br />pp. 119–128.<br />[66] M. Bhattacharya, Reduced computation for evolutionary optimization in<br />noisy environment, in: Genetic and Evolutionary Computation Conference,<br />2008, pp. 2117–2122.<br />Y.<br />for<br />Jin,B. Sendhoff, Individual-based<br />Optimization<br />Management<br />Applications<br />of<br />to Evolutionary with<br />[67] K.-H. Liang, X. Yao, C. Newton, Evolutionary search of approximated n-<br />dimensional landscapes, International Journal of Knowledge-Based Intelli-<br />gent Engineering Systems 4 (3) (2000) 172–183.<br />[68] H. Takagi, Interactive evolutionary computation: fusion of the capabilities<br />of ec optimization and human evaluation, Proceedings of IEEE 89 (2002)<br />1275–1296.<br />[69] J.A. Biles, P.G. Anderson, L.W. Loggi, Neural network fitness functions for a<br />musical IGA, in: The International ICSC Symposium on Intelligent Industrial<br />Automation and Soft Computing, 1996.<br />[70] R.R Kamalian, A.M. Agogino, H. Takagi, Use of interactive evolutionary<br />computation with simplified modeling for computationally expensive layout<br />design optimization, in: IEEE Congress on Evolutionary Computation, 2007,<br />pp. 4124–4129.<br />[71] X. Sun, D. Gong, S. Li, Classification and regression-based surrogate model<br />- Assisted interactive genetic algorithm with individual fuzzy fitness, in:<br />Genetic and Evolutionary Computation Conference, 2009, pp. 907–914.<br />[72] A. Zhou, Y. Jin, Q. Zhang, B. Sendhoff, E. Tsang, Prediction-based population<br />re-initialization for evolutionary dynamic multi-objective optimization,<br />in: The Fourth International Conference on Evolutionary Multi-Criterion<br />Optimization, in: LNCS, Springer, 2007, pp. 832–846.<br />[73] I. Hatzakis, D. Wallace, Dynamic multi-objective optimization with evolu-<br />tionary algorithms: a forward-looking approach, in: Genetic and Evolution-<br />ary Computation Conference, 2006, pp. 1201–1208.<br />[74] X. Yu, Y. Jin, K. Tang, X. Yao, Robust optimization over time — a new<br />perspectiveondynamicoptimizationproblems,in:CongressonEvolutionary<br />Computation, 2010, pp. 3998–4003.<br />[75] D. Lim, Y.-S. Ong, Y. Jin, B. Sendhoff, B.S. Lee, Inverse multi-objective robust<br />evolutionary optimization, Genetic Programming and Evolvable Machines 7<br />(4) (2006) 383–404.<br />[76] D. Lim, Y.-S. Ong, M.-H. Lim, Y. Jin, Single/multi-objective inverse robust<br />evolutionary design methodology in the presence of uncertainty, in: S. Yang,<br />Y.S. Ong, Y. Jin (Eds.), Evolutionary Computation in Dynamic and Uncertain<br />Environments, Springer, 2007, pp. 437–456.<br />[77] Y.-S. Ong, P.B. Nair, K.Y. Lum, Max–min surrogate-assisted evolutionary<br />algorithm for robust design, IEEE Transactions on Evolutionary Computation<br />10 (4) (2006) 392–404.<br />[78] I. Paenke, J. Banke, Y. Jin, Efficient search for robust solutions by means<br />of evolutionary algorithms and fitness approximation, IEEE Transactions on<br />Evolutionary Computation 10 (4) (2006) 405–420.<br />[79] T.P. Runarsson, Constrained evolutionary optimization by approximate<br />ranking and surrogate models, in: Parallel Problem Solving from Nature,<br />in: LNCS, Springer, 2004, pp. 401–410.<br />[80] S.D. Handoko, C.K. Kwoh, Y.S. Ong, Feasibility structure modeling: an<br />effective chaperon for constrained memetic algorithms, IEEE Transactions on<br />Evolutionary Computation 14 (5) (2010) 740–758.<br />[81] Y. Tenne, K. Izui, S. Nishiwaki, Handling undefined vectors in expensive<br />optimization problems, in: Applications of Evolutionary Computation,<br />in: LNCS, Springer, 2010, pp. 582–591.<br />[82] Y. Jin, S. Oh, M. Jeon, Incremental approximation of nonlinear constraint<br />functions for evolutionary constrained optimization, in: IEEE Congress on<br />Evolutionary Computation, 2010, pp. 2966–2973.<br />[83] S. Oh, Y. Jin, M. Jeon, Approximate models for constraint functions in<br />evolutionary constrained optimization, International Journal of Innovative<br />Computing, Information and Control 7 (10) (2011).<br />[84] M.K. Karakasis, K.C. Giannakoglou, Metamodel-assisted multi-objective<br />evolutionary optimization, in: Evolutionary and Deterministic Methods for<br />Design,OptimizationandControlwithApplicationstoIndustrialandSocietal<br />Problems, EUROGEN, 2005.<br />[85] A. Shahrokhi, A. Jahangirian, A surrogate assisted evolutionary optimization<br />method with application to the transonic airfoil design, Engineering<br />Optimization 42 (6) (2010) 497–515.<br />[86] V.G. Asouti, I.C. Kampolis, K.C. Giannakoglou, A grid-enabled asynchronous<br />metamodel-assisted evolutionary algorithm for aerodynamic optimization,<br />Genetic Programming and Evolvable Machines 10 (4) (2009) 373–389.<br />[87] M.H.A. Bonte, L. Fourment, T.-T. Do, A.H. van den Boogaard, J. Huetink,<br />Optimization of forging processes using finite element simulations, Struc-<br />tural Multidisciplinary Optimization 42 (2010) 797–810.<br />[88] K. Hamza, K. Saitou, Crashworthiness design using meta-models for<br />aprroximating the response of structural members, in: Cairo University<br />Conference on Mechanical Design and Production, 2004.<br />[89] G. Mariani, G. Palermo, C. Silvano, V. Zaccaria, Meta-model assisted<br />optimization for design space exploration of multi-processor systems-on-<br />chip, in: 12th Euromicro Conference on Digital System Design, Architectures,<br />Methods and Tools, 2009, pp. 383–389.<br />[90] G.Dellino,P.Lino,C.Meloni,A.Rizzo,Krigingmetamodelmanagementinthe<br />design optimization of a cng injection system, Mathematics and Computers<br />in Simulation 79 (8) (2009) 2345–2360.<br />[91] S.-T.Khu,D.Savic,Z.Kapelan,Evolutionary-basedmeta-modellingvtherele-<br />vance of using approximate models in hydroinformatics, in: Hydroinformat-<br />ics in Practice: Computational Intelligence and Technological Developments<br />in Water Applications, Springer, 2008.<br />[92] I.Dahm,J.Ziegler,Usingartificialneuralnetworkstoconstructameta-model<br />for the evolution of gait patterns, in: Proceedings of the 5th International<br />Conference on Climbing and Walking Robots, 2002.<br />[93] M.J. Powell, On the convergence of a wide range of trust region methods for<br />unconstrained optimization, IMA Journal of Numerical Analysis 30 (1) (2010)<br />289–301.<br />[94] V.J. Hodge, K.J. Lees, J.L. Austin, A high performance k-nn approach using<br />binary neural networks, Neural Networks 17 (3) (2004) 441–458.</p>  <p>Page 10</p> <p>70<br />Y. Jin / Swarm and Evolutionary Computation 1 (2011) 61–70<br />[95] R. Li, M.T.M. Emmerich, J. Eggermont, E.G.P. Bovenkamp, T. Bäck, J. Dijkstra,<br />J.H.C. Reiber, Metamodel-assisted mixed integer evolution strategies and<br />their application to intravascular ultrasound image analysis, in: IEEE<br />Congress on Evolutionary Computation, 2008, pp. 2764–2771.<br />[96] C. Ling, J.-H. Liang, B. Wu, Z.-W. Hu, A metamodel-based optimiza-<br />tion method for mobile ad hoc networks, in: 2010 International Con-<br />ference on Computer Application and System Modeling, ICCASM, 2010,<br />pp. 412–416.<br />[97] Y. Jin, J. Branke, Evolutionary optimization in uncertain environments-<br />a survey, IEEE Transactions on Evolutionary Computation 9 (3) (2005)<br />303–317.<br />[98] R. Polikar, L. Upda, S.S. Upda, V. Honavar, Learn++: An incremental learning<br />algorithm for supervised neural networks, IEEE Transactions on Systems,<br />Man, and Cybernetics, Part C: Applications and Reviews 31 (4) (2001)<br />479–508.<br />[99] D.H. Ackley, A Connectionist Machine for Genetic Hillclimbing, Kluwer<br />Academic Publishers, Norwell, MA, 1987.<br />[100] W. Hendrickx, D. Gorisson, T. Dhaene, Grid enabled sequential design and<br />adaptive metamodeling, in: Proceedings of the 2006 Winter Simulation<br />Conference, 2006.<br />[101] M. Miller, Cloud Computing: Web-Based Applications That Change the Way<br />You Work and Collaborate Online, Que Publishing, 2008.</p>  <a href="https://www.researchgate.net/profile/Yaochu_Jin/publication/220514418_Surrogate-assisted_evolutionary_computation_Recent_advances_and_future_challenges/links/563e857b08ae45b5d28c5bc8.pdf">Download full-text</a> </div> <div id="rgw18_56aba22853fca" class="c-box pub-resource-container js-toggle" style=""> <h4 class="lf js-expand-list"><small><a href="javascript:" class="lf">View other sources <span class="ico-expand-list"></span></a></small></h4> <h4 class="lf js-collapse-list hidden"><small><a href="javascript:" class="lf">Hide other sources <span class="ico-collapse-list"></span></a></small></h4> <div class="clear"></div> <div class="scroll-wrapper hidden"> <ul class="files-list c-list" id="rgw19_56aba22853fca">  <li class="c-list-item pub-resource-item"  data-type="fulltext" id="rgw20_56aba22853fca"> <span class="ico-pub"></span> <div class="file-content"> <div class="download"> <a href="profile/Yaochu_Jin/publication/220514418_Surrogate-assisted_evolutionary_computation_Recent_advances_and_future_challenges/links/563e857b08ae45b5d28c5bc8.pdf" class="publication-viewer" title="SECPublished.pdf">SECPublished.pdf</a> </div>  <div class="details">  <span> Available from <a href="profile/Yaochu_Jin">Yaochu Jin</a> &middot; Nov 8, 2015 </span>   </div>    </div> </li>  </ul> </div> </div> </noscript> <div class="clearfix"> <div class="action-container">  </div> <div class="pub-legal"> Data provided are for informational purposes only. Although carefully collected, accuracy cannot be guaranteed. The impact factor represents a rough estimation of the journal's impact factor and does not reflect the actual current impact factor. Publisher conditions are provided by RoMEO. Differing provisions from the publisher's actual policy or licence agreement may be applicable. </div>   </div> </div> <div class="clearfix">     <div id="rgw22_56aba22853fca" class="c-box pub-resource-container js-toggle" style="display: none;"> <h4 class="lf js-expand-list"><small><a href="javascript:" class="lf">View other sources <span class="ico-expand-list"></span></a></small></h4> <h4 class="lf js-collapse-list hidden"><small><a href="javascript:" class="lf">Hide other sources <span class="ico-collapse-list"></span></a></small></h4> <div class="clear"></div> <div class="scroll-wrapper hidden"> <ul class="files-list c-list" id="rgw23_56aba22853fca">  </ul> </div> </div>   <div id="rgw14_56aba22853fca" class="similar-publications"> <h2>Similar Publications</h2> <ul class="list-bordered">  <li class="c-list-item li-publication-teaser" id="rgw15_56aba22853fca"> <div> <h5> <a href="publication/288856816_Evolutionary_Dynamic_Multiobjective_Optimization_Via_Kalman_Filter_Prediction" class="color-inherit ga-similar-publication-title"><span class="publication-title">Evolutionary Dynamic Multiobjective Optimization Via Kalman Filter Prediction</span></a>  </h5>  <div class="authors"> <a href="researcher/2069027354_Arrchana_Muruganantham" class="authors ga-similar-publication-author">Arrchana Muruganantham</a>, <a href="researcher/10503174_Kay_Chen_Tan" class="authors ga-similar-publication-author">Kay Chen Tan</a>, <a href="researcher/2091797206_Prahlad_Vadakkepat" class="authors ga-similar-publication-author">Prahlad Vadakkepat</a>  </div>  </div> <div class="clear"></div> </li>  <li class="c-list-item li-publication-teaser" id="rgw16_56aba22853fca"> <div> <h5> <a href="publication/291018880_Dynamic_Optimization_of_Lurgi_Type_Methanol_Reactor_Using_Hybrid_GA-GPS_Algorithm_Optimal_Shell_Temperature_Trajectory_and_Carbon_Dioxide_Utilization" class="color-inherit ga-similar-publication-title"><span class="publication-title">Dynamic Optimization of Lurgi Type Methanol Reactor Using Hybrid GA-GPS Algorithm: Optimal Shell Temperature Trajectory and Carbon Dioxide Utilization</span></a>  </h5>  <div class="authors"> <a href="researcher/2051201363_abdulaziz_alarifi" class="authors ga-similar-publication-author">abdulaziz alarifi</a>, <a href="researcher/2094700237_Zhefu_Liu" class="authors ga-similar-publication-author">Zhefu Liu</a>, <a href="researcher/2094865634_Fatih_Erenay" class="authors ga-similar-publication-author">Fatih Erenay</a>, <a href="researcher/42391141_Ali_Elkamel" class="authors ga-similar-publication-author">Ali Elkamel</a>, <a href="researcher/2080948655_Eric_Croiset" class="authors ga-similar-publication-author">Eric Croiset</a>  </div>  </div> <div class="clear"></div> </li>  <li class="c-list-item li-publication-teaser" id="rgw17_56aba22853fca"> <div> <h5> <a href="publication/283648490_Diploidy_in_evolutionary_algorithms_for_dynamic_optimization_problems" class="color-inherit ga-similar-publication-title"><span class="publication-title">Diploidy in evolutionary algorithms for dynamic optimization problems</span></a>  </h5>  <div class="authors"> <a href="researcher/74654794_Boris_Shabash" class="authors ga-similar-publication-author">Boris Shabash</a>, <a href="researcher/39990560_Kay_C_Wiese" class="authors ga-similar-publication-author">Kay C. Wiese</a>  </div>  </div> <div class="clear"></div> </li>  </ul> </div> </div> </div> </div> </div></div></div>
<div class="clear"></div><div id="rgw36_56aba22853fca" class="default-footer"> <div id="footer" class="clearfix"> <span class="footer-left"> &copy; 2008&dash;2016 researchgate.net. All rights reserved. </span> <span class="footer-right"> <a href="https://www.researchgate.net/about">About us</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="https://www.researchgate.net/contact">Contact us</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="careers">Careers</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="developers">Developers</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="blog" target="_blank">News</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="application.PrivacyPolicy.html">Privacy</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="application.TermsAndConditions.html">Terms</a> <span class="footer-link-separator" style="padding: 0 5px;">&nbsp;|&nbsp;</span> <a href="advertising?_ref=ft">Advertising</a> <span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="recruiters?_ref=ft">Recruiting</a> </span> </div>  </div></div>
<div id="rgw37_56aba22853fca">  <div class="header-wrapper-logged-out"> <div id="header"> <div class="header-content"> <a href="" class="g-l-logo"> <svg width="149" height="19"> <image xlink:href="https://c5.rgstatic.net/m/235107188705592/images/template/brand-header-logo.svg" src="https://c5.rgstatic.net/m/238113351022438/images/template/brand-header-logo.png" width="149" height="19"/> </svg> </a> <a href="" class="g-l-logo-ico"> <svg width="127" height="17" viewbox="0 0 127 22"> <image xlink:href="https://c5.rgstatic.net/m/235107188705592/images/template/brand-header-logo.svg" src="https://c5.rgstatic.net/m/238113351022438/images/template/brand-header-logo.png" width="127" height="17"/> </svg> </a> <div id="rgw38_56aba22853fca" class="header-login-wrapper js-header-login"> <div class="dropdown-right-align"> <div class="login-signup-container lf"> <a href="https://www.researchgate.net/signup.SignUp.html?ev=su_chnl_index&amp;hdrsu=1&amp;_sg=9m6AyG2p1oUmI_QAoit2Gleq8NMYtM1p4oKk6GQhRPbit_Q6dt0Ui6zzG1MrUcu2" class="dropdown-toggle lf">Join for free</a> </div> <div class="dropdown lf" style="height: 20px;"> <a href="https://www.researchgate.net/application.Login.html" class="js-login-url dropdown-toggle lf">Log in <span class="caret"></span></a> <div class="dropdown-menu"> <div class="header-login-form-wrapper"> <!--[if IE 6]><p class="box-warning" style="margin-bottom: 0;">Sorry, ResearchGate no longer supports the version of Internet Explorer you are using. <a href="http://whatbrowser.org/" rel="nofollow" target="_blank">Update your web browser</a> and then log in. </p><![endif]--> <form method="post" action="https://www.researchgate.net/application.Login.html" class="form-big header-login-form js-login-form" name="loginForm" id="headerLoginForm"> <input type="hidden" name="request_token" value="V3GRx/mjoXXw3GfGltIOLQHV8eaCs5Alf8iIh9IFiI93xQXxgBLnZGUrleCMpAzxaxM3I41Q7p44sKNBlRJ2v/ZdsFR7tTmL4VaRq9kDQ5AsUDj3P1XdcB3l8QKc7A4Nqh4wrnWGkfGyPsMFCHkD4Iti81i/2/3dXDFseBwpPJbnQvvSHuoqDCU7Wj1R0tks1xtR3tFquypkqp9JgwVCDuDE+7nl8QhBwszrUqZvtnYEXWogRSmCJaeVaPsnLS49HQzMnTdEjWNJU0/Nfd8yoMUo/0hpHM5BedS+tFxDJ/4="/> <input type="hidden" name="urlAfterLogin" value="publication/220514418_Surrogate-assisted_evolutionary_computation_Recent_advances_and_future_challenges"/> <input type="hidden" name="invalidPasswordCount" value="0"/> <input type="hidden" name="headerLogin" value="yes"/> <label for="input-header-login">Email</label> <div class="login-input"> <div class="info-tip-wrapper"> <span class="ico-info js-info"></span> </div> <input type="email" value="" name="login" class="login js-login-input text" id="input-header-login" tabindex="1"/> </div> <div class="clear"></div> <label class="lf" for="input-header-password"> Password </label> <a class="rf forgot-password js-forgot-password" href="application.LostPassword.html">Forgot password?</a> <div class="clear"></div> <input type="password" value="" name="password" class="password js-password-input text" id="input-header-password" tabindex="2"/> <div class="clear"></div> <label class="remember-me" for="headerLoginCookie"> <input type="checkbox" checked="checked" value="yes" name="setLoginCookie" class="lf checkbox" id="headerLoginCookie" tabindex="3"/> Keep me logged in </label> <div class="clear"></div> <input value="Log in" name="loginSubmit" class="btn btn-promote btn-fullwidth btn-large allow-leave js-submit-button" type="submit" tabindex="4"/> </form> <div class="connectors"> <div class="text">or log in with</div> <div class="connector-actions"> <a href="connector/linkedin/" class="li-connect js-li-connect" data-redirect-url="cHVibGljYXRpb24vMjIwNTE0NDE4X1N1cnJvZ2F0ZS1hc3Npc3RlZF9ldm9sdXRpb25hcnlfY29tcHV0YXRpb25fUmVjZW50X2FkdmFuY2VzX2FuZF9mdXR1cmVfY2hhbGxlbmdlcw%3D%3D"> <span class="icon ico-linkedin-round-grey"></span> <span class="icon ico-linkedin-round"></span> </a> <a href="connector/facebook/" class="fb-connect middle js-fb-connect" data-redirect-url="cHVibGljYXRpb24vMjIwNTE0NDE4X1N1cnJvZ2F0ZS1hc3Npc3RlZF9ldm9sdXRpb25hcnlfY29tcHV0YXRpb25fUmVjZW50X2FkdmFuY2VzX2FuZF9mdXR1cmVfY2hhbGxlbmdlcw%3D%3D"> <span class="icon ico-facebook-round-grey"></span> <span class="icon ico-facebook-round"></span> </a> <a href="connector/google/" class="g-connect js-g-connect" data-redirect-url="cHVibGljYXRpb24vMjIwNTE0NDE4X1N1cnJvZ2F0ZS1hc3Npc3RlZF9ldm9sdXRpb25hcnlfY29tcHV0YXRpb25fUmVjZW50X2FkdmFuY2VzX2FuZF9mdXR1cmVfY2hhbGxlbmdlcw%3D%3D"> <span class="icon ico-google-round-grey"></span> <span class="icon ico-google-round"></span> </a> </div> </div> </div> </div> </div> </div> </div> </div> </div> <script type="application/ld+json">
{ "@context" : "http://schema.org",
  "@type" : "Organization",
  "name" : "ResearchGate",
  "url" : "http://www.researchgate.net",
  "logo" : "http://www.researchgate.net/images/template/rg_logo_square_brand.png",
  "sameAs" : [ "https://www.facebook.com/ResearchGate",
    "https://twitter.com/ResearchGate",
    "https://plus.google.com/+researchgate",
    "https://www.linkedin.com/company/researchgate"] 
}
</script> </div> </div><div class="c-signup-bar" id="rgw39_56aba22853fca"> <div class="banner-contents">   <span class="message">ResearchGate is the professional network for scientists and researchers.</span> <a href="signup.SignUp.html?ev=su_banner" class="btn btn-large btn-promote">Join for free</a>  </div> </div></div>
<script>
rgConfig.backendTime = 504;
</script>
<script src="//c5.rgstatic.net/m/2277196935388619/javascript/lib/yui3/yui/yui-min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/21832295316281274/javascript/yuiLoaderConfig-min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/23178613132105398/javascript/vendor/babel-core/browser-polyfill.min.js" type="text/javascript"></script>
<script>
(function (){
if (typeof YRG === "undefined") {
var xmlHttpRequest = new XMLHttpRequest();
xmlHttpRequest.open("post", "go.Error.html");
xmlHttpRequest.setRequestHeader("Content-Type", "application/json");
xmlHttpRequest.setRequestHeader("Accept", "application/json"); var loadedScripts = "";
if (window.performance && window.performance.getEntriesByType) {
    var result = [];
    var resources = performance.getEntriesByType("resource");
    for (var i in resources) {
        if (resources.hasOwnProperty(i)) {
            result.push({
                name: resources[i].name,
                duration: resources[i].duration
            });
        }
    }
    loadedScripts += "&loadedScripts=" + encodeURIComponent(JSON.stringify(result));
}
if (typeof YUI === "undefined") {
    loadedScripts += "&yuiLoaded=false";
} else {
    loadedScripts += "&yuiLoaded=true";
}
xmlHttpRequest.send("Type=InformationException&message=" + encodeURIComponent("Error loading YUI") + loadedScripts);
}
})();
</script>
<script>if (typeof YRG !== 'undefined') { YRG.use('rg-base',function(Y){Y.applyConfig({ignore: ["css-rg","css-rg2","css-ie","css-modules-publicprofile","css-pow-publicliterature-FigureList","css-pow-publicliterature-FollowPublicationPromo","css-pow-application-PdfJsReader","css-pow-publicliterature-PublicationInlineReader"]});Y.use(["rg.core.pagespeed.Monitoring"],function(Y){(function(){Y.rg.createInitialWidget({"data":{"content":{"data":{"profileSmallHeader":{"data":{"profileBadge":{"data":{"fullname":"Yaochu Jin","imageUrl":"https:\/\/i1.rgstatic.net\/ii\/profile.image\/AS%3A272587116773382%401442001241796_m\/Yaochu_Jin.png","profileStats":[],"profileFollowButton":null,"profileReputationScoreNumber":null,"profileUrl":"profile\/Yaochu_Jin","institution":"University of Surrey","institutionUrl":false,"widgetId":"rgw4_56aba22853fca"},"id":"rgw4_56aba22853fca","partials":[],"templateName":"publicprofile\/stubs\/ProfileBadge.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicprofile.ProfileBadge.html?accountId=2437436","viewClass":null,"yuiModules":["css-modules-publicprofile"],"stylesheets":["modules\/publicprofile.css"],"_isYUI":true},"widgetId":"rgw3_56aba22853fca"},"id":"rgw3_56aba22853fca","partials":[],"templateName":"publicprofile\/stubs\/ProfileSmallHeader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicprofile.ProfileSmallHeader.html?publicationUid=220514418","viewClass":null,"yuiModules":["css-modules-publicprofile"],"stylesheets":["modules\/publicprofile.css"],"_isYUI":true},"publication":{"data":{"publicationUid":220514418,"title":"Surrogate-assisted evolutionary computation: Recent advances and future challenges","journalTitle":"Swarm and Evolutionary Computation","journalDetailsTooltip":{"data":{"journalTitle":"Swarm and Evolutionary Computation","journalAbbrev":null,"publisher":"Elsevier","issn":"2210-6502","impactFactor":"0.00","fiveYearImpactFactor":"0.00","citedHalfLife":"0.00","immediacyIndex":"0.00","eigenFactor":"0.00","articleInfluence":"0.00","widgetId":"rgw6_56aba22853fca"},"id":"rgw6_56aba22853fca","partials":[],"templateName":"publicliterature\/stubs\/JournalInfo.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.JournalInfo.html?issn=2210-6502","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"affiliation":false,"type":"Article","details":{"doi":"10.1016\/j.swevo.2011.05.001","journalInfos":{"journal":"","publicationDate":"06\/2011;","publicationDateRobot":"2011-06","article":"1(2):61-70.","journalTitle":"Swarm and Evolutionary Computation","journalUrl":"journal\/2210-6502_Swarm_and_Evolutionary_Computation"}},"source":{"sourceUrl":"http:\/\/dblp.uni-trier.de\/db\/journals\/swevo\/swevo1.html#Jin11","sourceName":"DBLP"},"publicationActions":null,"publicationCoins":{"data":{"tags":[{"key":"ctx_ver","value":"Z39.88-2004"},{"key":"rft_val_fmt","value":"info:ofi\/fmt:kev:mtx:journal"},{"key":"rfr_id","value":"info:sid\/researchgate.net:researchgate"},{"key":"rft_id","value":"info:doi\/10.1016\/j.swevo.2011.05.001"},{"key":"rft.atitle","value":"Surrogate-assisted evolutionary computation: Recent advances and future challenges"},{"key":"rft.title","value":"Swarm and Evolutionary Computation"},{"key":"rft.jtitle","value":"Swarm and Evolutionary Computation"},{"key":"rft.volume","value":"1"},{"key":"rft.issue","value":"2"},{"key":"rft.date","value":"2011"},{"key":"rft.pages","value":"61-70"},{"key":"rft.issn","value":"2210-6502"},{"key":"rft.au","value":"Yaochu Jin"},{"key":"rft.genre","value":"article"}],"widgetId":"rgw7_56aba22853fca"},"id":"rgw7_56aba22853fca","partials":[],"templateName":"publicliterature\/stubs\/PublicationCoins.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationCoins.html?publicationUid=220514418","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationAuthors":{"data":{"publicationUid":220514418,"peopleItems":[{"data":{"authorNameOnPublication":"Yaochu Jin","accountUrl":"profile\/Yaochu_Jin","accountKey":"Yaochu_Jin","imageUrl":"https:\/\/i1.rgstatic.net\/ii\/profile.image\/AS%3A272587116773382%401442001241796_m\/Yaochu_Jin.png","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Yaochu Jin","profile":{"professionalInstitution":{"professionalInstitutionName":"University of Surrey","professionalInstitutionUrl":"institution\/University_of_Surrey"}},"professionalInstitutionName":"University of Surrey","professionalInstitutionUrl":"institution\/University_of_Surrey","url":"profile\/Yaochu_Jin","imageUrl":"https:\/\/i1.rgstatic.net\/ii\/profile.image\/AS%3A272587116773382%401442001241796_l\/Yaochu_Jin.png","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":false,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":true,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"accountKey":"Yaochu_Jin","hasInfoPopup":false,"hasTeaserPopup":true,"showContactAuthorButton":true,"widgetId":"rgw10_56aba22853fca"},"id":"rgw10_56aba22853fca","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAccountItem.html?entityId=2437436&enableUnfollow=0&imageSize=l&enableFollowButton=0&showContactAuthorButton=1","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"accountInstitution":"University of Surrey","score":null,"largeTooltip":false,"useRebrandedImageStyle":null,"authorCount":1,"accountCount":1,"publicationUid":220514418,"widgetId":"rgw9_56aba22853fca"},"id":"rgw9_56aba22853fca","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAccountItem.html","templateExtensions":[],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAccountItem.html?accountId=2437436&context=pubdetail_authors_xflw&showContactAuthorButton=1&authorCount=1&accountCount=1&publicationUid=220514418","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true}],"hasMore":false,"nextOffset":6,"useRebrandedImageStyle":null,"widgetId":"rgw8_56aba22853fca"},"id":"rgw8_56aba22853fca","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorList.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorList.html?publicationUid=220514418&context=pubdetail_authors_xflw&showContactAuthorButton=1","viewClass":"views.publicliterature.PublicationDetailAuthorListView","yuiModules":["rg.views.publicliterature.PublicationDetailAuthorListView"],"stylesheets":[],"_isYUI":true},"publicationAbstract":{"data":{"publicationUid":220514418,"abstract":"<noscript><\/noscript><div>Surrogate-assisted, or meta-model based evolutionary computation uses efficient computational models, often known as surrogates or meta-models, for approximating the fitness function in evolutionary algorithms. Research on surrogate-assisted evolutionary computation began over a decade ago and has received considerably increasing interest in recent years. Very interestingly, surrogate-assisted evolutionary computation has found successful applications not only in solving computationally expensive single- or multi-objective optimization problems, but also in addressing dynamic optimization problems, constrained optimization problems and multi-modal optimization problems. This paper provides a concise overview of the history and recent developments in surrogate-assisted evolutionary computation and suggests a few future trends in this research area.<\/div>","canEdit":false,"isAdmin":false,"isArtifact":false,"showFullAbstract":false,"widgetId":"rgw11_56aba22853fca"},"id":"rgw11_56aba22853fca","partials":[],"templateName":"publicliterature\/stubs\/PublicationAbstract.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationAbstract.html?publicationUid=220514418","viewClass":"views.publicliterature.PublicationAbstractView","yuiModules":["rg.views.publicliterature.PublicationAbstractView"],"stylesheets":[],"_isYUI":true},"publicationKeywords":null,"publicationState":null,"isGuest":true,"isAdminEditingAllowed":false,"isArtifact":false,"figureListWidget":{"data":{"figures":[{"imageUrl":"https:\/\/www.researchgate.net\/profile\/Yaochu_Jin\/publication\/220514418\/figure\/fig1\/Fig-4-Examples-of-surrogates-that-have-a-large-approximation-error-but-are-adequately.png","previewImageUrl":"https:\/\/www.researchgate.net\/profile\/Yaochu_Jin\/publication\/220514418\/figure\/fig1\/Fig-4-Examples-of-surrogates-that-have-a-large-approximation-error-but-are-adequately_small.png","figureUrl":"\/figure\/220514418_fig1_Fig-4-Examples-of-surrogates-that-have-a-large-approximation-error-but-are-adequately","selected":false,"title":"Fig. 4. Examples of surrogates that have a large approximation error...","key":"220514418_fig1_Fig-4-Examples-of-surrogates-that-have-a-large-approximation-error-but-are-adequately"},{"imageUrl":"https:\/\/www.researchgate.net\/profile\/Yaochu_Jin\/publication\/220514418\/figure\/fig2\/Fig-5-An-illustration-of-learning-iterative-fitness-evolutionary-process-using.png","previewImageUrl":"https:\/\/www.researchgate.net\/profile\/Yaochu_Jin\/publication\/220514418\/figure\/fig2\/Fig-5-An-illustration-of-learning-iterative-fitness-evolutionary-process-using_small.png","figureUrl":"\/figure\/220514418_fig2_Fig-5-An-illustration-of-learning-iterative-fitness-evolutionary-process-using","selected":false,"title":"Fig. 5. An illustration of learning iterative fitness evolutionary...","key":"220514418_fig2_Fig-5-An-illustration-of-learning-iterative-fitness-evolutionary-process-using"}],"readerDocId":"4495189","linkBehaviour":"dialog","isDialog":true,"headerText":"Figures in this publication","isNewPublicationDesign":false,"widgetId":"rgw12_56aba22853fca"},"id":"rgw12_56aba22853fca","partials":[],"templateName":"publicliterature\/stubs\/FigureList.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.FigureList.html?readerDocId=4495189&isDialog=1&linkBehaviour=dialog","viewClass":"views.publicliterature.FigureListView","yuiModules":["rg.views.publicliterature.FigureListView","css-pow-publicliterature-FigureList"],"stylesheets":["pow\/publicliterature\/FigureList.css"],"_isYUI":true},"previewImage":"https:\/\/i1.rgstatic.net\/publication\/220514418_Surrogate-assisted_evolutionary_computation_Recent_advances_and_future_challenges\/links\/563e857b08ae45b5d28c5bc8\/smallpreview.png","nativeAdDisclosure":null,"showFollowPublicationButton":false,"followPublicationPromo":{"data":{"widgetId":"rgw13_56aba22853fca"},"id":"rgw13_56aba22853fca","partials":[],"templateName":"publicliterature\/stubs\/FollowPublicationPromo.html","templateExtensions":[],"attrs":{"context":null,"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.FollowPublicationPromo.html","viewClass":null,"yuiModules":["css-pow-publicliterature-FollowPublicationPromo"],"stylesheets":["pow\/publicliterature\/FollowPublicationPromo.css"],"_isYUI":true},"widgetId":"rgw5_56aba22853fca"},"id":"rgw5_56aba22853fca","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailItem.html","templateExtensions":["generalHelpers"],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailItem.html?publicationUid=220514418&showActionBar=0&showContactAuthorButton=1&showRequestFulltextExperience=0&showNoRgAuthorsRequestFulltextExperience=0&showFollowPublicationPromo=1","viewClass":"views.publicliterature.PublicationDetailItemView","yuiModules":["rg.views.publicliterature.PublicationDetailItemView"],"stylesheets":[],"_isYUI":true},"similarPublications":{"data":{"publicationListItems":[{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":2069027354,"url":"researcher\/2069027354_Arrchana_Muruganantham","fullname":"Arrchana Muruganantham","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":10503174,"url":"researcher\/10503174_Kay_Chen_Tan","fullname":"Kay Chen Tan","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2091797206,"url":"researcher\/2091797206_Prahlad_Vadakkepat","fullname":"Prahlad Vadakkepat","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Dec 2015","journal":"Cybernetics, IEEE Transactions on","showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/288856816_Evolutionary_Dynamic_Multiobjective_Optimization_Via_Kalman_Filter_Prediction","usePlainButton":true,"publicationUid":288856816,"feedStubs":null,"hasFeedStubs":false,"impactPoints":"3.47","url":"publication\/288856816_Evolutionary_Dynamic_Multiobjective_Optimization_Via_Kalman_Filter_Prediction","title":"Evolutionary Dynamic Multiobjective Optimization Via Kalman Filter Prediction","displayTitleAsLink":true,"authors":[{"id":2069027354,"url":"researcher\/2069027354_Arrchana_Muruganantham","fullname":"Arrchana Muruganantham","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":10503174,"url":"researcher\/10503174_Kay_Chen_Tan","fullname":"Kay Chen Tan","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2091797206,"url":"researcher\/2091797206_Prahlad_Vadakkepat","fullname":"Prahlad Vadakkepat","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["Cybernetics, IEEE Transactions on 12\/2015;  DOI:10.1109\/TCYB.2015.2490738"],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/288856816_Evolutionary_Dynamic_Multiobjective_Optimization_Via_Kalman_Filter_Prediction","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/288856816_Evolutionary_Dynamic_Multiobjective_Optimization_Via_Kalman_Filter_Prediction\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw15_56aba22853fca"},"id":"rgw15_56aba22853fca","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=288856816","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":2051201363,"url":"researcher\/2051201363_abdulaziz_alarifi","fullname":"abdulaziz alarifi","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2094700237,"url":"researcher\/2094700237_Zhefu_Liu","fullname":"Zhefu Liu","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2094865634,"url":"researcher\/2094865634_Fatih_Erenay","fullname":"Fatih Erenay","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":{"id":42391141,"url":"researcher\/42391141_Ali_Elkamel","fullname":"Ali Elkamel","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},"surplusAuthors":1,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Dec 2015","journal":"Industrial & Engineering Chemistry Research","showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/291018880_Dynamic_Optimization_of_Lurgi_Type_Methanol_Reactor_Using_Hybrid_GA-GPS_Algorithm_Optimal_Shell_Temperature_Trajectory_and_Carbon_Dioxide_Utilization","usePlainButton":true,"publicationUid":291018880,"feedStubs":null,"hasFeedStubs":false,"impactPoints":"2.59","url":"publication\/291018880_Dynamic_Optimization_of_Lurgi_Type_Methanol_Reactor_Using_Hybrid_GA-GPS_Algorithm_Optimal_Shell_Temperature_Trajectory_and_Carbon_Dioxide_Utilization","title":"Dynamic Optimization of Lurgi Type Methanol Reactor Using Hybrid GA-GPS Algorithm: Optimal Shell Temperature Trajectory and Carbon Dioxide Utilization","displayTitleAsLink":true,"authors":[{"id":2051201363,"url":"researcher\/2051201363_abdulaziz_alarifi","fullname":"abdulaziz alarifi","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2094700237,"url":"researcher\/2094700237_Zhefu_Liu","fullname":"Zhefu Liu","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2094865634,"url":"researcher\/2094865634_Fatih_Erenay","fullname":"Fatih Erenay","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":42391141,"url":"researcher\/42391141_Ali_Elkamel","fullname":"Ali Elkamel","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2080948655,"url":"researcher\/2080948655_Eric_Croiset","fullname":"Eric Croiset","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["Industrial & Engineering Chemistry Research 12\/2015;  DOI:10.1021\/acs.iecr.5b02918"],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/291018880_Dynamic_Optimization_of_Lurgi_Type_Methanol_Reactor_Using_Hybrid_GA-GPS_Algorithm_Optimal_Shell_Temperature_Trajectory_and_Carbon_Dioxide_Utilization","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/291018880_Dynamic_Optimization_of_Lurgi_Type_Methanol_Reactor_Using_Hybrid_GA-GPS_Algorithm_Optimal_Shell_Temperature_Trajectory_and_Carbon_Dioxide_Utilization\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw16_56aba22853fca"},"id":"rgw16_56aba22853fca","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=291018880","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":74654794,"url":"researcher\/74654794_Boris_Shabash","fullname":"Boris Shabash","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":39990560,"url":"researcher\/39990560_Kay_C_Wiese","fullname":"Kay C. Wiese","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Nov 2015","journal":"International Journal of Intelligent Computing and Cybernetics","showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/283648490_Diploidy_in_evolutionary_algorithms_for_dynamic_optimization_problems","usePlainButton":true,"publicationUid":283648490,"feedStubs":null,"hasFeedStubs":false,"impactPoints":false,"url":"publication\/283648490_Diploidy_in_evolutionary_algorithms_for_dynamic_optimization_problems","title":"Diploidy in evolutionary algorithms for dynamic optimization problems","displayTitleAsLink":true,"authors":[{"id":74654794,"url":"researcher\/74654794_Boris_Shabash","fullname":"Boris Shabash","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":39990560,"url":"researcher\/39990560_Kay_C_Wiese","fullname":"Kay C. Wiese","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["International Journal of Intelligent Computing and Cybernetics 11\/2015; 8(4):312-329. DOI:10.1108\/IJICC-07-2015-0026"],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/283648490_Diploidy_in_evolutionary_algorithms_for_dynamic_optimization_problems","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/283648490_Diploidy_in_evolutionary_algorithms_for_dynamic_optimization_problems\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw17_56aba22853fca"},"id":"rgw17_56aba22853fca","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=283648490","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"viewClass":"sidebar","widgetId":"rgw14_56aba22853fca"},"id":"rgw14_56aba22853fca","partials":[],"templateName":"publicliterature\/stubs\/SimilarPublications.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.SimilarPublications.html?referencePublicationId=220514418&view=sidebar","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationFulltextPreview":null,"publicationResourcesFulltext":{"data":{"publicationUid":220514418,"publicationResourceList":{"data":{"publicationResourceItems":[{"data":{"publicationUid":220514418,"publicationType":"article","linkId":"563e857b08ae45b5d28c5bc8","fileName":"SECPublished.pdf","fileUrl":"profile\/Yaochu_Jin\/publication\/220514418_Surrogate-assisted_evolutionary_computation_Recent_advances_and_future_challenges\/links\/563e857b08ae45b5d28c5bc8.pdf","name":"Yaochu Jin","nameUrl":"profile\/Yaochu_Jin","canRemove":false,"fileIcon":"ico-pub","canPreview":true,"hasPublisherLink":null,"hasMetaData":true,"hide":false,"fulltext":"ico-pub","origin":"publication_list","isLastLink":false,"isUserLink":true,"uploadDate":"Nov 8, 2015","fileSize":"747.92 KB","widgetId":"rgw20_56aba22853fca"},"id":"rgw20_56aba22853fca","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceItem.html","templateExtensions":["generalHelpers"],"attrs":{"fileRequiredPublicationTypes":["code","coverPage","experimentFindings","method","negativeResults","presentation","rawData","researchProposal","workingPaper","artifact","dataset"]},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceItem.html?publicationUid=220514418&linkId=563e857b08ae45b5d28c5bc8&hide=0&disableJavascript=disableJavascript&useAlternativeTemplate=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"widgetId":"rgw19_56aba22853fca"},"id":"rgw19_56aba22853fca","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceList.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceList.html?publicationUid=220514418&limit=3&disableJavascript=disableJavascript&type=fulltextFile","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"resourceCount":1,"hidden":false,"showMore":false,"fulltext":true,"publicationDownloadCount":{"data":{"value":4,"valueFormatted":"4","widgetId":"rgw21_56aba22853fca"},"id":"rgw21_56aba22853fca","partials":[],"templateName":"publicliterature\/stubs\/PublicationDownloadCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDownloadCount.html?publicationUid=220514418","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw18_56aba22853fca"},"id":"rgw18_56aba22853fca","partials":[],"templateName":"publicliterature\/stubs\/PublicationResources.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResources.html?publicationUid=220514418&type=fulltextFile&disableJavascript=1","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationResourcesAttachments":{"data":{"publicationUid":220514418,"publicationResourceList":{"data":{"publicationResourceItems":[],"widgetId":"rgw23_56aba22853fca"},"id":"rgw23_56aba22853fca","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceList.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceList.html?publicationUid=220514418&limit=3&disableJavascript=disableJavascript&type=attachmentFile","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"resourceCount":0,"hidden":true,"showMore":false,"fulltext":false,"publicationDownloadCount":{"data":{"value":4,"valueFormatted":"4","widgetId":"rgw24_56aba22853fca"},"id":"rgw24_56aba22853fca","partials":[],"templateName":"publicliterature\/stubs\/PublicationDownloadCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDownloadCount.html?publicationUid=220514418","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw22_56aba22853fca"},"id":"rgw22_56aba22853fca","partials":[],"templateName":"publicliterature\/stubs\/PublicationResources.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResources.html?publicationUid=220514418&type=attachmentFile","viewClass":"views.publicliterature.PublicationResourcesView","yuiModules":["rg.views.publicliterature.PublicationResourcesView"],"stylesheets":[],"_isYUI":true},"publicationText":{"data":{"hide":false,"pages":[{"page":1,"text":"Swarm and Evolutionary Computation 1 (2011) 61\u201370\nContents lists available at ScienceDirect\nSwarm and Evolutionary Computation\njournal homepage: www.elsevier.com\/locate\/swevo\nSurvey paper\nSurrogate-assisted evolutionary computation: Recent advances and\nfuture challenges\nYaochu Jin\nDepartment of Computing, University of Surrey, Guildford, Surrey, GU2 7XH, UK\na r t i c l ei n f o\nArticle history:\nReceived 6 February 2011\nReceived in revised form\n20 April 2011\nAccepted 14 May 2011\nAvailable online 6 June 2011\nKeywords:\nEvolutionary computation\nSurrogates\nMeta-models\nMachine learning\nExpensive optimization problems\nModel management\na b s t r a c t\nSurrogate-assisted, or meta-model based evolutionary computation uses efficient computational models,\noften known as surrogates or meta-models, for approximating the fitness function in evolutionary\nalgorithms. Research on surrogate-assisted evolutionary computation began over a decade ago and\nhas received considerably increasing interest in recent years. Very interestingly, surrogate-assisted\nevolutionary computation has found successful applications not only in solving computationally\nexpensive single- or multi-objective optimization problems, but also in addressing dynamic optimization\nproblems, constrained optimization problems and multi-modal optimization problems. This paper\nprovides a concise overview of the history and recent developments in surrogate-assisted evolutionary\ncomputation and suggests a few future trends in this research area.\n\u00a9 2011 Elsevier B.V. All rights reserved.\n1. Introduction\nIn most evolutionary algorithms, it is often implicitly assumed\nthat there exists a means for evaluating the fitness value of\nall individuals in a population. In general, the fitness value\nof an individual can be computed using an explicit fitness\nfunction, a computational simulation, or an experiment. In\npractice, however, fitness evaluations may become non-trivial.\nSuch situations typically occur when evolutionary algorithms are\nemployed to solve expensive optimization problems, where either\nthe computational simulation for each fitness evaluation is highly\ntime-consuming, or the experiments for fitness estimation are\nprohibitivelycostly,orananalyticalfunctionforfitnessevaluations\nsimply does not exist.\nSurrogate-assisted evolutionary computation was mainly\nmotivated from reducing computational time in evolutionary op-\ntimization of expensive problems, such as aerodynamic design op-\ntimization [1] or drug design [2], where complex computational\nsimulations are involved.\nIn principle, surrogates should be used together with the\nreal fitness function, as long as such a fitness function exists to\nprevent the evolutionary algorithm from being misled by a false\nminimum introduced by the surrogates [3]. A strategy for properly\nusing the surrogates is often known as model management or\nevolution control. In surrogate-assisted evolutionary optimization\nE-mail address: yaochu.jin@surrey.ac.uk.\nof expensive problems, in particular when the problems are\nof high-dimension, the development of a model management\nstrategy remains a challenging research topic.\nThe remainder of the paper is organized as follows. Section 2\ntakes a brief look back at the history of surrogate-assisted evolu-\ntionary computation starting from the late 1990s. Representative\nmodel management strategies are discussed in Section 3, which\ndistinguish themselves into managing a single surrogate, homo-\ngeneous multiple surrogates, and heterogeneous multiple surro-\ngates. Application of surrogates to addressing problems other than\nexpensive optimization in evolutionary computation is presented\ninSection4.Applicationexamplesofmeta-modelbasedevolution-\nary optimization are briefly accounted in Section 5. A few promis-\ning yet challenging research topics are suggested in Section 4. The\npaper concludes with a brief summary in Section 7.\n2. A brief look back\nResearch on evolutionary optimization using approximate\nfitness evaluations was first reported in the mid-1980s [4],\nand sporadic yet increasing research results on evolutionary\noptimization using computational models for fitness estimation\nappeared after the mid-1990s [5\u20139]. The first event devoted to\nresearch on using surrogates in evolutionary optimization was\na workshop held in 2002 within the Genetic and Evolutionary\nComputation Conference (GECCO) [10]. Since then, a series of\nspecial sessions and workshops have been organized on the major\nconferences including GECCO and IEEE Congress on Evolutionary\n2210-6502\/$ \u2013 see front matter \u00a9 2011 Elsevier B.V. All rights reserved.\ndoi:10.1016\/j.swevo.2011.05.001"},{"page":2,"text":"62\nY. Jin \/ Swarm and Evolutionary Computation 1 (2011) 61\u201370\nComputation, and journal special issues have also been edited.\nAn overview of the research on surrogated-assisted evolutionary\noptimization reported in various fields was first presented in\na conference paper [11], and then a journal paper in a special\nissue [12]. A first tutorial on fitness approximation on evolutionary\noptimization was given at the GECCO in 2005. Most recently, an\nedited book on the use of surrogates in evolutionary computation\nwas also published [13].\nIn the review paper [12], the importance of managing\nsurrogates was emphasized for the first time to prevent the\nevolutionary algorithms from being misled to a false optimum\nthat can be introduced in a surrogate. In that review, methods for\nmanaging surrogates in evolutionary computation were divided\ninto three categories, namely, individual-based, generation-based\nand population-based strategies. A variety of computational\nmodels, including polynomials (also known as response surface\nmethodologies in the field of traditional design optimization),\nGaussian processes (also known as Kriging in traditional design\noptimization), neural networks, together with data sampling\ntechniques such as design of experiments, active learning and\nboosting were also presented. Practically, fitness inheritance from\nparents or fitness imitation from siblings [14\u201316] can be seen as\na sort of simplified yet effective interpolation technique. General\nissues such as the global and local approximation, approximation\nof nonlinear constraints and the use of multiple surrogates having\nvarious fidelities were discussed. Theoretical analysis of the\nconvergence properties was also raised.\nSince the review paper [12], very encouraging research\nprogresses have been made in many of the areas, whereas\nsome issues remain unsolved, in particular with respect to a\nrigorous theoretical support for the benefit for using surrogates\nin evolutionary computation. Note that this paper focuses on\nsurrogates in evolutionary computation. Readers interested in\nrecent developments of surrogate-assisted design and analysis\nmethods are referred to [17,18].\nThe next section provides a brief overview of recent advances\nin the research on surrogate-assisted evolutionary optimization,\nemphasizing on the progresses made after the review paper [12].\nResearch on using surrogates beyond solving expensive problems\nis discussed in Section 4. A few challenging topics for future\nresearch are suggested in Section 6. A summary of the paper is\ngiven in Section 7.\n3. Strategies for managing surrogates\nIn most real-world optimization problems, no analytical\nfitness function exists for accurately evaluating the fitness of\na candidate solution. Instead, there are only more accurate\nand less accurate fitness estimation methods, which often\ntrade off accuracy with computational costs, as illustrated in\nFig. 1. For example, in evolutionary optimization of aerodynamic\nstructures [1], wind tunnel experiments may provide the most\naccurate estimation of the quality of candidate designs. The cost\nof such experiments is often prohibitively high. In addition, three-\ndimensional (3-D) computational fluid dynamic (CFD) simulations\nusing Navier\u2013Stokes equations may provide very accurate fitness\nevaluations. Unfortunately, such CFD simulations are highly time-\nconsuming,whichcantakehoursorevendaysforonesinglefitness\nevaluation. Computationally more efficient simulations can be\nachieved by 2-D full simulations or even incomplete simulations.\nBy incomplete simulation, we mean that a simulation process is\nstopped before it converges. The computationally most efficient\nway for estimating fitness is the use of machine learning models,\ni.e., surrogates. Note, however that this graphic only shows a\nsimplified version of actual levels of accuracy.\nFig. 1.\nand computational cost. Usually, high-fidelity fitness evaluations are more time-\nconsuming. By contrast, low-fidelity fitness evaluations are often less time-\nconsuming.\nAn illustration of a trade-off between fidelity (approximation accuracy)\nIn the research of surrogate-assisted evolutionary optimiza-\ntion, most algorithms have been developed based on benchmark\nproblems, where it is assumed that fully accurate fitness evalu-\nations can be provided. Such fitness functions are often termed\n\u2018\u2018real fitness function\u2019\u2019 or \u2018\u2018original fitness function\u2019\u2019. In the follow-\ning, we use surrogates for denoting computational models con-\nstructed with data, whereas other approximate fitness techniques\nsuch as full or incomplete 2-D CFD simulations are called prob-\nlem approximations as termed in [12]. In addition, we do not dis-\ntinguish between surrogate-assisted single objective optimization\nand surrogate-assisted multi-objective optimization if the method\nfor model management does not differ.\nIn the early work on surrogate-assisted evolutionary opti-\nmization, the evolutionary search is based solely on a surrogate,\nassuming that the surrogate can provide sufficiently accurate fit-\nness evaluations. However, such assumptions can give rise to seri-\nous problems if the surrogate introduces optima that do not exist\nin the original optimization problem. This issue was first explic-\nitly raised in [3] to stress the importance of model management in\nsurrogate-assisted evolutionary optimization, mainly by using the\nsurrogate together with the real fitness function.\nSurrogates can be applied to almost all operations of evolution-\nary algorithms, such as population initialization, cross-over, mu-\ntation, local search and fitness evaluations, as illustrated in Fig. 2.\nFor instance, a surrogate can be used for filtering out poor solu-\ntions in population initialization, crossover [19] or mutation [20].\nThe use of surrogates in initialization, mutation or crossover [21]\ncan reduce the randomness in the genetic operators, thus termed\ninformed operators. Most recently, a similar approach is adopted\nfor multi-objective optimization [22], where a single, aggregated\nmeta-model is built to pre-screen candidate solutions before fit-\nness evaluation. The requirement on the quality of surrogates is\nminimum, as an estimated fitness that is better than a random\nguess is adequate.\nTechniques for managing surrogates for fitness evaluations\ncan generally be divided into individual-based, generation-based\nand population-based [12]. By generation-based, we mean that\nsurrogates are used for fitness evaluations in some of the\ngenerations, while in the rest of the generations, the real fitness\nfunction is used [8,23,24,7]. By contrast, in individual-based model\nmanagement techniques, the real-fitness function is used for\nfitness evaluations for some of the individuals in a generation\n[25,3,23]. In population-based approaches, more than one sub-\npopulation co-evolves, each using its own surrogate for fitness"},{"page":3,"text":"Y. Jin \/ Swarm and Evolutionary Computation 1 (2011) 61\u201370\n63\nFig. 2. A diagram for an evolutionary algorithm for optimization of a turbine blade.\nA star denotes an evolutionary operation where a surrogate can be helpful.\nevaluations. Migration of individuals from one sub-population to\nanother is allowed.\nA strategy closely related to the above methods is the\npre-selection strategy [26]. Pre-selection does not exactly fall\nin individual-based strategies. Assume the population size is\n\u03bb. In pre-selection, an initial offspring population contains \u03bb\u2032\nindividuals, where \u03bb\u2032> \u03bb are produced in each generation. Then,\nall\u03bb\u2032offspringindividualsareevaluatedusingthesurrogate.Based\non the fitness value obtained using the surrogate, only \u03bb offspring\nare kept and re-evaluated using the original fitness function.\nA main difference between individual-based strategies and pre-\nselection here is that in pre-selection, selection is always based\non the real fitness value whereas in individual-based methods,\nselectionmaybeconductedpartlybasedonfitnessvaluesfromthe\nsurrogate.\nThe main steps of one specific individual-based model manage-\nment method, termed best strategy, and the pre-selection method\nfor a (\u00b5, \u03bb) evolution strategy, (\u00b5, \u03bb)-ES, are illustrated in Fig. 3 (a)\nand (b), respectively. In a (\u00b5, \u03bb)-ES using best strategy, all \u03bb off-\nspring are first evaluated using the surrogate. Then, \u03bb\u22c6\u2264 \u03bb best\nindividuals according to the surrogate are re-evaluated using the\nexpensive real fitness function. As a result, it can happen that the\nfitness value of some of the selected \u00b5 parents is based on the sur-\nrogate. Contrary to that, in a (\u00b5, \u03bb)-ES using pre-selection, \u03bb\u22c6\u2265 \u03bb\noffspring are generated and then evaluated using the surrogate.\nThen, \u03bb best individuals are re-evaluated using the expensive real\nfitness function. Consequently, all the selected \u00b5 parents for the\nnext generation are evaluated by the real fitness function.\nA large category of surrogate-assisted evolutionary algorithms\nuse surrogates in local search only for both single [27,28] and\nmulti-objective optimization [29]. In this case, sophisticated\nmodel management methods developed in traditional design\noptimization [30], such as the trust-region method [31] can be\ndirectly employed.\nRecently, surrogates have also been used in stochastic search\nmethods other than evolutionary algorithms, such as surrogate-\nassisted simulated annealing [32] or surrogate-assisted artificial\nimmune systems [33].\nIn the following, we discuss a few interesting ideas for model\nmanagement, which are divided into two major categories \u2014 use\nof a single surrogate and multiple surrogates.\n3.1. Managing a single surrogate\nThe essential question to answer in surrogate-assisted evolu-\ntionary computation is which individuals should be chosen to be\nevaluated or re-evaluated using the real fitness function. As we\na\nb\nFig. 3. Two individual-based model management strategies. (a) Best strategy, and\n(b) Pre-selection strategy.\nassume fitness evaluations using the real fitness function is time-\nconsuming, the next question is how to adapt the number of in-\ndividuals to be evaluated with the real fitness function so that the\ntime for fitness evaluations can be reduced as much as possible,\nwhile the evolutionary algorithm can still find the global optimum.\nIn the following, we discuss a few issues related to the answer to\nthe above questions.\n3.1.1. Criteria for choosing individuals for re-evaluation\nThe most straightforward idea is to evaluate those individuals\nthat potentially have a good fitness value and the higher the\napproximation accuracy, the more often the surrogate can be\nused [3,23]. A slightly different idea is that representative\nindividuals can be chosen for re-evaluation by clustering the\npopulation into a number of crisp or fuzzy clusters. The individual\nclosest to each cluster center [34,15,35] or the best individual in\neach cluster [36,37] can be chosen for re-evaluation.\nIthasalsobeensuggestedthatindividualshavingalargedegree\nof uncertainty in approximation can be good candidates for re-\nevaluation [25,26]. This idea can be justified by two arguments.\nFirst, a large degree of uncertainty in approximation of the\nindividuals indicates that the fitness landscape around these\nsolutions has not been well explored and therefore may provide\na good chance of finding a better solution. Second, re-evaluation\nof these solutions may be the most effective in improving the"},{"page":4,"text":"64\nY. Jin \/ Swarm and Evolutionary Computation 1 (2011) 61\u201370\nFig. 4.\nadequately good for evolutionary search. Solid curves denote the original function\nand dashed curves are their approximation.\nExamples of surrogates that have a large approximation error but are\napproximation accuracy of the surrogate, similar to the idea of\nactive learning [38].\nTheestimationoftheapproximationerrorcanbeachievedwith\ndifferent methods. In [25], the degree of uncertainty is roughly set\nto be inversely proportional to the average distance to the closest\ndata samples used for constructing the surrogate. Alternatively, an\nensemble can be used for estimating the variance of the individual\nestimates given by an ensemble of surrogates. The most often\nused surrogate model for estimating model uncertainties is the\nGaussian processes [39], also known as the Kriging model [40].\nUnlike deterministic models, Gaussian processes provide an\nestimate of the fitness (mean) together with an estimate of the\nuncertainty (variance), which is a statistically sound boundary\nof the uncertainty in fitness estimation. Due to this property,\nGaussianprocesseshaveincreasinglybeenemployedassurrogates\nin evolutionary single- and multi-objective optimization [41\u201344].\nNote however, the computational cost for constructing Gaussian\nprocesses itself can be very high when the number of samples used\nis large and online learning of the Gaussian processes is non-trivial\nwhen new samples are available.\n3.1.2. Metrics for evaluating surrogates and adaptation\nNot much attention has been paid to adapting the frequency\nof using the surrogates. In [45], the model quality is estimated by\ncalculating the average approximation error after re-evaluation,\nwhich is used to adapt the frequency of using the surrogate in a\ngeneration-based model management method. Based on empirical\nobservations that large approximation errors must not mislead\nthe evolutionary search, see e.g., Fig. 4, a few metrics other than\napproximation error have been proposed in [46,45] in evaluating\nthe quality of surrogates. In the following, we present a few\nperformance measures for surrogates in great detail.\nThe most common measure for model quality or model fidelity\nis the mean squared error between the individual\u2019s real fitness\nvalue and the predicted fitness by the meta-model. However, from\nthe evolutionary perspective, selecting the right individuals for\nthe next generation is the main concern. For instance in Fig. 4,\nthe quality of the surrogate is poor in terms of approximation\naccuracy. However, an evolutionary algorithm searching on the\nsurrogate only will nevertheless find the right optimum. Consider\n(\u00b5,\u03bb)-selection with \u03bb \u2265 2\u00b5, which is of particular relevance\nin evolutionary optimization of complex real-world problems, the\nnumber of individuals that have been selected correctly using the\nsurrogate can be obtained by:\n\u03c1(sel.)=\u03be \u2212 \u27e8\u03be\u27e9\n\u00b5 \u2212 \u27e8\u03be\u27e9,\n(1)\nwhere \u03be (0 \u2264 \u03be\nindividuals, i.e., the number of individuals that would have also\nbeen selected if the real fitness function was used for fitness\n\u2264 \u00b5) is the number of correctly selected\nevaluations. The expectation\n\ued5b\u00b5\n\u27e8\u03be\u27e9 =\n\u00b5\n\u2212\nm=0\nm\nm\n\ued5f\ued5a\n\u03bb\u2212\u00b5\n\u00b5\u2212m\n\u03bb\n\u00b5\n\ued5e\n\ued5a\ued5e\n=\u00b52\n\u03bb\n(2)\nof \u03be in case random selection is used as a normalization in (1). It\ncan be seen that if all \u00b5 parent individuals are selected correctly,\nthe measure reaches its maximum of \u03c1(sel.)= 1, and that negative\nvalues indicate that the selection based on the surrogate is worse\nthan a random selection.\nThe measure \u03c1(sel.)only evaluates the absolute number of\ncorrectly selected individuals. If \u03c1(sel.)< 1, the measure does\nnot indicate whether the (\u00b5 + 1)-th or the worst offspring\nindividual has been selected, which may have significant influence\non the evolutionary process. Therefore, the measure \u03c1(sel.)can be\nextended to include the rank of the selected individuals, calculated\nbased on the real fitness function. A surrogate is assumed to be\ngood, if the rank of the selected individuals based on the model\nis above-average according to the rank based on the real fitness\nfunction.\nThedefinitionoftheextendedmeasure\u03c1(\u223csel.)isasfollows:The\nsurrogate achieves a grade of \u03bb \u2212 m, if the m-th best individual\nbased on the real fitness function is selected. Thus, the quality of\nthe surrogate can be indicated by summing up the grades of the\nselected individuals, which is denoted by \u03c0. It is obvious that \u03c0\nreaches its maximum, if all \u00b5 individuals are selected correctly:\n\u2212\n= \u00b5\n2\n\u03c0(max.)=\n\u00b5\nm=1\n(\u03bb \u2212 m)\n\ued5d\n\u03bb \u2212\u00b5 + 1\n\ued61\n.\n(3)\nSimilar to (1) the measure \u03c1(\u223csel.)is defined by transforming \u03c0\nlinearly, using the maximum \u03c0(max.)as well as the expectation\n\u27e8\u03c0\u27e9 =\u00b5\u03bb\n\u03c0 \u2212 \u27e8\u03c0\u27e9\n\u03c0(max.)\u2212 \u27e8\u03c0\u27e9.\nBesides these two problem-dependent measures for evaluating\nthe quality of the surrogate, two established measures \u2013 the\nrank correlation and the (continuous) correlation \u2013 partially fit\nthe requirements formulated above. The rank correlation can be\nexpressed by\n2for the case of a purely random selection:\n\u03c1(\u223csel.)=\n(4)\n\u03c1(rank)= 1 \u2212\nis a measure for the monotonic relation between the ranks of two\nvariables.Inourcase,dlisthedifferencebetweentheranksofthel-\nthoffspringindividualbasedontheoriginalfitnessfunctionandon\nthe approximate model. The range of\u03c1(rank)is the interval[\u22121;1].\nThe higher the value of\u03c1(rank), the stronger the monotonic relation\nwith a positive slope between the ranks of the two variables.\nIn contrast to \u03c1(\u223csel.), the rank correlation does not only take\nthe ranking of the selected individuals, but also the ranks of all\nindividuals into account.\nA slightly different quality measure can be defined by\ncalculatingthe(continuous)correlationbetweenthesurrogateand\nthe original fitness function.\nUsing the selection-based criterion [45] for evaluating surro-\ngates, an adaptation scheme has been suggested for adapting the\n6\n\u03bb \u2211\nl=0\nd2\nl\n\u03bb(\u03bb2\u2212 1),\n(5)"},{"page":5,"text":"Y. Jin \/ Swarm and Evolutionary Computation 1 (2011) 61\u201370\n65\nFig. 5.\nrecurrent neural networks for predicting converged fitness value.\nAn illustration of learning iterative fitness evolutionary process using\nnumberofindividualstobeevaluatedusingthesurrogate(\u03bb\u2032)[47].\nIt has been shown that \u03bb\u2032increases as the evolution proceeds, in-\ndicating that the quality of the surrogates improves. Interestingly,\nwhen noise is introduced into the fitness data samples, \u03bb\u2032first de-\ncreases and then increases again. The various selection based cri-\nteria suggested in [45] have been benchmarked for adapting the\nnumber of individuals to be re-evaluated by the real fitness func-\ntion [37]. The results, however, failed to show a clear advantage of\nany particular criterion.\n3.1.3. Improving approximation accuracy\nAlthough approximation quality is not the only criterion for\nsurrogates for fitness prediction in evolutionary optimization,\nimproving its approximation quality is desirable. Much work has\nbeen reported along this line. For example, in [3,23], regularization\nof the neural network model has been suggested to alleviate\noverfitting. Structure and parameter optimization of the surrogate\ncan co-evolve with the original optimization problem [46,48].\nOne of the main difficulties in improving the approximation\naccuracycanbeattributedtothehigh-dimensionalityinthedesign\nspace. To overcome this difficulty, the surrogate can be built up\nin a new space of a lower dimension using dimension reduction\ntechniques [49,50].\nIt is noticed that in many expensive optimization problems,\nthe fitness evaluation often consists of an iterative computation\nprocess, such as the numerical solution of differential equations\nin computational fluid dynamics simulations. In such cases,\nmany intermediate data will be produced before the simulation\nconverges. Such intermediate data can also be used for training\na surrogate in the first iterations and then the surrogate can be\nused for predicting the converged fitness [51]. An example of such\na process is illustrated in Fig. 5.\n3.2. Managing multiple surrogates\nMethods for multiple surrogates in evolutionary optimization\ndistinguish themselves in type and fidelity of the surrogates. For\nexample, a neural network ensemble has been used in [34], where\nall ensemble members are of the same type of feed-forward neural\nnetworks. Alternatively, multiple surrogates of different types,\nsuchaspolynomials,supportvectormachinesandneuralnetworks\ncan be used [52].\nA step further is to use surrogates of different fidelities.\nSurrogatesofdifferentfidelitiescanbeobtainedbyusingmodelsof\ndifferent complexities or different data sets. For instance, different\ntypes of training samples used for constructing the surrogates\ncan be generated from different problem approximations, such as\nwind-tunnel experiments, 3-D or 2-D CFD simulations. Another\nwayofgeneratingsurrogatesofheterogeneousfidelityistocontrol\nthecomplexityofthesurrogatesexplicitly,e.g.,byusingadifferent\nnumberoftrainingsamplesorbycontrollingthemodelcomplexity\nwith regularized learning [3] or a Pareto-based multi-objective\nlearning method [53].\nIn the following, we discuss the use of multiple surrogates in\nevolutionary optimization by dividing the methods into homoge-\nneous and heterogeneous multiple surrogates. By homogeneous\nmultiple surrogates, the fidelity of the surrogates are not explic-\nitly controlled, even if different types of surrogates are used. On\nthe contrary, heterogeneous surrogates vary in their fidelity due to\nan explicit control in model complexity or training data.\n3.2.1. Homogeneous multiple surrogates\nUse of ensembles for fitness approximation was suggested\nin [34], where it was shown that neural network ensembles\ncan improve the performance of surrogate-assisted evolutionary\noptimization in two aspects. First, ensembles can improve the\nquality in fitness prediction. Second, the variance of the predicted\nfitness of the ensemble members can help identify large prediction\nerrors so that false optima can be avoided.\nThe benefit of using multiple surrogates has also been shown\nempirically in many papers [54,55,52]. In this category of research,\nno explicit control of fidelity of the multiple surrogates is\nemployed. For example in [56,57] multiple surrogates such as\nKriging, polynomials, radial-basis-function networks (RBFN), and\nweightedaverageensembleareusedtodemonstratetheimproved\nrobustness of optimization. Polynomial and RBFN surrogates are\nemployed for multiobjective optimization and it was shown that\neach of the models performs better in different regions of the\nPareto front.\nMultiple surrogates have been used in evolutionary multi-\nobjective optimization [58]. In that work, a co-evolutionary\ngenetic algorithm for multiple-objective optimization based on\nsurrogates was introduced. After some fixed search intervals, the\nsurrogates that approximate different objectives are exchanged\nand shared among multiple sub-populations of genetic algorithms.\nSpatiallydistributedmultiplesurrogateshavebeenusedforfitness\napproximation in multi-objective optimization [59].\n3.2.2. Heterogeneous multiple surrogates\nAs illustrated in Fig. 1, in many real-world optimization\nproblems, various problem approximation techniques can be\nemployed. For example, in aerodynamic optimization 3-D or 2-D\nnumerical simulations can be used for estimating the quality of the\ndesigns in addition to wind tunnel experiments. In more extreme\nsituations, incomplete simulations can also be used, where a\nnumerical simulation is stopped earlier to reduce computation\ntime. Data from all these different processes can also be applied\nfor building up surrogates.\nThe motivation of explicitly controlling the fidelity of the\nsurrogates can also be justified by taking the computational costs\nof constructing surrogates into account. To reduce the cost for\nbuilding up surrogates, it makes good sense to use surrogates of a\nlower fidelity that can be obtained with less cost in the early stage\nof evolutionary optimization. Another more tricky motivation is to\ntake advantage of approximation errors introduced by surrogates,\nhoping to smoothen a rugged fitness landscape, or to increase the\ndiversity of the population, or simply to use data from incomplete\nsimulations.\nEarly work that uses heterogeneous multiple surrogates was\nreportedin[60,61],whereapopulation-basedmodelmanagement\nstrategy is used. In both papers, three sub-populations are used,"},{"page":6,"text":"66\nY. Jin \/ Swarm and Evolutionary Computation 1 (2011) 61\u201370\neach using a surrogate for fitness evaluations. In [60], individuals\nfrom a sub-population that use a surrogate of lower fidelity are\nallowed to migrate to the sub-population that uses a surrogate of\nhigher fidelity. The method presented in [61] is a minor variant\nof [60], where migration is allowed between all sub-populations.\nOneapproachtoreducingthecomputationalcostforconstruct-\ning surrogates is to use coarse surrogates (of lower fidelity) in\nthe early stage of the optimization and increase the quality of the\nsurrogate gradually as the search proceeds [6]. This idea of using\ncoarse-to-fine surrogates has been introduced into a surrogate-\nassisted evolutionary search in [42,62], where surrogates are used\nfor evolutionary multi-objective optimization.\nA more subtle way to control the fidelity of surrogates is to\nuse surrogates of a sufficiently good fidelity based on a correlation\nbased measure [63]. The fidelity control strategy was applied\nto a memetic algorithm in which the local search is based on\nsurrogates of a changing fidelity. The proposed method was\nevaluated empirically on an aerodynamic airfoil design problem\nand demonstrated that the use of a dynamic fidelity is able to\nimprove the search speed.\nThe idea of taking advantage of approximation errors intro-\nducedbysurrogateswasfurtherexploitedin[64].Inthatwork,two\ntypes of surrogates are used in the local search of an evolutionary\nmulti-objective optimization: One for getting a reliable local\nprediction and the other for a higher degree of diversity. Empir-\nical results show that an evolutionary search based on hetero-\ngeneous multiple models can considerably improve the search\nperformance, compared to surrogate-assisted evolutionary algo-\nrithms that use a single surrogate or homogeneous multiple\nsurrogates. Interestingly enough, the proposed algorithm also out-\nperforms its counterpart that uses an artificial perfect surrogate.\nDetailed analysis of the search processes confirmed the hypothe-\nsis that controlled approximation errors introduced by surrogates\ncanspeedupthesearchprocessinbothsingle-andmulti-objective\noptimization.\n3.3. Which model management strategy?\nAs we discussed above, surrogates can be used in population\ninitialization, crossover, mutation and preselection to pre-screen\ncandidatesolutions.Theadvantageoftheserelativelyconservative\napproaches to using surrogates is that they are less likely to\nmislead the search process. One concern might be that they may\ncause premature convergence. It is also less risky if a surrogate is\nused in a local search of memetic algorithms. The common feature\nof these approaches is that all individuals have been re-evaluated\nusing the original fitness function before selection.\nIn addition, among the model management strategies, the\nindividual-based model management may be more suited for\nsteady state evolution, or generational evolution implemented on\na single machine. By contrast, population-based and generation-\nbased model management is better for parallel implementation on\nheterogeneous machines having different speeds. An optimization\nstrategy may be desirable when multi-level surrogates having\ndifferentcomputationalcomplexitiesareusedonmachineshaving\ndifferent computational powers.\n4. Beyond evolutionary optimization of expensive problems\nIn addition to reducing the computation time in evolutionary\noptimization of expensive problems, surrogates can be useful in\naddressing other problems in evolutionary computation, such as\nthe use of surrogates for reducing fitness evaluations in search of\nrobust optimal solutions [65]. In addition, surrogates have been\nfound helpful in improving the efficiency of evolutionary algo-\nrithms for solving optimization with noisy fitness evaluations [66]\nor for solving multi-modal optimization with a very rugged fit-\nness landscape [6,67], where the purpose of using a surrogate is\nto smoothen the fitness landscape.\n4.1. Surrogates in interactive evolutionary computation\nIn interactive evolutionary computation, the fitness value of\neach individual is evaluated by human user subjectively [68].\nHuman fitness evaluations are necessary where no fitness function\nis available. For instance, when evolutionary algorithms are used\nfor aesthetic product design or art design. One main challenge of\ninteractiveevolutionarycomputationistheissueofhumanfatigue.\nTo address this problem to a certain degree, surrogates can be used\nto replace in part human evaluations. The main idea is to use a\nmachine learning model to predict the fitness value the human\nmay assign to a design based on history data [69\u201371].\n4.2. Surrogated-assisted evolution for solving dynamic optimization\nEvolutionary optimization of dynamic optimization problems\nhas become a popular research topic recently [12]. The primary\ngoal is to develop an evolutionary search strategy that can follow a\nmoving optimum or a moving Pareto front. To this end, a certain\ndegree of diversity in the population should be maintained or\na memory mechanism must be embedded in the evolutionary\nalgorithm.Memorymechanismsincludesub-populations,archives\nof optimal solutions found so far, or multiploidy in genetic\nrepresentation.\nIn addition to memory and diversity based strategies, antici-\npation and prediction of the change in the fitness function can\nbe helpful in solving dynamic problems more efficiently. In such\nstrategies, a surrogate can be helpful in learning the changing fit-\nness function [72\u201374].\n4.3. Surrogates for robust optimization\nIn evolutionary optimization of real-world problems, one is\nconcerned not only with the performance of the obtained optimal\nsolution, but also the sensitivity of the performance to small\nchangesinthedesignvariablesorintheenvironment.Ifanoptimal\nsolution is insensitive to such changes, the solution is known as\nrobust optimization.\nTo obtain robust optimal solutions using evolutionary algo-\nrithms, either implicit averaging or explicit averaging can be\nused [12], wherein an assumption on the probability distribution\nof the noise is often made. By contrast, one can predefine the al-\nlowed performance decrease and then search for an optimum that\nhas the maximum tolerance of changes in the design variables,\nwhich is termed inverse robust optimization [75]. In both explicit\naveraging based or inverse robust optimization, additional fitness\nevaluations are needed. To enhance the efficiency, some of these\nadditional fitness evaluations can be done based on a surrogate\n[76\u201378].\n4.4. Surrogates for constrained optimization\nMany optimization problems are subject to constraints. To\njudge if a candidate solution is feasible, the constraint functions\nneed to be frequently evaluated. Therefore, if the evaluations\nof constraint functions are time-consuming, it is desirable to\nreplace the constraint functions with computationally efficient\napproximate models [79].\nIn some real-world applications, an explicit constraint is not\navailable. For example in aerodynamic optimization, some of the\ncandidate designs may result in unstable computational fluid\ndynamic (CFD) simulations. In order to reduce the number of\nunnecessary, time-consuming CFD simulations, it is very helpful\nto judge whether a solution is feasible (e.g., converges in a CFD\nsimulation) before it is evaluated in a CFD simulation. Surrogates\ncan be used for this purpose [80,81].\nAn interesting idea of using surrogates in constrained opti-\nmization has been recently reported in [82], where surrogates are"},{"page":7,"text":"Y. Jin \/ Swarm and Evolutionary Computation 1 (2011) 61\u201370\n67\na\nb\nc\nFig. 6.\nevolutionary search [82]. (a) The true feasible region (shaded), which consists of\nthree separate sub-regions. (b) A linear approximation of the original constraints\nby using two data points, resulting in an enlarged single feasible region. (c) A more\naccurateapproximationoftheconstraintfunctionsandtheresultingfeasibleregion\nis close to real one.\nAn illustrative example of manipulating the constraints to facilitate\napplied to manipulate the shape and size of the feasible region to\neasethesolutionofhighlyconstrainedoptimizationproblems.The\nbasic idea is to deliberately enlarge the feasible region by build-\ning up a very simple surrogate for each constraint function. As the\nevolutionary optimization proceeds, the complexity of the surro-\ngates increases gradually so that the approximated feasible region\ncan converge to the real feasible region. An illustration of this ba-\nsic idea is given in Fig. 6. Simulation results on a set of benchmark\nproblems and a few structural design problems demonstrated that\nthe idea works well. Genetic programming based generation of in-\ncreasingly complex surrogates has also been reported [83].\n5. Real-world applications\nSurrogate-assisted\napplication driven. Thus, the effectiveness of surrogate-assisted\nevolutionaryoptimizationis more\nevolutionary algorithms need to be demonstrated in real-world\napplications. One intensively researched area is surrogate-assisted\ndesign optimization, such as turbine blades [9,23,84,85], air-\nfoils [27,86], forging [87], vehicle crash tests [88], multi-processor\nsystems-on-chip design [89] and injection systems [90]. Other ap-\nplications include drug design [2], protein design [5], hydroinfor-\nmatics [91] and evolutionary robotics [92]. We must note that\nnot many substantial successful applications of meta-model based\nevolutionary optimization have been reported, which, however\ndoesnotnecessarilymeannosuchworkhasbeendone.Somework\ncarried out in industry has not been published. We also want to\nnote that meta-model based evolutionary optimization has been\nincluded in a few commercial design software tools.\n6. Future challenges\nSurrogate-assisted evolutionary computation has achieved\nconsiderable advances over the past decade, not only in algorithm\ndesign, but also in real-world applications. Nevertheless, many\nchallenges remain to be addressed. In the following, we discuss a\nfewofthesechallengesandhopethatthesediscussionswilltrigger\nmore research efforts devoted to approaching these challenges.\n6.1. Theoretic work\nA wide range of trust-region methods have shown to converge\nto the global optimum [93] when a gradient-based method is\nused to search on the surrogate. Unfortunately, a convergence\nproof for surrogate-assisted evolutionary algorithms to the global\noptimum or to a local optimum is not straightforward, as a proof\nof any stochastic search algorithm to a global optimum is non-\ntrivial. Meanwhile, approximation errors introduced by surrogates\ncan usually neither be described by a Gaussian nor a uniform\ndistribution, which makes a quantitative analysis of the search\ndynamics on a surrogate very difficult, if not impossible.\nIf we go one step back, we may raise the question of whether\nwe can guarantee that a surrogate-assisted evolutionary algorithm\nconverges faster than its counterpart without using a surrogate\nusing the same number of expensive fitness evaluations. Again, no\ntheoretical work has been reported to show this.\n6.2. Multi-level, multi-fidelity heterogeneous surrogates\nUse of multi-level, multi-fidelity surrogates has already been\nsuggested in [12]. The heterogeneity can include the model type of\nthe surrogates and the degree of fidelity (modeling accuracy). On\nthe one hand, various surrogates, ranging from the deterministic\nlinear model (e.g., linear interpolation) to nonlinear models\n(e.g. feedforward neural networks, support vector machines)\nand to stochastic models, such as Gaussian processes (Kriging)\nand to dynamic models such as recurrent neural networks.\nMeanwhile, multi-fidelity models can be used either by using data\nfrom different problem approximations (e.g., 2D Navier\u2013Stokes\nsimulations and 3D Navier\u2013Stokes simulations) or experiments,\nor different degrees of incomplete simulations, or by deliberately\ncontrolling the complexity of the models.\nWhen heterogeneous surrogates are used, the computational\ntimes for fitness evaluations using different models can be very\ndifferent. To further improve the computational efficiency of\nthe whole evolutionary process, non-generational evolutionary\nalgorithms with grid-based or asynchronous computing structure\nmay be preferred [86,56].\n6.3. Surrogate-assisted combinatorial optimization\nSurrogate-assisted evolutionary algorithms have been studied\nextensively for continuous optimization. In real-world applica-\ntions, however, there are also many computationally intensive\ncombinatorial optimization problems, such as job shop scheduling"},{"page":8,"text":"68\nY. Jin \/ Swarm and Evolutionary Computation 1 (2011) 61\u201370\nand wireless network or mobile sensor network optimization. In\nsuch cases, discrete modeling techniques must be employed, e.g.,\nbinary neural networks [94]. In [95], an RNF neural network is ap-\nplied to assist a mixed integer evolution strategy for intravascu-\nlar ultrasound image analysis [95]. Recently, an integrated Kriging\nmodel is used for mobile network optimization [96].\n6.4. Surrogate-assisted dynamic optimization\nIf an expensive optimization is time-varying, evolutionary\nalgorithms for solving dynamic optimization problems must be\nadopted to track the moving optima or moving Pareto front [97].\nPractically, an optimal solution that is robust over time may be\nmore preferred [74]. In either case, the surrogate must be updated\nonline. Therefore, it may be of interest to introduce incremental\nlearning techniques [98] for efficient online learning when the\nobjective functions change over time.\n6.5. Rigorous benchmarking and test problems\nAlthough many surrogate-assisted evolutionary algorithms\nhave been proposed and demonstrated to be more efficient than\ntheir counterpart without using a surrogate, no rigorous compar-\native studies on surrogate-assisted evolutionary algorithms have\nbeen reported. This may be attributed to two reasons. First, no\nwidely accepted performance index for benchmarking surrogate-\nassisted evolutionary algorithms has been suggested. Second, no\nbenchmarkproblemsdedicatedtosurrogate-assistedevolutionary\nalgorithms have been proposed. Most work on surrogate-assisted\nevolutionary algorithms uses either standard test functions such\nas the Ackley function [99] or specific real-world applications for\nempirical evaluations. However, design of test problems relevant\nto real-world applications is non-trivial. Ideally, such test prob-\nlemsshouldreflectthemajordifficultiesinreal-worldapplications\nyet tractable for intensive empirical comparisons. As indicated\nin [1], expensive optimization problems such as aerodynamic de-\nsign optimization not only involve highly time-consuming fitness\nevaluations, the fitness landscape is often multi-modal as well. In\naddition, the CFD simulations may be unstable, resulting in many\nisolated infeasible solutions. Finally, the design space is very high\nand geometry representation may be critical for the efficiency of\nthe whole evolutionary design optimization.\n7. Summary\nSurrogate-assisted evolutionary algorithms are motivated from\nreal-world applications. As evolutionary algorithms are increas-\ningly applied to solving complex problems, research interests in\nsurrogate-assisted evolutionary algorithms have considerably in-\ncreased in recent years. This paper provides a brief overview of\nrecent advances in this research area and suggests a few chal-\nlenging issues that remain to be resolved in the future. We ex-\npect that successful resolution of these challenges heavily depends\non the progress in both optimization and learning, and new com-\nputing techniques such as grid computing [100] and cloud com-\nputing [101], with which more computing resources will be made\navailable to common users via computer networks.\nReferences\n[1] Y. Jin, B. Sendhoff, A systems approach to evolutionary multi-objective struc-\ntural optimization and beyond, IEEE Computational Intelligence Magazine 4\n(3) (2009) 62\u201376.\n[2] D. Douguet, e-LEA3D: A computational-aided drug design web server,\nNucleic Acids Research 38 (2010) w615\u2013w621.\n[3] Y. Jin, M. Olhofer, B. Sendhoff, On evolutionary optimization with approxi-\nmate fitness functions, in: Genetic and Evolutionary Computation Congress,\n2000, pp. 786\u2013793.\n[4] J.J. Grefenstette, J.M. Fitzpatrick, Genetic search with approximate fitness\nevaluations, in: Proceedings of the International Conference on Genetic\nAlgorithms and Their Applications, 1985, pp. 112\u2013120.\n[5] G. Schneider, J. Schuchhardt, P. Wrede, Artificial neural networks and\nsimulated molecular evolution are potential tools for sequence-oriented\nprotein design, CABIOS 10 (6) (1994) 635\u2013645.\n[6] D. Yang, S.J. Flockton, Evolutionary algorithms with a coarse-to-fine function\nsmoothing, in: IEEE International Conference on Evolutionary Computation,\n1995, pp. 657\u2013662.\n[7] A. Ratle, Accelerating the convergence of evolutionary algorithms by fitness\nlandscape approximation, in: Parallel Problem Solving from Nature, 1998,\npp. 87\u201396.\n[8] L. Bull, On model-based evolutionary computation, Soft Computing 3 (1999)\n76\u201382.\n[9] S. Pierret, Turbomachinery blade design using a Navier\u2013Stokes solver and\nartificial neural network, ASME Journal of Turbomachinery 121 (3) (1999)\n326\u2013332.\n[10] Y. Jin, S.J. Louis, K.M. Rasheed, Approximation and learning in evolutionary\ncomputation. GECCO Workshop, July 2002.\n[11] Y. Jin, B. Sendhoff, Fitness approximation in evolutionary computation \u2014\na survey, in: Genetic and Evolutionary Computation Conference, 2002,\npp. 1105\u20131112.\n[12] Y. Jin, A comprehensive survey of fitness approximation in evolutionary\ncomputation, Soft Computing 9 (1) (2005) 3\u201312.\n[13] Y.Tenne,C.-K.Goh(Eds.),ComputationalIntelligenceinExpensiveOptimiza-\ntion Problems, Springer, 2009.\n[14] M.M. Davarynejad, C.W. Ahn, J. Vranckena, J. van den Berga, C.A. Coello\nCoello, Evolutionary hidden information detection by granulation-based\nfitness approximation, Applied Soft Computing 10 (3) (2010) 719\u2013729.\n[15] H.S. Kim, S.B. Cho, An efficient genetic algorithms with less fitness evaluation\nby clustering, in: Congress on Evolutionary Computation, 2001, pp. 887\u2013894.\n[16] M. Salami, T. Hendtlass, The fast evaluation strategy for evolvable hardware,\nGenetic Programming and Evolvable Machines 6 (2) (2005) 139\u2013162.\n[17] A. Forrester, A. Sobester, A. Keane, Engineering Design via Surrogate\nModelling: A Practical Guide, John Wiley & Sons, 2008.\n[18] J.P.C. Kleijnen, Design and analysis of simulation experiments, in: Interna-\ntional Series in Operations Research & Management Science, Springer, 2009.\n[19] K. Anderson, Y. Hsu, Genetic crossover strategy using an approximation\nconcept, in: IEEE Congress on Evolutionary Computation, 1999, pp. 527\u2013533.\n[20] K. Abboud, M. Schoenauer, Surrogate deterministic mutation: Preliminary\nresults, in: Artificial Evolution, in: LNCS, 2002, pp. 919\u2013954.\n[21] K. Rasheed, H. Hirsh, Informed operators: speeding up genetic-algorithm-\nbased design optimization using reduced models, in: Genetic and Evolution-\nary Computation Conference, Morgan Kaufmann, 2000, pp. 628\u2013635.\n[22] I. Loshchilov, M. Schoenauer, S. Sebag, A mono surrogate for multiobjective\noptimization, in: Genetic and Evolutionary Computation Conference, 2010,\npp. 471\u2013478.\n[23] Y. Jin, M. Olhofer, B. Sendhoff, A framework for evolutionary optimization\nwith approximate fitness functions, IEEE Transactions on Evolutionary\nComputation 6 (5) (2002) 481\u2013494.\n[24] D. Lim, Y.-S. Ong, Y. Jin, B. Sendhoff, Trusted evolutionary algorithms, in: IEEE\nCongress on Evolutionary Computation, 2006, pp. 456\u2013463.\n[25] J. Branke, C. Schmidt, Fast convergence by means of fitness estimation, Soft\nComputing 9 (1) (2005) 13\u201320.\n[26] M. Emmerich, A. Giotis, M. Uezdenir, T. Baeck, K. Giannakoglou, Metamodel-\nassisted evolution strategies, in: Parallel Problem Solving from Nature,\nin: LNCS, Springer, 2002, pp. 371\u2013380.\n[27] Y.S. Ong, P.B. Nair, A.J. Keane, Evolutionary optimization of computationally\nexpensive problems via surrogate modeling, AIAA Journal 41 (4) (2003)\n687\u2013696.\n[28] Z. Zhou, Y.-S. Ong, M.-H. Lim, B.-S. Lee, Memetic algorithm using multi-\nsurrogates for computationally expensive optimization problems, Soft\nComputing 11 (10) (2007) 957\u2013971.\n[29] S.Z. Martinez, C.A. Coello Coello, A memetic algorithm with non gradient-\nbased local search assisted by a meta-model, in: Parallel Problem Solving\nfrom Nature, in: LNCS, Springer, 2010, pp. 576\u2013585.\n[30] J.-F.M. Barthelemy, Approximation concepts for optimum structural design\n\u2014 A review, Structural Optimization 5 (1993) 129\u2013144.\n[31] M. Celis, J.E. Dennis, R.A. Tapia, A trust region strategy for nonlinear equality\nconstrained optimization, in: P. Boggs, R. Byrd, R. Schnabel (Eds.), Numerical\nOptimization 1984, SIAM, Philadelphia, 1985, pp. 71\u201382.\n[32] H.K. Singh, T. Ray, W. Smith, Surrogate assisted simulated annealing\n(SASA) for constrained multi-objective optimization, in: IEEE Congress on\nEvolutionary Computation, 2010, pp. 1\u20138.\n[33] H.S. Bernardino, H.J.C. Barbosa, L.G. Fonseca, A faster clonal selection\nalgorithm for expensive optimization problems, in: Artificial Immune\nSystems, Springer, 2010, pp. 130\u2013143.\n[34] Y. Jin, B. Sendhoff, Reducing fitness evaluations using clustering techniques\nand neural network ensembles, in: Genetic and Evolutionary Computation\nConference, 2004, pp. 688\u2013699.\n[35] F. Mota, F. Gomide, Fuzzy clustering in fitness estimation models for genetic\nalgorithms and applications, in: IEEE International Conference on Fuzzy\nSystems, 2006, pp. 1388\u20131395.\n[36] L. Graening, Y. Jin, B. Sendhoff, Efficient evolutionary optimization using\nindividual-based evolution control and neural networks: A comparative\nstudy, in: European Symposium on Artificial Neural Networks, 2005,\npp. 273\u2013278."},{"page":9,"text":"Y. Jin \/ Swarm and Evolutionary Computation 1 (2011) 61\u201370\n69\n[37] L. Graening,\nMeta-models\nThree-dimensional Blade Optimization, Springer, 2007, pp. 225\u2013250\n(chapter 6).\n[38] S. Tong, Active learning: theory and applications. Ph.D. Thesis, Department of\nComputer Science, Stanford University, 2001.\n[39] D.J.C. MacKay, Introduction to gaussian processes, in: C.M. Bishop (Ed.),\nNeural Networks and Machine Learning, Springer, 1998, pp. 133\u2013165.\n[40] J. Sacks, W.J. Welch, T.J. Mitchell, H.P. Wynn, Design and analysis of computer\nexperiments, Statistical Science 4 (1989) 409\u2013435.\n[41] D. Buche, N.N. Schraudolph, P. Koumoutsakos, Accelerating evolutionary\nalgorithms with gaussian process fitness function models, IEEE Transactions\non Systems, Man, and Cybernetics, Part C: Applications and Reviews 35 (2)\n(2005) 183\u2013194.\n[42] M. Emmerich, K.C. Giannakoglou, B. Naujoks, Single- and multiobjective\nevolutionary optimization assisted by gaussian random field metamodels,\nIEEE Transactions on Evolutionary Computation 10 (4) (2006) 421\u2013439.\n[43] J.Knowles,Parego:ahybridalgorithmwithon-linelandscapeapproximation\nfor expensive multiobjective optimization problems, IEEE Transactions on\nEvolutionary Optimization 10 (1) (2006) 50\u201366.\n[44] Q. Zhang, W. Liu, E. Tsang, B. Virginas, Expensive multiobjective optimization\nby MOEA\/D with gaussian process model, IEEE Transactions on Evolutionary\nComputation 14 (3) (2010) 456\u2013474.\n[45] Y. Jin, M. Huesken, B. Sendhoff, Quality measures for approximate models in\nevolutionary computation, in: Proceedings of GECCO Workshops: Workshop\non Adaptation, Learning and Approximation in Evolutionary Computation,\n2003, pp. 170\u2013174.\n[46] M. Huesken, Y. Jin, B. Sendhoff, Structure optimization of neural networks for\naerodynamic optimization, Soft Computing 9 (1) (2005) 21\u201328.\n[47] H. Ulmer, F. Streichert, A. Zell, Evolution strategies with controlled model\nassistance, in: Congress on Evolutionary Computation, 2004, pp. 1569\u20131576.\n[48] M. Schmidt, H. Lipson, Coevolution of fitness predictors, IEEE Transactions on\nEvolutionary Computation 12 (6) (2008) 736\u2013749.\n[49] Y. Tenne, K. Izui, S. Nishiwaki, Dimensionality-reduction frameworks\nfor computationally expensive problems, IEEE Congress on Evolutionary\nComputation, 2010, pp. 1\u20138.\n[50] Z. Zhou, Y.S. Ong, P.B. Nair, A.J. Keane, K.Y. Lum, Combining global and local\nsurrogate models to accelerate evolutionary optimization, IEEE Transactions\non Systems, Man, and Cybernetics, Part C: Applications and Reviews 37 (1)\n(2007) 66\u201376.\n[51] Y. Cao, Y. Jin, M. Kowalczykiewicz, B. Sendhoff, Prediction of convergence dy-\nnamics of design performance using differential recurrent neural networks,\nin: International Joint Conference on Neural Networks, 2008, pp. 529\u2013534.\n[52] Y. Tenne, S.W. Armfield, A framework for memetic optimization using\nvariableglobalandlocalsurrogatemodels,SoftComputing13(2009)81\u2013793.\n[53] Y. Jin, B. Sendhoff, Pareto-based multi-objective machine learning: an\noverview and case studies, IEEE Transactions on Systems, Man, and\nCybernetics, Part C: Applications and Reviews 38 (3) (2008) 397\u2013415.\n[54] T. Goel, R.T. Haftka, W. Shyy, N.V. Queipo, Ensemble of surrogates, Structural\nand Multidisciplinary Optimization 33 (3) (2007) 199\u2013216.\n[55] E. Sanchez, S. Pintos, N.V. Queipo, Toward an optimal ensemble of\nkernel-based approximations with engineering applications, Structural and\nMultidisciplinary Optimization 36 (3) (2008) 247\u2013261.\n[56] D. Lim, Y.S. Ong, Y. Jin, B. Sendhoff, A study on metamodeling techniques,\nensembles, and multi-surrogates in evolutionary computation, in: Genetic\nand Evolutionary Computation Conference, 2007, pp. 1288\u20131295.\n[57] A. Samad, K.-Y. Kim, Multiple surrogate modeling for axial compressor blade\nshape optimization, Journal of Propulsion Power 24 (2) (2008) 302\u2013310.\n[58] D. Chafekar, L. Shi, K. Rasheed, J. Xuan, Constrained multi-objective ga\noptimization using reduced models, IEEE Transactions on Systems, Man and\nCybernetics, Part C: Applications and Reviews 35 (2) (2005) 261\u2013265.\n[59] A. Isaacs, T. Ray, W. Smith, An evolutionary algorithm with spatially\ndistributedsurrogatesformultiobjectiveoptimization,in:The3rdAustralian\nConference on Progress in Artificial Life, 2007, pp. 257\u2013268.\n[60] D. Eby, R. Averill, W. Punch, E. Goodman, Evaluation of injection island model\nga performance on flywheel design optimization, in: Third Conference on\nAdaptive Computing in Design and Manufacturing, 1998, pp. 121\u2013136.\n[61] M. Sefrioui, J. Periaux, A hierarchical genetic algorithm using multiple\nmodels for optimization, in: Parallel Problem Solving from Nature, 2000,\npp. 879\u2013888.\n[62] P.K.S. Nain, K. Deb, Computationally effective search and optimization\nprocedure using coarse to fine approximation, in: IEEE Congress on\nEvolutionary Computation, 2003, pp. 2081\u20132088.\n[63] D. Lim, Y.S. Ong, Y. Jin, B. Sendhoff, Evolutionary optimization with dynamic\nfidelity computational models, in: International Conference on Intelligent\nComputing, in: LNCS, Springer, 2008, pp. 235\u2013242.\n[64] D. Lim, Y. Jin, Y.S. Ong, B. Sendhoff, Generalizing surrogate-assisted\nevolutionary computation, IEEE Transactions on Evolutionary Computation\n14 (3) (2010) 329\u2013355.\n[65] J. Branke, Creating robust solutions by means of evolutionary algorithms,\nin: Parallel Problem Solving from Nature, in: LNCS, Springer, 1998,\npp. 119\u2013128.\n[66] M. Bhattacharya, Reduced computation for evolutionary optimization in\nnoisy environment, in: Genetic and Evolutionary Computation Conference,\n2008, pp. 2117\u20132122.\nY.\nfor\nJin,B. Sendhoff, Individual-based\nOptimization\nManagement\nApplications\nof\nto Evolutionary with\n[67] K.-H. Liang, X. Yao, C. Newton, Evolutionary search of approximated n-\ndimensional landscapes, International Journal of Knowledge-Based Intelli-\ngent Engineering Systems 4 (3) (2000) 172\u2013183.\n[68] H. Takagi, Interactive evolutionary computation: fusion of the capabilities\nof ec optimization and human evaluation, Proceedings of IEEE 89 (2002)\n1275\u20131296.\n[69] J.A. Biles, P.G. Anderson, L.W. Loggi, Neural network fitness functions for a\nmusical IGA, in: The International ICSC Symposium on Intelligent Industrial\nAutomation and Soft Computing, 1996.\n[70] R.R Kamalian, A.M. Agogino, H. Takagi, Use of interactive evolutionary\ncomputation with simplified modeling for computationally expensive layout\ndesign optimization, in: IEEE Congress on Evolutionary Computation, 2007,\npp. 4124\u20134129.\n[71] X. Sun, D. Gong, S. Li, Classification and regression-based surrogate model\n- Assisted interactive genetic algorithm with individual fuzzy fitness, in:\nGenetic and Evolutionary Computation Conference, 2009, pp. 907\u2013914.\n[72] A. Zhou, Y. Jin, Q. Zhang, B. Sendhoff, E. Tsang, Prediction-based population\nre-initialization for evolutionary dynamic multi-objective optimization,\nin: The Fourth International Conference on Evolutionary Multi-Criterion\nOptimization, in: LNCS, Springer, 2007, pp. 832\u2013846.\n[73] I. Hatzakis, D. Wallace, Dynamic multi-objective optimization with evolu-\ntionary algorithms: a forward-looking approach, in: Genetic and Evolution-\nary Computation Conference, 2006, pp. 1201\u20131208.\n[74] X. Yu, Y. Jin, K. Tang, X. Yao, Robust optimization over time \u2014 a new\nperspectiveondynamicoptimizationproblems,in:CongressonEvolutionary\nComputation, 2010, pp. 3998\u20134003.\n[75] D. Lim, Y.-S. Ong, Y. Jin, B. Sendhoff, B.S. Lee, Inverse multi-objective robust\nevolutionary optimization, Genetic Programming and Evolvable Machines 7\n(4) (2006) 383\u2013404.\n[76] D. Lim, Y.-S. Ong, M.-H. Lim, Y. Jin, Single\/multi-objective inverse robust\nevolutionary design methodology in the presence of uncertainty, in: S. Yang,\nY.S. Ong, Y. Jin (Eds.), Evolutionary Computation in Dynamic and Uncertain\nEnvironments, Springer, 2007, pp. 437\u2013456.\n[77] Y.-S. Ong, P.B. Nair, K.Y. Lum, Max\u2013min surrogate-assisted evolutionary\nalgorithm for robust design, IEEE Transactions on Evolutionary Computation\n10 (4) (2006) 392\u2013404.\n[78] I. Paenke, J. Banke, Y. Jin, Efficient search for robust solutions by means\nof evolutionary algorithms and fitness approximation, IEEE Transactions on\nEvolutionary Computation 10 (4) (2006) 405\u2013420.\n[79] T.P. Runarsson, Constrained evolutionary optimization by approximate\nranking and surrogate models, in: Parallel Problem Solving from Nature,\nin: LNCS, Springer, 2004, pp. 401\u2013410.\n[80] S.D. Handoko, C.K. Kwoh, Y.S. Ong, Feasibility structure modeling: an\neffective chaperon for constrained memetic algorithms, IEEE Transactions on\nEvolutionary Computation 14 (5) (2010) 740\u2013758.\n[81] Y. Tenne, K. Izui, S. Nishiwaki, Handling undefined vectors in expensive\noptimization problems, in: Applications of Evolutionary Computation,\nin: LNCS, Springer, 2010, pp. 582\u2013591.\n[82] Y. Jin, S. Oh, M. Jeon, Incremental approximation of nonlinear constraint\nfunctions for evolutionary constrained optimization, in: IEEE Congress on\nEvolutionary Computation, 2010, pp. 2966\u20132973.\n[83] S. Oh, Y. Jin, M. Jeon, Approximate models for constraint functions in\nevolutionary constrained optimization, International Journal of Innovative\nComputing, Information and Control 7 (10) (2011).\n[84] M.K. Karakasis, K.C. Giannakoglou, Metamodel-assisted multi-objective\nevolutionary optimization, in: Evolutionary and Deterministic Methods for\nDesign,OptimizationandControlwithApplicationstoIndustrialandSocietal\nProblems, EUROGEN, 2005.\n[85] A. Shahrokhi, A. Jahangirian, A surrogate assisted evolutionary optimization\nmethod with application to the transonic airfoil design, Engineering\nOptimization 42 (6) (2010) 497\u2013515.\n[86] V.G. Asouti, I.C. Kampolis, K.C. Giannakoglou, A grid-enabled asynchronous\nmetamodel-assisted evolutionary algorithm for aerodynamic optimization,\nGenetic Programming and Evolvable Machines 10 (4) (2009) 373\u2013389.\n[87] M.H.A. Bonte, L. Fourment, T.-T. Do, A.H. van den Boogaard, J. Huetink,\nOptimization of forging processes using finite element simulations, Struc-\ntural Multidisciplinary Optimization 42 (2010) 797\u2013810.\n[88] K. Hamza, K. Saitou, Crashworthiness design using meta-models for\naprroximating the response of structural members, in: Cairo University\nConference on Mechanical Design and Production, 2004.\n[89] G. Mariani, G. Palermo, C. Silvano, V. Zaccaria, Meta-model assisted\noptimization for design space exploration of multi-processor systems-on-\nchip, in: 12th Euromicro Conference on Digital System Design, Architectures,\nMethods and Tools, 2009, pp. 383\u2013389.\n[90] G.Dellino,P.Lino,C.Meloni,A.Rizzo,Krigingmetamodelmanagementinthe\ndesign optimization of a cng injection system, Mathematics and Computers\nin Simulation 79 (8) (2009) 2345\u20132360.\n[91] S.-T.Khu,D.Savic,Z.Kapelan,Evolutionary-basedmeta-modellingvtherele-\nvance of using approximate models in hydroinformatics, in: Hydroinformat-\nics in Practice: Computational Intelligence and Technological Developments\nin Water Applications, Springer, 2008.\n[92] I.Dahm,J.Ziegler,Usingartificialneuralnetworkstoconstructameta-model\nfor the evolution of gait patterns, in: Proceedings of the 5th International\nConference on Climbing and Walking Robots, 2002.\n[93] M.J. Powell, On the convergence of a wide range of trust region methods for\nunconstrained optimization, IMA Journal of Numerical Analysis 30 (1) (2010)\n289\u2013301.\n[94] V.J. Hodge, K.J. Lees, J.L. Austin, A high performance k-nn approach using\nbinary neural networks, Neural Networks 17 (3) (2004) 441\u2013458."},{"page":10,"text":"70\nY. Jin \/ Swarm and Evolutionary Computation 1 (2011) 61\u201370\n[95] R. Li, M.T.M. Emmerich, J. Eggermont, E.G.P. Bovenkamp, T. B\u00e4ck, J. Dijkstra,\nJ.H.C. Reiber, Metamodel-assisted mixed integer evolution strategies and\ntheir application to intravascular ultrasound image analysis, in: IEEE\nCongress on Evolutionary Computation, 2008, pp. 2764\u20132771.\n[96] C. Ling, J.-H. Liang, B. Wu, Z.-W. Hu, A metamodel-based optimiza-\ntion method for mobile ad hoc networks, in: 2010 International Con-\nference on Computer Application and System Modeling, ICCASM, 2010,\npp. 412\u2013416.\n[97] Y. Jin, J. Branke, Evolutionary optimization in uncertain environments-\na survey, IEEE Transactions on Evolutionary Computation 9 (3) (2005)\n303\u2013317.\n[98] R. Polikar, L. Upda, S.S. Upda, V. Honavar, Learn++: An incremental learning\nalgorithm for supervised neural networks, IEEE Transactions on Systems,\nMan, and Cybernetics, Part C: Applications and Reviews 31 (4) (2001)\n479\u2013508.\n[99] D.H. Ackley, A Connectionist Machine for Genetic Hillclimbing, Kluwer\nAcademic Publishers, Norwell, MA, 1987.\n[100] W. Hendrickx, D. Gorisson, T. Dhaene, Grid enabled sequential design and\nadaptive metamodeling, in: Proceedings of the 2006 Winter Simulation\nConference, 2006.\n[101] M. Miller, Cloud Computing: Web-Based Applications That Change the Way\nYou Work and Collaborate Online, Que Publishing, 2008."}],"fullTextUrl":"https:\/\/www.researchgate.net\/profile\/Yaochu_Jin\/publication\/220514418_Surrogate-assisted_evolutionary_computation_Recent_advances_and_future_challenges\/links\/563e857b08ae45b5d28c5bc8.pdf","widgetId":"rgw25_56aba22853fca"},"id":"rgw25_56aba22853fca","partials":[],"templateName":"publicliterature\/stubs\/PublicationText.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationText.html?publicationUid=220514418&hide=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationDetailAd":{"data":{"googleDfpSlot":null,"widgetId":"rgw26_56aba22853fca"},"id":"rgw26_56aba22853fca","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAd.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAd.html?publicationUid=220514418&slotId=336x280_Publications_ATF_Right&collapseSlotMode=never&fallbackContainerEnabled=1","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationRelations":null,"publicationRelationsReverse":null,"publicationUid":220514418,"showSignUpDialog":false,"selectNewSignUpDialog":false,"publicationQuestions":null,"publicationCitations":null,"publicationReviewPromo":null,"publicationUsedInReviews":null,"publicationPdfJsReader":{"data":{"isPreview":false,"licenseUrl":null,"licenseInfo":null,"defaultLinkData":{"linkId":"563e857b08ae45b5d28c5bc8","name":"Yaochu Jin","date":"Nov 07, 2015 ","nameLink":"profile\/Yaochu_Jin","filename":"SECPublished.pdf","downloadLink":"https:\/\/www.researchgate.net\/profile\/Yaochu_Jin\/publication\/220514418_Surrogate-assisted_evolutionary_computation_Recent_advances_and_future_challenges\/links\/563e857b08ae45b5d28c5bc8.pdf?inViewer=0&pdfJsDownload=0&origin=publication_detail","viewerUrl":"https:\/\/www.researchgate.net\/profile\/Yaochu_Jin\/publication\/220514418_Surrogate-assisted_evolutionary_computation_Recent_advances_and_future_challenges\/links\/563e857b08ae45b5d28c5bc8.pdf?inViewer=1&pdfJsDownload=1&origin=publication_detail","downloadHash":"94beae482c9a6c058342b68821ab091c","showFileSizeNote":false,"fileSize":"747.92 KB","noFollow":false,"isDefault":true,"doi":null},"displayableLinks":[{"linkId":"563e857b08ae45b5d28c5bc8","name":"Yaochu Jin","date":"Nov 07, 2015 ","nameLink":"profile\/Yaochu_Jin","filename":"SECPublished.pdf","downloadLink":"https:\/\/www.researchgate.net\/profile\/Yaochu_Jin\/publication\/220514418_Surrogate-assisted_evolutionary_computation_Recent_advances_and_future_challenges\/links\/563e857b08ae45b5d28c5bc8.pdf?inViewer=0&pdfJsDownload=0&origin=publication_detail","viewerUrl":"https:\/\/www.researchgate.net\/profile\/Yaochu_Jin\/publication\/220514418_Surrogate-assisted_evolutionary_computation_Recent_advances_and_future_challenges\/links\/563e857b08ae45b5d28c5bc8.pdf?inViewer=1&pdfJsDownload=1&origin=publication_detail","downloadHash":"94beae482c9a6c058342b68821ab091c","showFileSizeNote":false,"fileSize":"747.92 KB","noFollow":false,"isDefault":true,"doi":null}],"hasDisplayableLinks":false,"reader":{"data":{"pdfCommentsActive":false,"publicationType":"Article","onlyRenderFirstPage":false,"readMoreExperimentGoal":"goalPublicationPdfClicksReadMore","readMoreExperimentViewId":null,"comments":null,"figures":[{"props":{"position":"float","orientation":"portrait","coords":"pag:4:rect:32.71,166.46,251.06,23.70","ordinal":"4"},"assetId":"AS:293293344342016@1446937990492"},{"props":{"position":"float","orientation":"portrait","coords":"pag:5:rect:42.52,248.50,251.06,15.13","ordinal":"5"},"assetId":"AS:293293344342017@1446937990510"}],"figureAssetIds":["AS:293293344342016@1446937990492","AS:293293344342017@1446937990510"],"figureOverlayUrls":{"clickOnOverlay":"publication.PublicationFigures.html?_sg=r0fIkAc8U6mbEuI8d06YztiVZLPruv128WtZLXoDKXCTUil40mnHRH0iJGMbf2gjkyM5gvJWPbfkdLlPOBtG3Q.JPGrVHsYr0G7tSF6j4qag79-gwunfpjyXAhvKwY-OMCs3CQZw78cE20TUnFUUfuv2XEcZSbaQsCSha2o1a10_g","clickOnPill":"publication.PublicationFigures.html?_sg=QIw8XJ9AxV-alKOo1wQpPLFQxTaL3nA-CFrVXNrpS5hrl4qNyW5tl2EE5H_IFRw9d2TtTLk9vslMVszvemXODQ.dpOkOlv4H0Emld4M2lK5HxBZ7ofF_YtnBUKVSmSV9Ta1enonuMxRxRCDHApw5TyBtgG3Xxb7rDGHYaGTOlTTXQ"},"canSelect":false,"javascriptPath":"https:\/\/www.researchgate.net\/c\/o1q2er\/","downloadUrl":"https%3A%2F%2Fwww.researchgate.net%2Fprofile%2FYaochu_Jin%2Fpublication%2F220514418_Surrogate-assisted_evolutionary_computation_Recent_advances_and_future_challenges%2Flinks%2F563e857b08ae45b5d28c5bc8.pdf%3FinViewer%3D1%26pdfJsDownload%3D1%26origin%3Dpublication_detail","viewerUrl":"https:\/\/www.researchgate.net\/c\/o1q2er\/javascript\/lib\/pdfjs\/web\/viewer.html","commentEndpoint":"https:\/\/www.researchgate.net\/rgformat\/api\/comment","experimentEndpoint":"https:\/\/www.researchgate.net\/rgformat\/api\/experiment?key=pkMgI5PXWQLPHa4lgJtBRNm05-fuhUnXHg39MAcAhV9YDIk3FDYA6Wj3lrAKImTfwg4RzOH4oU8srOaYNhq0ug","urlHash":"3c37d27959aab7e1191339b819bb206d","downloadTrackUrl":"application.PdfJsReader.ajaxTrackDownload.html?msrp=-xWgtvCtC5sy8uvwNjbOu7s6QzrxPLLSWP0KzJwRRuXggogK9FXPTWCV8QDuLRIaBmmnSsYIP1BCfbwXhZp1xr_E9To-H0ae_RQx3RbZnbg.jb870Rj3sfRj2JpgCXyx4igs8rml3Up2F0TkKEEHNOw9TfqTjlTNP7--R1xWm8Vu2qDGywMNlvw1gvLBGhtDgg.YHWHfXlx3MF_Lrbj-8P2C8S2UxlFQ29wv-M8C6BifN23jAc4VG-zHDXzUkb0EPTnMgEUeIAc9yQ4_vSAdfs89A","viewportMilestoneTrackUrl":"application.PdfJsReader.ajaxTrackViewportMilestone.html","linkId":"563e857b08ae45b5d28c5bc8","trackedDownloads":{"563e857b08ae45b5d28c5bc8":{"v":false,"d":false}},"assetId":"AS:293293297553408@1446937979550","readerDocId":"4495189","assetType":"fulltext","interactionType":{"comment":"comment","highlight":"highlight"},"publicationUid":220514418,"commentCursorPromo":null,"widgetId":"rgw28_56aba22853fca"},"id":"rgw28_56aba22853fca","partials":[],"templateName":"application\/stubs\/PdfJsReader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PdfJsReader.html?fileHref=https%3A%2F%2Fwww.researchgate.net%2Fprofile%2FYaochu_Jin%2Fpublication%2F220514418_Surrogate-assisted_evolutionary_computation_Recent_advances_and_future_challenges%2Flinks%2F563e857b08ae45b5d28c5bc8.pdf%3FinViewer%3D1%26pdfJsDownload%3D1%26origin%3Dpublication_detail&assetId=AS%3A293293297553408%401446937979550&publicationUid=220514418&linkId=563e857b08ae45b5d28c5bc8&onlyShowFirstPage=0","viewClass":null,"yuiModules":["css-pow-application-PdfJsReader"],"stylesheets":["pow\/application\/PdfJsReader.css"],"_isYUI":true},"showHeader":true,"title":"Surrogate-assisted evolutionary computation: Recent advances and future challenges","publicationType":"Article","downloadTrackUrl":"publicliterature.PublicationInlineReader.ajaxTrackDownload.html?msrp=15C3uM3Vx_54JdkvQORMq9PGlIuK8t2j0nZHfeXOnIuVgu5wh_CB5YvlYWou9nLUeahpXsOG4QHzLYPZ0Kl9uFaDEhWIsxs8EuvrvT9-Vas.6_uWQKQxu_G7nn6by30hHmqFRCD8d3iU1DYazs7CPiuqFQ7zQKq_GfFz_1GGTHx6kz3oS-LY2Vg33PMt-tpYaA.OKoaGdKIYRq6i1G7Eizh4nENfs0OCjwuz2DXJqISfShCOHXdbVZuMEt6EPcxZcj62gHteJO3207v4alXjQo6mA","publicationUid":220514418,"trackedDownloads":{"563e857b08ae45b5d28c5bc8":{"v":false,"d":false}},"inlinePdf":false,"publicationComments":null,"showDownloadButton":true,"socialShare":{"data":{"shareItems":[{"data":{"name":"Facebook","url":"http:\/\/www.facebook.com\/share.php?u={{url}}{{#title}}&t={{title}}{{\/title}}","width":600,"height":350,"useUtmTags":true,"utmSource":"facebook","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareFacebook.ajaxTrackSocialShare.html","widgetId":"rgw30_56aba22853fca"},"id":"rgw30_56aba22853fca","partials":{"shareIcon":"application\/stubs\/partials\/shareFacebookBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareFacebook.html?provider=Facebook&shareIcon=shareIconBlog&utmSource=facebook&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"Twitter","url":"http:\/\/twitter.com\/intent\/tweet?text={{#title}}{{title}}: {{\/title}}{{url}}&via=researchgate","width":600,"height":350,"useUtmTags":true,"utmSource":"twitter","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareTwitter.ajaxTrackSocialShare.html","widgetId":"rgw31_56aba22853fca"},"id":"rgw31_56aba22853fca","partials":{"shareIcon":"application\/stubs\/partials\/shareTwitterBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareTwitter.html?provider=Twitter&shareIcon=shareIconBlog&utmSource=twitter&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"Google+","url":"https:\/\/plus.google.com\/share?url={{url}}","width":600,"height":600,"useUtmTags":true,"utmSource":"googleplus","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareGooglePlus.ajaxTrackSocialShare.html","widgetId":"rgw32_56aba22853fca"},"id":"rgw32_56aba22853fca","partials":{"shareIcon":"application\/stubs\/partials\/shareGooglePlusBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareGooglePlus.html?provider=Google%2B&shareIcon=shareIconBlog&utmSource=googleplus&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"LinkedIn","url":"http:\/\/www.linkedin.com\/shareArticle?mini=true&url={{url}}{{#title}}&title={{title}}{{\/title}}&source=ResearchGate","width":520,"height":570,"useUtmTags":true,"utmSource":"linkedin","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareLinkedIn.ajaxTrackSocialShare.html","widgetId":"rgw33_56aba22853fca"},"id":"rgw33_56aba22853fca","partials":{"shareIcon":"application\/stubs\/partials\/shareLinkedInBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareLinkedIn.html?provider=LinkedIn&shareIcon=shareIconBlog&utmSource=linkedin&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"Reddit","url":"https:\/\/www.reddit.com\/submit?url={{url}}{{#title}}&title={{title}}{{\/title}}","width":600,"height":600,"useUtmTags":true,"utmSource":"reddit","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareReddit.ajaxTrackSocialShare.html","widgetId":"rgw34_56aba22853fca"},"id":"rgw34_56aba22853fca","partials":{"shareIcon":"application\/stubs\/partials\/shareRedditBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareReddit.html?provider=Reddit&shareIcon=shareIconBlog&utmSource=reddit&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true}],"widgetId":"rgw29_56aba22853fca"},"id":"rgw29_56aba22853fca","partials":[],"templateName":"application\/stubs\/SocialShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.SocialShare.html?campaign=shareFullTextPublication&trackClick=1&shareIcon=shareIconBlog","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw27_56aba22853fca"},"id":"rgw27_56aba22853fca","partials":[],"templateName":"publicliterature\/stubs\/PublicationInlineReader.html","templateExtensions":["generalHelpers"],"attrs":{"showFulltextDownloadedSignupDialog":true,"preSignUpDialogContext":null,"requestFulltext":false},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationInlineReader.html","viewClass":"views.publicliterature.PublicationInlineReaderView","yuiModules":["rg.views.publicliterature.PublicationInlineReaderView","css-pow-publicliterature-PublicationInlineReader"],"stylesheets":["pow\/publicliterature\/PublicationInlineReader.css"],"_isYUI":true},"useFulltextOptimizedLayout":false,"publicationActions":null,"requestFulltextPromo":null,"currentUrl":"publication\/220514418_Surrogate-assisted_evolutionary_computation_Recent_advances_and_future_challenges","isLeaderboardAd":false,"enableStickyBox":null,"googleDfpSlotMobileBottom":null,"fullTextExitPopup":null,"showExitPopupDialog":false,"widgetId":"rgw2_56aba22853fca"},"id":"rgw2_56aba22853fca","partials":{"romeo_legal_notice":"publicliterature\/stubs\/partials\/romeo_legal_notice.html"},"templateName":"publicliterature\/stubs\/PublicPublicationDetails_NewLayout.html","templateExtensions":["generalHelpers"],"attrs":{"publicationUid":220514418},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicPublicationDetailsOld.html?publicationUid=220514418&isTestOldDesign=0","viewClass":"views.publicliterature.PublicPublicationDetailsOldView","yuiModules":["rg.views.publicliterature.PublicPublicationDetailsOldView"],"stylesheets":[],"_isYUI":true},"widgetId":"rgw1_56aba22853fca"},"id":"rgw1_56aba22853fca","partials":[],"templateName":"publicliterature\/stubs\/PublicPublicationDetails.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicPublicationDetails.html","viewClass":"views.publicliterature.PublicPublicationDetailsView","yuiModules":["rg.views.publicliterature.PublicPublicationDetailsView"],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"uaClass":"","headPrefix":[],"rootUrl":"https:\/\/www.researchgate.net\/","requestToken":"7CWDssMOKkaTt2nRNzoaUz5VXDPHm\/b0g\/5DjZpp8jqBma5lC1PjeDIAPRtdDxI9rYEPZ7IS8ZKDaNAcsAW0bnwIzHgsG37SxOET3ghlwz6LG8o1ieilHw5dzu5usCefjna8O8jNkzkdzatS09kOyjun28FZTY50AsXtv3fsrhOQxx7UIYQS3c0W+\/HW0Ep8yGjnUh8sf2z4EY+NR+1pyjByebvPoJxo27elx\/OfG2sukWhD2zMD2MJFQCbSSRpLsumlf5fGhNMTaevMc99sDc7R8wmbij15D7yP84sNQlg=","faviconCdnUrl":"https:\/\/c5.rgstatic.net\/m\/2390829798215018\/images\/favicon.ico","headerOutput":"<noscript><\/noscript><link rel=\"canonical\" href=\"https:\/\/www.researchgate.net\/publication\/220514418_Surrogate-assisted_evolutionary_computation_Recent_advances_and_future_challenges\" \/>\n<link rel=\"dns-prefetch\" href=\"\/\/c5.rgstatic.net\" \/>\n<link rel=\"dns-prefetch\" href=\"\/\/i1.rgstatic.net\" \/>\n<meta property=\"twitter:card\" content=\"summary\" \/>\n<meta property=\"twitter:site\" content=\"@ResearchGate\" \/>\n<meta property=\"og:title\" content=\"Surrogate-assisted evolutionary computation: Recent advances and future challenges\" \/>\n<meta property=\"og:description\" content=\"Surrogate-assisted, or meta-model based evolutionary computation uses efficient computational models, often known as surrogates or meta-models, for approximating the fitness function in...\" \/>\n<meta property=\"og:site_name\" content=\"ResearchGate\" \/>\n<meta property=\"og:image\" content=\"https:\/\/i1.rgstatic.net\/publication\/220514418_Surrogate-assisted_evolutionary_computation_Recent_advances_and_future_challenges\/links\/563e857b08ae45b5d28c5bc8\/smallpreview.png\" \/>\n<meta property=\"og:url\" content=\"https:\/\/www.researchgate.net\/publication\/220514418_Surrogate-assisted_evolutionary_computation_Recent_advances_and_future_challenges\" \/>\n<meta property=\"rg:id\" content=\"PB:220514418\" \/>\n<meta name=\"DC.identifier\" scheme=\"DCTERMS.URI\" content=\"http:\/\/dx.doi.org\/10.1016\/j.swevo.2011.05.001\" \/>\n<meta name=\"gs_meta_revision\" content=\"1.1\" \/>\n<meta name=\"citation_title\" content=\"Surrogate-assisted evolutionary computation: Recent advances and future challenges\" \/>\n<meta name=\"citation_author\" content=\"Yaochu Jin\" \/>\n<meta name=\"citation_publication_date\" content=\"2011\/06\/01\" \/>\n<meta name=\"citation_journal_title\" content=\"Swarm and Evolutionary Computation\" \/>\n<meta name=\"citation_issn\" content=\"2210-6502\" \/>\n<meta name=\"citation_volume\" content=\"1\" \/>\n<meta name=\"citation_issue\" content=\"2\" \/>\n<meta name=\"citation_firstpage\" content=\"61\" \/>\n<meta name=\"citation_lastpage\" content=\"70\" \/>\n<meta name=\"citation_doi\" content=\"10.1016\/j.swevo.2011.05.001\" \/>\n<meta name=\"citation_pdf_url\" content=\"https:\/\/www.researchgate.net\/profile\/Yaochu_Jin\/publication\/220514418_Surrogate-assisted_evolutionary_computation_Recent_advances_and_future_challenges\/links\/563e857b08ae45b5d28c5bc8.pdf\" \/>\n<meta name=\"citation_abstract_html_url\" content=\"https:\/\/www.researchgate.net\/publication\/220514418_Surrogate-assisted_evolutionary_computation_Recent_advances_and_future_challenges\" \/>\n<meta name=\"citation_fulltext_html_url\" content=\"https:\/\/www.researchgate.net\/publication\/220514418_Surrogate-assisted_evolutionary_computation_Recent_advances_and_future_challenges\" \/>\n<meta name=\"viewport\" content=\"width=device-width,initial-scale=1\" \/>\n<link href=\"\/\/c5.rgstatic.net\/m\/22664197317151888\/styles\/rg.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/21004998181197492\/styles\/rg2.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<!--[if lt IE 9]><link href=\"\/\/c5.rgstatic.net\/m\/238176252723686\/styles\/ie.css\" type=\"text\/css\" rel=\"stylesheet\"\/><![endif]-->\n<link href=\"\/\/c5.rgstatic.net\/m\/217752362214895\/styles\/modules\/publicprofile.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/215868066921738\/styles\/pow\/publicliterature\/FigureList.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/21993347442549\/styles\/pow\/publicliterature\/FollowPublicationPromo.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/282514599719602\/styles\/pow\/application\/PdfJsReader.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/23819663151220\/styles\/pow\/publicliterature\/PublicationInlineReader.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<script src=\"\/\/c5.rgstatic.net\/m\/2321000301012716\/javascript\/vendor\/webfontloader\/webfontloader.js\" type=\"text\/javascript\"><\/script>\n <script>(function(i,s,o,g,r,a,m){i[\"GoogleAnalyticsObject\"]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,\"script\",\"\/\/www.google-analytics.com\/analytics.js\",\"ga\");\n ga(\"create\",\"UA-58591210-1\");ga(\"set\",\"anonymizeIp\",true);ga('set', 'dimension1', 'publication full-text');ga('set', 'dimension2', 'Article');ga('set', 'dimension3', 'Logged out');ga('set', 'dimension4', 'https');ga(\"send\",\"pageview\");<\/script>\n","webfont":"<noscript><\/noscript><script> WebFontConfig = { custom: { families: ['source_sans_pro_italic', 'source_sans_pro_bold', 'source_sans_pro', 'martel'], urls : ['\/\/c5.rgstatic.net\/m\/231392577336386\/styles\/fonts.css'] } }; WebFont.load(WebFontConfig); <\/script>\n","correlationId":"rgreq-73d2e9fc-b6a8-4ff6-9412-bef193e05946","accountId":null,"module":"publicliterature","action":"publicliterature.PublicPublicationDetails","page":"publicationDetail","product":"publications","backendTime":488,"continent":"Asia","stylesHome":"\/\/c5.rgstatic.net\/m\/","staticHost":"c5.rgstatic.net","useEarlyFlush":false,"longRunningRequestIdentifier":"LongRunningRequest.publicliterature.PublicPublicationDetails","longRunningRequestFp":"e9e5bbe1366c7ee8c8e41d02f793c884ac9be19b","widgetId":"rgw35_56aba22853fca"},"id":"rgw35_56aba22853fca","partials":[],"templateName":"application\/stubs\/StaticHeader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.StaticHeader.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){
            Y.rg.core.pagespeed.Monitoring.monitorPage("\/\/glassmoni.researchgate.net", "publicliterature.PublicPublicationDetails.run.html.loggedOut.get", "59de9668d07aeb77ab4de5f24d382b5d199d2437", "rgreq-73d2e9fc-b6a8-4ff6-9412-bef193e05946", "f492d6f461742b4bb3435c56f5468ffe800301a4");
        
            Y.rg.core.pagespeed.Monitoring.monitorPage("\/\/glassmoni.researchgate.net", "publicationDetail.loggedOut", "ed1993d9e20f6cefa83edacaa24401a18c071aea", "rgreq-73d2e9fc-b6a8-4ff6-9412-bef193e05946", "f492d6f461742b4bb3435c56f5468ffe800301a4");
        })();
(function(){Y.rg.createInitialWidget({"data":{"year":"2016","inlinePromo":null,"isAdmin":false,"contactUrl":"https:\/\/www.researchgate.net\/contact","aboutUsUrl":"https:\/\/www.researchgate.net\/about","widgetId":"rgw36_56aba22853fca"},"id":"rgw36_56aba22853fca","partials":[],"templateName":"application\/stubs\/DefaultFooter.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.DefaultFooter.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"headerLogin":{"data":{"urlAfterLogin":"publication\/220514418_Surrogate-assisted_evolutionary_computation_Recent_advances_and_future_challenges","requestToken":"V3GRx\/mjoXXw3GfGltIOLQHV8eaCs5Alf8iIh9IFiI93xQXxgBLnZGUrleCMpAzxaxM3I41Q7p44sKNBlRJ2v\/ZdsFR7tTmL4VaRq9kDQ5AsUDj3P1XdcB3l8QKc7A4Nqh4wrnWGkfGyPsMFCHkD4Iti81i\/2\/3dXDFseBwpPJbnQvvSHuoqDCU7Wj1R0tks1xtR3tFquypkqp9JgwVCDuDE+7nl8QhBwszrUqZvtnYEXWogRSmCJaeVaPsnLS49HQzMnTdEjWNJU0\/Nfd8yoMUo\/0hpHM5BedS+tFxDJ\/4=","loginUrl":"https:\/\/www.researchgate.net\/application.Login.html","signupUrl":"https:\/\/www.researchgate.net\/signup.SignUp.html?ev=su_chnl_index&hdrsu=1&_sg=9m6AyG2p1oUmI_QAoit2Gleq8NMYtM1p4oKk6GQhRPbit_Q6dt0Ui6zzG1MrUcu2","encodedUrlAfterLogin":"cHVibGljYXRpb24vMjIwNTE0NDE4X1N1cnJvZ2F0ZS1hc3Npc3RlZF9ldm9sdXRpb25hcnlfY29tcHV0YXRpb25fUmVjZW50X2FkdmFuY2VzX2FuZF9mdXR1cmVfY2hhbGxlbmdlcw%3D%3D","signupCallToAction":"Join for free","widgetId":"rgw38_56aba22853fca"},"id":"rgw38_56aba22853fca","partials":{"partial":"application\/stubs\/partials\/headerLoginDefault.html"},"templateName":"application\/stubs\/HeaderLogin.html","templateExtensions":[],"attrs":{"goal":"milestoneHeaderLoginSeen"},"widgetUrl":"https:\/\/www.researchgate.net\/application.HeaderLogin.html","viewClass":"views.application.HeaderLoginView","yuiModules":["rg.views.application.HeaderLoginView"],"stylesheets":[],"_isYUI":true},"cookieConsent":null,"logoSvgSrc":"https:\/\/c5.rgstatic.net\/m\/235107188705592\/images\/template\/brand-header-logo.svg","logoFallbackSrc":"https:\/\/c5.rgstatic.net\/m\/238113351022438\/images\/template\/brand-header-logo.png","widgetId":"rgw37_56aba22853fca"},"id":"rgw37_56aba22853fca","partials":{"schemaSocialProfiles":"application\/stubs\/partials\/schemaSocialProfiles.html"},"templateName":"application\/stubs\/HeaderLoggedOut.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.HeaderLoggedOut.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"logEvent":"su_banner","specialCopy":false,"widgetId":"rgw39_56aba22853fca"},"id":"rgw39_56aba22853fca","partials":[],"templateName":"application\/stubs\/LoggedOutBanner.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.LoggedOutBanner.html","viewClass":"views.application.LoggedOutBannerView","yuiModules":["rg.views.application.LoggedOutBannerView"],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.core.util.ParameterFilter.filter(["ev","cp","ch","ref","dbw","pli","loginT","uid","claimChannel","enrichId","enrichSource","utm_source","utm_medium","utm_campaign","el","ci"]);})();
});}); } else { throw 'YRG was not loaded when attaching widgets'; }</script><script> dataLayer = [{"pageCategory":"publication full-text","publicationType":"Article","eventCategory":"Publication page"}]; </script> <noscript><iframe src="//www.googletagmanager.com/ns.html?id=GTM-MKVKH7" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-MKVKH7');</script><script>(function(e){function n(n,t,o,a){"use strict";var i=e.document.createElement("link"),r=t||e.document.getElementsByTagName("script")[0],d=e.document.styleSheets;return i.rel="stylesheet",i.href=n,i.media="only x",a&&(i.onload=a),r.parentNode.insertBefore(i,r),i.onloadcssdefined=function(e){for(var t,o=0;d.length>o;o++)d[o].href&&d[o].href.indexOf(n)>-1&&(t=!0);t?e():setTimeout(function(){i.onloadcssdefined(e)})},i.onloadcssdefined(function(){i.media=o||"all"}),i}function t(e,n){e.onload=function(){e.onload=null,n&&n.call(e)},"isApplicationInstalled"in navigator&&"onloadcssdefined"in e&&e.onloadcssdefined(n)}var o=function(a,i){"use strict";if(a&&3===a.length){var r=e.Image,d=!(!document.createElementNS||!document.createElementNS("http://www.w3.org/2000/svg","svg").createSVGRect||!document.implementation.hasFeature("http://www.w3.org/TR/SVG11/feature#Image","1.1")||e.opera&&-1===navigator.userAgent.indexOf("Chrome")||-1!==navigator.userAgent.indexOf("Series40")),c=new r;c.onerror=function(){o.method="png",o.href=a[2],n(a[2])},c.onload=function(){var e=1===c.width&&1===c.height,r=a[e&&d?0:e?1:2];o.method=e&&d?"svg":e?"datapng":"png",o.href=r,t(n(r),i)},c.src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///ywAAAAAAQABAAACAUwAOw==",document.documentElement.className+=" grunticon"}};o.loadCSS=n,o.onloadCSS=t,e.grunticon=o})(this);grunticon(["https://c5.rgstatic.net/c/o1q2er/styles/icons/_header-ico.svg.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_header-ico.png.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_header-ico.fallback.scss"]);grunticon(["https://c5.rgstatic.net/c/o1q2er/styles/icons/_admin-ico.svg.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_admin-ico.png.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_admin-ico.fallback.scss"]);grunticon(["https://c5.rgstatic.net/c/o1q2er/styles/icons/_ico.svg.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_ico.png.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_ico.fallback.scss"]);</script></body>
</html>
