<!DOCTYPE html> <html lang="en" class="" id="rgw28_56aba076a1103"> <head > <meta charset="utf-8"/> <meta http-equiv="content-type" content="text/html; charset=UTF-8"/> <meta name="Rg-Request-Token" id="Rg-Request-Token" content="e+45j63rhXOkQBgPETsGAT/AsuFBzd8Gn6g7VfNCHervvaMXHxcnCeSSa2SmQNBPCaw3Jhothc5bG+su43nmQVqXKJObLgTNmIe7c5msQliK176ST8eY9Pt2otpNW+cTjZU+EDamU+qpDf4oTfZr+SEONd/gla9bViuAD2ymC8OELZuaq25UY4qYlTtoVB/AYG4oa75uOd1p0A//jLrXwdpbIzIg/14SIt4D8MZmbkUvj10PsN1r3h60JjlzAgjASrvZZXLOh0DeQjhgEwJcGtsqbl5jUCjpzk+gb9+Wo6Q="/> <meta http-equiv="expires" content="0"/> <link rel="apple-touch-icon" sizes="57x57" href="https://www.researchgate.net/apple-touch-icon-57x57.png"> <link rel="apple-touch-icon" sizes="60x60" href="https://www.researchgate.net/apple-touch-icon-60x60.png"> <link rel="apple-touch-icon" sizes="72x72" href="https://www.researchgate.net/apple-touch-icon-72x72.png"> <link rel="apple-touch-icon" sizes="76x76" href="https://www.researchgate.net/apple-touch-icon-76x76.png"> <link rel="apple-touch-icon" sizes="114x114" href="https://www.researchgate.net/apple-touch-icon-114x114.png"> <link rel="apple-touch-icon" sizes="120x120" href="https://www.researchgate.net/apple-touch-icon-120x120.png"> <link rel="apple-touch-icon" sizes="144x144" href="https://www.researchgate.net/apple-touch-icon-144x144.png"> <link rel="apple-touch-icon" sizes="152x152" href="https://www.researchgate.net/apple-touch-icon-152x152.png"> <link rel="apple-touch-icon" sizes="180x180" href="https://www.researchgate.net/apple-touch-icon-180x180.png"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-32x32.png" sizes="32x32"> <link rel="icon" type="image/png" href="https://www.researchgate.net/android-chrome-192x192.png" sizes="192x192"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-96x96.png" sizes="96x96"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-16x16.png" sizes="16x16"> <link rel="shortcut icon" type="image/x-icon" href="https://c5.rgstatic.net/m/2390829798215018/images/favicon.ico"/> <link rel="manifest" href="https://www.researchgate.net/manifest.json"> <meta name="msapplication-TileColor" content="#da532c"> <meta name="msapplication-TileImage" content="https://www.researchgate.net/mstile-144x144.png"> <meta name="theme-color" content="#444444"> <link rel="search" type="application/opensearchdescription+xml" title="ResearchGate search" href="https://www.researchgate.net/application.DownloadOpenSearchPlugin.html"/> <link rel="meta" type="application/rdf+xml" title="ICRA labels" href="https://www.researchgate.net/application.DownloadLabels.html"/> <link rel="http://oexchange.org/spec/0.8/rel/related-target" type="application/xrd+xml" href="https://www.researchgate.net/application.DownloadOExchange.html"/> <base href="https://www.researchgate.net/"/> <script>
    var rgConfig = {
        correlationId: "rgreq-6b6efb49-191b-459c-b239-c29fc2284177",
        accountId: "",
        module: "publicliterature",
        action: "publicliterature.PublicPublicationDetails",
        page: "publicationDetail",
        product: "publications",
        continent: "Asia",
        stylesHome: "//c5.rgstatic.net/m/",
        staticHost: "c5.rgstatic.net",
        longRunningRequestIdentifier: "LongRunningRequest.publicliterature.PublicPublicationDetails",
        longRunningRequestFp: "e9e5bbe1366c7ee8c8e41d02f793c884ac9be19b"
    };
    window.rootUrl = "https://www.researchgate.net/";
</script> <link rel="canonical" href="https://www.researchgate.net/publication/235703008_Adaptive_Hamiltonian_and_Riemann_Manifold_Monte_Carlo_Samplers" />
<link rel="dns-prefetch" href="//c5.rgstatic.net" />
<link rel="dns-prefetch" href="//i1.rgstatic.net" />
<meta property="twitter:card" content="summary" />
<meta property="twitter:site" content="@ResearchGate" />
<meta property="og:title" content="Adaptive Hamiltonian and Riemann Manifold Monte Carlo Samplers" />
<meta property="og:description" content="In this paper we address the widely-experienced difficulty in tuning
Hamiltonian-based Monte Carlo samplers. We develop an algorithm that allows for
the adaptation of Hamiltonian and Riemann..." />
<meta property="og:site_name" content="ResearchGate" />
<meta property="og:image" content="https://i1.rgstatic.net/publication/235703008_Adaptive_Hamiltonian_and_Riemann_Manifold_Monte_Carlo_Samplers/links/034f93310cf2ac15472e88e3/smallpreview.png" />
<meta property="og:url" content="https://www.researchgate.net/publication/235703008_Adaptive_Hamiltonian_and_Riemann_Manifold_Monte_Carlo_Samplers" />
<meta property="rg:id" content="PB:235703008" />
<meta name="DC.identifier" scheme="DCTERMS.URI" content="http://dx.doi.org/" />
<meta name="gs_meta_revision" content="1.1" />
<meta name="citation_title" content="Adaptive Hamiltonian and Riemann Manifold Monte Carlo Samplers" />
<meta name="citation_author" content="ziyu wang" />
<meta name="citation_author" content="Shakir Mohamed" />
<meta name="citation_author" content="Nando de Freitas" />
<meta name="citation_publication_date" content="2013/02/25" />
<meta name="citation_abstract_html_url" content="https://www.researchgate.net/publication/235703008_Adaptive_Hamiltonian_and_Riemann_Manifold_Monte_Carlo_Samplers" />
<meta name="citation_fulltext_html_url" content="https://www.researchgate.net/publication/235703008_Adaptive_Hamiltonian_and_Riemann_Manifold_Monte_Carlo_Samplers" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<link href="//c5.rgstatic.net/m/22664197317151888/styles/rg.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/21004998181197492/styles/rg2.css" type="text/css" rel="stylesheet"/>
<!--[if lt IE 9]><link href="//c5.rgstatic.net/m/238176252723686/styles/ie.css" type="text/css" rel="stylesheet"/><![endif]-->
<link href="//c5.rgstatic.net/m/217752362214895/styles/modules/publicprofile.css" type="text/css" rel="stylesheet"/>
<script src="//c5.rgstatic.net/m/2321000301012716/javascript/vendor/webfontloader/webfontloader.js" type="text/javascript"></script>
 <script>(function(i,s,o,g,r,a,m){i["GoogleAnalyticsObject"]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,"script","//www.google-analytics.com/analytics.js","ga");
 ga("create","UA-58591210-1");ga("set","anonymizeIp",true);ga('set', 'dimension1', 'publication slurped');ga('set', 'dimension2', 'Article');ga('set', 'dimension3', 'Logged out');ga('set', 'dimension4', 'https');ga("send","pageview");</script>
  <script> WebFontConfig = { custom: { families: ['source_sans_pro_italic', 'source_sans_pro_bold', 'source_sans_pro', 'martel'], urls : ['//c5.rgstatic.net/m/231392577336386/styles/fonts.css'] } }; WebFont.load(WebFontConfig); </script><noscript></noscript>

<title>Adaptive Hamiltonian and Riemann Manifold Monte Carlo Samplers</title>
<meta name="description" content="Adaptive Hamiltonian and Riemann Manifold Monte Carlo Samplers on ResearchGate, the professional network for scientists."/>
<meta name="keywords" content="scientific network, scientific platform, scientific community, research partner, research collaboration, journal articles, international collaboration, find researcher, lifescience researcher, interdisciplinary research, research collaboration"/>
</head>
<body class="use-svg-icons logged-out">
<div id="page-container">
<script type="text/javascript">var googletag = googletag || {}; googletag.cmd = googletag.cmd || [];
(function() { var gads = document.createElement("script"); gads.async = true; gads.type = "text/javascript"; var useSSL = "https:" == document.location.protocol; gads.src = (useSSL ? "https:" : "http:") + "//www.googletagservices.com/tag/js/gpt.js"; var node =document.getElementsByTagName("script")[0]; node.parentNode.insertBefore(gads, node); })();</script><div id="main" class="logged-out-header-support">
<div id="content" class="">

<noscript>
<div class="c-box-warning full-width-element" style="text-align: center; ">
    <div style="margin: auto; padding:10px;" class="container">
        <b>For full functionality of ResearchGate it is necessary to enable JavaScript.
            Here are the <a href="http://www.enable-javascript.com/" rel="nofollow" target="_blank">
                instructions how to enable JavaScript in your web browser</a>.</b>
    </div>
</div>
</noscript>

<div id="rgw1_56aba076a1103" itemscope itemtype="http://schema.org/ScholarlyArticle"><div class="publication-wrapper publication-wrapper-onecol" id="rgw2_56aba076a1103" itemscope itemtype="http://schema.org/ScholarlyArticle"> <div class="c-col-content"> <div class="c-content"> <div class="clearfix">  <div class="publication-header"> <div id="rgw5_56aba076a1103">  <div class="type-label"> Article   </div> <span class="Z3988" title="ctx_ver=Z39.88-2004&rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&rfr_id=info%3Asid%2Fresearchgate.net%3Aresearchgate&rft.atitle=Adaptive%20Hamiltonian%20and%20Riemann%20Manifold%20Monte%20Carlo%20Samplers&rft.title=30th%20International%20Conference%20on%20Machine%20Learning%2C%20ICML%202013&rft.jtitle=30th%20International%20Conference%20on%20Machine%20Learning%2C%20ICML%202013&rft.date=2013&rft.au=ziyu%20wang%2CShakir%20Mohamed%2CNando%20de%20Freitas&rft.genre=article"></span> <h1 class="pub-title" itemprop="name">Adaptive Hamiltonian and Riemann Manifold Monte Carlo Samplers</h1> <meta itemprop="headline" content="Adaptive Hamiltonian and Riemann Manifold Monte Carlo Samplers">  <meta itemprop="image" content="https://i1.rgstatic.net/publication/235703008_Adaptive_Hamiltonian_and_Riemann_Manifold_Monte_Carlo_Samplers/links/034f93310cf2ac15472e88e3/smallpreview.png">  <div id="rgw7_56aba076a1103" class="publication-detail-author-list"> <div> <ul class="clearfix js-people-list">  <li id="rgw8_56aba076a1103" itemprop="author" itemscope itemtype="http://schema.org/Person"> <a itemprop="sameAs" href="profile/Ziyu_Wang2" class="pub-detail-item account-item"> <div class="indent-left"> <div class="people-img"> <img  src="https://i1.rgstatic.net/ii/profile.image/AS%3A273771454005251%401442283609269_m" title="Ziyu Wang" alt="Ziyu Wang" height="20px" width="20px" style="height: 20px;"/> </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Ziyu Wang</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item  remove-action-indent   " id="rgw9_56aba076a1103" data-account-key="Ziyu_Wang2">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="profile/Ziyu_Wang2"> <img class="lazyload" data-src="https://i1.rgstatic.net/ii/profile.image/AS%3A273771454005251%401442283609269_l" title="Ziyu Wang" alt="Ziyu Wang" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">     </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="profile/Ziyu_Wang2" class="display-name">Ziyu Wang</a>    </h5> <div class="truncate-single-line meta">   <a class="meta ga-top-coauthor-institution" href="institution/University_of_British_Columbia-Vancouver" title="University of British Columbia - Vancouver">University of British Columbia - Vancouver</a>     </div>  <a href="javascript:" class="btn btn-promote btn-large people-item-contact-author js-contact-author">Message author</a>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>  <li id="rgw10_56aba076a1103"> <a href="researcher/82243933_Shakir_Mohamed" class="pub-detail-item author-item" itemprop="author" itemscope itemtype="http://schema.org/Person"> <div class="indent-left"> <div class="people-img">  <img src="https://c5.rgstatic.net/m/2951093203564/images/template/default/profile/profile_default_s.jpg" title="Shakir Mohamed" alt="Shakir Mohamed" height="20px" width="20px" style="height: 20px;"/>  </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Shakir Mohamed</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item   not-claimed " id="rgw11_56aba076a1103">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="researcher/82243933_Shakir_Mohamed"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="Shakir Mohamed" alt="Shakir Mohamed" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">       </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="researcher/82243933_Shakir_Mohamed" class="display-name">Shakir Mohamed</a>    </h5> <div class="truncate-single-line meta">   </div>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>  <li id="rgw12_56aba076a1103"> <a href="researcher/35020845_Nando_de_Freitas" class="pub-detail-item author-item" itemprop="author" itemscope itemtype="http://schema.org/Person"> <div class="indent-left"> <div class="people-img">  <img src="https://c5.rgstatic.net/m/2951093203564/images/template/default/profile/profile_default_s.jpg" title="Nando de Freitas" alt="Nando de Freitas" height="20px" width="20px" style="height: 20px;"/>  </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Nando de Freitas</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item   not-claimed " id="rgw13_56aba076a1103">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="researcher/35020845_Nando_de_Freitas"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="Nando de Freitas" alt="Nando de Freitas" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">       </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="researcher/35020845_Nando_de_Freitas" class="display-name">Nando de Freitas</a>    </h5> <div class="truncate-single-line meta">   </div>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>   </ul> <div class="js-loading"></div>  </div> </div> <div class="pub-details js-pub-details">     30th International Conference on Machine Learning, ICML 2013   <meta itemprop="datePublished" content="2013-02">  02/2013;               <div class="pub-source"> Source: <a href="http://arxiv.org/abs/1302.6182" rel="nofollow">arXiv</a> </div>  </div> <div id="rgw14_56aba076a1103" class="pub-abstract">  <div class="clearfix">   <div style="max-height: 54px;" class="js-expander-container js-expander-collapsed">  <p itemprop="description"> <strong>ABSTRACT</strong> <div>In this paper we address the widely-experienced difficulty in tuning<br />
Hamiltonian-based Monte Carlo samplers. We develop an algorithm that allows for<br />
the adaptation of Hamiltonian and Riemann manifold Hamiltonian Monte Carlo<br />
samplers using Bayesian optimization that allows for infinite adaptation of the<br />
parameters of these samplers. We show that the resulting sampling algorithms<br />
are ergodic, and that the use of our adaptive algorithms makes it easy to<br />
obtain more efficient samplers, in some cases precluding the need for more<br />
complex solutions. Hamiltonian-based Monte Carlo samplers are widely known to<br />
be an excellent choice of MCMC method, and we aim with this paper to remove a<br />
key obstacle towards the more widespread use of these samplers in practice.</div> </p>  </div>  </div>   </div>      <div class="action-container">   <div class="clear"></div> <div class="share-dialog-container" style="display: none;">  </div> </div> </div> <div style="margin-left: -20px; margin-right: -20px;">  </div> </div>  <div class="publication-detail-dfp-container rf"> <div id="rgw27_56aba076a1103">  </div> </div>  </div>  <div class="clearfix">  <noscript> <div id="rgw26_56aba076a1103"  itemprop="articleBody">  <p>Page 1</p> <p>Adaptive Hamiltonian and Riemann Manifold Monte Carlo Samplers<br />Ziyu Wang<br />University of British Columbia Vancouver, Canada<br />ziyuw@cs.ubc.ca<br />Shakir Mohamed<br />University of British Columbia Vancouver, Canada<br />shakirm@cs.ubc.ca<br />Nando de Freitas<br />University of British Columbia Vancouver, Canada<br />nando@cs.ubc.ca<br />Abstract<br />In<br />experienced difficulty in tuning Hamiltonian-<br />based Monte Carlo samplers. We develop an<br />algorithm that allows for the adaptation of<br />Hamiltonian and Riemann manifold Hamil-<br />tonian Monte Carlo samplers using Bayesian<br />optimization that allows for infinite adap-<br />tation of the parameters of these samplers.<br />We show that the resulting sampling algo-<br />rithms are ergodic, and that the use of our<br />adaptive algorithms makes it easy to obtain<br />more efficient samplers, in some cases pre-<br />cluding the need for more complex solutions.<br />Hamiltonian-based Monte Carlo samplers are<br />widely known to be an excellent choice of<br />MCMC method, and we aim with this paper<br />to remove a key obstacle towards the more<br />widespread use of these samplers in practice.<br />this paperwe addressthe widely-<br />1. Introduction<br />Hamiltonian Monte Carlo (HMC) (Duane et al., 1987)<br />is widely-known as a powerful and efficient sampling<br />algorithm, having been demonstrated to outperform<br />many existing MCMC algorithms,<br />problems with high-dimensional, continuous, and cor-<br />related distributions (Chen et al., 2001; Neal, 2010).<br />Despite this flexibility, HMC has not been widely<br />adopted in practice, due principally to the sensitivity<br />and difficulty of tuning its hyperparameters. In fact,<br />tuning HMC has been reported by many experts to<br />be more difficult than tuning other MCMC methods<br />(Ishwaran, 1999; Neal, 2010). In this paper we aim to<br />remove this obstacle in the use of HMC by providing<br />an automated method of determining these tunable<br />parameters, paving the way for a more widespread<br />especially in<br />application of HMC in statistics and machine learning.<br />There are few existing works dealing with the<br />automated tuning of HMC. Two notable approaches<br />are:the No U-turn sampler (NUTS) (Hoffman &amp;<br />Gelman, 2011), which is an adaptive algorithm for<br />HMC that aims to find the best parameter settings by<br />tracking the sample path and preventing HMC from<br />retracing its steps in this path; and Riemann manifold<br />HMC (RMHMC) (Girolami &amp; Calderhead, 2011),<br />which provides adaptations using the Riemannian<br />geometry of the problem.<br />In this paper, we follow the approach of adapting<br />Markov chains in order to improve the convergence<br />of both HMC and RMHMC. Our adaptive strategy<br />is based on Bayesian optimization; see for example<br />Brochu et al. (2009) and Snoek et al. (2012) for a<br />clear and comprehensive introduction to Bayesian<br />optimization. Bayesian optimization has been pro-<br />posed previously for the adaptation of general MCMC<br />samplers by Mahendran et al. (2012) and Hamze<br />et al. (2013). To guarantee convergence, these works<br />were limited to a finite adaptation of the Markov<br />chain. However, in the field of adaptive MCMC, it<br />is well known that finite adaptation can result in<br />the sampler being trapped in suboptimal parameter<br />settings, leading to inefficient sampling.<br />We describe Hamiltonian-based Monte Carlo sam-<br />plers in section 2, and then make the following<br />contributions:<br />• We present an algorithm for adaptive HMC in<br />which we allow for infinite adaptation of the<br />Markov chain, thus avoiding parameter traps due<br />to finite adaptation (section 3).<br />• Importantly, we prove that the adaptive MCMC<br />arXiv:1302.6182v1  [stat.CO]  25 Feb 2013</p>  <p>Page 2</p> <p>Adaptive Hamiltonian and Riemann Manifold Monte Carlo Samplers<br />samplers we present are ergodic in this infinite<br />adaptation setting (section 4).<br />• We provide a comprehensive set of experiments<br />demonstrating that the adaptive schemes perform<br />better in a diverse set of statistical problems (sec-<br />tion 5).<br />• For most examples, we use a version of the<br />expected squared jumping distance proposed by<br />Pasarica &amp; Gelman (2010) as the objective func-<br />tion for adaptation. However, in section 5, we also<br />introduce a new approach for adaptive MCMC<br />based on predictive measures, for use in settings<br />where it is possible to perform cross-validation or<br />bootstrapping.<br />2. Hamiltonian-based Monte Carlo<br />Sampling<br />Hamiltonian (or Hybrid) Monte Carlo (Duane et al.,<br />1987; Neal, 2010), has become established as a pow-<br />erful, general purpose Markov chain Monte Carlo<br />(MCMC) algorithm for sampling from general, contin-<br />uous distributions. Its efficiency is due to the fact that<br />it makes use of gradient information from the target<br />density to allow for an ergodic Markov chain capable<br />of large transitions that are accepted with high prob-<br />ability. This efficiency and flexibility is demonstrated<br />by the wide range of applications to which HMC has<br />been applied, including: Bayesian generalized linear<br />models (Ishwaran, 1999), Bayesian neural networks<br />(Neal &amp; Zhang, 2006), Gaussian process regression and<br />classification (Rasmussen &amp; Williams, 2006), exponen-<br />tial family PCA and factor analysis (Mohamed et al.,<br />2008), and restricted Boltzmann machines (Ranzato &amp;<br />Hinton, 2010), amongst others.<br />For HMC, we are required to specify a potential energy<br />function, which is the log of the joint distribution we<br />wish to sample from, U(x) = −logp(x) and a kinetic<br />energy function, most typically, K(p) = pTM−1p/2,<br />with momentum vector p and a positive definite mass<br />matrix M. For standard HMC, the mass matrix is<br />set to the identity. We defer the technical details of<br />HMC to existing work (Neal, 2010), and present only<br />the algorithm here (Alg. 1).<br />HMC requires the selection of two free parameters: a<br />step-size ? and a number leapfrog steps L. The ac-<br />cepted guidance is to choose a step-size to ensure that<br />the sampler’s rejection rate is between 25%-35%. It is<br />also preferable to have a large L, since this reduces the<br />random walk behavior of the sampler (Neal, 2010), but<br />too large an L results in unnecessary computation. In<br />this paper, we consider a slight variation of the HMC<br />Algorithm 1 Hamiltonian Monte Carlo Algorithm<br />1: Given: M, L, ?, and x1.<br />2: for t = 1,2,··· do<br />3: Sample pt∼ N(0,M) and Lr ∼ U(1,L)<br />4:Let x0 = xtand p0 = pt+?<br />5: for l = 1,2,··· ,Lr do<br />6:xl= xl−1+ ?M−1pl−1<br />7:pl= pl−1+ ?∂U<br />∂x<br />xl<br />8:end for<br />9:pl= pl−1−?<br />10:Draw u ∼ U(0,1)<br />11:if u &lt; min[1,eU(xt)+K(pt)−U(xl)−K(pl)] then<br />12:Let (xt+1,pt+1) = (xl,pl)<br />13:else<br />14:Let (xt+1,pt+1) = (xt,pt)<br />15:end if<br />16: end for<br />2<br />∂U<br />∂x<br />??<br />x0<br />??<br />2<br />∂U<br />∂x<br />??<br />xl<br />algorithm: instead of performing L leapfrog steps at<br />each iteration, we only perform a random number of<br />leapfrog steps, chosen from the discrete uniform distri-<br />bution over {1,··· ,L}, i.e. Lr∼ U(1,L) steps. This<br />approach amounts to using a mixture of L different<br />HMC transition kernels, thus preserving detailed bal-<br />ance (Andrieu et al., 2003).<br />HMC is known to be highly sensitive to the choice of ?<br />and L. We demonstrate HMC’s sensitivity to these pa-<br />rameters by sampling from a bivariate Gaussian with<br />correlation coefficient 0.99. We consider three settings<br />(?,L) = {(0.16,40),(0.16,50),(0.15,50)} and show the<br />behavior of the sampler as well as the autocorrelation<br />plot in figure 1. While the first setting exhibits good<br />behavior and low auto-correlation, small changes to<br />these settings results in poor mixing and high auto-<br />correlation, as seen in the other graphs.<br />cal results concerning the optimal acceptance rate for<br />HMC exist, having been described by Beskos et al.<br />(2010) and Neal (2010), with both concluding a rate<br />around 0.65 as optimal. Such results, however, would<br />not help in choosing the best sampler out of the three<br />in Figure 1, since all three samplers in this demonstra-<br />tion have an acceptance rate around 0.7, leaving little<br />guidance for finding the most efficient sampler.<br />Theoreti-<br />To address the problem of choosing these parame-<br />ters, we will introduce a method for automatically and<br />adaptively tuning the parameters of HMC, reducing<br />the need for time-consuming, expert tuning. An ex-<br />isting approach for automatic tuning of HMC was in-<br />troduced by Hoffman &amp; Gelman (2011), referred to as<br />the No U-turn sampler (NUTS). NUTS allows for au-<br />tomatic tuning of both HMC’s parameters by tuning<br />the stepsize ? during the burn-in phase, after which<br />it is fixed and the number of leapfrog steps is ad-</p>  <p>Page 3</p> <p>Adaptive Hamiltonian and Riemann Manifold Monte Carlo Samplers<br />0246<br />0<br />2<br />4<br />6<br />8<br />Gaussian, ρ=0.99<br />ε = 0.16, L = 40<br />050<br />Lag<br />100<br />0<br />0.5<br />1<br />Auto−correlation<br />−5 05<br />−5<br />0<br />5<br />10<br />ε = 0.16, L = 50<br />050<br />Lag<br />100<br />0<br />0.5<br />1<br />0246<br />0<br />5<br />10<br />ε = 0.15, L = 50<br />050<br />Lag<br />100<br />0<br />0.5<br />1<br />Figure 1. 1000 samples from a bivariate Gaussian distribu-<br />tion generated using HMC. We show the trajectory and<br />auto-correlation of the samples for 3 parameter settings.<br />justed thereafter for every iteration. ? is chosen using<br />a stochastic approximation method referred to as dual<br />averaging, and L is chosen for every sample using a<br />recursive algorithm in which the number of leapfrog<br />steps is allowed to increase until the proposal trajec-<br />tory taken by the sampler begins to move back towards<br />the initial point, thus preventing U-turns and allowing<br />for the good mixing of the chain.<br />Riemann manifold HMC (RMHMC) (Girolami &amp;<br />Calderhead, 2011) is a sampling method derived from<br />HMC, and provides an adaptation mechanism for<br />HMC by exploiting the Riemannian geometry of the<br />parameter space.Rather than adapting ? and L,<br />RMHMC accounts for the local structure of the joint<br />density by adapting the mass matrix M used in HMC.<br />Since RMHMC automatically adapts its mass ma-<br />trix, the stepsize ? is usually fixed and the number<br />of leapfrog steps L, which is a single scalar, can be<br />chosen using the rejection rate. While the sensitivity<br />to these parameters is greatly reduced, they must still<br />be set and there is no general guidance on how these<br />parameters should be chosen, making it desirable to<br />have a fully automatic method for RMHMC as well.<br />3. Adaptive Hamiltonian Monte Carlo<br />In order to adapt the MCMC parameters L and ? for<br />HMC, we need to (i) define an objective function and<br />(ii) choose a suitable optimization method.<br />As pointed out in Pasarica &amp; Gelman (2010), a natu-<br />ral objective function for adaptation is the asymptotic<br />efficiency of an MCMC sampler, (1 + 2?∞<br />lag k. Despite its appeal, this measure is problematic<br />because the higher order auto-correlations are hard to<br />estimate. To circumvent this problem, Pasarica and<br />Gelman (2010) introduced an objective measure called<br />k=1ρk)−1,<br />where ρk is the auto-correlation of the sampler with<br />the expected squared jumping distance (ESJD):<br />ESJD(γ) = Eγ?xt+1− xt?2,<br />where γ = (L,?) denotes the set of parameters for<br />HMC. Maximizing the above objective is equivalent to<br />minimizing the first-order auto-correlation ρ1. In prac-<br />tice, the above intractable expectation with respect to<br />the Markov chain is approximated by an empirical es-<br />timator, as outlined in Pasarica &amp; Gelman (2010).<br />The ESJD measure is efficient in situations where the<br />higher order auto-correlations increase monotonically<br />with respect to ρ1.However, it is not suitable for<br />tuning HMC samplers since by increasing the number<br />of leapfrog steps one can almost always generate better<br />samples. What we need is a measure that also takes<br />computing time into consideration. With this goal in<br />mind, we introduce the following objective function:<br />f(γ) =ESJD(γ)<br />√L<br />=Eγ?xt+1− xt?2<br />√L<br />.<br />This function simply normalizes the ESJD by the num-<br />ber of leapfrog steps L, thus taking both statistical<br />efficiency and computation into consideration. Most<br />of our experiments will use this measure as we have<br />found it to work very well in practice. Many works in<br />the adaptive MCMC literature have considered match-<br />ing empirical and theoretical acceptance rates in order<br />to adapt MCMC samplers; see for example Andrieu &amp;<br />Robert (2001) or Vihola (2010). We have found this<br />strategy to perform poorly in the case of HMC, where<br />samplers with the same acceptance rate can exhibit<br />different mixing behavior (figure 1). When discussing<br />Bayesian neural networks in our experiments (section<br />5.4), we will introduce an alternative objective func-<br />tion based on predictive performance. Such a measure<br />does however only apply in predictive domains and is,<br />consequently, less general than the normalized ESJD<br />objective.<br />Now that we are armed with an objective function,<br />we need to address the issue of optimization. Since<br />the objective is only available point-wise (that is, it<br />can be evaluated but its exact form is intractable), re-<br />searchers typically use stochastic approximation. We<br />use Bayesian optimization to optimize the objective.<br />A discussion contrasting these two alternatives is pre-<br />sented in Hamze et al. (2013).<br />Bayesian optimization is an efficient gradient-free opti-<br />mization tool well suited for expensive black box func-<br />tions. Our objective function (normalized ESJD) is of<br />this nature. As mentioned earlier, normalized ESJD<br />involves an intractable expectation that can be approx-<br />imated by sample averages, where the samples are pro-<br />duced by running HMC for a few iterations. Each set</p>  <p>Page 4</p> <p>Adaptive Hamiltonian and Riemann Manifold Monte Carlo Samplers<br />of HMC samples for a specific set of hyper-parameters<br />γ ∈ Γ results in a noisy evaluation of the normalized<br />ESJD: r(γ) = f(γ) + ε, where we assume that the<br />measurement noise is Gaussian ε ∼ N(0,σ2<br />Following the standard Bayesian optimization method-<br />ology, we set Γ to be a box constraint such that<br />η).<br />Γ = {(?,L) : ? ∈ [b?<br />for some interval boundaries b?<br />parameter L is discrete. The parameter ? is continu-<br />ous, but since it is one-dimensional, we can discretize<br />it using a very fine grid.<br />l,b?<br />u],L ∈ [bL<br />l≤ b?<br />l,bL<br />u]}<br />l≤ bL<br />uand bL<br />u. The<br />Since the true objective function is unknown, we spec-<br />ify a zero-mean Gaussian prior over it:<br />f(·) ∼ GP(0,k(·,·))<br />where k(·,·) is the covariance function. Given noisy<br />evaluations of the objective function {rk}i<br />ated at points {γk}i<br />?{γk}i<br />objective function:<br />k=1evalu-<br />k=1, we form the dataset Di =<br />?. Using Bayes rule, we arrive at<br />k=1,{rk}i<br />k=1<br />the posterior predictive distribution over the unknown<br />f|Di,γ ∼ N(µi(γ),σ2<br />µi(γ) = kT(K + σ2<br />σ2<br />i(γ))<br />ηI)−1ri<br />i(γ) = k(γ,γ) − kT(K + σ2<br />ηI)−1k<br />where<br />K =<br /><br /><br /><br />k(γ1,γ1)<br />...<br />k(γi,γ1)<br />...<br />...<br />...<br />k(γ1,γi)<br />...<br />k(γi,γi)<br /><br />,<br /><br />k = [k(γ,γ1) ... k(γ,γi)]T, and ri = [r1 ... ri]T.<br />In this work, we adopt a Gaussian ARD covari-<br />ance function with k(γi,γj) = exp(−1<br />where Σ is a positive definite matrix. We set Σ =<br />diag[α(b?<br />For more details on Gaussian processes, please refer<br />to Rasmussen &amp; Williams (2006).<br />2γT<br />iΣ−1γj)<br />?<br />u− b?<br />l)]2;?α(bL<br />u− bL<br />l)?2?<br />, where α = 0.2.<br />The Gaussian process simply provides a surrogate<br />model for the true objective. The surrogate can be<br />used to search, efficiently, for the maximum of the ob-<br />jective function. In particular, it enables us to con-<br />struct an acquisition function u(·) that tells us which<br />parameters γ to try next. The acquisition function<br />uses the Gaussian process posterior mean to predict<br />regions of potentially higher objective values (exploita-<br />tion). It also uses the posterior variance to detect re-<br />gions of high uncertainty (exploration). Moreover, it<br />effectively trades-off exploration and exploitation. Dif-<br />ferent acquisition functions have been proposed in the<br />Algorithm 2 Adaptive HMC.<br />1: Given: Γ, m, k, α, and γ1.<br />2: for i = 1,2,..., do<br />3:Run HMC for m iterations with γi= (?i,Li).<br />4:Obtain the objective function value ri using the<br />drawn samples.<br />5:Augment the data Di = {Di−1,(γi,ri)}.<br />6:if ri &gt; supj∈{1,··· ,i−1}rj then<br />7:s =<br />ri<br />8:end if<br />9:Draw u ∼ U([0,1])<br />10:let pi = (max{i − k + 1,1})−0.5, with k ∈ N+.<br />11:if u &lt; pi then<br />12:γi+1:= argmaxγ∈Γu(γ,s|Di).<br />13:else<br />14:γi+1:= γi<br />15:end if<br />16: end for<br />α<br />literature (Moˇ ckus, 1982; Srinivas et al., 2010; Hoff-<br />man et al., 2011). We adopt a variant of the Upper<br />Confidence Bound (UCB) (Srinivas et al., 2010), mod-<br />ified to suit our application:<br />u(γ,s|Di) = µi(γ,s) + piβ<br />standard<br />d<br />2+2π2<br />3δ<br />, where d is the dimension of<br />Γ and δ is set to 0.1. The parameter piensures that<br />the diminishing adaptation condition for adaptive<br />MCMC (Roberts &amp; Rosenthal, 2007) is satisfied.<br />Specifically, we set pi = (max{i − k + 1,1})−0.5for<br />some k ∈ N+.<br />Bayesian optimization adapting γ vanishes as shown<br />in Algorithm 2.<br />1<br />2<br />i+1σi(γ).<br />Asin<br />?<br />UCB,we setβi+1<br />=<br />2log<br />(i+1)<br />?<br />As pi goes to 0, the probability of<br />It could be argued that this acquisition function could<br />lead to premature exploitation, which may prevent<br />Bayesian optimization from locating the true optimum<br />of the objective function.<br />this argument. Our goal when adapting the Markov<br />chain, however, is less about finding the absolute best<br />hyper-parameters but more about finding sufficiently<br />good hyper-parameters given finite computational re-<br />sources. Given enough time, we could slow the an-<br />nealing schedule thus allowing Bayesian optimization<br />to explore the hyper-parameter space fully. However,<br />under time constraints we must use faster annealing<br />schedules. As pidecreases, it becomes increasingly dif-<br />ficult for Bayesian optimization to propose new hyper-<br />parameters for HMC. Consequently, the sampler ends<br />up using the same set of hyper-parameters for many<br />iterations. With this in mind, we argue, it is more<br />reasonable to exploit known good hyper-parameters<br />rather than exploring for better ones. This intuition<br />matches our experience when conducting experiments.<br />There is some truth to</p>  <p>Page 5</p> <p>Adaptive Hamiltonian and Riemann Manifold Monte Carlo Samplers<br />The acquisition function also includes a scalar<br />scale-invariance parameter s, such that µi(γ,s) =<br />kT(K + σ2<br />tomatically so as to rescale the rewards to the same<br />range each time we encounter a new maximal reward.<br />ηI)−1ris. This parameter is estimated au-<br />Gaussian processes require the inversion of the covari-<br />ance matrix and, hence, have complexity O(i3), where<br />i is the number of iterations. Fortunately, thanks to<br />our annealing schedule, the number of unique points in<br />our Gaussian process grows sub-linearly with the num-<br />ber of iterations. This slow growth makes it possible to<br />adopt kernel specification techniques, as proposed by<br />Engel (2005), to drastically reduce the computational<br />cost without suffering any loss in accuracy.<br />Finally, in all our experiments, we set α = 4, k = 100,<br />m =B<br />k, where B is the number of burn-in samples. In<br />our experience, the algorithm is robust with respect<br />to these settings and we used the same set of param-<br />eters throughout our experiments with the exception<br />of Γ. Γ is easy to set, since one can choose the bound<br />to be large enough to contain all reasonable ? and L,<br />while allowing the adaptive algorithm enough time to<br />explore. Alternatively, one could gauge the hardness<br />of the sampling problem at hand and set more rea-<br />sonable bounds. In general, harder sampling problems<br />require a smaller ? and a larger L. We follow this sec-<br />ond strategy throughout our experiments and found<br />that most sensible bounds led to performance similar<br />to the ones reported.<br />4. Analysis of Convergence<br />The proof of ergodicity of the adaptive HMC algorithm<br />capitalizes on existing results for Langevin diffusions<br />and adaptive MCMC on compact state spaces. The<br />method of proof is based on the standard Lyapunov<br />stability functions, also known as drift or potential<br />functions.<br />We assume that our target distribution is compactly<br />supported on M. In practice, for target distributions<br />that are not compactly supported, we could set M<br />large enough to contain most of the mass of our tar-<br />get distribution. The sampler is restricted to M by<br />following this standard approach of rejecting all pro-<br />posals that fall outside M.<br />Let {Pγ}γ∈Γbe a collection of Markov chain kernels,<br />each admitting π as the stationary distribution. That<br />is, for each value of γ = (?,L), we have one such kernel.<br />Moreover, let Pn<br />γ denote the n-step Markov kernel.<br />Our proof requires the following classical definitions:<br />Definition 1. (Small set) A subset of the state space<br />C ⊆ X is small if there exists n0∈ N+, ξ &gt; 0 and a<br />probability measure ν(.) such that Pn0(x,·) ≥ ξν(·)<br />∀x ∈ C.<br />Definition 2. (Drift condition) A Markov chain<br />satisfies the drift condition if for a small set C, there<br />exist constants 0 &lt; λ &lt; 1 and b &lt; ∞, and a function<br />V : X → [1,∞] such that ∀x ∈ X<br />?<br />X<br />P(x,dy)V (y) ≤ λV (x) + b1C(x).<br />Having defined the necessary concepts, we now move<br />on to show the ergodicity of our adapted approach.<br />Proposition 3. Suppose that Pγ, when restricted to<br />a compact set M, admits the stationary distribution π<br />for all γ ∈ Γ. If π is continuous, positive and bounded<br />on M, and |Γ| is finite, then the adaptive HMC sam-<br />pler is ergodic.<br />Proof. To show that adaptive HMC converges on a<br />compact set, we first show that M is a small set.<br />The transition kernel of the random time HMC algo-<br />rithm can be written as Pγ(x,.) =<br />where Ql,?(x,.) is the transition kernel of an HMC<br />sampler that takes l leapfrog steps with parameter<br />?. In particular Q1,?(x,.) is the transition kernel of<br />Metropolis adjusted Langevin algorithm (MALA). As<br />π is bounded, and the proposal distribution of MALA<br />is positive every where, we have that Q1,? is µLeb-<br />irreducible. By a slight modification of Theorem 2-2<br />in Roberts &amp; Tweedie (1996), for Markov chains de-<br />fined by MALA, and any compact set C with posi-<br />tive Lebesgue measure (i.e. µLeb(C) &gt; 0) there exists<br />ξ &gt; 0 and a probability measure ν(·) such that ∀x ∈ C<br />Q1<br />1,?(x,.) ≥ ξν(.). Hence, M is a small set since<br />?L<br />l=1<br />1<br />LQl,?(x,.)<br />P1<br />γ(x,.) ≥1<br />LQ1<br />1,?(x,.) ≥1<br />Lξν(.)<br />for any compact set C where µLeb(C) &gt; 0. The drift<br />condition is trivially satisfied by each HMC sampler<br />when we choose C to be M, and V to be such that<br />V (x) = 1 for all x.<br />Having proved these conditions, we can now appeal to<br />Theorem 15.0.1 of Meyn &amp; Tweedie (1993) to conclude<br />that ?Pn<br />0 &lt; ργ&lt; 1. Since V (X) = 1 ∀x, we have<br />?Pn<br />γ(x,·) − π(·)? &lt; RγV (x)ρn<br />γfor all n and for<br />γ(x,·) − π(·)? &lt; Rγρn<br />γ.<br />Define Rmax= supγ∈ΓRγand ρmax= supγ∈Γργ, then<br />∀x ∈ M and ∀γ ∈ Γ we have<br />?Pn<br />γ(x,·) − π(·)? &lt; Rmaxρn<br />max.</p>  <p>Page 6</p> <p>Adaptive Hamiltonian and Riemann Manifold Monte Carlo Samplers<br />We have shown that the kernels {Pγ(x,·)}γ∈Γare si-<br />multaneously uniformly ergodic. Also, the adaptive<br />HMC sampler has diminishing adaptation by design.<br />By Theorem 5 of Roberts &amp; Rosenthal (2007), these<br />two conditions imply the claim of our proposition.<br />In general two sets of conditions together guarantee<br />ergodicity of an adaptive MCMC algorithm (Roberts<br />&amp; Rosenthal, 2007; Atchad´ e &amp; Fort, 2010). First, the<br />adaptation has to diminish eventually.<br />set of conditions is usually placed on the underlying<br />MCMC samplers. In Roberts &amp; Rosenthal (2007), the<br />samplers are required to be either simultaneously uni-<br />formly or geometrically ergodic. Without restricting<br />the state space to be compact, it is unlikely that HMC<br />is uniformly ergodic. Also, to the best of our knowl-<br />edge, no theoretical results exist on the geometric er-<br />godicity of HMC when the state space is not com-<br />pact.However, Roberts &amp; Stramer (2002) showed<br />that Langevin diffusion, which is closely related to<br />HMC, is geometrically ergodic.<br />challenge would be to prove or disprove geometric er-<br />godicity of HMC in general state spaces. Atchad´ e &amp;<br />Fort (2010) weakened the conditions required, still re-<br />quiring diminishing adaptation, but the requirements<br />on the underlying MCMC samplers were reduced to<br />sub-geometric ergodicity. Although these conditions<br />are weaker, it remains hard to check whether HMC<br />satisfies them.<br />The second<br />Thus one potential<br />5. Results<br />We show the performance of our adaptive algorithm<br />on four widely-used models. We evaluate the perfor-<br />mance of the samplers using the effective sample size<br />(ESS) using: ESS = R(1 + 2?<br />K monotone sample auto-correlations computed using<br />the monotone sequence estimator (Girolami &amp; Calder-<br />head, 2011). We adopt the total number of leapfrog<br />steps used in producing the set of samples as a proxy<br />for computational demand, since the computation is<br />dominated by the gradient evaluation required for each<br />leapfrog step. An efficient sampler will result in the<br />highest ESS for the least computation, and we will<br />thus report the effective sample size per leapfrog step<br />used (ESS/L), similarly to Hoffman &amp; Gelman (2011),<br />since this takes into account computational require-<br />ments. We compute the ESS/L over all dimensions of<br />the target distribution and report the minimum, me-<br />dian and maximum ESS obtained. While we report<br />all three summary statistics, we focus on the mini-<br />mum ESS/L as the most useful measure, since this<br />allows us to evaluate the efficiency of the most con-<br />kρk), where R is the<br />kρkis the sum of<br />number of posterior samples, and?<br />fined coordinate, and is more indicative of ESS jointly<br />over all coordinates rather than, as computed, over ev-<br />ery coordinate independently (Neal, 2010; Girolami &amp;<br />Calderhead, 2011).<br />We compare our adaptive HMC to NUTS, and ex-<br />tend our approach and compare an adaptive version<br />of RMHMC to the standard RMHMC. For NUTS,<br />we tuned the free parameters of its dual averaging<br />algorithm to obtain the best performance, and for<br />RMHMC we use the experimental protocol and code<br />used by Girolami &amp; Calderhead (2011). We do this<br />for all experiments in this section. Code to reproduce<br />these results will be available online.<br />5.1. Bayesian Logistic Regression<br />We consider a data set X consisting of N observations<br />and D features or covariates, and a binary label y.<br />Using regression coefficients β and bias β0 the joint<br />distribution for the logistic regression model is:<br />logp(X,y,β,β0)∝logp(y|X,β,β0)+logp(β)+logp(β0)<br />?<br />=−<br />i<br />log?1+exp?−yi(β0+x?<br />iβ)??−β2<br />0<br />2σ2−β?β<br />2σ2, (1)<br />where yi ∈ {−1,1}, and σ2is the prior variance of<br />the regression coefficients. We present results on five<br />data sets from the UCI repository. The data sets have<br />varying characteristics with features D ranging from<br />2 to 24, and the number of observations from 250 to<br />1000. For each data set, we generate 5000 samples<br />after a burnin phase of 1000 samples, and repeat this<br />process 10 times using differing starting points. The<br />top row of figure 2 compares the performance of our<br />adaptive HMC (AHMC) to NUTS, while the bottom<br />row compares our adaptive RMHMC (ARMHMC) to<br />RMHMC. For this experiment, for AHMC, we set Γ<br />such that ? ∈ [0.01,0.2] and L ∈ {0,··· ,100}, and for<br />ARMHMC, we use ? ∈ [0.1,1] and L ∈ {1,··· ,12}.<br />The columns of figure 2 shows box plots of the<br />minimum, median and maximum ESS/L values ob-<br />tained. We see that the adaptive methods (AHMC<br />and ARMHMC) exhibit good performance. For the<br />minimum ESS/L, AHMC has better (higher) values<br />that NUTS for all the data sets, and this behavior is<br />consistent across most other data sets for the other<br />summary statistics. Thus AHMC typically provides<br />better performance and a higher effective number of<br />samples per unit of computation used than NUTS. We<br />also see that the ARMHMC can improve RMHMC and<br />provide better ESS/L on what is already a highly effi-<br />cient sampler.</p>  <p>Page 7</p> <p>Adaptive Hamiltonian and Riemann Manifold Monte Carlo Samplers<br />German RipleyPimaHeart Australian<br />0<br />200<br />400<br />600<br />800<br />1000<br />1200<br />HMC Samplers<br />Minimum ESS/L<br /> <br /> <br />AHMC<br />NUTS<br />German RipleyPimaHeart Australian<br />0<br />200<br />400<br />600<br />800<br />1000<br />1200<br />Median ESS/L<br />German RipleyPimaHeart Australian<br />0<br />500<br />1000<br />1500<br />Maximum ESS/L<br />German RipleyPima Heart Australian<br />500<br />1000<br />1500<br />2000<br />2500<br />3000<br />RMHMC Samplers<br /> <br /> <br />ARMHMC<br />RMHMC<br />German Ripley PimaHeart Australian<br />500<br />1000<br />1500<br />2000<br />2500<br />3000<br />German Ripley PimaHeart Australian<br />500<br />1000<br />1500<br />2000<br />2500<br />3000<br />Figure 2. Box plots comparing ESS/L for Bayesian logis-<br />tic regression. Top row: AHMC vs NUTS. Bottom row:<br />ARMHMC vs RMHMC.<br />5.2. Log-Gaussian Cox Point Process<br />We model a data set Y = {yij} that consists of counts<br />at locations (i,j),i,j = 1...,d in a regular spatial grid<br />using a log-Gaussian Cox point process (LGC) (Chris-<br />tensen et al., 2005; Girolami &amp; Calderhead, 2011). Ob-<br />servations yij are Poisson distributed and condition-<br />ally independent given a latent intensity process Λ =<br />{λij} with means sλij = sexp(xij), where s =<br />The rates X = {xij} are obtained from a Gaussian<br />process with mean function m(xij) = µ1 and covari-<br />ance function Σ(xij,xi?j?) = σ2exp(−δ(i,i?,j,j?)/βd),<br />where δ(i,i?,j,j?) =<br />probability logp(y,x|µ,σ,β) is proportional to:<br />?<br />We generate samples jointly for x,σ,µ,β using a grid<br />of size d = 64, using a synthetic data set obtained by<br />drawing from the generative process for this model.<br />We generate 5000 samples after a burnin of 1000<br />samples. For this model, we use L ∈ {1,··· ,500},<br />? ∈ [0.001,0.1] for AHMC, and use L ∈ {1,··· ,60},<br />? ∈ [0.01,1] for ARMHMC. We compare the perfor-<br />mance of the adaptive method we presented in terms<br />of ESS per leapfrog step in figure 3.<br />AHMC versus NUTS and ARMHMC versus RMHMC,<br />showing the minimum, median and maximum ESS<br />per leapfrog step obtained for 10 chains with dis-<br />persed starting points. We see that almost all points<br />lie below the diagonal line, which indicates that the<br />AHMC and ARMHMC have better ESS/L compared<br />to NUTS and RMHMC, respectively. Thus even for<br />high-dimensional models with strong correlations our<br />adaptive method allows for automatic tuning of the<br />sampler and consequently the ability to obtain higher<br />quality samples than with competing methods.<br />1<br />d2.<br />?(i − i?)2+ (j − j?)2. The joint<br />yijxij−dexp(xij)−1<br />i,j<br />2(x−µ1)?Σ−1(x−µ1). (2)<br />We compare<br />We examine the quality of the posterior distribution<br />05 1015202530<br />0<br />5<br />10<br />15<br />20<br />25<br />30<br />NUTS<br />AHMC<br />ESS/L<br /> <br /> <br />Minimum<br />Median<br />Maximum<br />0100 200300<br />ARMHMC<br />400500600 700<br />0<br />100<br />200<br />300<br />400<br />500<br />600<br />700<br />RMHMC<br />ESS/L<br />Figure 3. Comparing minimum (red), median (blue) and<br />maximum (black) ESS/L for the Log-Gaussian Cox model.<br />Each of the colored glyphs represents one of the 10 chains<br />generated.<br />True Data<br />Latent Field x<br />Latent Process λ<br />Variance<br />AHMC<br />NUTS<br />Figure 4. Comparing quality of posterior distributions<br />from samples obtained using AHMC and NUTS for the<br />log-Gaussian Cox model. The top-right image shows the<br />locations of the true data.<br />obtained for AHMC and NUTS in figure 4, by visualiz-<br />ing the latent field and its variance, and comparing to<br />the true data (which is known for this data set). The<br />top row shows the true latent fields. From the true<br />data observations (shown in top right corner), we see<br />that there are few data points in this region and thus<br />we expect to have a high variance in this region. The<br />average of the samples obtained using AHMC shows<br />that we can accurately obtain samples from the latent<br />field x, and that the samples have a variance matching<br />our expectations. While NUTS is able to also produce<br />good samples of the latent field, the variance of the<br />field is not well captured (bottom right image).</p>  <p>Page 8</p> <p>Adaptive Hamiltonian and Riemann Manifold Monte Carlo Samplers<br />Table 1. Comparative results for the stochastic volatility<br />model.<br />ESS per Leapfrog<br />Samplerminimum<br />AHMC<br />1.3 ± 0.1<br />NUTS<br />0.7 ± 0.3<br />5.3. Stochastic Volatility<br />median<br />6.9 ± 0.7<br />3.5 ±1.6<br />maximum<br />14.9 ±1.4<br />9 ±2.8<br />We consider a stochastic volatility model described by<br />Kim et al. (1998) and Girolami &amp; Calderhead (2011),<br />in which we consider observations yt, regularly spaced<br />in time for t = 1,...,T. Each ytis specified using a<br />latent variable xt, which represents the log-volatility<br />following auto-regressive AR(1) dynamics. The model<br />is specified as:<br />yt=?tβ exp(0.5xt),?t∼N(0,1)<br />ηt+1∼N(0,σ2)<br />p(β) ∝1<br />(3)<br />xt+1=φxt+ ηt+1, (4)<br />x1∼N<br />?<br />0,<br />σ2<br />1 − φ2<br />?<br />,<br />β.<br />(5)<br />For stationarity of the log-volatility, |φ| &lt; 1, and the<br />standard deviation σ &gt; 0, whose priors we set to<br />φ+1<br />2<br />∼ Beta(20,1.5) and σ2∼ inv-χ2(10,0.05), re-<br />spectively. The parameters to be sampled by HMC is<br />thus Θ = {x,β,φ,σ2}, and the joint probability is:<br />p(y,Θ)=<br />T?<br />t=1<br />p(yt|xt,β)p(xt|xt−1,φ,σ2)p(β)p(σ2)p(φ). (6)<br />We make use of the transformations σ = exp(γ) and<br />φ = tanh(α) to ensure that we sample using un-<br />constrained variables; the use of this transformation<br />requires the addition of the Jacobian of the trans-<br />formation of variables. We generate samples jointly<br />using our AHMC methods, using training data with<br />T = 2000. For our experiments, we use a burnin pe-<br />riod of 10,000 samples and thereafter generate 20,000<br />posterior samples. We restrict our box constraint such<br />that L ∈ {1,··· ,300}, ? ∈ [10−4,10−2]. We show the<br />results comparing ESS for the two methods in table<br />1. These results again show higher values for ESS per<br />leapfrog step, demonstrating that a better perform-<br />ing sampler can be obtained using AHMC – further<br />demonstrating the advantages of AHMC methods for<br />sampling from complex hierarchical models.<br />5.4. Bayesian Neural Networks<br />We demonstrate the application of our adaptive ap-<br />proach using Bayesian neural networks (BNNs) to<br />show that AHMC allows for more effective sampling<br />of posterior parameters even when compared to sam-<br />plers finely tuned by an expert. We make use of the<br />Dexter data set from the NIPS 2003 feature selection<br />challenge, which is a subset of the well-known Reuters<br />text categorization benchmark. The winning entries<br />submitted by Neal &amp; Zhang (2006) used a number of<br />feature selection techniques followed by a combination<br />of Bayesian Neural Networks and Dirichlet diffusion<br />trees. The entry that used only BNNs was placed sec-<br />ond and achieved highly competitive results (Guyon<br />et al., 2005).<br />The BNN model consists of 295 input features and<br />2 hidden layers with 20 and 8 hidden units respec-<br />tively. The input features are selected from the full set<br />of features through univariate feature selection. The<br />weights and bias as well as a few other parameters of<br />this particular network adds up to form a 6097 dimen-<br />sional state space for the HMC sampler.<br />For this model, we use cross-validation to construct<br />the reward signal.We divide the data into n sets,<br />and train n BNNs each on n − 1 sets and test them<br />on the remaining set like in the case of normal cross-<br />validation. The cross-validation error is then used to<br />calculate the reward. To take computation into ac-<br />count, we always evaluate the reward over the same<br />number of leapfrog steps, i.e. for each evaluation of<br />the reward we use a different number of samples and<br />a different number of leapfrog steps for each sample,<br />but the product of the two remains constant.<br />We compare the results in table 2, where the perfor-<br />mance measure is the prediction error on a test set<br />(unknown to us) and was obtained after submission<br />to the competition system. The improved results ob-<br />tained using the AHMC strategy are clear from the ta-<br />ble, also demonstrating that good adaptation can be<br />preferable to the introduction of more sophisticated<br />models.<br />Table 2. Classification error on the test set of the Dexter<br />data set. The table shows the mean and the median pre-<br />diction errors of our 8 BNNs trained as in cross-validation.<br />The majority vote of these 8 networks achieves slightly<br />better results than that of a more sophisticated model in-<br />volving Dirichlet diffusion trees.<br />Method<br />Expert-tuned HMC for BNN<br />AHMC for BNN (Mean error)<br />AHMC for BNN (Median error)<br />Winning entry (using Dirichlet Diffusion Trees)<br />AHMC for BNN + Majority Voting<br />Error<br />0.0510<br />0.0498<br />0.0458<br />0.0390<br />0.0355<br />6. Discussion and Conclusion<br />In section 3 we described the use the expected squared<br />jumping distance as a suitable objective. Several other<br />objectives, such as the mean update distance, cross-<br />validation error and the cumulative auto-correlation,<br />are also suitable, and their use depends on the</p>  <p>Page 9</p> <p>Adaptive Hamiltonian and Riemann Manifold Monte Carlo Samplers<br />particular modelling problem.<br />learning tasks, researchers design MCMC algorithms<br />to estimate model parameters and, subsequently,<br />evaluate these models using cross-validation, such as<br />the competition task in section 5.4. Moreover, often<br />researchers modify their samplers so as to reduce<br />test set error. In this paper, we demonstrate the use<br />of predictive losses, such as cross-validation error,<br />to guide the adaptation.<br />never reported before to the best of our knowledge,<br />simply makes the tuning process followed by many<br />researchers explicit.Ultimately the models whose<br />parameters we are estimating by running a Markov<br />chain will be tested on predictive tasks.<br />is natural to use predictive performance on such<br />predictive tasks to improve the exploration of the<br />posterior distribution.Of course, these objective<br />measures are only applicable when sufficient data is<br />available to obtain good predictive estimates.<br />In many machine<br />This approach, although<br />Hence, it<br />We<br />in tuning Hamiltonian-based Monte Carlo samplers<br />by developing algorithms for infinite adaptation of<br />these Markov chains using Bayesian optimization.<br />The adaptive Hamiltonian Monte Carlo and adaptive<br />Riemann manifold HMC we developed automate the<br />process of finding the best parameters that control<br />the performance of the sampler, removing the need<br />for time-consuming and expert-driven tuning of these<br />samplers.Our experiments show conclusively that<br />over a wide range of models and data sets, the use<br />of adaptive algorithms makes it easy to obtain more<br />efficient samplers, in some cases precluding the need<br />for more complex approaches.<br />Monte Carlo samplers are widely known to be an<br />excellent choice of MCMC method, and we hope that<br />this paper removes a key obstacle towards the more<br />widespread use of these samplers in practice.<br />addressed the widely-experienceddifficulty<br />Hamiltonian-based<br />References<br />Andrieu, Christophe and Robert, Christian.<br />MCMC for optimal sampling. Technical Report 0125,<br />Cahiers de Mathematiques du Ceremade, Universite<br />Paris-Dauphine, 2001.<br />Andrieu, Christophe, de Freitas, Nando, Doucet, Arnaud,<br />and Jordan, Michael I. An Introduction to MCMC for<br />Machine Learning. Machine Learning, 50(1):5–43, 2003.<br />Atchad´ e, Yves and Fort, Gersende.<br />some adaptive MCMC algorithms with subgeometric<br />kernels. Bernoulli, 16(1):116–154, 2010.<br />Beskos, Alexandros, Pillai, Natesh S., Roberts, Gareth O.,<br />Sanz-Serna, Jesus M., and Stuart, Andrew M. Optimal<br />tuning of the hybrid Monte-Carlo algorithm. Preprint<br />arXiv:1001.4460, 2010.<br />Controlled<br />Limit theorems for<br />Brochu, Eric, Cora, Vlad M, and de Freitas, Nando. A tu-<br />torial on Bayesian optimization of expensive cost func-<br />tions. Preprint arXiv:1012.2599, 2009.<br />Chen, Lingyu, Qin, Zhaohui, and Liu, Jun S. Exploring<br />Hybrid Monte Carlo in Bayesian Computation. Sigma,<br />2:2–5, 2001.<br />Christensen, Ole F., Roberts, Gareth O., and Rosenthal,<br />Jeffrey S. Scaling limits for the transient phase of local<br />Metropolis–Hastings algorithms. Journal of the Royal<br />Statistical Society: Series B, 67(2):253–268, 2005.<br />Duane, S, Kennedy, A D, Pendleton, B J, and Roweth, D.<br />Hybrid Monte Carlo. Physics Letters B, 195(2):216–222,<br />1987.<br />Engel, Yaakov. Algorithms and representations for rein-<br />forcement learning. Doktorarbeit, The Hebrew Univer-<br />sity of Jerusalem, 2005.<br />Girolami, Mark and Calderhead, Ben. Riemann manifold<br />Langevin and Hamiltonian Monte Carlo methods. Jour-<br />nal of the Royal Statistical Society: Series B, 73(2):123–<br />214, 2011.<br />Guyon, Isabelle, Gunn, Steve, Ben-Hur, Asa, and Dror,<br />Gideon. Result analysis of the NIPS 2003 feature se-<br />lection challenge. In Advances in Neural Information<br />Processing Systems, volume 17, pp. 545–552, 2005.<br />Hamze, Firas, Wang, Ziyu, and de Freitas, Nando. Self-<br />avoiding random dynamics on integer complex systems.<br />ACM Transactions on Modeling and Computer Simula-<br />tion, 23(1):9:1–9:25, 2013.<br />Hoffman, Matthew, Brochu, Eric, and de Freitas, Nando.<br />Portfolio allocation for Bayesian optimization. In Un-<br />certainty in Artificial Intelligence, pp. 327–336, 2011.<br />Hoffman, Matthew D and Gelman, Andrew.<br />U-Turn Sampler: Adaptively setting path lengths in<br />Hamiltonian Monte Carlo.<br />2011.<br />Ishwaran, Hemant. Applications of hybrid Monte Carlo to<br />Bayesian generalized linear models: Quasicomplete sep-<br />aration and neural networks. Journal of Computational<br />and Graphical Statistics, 8(4):779–799, 1999.<br />Kim, Sangjoon, Shephard, Neil, and Chib, Siddhartha.<br />Stochastic volatility: likelihood inference and compari-<br />son with ARCH models. The Review of Economic Stud-<br />ies, 65(3):361–393, 1998.<br />Mahendran, Nimalan, Wang, Ziyu, Hamze, Firas, and<br />de Freitas, Nando. Adaptive MCMC with Bayesian op-<br />timization. Articial Intelligence and Statistics, 2012.<br />Meyn, Sean P. and Tweedie, Richard L. Markov chains<br />and stochastic stability. Springer-Verlag, 1993.<br />Moˇ ckus, Jonas. The Bayesian approach to global optimiza-<br />tion. In System Modeling and Optimization, volume 38,<br />pp. 473–481. Springer, 1982.<br />Mohamed, Shakir, Heller, Katherine, and Ghahramani,<br />Zoubin. Bayesian exponential family PCA. In Advances<br />in Neural Information Processing Systems, pp. 1089–<br />1096. 2008.<br />Neal, R. and Zhang, J. High dimensional classification with<br />Bayesian neural networks and Dirichlet diffusion trees.<br />In Feature Extraction, pp. 265–296. Springer, 2006.<br />Neal, Radford M. MCMC using Hamiltonian dynamics.<br />The No-<br />Preprint arXiv:1111.4246,</p>  <p>Page 10</p> <p>Adaptive Hamiltonian and Riemann Manifold Monte Carlo Samplers<br />Handbook of Markov Chain Monte Carlo, 54:113–162,<br />2010.<br />Pasarica, Cristian and Gelman, Andrew. Adaptively scal-<br />ing the Metropolis algorithm using expected squared<br />jumped distance. Statistica Sinica, 20(1):343, 2010.<br />Ranzato, Marc’Aurelio and Hinton, Geoffrey.<br />pixel means and covariances using factorized third-order<br />Boltzmann machines. In IEEE Computer Vision and<br />Pattern Recognition, pp. 2551–2558, 2010.<br />Rasmussen, Carl Edward and Williams, Christopher K I.<br />Gaussian Processes for Machine Learning. MIT Press,<br />Cambridge, Massachusetts, 2006.<br />Roberts, Gareth O. and Rosenthal, Jeffrey S. Coupling<br />and ergodicity of adaptive Markov chain Monte Carlo<br />algorithms. Journal of applied probability, 44(2):458–<br />475, 2007.<br />Roberts, Gareth O. and Stramer, Osnat. Langevin diffu-<br />Modeling<br />sions and Metropolis-Hastings algorithms. Methodology<br />and computing in applied probability, 4(4):337–357, 2002.<br />Roberts, Gareth O and Tweedie, Richard L. Geometric<br />convergence and central limit theorems for multidimen-<br />sional Hastings and Metropolis algorithms. Biometrika,<br />83(1):95–110, 1996.<br />Snoek,Jasper, Larochelle,<br />Ryan Prescott. Practical Bayesian optimization of<br />machine learning algorithms.<br />Processing Systems, 2012.<br />Srinivas, Niranjan, Krause, Andreas, Kakade, Sham M.,<br />and Seeger, Matthias. Gaussian process optimization in<br />the bandit setting: No regret and experimental design.<br />In International Conference on Machine Learning, 2010.<br />Vihola, Matti. Grapham: Graphical models with adap-<br />tive random walk Metropolis algorithms. Computational<br />Statistics and Data Analysis, 54(1):49 – 54, 2010.<br />Hugo,and Adams,<br />In Neural Information</p>   </div> <div id="rgw19_56aba076a1103" class="c-box pub-resource-container js-toggle" style=""> <h4 class="lf js-expand-list"><small><a href="javascript:" class="lf">View other sources <span class="ico-expand-list"></span></a></small></h4> <h4 class="lf js-collapse-list hidden"><small><a href="javascript:" class="lf">Hide other sources <span class="ico-collapse-list"></span></a></small></h4> <div class="clear"></div> <div class="scroll-wrapper hidden"> <ul class="files-list c-list" id="rgw20_56aba076a1103">  <li class="c-list-item pub-resource-item"  data-type="fulltext" id="rgw21_56aba076a1103"> <span class="ico-pub"></span> <div class="file-content"> <div class="download"> <a href="http://export.arxiv.org/pdf/1302.6182" target="_blank" rel="nofollow" class="publication-viewer" title="Adaptive Hamiltonian and Riemann Manifold Monte Carlo Samplers">Adaptive Hamiltonian and Riemann Manifold Monte Ca...</a> </div>  <div class="details">   Available from <a href="http://export.arxiv.org/pdf/1302.6182" target="_blank" rel="nofollow">export.arxiv.org</a>  </div>    </div> </li>  </ul> </div> </div> </noscript> <div class="clearfix"> <div class="action-container">  </div> <div class="pub-legal"> Data provided are for informational purposes only. Although carefully collected, accuracy cannot be guaranteed. The impact factor represents a rough estimation of the journal's impact factor and does not reflect the actual current impact factor. Publisher conditions are provided by RoMEO. Differing provisions from the publisher's actual policy or licence agreement may be applicable. </div>   </div> </div> <div class="clearfix">     <div id="rgw23_56aba076a1103" class="c-box pub-resource-container js-toggle" style="display: none;"> <h4 class="lf js-expand-list"><small><a href="javascript:" class="lf">View other sources <span class="ico-expand-list"></span></a></small></h4> <h4 class="lf js-collapse-list hidden"><small><a href="javascript:" class="lf">Hide other sources <span class="ico-collapse-list"></span></a></small></h4> <div class="clear"></div> <div class="scroll-wrapper hidden"> <ul class="files-list c-list" id="rgw24_56aba076a1103">  </ul> </div> </div>   <div id="rgw15_56aba076a1103" class="similar-publications"> <h2>Similar Publications</h2> <ul class="list-bordered">  <li class="c-list-item li-publication-teaser" id="rgw16_56aba076a1103"> <div> <h5> <a href="publication/263736747_Solving_Large-Scale_PDE-constrained_Bayesian_Inverse_Problems_with_Riemann_Manifold_Hamiltonian_Monte_Carlo" class="color-inherit ga-similar-publication-title"><span class="publication-title">Solving Large-Scale PDE-constrained Bayesian Inverse Problems with Riemann Manifold Hamiltonian Monte Carlo</span></a>  </h5>  <div class="authors"> <a href="researcher/72108042_Tan_Bui-Thanh" class="authors ga-similar-publication-author">Tan Bui-Thanh</a>, <a href="researcher/19524381_Mark_Girolami" class="authors ga-similar-publication-author">Mark Girolami</a>  </div>  </div> <div class="clear"></div> </li>  <li class="c-list-item li-publication-teaser" id="rgw17_56aba076a1103"> <div> <h5> <a href="publication/47637681_Discussion_of_Riemann_manifold_Langevin_and_Hamiltonian_Monte_Carlo_methods%27%27_by_M_Girolami_and_B_Calderhead" class="color-inherit ga-similar-publication-title"><span class="publication-title">Discussion of &quot;Riemann manifold Langevin and Hamiltonian Monte Carlo methods&#39;&#39; by M. Girolami and B. Calderhead</span></a>  </h5>  <div class="authors"> <a href="researcher/47303477_Luke_Bornn" class="authors ga-similar-publication-author">Luke Bornn</a>, <a href="researcher/46559484_Julien_Cornebise" class="authors ga-similar-publication-author">Julien Cornebise</a>, <a href="researcher/34112724_Gareth_W_Peters" class="authors ga-similar-publication-author">Gareth W. Peters</a>  </div>  </div> <div class="clear"></div> </li>  <li class="c-list-item li-publication-teaser" id="rgw18_56aba076a1103"> <div> <h5> <a href="publication/47651278_Discussions_on_Riemann_manifold_Langevin_and_Hamiltonian_Monte_Carlo_methods" class="color-inherit ga-similar-publication-title"><span class="publication-title">Discussions on &quot;Riemann manifold Langevin and Hamiltonian Monte Carlo methods&quot;</span></a>  </h5>  <div class="authors"> <a href="researcher/57038265_Simon_Barthelme" class="authors ga-similar-publication-author">Simon Barthelme</a>, <a href="researcher/34883089_Magali_Beffy" class="authors ga-similar-publication-author">Magali Beffy</a>, <a href="researcher/11144908_Nicolas_Chopin" class="authors ga-similar-publication-author">Nicolas Chopin</a>, <a href="researcher/2061952066_Arnaud_Doucet" class="authors ga-similar-publication-author">Arnaud Doucet</a>, <a href="researcher/48987261_Pierre_Jacob" class="authors ga-similar-publication-author">Pierre Jacob</a>, <a href="researcher/42467195_Adam_M_Johansen" class="authors ga-similar-publication-author">Adam M. Johansen</a>, <a href="researcher/12567635_Jean-Michel_Marin" class="authors ga-similar-publication-author">Jean-Michel Marin</a>, <a href="researcher/61296156_Christian_P_Robert" class="authors ga-similar-publication-author">Christian P. Robert</a>  </div>  </div> <div class="clear"></div> </li>  </ul> </div> </div> </div> </div> </div></div></div>
<div class="clear"></div><div id="rgw29_56aba076a1103" class="default-footer"> <div id="footer" class="clearfix"> <span class="footer-left"> &copy; 2008&dash;2016 researchgate.net. All rights reserved. </span> <span class="footer-right"> <a href="https://www.researchgate.net/about">About us</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="https://www.researchgate.net/contact">Contact us</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="careers">Careers</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="developers">Developers</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="blog" target="_blank">News</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="application.PrivacyPolicy.html">Privacy</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="application.TermsAndConditions.html">Terms</a> <span class="footer-link-separator" style="padding: 0 5px;">&nbsp;|&nbsp;</span> <a href="advertising?_ref=ft">Advertising</a> <span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="recruiters?_ref=ft">Recruiting</a> </span> </div>  </div></div>
<div id="rgw30_56aba076a1103">  <div class="header-wrapper-logged-out"> <div id="header"> <div class="header-content"> <a href="" class="g-l-logo"> <svg width="149" height="19"> <image xlink:href="https://c5.rgstatic.net/m/235107188705592/images/template/brand-header-logo.svg" src="https://c5.rgstatic.net/m/238113351022438/images/template/brand-header-logo.png" width="149" height="19"/> </svg> </a> <a href="" class="g-l-logo-ico"> <svg width="127" height="17" viewbox="0 0 127 22"> <image xlink:href="https://c5.rgstatic.net/m/235107188705592/images/template/brand-header-logo.svg" src="https://c5.rgstatic.net/m/238113351022438/images/template/brand-header-logo.png" width="127" height="17"/> </svg> </a> <div id="rgw31_56aba076a1103" class="header-login-wrapper js-header-login"> <div class="dropdown-right-align"> <div class="login-signup-container lf"> <a href="https://www.researchgate.net/signup.SignUp.html?ev=su_chnl_index&amp;hdrsu=1&amp;_sg=h0VoMcWXFU3HOJWsPiBeJBcV3gsE9TmFlIAjNq08kHdNC7djgoEPy0byDBNO6Gvx" class="dropdown-toggle lf">Join for free</a> </div> <div class="dropdown lf" style="height: 20px;"> <a href="https://www.researchgate.net/application.Login.html" class="js-login-url dropdown-toggle lf">Log in <span class="caret"></span></a> <div class="dropdown-menu"> <div class="header-login-form-wrapper"> <!--[if IE 6]><p class="box-warning" style="margin-bottom: 0;">Sorry, ResearchGate no longer supports the version of Internet Explorer you are using. <a href="http://whatbrowser.org/" rel="nofollow" target="_blank">Update your web browser</a> and then log in. </p><![endif]--> <form method="post" action="https://www.researchgate.net/application.Login.html" class="form-big header-login-form js-login-form" name="loginForm" id="headerLoginForm"> <input type="hidden" name="request_token" value="sbCzf1k4kB+o4TMjbo3hVn7PG3jO27Yb+XRNGW6sbzIIQXJPWpP3+UCh5UsRPZR+SFg6s/Jtc9NcqFvBnjKeNwsNyCehLU28WqmifRjYu1cGxb3TEWkh4HelnRIKpnMjIPv7O5q5v5PLPfozlmrvZyEP8ZnleeA1JP3fRI39ZQQ4b3PkBFLBOZiKz6i9Wg5GaF4+Tr3HLW8EQSvWGgBa7eF+FgqLHp0aqVG4KH036+yL2mclXM93TlMU60WvogEJiwxLtzYNSgGUnisO8Nl9KW+8PN5JJZBIQPAN6tWNu/c="/> <input type="hidden" name="urlAfterLogin" value="publication/235703008_Adaptive_Hamiltonian_and_Riemann_Manifold_Monte_Carlo_Samplers"/> <input type="hidden" name="invalidPasswordCount" value="0"/> <input type="hidden" name="headerLogin" value="yes"/> <label for="input-header-login">Email</label> <div class="login-input"> <div class="info-tip-wrapper"> <span class="ico-info js-info"></span> </div> <input type="email" value="" name="login" class="login js-login-input text" id="input-header-login" tabindex="1"/> </div> <div class="clear"></div> <label class="lf" for="input-header-password"> Password </label> <a class="rf forgot-password js-forgot-password" href="application.LostPassword.html">Forgot password?</a> <div class="clear"></div> <input type="password" value="" name="password" class="password js-password-input text" id="input-header-password" tabindex="2"/> <div class="clear"></div> <label class="remember-me" for="headerLoginCookie"> <input type="checkbox" checked="checked" value="yes" name="setLoginCookie" class="lf checkbox" id="headerLoginCookie" tabindex="3"/> Keep me logged in </label> <div class="clear"></div> <input value="Log in" name="loginSubmit" class="btn btn-promote btn-fullwidth btn-large allow-leave js-submit-button" type="submit" tabindex="4"/> </form> <div class="connectors"> <div class="text">or log in with</div> <div class="connector-actions"> <a href="connector/linkedin/" class="li-connect js-li-connect" data-redirect-url="cHVibGljYXRpb24vMjM1NzAzMDA4X0FkYXB0aXZlX0hhbWlsdG9uaWFuX2FuZF9SaWVtYW5uX01hbmlmb2xkX01vbnRlX0NhcmxvX1NhbXBsZXJz"> <span class="icon ico-linkedin-round-grey"></span> <span class="icon ico-linkedin-round"></span> </a> <a href="connector/facebook/" class="fb-connect middle js-fb-connect" data-redirect-url="cHVibGljYXRpb24vMjM1NzAzMDA4X0FkYXB0aXZlX0hhbWlsdG9uaWFuX2FuZF9SaWVtYW5uX01hbmlmb2xkX01vbnRlX0NhcmxvX1NhbXBsZXJz"> <span class="icon ico-facebook-round-grey"></span> <span class="icon ico-facebook-round"></span> </a> <a href="connector/google/" class="g-connect js-g-connect" data-redirect-url="cHVibGljYXRpb24vMjM1NzAzMDA4X0FkYXB0aXZlX0hhbWlsdG9uaWFuX2FuZF9SaWVtYW5uX01hbmlmb2xkX01vbnRlX0NhcmxvX1NhbXBsZXJz"> <span class="icon ico-google-round-grey"></span> <span class="icon ico-google-round"></span> </a> </div> </div> </div> </div> </div> </div> </div> </div> </div> <script type="application/ld+json">
{ "@context" : "http://schema.org",
  "@type" : "Organization",
  "name" : "ResearchGate",
  "url" : "http://www.researchgate.net",
  "logo" : "http://www.researchgate.net/images/template/rg_logo_square_brand.png",
  "sameAs" : [ "https://www.facebook.com/ResearchGate",
    "https://twitter.com/ResearchGate",
    "https://plus.google.com/+researchgate",
    "https://www.linkedin.com/company/researchgate"] 
}
</script> </div> </div><div class="c-signup-bar" id="rgw32_56aba076a1103"> <div class="banner-contents">   <span class="message">ResearchGate is the professional network for scientists and researchers.</span> <a href="signup.SignUp.html?ev=su_banner" class="btn btn-large btn-promote">Join for free</a>  </div> </div></div>
<script>
rgConfig.backendTime = 464;
</script>
<script src="//c5.rgstatic.net/m/2277196935388619/javascript/lib/yui3/yui/yui-min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/21832295316281274/javascript/yuiLoaderConfig-min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/23178613132105398/javascript/vendor/babel-core/browser-polyfill.min.js" type="text/javascript"></script>
<script>
(function (){
if (typeof YRG === "undefined") {
var xmlHttpRequest = new XMLHttpRequest();
xmlHttpRequest.open("post", "go.Error.html");
xmlHttpRequest.setRequestHeader("Content-Type", "application/json");
xmlHttpRequest.setRequestHeader("Accept", "application/json"); var loadedScripts = "";
if (window.performance && window.performance.getEntriesByType) {
    var result = [];
    var resources = performance.getEntriesByType("resource");
    for (var i in resources) {
        if (resources.hasOwnProperty(i)) {
            result.push({
                name: resources[i].name,
                duration: resources[i].duration
            });
        }
    }
    loadedScripts += "&loadedScripts=" + encodeURIComponent(JSON.stringify(result));
}
if (typeof YUI === "undefined") {
    loadedScripts += "&yuiLoaded=false";
} else {
    loadedScripts += "&yuiLoaded=true";
}
xmlHttpRequest.send("Type=InformationException&message=" + encodeURIComponent("Error loading YUI") + loadedScripts);
}
})();
</script>
<script>if (typeof YRG !== 'undefined') { YRG.use('rg-base',function(Y){Y.applyConfig({ignore: ["css-rg","css-rg2","css-ie","css-modules-publicprofile"]});Y.use(["rg.core.pagespeed.Monitoring"],function(Y){(function(){Y.rg.createInitialWidget({"data":{"content":{"data":{"profileSmallHeader":{"data":{"profileBadge":{"data":{"fullname":"Ziyu Wang","imageUrl":"https:\/\/i1.rgstatic.net\/ii\/profile.image\/AS%3A273771454005251%401442283609269_m","profileStats":[],"profileFollowButton":null,"profileReputationScoreNumber":null,"profileUrl":"profile\/Ziyu_Wang2","institution":"University of British Columbia - Vancouver","institutionUrl":false,"widgetId":"rgw4_56aba076a1103"},"id":"rgw4_56aba076a1103","partials":[],"templateName":"publicprofile\/stubs\/ProfileBadge.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicprofile.ProfileBadge.html?accountId=3158930","viewClass":null,"yuiModules":["css-modules-publicprofile"],"stylesheets":["modules\/publicprofile.css"],"_isYUI":true},"widgetId":"rgw3_56aba076a1103"},"id":"rgw3_56aba076a1103","partials":[],"templateName":"publicprofile\/stubs\/ProfileSmallHeader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicprofile.ProfileSmallHeader.html?publicationUid=235703008","viewClass":null,"yuiModules":["css-modules-publicprofile"],"stylesheets":["modules\/publicprofile.css"],"_isYUI":true},"publication":{"data":{"publicationUid":235703008,"title":"Adaptive Hamiltonian and Riemann Manifold Monte Carlo Samplers","journalTitle":false,"journalDetailsTooltip":false,"affiliation":false,"type":"Article","details":{"journalInfos":{"journal":"30th International Conference on Machine Learning, ICML 2013","publicationDate":"02\/2013;","publicationDateRobot":"2013-02","article":""}},"source":{"sourceUrl":"http:\/\/arxiv.org\/abs\/1302.6182","sourceName":"arXiv"},"publicationActions":null,"publicationCoins":{"data":{"tags":[{"key":"ctx_ver","value":"Z39.88-2004"},{"key":"rft_val_fmt","value":"info:ofi\/fmt:kev:mtx:journal"},{"key":"rfr_id","value":"info:sid\/researchgate.net:researchgate"},{"key":"rft.atitle","value":"Adaptive Hamiltonian and Riemann Manifold Monte Carlo Samplers"},{"key":"rft.title","value":"30th International Conference on Machine Learning, ICML 2013"},{"key":"rft.jtitle","value":"30th International Conference on Machine Learning, ICML 2013"},{"key":"rft.date","value":"2013"},{"key":"rft.au","value":"ziyu wang,Shakir Mohamed,Nando de Freitas"},{"key":"rft.genre","value":"article"}],"widgetId":"rgw6_56aba076a1103"},"id":"rgw6_56aba076a1103","partials":[],"templateName":"publicliterature\/stubs\/PublicationCoins.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationCoins.html?publicationUid=235703008","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationAuthors":{"data":{"publicationUid":235703008,"peopleItems":[{"data":{"authorNameOnPublication":"Ziyu Wang","accountUrl":"profile\/Ziyu_Wang2","accountKey":"Ziyu_Wang2","imageUrl":"https:\/\/i1.rgstatic.net\/ii\/profile.image\/AS%3A273771454005251%401442283609269_m","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Ziyu Wang","profile":{"professionalInstitution":{"professionalInstitutionName":"University of British Columbia - Vancouver","professionalInstitutionUrl":"institution\/University_of_British_Columbia-Vancouver"}},"professionalInstitutionName":"University of British Columbia - Vancouver","professionalInstitutionUrl":"institution\/University_of_British_Columbia-Vancouver","url":"profile\/Ziyu_Wang2","imageUrl":"https:\/\/i1.rgstatic.net\/ii\/profile.image\/AS%3A273771454005251%401442283609269_l","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":false,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":true,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"accountKey":"Ziyu_Wang2","hasInfoPopup":false,"hasTeaserPopup":true,"showContactAuthorButton":true,"widgetId":"rgw9_56aba076a1103"},"id":"rgw9_56aba076a1103","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAccountItem.html?entityId=3158930&enableUnfollow=0&imageSize=l&enableFollowButton=0&showContactAuthorButton=1","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"accountInstitution":"University of British Columbia - Vancouver","score":null,"largeTooltip":false,"useRebrandedImageStyle":null,"authorCount":3,"accountCount":1,"publicationUid":235703008,"widgetId":"rgw8_56aba076a1103"},"id":"rgw8_56aba076a1103","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAccountItem.html","templateExtensions":[],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAccountItem.html?accountId=3158930&context=pubdetail_authors_xflw&showContactAuthorButton=1&authorCount=3&accountCount=1&publicationUid=235703008","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true},{"data":{"authorUrl":"researcher\/82243933_Shakir_Mohamed","authorNameOnPublication":"Shakir Mohamed","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg","imageSize":"s","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Shakir Mohamed","profile":{"professionalInstitution":{"professionalInstitutionName":false,"professionalInstitutionUrl":null}},"professionalInstitutionName":false,"professionalInstitutionUrl":null,"url":"researcher\/82243933_Shakir_Mohamed","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":true,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":false,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"widgetId":"rgw11_56aba076a1103"},"id":"rgw11_56aba076a1103","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAuthorItem.html?entityId=82243933&imageSize=l&enableAuthorInviteButton=0","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"largeTooltip":false,"useRebrandedImageStyle":null,"widgetId":"rgw10_56aba076a1103"},"id":"rgw10_56aba076a1103","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorItem.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorItem.html?authorUid=82243933&authorNameOnPublication=Shakir%20Mohamed","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true},{"data":{"authorUrl":"researcher\/35020845_Nando_de_Freitas","authorNameOnPublication":"Nando de Freitas","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg","imageSize":"s","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Nando de Freitas","profile":{"professionalInstitution":{"professionalInstitutionName":false,"professionalInstitutionUrl":null}},"professionalInstitutionName":false,"professionalInstitutionUrl":null,"url":"researcher\/35020845_Nando_de_Freitas","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":true,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":false,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"widgetId":"rgw13_56aba076a1103"},"id":"rgw13_56aba076a1103","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAuthorItem.html?entityId=35020845&imageSize=l&enableAuthorInviteButton=0","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"largeTooltip":false,"useRebrandedImageStyle":null,"widgetId":"rgw12_56aba076a1103"},"id":"rgw12_56aba076a1103","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorItem.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorItem.html?authorUid=35020845&authorNameOnPublication=Nando%20de%20Freitas","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true}],"hasMore":false,"nextOffset":6,"useRebrandedImageStyle":null,"widgetId":"rgw7_56aba076a1103"},"id":"rgw7_56aba076a1103","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorList.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorList.html?publicationUid=235703008&context=pubdetail_authors_xflw&showContactAuthorButton=1","viewClass":"views.publicliterature.PublicationDetailAuthorListView","yuiModules":["rg.views.publicliterature.PublicationDetailAuthorListView"],"stylesheets":[],"_isYUI":true},"publicationAbstract":{"data":{"publicationUid":235703008,"abstract":"<noscript><\/noscript><div>In this paper we address the widely-experienced difficulty in tuning<br \/>\nHamiltonian-based Monte Carlo samplers. We develop an algorithm that allows for<br \/>\nthe adaptation of Hamiltonian and Riemann manifold Hamiltonian Monte Carlo<br \/>\nsamplers using Bayesian optimization that allows for infinite adaptation of the<br \/>\nparameters of these samplers. We show that the resulting sampling algorithms<br \/>\nare ergodic, and that the use of our adaptive algorithms makes it easy to<br \/>\nobtain more efficient samplers, in some cases precluding the need for more<br \/>\ncomplex solutions. Hamiltonian-based Monte Carlo samplers are widely known to<br \/>\nbe an excellent choice of MCMC method, and we aim with this paper to remove a<br \/>\nkey obstacle towards the more widespread use of these samplers in practice.<\/div>","canEdit":false,"isAdmin":false,"isArtifact":false,"showFullAbstract":false,"widgetId":"rgw14_56aba076a1103"},"id":"rgw14_56aba076a1103","partials":[],"templateName":"publicliterature\/stubs\/PublicationAbstract.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationAbstract.html?publicationUid=235703008","viewClass":"views.publicliterature.PublicationAbstractView","yuiModules":["rg.views.publicliterature.PublicationAbstractView"],"stylesheets":[],"_isYUI":true},"publicationKeywords":null,"publicationState":null,"isGuest":true,"isAdminEditingAllowed":false,"isArtifact":false,"figureListWidget":null,"previewImage":"https:\/\/i1.rgstatic.net\/publication\/235703008_Adaptive_Hamiltonian_and_Riemann_Manifold_Monte_Carlo_Samplers\/links\/034f93310cf2ac15472e88e3\/smallpreview.png","nativeAdDisclosure":null,"showFollowPublicationButton":false,"followPublicationPromo":"","widgetId":"rgw5_56aba076a1103"},"id":"rgw5_56aba076a1103","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailItem.html","templateExtensions":["generalHelpers"],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailItem.html?publicationUid=235703008&showActionBar=0&showContactAuthorButton=1&showRequestFulltextExperience=0&showNoRgAuthorsRequestFulltextExperience=0&showFollowPublicationPromo=0","viewClass":"views.publicliterature.PublicationDetailItemView","yuiModules":["rg.views.publicliterature.PublicationDetailItemView"],"stylesheets":[],"_isYUI":true},"similarPublications":{"data":{"publicationListItems":[{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":72108042,"url":"researcher\/72108042_Tan_Bui-Thanh","fullname":"Tan Bui-Thanh","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":19524381,"url":"researcher\/19524381_Mark_Girolami","fullname":"Mark Girolami","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Jul 2014","journal":"Inverse Problems","showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/263736747_Solving_Large-Scale_PDE-constrained_Bayesian_Inverse_Problems_with_Riemann_Manifold_Hamiltonian_Monte_Carlo","usePlainButton":true,"publicationUid":263736747,"feedStubs":null,"hasFeedStubs":false,"impactPoints":"1.32","url":"publication\/263736747_Solving_Large-Scale_PDE-constrained_Bayesian_Inverse_Problems_with_Riemann_Manifold_Hamiltonian_Monte_Carlo","title":"Solving Large-Scale PDE-constrained Bayesian Inverse Problems with Riemann Manifold Hamiltonian Monte Carlo","displayTitleAsLink":true,"authors":[{"id":72108042,"url":"researcher\/72108042_Tan_Bui-Thanh","fullname":"Tan Bui-Thanh","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":19524381,"url":"researcher\/19524381_Mark_Girolami","fullname":"Mark Girolami","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["Inverse Problems 07\/2014; 30(11). DOI:10.1088\/0266-5611\/30\/11\/114014"],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/263736747_Solving_Large-Scale_PDE-constrained_Bayesian_Inverse_Problems_with_Riemann_Manifold_Hamiltonian_Monte_Carlo","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/263736747_Solving_Large-Scale_PDE-constrained_Bayesian_Inverse_Problems_with_Riemann_Manifold_Hamiltonian_Monte_Carlo\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw16_56aba076a1103"},"id":"rgw16_56aba076a1103","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=263736747","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":47303477,"url":"researcher\/47303477_Luke_Bornn","fullname":"Luke Bornn","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":46559484,"url":"researcher\/46559484_Julien_Cornebise","fullname":"Julien Cornebise","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":34112724,"url":"researcher\/34112724_Gareth_W_Peters","fullname":"Gareth W. Peters","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Oct 2010","journal":null,"showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/47637681_Discussion_of_Riemann_manifold_Langevin_and_Hamiltonian_Monte_Carlo_methods''_by_M_Girolami_and_B_Calderhead","usePlainButton":true,"publicationUid":47637681,"feedStubs":null,"hasFeedStubs":false,"impactPoints":false,"url":"publication\/47637681_Discussion_of_Riemann_manifold_Langevin_and_Hamiltonian_Monte_Carlo_methods%27%27_by_M_Girolami_and_B_Calderhead","title":"Discussion of \"Riemann manifold Langevin and Hamiltonian Monte Carlo methods'' by M. Girolami and B. Calderhead","displayTitleAsLink":true,"authors":[{"id":47303477,"url":"researcher\/47303477_Luke_Bornn","fullname":"Luke Bornn","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":46559484,"url":"researcher\/46559484_Julien_Cornebise","fullname":"Julien Cornebise","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":34112724,"url":"researcher\/34112724_Gareth_W_Peters","fullname":"Gareth W. Peters","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":[],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/47637681_Discussion_of_Riemann_manifold_Langevin_and_Hamiltonian_Monte_Carlo_methods''_by_M_Girolami_and_B_Calderhead","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/47637681_Discussion_of_Riemann_manifold_Langevin_and_Hamiltonian_Monte_Carlo_methods''_by_M_Girolami_and_B_Calderhead\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw17_56aba076a1103"},"id":"rgw17_56aba076a1103","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=47637681","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":57038265,"url":"researcher\/57038265_Simon_Barthelme","fullname":"Simon Barthelme","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":34883089,"url":"researcher\/34883089_Magali_Beffy","fullname":"Magali Beffy","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":11144908,"url":"researcher\/11144908_Nicolas_Chopin","fullname":"Nicolas Chopin","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":{"id":2061952066,"url":"researcher\/2061952066_Arnaud_Doucet","fullname":"Arnaud Doucet","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},"surplusAuthors":4,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Nov 2010","journal":null,"showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/47651278_Discussions_on_Riemann_manifold_Langevin_and_Hamiltonian_Monte_Carlo_methods","usePlainButton":true,"publicationUid":47651278,"feedStubs":null,"hasFeedStubs":false,"impactPoints":false,"url":"publication\/47651278_Discussions_on_Riemann_manifold_Langevin_and_Hamiltonian_Monte_Carlo_methods","title":"Discussions on \"Riemann manifold Langevin and Hamiltonian Monte Carlo methods\"","displayTitleAsLink":true,"authors":[{"id":57038265,"url":"researcher\/57038265_Simon_Barthelme","fullname":"Simon Barthelme","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":34883089,"url":"researcher\/34883089_Magali_Beffy","fullname":"Magali Beffy","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":11144908,"url":"researcher\/11144908_Nicolas_Chopin","fullname":"Nicolas Chopin","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2061952066,"url":"researcher\/2061952066_Arnaud_Doucet","fullname":"Arnaud Doucet","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":48987261,"url":"researcher\/48987261_Pierre_Jacob","fullname":"Pierre Jacob","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":42467195,"url":"researcher\/42467195_Adam_M_Johansen","fullname":"Adam M. Johansen","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":12567635,"url":"researcher\/12567635_Jean-Michel_Marin","fullname":"Jean-Michel Marin","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":61296156,"url":"researcher\/61296156_Christian_P_Robert","fullname":"Christian P. Robert","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":[],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/47651278_Discussions_on_Riemann_manifold_Langevin_and_Hamiltonian_Monte_Carlo_methods","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/47651278_Discussions_on_Riemann_manifold_Langevin_and_Hamiltonian_Monte_Carlo_methods\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw18_56aba076a1103"},"id":"rgw18_56aba076a1103","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=47651278","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"viewClass":"sidebar","widgetId":"rgw15_56aba076a1103"},"id":"rgw15_56aba076a1103","partials":[],"templateName":"publicliterature\/stubs\/SimilarPublications.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.SimilarPublications.html?referencePublicationId=235703008&view=sidebar","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationFulltextPreview":null,"publicationResourcesFulltext":{"data":{"publicationUid":235703008,"publicationResourceList":{"data":{"publicationResourceItems":[{"data":{"publicationUid":235703008,"publicationType":"article","linkId":"034f93310cf2ac15472e88e3","fileName":"Adaptive Hamiltonian and Riemann Manifold Monte Carlo Samplers","fileUrl":"http:\/\/export.arxiv.org\/pdf\/1302.6182","name":"export.arxiv.org","nameUrl":"http:\/\/export.arxiv.org\/pdf\/1302.6182","canRemove":false,"fileIcon":"ico-pub","canPreview":true,"hasPublisherLink":null,"hasMetaData":true,"hide":false,"fulltext":"ico-pub","origin":"publication_list","isLastLink":true,"isUserLink":false,"widgetId":"rgw21_56aba076a1103"},"id":"rgw21_56aba076a1103","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceItem.html","templateExtensions":["generalHelpers"],"attrs":{"fileRequiredPublicationTypes":["code","coverPage","experimentFindings","method","negativeResults","presentation","rawData","researchProposal","workingPaper","artifact","dataset"]},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceItem.html?publicationUid=235703008&linkId=034f93310cf2ac15472e88e3&hide=0&disableJavascript=disableJavascript&useAlternativeTemplate=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"widgetId":"rgw20_56aba076a1103"},"id":"rgw20_56aba076a1103","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceList.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceList.html?publicationUid=235703008&limit=3&disableJavascript=disableJavascript&type=fulltextFile","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"resourceCount":1,"hidden":false,"showMore":false,"fulltext":true,"publicationDownloadCount":{"data":{"value":3,"valueFormatted":"3","widgetId":"rgw22_56aba076a1103"},"id":"rgw22_56aba076a1103","partials":[],"templateName":"publicliterature\/stubs\/PublicationDownloadCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDownloadCount.html?publicationUid=235703008","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw19_56aba076a1103"},"id":"rgw19_56aba076a1103","partials":[],"templateName":"publicliterature\/stubs\/PublicationResources.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResources.html?publicationUid=235703008&type=fulltextFile&disableJavascript=1","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationResourcesAttachments":{"data":{"publicationUid":235703008,"publicationResourceList":{"data":{"publicationResourceItems":[],"widgetId":"rgw24_56aba076a1103"},"id":"rgw24_56aba076a1103","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceList.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceList.html?publicationUid=235703008&limit=3&disableJavascript=disableJavascript&type=attachmentFile","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"resourceCount":0,"hidden":true,"showMore":false,"fulltext":false,"publicationDownloadCount":{"data":{"value":3,"valueFormatted":"3","widgetId":"rgw25_56aba076a1103"},"id":"rgw25_56aba076a1103","partials":[],"templateName":"publicliterature\/stubs\/PublicationDownloadCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDownloadCount.html?publicationUid=235703008","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw23_56aba076a1103"},"id":"rgw23_56aba076a1103","partials":[],"templateName":"publicliterature\/stubs\/PublicationResources.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResources.html?publicationUid=235703008&type=attachmentFile","viewClass":"views.publicliterature.PublicationResourcesView","yuiModules":["rg.views.publicliterature.PublicationResourcesView"],"stylesheets":[],"_isYUI":true},"publicationText":{"data":{"hide":false,"pages":[{"page":1,"text":"Adaptive Hamiltonian and Riemann Manifold Monte Carlo Samplers\nZiyu Wang\nUniversity of British Columbia Vancouver, Canada\nziyuw@cs.ubc.ca\nShakir Mohamed\nUniversity of British Columbia Vancouver, Canada\nshakirm@cs.ubc.ca\nNando de Freitas\nUniversity of British Columbia Vancouver, Canada\nnando@cs.ubc.ca\nAbstract\nIn\nexperienced difficulty in tuning Hamiltonian-\nbased Monte Carlo samplers. We develop an\nalgorithm that allows for the adaptation of\nHamiltonian and Riemann manifold Hamil-\ntonian Monte Carlo samplers using Bayesian\noptimization that allows for infinite adap-\ntation of the parameters of these samplers.\nWe show that the resulting sampling algo-\nrithms are ergodic, and that the use of our\nadaptive algorithms makes it easy to obtain\nmore efficient samplers, in some cases pre-\ncluding the need for more complex solutions.\nHamiltonian-based Monte Carlo samplers are\nwidely known to be an excellent choice of\nMCMC method, and we aim with this paper\nto remove a key obstacle towards the more\nwidespread use of these samplers in practice.\nthis paperwe addressthe widely-\n1. Introduction\nHamiltonian Monte Carlo (HMC) (Duane et al., 1987)\nis widely-known as a powerful and efficient sampling\nalgorithm, having been demonstrated to outperform\nmany existing MCMC algorithms,\nproblems with high-dimensional, continuous, and cor-\nrelated distributions (Chen et al., 2001; Neal, 2010).\nDespite this flexibility, HMC has not been widely\nadopted in practice, due principally to the sensitivity\nand difficulty of tuning its hyperparameters. In fact,\ntuning HMC has been reported by many experts to\nbe more difficult than tuning other MCMC methods\n(Ishwaran, 1999; Neal, 2010). In this paper we aim to\nremove this obstacle in the use of HMC by providing\nan automated method of determining these tunable\nparameters, paving the way for a more widespread\nespecially in\napplication of HMC in statistics and machine learning.\nThere are few existing works dealing with the\nautomated tuning of HMC. Two notable approaches\nare:the No U-turn sampler (NUTS) (Hoffman &\nGelman, 2011), which is an adaptive algorithm for\nHMC that aims to find the best parameter settings by\ntracking the sample path and preventing HMC from\nretracing its steps in this path; and Riemann manifold\nHMC (RMHMC) (Girolami & Calderhead, 2011),\nwhich provides adaptations using the Riemannian\ngeometry of the problem.\nIn this paper, we follow the approach of adapting\nMarkov chains in order to improve the convergence\nof both HMC and RMHMC. Our adaptive strategy\nis based on Bayesian optimization; see for example\nBrochu et al. (2009) and Snoek et al. (2012) for a\nclear and comprehensive introduction to Bayesian\noptimization. Bayesian optimization has been pro-\nposed previously for the adaptation of general MCMC\nsamplers by Mahendran et al. (2012) and Hamze\net al. (2013). To guarantee convergence, these works\nwere limited to a finite adaptation of the Markov\nchain. However, in the field of adaptive MCMC, it\nis well known that finite adaptation can result in\nthe sampler being trapped in suboptimal parameter\nsettings, leading to inefficient sampling.\nWe describe Hamiltonian-based Monte Carlo sam-\nplers in section 2, and then make the following\ncontributions:\n\u2022 We present an algorithm for adaptive HMC in\nwhich we allow for infinite adaptation of the\nMarkov chain, thus avoiding parameter traps due\nto finite adaptation (section 3).\n\u2022 Importantly, we prove that the adaptive MCMC\narXiv:1302.6182v1  [stat.CO]  25 Feb 2013"},{"page":2,"text":"Adaptive Hamiltonian and Riemann Manifold Monte Carlo Samplers\nsamplers we present are ergodic in this infinite\nadaptation setting (section 4).\n\u2022 We provide a comprehensive set of experiments\ndemonstrating that the adaptive schemes perform\nbetter in a diverse set of statistical problems (sec-\ntion 5).\n\u2022 For most examples, we use a version of the\nexpected squared jumping distance proposed by\nPasarica & Gelman (2010) as the objective func-\ntion for adaptation. However, in section 5, we also\nintroduce a new approach for adaptive MCMC\nbased on predictive measures, for use in settings\nwhere it is possible to perform cross-validation or\nbootstrapping.\n2. Hamiltonian-based Monte Carlo\nSampling\nHamiltonian (or Hybrid) Monte Carlo (Duane et al.,\n1987; Neal, 2010), has become established as a pow-\nerful, general purpose Markov chain Monte Carlo\n(MCMC) algorithm for sampling from general, contin-\nuous distributions. Its efficiency is due to the fact that\nit makes use of gradient information from the target\ndensity to allow for an ergodic Markov chain capable\nof large transitions that are accepted with high prob-\nability. This efficiency and flexibility is demonstrated\nby the wide range of applications to which HMC has\nbeen applied, including: Bayesian generalized linear\nmodels (Ishwaran, 1999), Bayesian neural networks\n(Neal & Zhang, 2006), Gaussian process regression and\nclassification (Rasmussen & Williams, 2006), exponen-\ntial family PCA and factor analysis (Mohamed et al.,\n2008), and restricted Boltzmann machines (Ranzato &\nHinton, 2010), amongst others.\nFor HMC, we are required to specify a potential energy\nfunction, which is the log of the joint distribution we\nwish to sample from, U(x) = \u2212logp(x) and a kinetic\nenergy function, most typically, K(p) = pTM\u22121p\/2,\nwith momentum vector p and a positive definite mass\nmatrix M. For standard HMC, the mass matrix is\nset to the identity. We defer the technical details of\nHMC to existing work (Neal, 2010), and present only\nthe algorithm here (Alg. 1).\nHMC requires the selection of two free parameters: a\nstep-size ? and a number leapfrog steps L. The ac-\ncepted guidance is to choose a step-size to ensure that\nthe sampler\u2019s rejection rate is between 25%-35%. It is\nalso preferable to have a large L, since this reduces the\nrandom walk behavior of the sampler (Neal, 2010), but\ntoo large an L results in unnecessary computation. In\nthis paper, we consider a slight variation of the HMC\nAlgorithm 1 Hamiltonian Monte Carlo Algorithm\n1: Given: M, L, ?, and x1.\n2: for t = 1,2,\u00b7\u00b7\u00b7 do\n3: Sample pt\u223c N(0,M) and Lr \u223c U(1,L)\n4:Let x0 = xtand p0 = pt+?\n5: for l = 1,2,\u00b7\u00b7\u00b7 ,Lr do\n6:xl= xl\u22121+ ?M\u22121pl\u22121\n7:pl= pl\u22121+ ?\u2202U\n\u2202x\nxl\n8:end for\n9:pl= pl\u22121\u2212?\n10:Draw u \u223c U(0,1)\n11:if u < min[1,eU(xt)+K(pt)\u2212U(xl)\u2212K(pl)] then\n12:Let (xt+1,pt+1) = (xl,pl)\n13:else\n14:Let (xt+1,pt+1) = (xt,pt)\n15:end if\n16: end for\n2\n\u2202U\n\u2202x\n??\nx0\n??\n2\n\u2202U\n\u2202x\n??\nxl\nalgorithm: instead of performing L leapfrog steps at\neach iteration, we only perform a random number of\nleapfrog steps, chosen from the discrete uniform distri-\nbution over {1,\u00b7\u00b7\u00b7 ,L}, i.e. Lr\u223c U(1,L) steps. This\napproach amounts to using a mixture of L different\nHMC transition kernels, thus preserving detailed bal-\nance (Andrieu et al., 2003).\nHMC is known to be highly sensitive to the choice of ?\nand L. We demonstrate HMC\u2019s sensitivity to these pa-\nrameters by sampling from a bivariate Gaussian with\ncorrelation coefficient 0.99. We consider three settings\n(?,L) = {(0.16,40),(0.16,50),(0.15,50)} and show the\nbehavior of the sampler as well as the autocorrelation\nplot in figure 1. While the first setting exhibits good\nbehavior and low auto-correlation, small changes to\nthese settings results in poor mixing and high auto-\ncorrelation, as seen in the other graphs.\ncal results concerning the optimal acceptance rate for\nHMC exist, having been described by Beskos et al.\n(2010) and Neal (2010), with both concluding a rate\naround 0.65 as optimal. Such results, however, would\nnot help in choosing the best sampler out of the three\nin Figure 1, since all three samplers in this demonstra-\ntion have an acceptance rate around 0.7, leaving little\nguidance for finding the most efficient sampler.\nTheoreti-\nTo address the problem of choosing these parame-\nters, we will introduce a method for automatically and\nadaptively tuning the parameters of HMC, reducing\nthe need for time-consuming, expert tuning. An ex-\nisting approach for automatic tuning of HMC was in-\ntroduced by Hoffman & Gelman (2011), referred to as\nthe No U-turn sampler (NUTS). NUTS allows for au-\ntomatic tuning of both HMC\u2019s parameters by tuning\nthe stepsize ? during the burn-in phase, after which\nit is fixed and the number of leapfrog steps is ad-"},{"page":3,"text":"Adaptive Hamiltonian and Riemann Manifold Monte Carlo Samplers\n0246\n0\n2\n4\n6\n8\nGaussian, \u03c1=0.99\n\u03b5 = 0.16, L = 40\n050\nLag\n100\n0\n0.5\n1\nAuto\u2212correlation\n\u22125 05\n\u22125\n0\n5\n10\n\u03b5 = 0.16, L = 50\n050\nLag\n100\n0\n0.5\n1\n0246\n0\n5\n10\n\u03b5 = 0.15, L = 50\n050\nLag\n100\n0\n0.5\n1\nFigure 1. 1000 samples from a bivariate Gaussian distribu-\ntion generated using HMC. We show the trajectory and\nauto-correlation of the samples for 3 parameter settings.\njusted thereafter for every iteration. ? is chosen using\na stochastic approximation method referred to as dual\naveraging, and L is chosen for every sample using a\nrecursive algorithm in which the number of leapfrog\nsteps is allowed to increase until the proposal trajec-\ntory taken by the sampler begins to move back towards\nthe initial point, thus preventing U-turns and allowing\nfor the good mixing of the chain.\nRiemann manifold HMC (RMHMC) (Girolami &\nCalderhead, 2011) is a sampling method derived from\nHMC, and provides an adaptation mechanism for\nHMC by exploiting the Riemannian geometry of the\nparameter space.Rather than adapting ? and L,\nRMHMC accounts for the local structure of the joint\ndensity by adapting the mass matrix M used in HMC.\nSince RMHMC automatically adapts its mass ma-\ntrix, the stepsize ? is usually fixed and the number\nof leapfrog steps L, which is a single scalar, can be\nchosen using the rejection rate. While the sensitivity\nto these parameters is greatly reduced, they must still\nbe set and there is no general guidance on how these\nparameters should be chosen, making it desirable to\nhave a fully automatic method for RMHMC as well.\n3. Adaptive Hamiltonian Monte Carlo\nIn order to adapt the MCMC parameters L and ? for\nHMC, we need to (i) define an objective function and\n(ii) choose a suitable optimization method.\nAs pointed out in Pasarica & Gelman (2010), a natu-\nral objective function for adaptation is the asymptotic\nefficiency of an MCMC sampler, (1 + 2?\u221e\nlag k. Despite its appeal, this measure is problematic\nbecause the higher order auto-correlations are hard to\nestimate. To circumvent this problem, Pasarica and\nGelman (2010) introduced an objective measure called\nk=1\u03c1k)\u22121,\nwhere \u03c1k is the auto-correlation of the sampler with\nthe expected squared jumping distance (ESJD):\nESJD(\u03b3) = E\u03b3?xt+1\u2212 xt?2,\nwhere \u03b3 = (L,?) denotes the set of parameters for\nHMC. Maximizing the above objective is equivalent to\nminimizing the first-order auto-correlation \u03c11. In prac-\ntice, the above intractable expectation with respect to\nthe Markov chain is approximated by an empirical es-\ntimator, as outlined in Pasarica & Gelman (2010).\nThe ESJD measure is efficient in situations where the\nhigher order auto-correlations increase monotonically\nwith respect to \u03c11.However, it is not suitable for\ntuning HMC samplers since by increasing the number\nof leapfrog steps one can almost always generate better\nsamples. What we need is a measure that also takes\ncomputing time into consideration. With this goal in\nmind, we introduce the following objective function:\nf(\u03b3) =ESJD(\u03b3)\n\u221aL\n=E\u03b3?xt+1\u2212 xt?2\n\u221aL\n.\nThis function simply normalizes the ESJD by the num-\nber of leapfrog steps L, thus taking both statistical\nefficiency and computation into consideration. Most\nof our experiments will use this measure as we have\nfound it to work very well in practice. Many works in\nthe adaptive MCMC literature have considered match-\ning empirical and theoretical acceptance rates in order\nto adapt MCMC samplers; see for example Andrieu &\nRobert (2001) or Vihola (2010). We have found this\nstrategy to perform poorly in the case of HMC, where\nsamplers with the same acceptance rate can exhibit\ndifferent mixing behavior (figure 1). When discussing\nBayesian neural networks in our experiments (section\n5.4), we will introduce an alternative objective func-\ntion based on predictive performance. Such a measure\ndoes however only apply in predictive domains and is,\nconsequently, less general than the normalized ESJD\nobjective.\nNow that we are armed with an objective function,\nwe need to address the issue of optimization. Since\nthe objective is only available point-wise (that is, it\ncan be evaluated but its exact form is intractable), re-\nsearchers typically use stochastic approximation. We\nuse Bayesian optimization to optimize the objective.\nA discussion contrasting these two alternatives is pre-\nsented in Hamze et al. (2013).\nBayesian optimization is an efficient gradient-free opti-\nmization tool well suited for expensive black box func-\ntions. Our objective function (normalized ESJD) is of\nthis nature. As mentioned earlier, normalized ESJD\ninvolves an intractable expectation that can be approx-\nimated by sample averages, where the samples are pro-\nduced by running HMC for a few iterations. Each set"},{"page":4,"text":"Adaptive Hamiltonian and Riemann Manifold Monte Carlo Samplers\nof HMC samples for a specific set of hyper-parameters\n\u03b3 \u2208 \u0393 results in a noisy evaluation of the normalized\nESJD: r(\u03b3) = f(\u03b3) + \u03b5, where we assume that the\nmeasurement noise is Gaussian \u03b5 \u223c N(0,\u03c32\nFollowing the standard Bayesian optimization method-\nology, we set \u0393 to be a box constraint such that\n\u03b7).\n\u0393 = {(?,L) : ? \u2208 [b?\nfor some interval boundaries b?\nparameter L is discrete. The parameter ? is continu-\nous, but since it is one-dimensional, we can discretize\nit using a very fine grid.\nl,b?\nu],L \u2208 [bL\nl\u2264 b?\nl,bL\nu]}\nl\u2264 bL\nuand bL\nu. The\nSince the true objective function is unknown, we spec-\nify a zero-mean Gaussian prior over it:\nf(\u00b7) \u223c GP(0,k(\u00b7,\u00b7))\nwhere k(\u00b7,\u00b7) is the covariance function. Given noisy\nevaluations of the objective function {rk}i\nated at points {\u03b3k}i\n?{\u03b3k}i\nobjective function:\nk=1evalu-\nk=1, we form the dataset Di =\n?. Using Bayes rule, we arrive at\nk=1,{rk}i\nk=1\nthe posterior predictive distribution over the unknown\nf|Di,\u03b3 \u223c N(\u00b5i(\u03b3),\u03c32\n\u00b5i(\u03b3) = kT(K + \u03c32\n\u03c32\ni(\u03b3))\n\u03b7I)\u22121ri\ni(\u03b3) = k(\u03b3,\u03b3) \u2212 kT(K + \u03c32\n\u03b7I)\u22121k\nwhere\nK =\n\uf8ee\n\uf8f0\n\uf8ef\nk(\u03b31,\u03b31)\n...\nk(\u03b3i,\u03b31)\n...\n...\n...\nk(\u03b31,\u03b3i)\n...\nk(\u03b3i,\u03b3i)\n\uf8f9\n\uf8fb,\n\uf8fa\nk = [k(\u03b3,\u03b31) ... k(\u03b3,\u03b3i)]T, and ri = [r1 ... ri]T.\nIn this work, we adopt a Gaussian ARD covari-\nance function with k(\u03b3i,\u03b3j) = exp(\u22121\nwhere \u03a3 is a positive definite matrix. We set \u03a3 =\ndiag[\u03b1(b?\nFor more details on Gaussian processes, please refer\nto Rasmussen & Williams (2006).\n2\u03b3T\ni\u03a3\u22121\u03b3j)\n?\nu\u2212 b?\nl)]2;?\u03b1(bL\nu\u2212 bL\nl)?2?\n, where \u03b1 = 0.2.\nThe Gaussian process simply provides a surrogate\nmodel for the true objective. The surrogate can be\nused to search, efficiently, for the maximum of the ob-\njective function. In particular, it enables us to con-\nstruct an acquisition function u(\u00b7) that tells us which\nparameters \u03b3 to try next. The acquisition function\nuses the Gaussian process posterior mean to predict\nregions of potentially higher objective values (exploita-\ntion). It also uses the posterior variance to detect re-\ngions of high uncertainty (exploration). Moreover, it\neffectively trades-off exploration and exploitation. Dif-\nferent acquisition functions have been proposed in the\nAlgorithm 2 Adaptive HMC.\n1: Given: \u0393, m, k, \u03b1, and \u03b31.\n2: for i = 1,2,..., do\n3:Run HMC for m iterations with \u03b3i= (?i,Li).\n4:Obtain the objective function value ri using the\ndrawn samples.\n5:Augment the data Di = {Di\u22121,(\u03b3i,ri)}.\n6:if ri > supj\u2208{1,\u00b7\u00b7\u00b7 ,i\u22121}rj then\n7:s =\nri\n8:end if\n9:Draw u \u223c U([0,1])\n10:let pi = (max{i \u2212 k + 1,1})\u22120.5, with k \u2208 N+.\n11:if u < pi then\n12:\u03b3i+1:= argmax\u03b3\u2208\u0393u(\u03b3,s|Di).\n13:else\n14:\u03b3i+1:= \u03b3i\n15:end if\n16: end for\n\u03b1\nliterature (Mo\u02c7 ckus, 1982; Srinivas et al., 2010; Hoff-\nman et al., 2011). We adopt a variant of the Upper\nConfidence Bound (UCB) (Srinivas et al., 2010), mod-\nified to suit our application:\nu(\u03b3,s|Di) = \u00b5i(\u03b3,s) + pi\u03b2\nstandard\nd\n2+2\u03c02\n3\u03b4\n, where d is the dimension of\n\u0393 and \u03b4 is set to 0.1. The parameter piensures that\nthe diminishing adaptation condition for adaptive\nMCMC (Roberts & Rosenthal, 2007) is satisfied.\nSpecifically, we set pi = (max{i \u2212 k + 1,1})\u22120.5for\nsome k \u2208 N+.\nBayesian optimization adapting \u03b3 vanishes as shown\nin Algorithm 2.\n1\n2\ni+1\u03c3i(\u03b3).\nAsin\n?\nUCB,we set\u03b2i+1\n=\n2log\n(i+1)\n?\nAs pi goes to 0, the probability of\nIt could be argued that this acquisition function could\nlead to premature exploitation, which may prevent\nBayesian optimization from locating the true optimum\nof the objective function.\nthis argument. Our goal when adapting the Markov\nchain, however, is less about finding the absolute best\nhyper-parameters but more about finding sufficiently\ngood hyper-parameters given finite computational re-\nsources. Given enough time, we could slow the an-\nnealing schedule thus allowing Bayesian optimization\nto explore the hyper-parameter space fully. However,\nunder time constraints we must use faster annealing\nschedules. As pidecreases, it becomes increasingly dif-\nficult for Bayesian optimization to propose new hyper-\nparameters for HMC. Consequently, the sampler ends\nup using the same set of hyper-parameters for many\niterations. With this in mind, we argue, it is more\nreasonable to exploit known good hyper-parameters\nrather than exploring for better ones. This intuition\nmatches our experience when conducting experiments.\nThere is some truth to"},{"page":5,"text":"Adaptive Hamiltonian and Riemann Manifold Monte Carlo Samplers\nThe acquisition function also includes a scalar\nscale-invariance parameter s, such that \u00b5i(\u03b3,s) =\nkT(K + \u03c32\ntomatically so as to rescale the rewards to the same\nrange each time we encounter a new maximal reward.\n\u03b7I)\u22121ris. This parameter is estimated au-\nGaussian processes require the inversion of the covari-\nance matrix and, hence, have complexity O(i3), where\ni is the number of iterations. Fortunately, thanks to\nour annealing schedule, the number of unique points in\nour Gaussian process grows sub-linearly with the num-\nber of iterations. This slow growth makes it possible to\nadopt kernel specification techniques, as proposed by\nEngel (2005), to drastically reduce the computational\ncost without suffering any loss in accuracy.\nFinally, in all our experiments, we set \u03b1 = 4, k = 100,\nm =B\nk, where B is the number of burn-in samples. In\nour experience, the algorithm is robust with respect\nto these settings and we used the same set of param-\neters throughout our experiments with the exception\nof \u0393. \u0393 is easy to set, since one can choose the bound\nto be large enough to contain all reasonable ? and L,\nwhile allowing the adaptive algorithm enough time to\nexplore. Alternatively, one could gauge the hardness\nof the sampling problem at hand and set more rea-\nsonable bounds. In general, harder sampling problems\nrequire a smaller ? and a larger L. We follow this sec-\nond strategy throughout our experiments and found\nthat most sensible bounds led to performance similar\nto the ones reported.\n4. Analysis of Convergence\nThe proof of ergodicity of the adaptive HMC algorithm\ncapitalizes on existing results for Langevin diffusions\nand adaptive MCMC on compact state spaces. The\nmethod of proof is based on the standard Lyapunov\nstability functions, also known as drift or potential\nfunctions.\nWe assume that our target distribution is compactly\nsupported on M. In practice, for target distributions\nthat are not compactly supported, we could set M\nlarge enough to contain most of the mass of our tar-\nget distribution. The sampler is restricted to M by\nfollowing this standard approach of rejecting all pro-\nposals that fall outside M.\nLet {P\u03b3}\u03b3\u2208\u0393be a collection of Markov chain kernels,\neach admitting \u03c0 as the stationary distribution. That\nis, for each value of \u03b3 = (?,L), we have one such kernel.\nMoreover, let Pn\n\u03b3 denote the n-step Markov kernel.\nOur proof requires the following classical definitions:\nDefinition 1. (Small set) A subset of the state space\nC \u2286 X is small if there exists n0\u2208 N+, \u03be > 0 and a\nprobability measure \u03bd(.) such that Pn0(x,\u00b7) \u2265 \u03be\u03bd(\u00b7)\n\u2200x \u2208 C.\nDefinition 2. (Drift condition) A Markov chain\nsatisfies the drift condition if for a small set C, there\nexist constants 0 < \u03bb < 1 and b < \u221e, and a function\nV : X \u2192 [1,\u221e] such that \u2200x \u2208 X\n?\nX\nP(x,dy)V (y) \u2264 \u03bbV (x) + b1C(x).\nHaving defined the necessary concepts, we now move\non to show the ergodicity of our adapted approach.\nProposition 3. Suppose that P\u03b3, when restricted to\na compact set M, admits the stationary distribution \u03c0\nfor all \u03b3 \u2208 \u0393. If \u03c0 is continuous, positive and bounded\non M, and |\u0393| is finite, then the adaptive HMC sam-\npler is ergodic.\nProof. To show that adaptive HMC converges on a\ncompact set, we first show that M is a small set.\nThe transition kernel of the random time HMC algo-\nrithm can be written as P\u03b3(x,.) =\nwhere Ql,?(x,.) is the transition kernel of an HMC\nsampler that takes l leapfrog steps with parameter\n?. In particular Q1,?(x,.) is the transition kernel of\nMetropolis adjusted Langevin algorithm (MALA). As\n\u03c0 is bounded, and the proposal distribution of MALA\nis positive every where, we have that Q1,? is \u00b5Leb-\nirreducible. By a slight modification of Theorem 2-2\nin Roberts & Tweedie (1996), for Markov chains de-\nfined by MALA, and any compact set C with posi-\ntive Lebesgue measure (i.e. \u00b5Leb(C) > 0) there exists\n\u03be > 0 and a probability measure \u03bd(\u00b7) such that \u2200x \u2208 C\nQ1\n1,?(x,.) \u2265 \u03be\u03bd(.). Hence, M is a small set since\n?L\nl=1\n1\nLQl,?(x,.)\nP1\n\u03b3(x,.) \u22651\nLQ1\n1,?(x,.) \u22651\nL\u03be\u03bd(.)\nfor any compact set C where \u00b5Leb(C) > 0. The drift\ncondition is trivially satisfied by each HMC sampler\nwhen we choose C to be M, and V to be such that\nV (x) = 1 for all x.\nHaving proved these conditions, we can now appeal to\nTheorem 15.0.1 of Meyn & Tweedie (1993) to conclude\nthat ?Pn\n0 < \u03c1\u03b3< 1. Since V (X) = 1 \u2200x, we have\n?Pn\n\u03b3(x,\u00b7) \u2212 \u03c0(\u00b7)? < R\u03b3V (x)\u03c1n\n\u03b3for all n and for\n\u03b3(x,\u00b7) \u2212 \u03c0(\u00b7)? < R\u03b3\u03c1n\n\u03b3.\nDefine Rmax= sup\u03b3\u2208\u0393R\u03b3and \u03c1max= sup\u03b3\u2208\u0393\u03c1\u03b3, then\n\u2200x \u2208 M and \u2200\u03b3 \u2208 \u0393 we have\n?Pn\n\u03b3(x,\u00b7) \u2212 \u03c0(\u00b7)? < Rmax\u03c1n\nmax."},{"page":6,"text":"Adaptive Hamiltonian and Riemann Manifold Monte Carlo Samplers\nWe have shown that the kernels {P\u03b3(x,\u00b7)}\u03b3\u2208\u0393are si-\nmultaneously uniformly ergodic. Also, the adaptive\nHMC sampler has diminishing adaptation by design.\nBy Theorem 5 of Roberts & Rosenthal (2007), these\ntwo conditions imply the claim of our proposition.\nIn general two sets of conditions together guarantee\nergodicity of an adaptive MCMC algorithm (Roberts\n& Rosenthal, 2007; Atchad\u00b4 e & Fort, 2010). First, the\nadaptation has to diminish eventually.\nset of conditions is usually placed on the underlying\nMCMC samplers. In Roberts & Rosenthal (2007), the\nsamplers are required to be either simultaneously uni-\nformly or geometrically ergodic. Without restricting\nthe state space to be compact, it is unlikely that HMC\nis uniformly ergodic. Also, to the best of our knowl-\nedge, no theoretical results exist on the geometric er-\ngodicity of HMC when the state space is not com-\npact.However, Roberts & Stramer (2002) showed\nthat Langevin diffusion, which is closely related to\nHMC, is geometrically ergodic.\nchallenge would be to prove or disprove geometric er-\ngodicity of HMC in general state spaces. Atchad\u00b4 e &\nFort (2010) weakened the conditions required, still re-\nquiring diminishing adaptation, but the requirements\non the underlying MCMC samplers were reduced to\nsub-geometric ergodicity. Although these conditions\nare weaker, it remains hard to check whether HMC\nsatisfies them.\nThe second\nThus one potential\n5. Results\nWe show the performance of our adaptive algorithm\non four widely-used models. We evaluate the perfor-\nmance of the samplers using the effective sample size\n(ESS) using: ESS = R(1 + 2?\nK monotone sample auto-correlations computed using\nthe monotone sequence estimator (Girolami & Calder-\nhead, 2011). We adopt the total number of leapfrog\nsteps used in producing the set of samples as a proxy\nfor computational demand, since the computation is\ndominated by the gradient evaluation required for each\nleapfrog step. An efficient sampler will result in the\nhighest ESS for the least computation, and we will\nthus report the effective sample size per leapfrog step\nused (ESS\/L), similarly to Hoffman & Gelman (2011),\nsince this takes into account computational require-\nments. We compute the ESS\/L over all dimensions of\nthe target distribution and report the minimum, me-\ndian and maximum ESS obtained. While we report\nall three summary statistics, we focus on the mini-\nmum ESS\/L as the most useful measure, since this\nallows us to evaluate the efficiency of the most con-\nk\u03c1k), where R is the\nk\u03c1kis the sum of\nnumber of posterior samples, and?\nfined coordinate, and is more indicative of ESS jointly\nover all coordinates rather than, as computed, over ev-\nery coordinate independently (Neal, 2010; Girolami &\nCalderhead, 2011).\nWe compare our adaptive HMC to NUTS, and ex-\ntend our approach and compare an adaptive version\nof RMHMC to the standard RMHMC. For NUTS,\nwe tuned the free parameters of its dual averaging\nalgorithm to obtain the best performance, and for\nRMHMC we use the experimental protocol and code\nused by Girolami & Calderhead (2011). We do this\nfor all experiments in this section. Code to reproduce\nthese results will be available online.\n5.1. Bayesian Logistic Regression\nWe consider a data set X consisting of N observations\nand D features or covariates, and a binary label y.\nUsing regression coefficients \u03b2 and bias \u03b20 the joint\ndistribution for the logistic regression model is:\nlogp(X,y,\u03b2,\u03b20)\u221dlogp(y|X,\u03b2,\u03b20)+logp(\u03b2)+logp(\u03b20)\n?\n=\u2212\ni\nlog?1+exp?\u2212yi(\u03b20+x?\ni\u03b2)??\u2212\u03b22\n0\n2\u03c32\u2212\u03b2?\u03b2\n2\u03c32, (1)\nwhere yi \u2208 {\u22121,1}, and \u03c32is the prior variance of\nthe regression coefficients. We present results on five\ndata sets from the UCI repository. The data sets have\nvarying characteristics with features D ranging from\n2 to 24, and the number of observations from 250 to\n1000. For each data set, we generate 5000 samples\nafter a burnin phase of 1000 samples, and repeat this\nprocess 10 times using differing starting points. The\ntop row of figure 2 compares the performance of our\nadaptive HMC (AHMC) to NUTS, while the bottom\nrow compares our adaptive RMHMC (ARMHMC) to\nRMHMC. For this experiment, for AHMC, we set \u0393\nsuch that ? \u2208 [0.01,0.2] and L \u2208 {0,\u00b7\u00b7\u00b7 ,100}, and for\nARMHMC, we use ? \u2208 [0.1,1] and L \u2208 {1,\u00b7\u00b7\u00b7 ,12}.\nThe columns of figure 2 shows box plots of the\nminimum, median and maximum ESS\/L values ob-\ntained. We see that the adaptive methods (AHMC\nand ARMHMC) exhibit good performance. For the\nminimum ESS\/L, AHMC has better (higher) values\nthat NUTS for all the data sets, and this behavior is\nconsistent across most other data sets for the other\nsummary statistics. Thus AHMC typically provides\nbetter performance and a higher effective number of\nsamples per unit of computation used than NUTS. We\nalso see that the ARMHMC can improve RMHMC and\nprovide better ESS\/L on what is already a highly effi-\ncient sampler."},{"page":7,"text":"Adaptive Hamiltonian and Riemann Manifold Monte Carlo Samplers\nGerman RipleyPimaHeart Australian\n0\n200\n400\n600\n800\n1000\n1200\nHMC Samplers\nMinimum ESS\/L\n \n \nAHMC\nNUTS\nGerman RipleyPimaHeart Australian\n0\n200\n400\n600\n800\n1000\n1200\nMedian ESS\/L\nGerman RipleyPimaHeart Australian\n0\n500\n1000\n1500\nMaximum ESS\/L\nGerman RipleyPima Heart Australian\n500\n1000\n1500\n2000\n2500\n3000\nRMHMC Samplers\n \n \nARMHMC\nRMHMC\nGerman Ripley PimaHeart Australian\n500\n1000\n1500\n2000\n2500\n3000\nGerman Ripley PimaHeart Australian\n500\n1000\n1500\n2000\n2500\n3000\nFigure 2. Box plots comparing ESS\/L for Bayesian logis-\ntic regression. Top row: AHMC vs NUTS. Bottom row:\nARMHMC vs RMHMC.\n5.2. Log-Gaussian Cox Point Process\nWe model a data set Y = {yij} that consists of counts\nat locations (i,j),i,j = 1...,d in a regular spatial grid\nusing a log-Gaussian Cox point process (LGC) (Chris-\ntensen et al., 2005; Girolami & Calderhead, 2011). Ob-\nservations yij are Poisson distributed and condition-\nally independent given a latent intensity process \u039b =\n{\u03bbij} with means s\u03bbij = sexp(xij), where s =\nThe rates X = {xij} are obtained from a Gaussian\nprocess with mean function m(xij) = \u00b51 and covari-\nance function \u03a3(xij,xi?j?) = \u03c32exp(\u2212\u03b4(i,i?,j,j?)\/\u03b2d),\nwhere \u03b4(i,i?,j,j?) =\nprobability logp(y,x|\u00b5,\u03c3,\u03b2) is proportional to:\n?\nWe generate samples jointly for x,\u03c3,\u00b5,\u03b2 using a grid\nof size d = 64, using a synthetic data set obtained by\ndrawing from the generative process for this model.\nWe generate 5000 samples after a burnin of 1000\nsamples. For this model, we use L \u2208 {1,\u00b7\u00b7\u00b7 ,500},\n? \u2208 [0.001,0.1] for AHMC, and use L \u2208 {1,\u00b7\u00b7\u00b7 ,60},\n? \u2208 [0.01,1] for ARMHMC. We compare the perfor-\nmance of the adaptive method we presented in terms\nof ESS per leapfrog step in figure 3.\nAHMC versus NUTS and ARMHMC versus RMHMC,\nshowing the minimum, median and maximum ESS\nper leapfrog step obtained for 10 chains with dis-\npersed starting points. We see that almost all points\nlie below the diagonal line, which indicates that the\nAHMC and ARMHMC have better ESS\/L compared\nto NUTS and RMHMC, respectively. Thus even for\nhigh-dimensional models with strong correlations our\nadaptive method allows for automatic tuning of the\nsampler and consequently the ability to obtain higher\nquality samples than with competing methods.\n1\nd2.\n?(i \u2212 i?)2+ (j \u2212 j?)2. The joint\nyijxij\u2212dexp(xij)\u22121\ni,j\n2(x\u2212\u00b51)?\u03a3\u22121(x\u2212\u00b51). (2)\nWe compare\nWe examine the quality of the posterior distribution\n05 1015202530\n0\n5\n10\n15\n20\n25\n30\nNUTS\nAHMC\nESS\/L\n \n \nMinimum\nMedian\nMaximum\n0100 200300\nARMHMC\n400500600 700\n0\n100\n200\n300\n400\n500\n600\n700\nRMHMC\nESS\/L\nFigure 3. Comparing minimum (red), median (blue) and\nmaximum (black) ESS\/L for the Log-Gaussian Cox model.\nEach of the colored glyphs represents one of the 10 chains\ngenerated.\nTrue Data\nLatent Field x\nLatent Process \u03bb\nVariance\nAHMC\nNUTS\nFigure 4. Comparing quality of posterior distributions\nfrom samples obtained using AHMC and NUTS for the\nlog-Gaussian Cox model. The top-right image shows the\nlocations of the true data.\nobtained for AHMC and NUTS in figure 4, by visualiz-\ning the latent field and its variance, and comparing to\nthe true data (which is known for this data set). The\ntop row shows the true latent fields. From the true\ndata observations (shown in top right corner), we see\nthat there are few data points in this region and thus\nwe expect to have a high variance in this region. The\naverage of the samples obtained using AHMC shows\nthat we can accurately obtain samples from the latent\nfield x, and that the samples have a variance matching\nour expectations. While NUTS is able to also produce\ngood samples of the latent field, the variance of the\nfield is not well captured (bottom right image)."},{"page":8,"text":"Adaptive Hamiltonian and Riemann Manifold Monte Carlo Samplers\nTable 1. Comparative results for the stochastic volatility\nmodel.\nESS per Leapfrog\nSamplerminimum\nAHMC\n1.3 \u00b1 0.1\nNUTS\n0.7 \u00b1 0.3\n5.3. Stochastic Volatility\nmedian\n6.9 \u00b1 0.7\n3.5 \u00b11.6\nmaximum\n14.9 \u00b11.4\n9 \u00b12.8\nWe consider a stochastic volatility model described by\nKim et al. (1998) and Girolami & Calderhead (2011),\nin which we consider observations yt, regularly spaced\nin time for t = 1,...,T. Each ytis specified using a\nlatent variable xt, which represents the log-volatility\nfollowing auto-regressive AR(1) dynamics. The model\nis specified as:\nyt=?t\u03b2 exp(0.5xt),?t\u223cN(0,1)\n\u03b7t+1\u223cN(0,\u03c32)\np(\u03b2) \u221d1\n(3)\nxt+1=\u03c6xt+ \u03b7t+1, (4)\nx1\u223cN\n?\n0,\n\u03c32\n1 \u2212 \u03c62\n?\n,\n\u03b2.\n(5)\nFor stationarity of the log-volatility, |\u03c6| < 1, and the\nstandard deviation \u03c3 > 0, whose priors we set to\n\u03c6+1\n2\n\u223c Beta(20,1.5) and \u03c32\u223c inv-\u03c72(10,0.05), re-\nspectively. The parameters to be sampled by HMC is\nthus \u0398 = {x,\u03b2,\u03c6,\u03c32}, and the joint probability is:\np(y,\u0398)=\nT?\nt=1\np(yt|xt,\u03b2)p(xt|xt\u22121,\u03c6,\u03c32)p(\u03b2)p(\u03c32)p(\u03c6). (6)\nWe make use of the transformations \u03c3 = exp(\u03b3) and\n\u03c6 = tanh(\u03b1) to ensure that we sample using un-\nconstrained variables; the use of this transformation\nrequires the addition of the Jacobian of the trans-\nformation of variables. We generate samples jointly\nusing our AHMC methods, using training data with\nT = 2000. For our experiments, we use a burnin pe-\nriod of 10,000 samples and thereafter generate 20,000\nposterior samples. We restrict our box constraint such\nthat L \u2208 {1,\u00b7\u00b7\u00b7 ,300}, ? \u2208 [10\u22124,10\u22122]. We show the\nresults comparing ESS for the two methods in table\n1. These results again show higher values for ESS per\nleapfrog step, demonstrating that a better perform-\ning sampler can be obtained using AHMC \u2013 further\ndemonstrating the advantages of AHMC methods for\nsampling from complex hierarchical models.\n5.4. Bayesian Neural Networks\nWe demonstrate the application of our adaptive ap-\nproach using Bayesian neural networks (BNNs) to\nshow that AHMC allows for more effective sampling\nof posterior parameters even when compared to sam-\nplers finely tuned by an expert. We make use of the\nDexter data set from the NIPS 2003 feature selection\nchallenge, which is a subset of the well-known Reuters\ntext categorization benchmark. The winning entries\nsubmitted by Neal & Zhang (2006) used a number of\nfeature selection techniques followed by a combination\nof Bayesian Neural Networks and Dirichlet diffusion\ntrees. The entry that used only BNNs was placed sec-\nond and achieved highly competitive results (Guyon\net al., 2005).\nThe BNN model consists of 295 input features and\n2 hidden layers with 20 and 8 hidden units respec-\ntively. The input features are selected from the full set\nof features through univariate feature selection. The\nweights and bias as well as a few other parameters of\nthis particular network adds up to form a 6097 dimen-\nsional state space for the HMC sampler.\nFor this model, we use cross-validation to construct\nthe reward signal.We divide the data into n sets,\nand train n BNNs each on n \u2212 1 sets and test them\non the remaining set like in the case of normal cross-\nvalidation. The cross-validation error is then used to\ncalculate the reward. To take computation into ac-\ncount, we always evaluate the reward over the same\nnumber of leapfrog steps, i.e. for each evaluation of\nthe reward we use a different number of samples and\na different number of leapfrog steps for each sample,\nbut the product of the two remains constant.\nWe compare the results in table 2, where the perfor-\nmance measure is the prediction error on a test set\n(unknown to us) and was obtained after submission\nto the competition system. The improved results ob-\ntained using the AHMC strategy are clear from the ta-\nble, also demonstrating that good adaptation can be\npreferable to the introduction of more sophisticated\nmodels.\nTable 2. Classification error on the test set of the Dexter\ndata set. The table shows the mean and the median pre-\ndiction errors of our 8 BNNs trained as in cross-validation.\nThe majority vote of these 8 networks achieves slightly\nbetter results than that of a more sophisticated model in-\nvolving Dirichlet diffusion trees.\nMethod\nExpert-tuned HMC for BNN\nAHMC for BNN (Mean error)\nAHMC for BNN (Median error)\nWinning entry (using Dirichlet Diffusion Trees)\nAHMC for BNN + Majority Voting\nError\n0.0510\n0.0498\n0.0458\n0.0390\n0.0355\n6. Discussion and Conclusion\nIn section 3 we described the use the expected squared\njumping distance as a suitable objective. Several other\nobjectives, such as the mean update distance, cross-\nvalidation error and the cumulative auto-correlation,\nare also suitable, and their use depends on the"},{"page":9,"text":"Adaptive Hamiltonian and Riemann Manifold Monte Carlo Samplers\nparticular modelling problem.\nlearning tasks, researchers design MCMC algorithms\nto estimate model parameters and, subsequently,\nevaluate these models using cross-validation, such as\nthe competition task in section 5.4. Moreover, often\nresearchers modify their samplers so as to reduce\ntest set error. In this paper, we demonstrate the use\nof predictive losses, such as cross-validation error,\nto guide the adaptation.\nnever reported before to the best of our knowledge,\nsimply makes the tuning process followed by many\nresearchers explicit.Ultimately the models whose\nparameters we are estimating by running a Markov\nchain will be tested on predictive tasks.\nis natural to use predictive performance on such\npredictive tasks to improve the exploration of the\nposterior distribution.Of course, these objective\nmeasures are only applicable when sufficient data is\navailable to obtain good predictive estimates.\nIn many machine\nThis approach, although\nHence, it\nWe\nin tuning Hamiltonian-based Monte Carlo samplers\nby developing algorithms for infinite adaptation of\nthese Markov chains using Bayesian optimization.\nThe adaptive Hamiltonian Monte Carlo and adaptive\nRiemann manifold HMC we developed automate the\nprocess of finding the best parameters that control\nthe performance of the sampler, removing the need\nfor time-consuming and expert-driven tuning of these\nsamplers.Our experiments show conclusively that\nover a wide range of models and data sets, the use\nof adaptive algorithms makes it easy to obtain more\nefficient samplers, in some cases precluding the need\nfor more complex approaches.\nMonte Carlo samplers are widely known to be an\nexcellent choice of MCMC method, and we hope that\nthis paper removes a key obstacle towards the more\nwidespread use of these samplers in practice.\naddressed the widely-experienceddifficulty\nHamiltonian-based\nReferences\nAndrieu, Christophe and Robert, Christian.\nMCMC for optimal sampling. Technical Report 0125,\nCahiers de Mathematiques du Ceremade, Universite\nParis-Dauphine, 2001.\nAndrieu, Christophe, de Freitas, Nando, Doucet, Arnaud,\nand Jordan, Michael I. An Introduction to MCMC for\nMachine Learning. Machine Learning, 50(1):5\u201343, 2003.\nAtchad\u00b4 e, Yves and Fort, Gersende.\nsome adaptive MCMC algorithms with subgeometric\nkernels. Bernoulli, 16(1):116\u2013154, 2010.\nBeskos, Alexandros, Pillai, Natesh S., Roberts, Gareth O.,\nSanz-Serna, Jesus M., and Stuart, Andrew M. Optimal\ntuning of the hybrid Monte-Carlo algorithm. Preprint\narXiv:1001.4460, 2010.\nControlled\nLimit theorems for\nBrochu, Eric, Cora, Vlad M, and de Freitas, Nando. A tu-\ntorial on Bayesian optimization of expensive cost func-\ntions. Preprint arXiv:1012.2599, 2009.\nChen, Lingyu, Qin, Zhaohui, and Liu, Jun S. Exploring\nHybrid Monte Carlo in Bayesian Computation. Sigma,\n2:2\u20135, 2001.\nChristensen, Ole F., Roberts, Gareth O., and Rosenthal,\nJeffrey S. Scaling limits for the transient phase of local\nMetropolis\u2013Hastings algorithms. Journal of the Royal\nStatistical Society: Series B, 67(2):253\u2013268, 2005.\nDuane, S, Kennedy, A D, Pendleton, B J, and Roweth, D.\nHybrid Monte Carlo. Physics Letters B, 195(2):216\u2013222,\n1987.\nEngel, Yaakov. Algorithms and representations for rein-\nforcement learning. Doktorarbeit, The Hebrew Univer-\nsity of Jerusalem, 2005.\nGirolami, Mark and Calderhead, Ben. Riemann manifold\nLangevin and Hamiltonian Monte Carlo methods. Jour-\nnal of the Royal Statistical Society: Series B, 73(2):123\u2013\n214, 2011.\nGuyon, Isabelle, Gunn, Steve, Ben-Hur, Asa, and Dror,\nGideon. Result analysis of the NIPS 2003 feature se-\nlection challenge. In Advances in Neural Information\nProcessing Systems, volume 17, pp. 545\u2013552, 2005.\nHamze, Firas, Wang, Ziyu, and de Freitas, Nando. Self-\navoiding random dynamics on integer complex systems.\nACM Transactions on Modeling and Computer Simula-\ntion, 23(1):9:1\u20139:25, 2013.\nHoffman, Matthew, Brochu, Eric, and de Freitas, Nando.\nPortfolio allocation for Bayesian optimization. In Un-\ncertainty in Artificial Intelligence, pp. 327\u2013336, 2011.\nHoffman, Matthew D and Gelman, Andrew.\nU-Turn Sampler: Adaptively setting path lengths in\nHamiltonian Monte Carlo.\n2011.\nIshwaran, Hemant. Applications of hybrid Monte Carlo to\nBayesian generalized linear models: Quasicomplete sep-\naration and neural networks. Journal of Computational\nand Graphical Statistics, 8(4):779\u2013799, 1999.\nKim, Sangjoon, Shephard, Neil, and Chib, Siddhartha.\nStochastic volatility: likelihood inference and compari-\nson with ARCH models. The Review of Economic Stud-\nies, 65(3):361\u2013393, 1998.\nMahendran, Nimalan, Wang, Ziyu, Hamze, Firas, and\nde Freitas, Nando. Adaptive MCMC with Bayesian op-\ntimization. Articial Intelligence and Statistics, 2012.\nMeyn, Sean P. and Tweedie, Richard L. Markov chains\nand stochastic stability. Springer-Verlag, 1993.\nMo\u02c7 ckus, Jonas. The Bayesian approach to global optimiza-\ntion. In System Modeling and Optimization, volume 38,\npp. 473\u2013481. Springer, 1982.\nMohamed, Shakir, Heller, Katherine, and Ghahramani,\nZoubin. Bayesian exponential family PCA. In Advances\nin Neural Information Processing Systems, pp. 1089\u2013\n1096. 2008.\nNeal, R. and Zhang, J. High dimensional classification with\nBayesian neural networks and Dirichlet diffusion trees.\nIn Feature Extraction, pp. 265\u2013296. Springer, 2006.\nNeal, Radford M. MCMC using Hamiltonian dynamics.\nThe No-\nPreprint arXiv:1111.4246,"},{"page":10,"text":"Adaptive Hamiltonian and Riemann Manifold Monte Carlo Samplers\nHandbook of Markov Chain Monte Carlo, 54:113\u2013162,\n2010.\nPasarica, Cristian and Gelman, Andrew. Adaptively scal-\ning the Metropolis algorithm using expected squared\njumped distance. Statistica Sinica, 20(1):343, 2010.\nRanzato, Marc\u2019Aurelio and Hinton, Geoffrey.\npixel means and covariances using factorized third-order\nBoltzmann machines. In IEEE Computer Vision and\nPattern Recognition, pp. 2551\u20132558, 2010.\nRasmussen, Carl Edward and Williams, Christopher K I.\nGaussian Processes for Machine Learning. MIT Press,\nCambridge, Massachusetts, 2006.\nRoberts, Gareth O. and Rosenthal, Jeffrey S. Coupling\nand ergodicity of adaptive Markov chain Monte Carlo\nalgorithms. Journal of applied probability, 44(2):458\u2013\n475, 2007.\nRoberts, Gareth O. and Stramer, Osnat. Langevin diffu-\nModeling\nsions and Metropolis-Hastings algorithms. Methodology\nand computing in applied probability, 4(4):337\u2013357, 2002.\nRoberts, Gareth O and Tweedie, Richard L. Geometric\nconvergence and central limit theorems for multidimen-\nsional Hastings and Metropolis algorithms. Biometrika,\n83(1):95\u2013110, 1996.\nSnoek,Jasper, Larochelle,\nRyan Prescott. Practical Bayesian optimization of\nmachine learning algorithms.\nProcessing Systems, 2012.\nSrinivas, Niranjan, Krause, Andreas, Kakade, Sham M.,\nand Seeger, Matthias. Gaussian process optimization in\nthe bandit setting: No regret and experimental design.\nIn International Conference on Machine Learning, 2010.\nVihola, Matti. Grapham: Graphical models with adap-\ntive random walk Metropolis algorithms. Computational\nStatistics and Data Analysis, 54(1):49 \u2013 54, 2010.\nHugo,and Adams,\nIn Neural Information"}],"widgetId":"rgw26_56aba076a1103"},"id":"rgw26_56aba076a1103","partials":[],"templateName":"publicliterature\/stubs\/PublicationText.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationText.html?publicationUid=235703008&hide=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationDetailAd":{"data":{"googleDfpSlot":null,"widgetId":"rgw27_56aba076a1103"},"id":"rgw27_56aba076a1103","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAd.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAd.html?publicationUid=235703008&slotId=336x280_Publications_ATF_Right&collapseSlotMode=never&fallbackContainerEnabled=1","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationRelations":null,"publicationRelationsReverse":null,"publicationUid":235703008,"showSignUpDialog":false,"selectNewSignUpDialog":false,"publicationQuestions":null,"publicationCitations":null,"publicationReviewPromo":null,"publicationUsedInReviews":null,"publicationPdfJsReader":null,"useFulltextOptimizedLayout":false,"publicationActions":null,"requestFulltextPromo":null,"currentUrl":"publication\/235703008_Adaptive_Hamiltonian_and_Riemann_Manifold_Monte_Carlo_Samplers","isLeaderboardAd":false,"enableStickyBox":null,"googleDfpSlotMobileBottom":null,"fullTextExitPopup":null,"showExitPopupDialog":false,"widgetId":"rgw2_56aba076a1103"},"id":"rgw2_56aba076a1103","partials":{"romeo_legal_notice":"publicliterature\/stubs\/partials\/romeo_legal_notice.html"},"templateName":"publicliterature\/stubs\/PublicPublicationDetails_NewLayout.html","templateExtensions":["generalHelpers"],"attrs":{"publicationUid":235703008},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicPublicationDetailsOld.html?publicationUid=235703008&isTestOldDesign=0","viewClass":"views.publicliterature.PublicPublicationDetailsOldView","yuiModules":["rg.views.publicliterature.PublicPublicationDetailsOldView"],"stylesheets":[],"_isYUI":true},"widgetId":"rgw1_56aba076a1103"},"id":"rgw1_56aba076a1103","partials":[],"templateName":"publicliterature\/stubs\/PublicPublicationDetails.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicPublicationDetails.html","viewClass":"views.publicliterature.PublicPublicationDetailsView","yuiModules":["rg.views.publicliterature.PublicPublicationDetailsView"],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"uaClass":"","headPrefix":[],"rootUrl":"https:\/\/www.researchgate.net\/","requestToken":"e+45j63rhXOkQBgPETsGAT\/AsuFBzd8Gn6g7VfNCHervvaMXHxcnCeSSa2SmQNBPCaw3Jhothc5bG+su43nmQVqXKJObLgTNmIe7c5msQliK176ST8eY9Pt2otpNW+cTjZU+EDamU+qpDf4oTfZr+SEONd\/gla9bViuAD2ymC8OELZuaq25UY4qYlTtoVB\/AYG4oa75uOd1p0A\/\/jLrXwdpbIzIg\/14SIt4D8MZmbkUvj10PsN1r3h60JjlzAgjASrvZZXLOh0DeQjhgEwJcGtsqbl5jUCjpzk+gb9+Wo6Q=","faviconCdnUrl":"https:\/\/c5.rgstatic.net\/m\/2390829798215018\/images\/favicon.ico","headerOutput":"<noscript><\/noscript><link rel=\"canonical\" href=\"https:\/\/www.researchgate.net\/publication\/235703008_Adaptive_Hamiltonian_and_Riemann_Manifold_Monte_Carlo_Samplers\" \/>\n<link rel=\"dns-prefetch\" href=\"\/\/c5.rgstatic.net\" \/>\n<link rel=\"dns-prefetch\" href=\"\/\/i1.rgstatic.net\" \/>\n<meta property=\"twitter:card\" content=\"summary\" \/>\n<meta property=\"twitter:site\" content=\"@ResearchGate\" \/>\n<meta property=\"og:title\" content=\"Adaptive Hamiltonian and Riemann Manifold Monte Carlo Samplers\" \/>\n<meta property=\"og:description\" content=\"In this paper we address the widely-experienced difficulty in tuning\nHamiltonian-based Monte Carlo samplers. We develop an algorithm that allows for\nthe adaptation of Hamiltonian and Riemann...\" \/>\n<meta property=\"og:site_name\" content=\"ResearchGate\" \/>\n<meta property=\"og:image\" content=\"https:\/\/i1.rgstatic.net\/publication\/235703008_Adaptive_Hamiltonian_and_Riemann_Manifold_Monte_Carlo_Samplers\/links\/034f93310cf2ac15472e88e3\/smallpreview.png\" \/>\n<meta property=\"og:url\" content=\"https:\/\/www.researchgate.net\/publication\/235703008_Adaptive_Hamiltonian_and_Riemann_Manifold_Monte_Carlo_Samplers\" \/>\n<meta property=\"rg:id\" content=\"PB:235703008\" \/>\n<meta name=\"DC.identifier\" scheme=\"DCTERMS.URI\" content=\"http:\/\/dx.doi.org\/\" \/>\n<meta name=\"gs_meta_revision\" content=\"1.1\" \/>\n<meta name=\"citation_title\" content=\"Adaptive Hamiltonian and Riemann Manifold Monte Carlo Samplers\" \/>\n<meta name=\"citation_author\" content=\"ziyu wang\" \/>\n<meta name=\"citation_author\" content=\"Shakir Mohamed\" \/>\n<meta name=\"citation_author\" content=\"Nando de Freitas\" \/>\n<meta name=\"citation_publication_date\" content=\"2013\/02\/25\" \/>\n<meta name=\"citation_abstract_html_url\" content=\"https:\/\/www.researchgate.net\/publication\/235703008_Adaptive_Hamiltonian_and_Riemann_Manifold_Monte_Carlo_Samplers\" \/>\n<meta name=\"citation_fulltext_html_url\" content=\"https:\/\/www.researchgate.net\/publication\/235703008_Adaptive_Hamiltonian_and_Riemann_Manifold_Monte_Carlo_Samplers\" \/>\n<meta name=\"viewport\" content=\"width=device-width,initial-scale=1\" \/>\n<link href=\"\/\/c5.rgstatic.net\/m\/22664197317151888\/styles\/rg.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/21004998181197492\/styles\/rg2.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<!--[if lt IE 9]><link href=\"\/\/c5.rgstatic.net\/m\/238176252723686\/styles\/ie.css\" type=\"text\/css\" rel=\"stylesheet\"\/><![endif]-->\n<link href=\"\/\/c5.rgstatic.net\/m\/217752362214895\/styles\/modules\/publicprofile.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<script src=\"\/\/c5.rgstatic.net\/m\/2321000301012716\/javascript\/vendor\/webfontloader\/webfontloader.js\" type=\"text\/javascript\"><\/script>\n <script>(function(i,s,o,g,r,a,m){i[\"GoogleAnalyticsObject\"]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,\"script\",\"\/\/www.google-analytics.com\/analytics.js\",\"ga\");\n ga(\"create\",\"UA-58591210-1\");ga(\"set\",\"anonymizeIp\",true);ga('set', 'dimension1', 'publication slurped');ga('set', 'dimension2', 'Article');ga('set', 'dimension3', 'Logged out');ga('set', 'dimension4', 'https');ga(\"send\",\"pageview\");<\/script>\n","webfont":"<noscript><\/noscript><script> WebFontConfig = { custom: { families: ['source_sans_pro_italic', 'source_sans_pro_bold', 'source_sans_pro', 'martel'], urls : ['\/\/c5.rgstatic.net\/m\/231392577336386\/styles\/fonts.css'] } }; WebFont.load(WebFontConfig); <\/script>\n","correlationId":"rgreq-6b6efb49-191b-459c-b239-c29fc2284177","accountId":null,"module":"publicliterature","action":"publicliterature.PublicPublicationDetails","page":"publicationDetail","product":"publications","backendTime":448,"continent":"Asia","stylesHome":"\/\/c5.rgstatic.net\/m\/","staticHost":"c5.rgstatic.net","useEarlyFlush":false,"longRunningRequestIdentifier":"LongRunningRequest.publicliterature.PublicPublicationDetails","longRunningRequestFp":"e9e5bbe1366c7ee8c8e41d02f793c884ac9be19b","widgetId":"rgw28_56aba076a1103"},"id":"rgw28_56aba076a1103","partials":[],"templateName":"application\/stubs\/StaticHeader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.StaticHeader.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){
            Y.rg.core.pagespeed.Monitoring.monitorPage("\/\/glassmoni.researchgate.net", "publicliterature.PublicPublicationDetails.run.html.loggedOut.get", "59de9668d07aeb77ab4de5f24d382b5d199d2437", "rgreq-6b6efb49-191b-459c-b239-c29fc2284177", "d4e36b3f2c837bcc3fb483a6520bb905b579f9b3");
        
            Y.rg.core.pagespeed.Monitoring.monitorPage("\/\/glassmoni.researchgate.net", "publicationDetail.loggedOut", "ed1993d9e20f6cefa83edacaa24401a18c071aea", "rgreq-6b6efb49-191b-459c-b239-c29fc2284177", "d4e36b3f2c837bcc3fb483a6520bb905b579f9b3");
        })();
(function(){Y.rg.createInitialWidget({"data":{"year":"2016","inlinePromo":null,"isAdmin":false,"contactUrl":"https:\/\/www.researchgate.net\/contact","aboutUsUrl":"https:\/\/www.researchgate.net\/about","widgetId":"rgw29_56aba076a1103"},"id":"rgw29_56aba076a1103","partials":[],"templateName":"application\/stubs\/DefaultFooter.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.DefaultFooter.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"headerLogin":{"data":{"urlAfterLogin":"publication\/235703008_Adaptive_Hamiltonian_and_Riemann_Manifold_Monte_Carlo_Samplers","requestToken":"sbCzf1k4kB+o4TMjbo3hVn7PG3jO27Yb+XRNGW6sbzIIQXJPWpP3+UCh5UsRPZR+SFg6s\/Jtc9NcqFvBnjKeNwsNyCehLU28WqmifRjYu1cGxb3TEWkh4HelnRIKpnMjIPv7O5q5v5PLPfozlmrvZyEP8ZnleeA1JP3fRI39ZQQ4b3PkBFLBOZiKz6i9Wg5GaF4+Tr3HLW8EQSvWGgBa7eF+FgqLHp0aqVG4KH036+yL2mclXM93TlMU60WvogEJiwxLtzYNSgGUnisO8Nl9KW+8PN5JJZBIQPAN6tWNu\/c=","loginUrl":"https:\/\/www.researchgate.net\/application.Login.html","signupUrl":"https:\/\/www.researchgate.net\/signup.SignUp.html?ev=su_chnl_index&hdrsu=1&_sg=h0VoMcWXFU3HOJWsPiBeJBcV3gsE9TmFlIAjNq08kHdNC7djgoEPy0byDBNO6Gvx","encodedUrlAfterLogin":"cHVibGljYXRpb24vMjM1NzAzMDA4X0FkYXB0aXZlX0hhbWlsdG9uaWFuX2FuZF9SaWVtYW5uX01hbmlmb2xkX01vbnRlX0NhcmxvX1NhbXBsZXJz","signupCallToAction":"Join for free","widgetId":"rgw31_56aba076a1103"},"id":"rgw31_56aba076a1103","partials":{"partial":"application\/stubs\/partials\/headerLoginDefault.html"},"templateName":"application\/stubs\/HeaderLogin.html","templateExtensions":[],"attrs":{"goal":"milestoneHeaderLoginSeen"},"widgetUrl":"https:\/\/www.researchgate.net\/application.HeaderLogin.html","viewClass":"views.application.HeaderLoginView","yuiModules":["rg.views.application.HeaderLoginView"],"stylesheets":[],"_isYUI":true},"cookieConsent":null,"logoSvgSrc":"https:\/\/c5.rgstatic.net\/m\/235107188705592\/images\/template\/brand-header-logo.svg","logoFallbackSrc":"https:\/\/c5.rgstatic.net\/m\/238113351022438\/images\/template\/brand-header-logo.png","widgetId":"rgw30_56aba076a1103"},"id":"rgw30_56aba076a1103","partials":{"schemaSocialProfiles":"application\/stubs\/partials\/schemaSocialProfiles.html"},"templateName":"application\/stubs\/HeaderLoggedOut.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.HeaderLoggedOut.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"logEvent":"su_banner","specialCopy":false,"widgetId":"rgw32_56aba076a1103"},"id":"rgw32_56aba076a1103","partials":[],"templateName":"application\/stubs\/LoggedOutBanner.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.LoggedOutBanner.html","viewClass":"views.application.LoggedOutBannerView","yuiModules":["rg.views.application.LoggedOutBannerView"],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.core.util.ParameterFilter.filter(["ev","cp","ch","ref","dbw","pli","loginT","uid","claimChannel","enrichId","enrichSource","utm_source","utm_medium","utm_campaign","el","ci"]);})();
});}); } else { throw 'YRG was not loaded when attaching widgets'; }</script><script> dataLayer = [{"pageCategory":"publication slurped","publicationType":"Article","eventCategory":"Publication page"}]; </script> <noscript><iframe src="//www.googletagmanager.com/ns.html?id=GTM-MKVKH7" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-MKVKH7');</script><script>(function(e){function n(n,t,o,a){"use strict";var i=e.document.createElement("link"),r=t||e.document.getElementsByTagName("script")[0],d=e.document.styleSheets;return i.rel="stylesheet",i.href=n,i.media="only x",a&&(i.onload=a),r.parentNode.insertBefore(i,r),i.onloadcssdefined=function(e){for(var t,o=0;d.length>o;o++)d[o].href&&d[o].href.indexOf(n)>-1&&(t=!0);t?e():setTimeout(function(){i.onloadcssdefined(e)})},i.onloadcssdefined(function(){i.media=o||"all"}),i}function t(e,n){e.onload=function(){e.onload=null,n&&n.call(e)},"isApplicationInstalled"in navigator&&"onloadcssdefined"in e&&e.onloadcssdefined(n)}var o=function(a,i){"use strict";if(a&&3===a.length){var r=e.Image,d=!(!document.createElementNS||!document.createElementNS("http://www.w3.org/2000/svg","svg").createSVGRect||!document.implementation.hasFeature("http://www.w3.org/TR/SVG11/feature#Image","1.1")||e.opera&&-1===navigator.userAgent.indexOf("Chrome")||-1!==navigator.userAgent.indexOf("Series40")),c=new r;c.onerror=function(){o.method="png",o.href=a[2],n(a[2])},c.onload=function(){var e=1===c.width&&1===c.height,r=a[e&&d?0:e?1:2];o.method=e&&d?"svg":e?"datapng":"png",o.href=r,t(n(r),i)},c.src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///ywAAAAAAQABAAACAUwAOw==",document.documentElement.className+=" grunticon"}};o.loadCSS=n,o.onloadCSS=t,e.grunticon=o})(this);grunticon(["https://c5.rgstatic.net/c/o1q2er/styles/icons/_header-ico.svg.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_header-ico.png.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_header-ico.fallback.scss"]);grunticon(["https://c5.rgstatic.net/c/o1q2er/styles/icons/_admin-ico.svg.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_admin-ico.png.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_admin-ico.fallback.scss"]);grunticon(["https://c5.rgstatic.net/c/o1q2er/styles/icons/_ico.svg.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_ico.png.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_ico.fallback.scss"]);</script></body>
</html>
