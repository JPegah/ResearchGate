<!DOCTYPE html> <html lang="en" class="" id="rgw44_56ab9f2c79194"> <head > <meta charset="utf-8"/> <meta http-equiv="content-type" content="text/html; charset=UTF-8"/> <meta name="Rg-Request-Token" id="Rg-Request-Token" content="jYdNmHg//uTnAHKGe0YB6+eiP5f9BHGtPOhgm096z/SYL9DlETYTO0HBwFyU0PbJq14idi4r7xjwhOwKRjaqdhkJjdGsKBbIyQhNf9M7fjAR4NPKevKQHs+WBqbTY9ETq+Ys8B1oOrWhkbF8RSdUcYScXF4PJyva7tr2MtKtmLKLC+1/GEUIwBLXZ1ZpUE0NBqTgANS+g+ffnCniU3mOXc09xACaqYOjI03sThlQQEeQ0UnhLp+WJ3gMr3SuFpi5niAQ+UIw91Pf6Wz9N/ruTtjAGbcaiF4toZzJanTGLGA="/> <meta http-equiv="expires" content="0"/> <link rel="apple-touch-icon" sizes="57x57" href="https://www.researchgate.net/apple-touch-icon-57x57.png"> <link rel="apple-touch-icon" sizes="60x60" href="https://www.researchgate.net/apple-touch-icon-60x60.png"> <link rel="apple-touch-icon" sizes="72x72" href="https://www.researchgate.net/apple-touch-icon-72x72.png"> <link rel="apple-touch-icon" sizes="76x76" href="https://www.researchgate.net/apple-touch-icon-76x76.png"> <link rel="apple-touch-icon" sizes="114x114" href="https://www.researchgate.net/apple-touch-icon-114x114.png"> <link rel="apple-touch-icon" sizes="120x120" href="https://www.researchgate.net/apple-touch-icon-120x120.png"> <link rel="apple-touch-icon" sizes="144x144" href="https://www.researchgate.net/apple-touch-icon-144x144.png"> <link rel="apple-touch-icon" sizes="152x152" href="https://www.researchgate.net/apple-touch-icon-152x152.png"> <link rel="apple-touch-icon" sizes="180x180" href="https://www.researchgate.net/apple-touch-icon-180x180.png"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-32x32.png" sizes="32x32"> <link rel="icon" type="image/png" href="https://www.researchgate.net/android-chrome-192x192.png" sizes="192x192"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-96x96.png" sizes="96x96"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-16x16.png" sizes="16x16"> <link rel="shortcut icon" type="image/x-icon" href="https://c5.rgstatic.net/m/2390829798215018/images/favicon.ico"/> <link rel="manifest" href="https://www.researchgate.net/manifest.json"> <meta name="msapplication-TileColor" content="#da532c"> <meta name="msapplication-TileImage" content="https://www.researchgate.net/mstile-144x144.png"> <meta name="theme-color" content="#444444"> <link rel="search" type="application/opensearchdescription+xml" title="ResearchGate search" href="https://www.researchgate.net/application.DownloadOpenSearchPlugin.html"/> <link rel="meta" type="application/rdf+xml" title="ICRA labels" href="https://www.researchgate.net/application.DownloadLabels.html"/> <link rel="http://oexchange.org/spec/0.8/rel/related-target" type="application/xrd+xml" href="https://www.researchgate.net/application.DownloadOExchange.html"/> <base href="https://www.researchgate.net/"/> <script>
    var rgConfig = {
        correlationId: "rgreq-43ff719f-a420-494e-8989-aed204076a2e",
        accountId: "",
        module: "publicliterature",
        action: "publicliterature.PublicPublicationDetails",
        page: "publicationDetail",
        product: "publications",
        continent: "Asia",
        stylesHome: "//c5.rgstatic.net/m/",
        staticHost: "c5.rgstatic.net",
        longRunningRequestIdentifier: "LongRunningRequest.publicliterature.PublicPublicationDetails",
        longRunningRequestFp: "e9e5bbe1366c7ee8c8e41d02f793c884ac9be19b"
    };
    window.rootUrl = "https://www.researchgate.net/";
</script> <link rel="canonical" href="https://www.researchgate.net/publication/230996489_A_Bayesian_Nonparametric_Approach_to_Image_Super-Resolution" />
<link rel="dns-prefetch" href="//c5.rgstatic.net" />
<link rel="dns-prefetch" href="//i1.rgstatic.net" />
<meta property="twitter:card" content="summary" />
<meta property="twitter:site" content="@ResearchGate" />
<meta property="og:title" content="A Bayesian Nonparametric Approach to Image Super-Resolution" />
<meta property="og:description" content="Super-resolution methods form high-resolution images from low-resolution
images. In this paper, we develop a new Bayesian nonparametric model for
super-resolution. Our method uses a beta-Bernoulli..." />
<meta property="og:site_name" content="ResearchGate" />
<meta property="og:image" content="https://i1.rgstatic.net/publication/230996489_A_Bayesian_Nonparametric_Approach_to_Image_Super-Resolution/links/004635320936583c57000000/smallpreview.png" />
<meta property="og:url" content="https://www.researchgate.net/publication/230996489_A_Bayesian_Nonparametric_Approach_to_Image_Super-Resolution" />
<meta property="rg:id" content="PB:230996489" />
<meta name="DC.identifier" scheme="DCTERMS.URI" content="http://dx.doi.org/10.1109/TPAMI.2014.2321404" />
<meta name="gs_meta_revision" content="1.1" />
<meta name="citation_title" content="A Bayesian Nonparametric Approach to Image Super-Resolution" />
<meta name="citation_author" content="Gungor Polatkan" />
<meta name="citation_author" content="Mingyuan Zhou" />
<meta name="citation_author" content="Lawrence Carin" />
<meta name="citation_author" content="David Blei" />
<meta name="citation_author" content="Ingrid Daubechies" />
<meta name="citation_pmid" content="26353246" />
<meta name="citation_publication_date" content="2012/09/22" />
<meta name="citation_journal_title" content="IEEE Transactions on Pattern Analysis and Machine Intelligence" />
<meta name="citation_issn" content="0162-8828" />
<meta name="citation_volume" content="37" />
<meta name="citation_issue" content="2" />
<meta name="citation_doi" content="10.1109/TPAMI.2014.2321404" />
<meta name="citation_pdf_url" content="https://www.researchgate.net/profile/Mingyuan_Zhou/publication/230996489_A_Bayesian_Nonparametric_Approach_to_Image_Super-Resolution/links/004635320936583c57000000.pdf" />
<meta name="citation_abstract_html_url" content="https://www.researchgate.net/publication/230996489_A_Bayesian_Nonparametric_Approach_to_Image_Super-Resolution" />
<meta name="citation_fulltext_html_url" content="https://www.researchgate.net/publication/230996489_A_Bayesian_Nonparametric_Approach_to_Image_Super-Resolution" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<link href="//c5.rgstatic.net/m/22664197317151888/styles/rg.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/21004998181197492/styles/rg2.css" type="text/css" rel="stylesheet"/>
<!--[if lt IE 9]><link href="//c5.rgstatic.net/m/238176252723686/styles/ie.css" type="text/css" rel="stylesheet"/><![endif]-->
<link href="//c5.rgstatic.net/m/217752362214895/styles/modules/publicprofile.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/215868066921738/styles/pow/publicliterature/FigureList.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/21993347442549/styles/pow/publicliterature/FollowPublicationPromo.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/282514599719602/styles/pow/application/PdfJsReader.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/23819663151220/styles/pow/publicliterature/PublicationInlineReader.css" type="text/css" rel="stylesheet"/>
<script src="//c5.rgstatic.net/m/2321000301012716/javascript/vendor/webfontloader/webfontloader.js" type="text/javascript"></script>
 <script>(function(i,s,o,g,r,a,m){i["GoogleAnalyticsObject"]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,"script","//www.google-analytics.com/analytics.js","ga");
 ga("create","UA-58591210-1");ga("set","anonymizeIp",true);ga('set', 'dimension1', 'publication full-text');ga('set', 'dimension2', 'Article');ga('set', 'dimension3', 'Logged out');ga('set', 'dimension4', 'https');ga("send","pageview");</script>
  <script> WebFontConfig = { custom: { families: ['source_sans_pro_italic', 'source_sans_pro_bold', 'source_sans_pro', 'martel'], urls : ['//c5.rgstatic.net/m/231392577336386/styles/fonts.css'] } }; WebFont.load(WebFontConfig); </script><noscript></noscript>

<title>A Bayesian Nonparametric Approach to Image Super-Resolution (PDF Download Available)</title>
<meta name="description" content="Official Full-Text Publication: A Bayesian Nonparametric Approach to Image Super-Resolution on ResearchGate, the professional network for scientists."/>
<meta name="keywords" content="scientific network, scientific platform, scientific community, research partner, research collaboration, journal articles, international collaboration, find researcher, lifescience researcher, interdisciplinary research, research collaboration"/>
</head>
<body class="use-svg-icons logged-out">
<div id="page-container">
<script type="text/javascript">var googletag = googletag || {}; googletag.cmd = googletag.cmd || [];
(function() { var gads = document.createElement("script"); gads.async = true; gads.type = "text/javascript"; var useSSL = "https:" == document.location.protocol; gads.src = (useSSL ? "https:" : "http:") + "//www.googletagservices.com/tag/js/gpt.js"; var node =document.getElementsByTagName("script")[0]; node.parentNode.insertBefore(gads, node); })();</script><div id="main" class="logged-out-header-support">
<div id="content" class="">

<noscript>
<div class="c-box-warning full-width-element" style="text-align: center; ">
    <div style="margin: auto; padding:10px;" class="container">
        <b>For full functionality of ResearchGate it is necessary to enable JavaScript.
            Here are the <a href="http://www.enable-javascript.com/" rel="nofollow" target="_blank">
                instructions how to enable JavaScript in your web browser</a>.</b>
    </div>
</div>
</noscript>

<div id="rgw1_56ab9f2c79194" itemscope itemtype="http://schema.org/ScholarlyArticle"><div class="publication-wrapper publication-wrapper-onecol" id="rgw2_56ab9f2c79194" itemscope itemtype="http://schema.org/ScholarlyArticle"> <div class="c-col-content"> <div class="c-content"> <div class="clearfix">  <div class="publication-header"> <div id="rgw5_56ab9f2c79194">  <div class="type-label"> Article   </div> <span class="Z3988" title="ctx_ver=Z39.88-2004&rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&rfr_id=info%3Asid%2Fresearchgate.net%3Aresearchgate&rft_id=info%3Adoi%2F10.1109%2FTPAMI.2014.2321404&rft.atitle=A%20Bayesian%20Nonparametric%20Approach%20to%20Image%20Super-Resolution&rft.title=IEEE%20Transactions%20on%20Pattern%20Analysis%20and%20Machine%20Intelligence&rft.jtitle=IEEE%20Transactions%20on%20Pattern%20Analysis%20and%20Machine%20Intelligence&rft.volume=37&rft.issue=2&rft.date=2012&rft.issn=0162-8828&rft.au=Gungor%20Polatkan%2CMingyuan%20Zhou%2CLawrence%20Carin%2CDavid%20Blei%2CIngrid%20Daubechies&rft.genre=article"></span> <h1 class="pub-title" itemprop="name">A Bayesian Nonparametric Approach to Image Super-Resolution</h1> <meta itemprop="headline" content="A Bayesian Nonparametric Approach to Image Super-Resolution">  <meta itemprop="image" content="https://i1.rgstatic.net/publication/230996489_A_Bayesian_Nonparametric_Approach_to_Image_Super-Resolution/links/004635320936583c57000000/smallpreview.png">  <div id="rgw8_56ab9f2c79194" class="publication-detail-author-list"> <div> <ul class="clearfix js-people-list">  <li id="rgw9_56ab9f2c79194" itemprop="author" itemscope itemtype="http://schema.org/Person"> <a itemprop="sameAs" href="profile/Gungor_Polatkan" class="pub-detail-item account-item"> <div class="indent-left"> <div class="people-img"> <img  src="https://c5.rgstatic.net/m/2671872220764/images/template/default/profile/profile_default_m.jpg" title="Gungor Polatkan" alt="Gungor Polatkan" height="20px" width="20px" style="height: 20px;"/> </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Gungor Polatkan</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item  remove-action-indent   " id="rgw10_56ab9f2c79194" data-account-key="Gungor_Polatkan">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="profile/Gungor_Polatkan"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="Gungor Polatkan" alt="Gungor Polatkan" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">     </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="profile/Gungor_Polatkan" class="display-name">Gungor Polatkan</a>    </h5> <div class="truncate-single-line meta">   <a class="meta ga-top-coauthor-institution" href="institution/Princeton_University" title="Princeton University">Princeton University</a>     </div>  <a href="javascript:" class="btn btn-promote btn-large people-item-contact-author js-contact-author">Message author</a>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>  <li id="rgw11_56ab9f2c79194" itemprop="author" itemscope itemtype="http://schema.org/Person"> <a itemprop="sameAs" href="profile/Mingyuan_Zhou" class="pub-detail-item account-item"> <div class="indent-left"> <div class="people-img"> <img  src="https://c5.rgstatic.net/m/2671872220764/images/template/default/profile/profile_default_m.jpg" title="Mingyuan Zhou" alt="Mingyuan Zhou" height="20px" width="20px" style="height: 20px;"/> </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Mingyuan Zhou</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item  remove-action-indent   " id="rgw12_56ab9f2c79194" data-account-key="Mingyuan_Zhou">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="profile/Mingyuan_Zhou"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="Mingyuan Zhou" alt="Mingyuan Zhou" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">     </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="profile/Mingyuan_Zhou" class="display-name">Mingyuan Zhou</a>    </h5> <div class="truncate-single-line meta">   <a class="meta ga-top-coauthor-institution" href="institution/Duke_University" title="Duke University">Duke University</a>     </div>  <a href="javascript:" class="btn btn-promote btn-large people-item-contact-author js-contact-author">Message author</a>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>  <li id="rgw13_56ab9f2c79194"> <a href="researcher/10135830_Lawrence_Carin" class="pub-detail-item author-item" itemprop="author" itemscope itemtype="http://schema.org/Person"> <div class="indent-left"> <div class="people-img">  <img src="https://c5.rgstatic.net/m/2951093203564/images/template/default/profile/profile_default_s.jpg" title="Lawrence Carin" alt="Lawrence Carin" height="20px" width="20px" style="height: 20px;"/>  </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Lawrence Carin</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item   not-claimed " id="rgw14_56ab9f2c79194">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="researcher/10135830_Lawrence_Carin"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="Lawrence Carin" alt="Lawrence Carin" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">       </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="researcher/10135830_Lawrence_Carin" class="display-name">Lawrence Carin</a>    </h5> <div class="truncate-single-line meta">   </div>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>  <li id="rgw15_56ab9f2c79194"> <a href="researcher/2064238818_David_Blei" class="pub-detail-item author-item" itemprop="author" itemscope itemtype="http://schema.org/Person"> <div class="indent-left"> <div class="people-img">  <img src="https://c5.rgstatic.net/m/2951093203564/images/template/default/profile/profile_default_s.jpg" title="David Blei" alt="David Blei" height="20px" width="20px" style="height: 20px;"/>  </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">David Blei</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item   not-claimed " id="rgw16_56ab9f2c79194">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="researcher/2064238818_David_Blei"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="David Blei" alt="David Blei" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">       </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="researcher/2064238818_David_Blei" class="display-name">David Blei</a>    </h5> <div class="truncate-single-line meta">   </div>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>  <li id="rgw17_56ab9f2c79194"> <a href="researcher/7792029_Ingrid_Daubechies" class="pub-detail-item author-item" itemprop="author" itemscope itemtype="http://schema.org/Person"> <div class="indent-left"> <div class="people-img">  <img src="https://c5.rgstatic.net/m/2951093203564/images/template/default/profile/profile_default_s.jpg" title="Ingrid Daubechies" alt="Ingrid Daubechies" height="20px" width="20px" style="height: 20px;"/>  </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Ingrid Daubechies</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item   not-claimed " id="rgw18_56ab9f2c79194">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="researcher/7792029_Ingrid_Daubechies"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="Ingrid Daubechies" alt="Ingrid Daubechies" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">       </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="researcher/7792029_Ingrid_Daubechies" class="display-name">Ingrid Daubechies</a>    </h5> <div class="truncate-single-line meta">   </div>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>   </ul> <div class="js-loading"></div>  </div> </div> <div class="pub-details js-pub-details">      <span itemprop="isPartOf" itemscope itemtype="http://schema.org/Periodical"> <a itemprop="sameAs" href="journal/0162-8828_IEEE_Transactions_on_Pattern_Analysis_and_Machine_Intelligence"><span itemprop="name">IEEE Transactions on Pattern Analysis and Machine Intelligence</span></a> </span>    (Impact Factor: 5.78).     <meta itemprop="datePublished" content="2012-09">  09/2012;  37(2).    DOI:&nbsp;10.1109/TPAMI.2014.2321404           <div class="pub-source"> Source: <a href="http://arxiv.org/abs/1209.5019" rel="nofollow">arXiv</a> </div>  </div> <div id="rgw19_56ab9f2c79194" class="pub-abstract">  <div class="clearfix">   <p itemprop="description"> <strong>ABSTRACT</strong> <div>Super-resolution methods form high-resolution images from low-resolution<br />
images. In this paper, we develop a new Bayesian nonparametric model for<br />
super-resolution. Our method uses a beta-Bernoulli process to learn a set of<br />
recurring visual patterns, called dictionary elements, from the data. Because<br />
it is nonparametric, the number of elements found is also determined from the<br />
data. We test the results on both benchmark and natural images, comparing with<br />
several other models from the research literature. We perform large-scale human<br />
evaluation experiments to assess the visual quality of the results. In a first<br />
implementation, we use Gibbs sampling to approximate the posterior. However,<br />
this algorithm is not feasible for large-scale data. To circumvent this, we<br />
then develop an online variational Bayes (VB) algorithm. This algorithm finds<br />
high quality dictionaries in a fraction of the time needed by the Gibbs<br />
sampler.</div> </p>  </div>   </div>     <div id="rgw20_56ab9f2c79194" class="figure-carousel"> <div class="carousel-hd"> Figures in this publication </div> <div class="carousel-bd"> <ul class="clearfix">  <li> <a href="/figure/230996489_fig1_Fig-1" class=" fig-frame js-click-link "  rel="tooltip" data-tooltip="Fig. 1. " data-key="230996489_fig1_Fig-1"> <img class="fig" src="https://www.researchgate.net/profile/Mingyuan_Zhou/publication/230996489/figure/fig1/Fig-1_small.png" alt="Fig. 1. " title="Fig. 1. "/> </a> </li>  <li> <a href="/figure/230996489_fig2_Fig-2" class=" fig-frame js-click-link "  rel="tooltip" data-tooltip="Fig. 2. " data-key="230996489_fig2_Fig-2"> <img class="fig" src="https://www.researchgate.net/profile/Mingyuan_Zhou/publication/230996489/figure/fig2/Fig-2_small.png" alt="Fig. 2. " title="Fig. 2. "/> </a> </li>  <li> <a href="/figure/230996489_fig3_Fig-3-Dictionary-trained-in-batch-mode-on-lluminance-channel-with-SR-ratio-2-Left" class=" fig-frame js-click-link "  rel="tooltip" data-tooltip="Fig. 3. Dictionary trained in batch mode on lluminance channel with SR..." data-key="230996489_fig3_Fig-3-Dictionary-trained-in-batch-mode-on-lluminance-channel-with-SR-ratio-2-Left"> <img class="fig" src="https://www.researchgate.net/profile/Mingyuan_Zhou/publication/230996489/figure/fig3/Fig-3-Dictionary-trained-in-batch-mode-on-lluminance-channel-with-SR-ratio-2-Left_small.png" alt="Fig. 3. Dictionary trained in batch mode on lluminance channel with SR..." title="Fig. 3. Dictionary trained in batch mode on lluminance channel with SR..."/> </a> </li>  <li> <a href="/figure/230996489_fig4_Fig-4" class=" fig-frame js-click-link "  rel="tooltip" data-tooltip="Fig. 4. " data-key="230996489_fig4_Fig-4"> <img class="fig" src="https://www.researchgate.net/profile/Mingyuan_Zhou/publication/230996489/figure/fig4/Fig-4_small.png" alt="Fig. 4. " title="Fig. 4. "/> </a> </li>  <li> <a href="/figure/230996489_fig5_Fig-6-Reconstruction-of-Parthenon-Image-BP-Algorithm-presented-in-this-work-trained" class=" fig-frame js-click-link "  rel="tooltip" data-tooltip="Fig. 6. Reconstruction of Parthenon Image . BP : Algorithm presented in..." data-key="230996489_fig5_Fig-6-Reconstruction-of-Parthenon-Image-BP-Algorithm-presented-in-this-work-trained"> <img class="fig" src="https://www.researchgate.net/profile/Mingyuan_Zhou/publication/230996489/figure/fig5/Fig-6-Reconstruction-of-Parthenon-Image-BP-Algorithm-presented-in-this-work-trained_small.png" alt="Fig. 6. Reconstruction of Parthenon Image . BP : Algorithm presented in..." title="Fig. 6. Reconstruction of Parthenon Image . BP : Algorithm presented in..."/> </a> </li>  </ul> </div> </div> <div class="action-container"> <div id="rgw21_56ab9f2c79194" class="follow-publication-promo"> <table> <tr> <td class="follow-publication-promo-text-cell"> <p>Get notified about updates to this publication</p> <a class="btn btn-large btn-promote js-follow-publication ga-follow-publication-new-promo">Follow publication</a> </td> <td> <div class="follow-publication-publication-image"></div> </td> </tr> </table> </div>  <div class="clear"></div> <div class="share-dialog-container" style="display: none;">  </div> </div> </div> <div style="margin-left: -20px; margin-right: -20px;">  </div> </div>  <div class="publication-detail-dfp-container rf"> <div id="rgw35_56ab9f2c79194">  </div> </div>  </div>  <div class="clearfix"> <div class="pdf-js-container clearfix " id="rgw36_56ab9f2c79194">  <div class="pdf-js-header js-sticky-header clear">  <a class="blue-link js-download rf btn btn-promote" href="https://www.researchgate.net/profile/Mingyuan_Zhou/publication/230996489_A_Bayesian_Nonparametric_Approach_to_Image_Super-Resolution/links/004635320936583c57000000.pdf?inViewer=0&amp;pdfJsDownload=0&amp;origin=publication_detail">Download full-text</a>  <h3>Full-text</h3> <span class="publication-info">  <span class="js-doi-container" style="display: none;"> DOI: <span class="js-doi"></span> &middot; </span> Available from: <a class="js-name" href="profile/Mingyuan_Zhou">Mingyuan Zhou</a>, <span class="js-publication-date"> Mar 12, 2014 </span>   </span>  </div>  <div class="social-share-container"><div id="rgw38_56ab9f2c79194" class="social-share js-social-share"> <div class="social-share-heading">Share</div>  <a id="rgw39_56ab9f2c79194" href="javascript:" title="Share on Facebook" class="link-nostyle js-share-item share-icon "  data-url="http://www.facebook.com/share.php?u={{url}}{{#title}}&amp;t={{title}}{{/title}}" data-width="600" data-height="350" data-name="Facebook"> <span class="share-icon ico-share-facebook-round reset-background ga-share-blog-facebook"></span> </a>  <a id="rgw40_56ab9f2c79194" href="javascript:" title="Share on Twitter" class="link-nostyle js-share-item share-icon "  data-url="http://twitter.com/intent/tweet?text={{#title}}{{title}}: {{/title}}{{url}}&amp;via=researchgate" data-width="600" data-height="350" data-name="Twitter"> <span class="share-icon ico-share-twitter-round reset-background ga-share-blog-twitter"></span> </a>  <a id="rgw41_56ab9f2c79194" href="javascript:" title="Share on Google+" class="link-nostyle js-share-item share-icon "  data-url="https://plus.google.com/share?url={{url}}" data-width="600" data-height="600" data-name="Google+"> <span class="share-icon ico-share-gplus-round reset-background ga-share-blog-gplus"></span> </a>  <a id="rgw42_56ab9f2c79194" href="javascript:" title="Share on LinkedIn" class="link-nostyle js-share-item share-icon "  data-url="http://www.linkedin.com/shareArticle?mini=true&amp;url={{url}}{{#title}}&amp;title={{title}}{{/title}}&amp;source=ResearchGate" data-width="520" data-height="570" data-name="LinkedIn"> <span class="share-icon ico-share-linkedin-round reset-background ga-share-blog-linkedin"></span> </a>  <a id="rgw43_56ab9f2c79194" href="javascript:" title="Share on Reddit" class="link-nostyle js-share-item share-icon "  data-url="https://www.reddit.com/submit?url={{url}}{{#title}}&amp;title={{title}}{{/title}}" data-width="600" data-height="600" data-name="Reddit"> <span class="share-icon ico-share-reddit reset-background ga-share-blog-reddit"></span> </a>  </div></div>    <iframe id="rgw37_56ab9f2c79194" src="https://www.researchgate.net/c/o1q2er/javascript/lib/pdfjs/web/viewer.html?file=https%3A%2F%2Fwww.researchgate.net%2Fprofile%2FMingyuan_Zhou%2Fpublication%2F230996489_A_Bayesian_Nonparametric_Approach_to_Image_Super-Resolution%2Flinks%2F004635320936583c57000000.pdf%3FinViewer%3D1%26pdfJsDownload%3D1%26origin%3Dpublication_detail" allowfullscreen frameborder="0" style="width: 100%; height: 100%; box-sizing: border-box;"></iframe>    </div> <noscript> <div id="rgw34_56ab9f2c79194"  itemprop="articleBody">  <p>Page 1</p> <p>1<br />A Bayesian Nonparametric Approach to Image<br />Super-resolution<br />Gungor Polatkan1, Mingyuan Zhou2, Lawrence Carin2, David Blei3, and Ingrid<br />Daubechies4<br />1Department of Electrical Engineering<br />3Department of Computer Science<br />Princeton University<br />Princeton, NJ<br />polatkan@princeton.edu, blei@cs.princeton.edu<br />2Department of Electrical Engineering<br />4Department of Mathematics<br />Duke University<br />Durham, NC<br />mz31@duke.edu, lcarin@duke.edu, ingrid@math.duke.edu<br />Abstract<br />Super-resolution methods form high-resolution images from low-resolution images. In this paper,<br />we develop a new Bayesian nonparametric model for super-resolution. Our method uses a beta-Bernoulli<br />process to learn a set of recurring visual patterns, called dictionary elements, from the data. Because it<br />is nonparametric, the number of elements found is also determined from the data. We test the results on<br />both benchmark and natural images, comparing with several other models from the research literature.<br />We perform large-scale human evaluation experiments to assess the visual quality of the results. In a<br />first implementation, we use Gibbs sampling to approximate the posterior. However, this algorithm is<br />not feasible for large-scale data. To circumvent this, we then develop an online variational Bayes (VB)<br />algorithm. This algorithm finds high quality dictionaries in a fraction of the time needed by the Gibbs<br />September 25, 2012 DRAFT<br />arXiv:1209.5019v1  [cs.LG]  22 Sep 2012</p>  <p>Page 2</p> <p>2<br />sampler.<br />Index Terms<br />Bayesian nonparametrics, factor analysis, dictionary learning, variational inference, gibbs sampling,<br />stochastic optimization, image super-resolution.<br />I. INTRODUCTION<br />The sparse representation of signals with a basis is important in many applications. It has been<br />extensively used in image denoising, inpainting, super-resolution, classification and compressive<br />sensing [1], [2], [3], [4], [5], [6], [7], [8].<br />Many real data sets can be sparsely represented in some basis; typically this basis itself has to<br />be learned from the data [1], [2], [3], [6], [7], [8], [9], [10], [11], [12]. For example, an image<br />can be represented by weighted combinations of recurrent patterns of pixels. This construction<br />may be beneficial, both while building a model for more accurate representation of the data (e.g.<br />superior image denoising models) and while deriving and implementing an inference procedure<br />for more efficient algorithms.<br />In this paper we consider image super-resolution (SR), the problem of recovering a high-<br />resolution (HR) image from a low-resolution (LR) image. It has many applications, e.g., to<br />smart phones, surveillance cameras, medical imaging, and satellite imaging.<br />There are a variety of approaches for image super-resolution. In general, rendering an HR<br />image from an LR image has many possible solutions. We must use regularization of some<br />form, i.e., prior information about the HR, to guarantee uniqueness and stability of the extension.<br />For this purpose, researchers have proposed several methods [13], [14]. Interpolation-based<br />methods, such as the Bicubic method and Bilinear method, often over-smooth images, losing<br />detail. Example-based approaches use machine learning to avoid this [15], [16], [17]; they train<br />on ground-truth HR and LR images, learning a statistical relationship between the two. These<br />relationships are later used to reconstruct unknown HR images from corresponding LR images.<br />Freeman et al. ([15]) proposes a method that stores a training set of preprocessed patches<br />and uses a nearest-neighbor search to super-resolve. Kim et al. ([16]) proposes using kernel<br />ridge regression with a regularized gradient descent. Another class of SR algorithms use texture<br />similarity to match image regions with known textures [18], [19]. Finally, there are methods for<br />September 25, 2012 DRAFT</p>  <p>Page 3</p> <p>3<br />single-image super-resolution. One classic example is [20] which uses recurring patterns at same<br />and different scales in a single image.<br />In this work, our focus is on SR via example-based sparse coding. ScSR (Super-resolution via<br />Sparse Representation) is such an algorithm pioneered in [21]. This algorithm is based on sparse<br />coding via L1 regularized optimization. In [21], image data are represented using a collection<br />of dictionary elements (recurring patterns of pixels) that are weighted across different positions.<br />Although very powerful, this model requires one to specify the number of dictionary elements<br />and the variance of the noise model in advance—parameters that may be difficult to assess<br />for real-world images. It also only provides a batch learning algorithm, i.e., computing model<br />parameters via a gradient descent algorithm on a fixed small subset of the data.<br />Bayesian nonparametric methods circumvent all these limitations. These methods adapt the<br />structure of the latent space to the data and provide a powerful representation because they<br />infer parameters that otherwise have to be assigned a priori [22], [23], [24], [25], [26], [27],<br />[28], [29], [30], [31], [32]. The full posterior distribution can be approximated via MCMC or<br />variational inference, yielding sparse representations and learned dictionaries.<br />Bayesian nonparametric methods have been used in many image analysis applications: to learn<br />deep architectures used for object recognition in [22], for image inpainting and denoising in [28],<br />[29], for image segmentation in [30], [31], and to learn nonparametric multiscale representations<br />of images in [32].<br />In this paper, we develop a Bayesian nonparametric method for super-resolution. We show<br />that inference in our model is feasible, performing super-resolution with both a sampling based<br />algorithm and an online variational inference algorithm. In the latter, we approximate the posterior<br />distributions via a stochastic gradient descent over a variational objective that enables us to use<br />the full data set and process the data segment by segment. We also provide human evaluation<br />experiments which shows that signal-to-noise ratio (a typical quantitative measure of success<br />in image analysis applications) is not necessarily consistent with human judgement. We devise<br />a new model, new algorithms, and study a human-based evaluation. We make the following<br />contributions:<br />‚ We develop a sparse Bayesian nonparametric model for SR, learning the number of dictio-<br />nary elements and the noise variance from the data.<br />‚ We develop an online variational Bayes (VB) algorithm finding high quality “coupled<br />September 25, 2012 DRAFT</p>  <p>Page 4</p> <p>4<br />Fig. 1.<br />Depicting the observations extracted (e.g. image patches) from high and low resolution images.<br />dictionaries&quot; in a fraction of the time needed by traditional inference.<br />‚ We devise large scale human evaluation experiments to explicitly assess the visual quality<br />of results.<br />Our approach to SR gives a rich nonparametric representation with scalable learning.<br />The remainder of the paper is organized as follows: Section II describes the proposed super-<br />resolution model and non-parametric prior, Section III contains the derivation of the posterior<br />inference algorithms, Section IV presents the experimental results and implementation details,<br />Section V includes the discussion and future work.<br />II. PROPOSED APPROACH<br />Bayesian factor analysis can be used to learn factors / dictionaries from natural images. Zhou<br />et al. ([28]) used beta process factor analysis in image denoising, inpainting and compressive<br />sensing. These models learn both the dictionary elements and their number from the data.<br />We build here a nonparametric factor analysis model that couples an HR image to a corre-<br />sponding LR image. In training, we learn the HR/LR relationship from observed HR/LR pairs.<br />To perform super-resolution, we condition on an observed LR image and compute the conditional<br />expectation of its corresponding HR image. A more detailed description of the training process is<br />as follows. We create training data by taking observed HR images and forming corresponding LR<br />images. Figure 1 depicts the preprocessing and data extraction steps. We first down-sample the<br />HR images. Then, we up-sample those by interpolating with a deterministic weighting function<br />(e.g. bicubic interpolation). We extract same-sized patches from the same locations of both the<br />HR and interpolated LR images, and consider those patches as coupled to each other. These are<br />September 25, 2012DRAFT</p>  <p>Page 5</p> <p>5<br />the data on which we train the model.<br />In the model, each small patch is generated from latent global dictionary elements—small<br />images functioning as factor loadings—using local sparse weights and Gaussian noise. We will<br />first explain how these latent variables are generated and then present how they are used to<br />generate the observations.<br />We learn two dictionaries: one for high resolution images and one for low resolution images.<br />In terms of notation, dplq<br />element. Pplqand Pphqrepresent the dimensionality of the low and high resolution dictionary<br />krepresents the LR dictionary element, and dphq<br />k<br />is the HR dictionary<br />elements, respectively. To model each dictionary element, we use a zero-mean Gaussian distri-<br />bution,<br />dplq<br />k<br />∼ Np0,Pplq´1IPplqq<br />dphq<br />k<br />∼ Np0,Pphq´1IPphqq.<br />The matrix form of the dictionaries are Dplqand Dphqwhere kth columns of those matrices are<br />dplq<br />Following [21], we assume that the sparse weights are shared by both resolution levels for<br />kand dphq<br />k, respectively.<br />combining dictionary elements to produce images. This is the key property of the model that<br />allows us to frame super-resolution as inference. Sparse weights have two components: real<br />valued weights sikand binary valued assignments zik. To model the weights sik, we use a zero-<br />mean Gaussian distribution with precision α. ziis a binary vector that encodes which dictionary<br />elements are activated for the corresponding observation. ppzq represents the prior of this variable<br />and we will elaborate on this in next section. These are given as<br />sik ∼ Np0,1{αq<br />zik ∼ ppzikq.<br />We place Gamma priors on the precisions of the sparse weights and observation noise (α and<br />γ). The two resolution levels share these variables as well,<br />γ ∼ Gammapc,dq,<br />represents patches extracted from HR and LR images, respectively, as shown<br />α „ Gammape,fq.<br />Let xphq<br />in Figure 1. Given the (global) dictionary elements and (local) sparse weights, the observations<br />i<br />and xplq<br />i<br />are modeled as<br />?plq<br />i ∼ Np0,γ´1IPplqq<br />xplq<br />?phq<br />i<br />∼ Np0,γ´1IPphqq<br />“ Dphqpsid ziq ` ?iphq<br />i “ Dplqpsid ziq ` ?iplq<br />xphq<br />i<br />September 25, 2012DRAFT</p>  <p>Page 6</p> <p>6<br />where tplq,phqu represents LR and HR, respectively. Here, N is the total number of patches, and<br />d represents the element-wise multiplication of two vectors. Figure 1 illustrates the graphical<br />model.<br />To use this model in SR, we must be able to compute the posterior distributions of the hidden<br />variables. In the training phase, we must compute the posterior distributions ppDphq,Dplq|txphq<br />of the dictionaries, given a collection of HR/LR image pairs. In testing, we use their posterior<br />i,xplq<br />iuq<br />expectation to reconstruct a held-out HR image from an LR image,<br />Erxphq<br />j|xplq<br />j,txphq<br />i,xplq<br />ius «ˆD<br />phqpˆ sjd ˆ zjq<br />(1)<br />whereˆD<br />posterior expectation of the sparse weights from the LR image patches (xplq<br />inference. (We discuss algorithms for posterior inference in Section III.)<br />phqis the mean of the posterior distribution ppDphq|txphq<br />i,xplq<br />iuq and pˆ sjd ˆ zjq are the<br />j) via posterior<br />A. Beta-Bernoulli Process Prior (BP)<br />We now discuss the prior for the factor assignments zi. We use a beta-Bernoulli process (BP)<br />[22], [23], [24], [25], [26], [27], [28], [29], a prior on infinite binary matrices which is connected<br />to the Indian buffet process (IBP). Each row encodes which dictionary elements are activated<br />for the corresponding observation; columns with at least one active cell correspond to factors.<br />The distinguishing characteristic of this prior is that the number of these factors is not specified<br />a priori. Conditioned on the data, we examine the posterior distribution of the binary matrix to<br />obtain a data-dependent distribution of how many components are needed.<br />The IBP metaphor gives the intuition. Consider a buffet of dishes at a restaurant. Suppose there<br />are infinite number of dishes and we are trying to specify the infinite binary matrix indicating<br />which customers (observations) choose which dishes (factors/dictionary elements). In the Indian<br />buffet process (IBP), N customers enter the restaurant sequentially. Each customer chooses<br />dishes in a line from a buffet. The first customer starts from the beginning of the buffet and<br />takes from each dish, stopping after Poisson(τ) number of dishes. The ith customer starts from<br />the beginning as well, but decides to take from dishes in proportion to their popularity within the<br />previous i´1 customers. This proportionality can be quantified as<br />of previous customers who took this kth dish. After considering the dishes previously taken by<br />mk<br />iwhere mkis the number<br />other customers, the ith customer tries a Poisson(τ<br />i) number of new dishes. Which customers<br />September 25, 2012DRAFT</p>  <p>Page 7</p> <p>7<br />Fig. 2.<br />Graphical Model.<br />chose which dishes is recorded by the infinite binary matrix with N rows (indicating the<br />customers/observations) and infinite columns (indicating the dishes/factors/dictionary elements).<br />One important (and surprising) property of this process is that the joint probability of final<br />assignment is independent of the order of customers getting into the restaurant which is called<br />exchangeability property of the prior [33].<br />The probabilistic construction is as follows. Each observation i is drawn from a Bernoulli<br />process (a sequence of independent identically distributed Bernoulli trials), xi„ BePpBq where<br />B is drawn from a beta process B „ BPpc0,B0q. B0represents the base measure with B0“<br />Np0,1{βIq. As K Ñ 8, the ith observation is xi “ř8<br />the dictionary element dkis used while representing the ith observation or not, and the sample<br />from the beta process is given by B “ř8<br />dictionary element dk.<br />In inference, we use a finite beta-Bernoulli approximation [25]. The finite model truncates the<br />k“1zikδdkwhere zik denotes whether<br />k“1πkδdk. Here, πkrepresents the usage probability of<br />number of dictionary elements to K and is given by<br />πk„ Betapc0η0,c0p1 ´ η0qq, zik„ Bernoullipπkq<br />where c0and η0are scalars and<br />approximation approaches the IBP/BP. If the truncation is large enough, data analyzed with this<br />k P 1,...K. As K tends to infinity, the finite beta-Bernoulli<br />prior will exhibit fewer than K components [23].<br />September 25, 2012DRAFT</p>  <p>Page 8</p> <p>8<br />B. Super-resolution via Posterior Distributions<br />Our algorithm has 2 stages: fitting the model on pairs of HR and LR images, and super-<br />resolving new LR images to create HR versions.<br />Training: Coupled Dictionary Learning Stage. In training, we observe xphq<br />other random variables are latent. The key inference problem to be solved is the computation of<br />i<br />and xplq<br />i. All<br />the posterior distributions of the hidden variables. In the training phase, we must compute the<br />posterior distributions ppDphq,Dplq|txphq<br />image pairs. We rewrite the coupled model in a form similar to the single scale model:<br />¨<br />xphq<br />i<br />i,xplq<br />iuq of the dictionaries given a collection of HR/LR<br />xpcq<br />i<br />“<br />˝xplq<br />i<br />˛<br />‚,dpcq<br />k“<br />¨<br />˝dplq<br />k<br />dphq<br />k<br />˛<br />‚,?pcq<br />i<br />“<br />¨<br />˝?plq<br />i<br />?phq<br />i<br />˛<br />‚<br />(2)<br />where the superscript pcq corresponds to combination of plq and phq. Writing the fully-observed<br />model in this way reveals that we can train the dictionaries with similar methods as for the<br />single-scale base model (Training amounts to approximating the posteriors of these values). The<br />differences are that we use combined patches xpcq<br />to shared sparse weights for the two resolution levels. (The details of how we compute the<br />distribution ppDphq,Dplq|txphq<br />Super-resolving a Low Resolution Image. With fitted dictionaries in hand, we now show<br />how to form HR images from LR images via posterior computation.<br />In this prediction setting, the HR image xphq<br />i<br />is unknown; the goal is to reconstruct it from the<br />LR image patches xplq<br />ˆ γ, ˆ α of the noise and the sparse weights,<br />¨<br />´<br />First we find estimates of the sparse factor scores, pˆ sid ˆ ziq, by using the LR image patches<br />xplq<br />i<br />and posterior estimates of the dictionaries and precisions γ and α. The fitted value of α<br />determines the strength of a “regularization term&quot; that controls the sparsity of the factor scores.<br />i<br />and combined dictionaries dpcq<br />k. This leads<br />i,xplq<br />iuq are discussed in Section III.)<br />i, the posterior estimates of the dictionaries pˆD<br />phq,ˆD<br />plqq, and the precisions<br />xpcq<br />i<br />“<br />˝xplq<br />i<br />˛<br />‚, dpcq<br />k“<br />¨<br />˝dplq<br />k<br />dphq<br />k<br />˛<br />‚, ?pcq<br />i<br />“<br />¨<br />˝?plq<br />i<br />´<br />˛<br />‚.<br />More precisely, this prediction setting has 3 steps. The input is a set of held-out LR image<br />patches xplq<br />noise and the sparse weights. The steps are as follows:<br />i, the posterior estimates of the dictionaries pˆD<br />phq,ˆD<br />plqq, and the precisions ˆ γ, ˆ α of the<br />September 25, 2012DRAFT</p>  <p>Page 9</p> <p>9<br />1) We find estimates of the sparse factor scores, pˆ sid ˆ ziq, conditioned on the LR image<br />patches xplq<br />i<br />and estimates pˆD<br />2) Eq. 1 determines the HR patches ˆ xphq<br />3) We replace each xplq<br />i<br />pixel-wise average of those overlapping reconstructions.<br />phq,ˆD<br />plqq, ˆ γ, ˆ α from the training stage.<br />i.<br />by its corresponding collocated ˆ xphq<br />i; the whole HR image,ˆX<br />phq, is the<br />Post-processing: Following [21], we apply a post-processing step that, when down-sampled,<br />the reconstructed HR image,ˆX<br />the following optimization:<br />phq, should match the given LR image Xplq. Specifically, we solve<br />ˆX<br />phq˚“ argmin<br />X<br />||fpXq ´ Xplq||2<br />2` c||fpXq ´ˆX<br />phq||2<br />2<br />where fpq is a linear operator consisting of an anti-aliasing filter followed by down-sampling.<br />This optimization problem is solved with gradient descent.<br />III. POSTERIOR INFERENCE<br />In the proposed approach, all of the priors are in the conjugate exponential family. In a first<br />implementation, we use Gibbs sampling. We iteratively sample from the conditional distribution<br />of each hidden variable given the others and the observations. This defines a Markov chain<br />whose stationary distribution is the posterior [34]. The corresponding sampling equations are<br />analytic and provided in the appendix A-B (appendix is in the supplementary material).<br />The Gibbs sampler has difficulty with scaling to large data, because it must go through many<br />iterations, each time visiting the entire data set before the sampler mixes. For this reason, both<br />our Gibbs sampler and ScSR use 105patches sampled from 3 ˆ 106. We now develop here<br />an alternative algorithm to Gibbs sampling for SR that scales to large and streaming data.<br />Specifically, we develop an online variational inference algorithm.<br />Variational inference is a deterministic alternative to MCMC that replaces sampling with<br />optimization. The idea is to posit a parameterized family of distribution over the hidden variables<br />and then optimize the parameters to minimize the KL divergence to the posterior of interest [35].<br />Our algorithm iteratively tracks an approximate posterior distribution, which improves as more<br />data are seen.<br />In typical applications, the variational objective is optimized with coordinate ascent, iteratively<br />optimizing each parameter while holding the others fixed. However, in Bayesian settings, this<br />September 25, 2012DRAFT</p>  <p>Page 10</p> <p>10<br />suffers from the same problem as Gibbs sampling—the entire data set must be swept through<br />multiple times in order to find a good approximate posterior. In the algorithm we present here,<br />we replace coordinate ascent optimization with stochastic optimization—at each iteration, we<br />subsample our data and then adjust the parameters according to a noisy estimate of the gradient.<br />Because we only to subsample the data at each iteration, rather than analyze the whole data<br />set, the resulting algorithm scales well to large data. This technique was pioneered in [36]<br />and was recently exploited for online learning of topic models [37] and hierarchical Dirichlet<br />processes [38].<br />We first develop the coordinate ascent algorithm for the coupled model. Then we derive the<br />online variational inference algorithm, which can more easily handle large data sets.<br />A. Variational Inference for the Coupled model<br />We use the coupling perspective in Section II-B to derive the batch variational Bayes (VB)<br />algorithm. The single-scale base model is the BPFA model of [26], which gives a mean-field<br />variational inference algorithm. The batch VB algorithm derived here is the coupled version of<br />that.<br />We first define a parametrized family of distributions over the hidden variables. Let Q “<br />tπ,Z, S, D,γ,αu denote the hidden variables for all i,k. We write coupled data as in Equation<br />2; in the new set-up the variables to be learned become Q “ tπ,Z, S,Dpcq,γ,αu. We use a fully<br />factorized variational distribution,<br />qpQq “ qτpπqqφpDpcqqqνpZqqθpSqqλpγqq?pαq.<br />Each component of this distribution is governed by a free variational parameter,<br />qτkpπkq “ Betapτk1,τk2q<br />qφkjpdkjq “ Npφkj,Φkjq<br />qθikpsikq “ Npθik,Θikq<br />qνikpzikq “ Bernoullipνikq<br />qλpγq “ Gammapλ1,λ2q<br />q?pαq “ Gammap?1,?2q<br />We optimize these parameters with respect to a bound on the marginal probability of the<br />observations. This bound is equivalent, up to a constant, to the negative KL divergence between<br />q and the true posterior. Thus maximizing the bound is equivalent to minimizing KL divergence<br />September 25, 2012DRAFT</p>  <p>Page 11</p> <p>11<br />to the true posterior. Let Ξ “ tc0,η0,c,d,e,fu be the hyper-parameters. The variational lower<br />bound is<br />ÿK<br />`<br />`<br />`<br />logpppXpcq|Ξqq ě Hpqq `<br />ÿN<br />ÿN<br />ÿN<br />k“1<br />ÿJ<br />!<br />Eqrlogppπk|c0,η0,Kqs<br />j“1Eqrlog`ppdkj|βkjq˘s<br />i“1Eqrlogppzik|πqs `<br />i“1Eqrlog`ppsik|αqppα|e,fq˘s<br />i“1<br />)<br />(3)<br />!<br />Eqrlogppxpcq<br />i|Z,S,Dpcqγqs ` Eqrlogppγ|c,dqs<br />)<br />,<br />where Hpqq is the entropy of the variational distribution and dimensionality of the dictionary<br />elements J is twice as big as the single-scale model. We denote this function Lpqq.<br />Holding the other parameters fixed, we can optimize each variational parameter exactly; this<br />gives an algorithm that goes uphill in Lpqq [39]. (Further, this will provide the algorithmic<br />components needed for the online algorithm of Section III-B.)<br />Update equations for each free parameter optimizing this bound are given below. In all<br />equations, IP represents P ˆ P identity matrix, and ˜ xpcq<br />using all but the kth dictionary element, that is<br />ip´kqrepresents the reconstruction error<br />˜ xpcq<br />ip´kq“ xpcq<br />i<br />´ Dpcqpsid ziq ` dpcq<br />kpsikd zikq.<br />The expectation based on the variational distribution is then given by<br />Eqr˜ xpcq<br />ip´kqs “ xpcq<br />i<br />` φpcq<br />kpθikνikq ´<br />K ÿ<br />k“1<br />φpcq<br />kpθikνikq.<br />Update for the binary factor assignment zik: The variational parameter for factor assignment<br />zikis νik. We first consider two values of the variational distribution for two values (0,1) of zik,<br />`pθ2<br />qpzik“ 0q 9 exppEqrlnp1 ´ πkqsq, where<br />ÿ<br />Eqrlnp1 ´ πkqs “ ψ`c0p1 ´ η0q ´<br />qpzik“ 1q 9 exppEqrlnpπkqsqexp<br />´<br />´<br />λ1<br />λ2<br />ik` ΘikqpφpcqT<br />k<br />φpcq<br />k`ř<br />jΦkjq ´ 2θikφpcqT<br />2<br />k<br />Eqr˜ xpcq<br />ip´kqs˘<br />¯<br />Eqrlnpπkqs “ ψ`c0η0`<br />i<br />νik<br />˘´ ψpc0` Nq<br />ÿ<br />i<br />νik` N˘´ ψpc0` Nq<br />September 25, 2012DRAFT</p>  <p>Page 12</p> <p>12<br />Then the update equation for the variational parameter νikis given as<br />νik “<br />qpzik“ 1|´q<br />qpzik“ 1|´q ` qpzik“ 01|´q<br />Update for the shared sparse weight sik: The variational distribution for the sparse weight<br />sikis Gaussian parametrized with mean θikand variance Θik. Coordinate ascent update equation<br />for these free variational parameters are<br />´?1<br />θik “<br />Update for the kth coupled dictionary element dpcq<br />couple dictionary element dpcq<br />k<br />Coordinate ascent update equation for these free variational parameters are<br />Θik “<br />?2<br />`λ1<br />λ2νikpφpcqT<br />k<br />φpcq<br />k`<br />ÿ<br />j<br />Φkjq<br />¯´1<br />λ1<br />λ2ΘikνikφpcqT<br />k<br />Eqr˜ xpcq<br />ip´kqs.<br />k: The variational distribution for the<br />is Gaussian parametrized with mean φpcq<br />k<br />and variance Φpcq<br />k.<br />Φpcq<br />k<br />“<br />´<br />λ1<br />λ2Φpcq<br />2PI2P`λ1<br />λ2<br />N ÿ<br />i“1<br />pθ2<br />ik` Θikqν2<br />ik<br />¯´1<br />φpcq<br />k<br />“<br />k<br />N ÿ<br />i“1<br />θikνikEqr˜ xpcq<br />ip´kqs.<br />The updates for high resolution (h) and low resolution (l) components can be given separately<br />as<br />Φphq<br />k<br />“<br />´<br />λ1<br />λ2Φphq<br />2PIP`λ1<br />λ2<br />N ÿ<br />i“1<br />pθ2<br />ik` Θikqν2<br />ik<br />¯´1<br />Φplq<br />k<br />“<br />´<br />λ1<br />λ2Φplq<br />2PIP`λ1<br />λ2<br />N ÿ<br />i“1<br />pθ2<br />ik` Θikqν2<br />ik<br />¯´1<br />φphq<br />k<br />“<br />k<br />N ÿ<br />i“1<br />θikνik˜ xphq<br />ip´kq<br />φplq<br />k<br />“<br />k<br />N ÿ<br />i“1<br />θikνik˜ xplq<br />ip´kq.<br />Update for the dictionary usage probabilities πk: The variational distribution for the<br />dictionary usage probabilities πkis a beta distribution parametrized with the shape parameters<br />(τk1,τk2). Coordinate ascent update equation for these free variational parameters are<br />τk1 “ c0η0`<br />N ÿ<br />N ÿ<br />i“1<br />νik<br />τk2 “<br />N ´<br />i“1<br />νik` c0p1 ´ η0q.<br />September 25, 2012DRAFT</p>  <p>Page 13</p> <p>13<br />Update for the precision γ: The variational distribution for the precision γ of the observation<br />noise ?iis a gamma distribution parametrized with (λ1,λ2). Coordinate ascent update equation<br />for these free variational parameters are<br />λ1 “ c ` NP<br />λ2 “ d `1<br />2<br />N ÿ<br />i“1<br />!<br />||xpcq<br />i<br />´<br />K ÿ<br />)<br />k“1<br />φpcq<br />kpθikνikq||2<br />2`<br />K ÿ<br />k“1<br />νikpθ2<br />ik` ΘikqpφpcqT<br />k<br />φpcq<br />k`<br />ÿ<br />j<br />Φkjq<br />´<br />K ÿ<br />k“1<br />νikφpcqT<br />k<br />φpcq<br />kθ2<br />ik<br />.<br />Update for the precision α: The variational distribution for the precision α of the sparse<br />weights sikis a gamma distribution parametrized with (?1,?2). Coordinate ascent update equation<br />for these free variational parameters are<br />?1 “ e `1<br />?2 “ f `1<br />2NK<br />N ÿ<br />2<br />i“1<br />K ÿ<br />k“1<br />pθ2<br />ik` Θ2<br />ikq.<br />Algorithm 1 Batch VB<br />Sample N observations from the data. Initialize τ,ν,φ,Φ,θ,Θ,λ,? using Gibbs sampler.<br />for t “ 1 to T do<br />Init. local variables νnk,θnk,Θnkusing Gibbs sampler.<br />while relative improvement in ? is large do<br />for k “ 1 to K do<br />for n “ 1 to N do<br />update νnk,θnk,Θnkby using batch VB updates.<br />compute Φk,φk,τk,λ,? by batch VB updates.<br />B. Online Variational Inference<br />We now develop online variational inference. We divide the variational parameters into global<br />variables and local variables. Global variables depend on all of the images. These are the<br />dictionary probabilities πk, dictionary elements dk, precisions α and γ. Local variables are<br />the ones drawn for each image. These are the weights si, binary variables zi. The algorithm<br />September 25, 2012 DRAFT</p>  <p>Page 14</p> <p>14<br />iterates between optimizing the local variables using local (per-image) coordinate ascent, and<br />optimizing the global variables. This same structure is found in many Bayesian nonparametric<br />models [23], [40].<br />The basic idea is to optimize Equation 3 via stochastic optimization [41]. This means we<br />repeatedly follow noisy estimates of the gradient with decreasing step sizes ρt. If the step sizes<br />satisfyř<br />variational inference, we will converge to a local optimum.)<br />tρt“ 8 andř<br />tρ2<br />tă 8 then we will converge to the optimum of the objective. (In<br />Algorithm 2 Online VB with mini-batches<br />Define ρt“ pr ` tq´κ, Initialize τ,ν,φ,Φ,θ,Θ,λ,? using Gibbs sampler.<br />for t “ 1 to<br />Sample NSnew observations from the data. Initialize local variables νnk,θnk,Θnkusing Gibbs sampler.<br />while relative improvement in ? is large do<br />for k “ 1 to K do<br />for nt“ pt ´ 1q ˆ NS` 1 to t ˆ NSdo<br />update νntk,θntk,Θntkby using batch VB updates.<br />compute˜Φk,˜φk, ˜ τk,˜λ,˜ ? by batch VB updates as if there are N{NScopies of the images.<br />for k “ 1 to K do<br />update Φk,φk,τk,λ,? by Equation 6<br />N<br />NSdo<br />The noisy estimates of the gradient are obtained from subsampled data. We write the objective<br />L as a sum over data points. Defining the distribution gpnq which uniformly samples from the<br />data, we can then write L as an expectation under this distribution,<br />L “<br />“ NEgr?pτ,νn,φ,θn,Θn,λn,?n,Xnqs<br />The gradient of the objective can be written as a similar expectation. Thus, sampling data at<br />ÿN<br />n“1?pτ,νn,φ,θn,λn,?n,Xnq.<br />(4)<br />(5)<br />random and computing the gradient of ?ngives a noisy estimate of the gradient.<br />There are two further simplifications. First, when we subsample the data we optimize the<br />local variational parameters fully and compute the gradient of ?nwith respect to only the global<br />variational parameters. Second, we use the natural gradient [42] rather than the gradient. In mean<br />field variational inference, this simplifies the gradient step as follows. Suppose we have sampled<br />an image n and fitted its local variational parameters given the current settings of the global<br />September 25, 2012DRAFT</p>  <p>Page 15</p> <p>15<br />Fig. 3.<br />Dictionary trained in batch mode on lluminance channel with SR ratio = 2. (Left) HR Dictionary, (Right) LR<br />Dictionary, Every square represents a dictionary element and the HR-LR pairs are co-located. HR dictionary consists of sharper<br />edges.<br />variational parameters. Let ˜ τ,˜φ,˜Φ,˜λ,˜ ? be the global variational updates from Section III-A as<br />though we observed N copies of that image. (Note that these depend on its local variational<br />parameters.) Following a noisy estimate of the natural gradient of L is equivalent to taking a<br />weighted average of the current and the newly fitted global parameters, e.g.<br />φ “ p1 ´ ρtqφ ` ρt˜φ.<br />(6)<br />It follows that there is no additional computational cost to optimizing the global variational<br />parameters with stochastic optimization versus coordinate ascent.<br />In our implementation, we decrease the step-size ρt by ρt“ pρ0` tq´κ. The learning rate<br />parameter ρ0 down-weights early iterations; the parameter κ controls the speed of forgetting<br />previous values of the global variables.<br />The full online VB algorithm is listed in Algorithm 2. (Note that we sample the data in<br />mini-batches, rather than one at a time. When the mini-batch size is equal to one data point, we<br />recover the algorithm as described above.)<br />September 25, 2012DRAFT</p>  <p>Page 16</p> <p>16<br />C. Initialization with MCMC.<br />We initialize both the batch and online VB with a few iterations (e.g. 5 or 10) of MCMC.1This<br />is useful for two reasons: (1) It provides a good initialization and thus faster convergence, (2)<br />Noisy random-walks of MCMC help VB avoid low-quality local optima: at the beginning of each<br />e-step, MCMC initializes siand ziby sampling from their approximate posterior distribution,<br />given the most recent global variables. These samples are noisy estimates of the sparse weights<br />near their posterior means. For instance, when the factor assignment zikequals 0, the MCMC<br />draws the sparse weight sik from the prior Np0,1{αq whereas in VB it would be exactly 0.<br />Providing the freedom to “jiggle&quot; gives the algorithm the opportunity, similar to simulated<br />annealing, to jump away from one local optimum to reach a better optimum.<br />IV. EXPERIMENTS<br />We use three data sets. To train, we use the set of 68 images collected from the web by [21].<br />We test on the Berkeley natural image data set (20 100ˆ100 images) and a benchmark set of<br />images (11 images of various size) used by the community to evaluate SR algorithms.2These<br />data sets provide us with a rich set of HR-LR pairs.<br />Throughout this work, unless otherwise mentioned we use the same parameters (without any<br />tuning): we set the SR ratio to 2 or 4 and the patch size to 8 ˆ 8.3The hyper-parameters are<br />c “ d “ e “ f “ 10´6and c0“ 2,η0“ 0.5, these are standard uninformative priors used in e.g.<br />[28]. The truncation level K in BP is set to 512. Most images use fewer factors, e.g. Baboon<br />uses 487, House 438 and Barbara 471 factors. We apply all algorithms only to the illuminance<br />channel and use Bicubic interpolation for the color layers (Cb, Cr) for all compared methods.<br />We study our methods with two kinds of posterior inference—Gibbs sampling (BP) and online<br />1For batch VB, these MCMC samples are collected on the same subset of the data on which batch VB will process. For<br />online VB, they are collected from the mini-batches. In both cases, scale problem of MCMC is not an issue since we only<br />collect few samples (e.g. 5 or 10). As we mentioned before, scale is a problem for MCMC since it needs to go over the data<br />many times for convergence (e.g. thousands of iterations). Time scaling is discussed in more detail in Section IV-C<br />2We are using SR ratio=2 or 4. For SR ratio 2, the images which do not have even number of rows/columns are cut to have<br />even number of rows/column to prevent any possible mismatch and error in computing PSNR in all algorithms. For instance<br />the last column of pixels from an image of size 330 ˆ 171 is excluded so the corresponding image have the size 330 ˆ 170.<br />3The visual results for SR ratio 4 are in the appendix G.<br />September 25, 2012DRAFT</p>  <p>Page 17</p> <p>17<br />TABLE I<br />TEST RESULTS WITH SR RATIO = 2. PSNR FOR THE ILLUMINANCE CHANNEL IS PRESENTED (THE HIGHER THE BETTER).<br />BP: PROPOSED ALGORITHM TRAINED VIA GIBBS SAMPLER, O-BP PROPOSED ALGORITHM TRAINED VIA ONLINE VB,<br />SEEING MORE DATA, SCSR: SUPER-RESOLUTION VIA SPARSE REPRESENTATION [21], NNI: NEAREST NEIGHBOR<br />INTERPOLATION, SME: SPARSE MIXING ESTIMATION [43].<br />PSNR<br />Bic.NNI Bil. SMEScSR256 ScSR512 BPOBP<br />Baboon23.63 23.1223.0523.10 24.33 24.3624.27<br />24.39<br />25.99<br />31.31<br />Barbara25.35 25.10 24.92 24.42 25.8825.8925.98<br />Boat29.95 28.39 28.9429.72 31.2331.2931.17<br />Camera30.32<br />35.20<br />28.94 26.33 30.6830.46 31.5130.94<br />House 32.79 30.3431.61 33.2834.26<br />34.31<br />34.0834.27<br />Peppers 31.9929.8831.18 33.06 33.0533.06 32.45<br />33.08<br />Parthen.28.1227.2827.42 27.2829.05<br />29.10<br />28.96 29.06<br />Girl34.76 33.4433.98 33.98 35.5735.5835.62<br />35.66<br />41.33<br />34.68<br />32.62<br />Flower 40.0437.96 38.9439.72 41.06 41.11 41.26<br />Lena32.83 31.0031.7233.57 34.4734.54 34.56<br />Raccoon 30.9529.82 29.9531.73 32.39 32.4332.43<br />variational inference (O-BP), which scales to larger data sets.4To compare, we study both<br />interpolation and example-based algorithms. Bicubic interpolation is the gold standard in the SR<br />literature. We also study nearest neighbor interpolation, bilinear interpolation and sparse mixing<br />estimation (SME) [43]. To compare with an example-based method, we use super-resolution via<br />4The software for each algorithm presented and all of the visual results will be publicly available.<br />September 25, 2012DRAFT</p>  <p>Page 18</p> <p>18<br />sparse representation (ScSR, [21]).5 6 7Both BP’s and ScSR’s dictionary learning stages use<br />105patches sampled from the training data, however O-BP uses the whole set in online fashion.<br />The HR and LR dictionaries trained by our approach are shown in Figure 3. The HR dictionary<br />consists of sharper edges.<br />As a quantitative measure of performance we compute the signal to noise ratio (PSNR), a<br />measure that is widely used in image recovery applications. We present the PSNR results for<br />benchmark images in Table I and natural images in Table II. These PSNR based results can be<br />summarized as: (1) The online learning algorithm and ScSR performs similarly, (2) They both<br />slightly perform better than the Gibbs sampler. (3) All of the example based algorithms perform<br />better than the interpolation based techniques.<br />A. Evaluation and Crowdsourcing via Mechanical Turk<br />Though signal to noise ratio (PSNR), is a widely used metric in image recovery applications,<br />this is not enough to measure human judgement. For this purpose, we also performed human<br />evaluation experiments on Amazon Mechanical Turk (MTurk, http://www.mturk.com).<br />The Amazon Mechanical Turk (MTurk) is a web interface for deploying small tasks to<br />people, called Turkers. Typically an MTurk experiment works as follows: the requesters, people<br />organizing the experiments and paying Turkers, prepare tasks called HITs (Human Intelligence<br />Tasks). Each HIT might be a comparison of images, labeling of text etc. Once the HITs are<br />completed, requesters can approve or reject the HITs based on their reliability measures (for<br />5We used the code and implementation provided by [21]. We also used their training images, in order to have a fair comparison,<br />and we did not change any of their parameters (including noise variance).<br />6We provide visual comparisons to [15], [16], [20], [44] in appendix H. [20] provides very sharp edges by artificially enhancing<br />them. However, this makes images unrealistic (looking like graphically rendered). Sparse coding allows any single-image SR<br />algorithm as a pre-processing step. Instead of bicubic interpolation (see Figure 1) [20] might be used with sparse coding to<br />boost the sharpness of the edges.<br />7The dependent hierarchical Beta process (dHBP), another bayesian nonparametric prior, is proposed in [29]. It removes the<br />exchangeability assumption of beta-Bernoulli construction. This prior assumes that each observation i has a covariate ?i P RL.<br />In this model, the closer the two sparse factor assignments zi and zj in the covariate space, the more likely they share similar<br />dictionary elements. It applies dHBP using spatial information as covariates to image inpainting and spiky noise removal, and<br />shows significant improvement over BP. We obtained preliminary results with dHBP for super-resolution. However, in this setting<br />we did not observe improvement over BP.<br />September 25, 2012DRAFT</p>  <p>Page 19</p> <p>19<br />TABLE II<br />TEST RESULTS WITH SR RATIO = 2. PSNR FOR THE ILLUMINANCE CHANNEL IS PRESENTED (THE HIGHER THE BETTER).<br />BP: PROPOSED ALGORITHM TRAINED VIA GIBBS SAMPLER, O-BP PROPOSED ALGORITHM TRAINED VIA ONLINE VB,<br />SEEING MORE DATA, SCSR: SUPER-RESOLUTION VIA SPARSE REPRESENTATION [21], NNI: NEAREST NEIGHBOR<br />INTERPOLATION.<br />PSNR<br />Bic. NNIBilin.ScSR256 ScSR512BPO-BP<br />N129.7427.4428.39 31.52 31.5531.52<br />31.56<br />31.20<br />N2 29.5227.7128.27 31.16<br />31.20<br />24.00<br />22.66<br />26.06<br />26.26<br />31.17<br />N322.9721.95 22.12 23.94 23.8023.94<br />N421.6320.98 20.90 22.5922.3822.41<br />N5 24.8523.85 24.0126.01 25.7725.90<br />N625.34 24.6124.7026.20 26.0826.07<br />N726.66 25.4325.7327.92 27.92 27.77<br />27.97<br />N826.08 24.7125.23 27.27<br />27.43<br />26.89<br />26.25<br />27.01 27.26<br />N926.02 25.2925.42 26.82 26.5826.73<br />N10 24.7924.07 23.92 26.2325.91 26.16<br />N11 26.8625.22 25.9728.06 28.04 27.99<br />28.16<br />29.86<br />N1228.16 26.65 27.0729.6329.66 29.78<br />N1325.1524.18 24.22 26.40<br />26.36<br />28.01<br />26.31 26.33<br />N1426.82 25.9825.9227.99 27.8627.94<br />N15 25.7824.64 24.81 27.0027.04 26.90<br />27.06<br />N16 27.28 25.8526.16 28.88<br />29.01<br />29.24<br />28.8328.96<br />N1727.79 26.3326.81 29.21 29.0229.16<br />N1829.1327.7528.18 30.3830.41 30.25<br />30.43<br />N1924.57 23.1923.5026.07<br />26.10<br />25.9226.02<br />N20 22.0021.13 21.05 23.2623.28 23.26<br />23.29<br />instance trivial solution HITs, as we explain next, and the time spend on each HIT are frequently<br />used measures for reliability). Approved results are acquired to be used in the analysis.<br />While preparing HITs, we used the natural image data. We asked Turkers to visually assess<br />and select the better of two HR reconstructions of each image. We considered all ordered<br />combinations of the algorithms, each equally likely, e.g., BP vs ScSR, BP vs Bicubic etc.<br />We initially collected 42,807 decisions from 208 unique Turkers. For quality control we gave<br />test pairs in which a ground truth HR image was used, i.e., a comparison of an algorithmic<br />reconstruction vs a true HR image. All of the judgments of the Turkers who failed to pass this<br />September 25, 2012DRAFT</p>  <p>Page 20</p> <p>20<br />Fig. 4.<br />Human Evaluation via Mechanical Turk. (Top) Average win rate in one-to-one comparisons. (Bottom) Win rates<br />for each one-to-one comparison. Each number represents the winning rate of the method in the column, e.g., 0.57 for BP vs<br />ScSR (BP is on the column and ScSR on the row) means that on average, 0.57 of the times Turkers voted in favor of BP.<br />test (Turkers who selected the algorithmic reconstruction instead of true HR) were removed.<br />This reduced the data to 20,469 decisions from 161 unique reliable Turkers.<br />The results of the human evaluation are in Figure 4. In the bottom table, win rates for each<br />one-to-one comparisons are provided. Each number represents the winning rate of the method in<br />the column. For instance, 0.93 for O-BP vs Nearest (O-BP is on the column and Nearest on the<br />row) means that out of 100 binary comparisons of O-BP and Nearest, 93 of the times Turkers<br />voted in favor of O-BP. In general, we observe that example-based methods perform significantly<br />better than interpolation-based methods. Within the example-based approaches, the models are<br />similar. However, our approach does not use the first and second-order derivative filters for the<br />LR patches used by ScSR as features, yet we perform similarly; moreover we do not need to set<br />the noise precision and the number of dictionary elements, both required parameters of ScSR<br />(We used the parameters provided by [21] in ScSR.).<br />September 25, 2012 DRAFT</p>  <p>Page 21</p> <p>21<br />(a) High(b) Low (c) Bicubic (d) NNI(e) Bilinear<br />(f) ScSR (g) BP(h) O-BP<br />Fig. 5.<br />Reconstruction of Natural Image 3. BP: Algorithm presented in this work trained via Gibbs sampler, O-BP Algorithm<br />presented in this work trained via Online VB, ScSR: Super-Resolution via Sparse Representation. Example based approaches<br />are superior to interpolation techniques, ScSR and our approach perform similarly.<br />In the PSNR results, ScSR and O-BP seem to perform similarly and both slightly better than<br />BP. However, in the human evaluation we observed that BP reconstructions are found to be<br />better. (Based on 95% confidence intervals, both the BP vs O-BP and BP vs ScSR results are<br />statistically significant. The O-BP vs ScSR difference is statistically insignificant.) This shows<br />that PSNR is not necessarily consistent with the human assessment of images [45]. Sample<br />visual results are shown in Figures 5, 6 and 7. (The remaining results are in the appendix E and<br />F.)<br />September 25, 2012 DRAFT</p>  <p>Page 22</p> <p>22<br />(a) High(b) Low (c) Bicubic<br />(d) NNI (e) Bilinear<br />(f) SME (g) ScSR<br />(h) BP(i) O-BP<br />Fig. 6.<br />Reconstruction of Parthenon Image. BP: Algorithm presented in this work trained via Gibbs sampler, O-BP<br />Algorithm presented in this work trained via Online VB, ScSR: Super-Resolution via Sparse Representation. SME: Sparse<br />Mixing Estimation [43]<br />September 25, 2012DRAFT</p>  <p>Page 23</p> <p>23<br />(a) High(b) Low (c) Bicubic<br />(d) NNI(e) Bilinear (f) SME<br />(g) ScSR(h) BP (i) O-BP<br />Fig. 7.<br />Reconstruction of Baboon Image. BP: Algorithm presented in this work trained via Gibbs sampler, O-BP Algorithm<br />presented in this work trained via Online VB, ScSR: Super-Resolution via Sparse Representation. SME: Sparse Mixing<br />Estimation [43].<br />September 25, 2012 DRAFT</p>  <p>Page 24</p> <p>24<br />10<br />Number of Dictionary Elements  in Log scale(K)Number of Dictionary Elements  in Log scale(K)<br />11<br />10 10<br />22<br />1010<br />33<br />1010<br />44<br />25.625.6<br />25.6525.65<br />25.7 25.7<br />25.75 25.75<br />25.8 25.8<br />25.85 25.85<br />25.9 25.9<br />25.9525.95<br />26 26<br />PSNR (dB)<br />  <br />  <br />ScSR<br />BP<br />BP<br />10<br />PSNR (dB)<br />ScSR<br />890900 910920 930940<br />0<br />5<br />10<br />15<br />20<br />25<br />Number of Samples<br />Number of Dictionary Elements<br />Fig. 8.<br />Learning the number of dictionary elements from the data. (Left) PSNR of the reconstruction of the Barbara image<br />by nonparametric BP and parametric ScSR with different number of dictionary elements. (Right) Histogram of the number of<br />dictionary elements for BP when K “ 1024 over 100 samples.<br />B. Nonparametric property of the model.<br />In this section, we demonstrate the importance of a Bayesian nonparametric method for image<br />super-resolution. As we mentioned in Section II-A, we use a beta-Bernoulli process (BP) for the<br />factor assignments zithat encodes which dictionary elements are activated for the corresponding<br />observation. In the binary matrix (whose rows are the factor assignment zi’s), the columns with<br />at least one active cell correspond to factors that are used.<br />The distinguishing characteristic of this prior is that the number of the factors to be learned<br />is not specified a priori. Conditioned on the data, we examine the posterior distribution of the<br />binary matrix to obtain a data-dependent distribution of how many components are needed. For<br />the parametric ScSR, the number of dictionary elements must be set a priori. This is illustrated<br />by the following experiment. For both model, we train on 104patches, for different values of<br />K (starting from scratch each time); for ScSR, K is the target number (which needs to be set<br />before starting the algorithm), while for our approach, K functions as an upper bound on the<br />number of dictionary elements (which should not be too low). Figure 8 shows that, unlike ScSR,<br />our approach is less sensitive to the value of K if it is sufficiently large. The Barbara image uses<br />700, 801 and 816 factors in our approach for K equals to 1024,2048 and 4096 respectively.<br />September 25, 2012DRAFT</p>  <p>Page 25</p> <p>25<br />0 0.61.21.8 2.43 3.6<br />Image Patches Seen<br />4.2 4.85.46 6.6 7.27.8 8.49<br />5<br />x 10<br />26.2<br />26.4<br />26.6<br />26.8<br />27<br />27.2<br />Mean PSNR (dB)<br /> <br /> <br />Batch−VB 100K<br />Batch−VB 50K<br />Online−VB Mini−batch 20K<br />Online−VB Mini−batch 10K<br />Online−VB Mini−batch  5K<br />Fig. 9.<br />Held-out prediction performances of Online Learning with different mini-batch sizes. Online-VB run on the whole<br />data set is compared with the Batch-VB run on a subset of the data. The online algorithms converge much faster than the batch<br />algorithm does.<br />C. Online learning, Computational Time and Scaling<br />In this section, we compare the scale properties of the algorithms presented in this paper. In<br />online learning, instead of subsampling the patches during the dictionary learning stage, we use<br />the full data set and process the data segment by segment (so called &quot;mini-batches&quot;). We use<br />the training data set of Section IV. The learning parameters are set to κ “ 0.501 and ρ0“ 3.<br />Figure 9 shows the evolution of the mean PSNR on the held-out natural image data set<br />by the online and the batch algorithms as a function of the number of image patches seen<br />(visualizations of the learned dictionaries are provided in appendix D). The number of patches<br />seen represents the computational time since both algorithms’ time complexity is linear with<br />number of observations. For online VB, the number of patches seen represents the total number<br />of data seen after each iteration. For batch VB, this represents cumulative sum of the number<br />of same data seen after each variational-EM iteration. Even before the second iteration of the<br />batch VB (100K) is completed, online VB with 5K mini-batch converges – reaches to a local<br />optima better than batch VB. This means that the online algorithm finds dictionaries at least as<br />good as those found by the batch VB in only a fraction of the time. As also shown in Table<br />I, it finds high quality dictionaries. This may be because stochastic gradient is robust to local<br />September 25, 2012DRAFT</p>  <p>Page 26</p> <p>26<br />optima [46].<br />For dictionary training, the convergence time for online VB with 5K mini-batch size is 16<br />hours. In Gibbs sampling, we throw away the first 1500 samples for the burn-in period and<br />later collect 1500 samples to approximate the posterior distributions. This takes approximately<br />50 hours on the same machine with an unoptimized Matlab implementation on 105number<br />of patches. Running Gibbs sampling same amount of time with online VB, i.e. collecting less<br />number of samples such as 500, reduces held-out PSNR between 0.2 dB to 0.5 dB, depending<br />on the image. This is consistent with the findings in [28].<br />V. DISCUSSION<br />We developed a new model for super-resolution based on Bayesian nonparametric factor<br />analysis, and new algorithms based on Gibbs sampling and online variational inference. With<br />online training, our algorithm scales to very large data sets. We evaluated our method against<br />a leading sparse coding technique [21] and other state of the art methods. We evaluated both<br />with traditional PSNR and by devising a large scale human evaluation. This is a new real-world<br />application that can utilize online variational methods.<br />The choice of the inference algorithm depends on the usage case. Our results suggest that with<br />more computation time Gibbs sampling performs slightly better (based on human evaluation).<br />If speed is important, our online algorithms can be used without much loss.<br />Regarding the evaluation metric, the standard in image analysis has been signal-to-noise ratio<br />(PSNR). However, its practical relevance has been questioned [45]. The human eye is sensitive to<br />details which are not always captured in this metric, and that is why we ran a human evaluation.<br />Our experiments show that the signal-to-noise ratio is not necessarily consistent with human<br />judgement.<br />As future work, our approach can be used as a building block in other, more complicated,<br />probabilistic models. For example, our approach could be developed into a time series to perform<br />super-resolution on video or a hierarchical model can be built that fully generates the whole image<br />instead of patch based approach.<br />REFERENCES<br />[1] M. Aharon, M. Elad, and A. Bruckstein, “SVD: An Algorithm for Designing Overcomplete Dictionaries for Sparse<br />Representation,” IEEE Transactions on Signal Processing, vol. 54, pp. 4311–4322, 2006.<br />September 25, 2012DRAFT</p>  <p>Page 27</p> <p>27<br />(a) High(b)<br />Low<br />(c) Bicubic<br />(d) NNI (e) ScSR(f) BP<br />Fig. 10. (Natural Image 18) Test Set Results with SR ratio = 4.<br />(a) High (b)<br />Low<br />(c) Bicubic<br />(d) NNI (e) ScSR(f) BP<br />Fig. 11. (Natural Image 19) Test Set Results with SR ratio = 4.<br />September 25, 2012DRAFT</p>  <p>Page 28</p> <p>28<br />TABLE III<br />TEST SET RESULTS WITH SR RATIO = 4. PSNR FOR THE ILLUMINANCE CHANNEL (HIGHER THE BETTER). BP:<br />ALGORITHM PRESENTED IN THIS PAPER WITH BETA PROCESS (BP) PRIOR TRAINED WITH GIBBS SAMPLER, SCSR:<br />SUPER-RESOLUTION VIA SPARSE REPRESENTATION, NNI: NEAREST NEIGHBOR INTERPOLATION.<br />PSNR<br />Bicubic NNI BilinearScSR BP<br />N1 24.58 22.8023.7725.36 25.15<br />N224.8123.5424.18 25.51 25.28<br />N3 18.9718.43 18.6019.3919.38<br />N4 18.1117.78 17.83 18.5018.37<br />N521.1720.60 20.78 21.7221.54<br />N6 22.1221.6821.84 22.4322.41<br />N7 22.6221.62 22.20 23.1323.12<br />N8 22.0020.8221.53 22.5922.47<br />N922.90 22.2722.5923.10 23.16<br />N10 21.3921.04 21.2221.53 21.55<br />N1122.8221.2822.22 23.5123.41<br />N12 24.0923.1023.5324.74 24.66<br />N1321.13 20.4220.77 21.42 21.45<br />N1423.06 22.5022.72 23.31 23.33<br />N15 21.7921.15 21.4522.11 22.16<br />N1622.5221.58 22.0523.00 22.92<br />N1723.70 22.66 23.1924.2524.10<br />N1825.21 24.38 24.7425.4825.62<br />N1920.3319.55 19.8920.79 20.76<br />N20 18.3117.92 18.00 18.5418.67<br />[2] M. Elad and M. Aharon, “Image Denoising Via Sparse and Redundant Representations Over Learned Dictionaries,” IEEE<br />Transactions on Image Processing, vol. 15, pp. 3736–3745, 2006.<br />[3] J. Mairal, F. Bach, J. Ponce, G. Sapiro, and A. Zisserman, “Supervised Dictionary Learning,” Computing Research<br />Repository, vol. abs/0809.3, pp. 1033–1040, 2008.<br />[4] ——, “Nonlocal sparse models for image restoration,” in International Conference on Computer Vision, 2009, pp. 2272–<br />2279.<br />[5] J. Mairal, M. Elad, and G. Sapiro, “Sparse Representation for Color Image Restoration,” IEEE Transactions on Image<br />Processing, vol. 17, pp. 53–69, 2008.<br />[6] J. Mairal, G. Sapiro, and M. Elad, “Learning Multiscale Sparse Representations for Image and Video Restoration,”<br />Multiscale Modeling and Simulation, vol. 7, pp. 214–241, 2008.<br />[7] M. Ranzato, C. S. Poultney, S. Chopra, and Y. Lecun, “Efficient Learning of Sparse Representations with an Energy-Based<br />September 25, 2012DRAFT</p>  <p>Page 29</p> <p>29<br />Model,” in Neural Information Processing Systems, 2006, pp. 1137–1144.<br />[8] J. Wright, A. Y. Yang, A. Ganesh, S. S. Sastry, and Y. Ma, “Robust Face Recognition via Sparse Representation,” IEEE<br />Transactions on Pattern Analysis and Machine Intelligence, vol. 31, pp. 210–227, 2009.<br />[9] A. M. Bruckstein, D. L. Donoho, and M. Elad, “From Sparse Solutions of Systems of Equations to Sparse Modeling of<br />Signals and Images,” Siam Review, vol. 51, pp. 34–81, 2009.<br />[10] E. J. Cand´Rs and T. Tao, “Near-Optimal Signal Recovery From Random Projections: Universal Encoding Strategies?”<br />IEEE Transactions on Information Theory, vol. 52, pp. 5406–5425, 2006.<br />[11] J. Mairal, F. Bach, J. Ponce, and G. Sapiro, “Online dictionary learning for sparse coding,” in International Conference<br />on Machine Learning, 2009, pp. 87–696.<br />[12] R. Raina, A. Battle, H. Lee, B. Packer, and A. Y. Ng, “Self-taught learning: transfer learning from unlabeled data,” in<br />International Conference on Machine Learning, 2007, pp. 759–766.<br />[13] S. Farsiu, M. Robinson, M. Elad, and P. Milanfar, “Fast and robust multiframe super resolution,” Image Processing, IEEE<br />Transactions on, vol. 13, no. 10, pp. 1327–1344, 2004.<br />[14] M. Tipping and C. Bishop, “Bayesian image super-resolution,” NIPS, 2003.<br />[15] W. T. Freeman, T. R. Jones, and E. C. Pasztor, “Example-based super-resolution,” IEEE Computer Graphics and<br />Applications, vol. 22, pp. 56–65, 2002.<br />[16] K. I. Kim and Y. Kwon, “Single-image super-resolution using sparse regression and natural image prior,” IEEE Transactions<br />on Pattern Analysis and Machine Intelligence, vol. 32, pp. 1127–1133, 2010.<br />[17] J. Sun, N. Zheng, H. Tao, and H. Shum, “Image hallucination with primal sketch priors,” CVPR, 2003.<br />[18] Y. HaCohen, R. Fattal, and D. Lischinski, “Image upsampling via texture hallucination,” in IEEE International Conference<br />on Computational Photography, 2010.<br />[19] J. Sun, J. Zhu, and M. F. Tappen, “Context-constrained hallucination for image super-resolution,” in Computer Vision and<br />Pattern Recognition, 2010, pp. 231–238.<br />[20] D. Glasner, S. Bagon, and M. Irani, “Super-resolution from a single image,” in International Conference on Computer<br />Vision, 2009, pp. 349–356.<br />[21] J. Yang, J. Wright, T. Huang, and Y. Ma, “Image super-resolution via sparse representation,” Image Processing, IEEE<br />Transactions on, vol. 19, no. 11, pp. 2861–2873, 2010.<br />[22] B. Chen, G. Polatkan, G. Sapiro, D. Dunson, and L. Carin, “The hierarchical beta process for convolutional factor analysis<br />and deep learning,” in Proceedings of the 28th International Conference on Machine Learning (ICML-11), ser. ICML ’11,<br />June 2011, pp. 361–368.<br />[23] F. Doshi-Velez, K. T. Miller, J. Van Gael, and Y. W. Teh, “Variational inference for the indian buffet process,” in AISTATS,<br />2009.<br />[24] Z. Ghahramani and K. David, “Infinite Sparse Factor Analysis and Infinite Independent Components Analysis,” in<br />Independent Component Analysis, 2007, pp. 381–388.<br />[25] T. L. Griffiths and Z. Ghahramani, “Infinite latent feature models and the indian buffet process,” in NIPS, 2005.<br />[26] J. Paisley and L. Carin, “Nonparametric factor analysis with beta process priors,” in ICML, 2009.<br />[27] R. Thibaux and M. I. Jordan, “Hierarchical beta processes and the indian buffet process,” AISTATS, 2007.<br />[28] M. Zhou, H. Chen, J. Paisley, L. Ren, G. Sapiro, and L. Carin, “Non-parametric bayesian dictionary learning for sparse<br />image representations 1,” NIPS, 2009.<br />September 25, 2012DRAFT</p>  <p>Page 30</p> <p>30<br />[29] M. Zhou, H. Yang, G. Sapiro, D. Dunson, and L. Carin, “Dependent hierarchical beta process for image interpolation and<br />denoising,” Proc. Artificial Intelligence and Statistics (AISTATS), 2011.<br />[30] S. Ghosh, A. B. Ungureanu, E. B. Sudderth, D. M. Blei, and M. Stanley, “Spatial distance dependent chinese restaurant<br />processes for image segmentation,” NIPS, pp. 1–9, 2011.<br />[31] S. Ghosh and E. B. Sudderth, “Nonparametric learning for layered segmentation of natural images,” IEEE Conference on<br />computer vision and Pattern Recognition, 2012.<br />[32] J. J. Kivinen, E. B. Sudderth, and M. I. Jordan, “Learning multiscale representations of natural scenes using dirichlet<br />processes,” IEEE 11th International Conference on Computer Vision, 2007.<br />[33] T. L. Griffiths and Z. Ghahramani, “The indian buffet process: An introduction and review,” JMLR, vol. 12, pp. 1185–1224,<br />2011.<br />[34] C. P. Robert and G. Casella, Monte Carlo statistical methods. Springer New York, 2004.<br />[35] M. Jordan, Z. Ghahramani, T. Jaakkola, and L. Saul, “An introduction to variational methods for graphical models,”<br />Machine learning, 1999.<br />[36] M. Sato, “On-line model selection based on the variational Bayes,” Neural Computation, 2000.<br />[37] M. D. Hoffman, D. M. Blei, and F. Bach, “Online learning for latent dirichlet allocation,” in NIPS, 2010.<br />[38] C. Wang, J. Paisley, and D. Blei, “Online variational inference for the hierarchical dirichlet process,” AISTATS, 2011.<br />[39] C. Bishop, Pattern recognition and machine learning. Springer New York, 2006.<br />[40] Y. Teh, M. Jordan, M. Beal, and D. Blei, “Hierarchical dirichlet processes,” Journal of the American Statistical Association,<br />2006.<br />[41] H. Robbins and S. Monro, “A stochastic approximation method,” The Annals of Mathematical Statistics, vol. 22, no. 3,<br />pp. 400–407, 1951.<br />[42] S. Amari, “Natural gradient works efficiently in learning,” Neural computation, 1998.<br />[43] S. Mallat and G. Yu, “Super-Resolution With Sparse Mixing Estimators,” IEEE Transactions on Image Processing, vol. 19,<br />pp. 2889–2900, 2010.<br />[44] R. Fattal, “Image upsampling via imposed edge statistics,” ACM Transactions on Graphics, vol. 26, 2007.<br />[45] Z. Wang and A. Bovik, “Mean squared error: love it or leave it? a new look at signal fidelity measures,” Signal Processing<br />Magazine, IEEE, vol. 26, no. 1, pp. 98–117, 2009.<br />[46] L. Bottou, “Online learning and stochastic approximations,” 1998.<br />September 25, 2012DRAFT</p>  <a href="https://www.researchgate.net/profile/Mingyuan_Zhou/publication/230996489_A_Bayesian_Nonparametric_Approach_to_Image_Super-Resolution/links/004635320936583c57000000.pdf">Download full-text</a> </div> <div id="rgw26_56ab9f2c79194" class="c-box pub-resource-container js-toggle" style=""> <h4 class="lf js-expand-list"><small><a href="javascript:" class="lf">View other sources <span class="ico-expand-list"></span></a></small></h4> <h4 class="lf js-collapse-list hidden"><small><a href="javascript:" class="lf">Hide other sources <span class="ico-collapse-list"></span></a></small></h4> <div class="clear"></div> <div class="scroll-wrapper hidden"> <ul class="files-list c-list" id="rgw27_56ab9f2c79194">  <li class="c-list-item pub-resource-item"  data-type="fulltext" id="rgw28_56ab9f2c79194"> <span class="ico-pub"></span> <div class="file-content"> <div class="download"> <a href="profile/Mingyuan_Zhou/publication/230996489_A_Bayesian_Nonparametric_Approach_to_Image_Super-Resolution/links/004635320936583c57000000.pdf" class="publication-viewer" title="004635320936583c57000000.pdf">004635320936583c57000000.pdf</a> </div>  <div class="details">  <span> Available from <a href="profile/Mingyuan_Zhou">Mingyuan Zhou</a> &middot; May 31, 2014 </span>   </div>    </div> </li>  <li class="c-list-item pub-resource-item"  data-type="fulltext" id="rgw29_56ab9f2c79194"> <span class="ico-pub"></span> <div class="file-content"> <div class="download"> <a href="http://arxiv.org/pdf/1209.5019" target="_blank" rel="nofollow" class="publication-viewer" title="A Bayesian Nonparametric Approach to Image Super-Resolution">A Bayesian Nonparametric Approach to Image Super-R...</a> </div>  <div class="details">   Available from <a href="http://arxiv.org/pdf/1209.5019" target="_blank" rel="nofollow">arxiv.org</a>  </div>    </div> </li>  </ul> </div> </div> </noscript> <div class="clearfix"> <div class="action-container">  </div> <div class="pub-legal"> Data provided are for informational purposes only. Although carefully collected, accuracy cannot be guaranteed. The impact factor represents a rough estimation of the journal's impact factor and does not reflect the actual current impact factor. Publisher conditions are provided by RoMEO. Differing provisions from the publisher's actual policy or licence agreement may be applicable. </div>   </div> </div> <div class="clearfix">     <div id="rgw31_56ab9f2c79194" class="c-box pub-resource-container js-toggle" style="display: none;"> <h4 class="lf js-expand-list"><small><a href="javascript:" class="lf">View other sources <span class="ico-expand-list"></span></a></small></h4> <h4 class="lf js-collapse-list hidden"><small><a href="javascript:" class="lf">Hide other sources <span class="ico-collapse-list"></span></a></small></h4> <div class="clear"></div> <div class="scroll-wrapper hidden"> <ul class="files-list c-list" id="rgw32_56ab9f2c79194">  </ul> </div> </div>   <div id="rgw22_56ab9f2c79194" class="similar-publications"> <h2>Similar Publications</h2> <ul class="list-bordered">  <li class="c-list-item li-publication-teaser" id="rgw23_56ab9f2c79194"> <div> <h5> <a href="publication/241835178_Modeling_Endogenous_Treatment_Eects_with_Heterogeneity_A_Bayesian_Nonparametric_Approach" class="color-inherit ga-similar-publication-title"><span class="publication-title">Modeling Endogenous Treatment Eects with Heterogeneity: A Bayesian Nonparametric Approach</span></a>  </h5>  <div class="authors"> <a href="researcher/2014615436_Xuequn_Hu" class="authors ga-similar-publication-author">Xuequn Hu</a>  </div>  </div> <div class="clear"></div> </li>  <li class="c-list-item li-publication-teaser" id="rgw24_56ab9f2c79194"> <div> <h5> <a href="publication/269417283_Model-based_Path_Integral_Stochastic_Control_A_Bayesian_Nonparametric_Approach" class="color-inherit ga-similar-publication-title"><span class="publication-title">Model-based Path Integral Stochastic Control: A Bayesian Nonparametric Approach</span></a>  </h5>  <div class="authors"> <a href="researcher/70219070_Yunpeng_Pan" class="authors ga-similar-publication-author">Yunpeng Pan</a>, <a href="researcher/70659357_Evangelos_A_Theodorou" class="authors ga-similar-publication-author">Evangelos A. Theodorou</a>, <a href="researcher/34869527_Michail_Kontitsis" class="authors ga-similar-publication-author">Michail Kontitsis</a>  </div>  </div> <div class="clear"></div> </li>  <li class="c-list-item li-publication-teaser" id="rgw25_56ab9f2c79194"> <div> <h5> <a href="publication/38358679_A_Bayesian_Nonparametric_Approach_to_Reliability" class="color-inherit ga-similar-publication-title"><span class="publication-title">A Bayesian Nonparametric Approach to Reliability</span></a>  </h5>  <div class="authors"> <a href="researcher/26838447_R_L_Dykstra" class="authors ga-similar-publication-author">R. L. Dykstra</a>, <a href="researcher/2038897193_Purushottam_Laud" class="authors ga-similar-publication-author">Purushottam Laud</a>  </div>  </div> <div class="clear"></div> </li>  </ul> </div> </div> </div> </div> </div></div></div>
<div class="clear"></div><div id="rgw45_56ab9f2c79194" class="default-footer"> <div id="footer" class="clearfix"> <span class="footer-left"> &copy; 2008&dash;2016 researchgate.net. All rights reserved. </span> <span class="footer-right"> <a href="https://www.researchgate.net/about">About us</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="https://www.researchgate.net/contact">Contact us</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="careers">Careers</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="developers">Developers</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="blog" target="_blank">News</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="application.PrivacyPolicy.html">Privacy</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="application.TermsAndConditions.html">Terms</a> <span class="footer-link-separator" style="padding: 0 5px;">&nbsp;|&nbsp;</span> <a href="advertising?_ref=ft">Advertising</a> <span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="recruiters?_ref=ft">Recruiting</a> </span> </div>  </div></div>
<div id="rgw46_56ab9f2c79194">  <div class="header-wrapper-logged-out"> <div id="header"> <div class="header-content"> <a href="" class="g-l-logo"> <svg width="149" height="19"> <image xlink:href="https://c5.rgstatic.net/m/235107188705592/images/template/brand-header-logo.svg" src="https://c5.rgstatic.net/m/238113351022438/images/template/brand-header-logo.png" width="149" height="19"/> </svg> </a> <a href="" class="g-l-logo-ico"> <svg width="127" height="17" viewbox="0 0 127 22"> <image xlink:href="https://c5.rgstatic.net/m/235107188705592/images/template/brand-header-logo.svg" src="https://c5.rgstatic.net/m/238113351022438/images/template/brand-header-logo.png" width="127" height="17"/> </svg> </a> <div id="rgw47_56ab9f2c79194" class="header-login-wrapper js-header-login"> <div class="dropdown-right-align"> <div class="login-signup-container lf"> <a href="https://www.researchgate.net/signup.SignUp.html?ev=su_chnl_index&amp;hdrsu=1&amp;_sg=N0niNpS6e-F-qdGCcL-LqPFIEFVAAcAsax4KCtv3Grap67HAW7vcW_B4OYltFzP6" class="dropdown-toggle lf">Join for free</a> </div> <div class="dropdown lf" style="height: 20px;"> <a href="https://www.researchgate.net/application.Login.html" class="js-login-url dropdown-toggle lf">Log in <span class="caret"></span></a> <div class="dropdown-menu"> <div class="header-login-form-wrapper"> <!--[if IE 6]><p class="box-warning" style="margin-bottom: 0;">Sorry, ResearchGate no longer supports the version of Internet Explorer you are using. <a href="http://whatbrowser.org/" rel="nofollow" target="_blank">Update your web browser</a> and then log in. </p><![endif]--> <form method="post" action="https://www.researchgate.net/application.Login.html" class="form-big header-login-form js-login-form" name="loginForm" id="headerLoginForm"> <input type="hidden" name="request_token" value="XNDKWbI90WSjWCSkczujALMoubE70A/7ORH2xmO53QISrANAiAcuwdgrciEiLpwnzIJsez5Ie3ZdSMBuKLXtor8uy6s//v+bJ0dzVV68CV3Ponw9oBHKvqVJL5uzqxIfpeQIBQpytLp9xf8F2Xtf6Il9lkRpnFg1vKB0A5xL1+7SeWsAfd2kWtA88RBqIHRde/HJc4TZFvJp/mRLP7UYWUxpSa8gNEyE67v5lEx328y29BnwPpJuuMOzNRPCeAKlcr9VPvgSxhT4/bOKN4ryhUmacJPj6hqDTPICJFdN7i0="/> <input type="hidden" name="urlAfterLogin" value="publication/230996489_A_Bayesian_Nonparametric_Approach_to_Image_Super-Resolution"/> <input type="hidden" name="invalidPasswordCount" value="0"/> <input type="hidden" name="headerLogin" value="yes"/> <label for="input-header-login">Email</label> <div class="login-input"> <div class="info-tip-wrapper"> <span class="ico-info js-info"></span> </div> <input type="email" value="" name="login" class="login js-login-input text" id="input-header-login" tabindex="1"/> </div> <div class="clear"></div> <label class="lf" for="input-header-password"> Password </label> <a class="rf forgot-password js-forgot-password" href="application.LostPassword.html">Forgot password?</a> <div class="clear"></div> <input type="password" value="" name="password" class="password js-password-input text" id="input-header-password" tabindex="2"/> <div class="clear"></div> <label class="remember-me" for="headerLoginCookie"> <input type="checkbox" checked="checked" value="yes" name="setLoginCookie" class="lf checkbox" id="headerLoginCookie" tabindex="3"/> Keep me logged in </label> <div class="clear"></div> <input value="Log in" name="loginSubmit" class="btn btn-promote btn-fullwidth btn-large allow-leave js-submit-button" type="submit" tabindex="4"/> </form> <div class="connectors"> <div class="text">or log in with</div> <div class="connector-actions"> <a href="connector/linkedin/" class="li-connect js-li-connect" data-redirect-url="cHVibGljYXRpb24vMjMwOTk2NDg5X0FfQmF5ZXNpYW5fTm9ucGFyYW1ldHJpY19BcHByb2FjaF90b19JbWFnZV9TdXBlci1SZXNvbHV0aW9u"> <span class="icon ico-linkedin-round-grey"></span> <span class="icon ico-linkedin-round"></span> </a> <a href="connector/facebook/" class="fb-connect middle js-fb-connect" data-redirect-url="cHVibGljYXRpb24vMjMwOTk2NDg5X0FfQmF5ZXNpYW5fTm9ucGFyYW1ldHJpY19BcHByb2FjaF90b19JbWFnZV9TdXBlci1SZXNvbHV0aW9u"> <span class="icon ico-facebook-round-grey"></span> <span class="icon ico-facebook-round"></span> </a> <a href="connector/google/" class="g-connect js-g-connect" data-redirect-url="cHVibGljYXRpb24vMjMwOTk2NDg5X0FfQmF5ZXNpYW5fTm9ucGFyYW1ldHJpY19BcHByb2FjaF90b19JbWFnZV9TdXBlci1SZXNvbHV0aW9u"> <span class="icon ico-google-round-grey"></span> <span class="icon ico-google-round"></span> </a> </div> </div> </div> </div> </div> </div> </div> </div> </div> <script type="application/ld+json">
{ "@context" : "http://schema.org",
  "@type" : "Organization",
  "name" : "ResearchGate",
  "url" : "http://www.researchgate.net",
  "logo" : "http://www.researchgate.net/images/template/rg_logo_square_brand.png",
  "sameAs" : [ "https://www.facebook.com/ResearchGate",
    "https://twitter.com/ResearchGate",
    "https://plus.google.com/+researchgate",
    "https://www.linkedin.com/company/researchgate"] 
}
</script> </div> </div><div class="c-signup-bar" id="rgw48_56ab9f2c79194"> <div class="banner-contents">   <span class="message">ResearchGate is the professional network for scientists and researchers.</span> <a href="signup.SignUp.html?ev=su_banner" class="btn btn-large btn-promote">Join for free</a>  </div> </div></div>
<script>
rgConfig.backendTime = 757;
</script>
<script src="//c5.rgstatic.net/m/2277196935388619/javascript/lib/yui3/yui/yui-min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/21832295316281274/javascript/yuiLoaderConfig-min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/23178613132105398/javascript/vendor/babel-core/browser-polyfill.min.js" type="text/javascript"></script>
<script>
(function (){
if (typeof YRG === "undefined") {
var xmlHttpRequest = new XMLHttpRequest();
xmlHttpRequest.open("post", "go.Error.html");
xmlHttpRequest.setRequestHeader("Content-Type", "application/json");
xmlHttpRequest.setRequestHeader("Accept", "application/json"); var loadedScripts = "";
if (window.performance && window.performance.getEntriesByType) {
    var result = [];
    var resources = performance.getEntriesByType("resource");
    for (var i in resources) {
        if (resources.hasOwnProperty(i)) {
            result.push({
                name: resources[i].name,
                duration: resources[i].duration
            });
        }
    }
    loadedScripts += "&loadedScripts=" + encodeURIComponent(JSON.stringify(result));
}
if (typeof YUI === "undefined") {
    loadedScripts += "&yuiLoaded=false";
} else {
    loadedScripts += "&yuiLoaded=true";
}
xmlHttpRequest.send("Type=InformationException&message=" + encodeURIComponent("Error loading YUI") + loadedScripts);
}
})();
</script>
<script>if (typeof YRG !== 'undefined') { YRG.use('rg-base',function(Y){Y.applyConfig({ignore: ["css-rg","css-rg2","css-ie","css-modules-publicprofile","css-pow-publicliterature-FigureList","css-pow-publicliterature-FollowPublicationPromo","css-pow-application-PdfJsReader","css-pow-publicliterature-PublicationInlineReader"]});Y.use(["rg.core.pagespeed.Monitoring"],function(Y){(function(){Y.rg.createInitialWidget({"data":{"content":{"data":{"profileSmallHeader":{"data":{"profileBadge":{"data":{"fullname":"Gungor Polatkan","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2671872220764\/images\/template\/default\/profile\/profile_default_m.jpg","profileStats":[],"profileFollowButton":null,"profileReputationScoreNumber":null,"profileUrl":"profile\/Gungor_Polatkan","institution":"Princeton University","institutionUrl":false,"widgetId":"rgw4_56ab9f2c79194"},"id":"rgw4_56ab9f2c79194","partials":[],"templateName":"publicprofile\/stubs\/ProfileBadge.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicprofile.ProfileBadge.html?accountId=1908173","viewClass":null,"yuiModules":["css-modules-publicprofile"],"stylesheets":["modules\/publicprofile.css"],"_isYUI":true},"widgetId":"rgw3_56ab9f2c79194"},"id":"rgw3_56ab9f2c79194","partials":[],"templateName":"publicprofile\/stubs\/ProfileSmallHeader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicprofile.ProfileSmallHeader.html?publicationUid=230996489","viewClass":null,"yuiModules":["css-modules-publicprofile"],"stylesheets":["modules\/publicprofile.css"],"_isYUI":true},"publication":{"data":{"publicationUid":230996489,"title":"A Bayesian Nonparametric Approach to Image Super-Resolution","journalTitle":"IEEE Transactions on Pattern Analysis and Machine Intelligence","journalDetailsTooltip":{"data":{"journalTitle":"IEEE Transactions on Pattern Analysis and Machine Intelligence","journalAbbrev":"IEEE T PATTERN ANAL","publisher":"IEEE Computer Society; Institute of Electrical and Electronics Engineers, Institute of Electrical and Electronics Engineers","issn":"0162-8828","impactFactor":"5.78","fiveYearImpactFactor":"7.76","citedHalfLife":">10.0","immediacyIndex":"0.71","eigenFactor":"0.05","articleInfluence":"3.31","widgetId":"rgw6_56ab9f2c79194"},"id":"rgw6_56ab9f2c79194","partials":[],"templateName":"publicliterature\/stubs\/JournalInfo.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.JournalInfo.html?issn=0162-8828","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"affiliation":false,"type":"Article","details":{"doi":"10.1109\/TPAMI.2014.2321404","journalInfos":{"journal":"","publicationDate":"09\/2012;","publicationDateRobot":"2012-09","article":"37(2).","journalTitle":"IEEE Transactions on Pattern Analysis and Machine Intelligence","journalUrl":"journal\/0162-8828_IEEE_Transactions_on_Pattern_Analysis_and_Machine_Intelligence","impactFactor":5.78}},"source":{"sourceUrl":"http:\/\/arxiv.org\/abs\/1209.5019","sourceName":"arXiv"},"publicationActions":null,"publicationCoins":{"data":{"tags":[{"key":"ctx_ver","value":"Z39.88-2004"},{"key":"rft_val_fmt","value":"info:ofi\/fmt:kev:mtx:journal"},{"key":"rfr_id","value":"info:sid\/researchgate.net:researchgate"},{"key":"rft_id","value":"info:doi\/10.1109\/TPAMI.2014.2321404"},{"key":"rft.atitle","value":"A Bayesian Nonparametric Approach to Image Super-Resolution"},{"key":"rft.title","value":"IEEE Transactions on Pattern Analysis and Machine Intelligence"},{"key":"rft.jtitle","value":"IEEE Transactions on Pattern Analysis and Machine Intelligence"},{"key":"rft.volume","value":"37"},{"key":"rft.issue","value":"2"},{"key":"rft.date","value":"2012"},{"key":"rft.issn","value":"0162-8828"},{"key":"rft.au","value":"Gungor Polatkan,Mingyuan Zhou,Lawrence Carin,David Blei,Ingrid Daubechies"},{"key":"rft.genre","value":"article"}],"widgetId":"rgw7_56ab9f2c79194"},"id":"rgw7_56ab9f2c79194","partials":[],"templateName":"publicliterature\/stubs\/PublicationCoins.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationCoins.html?publicationUid=230996489","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationAuthors":{"data":{"publicationUid":230996489,"peopleItems":[{"data":{"authorNameOnPublication":"Gungor Polatkan","accountUrl":"profile\/Gungor_Polatkan","accountKey":"Gungor_Polatkan","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2671872220764\/images\/template\/default\/profile\/profile_default_m.jpg","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Gungor Polatkan","profile":{"professionalInstitution":{"professionalInstitutionName":"Princeton University","professionalInstitutionUrl":"institution\/Princeton_University"}},"professionalInstitutionName":"Princeton University","professionalInstitutionUrl":"institution\/Princeton_University","url":"profile\/Gungor_Polatkan","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":false,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":true,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"accountKey":"Gungor_Polatkan","hasInfoPopup":false,"hasTeaserPopup":true,"showContactAuthorButton":true,"widgetId":"rgw10_56ab9f2c79194"},"id":"rgw10_56ab9f2c79194","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAccountItem.html?entityId=1908173&enableUnfollow=0&imageSize=l&enableFollowButton=0&showContactAuthorButton=1","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"accountInstitution":"Princeton University","score":null,"largeTooltip":false,"useRebrandedImageStyle":null,"authorCount":5,"accountCount":2,"publicationUid":230996489,"widgetId":"rgw9_56ab9f2c79194"},"id":"rgw9_56ab9f2c79194","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAccountItem.html","templateExtensions":[],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAccountItem.html?accountId=1908173&context=pubdetail_authors_xflw&showContactAuthorButton=1&authorCount=5&accountCount=2&publicationUid=230996489","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true},{"data":{"authorNameOnPublication":"Mingyuan Zhou","accountUrl":"profile\/Mingyuan_Zhou","accountKey":"Mingyuan_Zhou","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2671872220764\/images\/template\/default\/profile\/profile_default_m.jpg","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Mingyuan Zhou","profile":{"professionalInstitution":{"professionalInstitutionName":"Duke University","professionalInstitutionUrl":"institution\/Duke_University"}},"professionalInstitutionName":"Duke University","professionalInstitutionUrl":"institution\/Duke_University","url":"profile\/Mingyuan_Zhou","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":false,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":true,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"accountKey":"Mingyuan_Zhou","hasInfoPopup":false,"hasTeaserPopup":true,"showContactAuthorButton":true,"widgetId":"rgw12_56ab9f2c79194"},"id":"rgw12_56ab9f2c79194","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAccountItem.html?entityId=1820977&enableUnfollow=0&imageSize=l&enableFollowButton=0&showContactAuthorButton=1","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"accountInstitution":"Duke University","score":null,"largeTooltip":false,"useRebrandedImageStyle":null,"authorCount":5,"accountCount":2,"publicationUid":230996489,"widgetId":"rgw11_56ab9f2c79194"},"id":"rgw11_56ab9f2c79194","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAccountItem.html","templateExtensions":[],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAccountItem.html?accountId=1820977&context=pubdetail_authors_xflw&showContactAuthorButton=1&authorCount=5&accountCount=2&publicationUid=230996489","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true},{"data":{"authorUrl":"researcher\/10135830_Lawrence_Carin","authorNameOnPublication":"Lawrence Carin","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg","imageSize":"s","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Lawrence Carin","profile":{"professionalInstitution":{"professionalInstitutionName":false,"professionalInstitutionUrl":null}},"professionalInstitutionName":false,"professionalInstitutionUrl":null,"url":"researcher\/10135830_Lawrence_Carin","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":true,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":false,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"widgetId":"rgw14_56ab9f2c79194"},"id":"rgw14_56ab9f2c79194","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAuthorItem.html?entityId=10135830&imageSize=l&enableAuthorInviteButton=0","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"largeTooltip":false,"useRebrandedImageStyle":null,"widgetId":"rgw13_56ab9f2c79194"},"id":"rgw13_56ab9f2c79194","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorItem.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorItem.html?authorUid=10135830&authorNameOnPublication=Lawrence%20Carin","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true},{"data":{"authorUrl":"researcher\/2064238818_David_Blei","authorNameOnPublication":"David Blei","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg","imageSize":"s","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"David Blei","profile":{"professionalInstitution":{"professionalInstitutionName":false,"professionalInstitutionUrl":null}},"professionalInstitutionName":false,"professionalInstitutionUrl":null,"url":"researcher\/2064238818_David_Blei","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":true,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":false,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"widgetId":"rgw16_56ab9f2c79194"},"id":"rgw16_56ab9f2c79194","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAuthorItem.html?entityId=2064238818&imageSize=l&enableAuthorInviteButton=0","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"largeTooltip":false,"useRebrandedImageStyle":null,"widgetId":"rgw15_56ab9f2c79194"},"id":"rgw15_56ab9f2c79194","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorItem.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorItem.html?authorUid=2064238818&authorNameOnPublication=David%20Blei","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true},{"data":{"authorUrl":"researcher\/7792029_Ingrid_Daubechies","authorNameOnPublication":"Ingrid Daubechies","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg","imageSize":"s","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Ingrid Daubechies","profile":{"professionalInstitution":{"professionalInstitutionName":false,"professionalInstitutionUrl":null}},"professionalInstitutionName":false,"professionalInstitutionUrl":null,"url":"researcher\/7792029_Ingrid_Daubechies","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":true,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":false,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"widgetId":"rgw18_56ab9f2c79194"},"id":"rgw18_56ab9f2c79194","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAuthorItem.html?entityId=7792029&imageSize=l&enableAuthorInviteButton=0","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"largeTooltip":false,"useRebrandedImageStyle":null,"widgetId":"rgw17_56ab9f2c79194"},"id":"rgw17_56ab9f2c79194","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorItem.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorItem.html?authorUid=7792029&authorNameOnPublication=Ingrid%20Daubechies","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true}],"hasMore":false,"nextOffset":6,"useRebrandedImageStyle":null,"widgetId":"rgw8_56ab9f2c79194"},"id":"rgw8_56ab9f2c79194","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorList.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorList.html?publicationUid=230996489&context=pubdetail_authors_xflw&showContactAuthorButton=1","viewClass":"views.publicliterature.PublicationDetailAuthorListView","yuiModules":["rg.views.publicliterature.PublicationDetailAuthorListView"],"stylesheets":[],"_isYUI":true},"publicationAbstract":{"data":{"publicationUid":230996489,"abstract":"<noscript><\/noscript><div>Super-resolution methods form high-resolution images from low-resolution<br \/>\nimages. In this paper, we develop a new Bayesian nonparametric model for<br \/>\nsuper-resolution. Our method uses a beta-Bernoulli process to learn a set of<br \/>\nrecurring visual patterns, called dictionary elements, from the data. Because<br \/>\nit is nonparametric, the number of elements found is also determined from the<br \/>\ndata. We test the results on both benchmark and natural images, comparing with<br \/>\nseveral other models from the research literature. We perform large-scale human<br \/>\nevaluation experiments to assess the visual quality of the results. In a first<br \/>\nimplementation, we use Gibbs sampling to approximate the posterior. However,<br \/>\nthis algorithm is not feasible for large-scale data. To circumvent this, we<br \/>\nthen develop an online variational Bayes (VB) algorithm. This algorithm finds<br \/>\nhigh quality dictionaries in a fraction of the time needed by the Gibbs<br \/>\nsampler.<\/div>","canEdit":false,"isAdmin":false,"isArtifact":false,"showFullAbstract":true,"widgetId":"rgw19_56ab9f2c79194"},"id":"rgw19_56ab9f2c79194","partials":[],"templateName":"publicliterature\/stubs\/PublicationAbstract.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationAbstract.html?publicationUid=230996489","viewClass":"views.publicliterature.PublicationAbstractView","yuiModules":["rg.views.publicliterature.PublicationAbstractView"],"stylesheets":[],"_isYUI":true},"publicationKeywords":null,"publicationState":null,"isGuest":true,"isAdminEditingAllowed":false,"isArtifact":false,"figureListWidget":{"data":{"figures":[{"imageUrl":"https:\/\/www.researchgate.net\/profile\/Mingyuan_Zhou\/publication\/230996489\/figure\/fig1\/Fig-1.png","previewImageUrl":"https:\/\/www.researchgate.net\/profile\/Mingyuan_Zhou\/publication\/230996489\/figure\/fig1\/Fig-1_small.png","figureUrl":"\/figure\/230996489_fig1_Fig-1","selected":false,"title":"Fig. 1.\u00a0","key":"230996489_fig1_Fig-1"},{"imageUrl":"https:\/\/www.researchgate.net\/profile\/Mingyuan_Zhou\/publication\/230996489\/figure\/fig2\/Fig-2.png","previewImageUrl":"https:\/\/www.researchgate.net\/profile\/Mingyuan_Zhou\/publication\/230996489\/figure\/fig2\/Fig-2_small.png","figureUrl":"\/figure\/230996489_fig2_Fig-2","selected":false,"title":"Fig. 2.\u00a0","key":"230996489_fig2_Fig-2"},{"imageUrl":"https:\/\/www.researchgate.net\/profile\/Mingyuan_Zhou\/publication\/230996489\/figure\/fig3\/Fig-3-Dictionary-trained-in-batch-mode-on-lluminance-channel-with-SR-ratio-2-Left.png","previewImageUrl":"https:\/\/www.researchgate.net\/profile\/Mingyuan_Zhou\/publication\/230996489\/figure\/fig3\/Fig-3-Dictionary-trained-in-batch-mode-on-lluminance-channel-with-SR-ratio-2-Left_small.png","figureUrl":"\/figure\/230996489_fig3_Fig-3-Dictionary-trained-in-batch-mode-on-lluminance-channel-with-SR-ratio-2-Left","selected":false,"title":"Fig. 3. Dictionary trained in batch mode on lluminance channel with SR...","key":"230996489_fig3_Fig-3-Dictionary-trained-in-batch-mode-on-lluminance-channel-with-SR-ratio-2-Left"},{"imageUrl":"https:\/\/www.researchgate.net\/profile\/Mingyuan_Zhou\/publication\/230996489\/figure\/fig4\/Fig-4.png","previewImageUrl":"https:\/\/www.researchgate.net\/profile\/Mingyuan_Zhou\/publication\/230996489\/figure\/fig4\/Fig-4_small.png","figureUrl":"\/figure\/230996489_fig4_Fig-4","selected":false,"title":"Fig. 4.\u00a0","key":"230996489_fig4_Fig-4"},{"imageUrl":"https:\/\/www.researchgate.net\/profile\/Mingyuan_Zhou\/publication\/230996489\/figure\/fig5\/Fig-6-Reconstruction-of-Parthenon-Image-BP-Algorithm-presented-in-this-work-trained.png","previewImageUrl":"https:\/\/www.researchgate.net\/profile\/Mingyuan_Zhou\/publication\/230996489\/figure\/fig5\/Fig-6-Reconstruction-of-Parthenon-Image-BP-Algorithm-presented-in-this-work-trained_small.png","figureUrl":"\/figure\/230996489_fig5_Fig-6-Reconstruction-of-Parthenon-Image-BP-Algorithm-presented-in-this-work-trained","selected":false,"title":"Fig. 6. Reconstruction of Parthenon Image . BP : Algorithm presented in...","key":"230996489_fig5_Fig-6-Reconstruction-of-Parthenon-Image-BP-Algorithm-presented-in-this-work-trained"}],"readerDocId":"6280195","linkBehaviour":"dialog","isDialog":true,"headerText":"Figures in this publication","isNewPublicationDesign":false,"widgetId":"rgw20_56ab9f2c79194"},"id":"rgw20_56ab9f2c79194","partials":[],"templateName":"publicliterature\/stubs\/FigureList.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.FigureList.html?readerDocId=6280195&isDialog=1&linkBehaviour=dialog","viewClass":"views.publicliterature.FigureListView","yuiModules":["rg.views.publicliterature.FigureListView","css-pow-publicliterature-FigureList"],"stylesheets":["pow\/publicliterature\/FigureList.css"],"_isYUI":true},"previewImage":"https:\/\/i1.rgstatic.net\/publication\/230996489_A_Bayesian_Nonparametric_Approach_to_Image_Super-Resolution\/links\/004635320936583c57000000\/smallpreview.png","nativeAdDisclosure":null,"showFollowPublicationButton":false,"followPublicationPromo":{"data":{"widgetId":"rgw21_56ab9f2c79194"},"id":"rgw21_56ab9f2c79194","partials":[],"templateName":"publicliterature\/stubs\/FollowPublicationPromo.html","templateExtensions":[],"attrs":{"context":null,"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.FollowPublicationPromo.html","viewClass":null,"yuiModules":["css-pow-publicliterature-FollowPublicationPromo"],"stylesheets":["pow\/publicliterature\/FollowPublicationPromo.css"],"_isYUI":true},"widgetId":"rgw5_56ab9f2c79194"},"id":"rgw5_56ab9f2c79194","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailItem.html","templateExtensions":["generalHelpers"],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailItem.html?publicationUid=230996489&showActionBar=0&showContactAuthorButton=1&showRequestFulltextExperience=0&showNoRgAuthorsRequestFulltextExperience=0&showFollowPublicationPromo=1","viewClass":"views.publicliterature.PublicationDetailItemView","yuiModules":["rg.views.publicliterature.PublicationDetailItemView"],"stylesheets":[],"_isYUI":true},"similarPublications":{"data":{"publicationListItems":[{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":2014615436,"url":"researcher\/2014615436_Xuequn_Hu","fullname":"Xuequn Hu","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"","journal":null,"showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/241835178_Modeling_Endogenous_Treatment_Eects_with_Heterogeneity_A_Bayesian_Nonparametric_Approach","usePlainButton":true,"publicationUid":241835178,"feedStubs":null,"hasFeedStubs":false,"impactPoints":false,"url":"publication\/241835178_Modeling_Endogenous_Treatment_Eects_with_Heterogeneity_A_Bayesian_Nonparametric_Approach","title":"Modeling Endogenous Treatment Eects with Heterogeneity: A Bayesian Nonparametric Approach","displayTitleAsLink":true,"authors":[{"id":2014615436,"url":"researcher\/2014615436_Xuequn_Hu","fullname":"Xuequn Hu","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":[],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/241835178_Modeling_Endogenous_Treatment_Eects_with_Heterogeneity_A_Bayesian_Nonparametric_Approach","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/241835178_Modeling_Endogenous_Treatment_Eects_with_Heterogeneity_A_Bayesian_Nonparametric_Approach\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw23_56ab9f2c79194"},"id":"rgw23_56ab9f2c79194","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=241835178","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":70219070,"url":"researcher\/70219070_Yunpeng_Pan","fullname":"Yunpeng Pan","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":70659357,"url":"researcher\/70659357_Evangelos_A_Theodorou","fullname":"Evangelos A. Theodorou","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":34869527,"url":"researcher\/34869527_Michail_Kontitsis","fullname":"Michail Kontitsis","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Dec 2014","journal":null,"showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/269417283_Model-based_Path_Integral_Stochastic_Control_A_Bayesian_Nonparametric_Approach","usePlainButton":true,"publicationUid":269417283,"feedStubs":null,"hasFeedStubs":false,"impactPoints":false,"url":"publication\/269417283_Model-based_Path_Integral_Stochastic_Control_A_Bayesian_Nonparametric_Approach","title":"Model-based Path Integral Stochastic Control: A Bayesian Nonparametric Approach","displayTitleAsLink":true,"authors":[{"id":70219070,"url":"researcher\/70219070_Yunpeng_Pan","fullname":"Yunpeng Pan","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":70659357,"url":"researcher\/70659357_Evangelos_A_Theodorou","fullname":"Evangelos A. Theodorou","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":34869527,"url":"researcher\/34869527_Michail_Kontitsis","fullname":"Michail Kontitsis","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":[],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/269417283_Model-based_Path_Integral_Stochastic_Control_A_Bayesian_Nonparametric_Approach","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/269417283_Model-based_Path_Integral_Stochastic_Control_A_Bayesian_Nonparametric_Approach\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw24_56ab9f2c79194"},"id":"rgw24_56ab9f2c79194","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=269417283","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":26838447,"url":"researcher\/26838447_R_L_Dykstra","fullname":"R. L. Dykstra","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2038897193,"url":"researcher\/2038897193_Purushottam_Laud","fullname":"Purushottam Laud","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Mar 1981","journal":"The Annals of Statistics","showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/38358679_A_Bayesian_Nonparametric_Approach_to_Reliability","usePlainButton":true,"publicationUid":38358679,"feedStubs":null,"hasFeedStubs":false,"impactPoints":"2.18","url":"publication\/38358679_A_Bayesian_Nonparametric_Approach_to_Reliability","title":"A Bayesian Nonparametric Approach to Reliability","displayTitleAsLink":true,"authors":[{"id":26838447,"url":"researcher\/26838447_R_L_Dykstra","fullname":"R. L. Dykstra","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2038897193,"url":"researcher\/2038897193_Purushottam_Laud","fullname":"Purushottam Laud","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["The Annals of Statistics 03\/1981; 9(2). DOI:10.1214\/aos\/1176345401"],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/38358679_A_Bayesian_Nonparametric_Approach_to_Reliability","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/38358679_A_Bayesian_Nonparametric_Approach_to_Reliability\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw25_56ab9f2c79194"},"id":"rgw25_56ab9f2c79194","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=38358679","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"viewClass":"sidebar","widgetId":"rgw22_56ab9f2c79194"},"id":"rgw22_56ab9f2c79194","partials":[],"templateName":"publicliterature\/stubs\/SimilarPublications.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.SimilarPublications.html?referencePublicationId=230996489&view=sidebar","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationFulltextPreview":null,"publicationResourcesFulltext":{"data":{"publicationUid":230996489,"publicationResourceList":{"data":{"publicationResourceItems":[{"data":{"publicationUid":230996489,"publicationType":"article","linkId":"004635320936583c57000000","fileName":"004635320936583c57000000.pdf","fileUrl":"profile\/Mingyuan_Zhou\/publication\/230996489_A_Bayesian_Nonparametric_Approach_to_Image_Super-Resolution\/links\/004635320936583c57000000.pdf","name":"Mingyuan Zhou","nameUrl":"profile\/Mingyuan_Zhou","canRemove":false,"fileIcon":"ico-pub","canPreview":true,"hasPublisherLink":null,"hasMetaData":true,"hide":false,"fulltext":"ico-pub","origin":"publication_list","isLastLink":false,"isUserLink":true,"uploadDate":"May 31, 2014","fileSize":"3.46 MB","widgetId":"rgw28_56ab9f2c79194"},"id":"rgw28_56ab9f2c79194","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceItem.html","templateExtensions":["generalHelpers"],"attrs":{"fileRequiredPublicationTypes":["code","coverPage","experimentFindings","method","negativeResults","presentation","rawData","researchProposal","workingPaper","artifact","dataset"]},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceItem.html?publicationUid=230996489&linkId=004635320936583c57000000&hide=0&disableJavascript=disableJavascript&useAlternativeTemplate=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"publicationUid":230996489,"publicationType":"article","linkId":"02b1a1630cf2b0632955d098","fileName":"A Bayesian Nonparametric Approach to Image Super-Resolution","fileUrl":"http:\/\/arxiv.org\/pdf\/1209.5019","name":"arxiv.org","nameUrl":"http:\/\/arxiv.org\/pdf\/1209.5019","canRemove":false,"fileIcon":"ico-pub","canPreview":true,"hasPublisherLink":null,"hasMetaData":true,"hide":false,"fulltext":"ico-pub","origin":"publication_list","isLastLink":false,"isUserLink":false,"widgetId":"rgw29_56ab9f2c79194"},"id":"rgw29_56ab9f2c79194","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceItem.html","templateExtensions":["generalHelpers"],"attrs":{"fileRequiredPublicationTypes":["code","coverPage","experimentFindings","method","negativeResults","presentation","rawData","researchProposal","workingPaper","artifact","dataset"]},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceItem.html?publicationUid=230996489&linkId=02b1a1630cf2b0632955d098&hide=0&disableJavascript=disableJavascript&useAlternativeTemplate=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"widgetId":"rgw27_56ab9f2c79194"},"id":"rgw27_56ab9f2c79194","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceList.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceList.html?publicationUid=230996489&limit=3&disableJavascript=disableJavascript&type=fulltextFile","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"resourceCount":2,"hidden":false,"showMore":false,"fulltext":true,"publicationDownloadCount":{"data":{"value":108,"valueFormatted":"108","widgetId":"rgw30_56ab9f2c79194"},"id":"rgw30_56ab9f2c79194","partials":[],"templateName":"publicliterature\/stubs\/PublicationDownloadCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDownloadCount.html?publicationUid=230996489","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw26_56ab9f2c79194"},"id":"rgw26_56ab9f2c79194","partials":[],"templateName":"publicliterature\/stubs\/PublicationResources.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResources.html?publicationUid=230996489&type=fulltextFile&disableJavascript=1","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationResourcesAttachments":{"data":{"publicationUid":230996489,"publicationResourceList":{"data":{"publicationResourceItems":[],"widgetId":"rgw32_56ab9f2c79194"},"id":"rgw32_56ab9f2c79194","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceList.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceList.html?publicationUid=230996489&limit=3&disableJavascript=disableJavascript&type=attachmentFile","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"resourceCount":0,"hidden":true,"showMore":false,"fulltext":false,"publicationDownloadCount":{"data":{"value":108,"valueFormatted":"108","widgetId":"rgw33_56ab9f2c79194"},"id":"rgw33_56ab9f2c79194","partials":[],"templateName":"publicliterature\/stubs\/PublicationDownloadCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDownloadCount.html?publicationUid=230996489","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw31_56ab9f2c79194"},"id":"rgw31_56ab9f2c79194","partials":[],"templateName":"publicliterature\/stubs\/PublicationResources.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResources.html?publicationUid=230996489&type=attachmentFile","viewClass":"views.publicliterature.PublicationResourcesView","yuiModules":["rg.views.publicliterature.PublicationResourcesView"],"stylesheets":[],"_isYUI":true},"publicationText":{"data":{"hide":false,"pages":[{"page":1,"text":"1\nA Bayesian Nonparametric Approach to Image\nSuper-resolution\nGungor Polatkan1, Mingyuan Zhou2, Lawrence Carin2, David Blei3, and Ingrid\nDaubechies4\n1Department of Electrical Engineering\n3Department of Computer Science\nPrinceton University\nPrinceton, NJ\npolatkan@princeton.edu, blei@cs.princeton.edu\n2Department of Electrical Engineering\n4Department of Mathematics\nDuke University\nDurham, NC\nmz31@duke.edu, lcarin@duke.edu, ingrid@math.duke.edu\nAbstract\nSuper-resolution methods form high-resolution images from low-resolution images. In this paper,\nwe develop a new Bayesian nonparametric model for super-resolution. Our method uses a beta-Bernoulli\nprocess to learn a set of recurring visual patterns, called dictionary elements, from the data. Because it\nis nonparametric, the number of elements found is also determined from the data. We test the results on\nboth benchmark and natural images, comparing with several other models from the research literature.\nWe perform large-scale human evaluation experiments to assess the visual quality of the results. In a\nfirst implementation, we use Gibbs sampling to approximate the posterior. However, this algorithm is\nnot feasible for large-scale data. To circumvent this, we then develop an online variational Bayes (VB)\nalgorithm. This algorithm finds high quality dictionaries in a fraction of the time needed by the Gibbs\nSeptember 25, 2012 DRAFT\narXiv:1209.5019v1  [cs.LG]  22 Sep 2012"},{"page":2,"text":"2\nsampler.\nIndex Terms\nBayesian nonparametrics, factor analysis, dictionary learning, variational inference, gibbs sampling,\nstochastic optimization, image super-resolution.\nI. INTRODUCTION\nThe sparse representation of signals with a basis is important in many applications. It has been\nextensively used in image denoising, inpainting, super-resolution, classification and compressive\nsensing [1], [2], [3], [4], [5], [6], [7], [8].\nMany real data sets can be sparsely represented in some basis; typically this basis itself has to\nbe learned from the data [1], [2], [3], [6], [7], [8], [9], [10], [11], [12]. For example, an image\ncan be represented by weighted combinations of recurrent patterns of pixels. This construction\nmay be beneficial, both while building a model for more accurate representation of the data (e.g.\nsuperior image denoising models) and while deriving and implementing an inference procedure\nfor more efficient algorithms.\nIn this paper we consider image super-resolution (SR), the problem of recovering a high-\nresolution (HR) image from a low-resolution (LR) image. It has many applications, e.g., to\nsmart phones, surveillance cameras, medical imaging, and satellite imaging.\nThere are a variety of approaches for image super-resolution. In general, rendering an HR\nimage from an LR image has many possible solutions. We must use regularization of some\nform, i.e., prior information about the HR, to guarantee uniqueness and stability of the extension.\nFor this purpose, researchers have proposed several methods [13], [14]. Interpolation-based\nmethods, such as the Bicubic method and Bilinear method, often over-smooth images, losing\ndetail. Example-based approaches use machine learning to avoid this [15], [16], [17]; they train\non ground-truth HR and LR images, learning a statistical relationship between the two. These\nrelationships are later used to reconstruct unknown HR images from corresponding LR images.\nFreeman et al. ([15]) proposes a method that stores a training set of preprocessed patches\nand uses a nearest-neighbor search to super-resolve. Kim et al. ([16]) proposes using kernel\nridge regression with a regularized gradient descent. Another class of SR algorithms use texture\nsimilarity to match image regions with known textures [18], [19]. Finally, there are methods for\nSeptember 25, 2012 DRAFT"},{"page":3,"text":"3\nsingle-image super-resolution. One classic example is [20] which uses recurring patterns at same\nand different scales in a single image.\nIn this work, our focus is on SR via example-based sparse coding. ScSR (Super-resolution via\nSparse Representation) is such an algorithm pioneered in [21]. This algorithm is based on sparse\ncoding via L1 regularized optimization. In [21], image data are represented using a collection\nof dictionary elements (recurring patterns of pixels) that are weighted across different positions.\nAlthough very powerful, this model requires one to specify the number of dictionary elements\nand the variance of the noise model in advance\u2014parameters that may be difficult to assess\nfor real-world images. It also only provides a batch learning algorithm, i.e., computing model\nparameters via a gradient descent algorithm on a fixed small subset of the data.\nBayesian nonparametric methods circumvent all these limitations. These methods adapt the\nstructure of the latent space to the data and provide a powerful representation because they\ninfer parameters that otherwise have to be assigned a priori [22], [23], [24], [25], [26], [27],\n[28], [29], [30], [31], [32]. The full posterior distribution can be approximated via MCMC or\nvariational inference, yielding sparse representations and learned dictionaries.\nBayesian nonparametric methods have been used in many image analysis applications: to learn\ndeep architectures used for object recognition in [22], for image inpainting and denoising in [28],\n[29], for image segmentation in [30], [31], and to learn nonparametric multiscale representations\nof images in [32].\nIn this paper, we develop a Bayesian nonparametric method for super-resolution. We show\nthat inference in our model is feasible, performing super-resolution with both a sampling based\nalgorithm and an online variational inference algorithm. In the latter, we approximate the posterior\ndistributions via a stochastic gradient descent over a variational objective that enables us to use\nthe full data set and process the data segment by segment. We also provide human evaluation\nexperiments which shows that signal-to-noise ratio (a typical quantitative measure of success\nin image analysis applications) is not necessarily consistent with human judgement. We devise\na new model, new algorithms, and study a human-based evaluation. We make the following\ncontributions:\n\u201a We develop a sparse Bayesian nonparametric model for SR, learning the number of dictio-\nnary elements and the noise variance from the data.\n\u201a We develop an online variational Bayes (VB) algorithm finding high quality \u201ccoupled\nSeptember 25, 2012 DRAFT"},{"page":4,"text":"4\nFig. 1.\nDepicting the observations extracted (e.g. image patches) from high and low resolution images.\ndictionaries\" in a fraction of the time needed by traditional inference.\n\u201a We devise large scale human evaluation experiments to explicitly assess the visual quality\nof results.\nOur approach to SR gives a rich nonparametric representation with scalable learning.\nThe remainder of the paper is organized as follows: Section II describes the proposed super-\nresolution model and non-parametric prior, Section III contains the derivation of the posterior\ninference algorithms, Section IV presents the experimental results and implementation details,\nSection V includes the discussion and future work.\nII. PROPOSED APPROACH\nBayesian factor analysis can be used to learn factors \/ dictionaries from natural images. Zhou\net al. ([28]) used beta process factor analysis in image denoising, inpainting and compressive\nsensing. These models learn both the dictionary elements and their number from the data.\nWe build here a nonparametric factor analysis model that couples an HR image to a corre-\nsponding LR image. In training, we learn the HR\/LR relationship from observed HR\/LR pairs.\nTo perform super-resolution, we condition on an observed LR image and compute the conditional\nexpectation of its corresponding HR image. A more detailed description of the training process is\nas follows. We create training data by taking observed HR images and forming corresponding LR\nimages. Figure 1 depicts the preprocessing and data extraction steps. We first down-sample the\nHR images. Then, we up-sample those by interpolating with a deterministic weighting function\n(e.g. bicubic interpolation). We extract same-sized patches from the same locations of both the\nHR and interpolated LR images, and consider those patches as coupled to each other. These are\nSeptember 25, 2012DRAFT"},{"page":5,"text":"5\nthe data on which we train the model.\nIn the model, each small patch is generated from latent global dictionary elements\u2014small\nimages functioning as factor loadings\u2014using local sparse weights and Gaussian noise. We will\nfirst explain how these latent variables are generated and then present how they are used to\ngenerate the observations.\nWe learn two dictionaries: one for high resolution images and one for low resolution images.\nIn terms of notation, dplq\nelement. Pplqand Pphqrepresent the dimensionality of the low and high resolution dictionary\nkrepresents the LR dictionary element, and dphq\nk\nis the HR dictionary\nelements, respectively. To model each dictionary element, we use a zero-mean Gaussian distri-\nbution,\ndplq\nk\n\u223c Np0,Pplq\u00b41IPplqq\ndphq\nk\n\u223c Np0,Pphq\u00b41IPphqq.\nThe matrix form of the dictionaries are Dplqand Dphqwhere kth columns of those matrices are\ndplq\nFollowing [21], we assume that the sparse weights are shared by both resolution levels for\nkand dphq\nk, respectively.\ncombining dictionary elements to produce images. This is the key property of the model that\nallows us to frame super-resolution as inference. Sparse weights have two components: real\nvalued weights sikand binary valued assignments zik. To model the weights sik, we use a zero-\nmean Gaussian distribution with precision \u03b1. ziis a binary vector that encodes which dictionary\nelements are activated for the corresponding observation. ppzq represents the prior of this variable\nand we will elaborate on this in next section. These are given as\nsik \u223c Np0,1{\u03b1q\nzik \u223c ppzikq.\nWe place Gamma priors on the precisions of the sparse weights and observation noise (\u03b1 and\n\u03b3). The two resolution levels share these variables as well,\n\u03b3 \u223c Gammapc,dq,\nrepresents patches extracted from HR and LR images, respectively, as shown\n\u03b1 \u201e Gammape,fq.\nLet xphq\nin Figure 1. Given the (global) dictionary elements and (local) sparse weights, the observations\ni\nand xplq\ni\nare modeled as\n?plq\ni \u223c Np0,\u03b3\u00b41IPplqq\nxplq\n?phq\ni\n\u223c Np0,\u03b3\u00b41IPphqq\n\u201c Dphqpsid ziq ` ?iphq\ni \u201c Dplqpsid ziq ` ?iplq\nxphq\ni\nSeptember 25, 2012DRAFT"},{"page":6,"text":"6\nwhere tplq,phqu represents LR and HR, respectively. Here, N is the total number of patches, and\nd represents the element-wise multiplication of two vectors. Figure 1 illustrates the graphical\nmodel.\nTo use this model in SR, we must be able to compute the posterior distributions of the hidden\nvariables. In the training phase, we must compute the posterior distributions ppDphq,Dplq|txphq\nof the dictionaries, given a collection of HR\/LR image pairs. In testing, we use their posterior\ni,xplq\niuq\nexpectation to reconstruct a held-out HR image from an LR image,\nErxphq\nj|xplq\nj,txphq\ni,xplq\nius \u00ab\u02c6D\nphqp\u02c6 sjd \u02c6 zjq\n(1)\nwhere\u02c6D\nposterior expectation of the sparse weights from the LR image patches (xplq\ninference. (We discuss algorithms for posterior inference in Section III.)\nphqis the mean of the posterior distribution ppDphq|txphq\ni,xplq\niuq and p\u02c6 sjd \u02c6 zjq are the\nj) via posterior\nA. Beta-Bernoulli Process Prior (BP)\nWe now discuss the prior for the factor assignments zi. We use a beta-Bernoulli process (BP)\n[22], [23], [24], [25], [26], [27], [28], [29], a prior on infinite binary matrices which is connected\nto the Indian buffet process (IBP). Each row encodes which dictionary elements are activated\nfor the corresponding observation; columns with at least one active cell correspond to factors.\nThe distinguishing characteristic of this prior is that the number of these factors is not specified\na priori. Conditioned on the data, we examine the posterior distribution of the binary matrix to\nobtain a data-dependent distribution of how many components are needed.\nThe IBP metaphor gives the intuition. Consider a buffet of dishes at a restaurant. Suppose there\nare infinite number of dishes and we are trying to specify the infinite binary matrix indicating\nwhich customers (observations) choose which dishes (factors\/dictionary elements). In the Indian\nbuffet process (IBP), N customers enter the restaurant sequentially. Each customer chooses\ndishes in a line from a buffet. The first customer starts from the beginning of the buffet and\ntakes from each dish, stopping after Poisson(\u03c4) number of dishes. The ith customer starts from\nthe beginning as well, but decides to take from dishes in proportion to their popularity within the\nprevious i\u00b41 customers. This proportionality can be quantified as\nof previous customers who took this kth dish. After considering the dishes previously taken by\nmk\niwhere mkis the number\nother customers, the ith customer tries a Poisson(\u03c4\ni) number of new dishes. Which customers\nSeptember 25, 2012DRAFT"},{"page":7,"text":"7\nFig. 2.\nGraphical Model.\nchose which dishes is recorded by the infinite binary matrix with N rows (indicating the\ncustomers\/observations) and infinite columns (indicating the dishes\/factors\/dictionary elements).\nOne important (and surprising) property of this process is that the joint probability of final\nassignment is independent of the order of customers getting into the restaurant which is called\nexchangeability property of the prior [33].\nThe probabilistic construction is as follows. Each observation i is drawn from a Bernoulli\nprocess (a sequence of independent identically distributed Bernoulli trials), xi\u201e BePpBq where\nB is drawn from a beta process B \u201e BPpc0,B0q. B0represents the base measure with B0\u201c\nNp0,1{\u03b2Iq. As K \u00d1 8, the ith observation is xi \u201c\u01598\nthe dictionary element dkis used while representing the ith observation or not, and the sample\nfrom the beta process is given by B \u201c\u01598\ndictionary element dk.\nIn inference, we use a finite beta-Bernoulli approximation [25]. The finite model truncates the\nk\u201c1zik\u03b4dkwhere zik denotes whether\nk\u201c1\u03c0k\u03b4dk. Here, \u03c0krepresents the usage probability of\nnumber of dictionary elements to K and is given by\n\u03c0k\u201e Betapc0\u03b70,c0p1 \u00b4 \u03b70qq, zik\u201e Bernoullip\u03c0kq\nwhere c0and \u03b70are scalars and\napproximation approaches the IBP\/BP. If the truncation is large enough, data analyzed with this\nk P 1,...K. As K tends to infinity, the finite beta-Bernoulli\nprior will exhibit fewer than K components [23].\nSeptember 25, 2012DRAFT"},{"page":8,"text":"8\nB. Super-resolution via Posterior Distributions\nOur algorithm has 2 stages: fitting the model on pairs of HR and LR images, and super-\nresolving new LR images to create HR versions.\nTraining: Coupled Dictionary Learning Stage. In training, we observe xphq\nother random variables are latent. The key inference problem to be solved is the computation of\ni\nand xplq\ni. All\nthe posterior distributions of the hidden variables. In the training phase, we must compute the\nposterior distributions ppDphq,Dplq|txphq\nimage pairs. We rewrite the coupled model in a form similar to the single scale model:\n\u00a8\nxphq\ni\ni,xplq\niuq of the dictionaries given a collection of HR\/LR\nxpcq\ni\n\u201c\n\u02ddxplq\ni\n\u02db\n\u201a,dpcq\nk\u201c\n\u00a8\n\u02dddplq\nk\ndphq\nk\n\u02db\n\u201a,?pcq\ni\n\u201c\n\u00a8\n\u02dd?plq\ni\n?phq\ni\n\u02db\n\u201a\n(2)\nwhere the superscript pcq corresponds to combination of plq and phq. Writing the fully-observed\nmodel in this way reveals that we can train the dictionaries with similar methods as for the\nsingle-scale base model (Training amounts to approximating the posteriors of these values). The\ndifferences are that we use combined patches xpcq\nto shared sparse weights for the two resolution levels. (The details of how we compute the\ndistribution ppDphq,Dplq|txphq\nSuper-resolving a Low Resolution Image. With fitted dictionaries in hand, we now show\nhow to form HR images from LR images via posterior computation.\nIn this prediction setting, the HR image xphq\ni\nis unknown; the goal is to reconstruct it from the\nLR image patches xplq\n\u02c6 \u03b3, \u02c6 \u03b1 of the noise and the sparse weights,\n\u00a8\n\u00b4\nFirst we find estimates of the sparse factor scores, p\u02c6 sid \u02c6 ziq, by using the LR image patches\nxplq\ni\nand posterior estimates of the dictionaries and precisions \u03b3 and \u03b1. The fitted value of \u03b1\ndetermines the strength of a \u201cregularization term\" that controls the sparsity of the factor scores.\ni\nand combined dictionaries dpcq\nk. This leads\ni,xplq\niuq are discussed in Section III.)\ni, the posterior estimates of the dictionaries p\u02c6D\nphq,\u02c6D\nplqq, and the precisions\nxpcq\ni\n\u201c\n\u02ddxplq\ni\n\u02db\n\u201a, dpcq\nk\u201c\n\u00a8\n\u02dddplq\nk\ndphq\nk\n\u02db\n\u201a, ?pcq\ni\n\u201c\n\u00a8\n\u02dd?plq\ni\n\u00b4\n\u02db\n\u201a.\nMore precisely, this prediction setting has 3 steps. The input is a set of held-out LR image\npatches xplq\nnoise and the sparse weights. The steps are as follows:\ni, the posterior estimates of the dictionaries p\u02c6D\nphq,\u02c6D\nplqq, and the precisions \u02c6 \u03b3, \u02c6 \u03b1 of the\nSeptember 25, 2012DRAFT"},{"page":9,"text":"9\n1) We find estimates of the sparse factor scores, p\u02c6 sid \u02c6 ziq, conditioned on the LR image\npatches xplq\ni\nand estimates p\u02c6D\n2) Eq. 1 determines the HR patches \u02c6 xphq\n3) We replace each xplq\ni\npixel-wise average of those overlapping reconstructions.\nphq,\u02c6D\nplqq, \u02c6 \u03b3, \u02c6 \u03b1 from the training stage.\ni.\nby its corresponding collocated \u02c6 xphq\ni; the whole HR image,\u02c6X\nphq, is the\nPost-processing: Following [21], we apply a post-processing step that, when down-sampled,\nthe reconstructed HR image,\u02c6X\nthe following optimization:\nphq, should match the given LR image Xplq. Specifically, we solve\n\u02c6X\nphq\u02da\u201c argmin\nX\n||fpXq \u00b4 Xplq||2\n2` c||fpXq \u00b4\u02c6X\nphq||2\n2\nwhere fpq is a linear operator consisting of an anti-aliasing filter followed by down-sampling.\nThis optimization problem is solved with gradient descent.\nIII. POSTERIOR INFERENCE\nIn the proposed approach, all of the priors are in the conjugate exponential family. In a first\nimplementation, we use Gibbs sampling. We iteratively sample from the conditional distribution\nof each hidden variable given the others and the observations. This defines a Markov chain\nwhose stationary distribution is the posterior [34]. The corresponding sampling equations are\nanalytic and provided in the appendix A-B (appendix is in the supplementary material).\nThe Gibbs sampler has difficulty with scaling to large data, because it must go through many\niterations, each time visiting the entire data set before the sampler mixes. For this reason, both\nour Gibbs sampler and ScSR use 105patches sampled from 3 \u02c6 106. We now develop here\nan alternative algorithm to Gibbs sampling for SR that scales to large and streaming data.\nSpecifically, we develop an online variational inference algorithm.\nVariational inference is a deterministic alternative to MCMC that replaces sampling with\noptimization. The idea is to posit a parameterized family of distribution over the hidden variables\nand then optimize the parameters to minimize the KL divergence to the posterior of interest [35].\nOur algorithm iteratively tracks an approximate posterior distribution, which improves as more\ndata are seen.\nIn typical applications, the variational objective is optimized with coordinate ascent, iteratively\noptimizing each parameter while holding the others fixed. However, in Bayesian settings, this\nSeptember 25, 2012DRAFT"},{"page":10,"text":"10\nsuffers from the same problem as Gibbs sampling\u2014the entire data set must be swept through\nmultiple times in order to find a good approximate posterior. In the algorithm we present here,\nwe replace coordinate ascent optimization with stochastic optimization\u2014at each iteration, we\nsubsample our data and then adjust the parameters according to a noisy estimate of the gradient.\nBecause we only to subsample the data at each iteration, rather than analyze the whole data\nset, the resulting algorithm scales well to large data. This technique was pioneered in [36]\nand was recently exploited for online learning of topic models [37] and hierarchical Dirichlet\nprocesses [38].\nWe first develop the coordinate ascent algorithm for the coupled model. Then we derive the\nonline variational inference algorithm, which can more easily handle large data sets.\nA. Variational Inference for the Coupled model\nWe use the coupling perspective in Section II-B to derive the batch variational Bayes (VB)\nalgorithm. The single-scale base model is the BPFA model of [26], which gives a mean-field\nvariational inference algorithm. The batch VB algorithm derived here is the coupled version of\nthat.\nWe first define a parametrized family of distributions over the hidden variables. Let Q \u201c\nt\u03c0,Z, S, D,\u03b3,\u03b1u denote the hidden variables for all i,k. We write coupled data as in Equation\n2; in the new set-up the variables to be learned become Q \u201c t\u03c0,Z, S,Dpcq,\u03b3,\u03b1u. We use a fully\nfactorized variational distribution,\nqpQq \u201c q\u03c4p\u03c0qq\u03c6pDpcqqq\u03bdpZqq\u03b8pSqq\u03bbp\u03b3qq?p\u03b1q.\nEach component of this distribution is governed by a free variational parameter,\nq\u03c4kp\u03c0kq \u201c Betap\u03c4k1,\u03c4k2q\nq\u03c6kjpdkjq \u201c Np\u03c6kj,\u03a6kjq\nq\u03b8ikpsikq \u201c Np\u03b8ik,\u0398ikq\nq\u03bdikpzikq \u201c Bernoullip\u03bdikq\nq\u03bbp\u03b3q \u201c Gammap\u03bb1,\u03bb2q\nq?p\u03b1q \u201c Gammap?1,?2q\nWe optimize these parameters with respect to a bound on the marginal probability of the\nobservations. This bound is equivalent, up to a constant, to the negative KL divergence between\nq and the true posterior. Thus maximizing the bound is equivalent to minimizing KL divergence\nSeptember 25, 2012DRAFT"},{"page":11,"text":"11\nto the true posterior. Let \u039e \u201c tc0,\u03b70,c,d,e,fu be the hyper-parameters. The variational lower\nbound is\n\u00ffK\n`\n`\n`\nlogpppXpcq|\u039eqq \u011b Hpqq `\n\u00ffN\n\u00ffN\n\u00ffN\nk\u201c1\n\u00ffJ\n!\nEqrlogpp\u03c0k|c0,\u03b70,Kqs\nj\u201c1Eqrlog`ppdkj|\u03b2kjq\u02d8s\ni\u201c1Eqrlogppzik|\u03c0qs `\ni\u201c1Eqrlog`ppsik|\u03b1qpp\u03b1|e,fq\u02d8s\ni\u201c1\n)\n(3)\n!\nEqrlogppxpcq\ni|Z,S,Dpcq\u03b3qs ` Eqrlogpp\u03b3|c,dqs\n)\n,\nwhere Hpqq is the entropy of the variational distribution and dimensionality of the dictionary\nelements J is twice as big as the single-scale model. We denote this function Lpqq.\nHolding the other parameters fixed, we can optimize each variational parameter exactly; this\ngives an algorithm that goes uphill in Lpqq [39]. (Further, this will provide the algorithmic\ncomponents needed for the online algorithm of Section III-B.)\nUpdate equations for each free parameter optimizing this bound are given below. In all\nequations, IP represents P \u02c6 P identity matrix, and \u02dc xpcq\nusing all but the kth dictionary element, that is\nip\u00b4kqrepresents the reconstruction error\n\u02dc xpcq\nip\u00b4kq\u201c xpcq\ni\n\u00b4 Dpcqpsid ziq ` dpcq\nkpsikd zikq.\nThe expectation based on the variational distribution is then given by\nEqr\u02dc xpcq\nip\u00b4kqs \u201c xpcq\ni\n` \u03c6pcq\nkp\u03b8ik\u03bdikq \u00b4\nK \u00ff\nk\u201c1\n\u03c6pcq\nkp\u03b8ik\u03bdikq.\nUpdate for the binary factor assignment zik: The variational parameter for factor assignment\nzikis \u03bdik. We first consider two values of the variational distribution for two values (0,1) of zik,\n`p\u03b82\nqpzik\u201c 0q 9 exppEqrlnp1 \u00b4 \u03c0kqsq, where\n\u00ff\nEqrlnp1 \u00b4 \u03c0kqs \u201c \u03c8`c0p1 \u00b4 \u03b70q \u00b4\nqpzik\u201c 1q 9 exppEqrlnp\u03c0kqsqexp\n\u00b4\n\u00b4\n\u03bb1\n\u03bb2\nik` \u0398ikqp\u03c6pcqT\nk\n\u03c6pcq\nk`\u0159\nj\u03a6kjq \u00b4 2\u03b8ik\u03c6pcqT\n2\nk\nEqr\u02dc xpcq\nip\u00b4kqs\u02d8\n\u00af\nEqrlnp\u03c0kqs \u201c \u03c8`c0\u03b70`\ni\n\u03bdik\n\u02d8\u00b4 \u03c8pc0` Nq\n\u00ff\ni\n\u03bdik` N\u02d8\u00b4 \u03c8pc0` Nq\nSeptember 25, 2012DRAFT"},{"page":12,"text":"12\nThen the update equation for the variational parameter \u03bdikis given as\n\u03bdik \u201c\nqpzik\u201c 1|\u00b4q\nqpzik\u201c 1|\u00b4q ` qpzik\u201c 01|\u00b4q\nUpdate for the shared sparse weight sik: The variational distribution for the sparse weight\nsikis Gaussian parametrized with mean \u03b8ikand variance \u0398ik. Coordinate ascent update equation\nfor these free variational parameters are\n\u00b4?1\n\u03b8ik \u201c\nUpdate for the kth coupled dictionary element dpcq\ncouple dictionary element dpcq\nk\nCoordinate ascent update equation for these free variational parameters are\n\u0398ik \u201c\n?2\n`\u03bb1\n\u03bb2\u03bdikp\u03c6pcqT\nk\n\u03c6pcq\nk`\n\u00ff\nj\n\u03a6kjq\n\u00af\u00b41\n\u03bb1\n\u03bb2\u0398ik\u03bdik\u03c6pcqT\nk\nEqr\u02dc xpcq\nip\u00b4kqs.\nk: The variational distribution for the\nis Gaussian parametrized with mean \u03c6pcq\nk\nand variance \u03a6pcq\nk.\n\u03a6pcq\nk\n\u201c\n\u00b4\n\u03bb1\n\u03bb2\u03a6pcq\n2PI2P`\u03bb1\n\u03bb2\nN \u00ff\ni\u201c1\np\u03b82\nik` \u0398ikq\u03bd2\nik\n\u00af\u00b41\n\u03c6pcq\nk\n\u201c\nk\nN \u00ff\ni\u201c1\n\u03b8ik\u03bdikEqr\u02dc xpcq\nip\u00b4kqs.\nThe updates for high resolution (h) and low resolution (l) components can be given separately\nas\n\u03a6phq\nk\n\u201c\n\u00b4\n\u03bb1\n\u03bb2\u03a6phq\n2PIP`\u03bb1\n\u03bb2\nN \u00ff\ni\u201c1\np\u03b82\nik` \u0398ikq\u03bd2\nik\n\u00af\u00b41\n\u03a6plq\nk\n\u201c\n\u00b4\n\u03bb1\n\u03bb2\u03a6plq\n2PIP`\u03bb1\n\u03bb2\nN \u00ff\ni\u201c1\np\u03b82\nik` \u0398ikq\u03bd2\nik\n\u00af\u00b41\n\u03c6phq\nk\n\u201c\nk\nN \u00ff\ni\u201c1\n\u03b8ik\u03bdik\u02dc xphq\nip\u00b4kq\n\u03c6plq\nk\n\u201c\nk\nN \u00ff\ni\u201c1\n\u03b8ik\u03bdik\u02dc xplq\nip\u00b4kq.\nUpdate for the dictionary usage probabilities \u03c0k: The variational distribution for the\ndictionary usage probabilities \u03c0kis a beta distribution parametrized with the shape parameters\n(\u03c4k1,\u03c4k2). Coordinate ascent update equation for these free variational parameters are\n\u03c4k1 \u201c c0\u03b70`\nN \u00ff\nN \u00ff\ni\u201c1\n\u03bdik\n\u03c4k2 \u201c\nN \u00b4\ni\u201c1\n\u03bdik` c0p1 \u00b4 \u03b70q.\nSeptember 25, 2012DRAFT"},{"page":13,"text":"13\nUpdate for the precision \u03b3: The variational distribution for the precision \u03b3 of the observation\nnoise ?iis a gamma distribution parametrized with (\u03bb1,\u03bb2). Coordinate ascent update equation\nfor these free variational parameters are\n\u03bb1 \u201c c ` NP\n\u03bb2 \u201c d `1\n2\nN \u00ff\ni\u201c1\n!\n||xpcq\ni\n\u00b4\nK \u00ff\n)\nk\u201c1\n\u03c6pcq\nkp\u03b8ik\u03bdikq||2\n2`\nK \u00ff\nk\u201c1\n\u03bdikp\u03b82\nik` \u0398ikqp\u03c6pcqT\nk\n\u03c6pcq\nk`\n\u00ff\nj\n\u03a6kjq\n\u00b4\nK \u00ff\nk\u201c1\n\u03bdik\u03c6pcqT\nk\n\u03c6pcq\nk\u03b82\nik\n.\nUpdate for the precision \u03b1: The variational distribution for the precision \u03b1 of the sparse\nweights sikis a gamma distribution parametrized with (?1,?2). Coordinate ascent update equation\nfor these free variational parameters are\n?1 \u201c e `1\n?2 \u201c f `1\n2NK\nN \u00ff\n2\ni\u201c1\nK \u00ff\nk\u201c1\np\u03b82\nik` \u03982\nikq.\nAlgorithm 1 Batch VB\nSample N observations from the data. Initialize \u03c4,\u03bd,\u03c6,\u03a6,\u03b8,\u0398,\u03bb,? using Gibbs sampler.\nfor t \u201c 1 to T do\nInit. local variables \u03bdnk,\u03b8nk,\u0398nkusing Gibbs sampler.\nwhile relative improvement in ? is large do\nfor k \u201c 1 to K do\nfor n \u201c 1 to N do\nupdate \u03bdnk,\u03b8nk,\u0398nkby using batch VB updates.\ncompute \u03a6k,\u03c6k,\u03c4k,\u03bb,? by batch VB updates.\nB. Online Variational Inference\nWe now develop online variational inference. We divide the variational parameters into global\nvariables and local variables. Global variables depend on all of the images. These are the\ndictionary probabilities \u03c0k, dictionary elements dk, precisions \u03b1 and \u03b3. Local variables are\nthe ones drawn for each image. These are the weights si, binary variables zi. The algorithm\nSeptember 25, 2012 DRAFT"},{"page":14,"text":"14\niterates between optimizing the local variables using local (per-image) coordinate ascent, and\noptimizing the global variables. This same structure is found in many Bayesian nonparametric\nmodels [23], [40].\nThe basic idea is to optimize Equation 3 via stochastic optimization [41]. This means we\nrepeatedly follow noisy estimates of the gradient with decreasing step sizes \u03c1t. If the step sizes\nsatisfy\u0159\nvariational inference, we will converge to a local optimum.)\nt\u03c1t\u201c 8 and\u0159\nt\u03c12\nt\u0103 8 then we will converge to the optimum of the objective. (In\nAlgorithm 2 Online VB with mini-batches\nDefine \u03c1t\u201c pr ` tq\u00b4\u03ba, Initialize \u03c4,\u03bd,\u03c6,\u03a6,\u03b8,\u0398,\u03bb,? using Gibbs sampler.\nfor t \u201c 1 to\nSample NSnew observations from the data. Initialize local variables \u03bdnk,\u03b8nk,\u0398nkusing Gibbs sampler.\nwhile relative improvement in ? is large do\nfor k \u201c 1 to K do\nfor nt\u201c pt \u00b4 1q \u02c6 NS` 1 to t \u02c6 NSdo\nupdate \u03bdntk,\u03b8ntk,\u0398ntkby using batch VB updates.\ncompute\u02dc\u03a6k,\u02dc\u03c6k, \u02dc \u03c4k,\u02dc\u03bb,\u02dc ? by batch VB updates as if there are N{NScopies of the images.\nfor k \u201c 1 to K do\nupdate \u03a6k,\u03c6k,\u03c4k,\u03bb,? by Equation 6\nN\nNSdo\nThe noisy estimates of the gradient are obtained from subsampled data. We write the objective\nL as a sum over data points. Defining the distribution gpnq which uniformly samples from the\ndata, we can then write L as an expectation under this distribution,\nL \u201c\n\u201c NEgr?p\u03c4,\u03bdn,\u03c6,\u03b8n,\u0398n,\u03bbn,?n,Xnqs\nThe gradient of the objective can be written as a similar expectation. Thus, sampling data at\n\u00ffN\nn\u201c1?p\u03c4,\u03bdn,\u03c6,\u03b8n,\u03bbn,?n,Xnq.\n(4)\n(5)\nrandom and computing the gradient of ?ngives a noisy estimate of the gradient.\nThere are two further simplifications. First, when we subsample the data we optimize the\nlocal variational parameters fully and compute the gradient of ?nwith respect to only the global\nvariational parameters. Second, we use the natural gradient [42] rather than the gradient. In mean\nfield variational inference, this simplifies the gradient step as follows. Suppose we have sampled\nan image n and fitted its local variational parameters given the current settings of the global\nSeptember 25, 2012DRAFT"},{"page":15,"text":"15\nFig. 3.\nDictionary trained in batch mode on lluminance channel with SR ratio = 2. (Left) HR Dictionary, (Right) LR\nDictionary, Every square represents a dictionary element and the HR-LR pairs are co-located. HR dictionary consists of sharper\nedges.\nvariational parameters. Let \u02dc \u03c4,\u02dc\u03c6,\u02dc\u03a6,\u02dc\u03bb,\u02dc ? be the global variational updates from Section III-A as\nthough we observed N copies of that image. (Note that these depend on its local variational\nparameters.) Following a noisy estimate of the natural gradient of L is equivalent to taking a\nweighted average of the current and the newly fitted global parameters, e.g.\n\u03c6 \u201c p1 \u00b4 \u03c1tq\u03c6 ` \u03c1t\u02dc\u03c6.\n(6)\nIt follows that there is no additional computational cost to optimizing the global variational\nparameters with stochastic optimization versus coordinate ascent.\nIn our implementation, we decrease the step-size \u03c1t by \u03c1t\u201c p\u03c10` tq\u00b4\u03ba. The learning rate\nparameter \u03c10 down-weights early iterations; the parameter \u03ba controls the speed of forgetting\nprevious values of the global variables.\nThe full online VB algorithm is listed in Algorithm 2. (Note that we sample the data in\nmini-batches, rather than one at a time. When the mini-batch size is equal to one data point, we\nrecover the algorithm as described above.)\nSeptember 25, 2012DRAFT"},{"page":16,"text":"16\nC. Initialization with MCMC.\nWe initialize both the batch and online VB with a few iterations (e.g. 5 or 10) of MCMC.1This\nis useful for two reasons: (1) It provides a good initialization and thus faster convergence, (2)\nNoisy random-walks of MCMC help VB avoid low-quality local optima: at the beginning of each\ne-step, MCMC initializes siand ziby sampling from their approximate posterior distribution,\ngiven the most recent global variables. These samples are noisy estimates of the sparse weights\nnear their posterior means. For instance, when the factor assignment zikequals 0, the MCMC\ndraws the sparse weight sik from the prior Np0,1{\u03b1q whereas in VB it would be exactly 0.\nProviding the freedom to \u201cjiggle\" gives the algorithm the opportunity, similar to simulated\nannealing, to jump away from one local optimum to reach a better optimum.\nIV. EXPERIMENTS\nWe use three data sets. To train, we use the set of 68 images collected from the web by [21].\nWe test on the Berkeley natural image data set (20 100\u02c6100 images) and a benchmark set of\nimages (11 images of various size) used by the community to evaluate SR algorithms.2These\ndata sets provide us with a rich set of HR-LR pairs.\nThroughout this work, unless otherwise mentioned we use the same parameters (without any\ntuning): we set the SR ratio to 2 or 4 and the patch size to 8 \u02c6 8.3The hyper-parameters are\nc \u201c d \u201c e \u201c f \u201c 10\u00b46and c0\u201c 2,\u03b70\u201c 0.5, these are standard uninformative priors used in e.g.\n[28]. The truncation level K in BP is set to 512. Most images use fewer factors, e.g. Baboon\nuses 487, House 438 and Barbara 471 factors. We apply all algorithms only to the illuminance\nchannel and use Bicubic interpolation for the color layers (Cb, Cr) for all compared methods.\nWe study our methods with two kinds of posterior inference\u2014Gibbs sampling (BP) and online\n1For batch VB, these MCMC samples are collected on the same subset of the data on which batch VB will process. For\nonline VB, they are collected from the mini-batches. In both cases, scale problem of MCMC is not an issue since we only\ncollect few samples (e.g. 5 or 10). As we mentioned before, scale is a problem for MCMC since it needs to go over the data\nmany times for convergence (e.g. thousands of iterations). Time scaling is discussed in more detail in Section IV-C\n2We are using SR ratio=2 or 4. For SR ratio 2, the images which do not have even number of rows\/columns are cut to have\neven number of rows\/column to prevent any possible mismatch and error in computing PSNR in all algorithms. For instance\nthe last column of pixels from an image of size 330 \u02c6 171 is excluded so the corresponding image have the size 330 \u02c6 170.\n3The visual results for SR ratio 4 are in the appendix G.\nSeptember 25, 2012DRAFT"},{"page":17,"text":"17\nTABLE I\nTEST RESULTS WITH SR RATIO = 2. PSNR FOR THE ILLUMINANCE CHANNEL IS PRESENTED (THE HIGHER THE BETTER).\nBP: PROPOSED ALGORITHM TRAINED VIA GIBBS SAMPLER, O-BP PROPOSED ALGORITHM TRAINED VIA ONLINE VB,\nSEEING MORE DATA, SCSR: SUPER-RESOLUTION VIA SPARSE REPRESENTATION [21], NNI: NEAREST NEIGHBOR\nINTERPOLATION, SME: SPARSE MIXING ESTIMATION [43].\nPSNR\nBic.NNI Bil. SMEScSR256 ScSR512 BPOBP\nBaboon23.63 23.1223.0523.10 24.33 24.3624.27\n24.39\n25.99\n31.31\nBarbara25.35 25.10 24.92 24.42 25.8825.8925.98\nBoat29.95 28.39 28.9429.72 31.2331.2931.17\nCamera30.32\n35.20\n28.94 26.33 30.6830.46 31.5130.94\nHouse 32.79 30.3431.61 33.2834.26\n34.31\n34.0834.27\nPeppers 31.9929.8831.18 33.06 33.0533.06 32.45\n33.08\nParthen.28.1227.2827.42 27.2829.05\n29.10\n28.96 29.06\nGirl34.76 33.4433.98 33.98 35.5735.5835.62\n35.66\n41.33\n34.68\n32.62\nFlower 40.0437.96 38.9439.72 41.06 41.11 41.26\nLena32.83 31.0031.7233.57 34.4734.54 34.56\nRaccoon 30.9529.82 29.9531.73 32.39 32.4332.43\nvariational inference (O-BP), which scales to larger data sets.4To compare, we study both\ninterpolation and example-based algorithms. Bicubic interpolation is the gold standard in the SR\nliterature. We also study nearest neighbor interpolation, bilinear interpolation and sparse mixing\nestimation (SME) [43]. To compare with an example-based method, we use super-resolution via\n4The software for each algorithm presented and all of the visual results will be publicly available.\nSeptember 25, 2012DRAFT"},{"page":18,"text":"18\nsparse representation (ScSR, [21]).5 6 7Both BP\u2019s and ScSR\u2019s dictionary learning stages use\n105patches sampled from the training data, however O-BP uses the whole set in online fashion.\nThe HR and LR dictionaries trained by our approach are shown in Figure 3. The HR dictionary\nconsists of sharper edges.\nAs a quantitative measure of performance we compute the signal to noise ratio (PSNR), a\nmeasure that is widely used in image recovery applications. We present the PSNR results for\nbenchmark images in Table I and natural images in Table II. These PSNR based results can be\nsummarized as: (1) The online learning algorithm and ScSR performs similarly, (2) They both\nslightly perform better than the Gibbs sampler. (3) All of the example based algorithms perform\nbetter than the interpolation based techniques.\nA. Evaluation and Crowdsourcing via Mechanical Turk\nThough signal to noise ratio (PSNR), is a widely used metric in image recovery applications,\nthis is not enough to measure human judgement. For this purpose, we also performed human\nevaluation experiments on Amazon Mechanical Turk (MTurk, http:\/\/www.mturk.com).\nThe Amazon Mechanical Turk (MTurk) is a web interface for deploying small tasks to\npeople, called Turkers. Typically an MTurk experiment works as follows: the requesters, people\norganizing the experiments and paying Turkers, prepare tasks called HITs (Human Intelligence\nTasks). Each HIT might be a comparison of images, labeling of text etc. Once the HITs are\ncompleted, requesters can approve or reject the HITs based on their reliability measures (for\n5We used the code and implementation provided by [21]. We also used their training images, in order to have a fair comparison,\nand we did not change any of their parameters (including noise variance).\n6We provide visual comparisons to [15], [16], [20], [44] in appendix H. [20] provides very sharp edges by artificially enhancing\nthem. However, this makes images unrealistic (looking like graphically rendered). Sparse coding allows any single-image SR\nalgorithm as a pre-processing step. Instead of bicubic interpolation (see Figure 1) [20] might be used with sparse coding to\nboost the sharpness of the edges.\n7The dependent hierarchical Beta process (dHBP), another bayesian nonparametric prior, is proposed in [29]. It removes the\nexchangeability assumption of beta-Bernoulli construction. This prior assumes that each observation i has a covariate ?i P RL.\nIn this model, the closer the two sparse factor assignments zi and zj in the covariate space, the more likely they share similar\ndictionary elements. It applies dHBP using spatial information as covariates to image inpainting and spiky noise removal, and\nshows significant improvement over BP. We obtained preliminary results with dHBP for super-resolution. However, in this setting\nwe did not observe improvement over BP.\nSeptember 25, 2012DRAFT"},{"page":19,"text":"19\nTABLE II\nTEST RESULTS WITH SR RATIO = 2. PSNR FOR THE ILLUMINANCE CHANNEL IS PRESENTED (THE HIGHER THE BETTER).\nBP: PROPOSED ALGORITHM TRAINED VIA GIBBS SAMPLER, O-BP PROPOSED ALGORITHM TRAINED VIA ONLINE VB,\nSEEING MORE DATA, SCSR: SUPER-RESOLUTION VIA SPARSE REPRESENTATION [21], NNI: NEAREST NEIGHBOR\nINTERPOLATION.\nPSNR\nBic. NNIBilin.ScSR256 ScSR512BPO-BP\nN129.7427.4428.39 31.52 31.5531.52\n31.56\n31.20\nN2 29.5227.7128.27 31.16\n31.20\n24.00\n22.66\n26.06\n26.26\n31.17\nN322.9721.95 22.12 23.94 23.8023.94\nN421.6320.98 20.90 22.5922.3822.41\nN5 24.8523.85 24.0126.01 25.7725.90\nN625.34 24.6124.7026.20 26.0826.07\nN726.66 25.4325.7327.92 27.92 27.77\n27.97\nN826.08 24.7125.23 27.27\n27.43\n26.89\n26.25\n27.01 27.26\nN926.02 25.2925.42 26.82 26.5826.73\nN10 24.7924.07 23.92 26.2325.91 26.16\nN11 26.8625.22 25.9728.06 28.04 27.99\n28.16\n29.86\nN1228.16 26.65 27.0729.6329.66 29.78\nN1325.1524.18 24.22 26.40\n26.36\n28.01\n26.31 26.33\nN1426.82 25.9825.9227.99 27.8627.94\nN15 25.7824.64 24.81 27.0027.04 26.90\n27.06\nN16 27.28 25.8526.16 28.88\n29.01\n29.24\n28.8328.96\nN1727.79 26.3326.81 29.21 29.0229.16\nN1829.1327.7528.18 30.3830.41 30.25\n30.43\nN1924.57 23.1923.5026.07\n26.10\n25.9226.02\nN20 22.0021.13 21.05 23.2623.28 23.26\n23.29\ninstance trivial solution HITs, as we explain next, and the time spend on each HIT are frequently\nused measures for reliability). Approved results are acquired to be used in the analysis.\nWhile preparing HITs, we used the natural image data. We asked Turkers to visually assess\nand select the better of two HR reconstructions of each image. We considered all ordered\ncombinations of the algorithms, each equally likely, e.g., BP vs ScSR, BP vs Bicubic etc.\nWe initially collected 42,807 decisions from 208 unique Turkers. For quality control we gave\ntest pairs in which a ground truth HR image was used, i.e., a comparison of an algorithmic\nreconstruction vs a true HR image. All of the judgments of the Turkers who failed to pass this\nSeptember 25, 2012DRAFT"},{"page":20,"text":"20\nFig. 4.\nHuman Evaluation via Mechanical Turk. (Top) Average win rate in one-to-one comparisons. (Bottom) Win rates\nfor each one-to-one comparison. Each number represents the winning rate of the method in the column, e.g., 0.57 for BP vs\nScSR (BP is on the column and ScSR on the row) means that on average, 0.57 of the times Turkers voted in favor of BP.\ntest (Turkers who selected the algorithmic reconstruction instead of true HR) were removed.\nThis reduced the data to 20,469 decisions from 161 unique reliable Turkers.\nThe results of the human evaluation are in Figure 4. In the bottom table, win rates for each\none-to-one comparisons are provided. Each number represents the winning rate of the method in\nthe column. For instance, 0.93 for O-BP vs Nearest (O-BP is on the column and Nearest on the\nrow) means that out of 100 binary comparisons of O-BP and Nearest, 93 of the times Turkers\nvoted in favor of O-BP. In general, we observe that example-based methods perform significantly\nbetter than interpolation-based methods. Within the example-based approaches, the models are\nsimilar. However, our approach does not use the first and second-order derivative filters for the\nLR patches used by ScSR as features, yet we perform similarly; moreover we do not need to set\nthe noise precision and the number of dictionary elements, both required parameters of ScSR\n(We used the parameters provided by [21] in ScSR.).\nSeptember 25, 2012 DRAFT"},{"page":21,"text":"21\n(a) High(b) Low (c) Bicubic (d) NNI(e) Bilinear\n(f) ScSR (g) BP(h) O-BP\nFig. 5.\nReconstruction of Natural Image 3. BP: Algorithm presented in this work trained via Gibbs sampler, O-BP Algorithm\npresented in this work trained via Online VB, ScSR: Super-Resolution via Sparse Representation. Example based approaches\nare superior to interpolation techniques, ScSR and our approach perform similarly.\nIn the PSNR results, ScSR and O-BP seem to perform similarly and both slightly better than\nBP. However, in the human evaluation we observed that BP reconstructions are found to be\nbetter. (Based on 95% confidence intervals, both the BP vs O-BP and BP vs ScSR results are\nstatistically significant. The O-BP vs ScSR difference is statistically insignificant.) This shows\nthat PSNR is not necessarily consistent with the human assessment of images [45]. Sample\nvisual results are shown in Figures 5, 6 and 7. (The remaining results are in the appendix E and\nF.)\nSeptember 25, 2012 DRAFT"},{"page":22,"text":"22\n(a) High(b) Low (c) Bicubic\n(d) NNI (e) Bilinear\n(f) SME (g) ScSR\n(h) BP(i) O-BP\nFig. 6.\nReconstruction of Parthenon Image. BP: Algorithm presented in this work trained via Gibbs sampler, O-BP\nAlgorithm presented in this work trained via Online VB, ScSR: Super-Resolution via Sparse Representation. SME: Sparse\nMixing Estimation [43]\nSeptember 25, 2012DRAFT"},{"page":23,"text":"23\n(a) High(b) Low (c) Bicubic\n(d) NNI(e) Bilinear (f) SME\n(g) ScSR(h) BP (i) O-BP\nFig. 7.\nReconstruction of Baboon Image. BP: Algorithm presented in this work trained via Gibbs sampler, O-BP Algorithm\npresented in this work trained via Online VB, ScSR: Super-Resolution via Sparse Representation. SME: Sparse Mixing\nEstimation [43].\nSeptember 25, 2012 DRAFT"},{"page":24,"text":"24\n10\nNumber of Dictionary Elements  in Log scale(K)Number of Dictionary Elements  in Log scale(K)\n11\n10 10\n22\n1010\n33\n1010\n44\n25.625.6\n25.6525.65\n25.7 25.7\n25.75 25.75\n25.8 25.8\n25.85 25.85\n25.9 25.9\n25.9525.95\n26 26\nPSNR (dB)\n  \n  \nScSR\nBP\nBP\n10\nPSNR (dB)\nScSR\n890900 910920 930940\n0\n5\n10\n15\n20\n25\nNumber of Samples\nNumber of Dictionary Elements\nFig. 8.\nLearning the number of dictionary elements from the data. (Left) PSNR of the reconstruction of the Barbara image\nby nonparametric BP and parametric ScSR with different number of dictionary elements. (Right) Histogram of the number of\ndictionary elements for BP when K \u201c 1024 over 100 samples.\nB. Nonparametric property of the model.\nIn this section, we demonstrate the importance of a Bayesian nonparametric method for image\nsuper-resolution. As we mentioned in Section II-A, we use a beta-Bernoulli process (BP) for the\nfactor assignments zithat encodes which dictionary elements are activated for the corresponding\nobservation. In the binary matrix (whose rows are the factor assignment zi\u2019s), the columns with\nat least one active cell correspond to factors that are used.\nThe distinguishing characteristic of this prior is that the number of the factors to be learned\nis not specified a priori. Conditioned on the data, we examine the posterior distribution of the\nbinary matrix to obtain a data-dependent distribution of how many components are needed. For\nthe parametric ScSR, the number of dictionary elements must be set a priori. This is illustrated\nby the following experiment. For both model, we train on 104patches, for different values of\nK (starting from scratch each time); for ScSR, K is the target number (which needs to be set\nbefore starting the algorithm), while for our approach, K functions as an upper bound on the\nnumber of dictionary elements (which should not be too low). Figure 8 shows that, unlike ScSR,\nour approach is less sensitive to the value of K if it is sufficiently large. The Barbara image uses\n700, 801 and 816 factors in our approach for K equals to 1024,2048 and 4096 respectively.\nSeptember 25, 2012DRAFT"},{"page":25,"text":"25\n0 0.61.21.8 2.43 3.6\nImage Patches Seen\n4.2 4.85.46 6.6 7.27.8 8.49\n5\nx 10\n26.2\n26.4\n26.6\n26.8\n27\n27.2\nMean PSNR (dB)\n \n \nBatch\u2212VB 100K\nBatch\u2212VB 50K\nOnline\u2212VB Mini\u2212batch 20K\nOnline\u2212VB Mini\u2212batch 10K\nOnline\u2212VB Mini\u2212batch  5K\nFig. 9.\nHeld-out prediction performances of Online Learning with different mini-batch sizes. Online-VB run on the whole\ndata set is compared with the Batch-VB run on a subset of the data. The online algorithms converge much faster than the batch\nalgorithm does.\nC. Online learning, Computational Time and Scaling\nIn this section, we compare the scale properties of the algorithms presented in this paper. In\nonline learning, instead of subsampling the patches during the dictionary learning stage, we use\nthe full data set and process the data segment by segment (so called \"mini-batches\"). We use\nthe training data set of Section IV. The learning parameters are set to \u03ba \u201c 0.501 and \u03c10\u201c 3.\nFigure 9 shows the evolution of the mean PSNR on the held-out natural image data set\nby the online and the batch algorithms as a function of the number of image patches seen\n(visualizations of the learned dictionaries are provided in appendix D). The number of patches\nseen represents the computational time since both algorithms\u2019 time complexity is linear with\nnumber of observations. For online VB, the number of patches seen represents the total number\nof data seen after each iteration. For batch VB, this represents cumulative sum of the number\nof same data seen after each variational-EM iteration. Even before the second iteration of the\nbatch VB (100K) is completed, online VB with 5K mini-batch converges \u2013 reaches to a local\noptima better than batch VB. This means that the online algorithm finds dictionaries at least as\ngood as those found by the batch VB in only a fraction of the time. As also shown in Table\nI, it finds high quality dictionaries. This may be because stochastic gradient is robust to local\nSeptember 25, 2012DRAFT"},{"page":26,"text":"26\noptima [46].\nFor dictionary training, the convergence time for online VB with 5K mini-batch size is 16\nhours. In Gibbs sampling, we throw away the first 1500 samples for the burn-in period and\nlater collect 1500 samples to approximate the posterior distributions. This takes approximately\n50 hours on the same machine with an unoptimized Matlab implementation on 105number\nof patches. Running Gibbs sampling same amount of time with online VB, i.e. collecting less\nnumber of samples such as 500, reduces held-out PSNR between 0.2 dB to 0.5 dB, depending\non the image. This is consistent with the findings in [28].\nV. DISCUSSION\nWe developed a new model for super-resolution based on Bayesian nonparametric factor\nanalysis, and new algorithms based on Gibbs sampling and online variational inference. With\nonline training, our algorithm scales to very large data sets. We evaluated our method against\na leading sparse coding technique [21] and other state of the art methods. We evaluated both\nwith traditional PSNR and by devising a large scale human evaluation. This is a new real-world\napplication that can utilize online variational methods.\nThe choice of the inference algorithm depends on the usage case. Our results suggest that with\nmore computation time Gibbs sampling performs slightly better (based on human evaluation).\nIf speed is important, our online algorithms can be used without much loss.\nRegarding the evaluation metric, the standard in image analysis has been signal-to-noise ratio\n(PSNR). However, its practical relevance has been questioned [45]. The human eye is sensitive to\ndetails which are not always captured in this metric, and that is why we ran a human evaluation.\nOur experiments show that the signal-to-noise ratio is not necessarily consistent with human\njudgement.\nAs future work, our approach can be used as a building block in other, more complicated,\nprobabilistic models. For example, our approach could be developed into a time series to perform\nsuper-resolution on video or a hierarchical model can be built that fully generates the whole image\ninstead of patch based approach.\nREFERENCES\n[1] M. Aharon, M. Elad, and A. Bruckstein, \u201cSVD: An Algorithm for Designing Overcomplete Dictionaries for Sparse\nRepresentation,\u201d IEEE Transactions on Signal Processing, vol. 54, pp. 4311\u20134322, 2006.\nSeptember 25, 2012DRAFT"},{"page":27,"text":"27\n(a) High(b)\nLow\n(c) Bicubic\n(d) NNI (e) ScSR(f) BP\nFig. 10. (Natural Image 18) Test Set Results with SR ratio = 4.\n(a) High (b)\nLow\n(c) Bicubic\n(d) NNI (e) ScSR(f) BP\nFig. 11. (Natural Image 19) Test Set Results with SR ratio = 4.\nSeptember 25, 2012DRAFT"},{"page":28,"text":"28\nTABLE III\nTEST SET RESULTS WITH SR RATIO = 4. PSNR FOR THE ILLUMINANCE CHANNEL (HIGHER THE BETTER). BP:\nALGORITHM PRESENTED IN THIS PAPER WITH BETA PROCESS (BP) PRIOR TRAINED WITH GIBBS SAMPLER, SCSR:\nSUPER-RESOLUTION VIA SPARSE REPRESENTATION, NNI: NEAREST NEIGHBOR INTERPOLATION.\nPSNR\nBicubic NNI BilinearScSR BP\nN1 24.58 22.8023.7725.36 25.15\nN224.8123.5424.18 25.51 25.28\nN3 18.9718.43 18.6019.3919.38\nN4 18.1117.78 17.83 18.5018.37\nN521.1720.60 20.78 21.7221.54\nN6 22.1221.6821.84 22.4322.41\nN7 22.6221.62 22.20 23.1323.12\nN8 22.0020.8221.53 22.5922.47\nN922.90 22.2722.5923.10 23.16\nN10 21.3921.04 21.2221.53 21.55\nN1122.8221.2822.22 23.5123.41\nN12 24.0923.1023.5324.74 24.66\nN1321.13 20.4220.77 21.42 21.45\nN1423.06 22.5022.72 23.31 23.33\nN15 21.7921.15 21.4522.11 22.16\nN1622.5221.58 22.0523.00 22.92\nN1723.70 22.66 23.1924.2524.10\nN1825.21 24.38 24.7425.4825.62\nN1920.3319.55 19.8920.79 20.76\nN20 18.3117.92 18.00 18.5418.67\n[2] M. Elad and M. Aharon, \u201cImage Denoising Via Sparse and Redundant Representations Over Learned Dictionaries,\u201d IEEE\nTransactions on Image Processing, vol. 15, pp. 3736\u20133745, 2006.\n[3] J. Mairal, F. Bach, J. Ponce, G. Sapiro, and A. Zisserman, \u201cSupervised Dictionary Learning,\u201d Computing Research\nRepository, vol. abs\/0809.3, pp. 1033\u20131040, 2008.\n[4] \u2014\u2014, \u201cNonlocal sparse models for image restoration,\u201d in International Conference on Computer Vision, 2009, pp. 2272\u2013\n2279.\n[5] J. Mairal, M. Elad, and G. Sapiro, \u201cSparse Representation for Color Image Restoration,\u201d IEEE Transactions on Image\nProcessing, vol. 17, pp. 53\u201369, 2008.\n[6] J. Mairal, G. Sapiro, and M. Elad, \u201cLearning Multiscale Sparse Representations for Image and Video Restoration,\u201d\nMultiscale Modeling and Simulation, vol. 7, pp. 214\u2013241, 2008.\n[7] M. Ranzato, C. S. Poultney, S. Chopra, and Y. Lecun, \u201cEfficient Learning of Sparse Representations with an Energy-Based\nSeptember 25, 2012DRAFT"},{"page":29,"text":"29\nModel,\u201d in Neural Information Processing Systems, 2006, pp. 1137\u20131144.\n[8] J. Wright, A. Y. Yang, A. Ganesh, S. S. Sastry, and Y. Ma, \u201cRobust Face Recognition via Sparse Representation,\u201d IEEE\nTransactions on Pattern Analysis and Machine Intelligence, vol. 31, pp. 210\u2013227, 2009.\n[9] A. M. Bruckstein, D. L. Donoho, and M. Elad, \u201cFrom Sparse Solutions of Systems of Equations to Sparse Modeling of\nSignals and Images,\u201d Siam Review, vol. 51, pp. 34\u201381, 2009.\n[10] E. J. Cand\u00b4Rs and T. Tao, \u201cNear-Optimal Signal Recovery From Random Projections: Universal Encoding Strategies?\u201d\nIEEE Transactions on Information Theory, vol. 52, pp. 5406\u20135425, 2006.\n[11] J. Mairal, F. Bach, J. Ponce, and G. Sapiro, \u201cOnline dictionary learning for sparse coding,\u201d in International Conference\non Machine Learning, 2009, pp. 87\u2013696.\n[12] R. Raina, A. Battle, H. Lee, B. Packer, and A. Y. Ng, \u201cSelf-taught learning: transfer learning from unlabeled data,\u201d in\nInternational Conference on Machine Learning, 2007, pp. 759\u2013766.\n[13] S. Farsiu, M. Robinson, M. Elad, and P. Milanfar, \u201cFast and robust multiframe super resolution,\u201d Image Processing, IEEE\nTransactions on, vol. 13, no. 10, pp. 1327\u20131344, 2004.\n[14] M. Tipping and C. Bishop, \u201cBayesian image super-resolution,\u201d NIPS, 2003.\n[15] W. T. Freeman, T. R. Jones, and E. C. Pasztor, \u201cExample-based super-resolution,\u201d IEEE Computer Graphics and\nApplications, vol. 22, pp. 56\u201365, 2002.\n[16] K. I. Kim and Y. Kwon, \u201cSingle-image super-resolution using sparse regression and natural image prior,\u201d IEEE Transactions\non Pattern Analysis and Machine Intelligence, vol. 32, pp. 1127\u20131133, 2010.\n[17] J. Sun, N. Zheng, H. Tao, and H. Shum, \u201cImage hallucination with primal sketch priors,\u201d CVPR, 2003.\n[18] Y. HaCohen, R. Fattal, and D. Lischinski, \u201cImage upsampling via texture hallucination,\u201d in IEEE International Conference\non Computational Photography, 2010.\n[19] J. Sun, J. Zhu, and M. F. Tappen, \u201cContext-constrained hallucination for image super-resolution,\u201d in Computer Vision and\nPattern Recognition, 2010, pp. 231\u2013238.\n[20] D. Glasner, S. Bagon, and M. Irani, \u201cSuper-resolution from a single image,\u201d in International Conference on Computer\nVision, 2009, pp. 349\u2013356.\n[21] J. Yang, J. Wright, T. Huang, and Y. Ma, \u201cImage super-resolution via sparse representation,\u201d Image Processing, IEEE\nTransactions on, vol. 19, no. 11, pp. 2861\u20132873, 2010.\n[22] B. Chen, G. Polatkan, G. Sapiro, D. Dunson, and L. Carin, \u201cThe hierarchical beta process for convolutional factor analysis\nand deep learning,\u201d in Proceedings of the 28th International Conference on Machine Learning (ICML-11), ser. ICML \u201911,\nJune 2011, pp. 361\u2013368.\n[23] F. Doshi-Velez, K. T. Miller, J. Van Gael, and Y. W. Teh, \u201cVariational inference for the indian buffet process,\u201d in AISTATS,\n2009.\n[24] Z. Ghahramani and K. David, \u201cInfinite Sparse Factor Analysis and Infinite Independent Components Analysis,\u201d in\nIndependent Component Analysis, 2007, pp. 381\u2013388.\n[25] T. L. Griffiths and Z. Ghahramani, \u201cInfinite latent feature models and the indian buffet process,\u201d in NIPS, 2005.\n[26] J. Paisley and L. Carin, \u201cNonparametric factor analysis with beta process priors,\u201d in ICML, 2009.\n[27] R. Thibaux and M. I. Jordan, \u201cHierarchical beta processes and the indian buffet process,\u201d AISTATS, 2007.\n[28] M. Zhou, H. Chen, J. Paisley, L. Ren, G. Sapiro, and L. Carin, \u201cNon-parametric bayesian dictionary learning for sparse\nimage representations 1,\u201d NIPS, 2009.\nSeptember 25, 2012DRAFT"},{"page":30,"text":"30\n[29] M. Zhou, H. Yang, G. Sapiro, D. Dunson, and L. Carin, \u201cDependent hierarchical beta process for image interpolation and\ndenoising,\u201d Proc. Artificial Intelligence and Statistics (AISTATS), 2011.\n[30] S. Ghosh, A. B. Ungureanu, E. B. Sudderth, D. M. Blei, and M. Stanley, \u201cSpatial distance dependent chinese restaurant\nprocesses for image segmentation,\u201d NIPS, pp. 1\u20139, 2011.\n[31] S. Ghosh and E. B. Sudderth, \u201cNonparametric learning for layered segmentation of natural images,\u201d IEEE Conference on\ncomputer vision and Pattern Recognition, 2012.\n[32] J. J. Kivinen, E. B. Sudderth, and M. I. Jordan, \u201cLearning multiscale representations of natural scenes using dirichlet\nprocesses,\u201d IEEE 11th International Conference on Computer Vision, 2007.\n[33] T. L. Griffiths and Z. Ghahramani, \u201cThe indian buffet process: An introduction and review,\u201d JMLR, vol. 12, pp. 1185\u20131224,\n2011.\n[34] C. P. Robert and G. Casella, Monte Carlo statistical methods. Springer New York, 2004.\n[35] M. Jordan, Z. Ghahramani, T. Jaakkola, and L. Saul, \u201cAn introduction to variational methods for graphical models,\u201d\nMachine learning, 1999.\n[36] M. Sato, \u201cOn-line model selection based on the variational Bayes,\u201d Neural Computation, 2000.\n[37] M. D. Hoffman, D. M. Blei, and F. Bach, \u201cOnline learning for latent dirichlet allocation,\u201d in NIPS, 2010.\n[38] C. Wang, J. Paisley, and D. Blei, \u201cOnline variational inference for the hierarchical dirichlet process,\u201d AISTATS, 2011.\n[39] C. Bishop, Pattern recognition and machine learning. Springer New York, 2006.\n[40] Y. Teh, M. Jordan, M. Beal, and D. Blei, \u201cHierarchical dirichlet processes,\u201d Journal of the American Statistical Association,\n2006.\n[41] H. Robbins and S. Monro, \u201cA stochastic approximation method,\u201d The Annals of Mathematical Statistics, vol. 22, no. 3,\npp. 400\u2013407, 1951.\n[42] S. Amari, \u201cNatural gradient works efficiently in learning,\u201d Neural computation, 1998.\n[43] S. Mallat and G. Yu, \u201cSuper-Resolution With Sparse Mixing Estimators,\u201d IEEE Transactions on Image Processing, vol. 19,\npp. 2889\u20132900, 2010.\n[44] R. Fattal, \u201cImage upsampling via imposed edge statistics,\u201d ACM Transactions on Graphics, vol. 26, 2007.\n[45] Z. Wang and A. Bovik, \u201cMean squared error: love it or leave it? a new look at signal fidelity measures,\u201d Signal Processing\nMagazine, IEEE, vol. 26, no. 1, pp. 98\u2013117, 2009.\n[46] L. Bottou, \u201cOnline learning and stochastic approximations,\u201d 1998.\nSeptember 25, 2012DRAFT"}],"fullTextUrl":"https:\/\/www.researchgate.net\/profile\/Mingyuan_Zhou\/publication\/230996489_A_Bayesian_Nonparametric_Approach_to_Image_Super-Resolution\/links\/004635320936583c57000000.pdf","widgetId":"rgw34_56ab9f2c79194"},"id":"rgw34_56ab9f2c79194","partials":[],"templateName":"publicliterature\/stubs\/PublicationText.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationText.html?publicationUid=230996489&hide=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationDetailAd":{"data":{"googleDfpSlot":null,"widgetId":"rgw35_56ab9f2c79194"},"id":"rgw35_56ab9f2c79194","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAd.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAd.html?publicationUid=230996489&slotId=336x280_Publications_ATF_Right&collapseSlotMode=never&fallbackContainerEnabled=1","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationRelations":null,"publicationRelationsReverse":null,"publicationUid":230996489,"showSignUpDialog":false,"selectNewSignUpDialog":false,"publicationQuestions":null,"publicationCitations":null,"publicationReviewPromo":null,"publicationUsedInReviews":null,"publicationPdfJsReader":{"data":{"isPreview":false,"licenseUrl":null,"licenseInfo":null,"defaultLinkData":{"linkId":"004635320936583c57000000","name":"Mingyuan Zhou","date":"Mar 12, 2014 ","nameLink":"profile\/Mingyuan_Zhou","filename":"","downloadLink":"https:\/\/www.researchgate.net\/profile\/Mingyuan_Zhou\/publication\/230996489_A_Bayesian_Nonparametric_Approach_to_Image_Super-Resolution\/links\/004635320936583c57000000.pdf?inViewer=0&pdfJsDownload=0&origin=publication_detail","viewerUrl":"https:\/\/www.researchgate.net\/profile\/Mingyuan_Zhou\/publication\/230996489_A_Bayesian_Nonparametric_Approach_to_Image_Super-Resolution\/links\/004635320936583c57000000.pdf?inViewer=1&pdfJsDownload=1&origin=publication_detail","downloadHash":"6c839dc3ebe02458fd29754ad0ddc084","showFileSizeNote":false,"fileSize":"3.46 MB","noFollow":false,"isDefault":true,"doi":null},"displayableLinks":[{"linkId":"004635320936583c57000000","name":"Mingyuan Zhou","date":"Mar 12, 2014 ","nameLink":"profile\/Mingyuan_Zhou","filename":"","downloadLink":"https:\/\/www.researchgate.net\/profile\/Mingyuan_Zhou\/publication\/230996489_A_Bayesian_Nonparametric_Approach_to_Image_Super-Resolution\/links\/004635320936583c57000000.pdf?inViewer=0&pdfJsDownload=0&origin=publication_detail","viewerUrl":"https:\/\/www.researchgate.net\/profile\/Mingyuan_Zhou\/publication\/230996489_A_Bayesian_Nonparametric_Approach_to_Image_Super-Resolution\/links\/004635320936583c57000000.pdf?inViewer=1&pdfJsDownload=1&origin=publication_detail","downloadHash":"6c839dc3ebe02458fd29754ad0ddc084","showFileSizeNote":false,"fileSize":"3.46 MB","noFollow":false,"isDefault":true,"doi":null}],"hasDisplayableLinks":false,"reader":{"data":{"pdfCommentsActive":false,"publicationType":"Article","onlyRenderFirstPage":false,"readMoreExperimentGoal":"goalPublicationPdfClicksReadMore","readMoreExperimentViewId":null,"comments":null,"figures":[{"props":{"position":"float","orientation":"portrait","coords":"pag:4:rect:72.00,198.63,24.07,8.02","ordinal":"1"},"assetId":"AS:300542623535109@1448666353759"},{"props":{"position":"float","orientation":"portrait","coords":"pag:7:rect:72.00,260.45,24.07,8.02","ordinal":"2"},"assetId":"AS:300542623535110@1448666353789"},{"props":{"position":"float","orientation":"portrait","coords":"pag:15:rect:72.00,281.10,468.00,39.51","ordinal":"3"},"assetId":"AS:300542623535111@1448666353817"},{"props":{"position":"float","orientation":"portrait","coords":"pag:20:rect:72.00,386.49,24.28,8.02","ordinal":"4"},"assetId":"AS:300542623535112@1448666353843"},{"props":{"position":"float","orientation":"portrait","coords":"pag:22:rect:72.00,680.54,468.00,39.51","ordinal":"6"},"assetId":"AS:300542623535116@1448666353934"}],"figureAssetIds":["AS:300542623535109@1448666353759","AS:300542623535110@1448666353789","AS:300542623535111@1448666353817","AS:300542623535112@1448666353843","AS:300542623535116@1448666353934"],"figureOverlayUrls":{"clickOnOverlay":"publication.PublicationFigures.html?_sg=rZtRr-zJQIf9PZlJn3qom22TBDoy1HHfqfY_1vtoaMetf4lNnwSPEQZYBFJu2_NEzx72pg0IL4Jfe06Q1OkODA.INwYhHa2Er9qceJm_I1QTLKj9gKO3l_544noSZvLNdwF5NUOxJaUXQo1p0niTZwraZLeGEPf4xgRAEcLkykBlA","clickOnPill":"publication.PublicationFigures.html?_sg=roZuZMoC7LSdHp8DFUgprsMG9wU_WhN3Dyo7CjNPSpGpARq_LG1vT_VqeWJNSI2QLYMDBFd4pTmonG-ykDg7vA.ZWBytUyf3AR0VRWv3rP6_f02EmVY6_RBOiR_vuE3hg7Q9qLHG60SqhDM6CcHCie9EEy3FzXSwhIFRNuoQxdVPw"},"canSelect":false,"javascriptPath":"https:\/\/www.researchgate.net\/c\/o1q2er\/","downloadUrl":"https%3A%2F%2Fwww.researchgate.net%2Fprofile%2FMingyuan_Zhou%2Fpublication%2F230996489_A_Bayesian_Nonparametric_Approach_to_Image_Super-Resolution%2Flinks%2F004635320936583c57000000.pdf%3FinViewer%3D1%26pdfJsDownload%3D1%26origin%3Dpublication_detail","viewerUrl":"https:\/\/www.researchgate.net\/c\/o1q2er\/javascript\/lib\/pdfjs\/web\/viewer.html","commentEndpoint":"https:\/\/www.researchgate.net\/rgformat\/api\/comment","experimentEndpoint":"https:\/\/www.researchgate.net\/rgformat\/api\/experiment?key=c5wDJu5m0z95Cv3xC79XwJjQC3S_5XUN2x8u4NYaqbBMAvpcQbSRGpkdQJdFD7x-j-1Wo7G1TCJgbzkFb_jKVg","urlHash":"2ab438d6bb5b36ee60f7bb81f9838a62","downloadTrackUrl":"application.PdfJsReader.ajaxTrackDownload.html?msrp=tpoi9HlF3PTNJeINunAqVGz8ty_-nei5gKZD7bFrIVXotBaVz_ozzk_lOUCLqNGG5V0ov5hvUdsLtJLSTyAlJSIH0IiuZM0M8uIoxicdVOU.ozslT8aITKCZ5ctabMFbee0ktB51Bx0E4GWwXFEWAzMdOOWr1tFT3SjqXQ6soI4SEhHcGQRkyqZ4tNN4bFZuGA.Dg6Zk1b9cWGELISOXV6rUOHNXxLgsbxCW3k14TWIrZ91Zi1cZ9fvRVMTKeKXZ8_BkCCupNn10YPjBW-R-uNE2Q","viewportMilestoneTrackUrl":"application.PdfJsReader.ajaxTrackViewportMilestone.html","linkId":"004635320936583c57000000","trackedDownloads":{"004635320936583c57000000":{"v":false,"d":false}},"assetId":"AS:102772175278080@1401514204330","readerDocId":"6280195","assetType":"fulltext","interactionType":{"comment":"comment","highlight":"highlight"},"publicationUid":230996489,"commentCursorPromo":null,"widgetId":"rgw37_56ab9f2c79194"},"id":"rgw37_56ab9f2c79194","partials":[],"templateName":"application\/stubs\/PdfJsReader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PdfJsReader.html?fileHref=https%3A%2F%2Fwww.researchgate.net%2Fprofile%2FMingyuan_Zhou%2Fpublication%2F230996489_A_Bayesian_Nonparametric_Approach_to_Image_Super-Resolution%2Flinks%2F004635320936583c57000000.pdf%3FinViewer%3D1%26pdfJsDownload%3D1%26origin%3Dpublication_detail&assetId=AS%3A102772175278080%401401514204330&publicationUid=230996489&linkId=004635320936583c57000000&onlyShowFirstPage=0","viewClass":null,"yuiModules":["css-pow-application-PdfJsReader"],"stylesheets":["pow\/application\/PdfJsReader.css"],"_isYUI":true},"showHeader":true,"title":"A Bayesian Nonparametric Approach to Image Super-Resolution","publicationType":"Article","downloadTrackUrl":"publicliterature.PublicationInlineReader.ajaxTrackDownload.html?msrp=plBZZRKNEJNbQFK5tyHRpDtGmlPxkqzzjIdQCUSa3WPHHLR0TyUGsFd8P4zZ3BS4lhps59z55OIfgaOskeWZPne0pNIqixORzDvWqawDPeU.umx3FmPNFZoJV9llNFbWyivpAf-TcpPBsZ_brD6t-U6NBHis_dsEMGpl-FHTyr0vbHb9RDmuQVSo6XdJHAl5Og.FNHXSCuH7cR1YLPgBHOOSXq7C74EWtt_niCvw97nSC2lgwrJXNQFGAlj3Q_JpR4tp2fja79zMOVoLhGhFUqQsA","publicationUid":230996489,"trackedDownloads":{"004635320936583c57000000":{"v":false,"d":false}},"inlinePdf":false,"publicationComments":null,"showDownloadButton":true,"socialShare":{"data":{"shareItems":[{"data":{"name":"Facebook","url":"http:\/\/www.facebook.com\/share.php?u={{url}}{{#title}}&t={{title}}{{\/title}}","width":600,"height":350,"useUtmTags":true,"utmSource":"facebook","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareFacebook.ajaxTrackSocialShare.html","widgetId":"rgw39_56ab9f2c79194"},"id":"rgw39_56ab9f2c79194","partials":{"shareIcon":"application\/stubs\/partials\/shareFacebookBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareFacebook.html?provider=Facebook&shareIcon=shareIconBlog&utmSource=facebook&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"Twitter","url":"http:\/\/twitter.com\/intent\/tweet?text={{#title}}{{title}}: {{\/title}}{{url}}&via=researchgate","width":600,"height":350,"useUtmTags":true,"utmSource":"twitter","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareTwitter.ajaxTrackSocialShare.html","widgetId":"rgw40_56ab9f2c79194"},"id":"rgw40_56ab9f2c79194","partials":{"shareIcon":"application\/stubs\/partials\/shareTwitterBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareTwitter.html?provider=Twitter&shareIcon=shareIconBlog&utmSource=twitter&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"Google+","url":"https:\/\/plus.google.com\/share?url={{url}}","width":600,"height":600,"useUtmTags":true,"utmSource":"googleplus","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareGooglePlus.ajaxTrackSocialShare.html","widgetId":"rgw41_56ab9f2c79194"},"id":"rgw41_56ab9f2c79194","partials":{"shareIcon":"application\/stubs\/partials\/shareGooglePlusBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareGooglePlus.html?provider=Google%2B&shareIcon=shareIconBlog&utmSource=googleplus&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"LinkedIn","url":"http:\/\/www.linkedin.com\/shareArticle?mini=true&url={{url}}{{#title}}&title={{title}}{{\/title}}&source=ResearchGate","width":520,"height":570,"useUtmTags":true,"utmSource":"linkedin","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareLinkedIn.ajaxTrackSocialShare.html","widgetId":"rgw42_56ab9f2c79194"},"id":"rgw42_56ab9f2c79194","partials":{"shareIcon":"application\/stubs\/partials\/shareLinkedInBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareLinkedIn.html?provider=LinkedIn&shareIcon=shareIconBlog&utmSource=linkedin&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"Reddit","url":"https:\/\/www.reddit.com\/submit?url={{url}}{{#title}}&title={{title}}{{\/title}}","width":600,"height":600,"useUtmTags":true,"utmSource":"reddit","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareReddit.ajaxTrackSocialShare.html","widgetId":"rgw43_56ab9f2c79194"},"id":"rgw43_56ab9f2c79194","partials":{"shareIcon":"application\/stubs\/partials\/shareRedditBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareReddit.html?provider=Reddit&shareIcon=shareIconBlog&utmSource=reddit&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true}],"widgetId":"rgw38_56ab9f2c79194"},"id":"rgw38_56ab9f2c79194","partials":[],"templateName":"application\/stubs\/SocialShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.SocialShare.html?campaign=shareFullTextPublication&trackClick=1&shareIcon=shareIconBlog","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw36_56ab9f2c79194"},"id":"rgw36_56ab9f2c79194","partials":[],"templateName":"publicliterature\/stubs\/PublicationInlineReader.html","templateExtensions":["generalHelpers"],"attrs":{"showFulltextDownloadedSignupDialog":true,"preSignUpDialogContext":null,"requestFulltext":false},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationInlineReader.html","viewClass":"views.publicliterature.PublicationInlineReaderView","yuiModules":["rg.views.publicliterature.PublicationInlineReaderView","css-pow-publicliterature-PublicationInlineReader"],"stylesheets":["pow\/publicliterature\/PublicationInlineReader.css"],"_isYUI":true},"useFulltextOptimizedLayout":false,"publicationActions":null,"requestFulltextPromo":null,"currentUrl":"publication\/230996489_A_Bayesian_Nonparametric_Approach_to_Image_Super-Resolution","isLeaderboardAd":false,"enableStickyBox":null,"googleDfpSlotMobileBottom":null,"fullTextExitPopup":null,"showExitPopupDialog":false,"widgetId":"rgw2_56ab9f2c79194"},"id":"rgw2_56ab9f2c79194","partials":{"romeo_legal_notice":"publicliterature\/stubs\/partials\/romeo_legal_notice.html"},"templateName":"publicliterature\/stubs\/PublicPublicationDetails_NewLayout.html","templateExtensions":["generalHelpers"],"attrs":{"publicationUid":230996489},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicPublicationDetailsOld.html?publicationUid=230996489&isTestOldDesign=0","viewClass":"views.publicliterature.PublicPublicationDetailsOldView","yuiModules":["rg.views.publicliterature.PublicPublicationDetailsOldView"],"stylesheets":[],"_isYUI":true},"widgetId":"rgw1_56ab9f2c79194"},"id":"rgw1_56ab9f2c79194","partials":[],"templateName":"publicliterature\/stubs\/PublicPublicationDetails.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicPublicationDetails.html","viewClass":"views.publicliterature.PublicPublicationDetailsView","yuiModules":["rg.views.publicliterature.PublicPublicationDetailsView"],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"uaClass":"","headPrefix":[],"rootUrl":"https:\/\/www.researchgate.net\/","requestToken":"jYdNmHg\/\/uTnAHKGe0YB6+eiP5f9BHGtPOhgm096z\/SYL9DlETYTO0HBwFyU0PbJq14idi4r7xjwhOwKRjaqdhkJjdGsKBbIyQhNf9M7fjAR4NPKevKQHs+WBqbTY9ETq+Ys8B1oOrWhkbF8RSdUcYScXF4PJyva7tr2MtKtmLKLC+1\/GEUIwBLXZ1ZpUE0NBqTgANS+g+ffnCniU3mOXc09xACaqYOjI03sThlQQEeQ0UnhLp+WJ3gMr3SuFpi5niAQ+UIw91Pf6Wz9N\/ruTtjAGbcaiF4toZzJanTGLGA=","faviconCdnUrl":"https:\/\/c5.rgstatic.net\/m\/2390829798215018\/images\/favicon.ico","headerOutput":"<noscript><\/noscript><link rel=\"canonical\" href=\"https:\/\/www.researchgate.net\/publication\/230996489_A_Bayesian_Nonparametric_Approach_to_Image_Super-Resolution\" \/>\n<link rel=\"dns-prefetch\" href=\"\/\/c5.rgstatic.net\" \/>\n<link rel=\"dns-prefetch\" href=\"\/\/i1.rgstatic.net\" \/>\n<meta property=\"twitter:card\" content=\"summary\" \/>\n<meta property=\"twitter:site\" content=\"@ResearchGate\" \/>\n<meta property=\"og:title\" content=\"A Bayesian Nonparametric Approach to Image Super-Resolution\" \/>\n<meta property=\"og:description\" content=\"Super-resolution methods form high-resolution images from low-resolution\nimages. In this paper, we develop a new Bayesian nonparametric model for\nsuper-resolution. Our method uses a beta-Bernoulli...\" \/>\n<meta property=\"og:site_name\" content=\"ResearchGate\" \/>\n<meta property=\"og:image\" content=\"https:\/\/i1.rgstatic.net\/publication\/230996489_A_Bayesian_Nonparametric_Approach_to_Image_Super-Resolution\/links\/004635320936583c57000000\/smallpreview.png\" \/>\n<meta property=\"og:url\" content=\"https:\/\/www.researchgate.net\/publication\/230996489_A_Bayesian_Nonparametric_Approach_to_Image_Super-Resolution\" \/>\n<meta property=\"rg:id\" content=\"PB:230996489\" \/>\n<meta name=\"DC.identifier\" scheme=\"DCTERMS.URI\" content=\"http:\/\/dx.doi.org\/10.1109\/TPAMI.2014.2321404\" \/>\n<meta name=\"gs_meta_revision\" content=\"1.1\" \/>\n<meta name=\"citation_title\" content=\"A Bayesian Nonparametric Approach to Image Super-Resolution\" \/>\n<meta name=\"citation_author\" content=\"Gungor Polatkan\" \/>\n<meta name=\"citation_author\" content=\"Mingyuan Zhou\" \/>\n<meta name=\"citation_author\" content=\"Lawrence Carin\" \/>\n<meta name=\"citation_author\" content=\"David Blei\" \/>\n<meta name=\"citation_author\" content=\"Ingrid Daubechies\" \/>\n<meta name=\"citation_pmid\" content=\"26353246\" \/>\n<meta name=\"citation_publication_date\" content=\"2012\/09\/22\" \/>\n<meta name=\"citation_journal_title\" content=\"IEEE Transactions on Pattern Analysis and Machine Intelligence\" \/>\n<meta name=\"citation_issn\" content=\"0162-8828\" \/>\n<meta name=\"citation_volume\" content=\"37\" \/>\n<meta name=\"citation_issue\" content=\"2\" \/>\n<meta name=\"citation_doi\" content=\"10.1109\/TPAMI.2014.2321404\" \/>\n<meta name=\"citation_pdf_url\" content=\"https:\/\/www.researchgate.net\/profile\/Mingyuan_Zhou\/publication\/230996489_A_Bayesian_Nonparametric_Approach_to_Image_Super-Resolution\/links\/004635320936583c57000000.pdf\" \/>\n<meta name=\"citation_abstract_html_url\" content=\"https:\/\/www.researchgate.net\/publication\/230996489_A_Bayesian_Nonparametric_Approach_to_Image_Super-Resolution\" \/>\n<meta name=\"citation_fulltext_html_url\" content=\"https:\/\/www.researchgate.net\/publication\/230996489_A_Bayesian_Nonparametric_Approach_to_Image_Super-Resolution\" \/>\n<meta name=\"viewport\" content=\"width=device-width,initial-scale=1\" \/>\n<link href=\"\/\/c5.rgstatic.net\/m\/22664197317151888\/styles\/rg.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/21004998181197492\/styles\/rg2.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<!--[if lt IE 9]><link href=\"\/\/c5.rgstatic.net\/m\/238176252723686\/styles\/ie.css\" type=\"text\/css\" rel=\"stylesheet\"\/><![endif]-->\n<link href=\"\/\/c5.rgstatic.net\/m\/217752362214895\/styles\/modules\/publicprofile.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/215868066921738\/styles\/pow\/publicliterature\/FigureList.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/21993347442549\/styles\/pow\/publicliterature\/FollowPublicationPromo.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/282514599719602\/styles\/pow\/application\/PdfJsReader.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/23819663151220\/styles\/pow\/publicliterature\/PublicationInlineReader.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<script src=\"\/\/c5.rgstatic.net\/m\/2321000301012716\/javascript\/vendor\/webfontloader\/webfontloader.js\" type=\"text\/javascript\"><\/script>\n <script>(function(i,s,o,g,r,a,m){i[\"GoogleAnalyticsObject\"]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,\"script\",\"\/\/www.google-analytics.com\/analytics.js\",\"ga\");\n ga(\"create\",\"UA-58591210-1\");ga(\"set\",\"anonymizeIp\",true);ga('set', 'dimension1', 'publication full-text');ga('set', 'dimension2', 'Article');ga('set', 'dimension3', 'Logged out');ga('set', 'dimension4', 'https');ga(\"send\",\"pageview\");<\/script>\n","webfont":"<noscript><\/noscript><script> WebFontConfig = { custom: { families: ['source_sans_pro_italic', 'source_sans_pro_bold', 'source_sans_pro', 'martel'], urls : ['\/\/c5.rgstatic.net\/m\/231392577336386\/styles\/fonts.css'] } }; WebFont.load(WebFontConfig); <\/script>\n","correlationId":"rgreq-43ff719f-a420-494e-8989-aed204076a2e","accountId":null,"module":"publicliterature","action":"publicliterature.PublicPublicationDetails","page":"publicationDetail","product":"publications","backendTime":739,"continent":"Asia","stylesHome":"\/\/c5.rgstatic.net\/m\/","staticHost":"c5.rgstatic.net","useEarlyFlush":false,"longRunningRequestIdentifier":"LongRunningRequest.publicliterature.PublicPublicationDetails","longRunningRequestFp":"e9e5bbe1366c7ee8c8e41d02f793c884ac9be19b","widgetId":"rgw44_56ab9f2c79194"},"id":"rgw44_56ab9f2c79194","partials":[],"templateName":"application\/stubs\/StaticHeader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.StaticHeader.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){
            Y.rg.core.pagespeed.Monitoring.monitorPage("\/\/glassmoni.researchgate.net", "publicliterature.PublicPublicationDetails.run.html.loggedOut.get", "59de9668d07aeb77ab4de5f24d382b5d199d2437", "rgreq-43ff719f-a420-494e-8989-aed204076a2e", "e1cb480f333bddcbeb532dacde1852c9ef6978ba");
        
            Y.rg.core.pagespeed.Monitoring.monitorPage("\/\/glassmoni.researchgate.net", "publicationDetail.loggedOut", "ed1993d9e20f6cefa83edacaa24401a18c071aea", "rgreq-43ff719f-a420-494e-8989-aed204076a2e", "e1cb480f333bddcbeb532dacde1852c9ef6978ba");
        })();
(function(){Y.rg.createInitialWidget({"data":{"year":"2016","inlinePromo":null,"isAdmin":false,"contactUrl":"https:\/\/www.researchgate.net\/contact","aboutUsUrl":"https:\/\/www.researchgate.net\/about","widgetId":"rgw45_56ab9f2c79194"},"id":"rgw45_56ab9f2c79194","partials":[],"templateName":"application\/stubs\/DefaultFooter.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.DefaultFooter.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"headerLogin":{"data":{"urlAfterLogin":"publication\/230996489_A_Bayesian_Nonparametric_Approach_to_Image_Super-Resolution","requestToken":"XNDKWbI90WSjWCSkczujALMoubE70A\/7ORH2xmO53QISrANAiAcuwdgrciEiLpwnzIJsez5Ie3ZdSMBuKLXtor8uy6s\/\/v+bJ0dzVV68CV3Ponw9oBHKvqVJL5uzqxIfpeQIBQpytLp9xf8F2Xtf6Il9lkRpnFg1vKB0A5xL1+7SeWsAfd2kWtA88RBqIHRde\/HJc4TZFvJp\/mRLP7UYWUxpSa8gNEyE67v5lEx328y29BnwPpJuuMOzNRPCeAKlcr9VPvgSxhT4\/bOKN4ryhUmacJPj6hqDTPICJFdN7i0=","loginUrl":"https:\/\/www.researchgate.net\/application.Login.html","signupUrl":"https:\/\/www.researchgate.net\/signup.SignUp.html?ev=su_chnl_index&hdrsu=1&_sg=N0niNpS6e-F-qdGCcL-LqPFIEFVAAcAsax4KCtv3Grap67HAW7vcW_B4OYltFzP6","encodedUrlAfterLogin":"cHVibGljYXRpb24vMjMwOTk2NDg5X0FfQmF5ZXNpYW5fTm9ucGFyYW1ldHJpY19BcHByb2FjaF90b19JbWFnZV9TdXBlci1SZXNvbHV0aW9u","signupCallToAction":"Join for free","widgetId":"rgw47_56ab9f2c79194"},"id":"rgw47_56ab9f2c79194","partials":{"partial":"application\/stubs\/partials\/headerLoginDefault.html"},"templateName":"application\/stubs\/HeaderLogin.html","templateExtensions":[],"attrs":{"goal":"milestoneHeaderLoginSeen"},"widgetUrl":"https:\/\/www.researchgate.net\/application.HeaderLogin.html","viewClass":"views.application.HeaderLoginView","yuiModules":["rg.views.application.HeaderLoginView"],"stylesheets":[],"_isYUI":true},"cookieConsent":null,"logoSvgSrc":"https:\/\/c5.rgstatic.net\/m\/235107188705592\/images\/template\/brand-header-logo.svg","logoFallbackSrc":"https:\/\/c5.rgstatic.net\/m\/238113351022438\/images\/template\/brand-header-logo.png","widgetId":"rgw46_56ab9f2c79194"},"id":"rgw46_56ab9f2c79194","partials":{"schemaSocialProfiles":"application\/stubs\/partials\/schemaSocialProfiles.html"},"templateName":"application\/stubs\/HeaderLoggedOut.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.HeaderLoggedOut.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"logEvent":"su_banner","specialCopy":false,"widgetId":"rgw48_56ab9f2c79194"},"id":"rgw48_56ab9f2c79194","partials":[],"templateName":"application\/stubs\/LoggedOutBanner.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.LoggedOutBanner.html","viewClass":"views.application.LoggedOutBannerView","yuiModules":["rg.views.application.LoggedOutBannerView"],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.core.util.ParameterFilter.filter(["ev","cp","ch","ref","dbw","pli","loginT","uid","claimChannel","enrichId","enrichSource","utm_source","utm_medium","utm_campaign","el","ci"]);})();
});}); } else { throw 'YRG was not loaded when attaching widgets'; }</script><script> dataLayer = [{"pageCategory":"publication full-text","publicationType":"Article","eventCategory":"Publication page"}]; </script> <noscript><iframe src="//www.googletagmanager.com/ns.html?id=GTM-MKVKH7" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-MKVKH7');</script><script>(function(e){function n(n,t,o,a){"use strict";var i=e.document.createElement("link"),r=t||e.document.getElementsByTagName("script")[0],d=e.document.styleSheets;return i.rel="stylesheet",i.href=n,i.media="only x",a&&(i.onload=a),r.parentNode.insertBefore(i,r),i.onloadcssdefined=function(e){for(var t,o=0;d.length>o;o++)d[o].href&&d[o].href.indexOf(n)>-1&&(t=!0);t?e():setTimeout(function(){i.onloadcssdefined(e)})},i.onloadcssdefined(function(){i.media=o||"all"}),i}function t(e,n){e.onload=function(){e.onload=null,n&&n.call(e)},"isApplicationInstalled"in navigator&&"onloadcssdefined"in e&&e.onloadcssdefined(n)}var o=function(a,i){"use strict";if(a&&3===a.length){var r=e.Image,d=!(!document.createElementNS||!document.createElementNS("http://www.w3.org/2000/svg","svg").createSVGRect||!document.implementation.hasFeature("http://www.w3.org/TR/SVG11/feature#Image","1.1")||e.opera&&-1===navigator.userAgent.indexOf("Chrome")||-1!==navigator.userAgent.indexOf("Series40")),c=new r;c.onerror=function(){o.method="png",o.href=a[2],n(a[2])},c.onload=function(){var e=1===c.width&&1===c.height,r=a[e&&d?0:e?1:2];o.method=e&&d?"svg":e?"datapng":"png",o.href=r,t(n(r),i)},c.src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///ywAAAAAAQABAAACAUwAOw==",document.documentElement.className+=" grunticon"}};o.loadCSS=n,o.onloadCSS=t,e.grunticon=o})(this);grunticon(["https://c5.rgstatic.net/c/o1q2er/styles/icons/_header-ico.svg.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_header-ico.png.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_header-ico.fallback.scss"]);grunticon(["https://c5.rgstatic.net/c/o1q2er/styles/icons/_admin-ico.svg.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_admin-ico.png.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_admin-ico.fallback.scss"]);grunticon(["https://c5.rgstatic.net/c/o1q2er/styles/icons/_ico.svg.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_ico.png.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_ico.fallback.scss"]);</script></body>
</html>
