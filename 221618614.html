<!DOCTYPE html> <html lang="en" class="" id="rgw36_56ab9e8f16567"> <head > <meta charset="utf-8"/> <meta http-equiv="content-type" content="text/html; charset=UTF-8"/> <meta name="Rg-Request-Token" id="Rg-Request-Token" content="sGaA14RDmVKrzjONOvwEalBfO77upML1vMTcuX6U4dc9mhLH559miLMxSvBKg89L+Uc4zjHncN9iM69PnPAshhmD7St92pywFo5fFO5MVxnqCo0qHKpE23HPrHqFnm2IG7mPEV2bZTqPnzrrTUaUdBfJmXuD2D0A5EudB+qGVa3mYtk7SAyirypV2RGoyuu+loCqMsZ1Xtmj6F1Z+d4JqJJQ+bIiRqgQ4f+KmZHVoNPoFgRq6yxY06Qdk2jsuRyTNYT2ZSIz1YkcuLgaSD0EnAVqqQFPNfQdvr+BQTj4xAA="/> <meta http-equiv="expires" content="0"/> <link rel="apple-touch-icon" sizes="57x57" href="https://www.researchgate.net/apple-touch-icon-57x57.png"> <link rel="apple-touch-icon" sizes="60x60" href="https://www.researchgate.net/apple-touch-icon-60x60.png"> <link rel="apple-touch-icon" sizes="72x72" href="https://www.researchgate.net/apple-touch-icon-72x72.png"> <link rel="apple-touch-icon" sizes="76x76" href="https://www.researchgate.net/apple-touch-icon-76x76.png"> <link rel="apple-touch-icon" sizes="114x114" href="https://www.researchgate.net/apple-touch-icon-114x114.png"> <link rel="apple-touch-icon" sizes="120x120" href="https://www.researchgate.net/apple-touch-icon-120x120.png"> <link rel="apple-touch-icon" sizes="144x144" href="https://www.researchgate.net/apple-touch-icon-144x144.png"> <link rel="apple-touch-icon" sizes="152x152" href="https://www.researchgate.net/apple-touch-icon-152x152.png"> <link rel="apple-touch-icon" sizes="180x180" href="https://www.researchgate.net/apple-touch-icon-180x180.png"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-32x32.png" sizes="32x32"> <link rel="icon" type="image/png" href="https://www.researchgate.net/android-chrome-192x192.png" sizes="192x192"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-96x96.png" sizes="96x96"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-16x16.png" sizes="16x16"> <link rel="shortcut icon" type="image/x-icon" href="https://c5.rgstatic.net/m/2390829798215018/images/favicon.ico"/> <link rel="manifest" href="https://www.researchgate.net/manifest.json"> <meta name="msapplication-TileColor" content="#da532c"> <meta name="msapplication-TileImage" content="https://www.researchgate.net/mstile-144x144.png"> <meta name="theme-color" content="#444444"> <link rel="search" type="application/opensearchdescription+xml" title="ResearchGate search" href="https://www.researchgate.net/application.DownloadOpenSearchPlugin.html"/> <link rel="meta" type="application/rdf+xml" title="ICRA labels" href="https://www.researchgate.net/application.DownloadLabels.html"/> <link rel="http://oexchange.org/spec/0.8/rel/related-target" type="application/xrd+xml" href="https://www.researchgate.net/application.DownloadOExchange.html"/> <base href="https://www.researchgate.net/"/> <script>
    var rgConfig = {
        correlationId: "rgreq-305537ad-0791-4b0a-b6e3-6ed6a0606899",
        accountId: "",
        module: "publicliterature",
        action: "publicliterature.PublicPublicationDetails",
        page: "publicationDetail",
        product: "publications",
        continent: "Asia",
        stylesHome: "//c5.rgstatic.net/m/",
        staticHost: "c5.rgstatic.net",
        longRunningRequestIdentifier: "LongRunningRequest.publicliterature.PublicPublicationDetails",
        longRunningRequestFp: "e9e5bbe1366c7ee8c8e41d02f793c884ac9be19b"
    };
    window.rootUrl = "https://www.researchgate.net/";
</script> <link rel="canonical" href="https://www.researchgate.net/publication/221618614_The_Tradeoffs_of_Large_Scale_Learning" />
<link rel="dns-prefetch" href="//c5.rgstatic.net" />
<link rel="dns-prefetch" href="//i1.rgstatic.net" />
<meta property="twitter:card" content="summary" />
<meta property="twitter:site" content="@ResearchGate" />
<meta property="og:title" content="The Tradeoffs of Large Scale Learning." />
<meta property="og:description" content="This contribution develops a theoretical framework that takes into account the effect of approximate optimization on learning algorithms. The analysis shows distinct tradeoffs for the case of..." />
<meta property="og:site_name" content="ResearchGate" />
<meta property="og:image" content="https://i1.rgstatic.net/publication/221618614_The_Tradeoffs_of_Large_Scale_Learning/links/004635219281099d85000000/smallpreview.png" />
<meta property="og:url" content="https://www.researchgate.net/publication/221618614_The_Tradeoffs_of_Large_Scale_Learning" />
<meta property="rg:id" content="PB:221618614" />
<meta name="DC.identifier" scheme="DCTERMS.URI" content="http://dx.doi.org/" />
<meta name="gs_meta_revision" content="1.1" />
<meta name="citation_title" content="The Tradeoffs of Large Scale Learning." />
<meta name="citation_author" content="Léon Bottou" />
<meta name="citation_author" content="Olivier Bousquet" />
<meta name="citation_conference_title" content="Advances in Neural Information Processing Systems 20, Proceedings of the Twenty-First Annual Conference on Neural Information Processing Systems, Vancouver, British Columbia, Canada, December 3-6, 2007" />
<meta name="citation_publication_date" content="2007/01/01" />
<meta name="citation_volume" content="20" />
<meta name="citation_pdf_url" content="https://www.researchgate.net/profile/Olivier_Bousquet/publication/221618614_The_Tradeoffs_of_Large_Scale_Learning/links/004635219281099d85000000.pdf" />
<meta name="citation_abstract_html_url" content="https://www.researchgate.net/publication/221618614_The_Tradeoffs_of_Large_Scale_Learning" />
<meta name="citation_fulltext_html_url" content="https://www.researchgate.net/publication/221618614_The_Tradeoffs_of_Large_Scale_Learning" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<link href="//c5.rgstatic.net/m/22664197317151888/styles/rg.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/21004998181197492/styles/rg2.css" type="text/css" rel="stylesheet"/>
<!--[if lt IE 9]><link href="//c5.rgstatic.net/m/238176252723686/styles/ie.css" type="text/css" rel="stylesheet"/><![endif]-->
<link href="//c5.rgstatic.net/m/217752362214895/styles/modules/publicprofile.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/21993347442549/styles/pow/publicliterature/FollowPublicationPromo.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/282514599719602/styles/pow/application/PdfJsReader.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/23819663151220/styles/pow/publicliterature/PublicationInlineReader.css" type="text/css" rel="stylesheet"/>
<script src="//c5.rgstatic.net/m/2321000301012716/javascript/vendor/webfontloader/webfontloader.js" type="text/javascript"></script>
 <script>(function(i,s,o,g,r,a,m){i["GoogleAnalyticsObject"]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,"script","//www.google-analytics.com/analytics.js","ga");
 ga("create","UA-58591210-1");ga("set","anonymizeIp",true);ga('set', 'dimension1', 'publication full-text');ga('set', 'dimension2', 'Conference Paper');ga('set', 'dimension3', 'Logged out');ga('set', 'dimension4', 'https');ga("send","pageview");</script>
  <script> WebFontConfig = { custom: { families: ['source_sans_pro_italic', 'source_sans_pro_bold', 'source_sans_pro', 'martel'], urls : ['//c5.rgstatic.net/m/231392577336386/styles/fonts.css'] } }; WebFont.load(WebFontConfig); </script><noscript></noscript>

<title>The Tradeoffs of Large Scale Learning. (PDF Download Available)</title>
<meta name="description" content="Official Full-Text Publication: The Tradeoffs of Large Scale Learning. on ResearchGate, the professional network for scientists."/>
<meta name="keywords" content="scientific network, scientific platform, scientific community, research partner, research collaboration, journal articles, international collaboration, find researcher, lifescience researcher, interdisciplinary research, research collaboration"/>
</head>
<body class="use-svg-icons logged-out">
<div id="page-container">
<script type="text/javascript">var googletag = googletag || {}; googletag.cmd = googletag.cmd || [];
(function() { var gads = document.createElement("script"); gads.async = true; gads.type = "text/javascript"; var useSSL = "https:" == document.location.protocol; gads.src = (useSSL ? "https:" : "http:") + "//www.googletagservices.com/tag/js/gpt.js"; var node =document.getElementsByTagName("script")[0]; node.parentNode.insertBefore(gads, node); })();</script><div id="main" class="logged-out-header-support">
<div id="content" class="">

<noscript>
<div class="c-box-warning full-width-element" style="text-align: center; ">
    <div style="margin: auto; padding:10px;" class="container">
        <b>For full functionality of ResearchGate it is necessary to enable JavaScript.
            Here are the <a href="http://www.enable-javascript.com/" rel="nofollow" target="_blank">
                instructions how to enable JavaScript in your web browser</a>.</b>
    </div>
</div>
</noscript>

<div id="rgw1_56ab9e8f16567" itemscope itemtype="http://schema.org/ScholarlyArticle"><div class="publication-wrapper publication-wrapper-onecol" id="rgw2_56ab9e8f16567" itemscope itemtype="http://schema.org/ScholarlyArticle"> <div class="c-col-content"> <div class="c-content"> <div class="clearfix">  <div class="publication-header"> <div id="rgw5_56ab9e8f16567">  <div class="type-label"> Conference Paper   </div> <span class="Z3988" title="ctx_ver=Z39.88-2004&rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&rfr_id=info%3Asid%2Fresearchgate.net%3Aresearchgate&rft.atitle=The%20Tradeoffs%20of%20Large%20Scale%20Learning.&rft.title=Optimization%20for%20Machine%20Learning&rft.jtitle=Optimization%20for%20Machine%20Learning&rft.volume=20&rft.date=2007&rft.au=L%C3%A9on%20Bottou%2COlivier%20Bousquet&rft.genre=inProceedings"></span> <h1 class="pub-title" itemprop="name">The Tradeoffs of Large Scale Learning.</h1> <meta itemprop="headline" content="The Tradeoffs of Large Scale Learning.">  <meta itemprop="image" content="https://i1.rgstatic.net/publication/221618614_The_Tradeoffs_of_Large_Scale_Learning/links/004635219281099d85000000/smallpreview.png">  <div id="rgw7_56ab9e8f16567" class="publication-detail-author-list"> <div> <ul class="clearfix js-people-list">  <li id="rgw8_56ab9e8f16567"> <a href="researcher/7871008_Leon_Bottou" class="pub-detail-item author-item" itemprop="author" itemscope itemtype="http://schema.org/Person"> <div class="indent-left"> <div class="people-img">  <img src="https://c5.rgstatic.net/m/2951093203564/images/template/default/profile/profile_default_s.jpg" title="Léon Bottou" alt="Léon Bottou" height="20px" width="20px" style="height: 20px;"/>  </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Léon Bottou</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item   not-claimed " id="rgw9_56ab9e8f16567">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="researcher/7871008_Leon_Bottou"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="Léon Bottou" alt="Léon Bottou" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">       </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="researcher/7871008_Leon_Bottou" class="display-name">Léon Bottou</a>    </h5> <div class="truncate-single-line meta">   </div>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>  <li id="rgw10_56ab9e8f16567" itemprop="author" itemscope itemtype="http://schema.org/Person"> <a itemprop="sameAs" href="profile/Olivier_Bousquet" class="pub-detail-item account-item"> <div class="indent-left"> <div class="people-img"> <img  src="https://i1.rgstatic.net/ii/profile.image/AS%3A276948442992654%401443041062828_m" title="Olivier Bousquet" alt="Olivier Bousquet" height="20px" width="20px" style="height: 20px;"/> </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Olivier Bousquet</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item  remove-action-indent   " id="rgw11_56ab9e8f16567" data-account-key="Olivier_Bousquet">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="profile/Olivier_Bousquet"> <img class="lazyload" data-src="https://i1.rgstatic.net/ii/profile.image/AS%3A276948442992654%401443041062828_l" title="Olivier Bousquet" alt="Olivier Bousquet" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">     </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="profile/Olivier_Bousquet" class="display-name">Olivier Bousquet</a>    </h5> <div class="truncate-single-line meta">   <a class="meta ga-top-coauthor-institution" href="institution/Google_Inc" title="Google Inc.">Google Inc.</a>     </div>  <a href="javascript:" class="btn btn-promote btn-large people-item-contact-author js-contact-author">Message author</a>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>   </ul> <div class="js-loading"></div>  </div> </div> <div class="pub-details js-pub-details">         Conference: Advances in Neural Information Processing Systems 20, Proceedings of the Twenty-First Annual Conference on Neural Information Processing Systems, Vancouver, British Columbia, Canada, December 3-6, 2007      <div class="pub-source"> Source: <a href="http://dblp.uni-trier.de/db/conf/nips/nips2007.html#BottouB07" rel="nofollow">DBLP</a> </div>  </div> <div id="rgw12_56ab9e8f16567" class="pub-abstract">  <div class="clearfix">   <div style="max-height: 54px;" class="js-expander-container js-expander-collapsed">  <p itemprop="description"> <strong>ABSTRACT</strong> <div>This contribution develops a theoretical framework that takes into account the effect of approximate optimization on learning algorithms. The analysis shows distinct tradeoffs for the case of small-scale and large-sc ale learning problems. Small-scale learning problems are subject to the usual approximation-estimation tradeoff. Large-scale learning problems are subject to a qualitatively different tradeoff involving the computational complexity of the underlying optimization algorithms in non-trivial ways.</div> </p>  </div>  </div>   </div>      <div class="action-container"> <div id="rgw13_56ab9e8f16567" class="follow-publication-promo"> <table> <tr> <td class="follow-publication-promo-text-cell"> <p>Get notified about updates to this publication</p> <a class="btn btn-large btn-promote js-follow-publication ga-follow-publication-new-promo">Follow publication</a> </td> <td> <div class="follow-publication-publication-image"></div> </td> </tr> </table> </div>  <div class="clear"></div> <div class="share-dialog-container" style="display: none;">  </div> </div> </div> <div style="margin-left: -20px; margin-right: -20px;">  </div> </div>  <div class="publication-detail-dfp-container rf"> <div id="rgw27_56ab9e8f16567">  </div> </div>  </div>  <div class="clearfix"> <div class="pdf-js-container clearfix " id="rgw28_56ab9e8f16567">  <div class="pdf-js-header js-sticky-header clear">  <a class="blue-link js-download rf btn btn-promote" href="https://www.researchgate.net/profile/Olivier_Bousquet/publication/221618614_The_Tradeoffs_of_Large_Scale_Learning/links/004635219281099d85000000.pdf?inViewer=0&amp;pdfJsDownload=0&amp;origin=publication_detail">Download full-text</a>  <h3>Full-text</h3> <span class="publication-info">  <span class="js-doi-container" style="display: none;"> DOI: <span class="js-doi"></span> &middot; </span> Available from: <a class="js-name" href="profile/Olivier_Bousquet">Olivier Bousquet</a>   </span>  </div>  <div class="social-share-container"><div id="rgw30_56ab9e8f16567" class="social-share js-social-share"> <div class="social-share-heading">Share</div>  <a id="rgw31_56ab9e8f16567" href="javascript:" title="Share on Facebook" class="link-nostyle js-share-item share-icon "  data-url="http://www.facebook.com/share.php?u={{url}}{{#title}}&amp;t={{title}}{{/title}}" data-width="600" data-height="350" data-name="Facebook"> <span class="share-icon ico-share-facebook-round reset-background ga-share-blog-facebook"></span> </a>  <a id="rgw32_56ab9e8f16567" href="javascript:" title="Share on Twitter" class="link-nostyle js-share-item share-icon "  data-url="http://twitter.com/intent/tweet?text={{#title}}{{title}}: {{/title}}{{url}}&amp;via=researchgate" data-width="600" data-height="350" data-name="Twitter"> <span class="share-icon ico-share-twitter-round reset-background ga-share-blog-twitter"></span> </a>  <a id="rgw33_56ab9e8f16567" href="javascript:" title="Share on Google+" class="link-nostyle js-share-item share-icon "  data-url="https://plus.google.com/share?url={{url}}" data-width="600" data-height="600" data-name="Google+"> <span class="share-icon ico-share-gplus-round reset-background ga-share-blog-gplus"></span> </a>  <a id="rgw34_56ab9e8f16567" href="javascript:" title="Share on LinkedIn" class="link-nostyle js-share-item share-icon "  data-url="http://www.linkedin.com/shareArticle?mini=true&amp;url={{url}}{{#title}}&amp;title={{title}}{{/title}}&amp;source=ResearchGate" data-width="520" data-height="570" data-name="LinkedIn"> <span class="share-icon ico-share-linkedin-round reset-background ga-share-blog-linkedin"></span> </a>  <a id="rgw35_56ab9e8f16567" href="javascript:" title="Share on Reddit" class="link-nostyle js-share-item share-icon "  data-url="https://www.reddit.com/submit?url={{url}}{{#title}}&amp;title={{title}}{{/title}}" data-width="600" data-height="600" data-name="Reddit"> <span class="share-icon ico-share-reddit reset-background ga-share-blog-reddit"></span> </a>  </div></div>    <iframe id="rgw29_56ab9e8f16567" src="https://www.researchgate.net/c/o1q2er/javascript/lib/pdfjs/web/viewer.html?file=https%3A%2F%2Fwww.researchgate.net%2Fprofile%2FOlivier_Bousquet%2Fpublication%2F221618614_The_Tradeoffs_of_Large_Scale_Learning%2Flinks%2F004635219281099d85000000.pdf%3FinViewer%3D1%26pdfJsDownload%3D1%26origin%3Dpublication_detail" allowfullscreen frameborder="0" style="width: 100%; height: 100%; box-sizing: border-box;"></iframe>    </div> <noscript> <div id="rgw26_56ab9e8f16567"  itemprop="articleBody">  <p>Page 1</p> <p>The Tradeoffs of Large Scale Learning<br />L´ eon Bottou<br />NEC laboratories of America<br />Princeton, NJ 08540, USA<br />leon@bottou.org<br />Olivier Bousquet<br />Google Z¨ urich<br />8002 Zurich, Switzerland<br />olivier.bousquet@m4x.org<br />Abstract<br />This contribution develops a theoretical framework that takes into account the<br />effect of approximate optimization on learning algorithms. The analysis shows<br />distinct tradeoffs for the case of small-scale and large-scale learning problems.<br />Small-scale learning problems are subject to the usual approximation–estimation<br />tradeoff. Large-scale learning problems are subject to a qualitatively different<br />tradeoff involving the computational complexity of the underlying optimization<br />algorithms in non-trivial ways.<br />1 Motivation<br />The computational complexity of learning algorithms has seldom been taken into account by the<br />learning theory. Valiant [1] states that a problem is “learnable” when there exists a probably approx-<br />imatively correct learning algorithm with polynomial complexity. Whereas much progress has been<br />made on the statistical aspect (e.g., [2, 3, 4]), very little has been told about the complexity side of<br />this proposal (e.g., [5].)<br />Computational complexity becomes the limiting factor when one envisions large amounts of training<br />data. Two important examples come to mind:<br />• Data mining exists because competitive advantages can be achieved by analyzing the<br />masses of data that describe the life of our computerized society. Since virtually every<br />computer generates data, the data volume is proportional to the available computing power.<br />Therefore one needs learning algorithms that scale roughly linearly with the total volume<br />of data.<br />• Artificial intelligence attempts to emulate the cognitive capabilities of human beings. Our<br />biological brains can learn quite efficiently from the continuous streams of perceptual data<br />generated by our six senses, using limited amounts of sugar as a source of power. This<br />observation suggests that there are learning algorithms whose computing time requirements<br />scale roughly linearly with the total volume of data.<br />This contribution finds its source in the idea that approximate optimization algorithms might be<br />sufficient for learning purposes. The first part proposes new decomposition of the test error where<br />an additional term represents the impact of approximate optimization. In the case of small-scale<br />learning problems, this decomposition reduces to the well known tradeoff between approximation<br />error and estimation error. In the case of large-scale learning problems, the tradeoff is more com-<br />plex because it involves the computational complexity of the learning algorithm. The second part<br />explores the asymptotic properties of the large-scale learning tradeoff for various prototypical learn-<br />ing algorithms under various assumptions regarding the statistical estimation rates associated with<br />the chosen objective functions. This part clearly shows that the best optimization algorithms are not<br />necessarily the best learning algorithms. Maybe more surprisingly, certain algorithms perform well<br />regardless of the assumed rate for the statistical estimation error.</p>  <p>Page 2</p> <p>2 Approximate Optimization<br />2.1 Setup<br />Following [6, 2], we consider a space of input-output pairs (x,y) ∈ X × Y endowed with a proba-<br />bility distribution P(x,y). The conditional distribution P(y|x) represents the unknown relationship<br />between inputs and outputs. The discrepancy between the predicted output ˆ y and the real output<br />y is measured with a loss function ℓ(ˆ y,y). Our benchmark is the function f∗that minimizes the<br />expected risk<br />?<br />that is,<br />f∗(x) = argmin<br />ˆ y<br />Although the distribution P(x,y) is unknown, we are given a sample S of n independently drawn<br />training examples (xi,yi), i = 1...n. We define the empirical risk<br />E(f) =ℓ(f(x),y)dP(x,y) = E[ℓ(f(x),y)],<br />E[ℓ(ˆ y,y)|x].<br />En(f) =1<br />n<br />n<br />?<br />i=1<br />ℓ(f(xi),yi) = En[ℓ(f(x),y)].<br />Our first learning principle consists in choosing a family F of candidate prediction functions and<br />finding the function fn= argminf∈FEn(f) that minimizes the empirical risk. Well known com-<br />binatorial results (e.g., [2]) support this approach provided that the chosen family F is sufficiently<br />restrictive. Since the optimal function f∗is unlikely to belong to the family F, we also define<br />f∗<br />F= argminf∈FE(f). For simplicity, we assume that f∗, f∗<br />We can then decompose the excess error as<br />Fand fnare well defined and unique.<br />E[E(fn) − E(f∗)] = E[E(f∗<br />where the expectation is taken with respect to the random choice of training set. The approximation<br />error Eappmeasures how closely functions in F can approximate the optimal solution f∗. The<br />estimation error Eestmeasures the effect of minimizing the empirical risk En(f) instead of the<br />expected risk E(f). The estimation error is determined by the number of training examples and by<br />the capacity of the family of functions [2]. Large families1of functions have smaller approximation<br />errors but lead to higher estimation errors. This tradeoff has been extensively discussed in the<br />literature [2, 3] and lead to excess errors that scale between the inverse and the inverse square root<br />of the number of examples [7, 8].<br />F) − E(f∗)] + E[E(fn) − E(f∗<br />F)] = Eapp+ Eest,<br />(1)<br />2.2 Optimization Error<br />Finding fnby minimizing the empirical risk En(f) is often a computationally expensive operation.<br />Since the empirical risk En(f) is already an approximation of the expected risk E(f), it should<br />not be necessary to carry out this minimization with great accuracy. For instance, we could stop an<br />iterative optimization algorithm long before its convergence.<br />Let us assume that our minimization algorithm returns an approximate solution˜fnsuch that<br />En(˜fn) &lt; En(fn) + ρ<br />where ρ ≥ 0 is a predefined tolerance. An additional term Eopt= E?E(˜fn) − E(fn)?then appears<br />E=<br />E[E(f∗<br />=Eapp+ Eest+ Eopt.<br />Wecallthisadditionaltermoptimizationerror. Itreflectstheimpactoftheapproximateoptimization<br />on the generalization performance. Its magnitude is comparable to ρ (see section 3.1.)<br />in the decomposition of the excess error E = E?E(˜fn) − E(f∗)?:<br />F) − E(f∗)] + E[E(fn) − E(f∗<br />F)] + E?E(˜fn) − E(fn)?<br />(2)<br />1We often consider nested families of functions of the form Fc = {f ∈ H, Ω(f) ≤ c}. Then, for each<br />value of c, function fnis obtained by minimizing the regularized empirical risk En(f) + λΩ(f) for a suitable<br />choice of the Lagrange coefficient λ. We can then control the estimation-approximation tradeoff by choosing<br />λ instead of c.</p>  <p>Page 3</p> <p>2.3The Approximation–Estimation–Optimization Tradeoff<br />This decomposition leads to a more complicated compromise. It involves three variables and two<br />constraints. The constraints are the maximal number of available training example and the maximal<br />computation time. The variables are the size of the family of functions F, the optimization accuracy<br />ρ, and the number of examples n. This is formalized by the following optimization problem.<br />min<br />F,ρ,n<br />E = Eapp+ Eest+ Eopt<br />subject to<br />?<br />n≤<br />≤<br />nmax<br />Tmax<br />T(F,ρ,n)<br />(3)<br />The number n of training examples is a variable because we could choose to use only a subset of<br />the available training examples in order to complete the optimization within the alloted time. This<br />happens often in practice. Table 1 summarizes the typical evolution of the quantities of interest with<br />the three variables F, n, and ρ increase.<br />Table 1: Typical variations when F, n, and ρ increase.<br />Fnρ<br />Eapp<br />Eest<br />Eopt<br />T<br />(approximation error)<br />(estimation error)<br />(optimization error)<br />(computation time)<br />ց<br />ր<br />···<br />ր<br />ց<br />···<br />ր<br />ր<br />ց<br />The solution of the optimization program (3) depends critically of which budget constraint is active:<br />constraint n &lt; nmaxon the number of examples, or constraint T &lt; Tmaxon the training time.<br />• We speak of small-scale learning problem when (3) is constrained by the maximal number<br />of examples nmax. Since the computing time is not limited, we can reduce the optimization<br />error Eoptto insignificant levels by choosing ρ arbitrarily small. The excess error is then<br />dominated by the approximation and estimation errors, Eappand Eest. Taking n = nmax,<br />we recover the approximation-estimation tradeoff that is the object of abundant literature.<br />• We speak of large-scale learning problem when (3) is constrained by the maximal comput-<br />ing time Tmax. Approximate optimization, that is, choosing ρ &gt; 0, possibly can achieve<br />better generalization because more training examples can be processed during the allowed<br />time. The specifics depend on the computational properties of the chosen optimization<br />algorithm through the expression of the computing time T(F,ρ,n).<br />3 The Asymptotics of Large-scale Learning<br />In the previous section, we have extended the classical approximation-estimation tradeoff by taking<br />into account the optimization error. We have given an objective criterion to distiguish small-scale<br />and large-scale learning problems. In the small-scale case, we recover the classical tradeoff between<br />approximation and estimation. The large-scale case is substantially different because it involves<br />the computational complexity of the learning algorithm. In order to clarify the large-scale learning<br />tradeoff with sufficient generality, this section makes several simplifications:<br />• We are studying upper bounds of the approximation, estimation, and optimization er-<br />rors (2). It is often accepted that these upper bounds give a realistic idea of the actual<br />convergence rates [9, 10, 11, 12]. Another way to find comfort in this approach is to say<br />that we study guaranteed convergence rates instead of the possibly pathological special<br />cases.<br />• We are studying the asymptotic properties of the tradeoff when the problem size increases.<br />Instead of carefully balancing the three terms, we write E = O(Eapp)+O(Eest)+O(Eopt)<br />and only need to ensure that the three terms decrease with the same asymptotic rate.<br />• We are considering a fixed family of functions F and therefore avoid taking into account<br />the approximation error Eapp. This part of the tradeoff covers a wide spectrum of practical<br />realities such as choosing models and choosing features. In the context of this work, we do</p>  <p>Page 4</p> <p>not believe we can meaningfully address this without discussing, for instance, the thorny<br />issue of feature selection. Instead we focus on the choice of optimization algorithm.<br />• Finally, in order to keep this paper short, we consider that the family of functions F is<br />linearly parametrized by a vector w ∈ Rd. We also assume that x, y and w are bounded,<br />ensuring that there is a constant B such that 0 ≤ ℓ(fw(x),y) ≤ B and ℓ(·,y) is Lipschitz.<br />We first explain how the uniform convergence bounds provide convergence rates that take the op-<br />timization error into account. Then we discuss and compare the asymptotic learning properties of<br />several optimization algorithms.<br />3.1 Convergence of the Estimation and Optimization Errors<br />The optimization error Eoptdepends directly on the optimization accuracy ρ. However, the accuracy<br />ρ involves the empirical quantity En(˜fn) − En(fn), whereas the optimization error Eoptinvolves<br />its expected counterpart E(˜fn) − E(fn). This section discusses the impact on the optimization<br />error Eoptand of the optimization accuracy ρ on generalization bounds that leverage the uniform<br />convergence concepts pioneered by Vapnik and Chervonenkis (e.g., [2].)<br />In this discussion, we use the letter c to refer to any positive constant. Multiple occurences of the<br />letter c do not necessarily imply that the constants have identical values.<br />3.1.1 Simple Uniform Convergence Bounds<br />Recall that we assume that F is linearly parametrized by w ∈ Rd. Elementary uniform convergence<br />results then state that<br />»<br />where the expectation is taken with respect to the random choice of the training set.2This result<br />immediately provides a bound on the estimation error:<br />E<br />sup<br />f∈F|E(f) − En(f)|<br />–<br />≤ c<br />r<br />d<br />n,<br />Eest<br />=<br />Eˆ `E(fn) − En(fn)´+`En(fn) − En(f∗<br />2 E<br />sup<br />F)´+`En(f∗<br />F) − E(f∗<br />F)´ ˜<br />≤<br />»<br />f∈F|E(f) − En(f)|<br />–<br />≤ c<br />r<br />d<br />n.<br />This same result also provides a combined bound for the estimation and optimization errors:<br />Eest+ Eopt<br />=<br />EˆE(˜fn) − En(˜fn)˜+ EˆEn(˜fn) − En(fn)˜<br />r<br />n<br />+<br />E[En(fn) − En(f∗<br />F)] + E[En(f∗<br />F) − E(f∗<br />F)]<br />≤<br />c<br />d<br />n+ ρ + 0 + c<br />r<br />d<br />= c<br /> <br />ρ +<br />r<br />d<br />n<br />!<br />.<br />Unfortunately, this convergence rate is known to be pessimistic in many important cases. More<br />sophisticated bounds are required.<br />3.1.2 Faster Rates in the Realizable Case<br />When the loss functions ℓ(ˆ y,y) is positive, with probability 1−e−τfor any τ &gt; 0, relative uniform<br />convergence bounds state that<br />sup<br />f∈F<br />E(f) − En(f)<br />pE(f)<br />≤ c<br />r<br />d<br />nlogn<br />d+τ<br />n.<br />This result is very useful because it provides faster convergence rates O(logn/n) in the realizable<br />case, that is when ℓ(fn(xi),yi) = 0 for all training examples (xi,yi). We have then En(fn) = 0,<br />En(˜fn) ≤ ρ, and we can write<br />E(˜fn) − ρ ≤ c<br />q<br />E(˜fn)<br />r<br />d<br />nlogn<br />d+τ<br />n.<br />2Although the original Vapnik-Chervonenkis bounds have the form c<br />be eliminated using the “chaining” technique (e.g., [10].)<br />q<br />d<br />nlogn<br />d, the logarithmic term can</p>  <p>Page 5</p> <p>Viewing this as a second degree polynomial inequality in variable<br />?<br />E(˜fn), we obtain<br />E(˜fn) ≤ c<br />„<br />ρ +d<br />nlogn<br />d+τ<br />n<br />«<br />.<br />Integrating this inequality using a standard technique (see, e.g., [13]), we obtain a better convergence<br />rate of the combined estimation and optimization error:<br />Eest+ Eopt = E<br />h<br />E(˜fn) − E(f∗<br />F)<br />i<br />≤ E<br />h<br />E(˜fn)<br />i<br />= c<br />„<br />ρ +d<br />nlogn<br />d<br />«<br />.<br />3.1.3Fast Rate Bounds<br />Many authors (e.g., [10, 4, 12]) obtain fast statistical estimation rates in more general conditions.<br />These bounds have the general form<br />Eapp+ Eest≤ c<br />?<br />Eapp+<br />?d<br />nlogn<br />d<br />?α?<br />for<br />1<br />2≤ α ≤ 1.<br />(4)<br />This result holds when one can establish the following variance condition:<br />∀f ∈ F<br />E<br />??ℓ(f(X),Y ) − ℓ(f∗<br />F(X),Y )?2?<br />≤ c<br />?<br />E(f) − E(f∗<br />F)<br />?2−1<br />α<br />.<br />(5)<br />The convergence rate of (4) is described by the exponent α which is determined by the quality of<br />the variance bound (5). Works on fast statistical estimation identify two main ways to establish such<br />a variance condition.<br />• Exploiting the strict convexity of certain loss functions [12, theorem 12]. For instance, Lee<br />et al. [14] establish a O(logn/n) rate using the squared loss ℓ(ˆ y,y) = (ˆ y − y)2.<br />• Making assumptions on the data distribution. In the case of pattern recognition problems,<br />for instance, the “Tsybakov condition” indicates how cleanly the posterior distributions<br />P(y|x) cross near the optimal decision boundary [11, 12]. The realizable case discussed in<br />section 3.1.2 can be viewed as an extreme case of this.<br />Despite their much greater complexity, fast rate estimation results can accomodate the optimization<br />accuracy ρ using essentially the methods illustrated in sections 3.1.1 and 3.1.2. We then obtain a<br />bound of the form<br />E = Eapp+ Eest+ Eopt= E<br />?<br />E(˜fn) − E(f∗)<br />?<br />≤ c<br />?<br />Eapp+<br />?d<br />nlogn<br />d<br />?α<br />+ ρ<br />?<br />.<br />(6)<br />For instance, a general result with α = 1 is provided by Massart [13, theorem 4.2]. Combining this<br />result with standard bounds on the complexity of classes of linear functions (e.g., [10]) yields the<br />following result:<br />E = Eapp+ Eest+ Eopt= E<br />?<br />E(˜fn) − E(f∗)<br />?<br />≤ c<br />?<br />Eapp+d<br />nlogn<br />d+ ρ<br />?<br />.<br />(7)<br />See also [15, 4] for more bounds taking into account the optimization accuracy.<br />3.2Gradient Optimization Algorithms<br />We now discuss and compare the asymptotic learning properties of four gradient optimization algo-<br />rithms. Recall that the family of function F is linearly parametrized by w ∈ Rd. Let w∗<br />correspond to the functions f∗<br />functions w ?→ ℓ(fw(x),y) are convex and twice differentiable with continuous second derivatives.<br />Convexity ensures that the empirical const function C(w) = En(fw) has a single minimum.<br />Two matrices play an important role in the analysis: the Hessian matrix H and the gradient covari-<br />ance matrix G, both measured at the empirical optimum wn.<br />∂2C<br />∂w2(wn) = En<br />??∂ℓ(fwn(x),y)<br />Fand wn<br />Fand fndefined in section 2.1. In this section, we assume that the<br />H=<br />?∂2ℓ(fwn(x),y)<br />??∂ℓ(fwn(x),y)<br />∂w2<br />?<br />,<br />(8)<br />G=<br />En<br />∂w ∂w<br />?′?<br />.<br />(9)</p>  <p>Page 6</p> <p>The relation between these two matrices depends on the chosen loss function. In order to summarize<br />them, we assume that there are constants λmax≥ λmin&gt; 0 and ν &gt; 0 such that, for any η &gt; 0,<br />we can choose the number of examples n large enough to ensure that the following assertion is true<br />with probability greater than 1 − η :<br />tr(G H−1) ≤ ν<br />and<br />EigenSpectrum(H) ⊂ [λmin, λmax]<br />(10)<br />The condition number κ = λmax/λmincharacterizes the optimisation difficulty (e.g., [16].)<br />The condition λmin &gt; 0 avoids complications with stochastic gradient algorithms. Note that this<br />condition only implies strict convexity around the optimum. For instance, consider a loss function<br />obtained by smoothing the well known hinge loss ℓ(z,y) = max{0,1−yz} in a small neighborhood<br />of its non-differentiable points. Function C(w) is then piecewise linear with smoothed edges and<br />vertices. It is not strictly convex. However its minimum is likely to be on a smoothed vertex with a<br />non singular Hessian. When we have strict convexity, the argument of [12, theorem 12] yields fast<br />estimation rates α ≈ 1 in (4) and (6). This is not necessarily the case here.<br />The four algorithm considered in this paper use information about the gradient of the cost function<br />to iteratively update their current estimate w(t) of the parameter vector.<br />• Gradient Descent (GD) iterates<br />w(t + 1) = w(t) − η∂C<br />∂w(w(t)) = w(t) − η1<br />n<br />n<br />?<br />i=1<br />∂<br />∂wℓ?fw(t)(xi),yi<br />?<br />where η &gt; 0 is a small enough gain. GD is an algorithm with linear convergence [16]:<br />when η = 1/λmax, this algorithm requires O(κlog(1/ρ)) iterations to reach accuracy ρ.<br />The exact number of iterations depends on the choice of the initial parameter vector.<br />• Second Order Gradient Descent (2GD) iterates<br />w(t + 1) = w(t) − H−1∂C<br />∂w(w(t)) = w(t) −1<br />nH−1<br />n<br />?<br />i=1<br />∂<br />∂wℓ?fw(t)(xi),yi<br />?<br />where matrix H−1is the inverse of the Hessian matrix (8). This is more favorable than<br />Newton’s algorithm because we do not evaluate the local Hessian at each iteration but<br />simply assume that we know in advance the Hessian at the optimum. 2GD is a superlinear<br />optimization algorithm with quadratic convergence [16]. When the cost is quadratic, a<br />single iteration is sufficient. In the general case, O(loglog(1/ρ)) iterations are required to<br />reach accuracy ρ.<br />• Stochastic Gradient Descent (SGD) picks a random training example (xt,yt) at each<br />iteration and updates the parameter w on the basis of this example only,<br />w(t + 1) = w(t) −η<br />t<br />∂<br />∂wℓ?fw(t)(xt),yt<br />?.<br />Murata [17, section 2.2], characterizes the mean ES[w(t)] and variance VarS[w(t)] with<br />respect to the distribution implied by the random examples drawn from a given training<br />set S at each iteration. Applying this result to the discrete training set distribution for<br />η = 1/λmin, we have δw(t)2= O(1/t) where δw(t) is a shorthand notation for w(t)−wn.<br />We can then write<br />ES[C(w(t)) − inf C ]=<br />ES<br />ˆtr`H δw(t)δw(t)′´˜+ o`1<br />tr`H ES[δw(t)]ES[δw(t)]′+ H VarS[w(t)]´+ o`1<br />t<br />+ o`1<br />t<br />´<br />=<br />t<br />´<br />≤<br />tr(GH)<br />t<br />´<br />≤<br />νκ2<br />t<br />+ o`1<br />t<br />´.<br />(11)<br />Therefore the SGD algorithm reaches accuracy ρ after less than νκ2/ρ + o(1/ρ) iterations<br />on average. The SGD convergence is essentially limited by the stochastic noise induced<br />by the random choice of one example at each iteration. Neither the initial value of the<br />parameter vector w nor the total number of examples n appear in the dominant term of this<br />bound! When the training set is large, one could reach the desired accuracy ρ measured on<br />the whole training set without even visiting all the training examples. This is in fact a kind<br />of generalization bound.</p>  <p>Page 7</p> <p>Table 2: Asymptotic results for gradient algorithms (with probability 1). Compare the second<br />last column (time to optimize) with the last column (time to reach the excess test error ǫ).<br />Legend: n number of examples; d parameter dimension; κ, ν see equation (10).<br />Algorithm Cost of one<br />iteration<br />Iterations<br />to reach ρ<br />Time to reach<br />accuracy ρ<br />Time to reach<br />E ≤ c(Eapp+ ε)<br />GD<br />O(nd)O<br />?<br />loglog1<br />κlog1<br />ρ<br />?<br />ρ<br />?<br />?<br />O<br />?<br />ndκlog1<br />ρ<br />?<br />O<br />?<br />d2κ<br />ε1/αlog2 1<br />ε<br />?<br />2GD<br />O?d2+ nd?<br />O(d)<br />O<br />?<br />ρ+ o<br />?<br />O<br />??d2+ nd?loglog1<br />O<br />?<br />O<br />?<br />ρ<br />?<br />O<br />?<br />d2<br />ε1/αlog1<br />εloglog1<br />?<br />d2ν<br />ε<br />ε<br />?<br />SGD<br />νκ2<br />?<br />1<br />ρ<br />1<br />ρ<br />dνκ2<br />ρ<br />?<br />?<br />O<br />?<br />dν κ2<br />ε<br />?<br />2SGD<br />O?d2?<br />ν<br />ρ+ o<br />?<br />d2ν<br />ρ<br />O<br />?<br />• Second Order Stochastic Gradient Descent (2SGD) replaces the gain η by the inverse of<br />the Hessian matrix H:<br />w(t + 1) = w(t) −1<br />tH−1∂<br />∂wℓ?fw(t)(xt),yt<br />?.<br />Unlike standard gradient algorithms, using the second order information does not change<br />the influence of ρ on the convergence rate but improves the constants. Using again [17,<br />theorem 4], accuracy ρ is reached after ν/ρ + o(1/ρ) iterations.<br />For each of the four gradient algorithms, the first three columns of table 2 report the time for a single<br />iteration, the number of iterations needed to reach a predefined accuracy ρ, and their product, the<br />time needed to reach accuracy ρ. These asymptotic results are valid with probability 1, since the<br />probability of their complement is smaller than η for any η &gt; 0.<br />The fourth column bounds the time necessary to reduce the excess error E below c(Eapp+ε) where c<br />is the constant from (6). This is computed by observing that choosing ρ ∼`d<br />ρ ∼ ε and n ∼<br />the best excess error achieved by each algorithm within the limited time Tmax. This provides the<br />asymptotic solution of the Estimation–Optimization tradeoff (3) for large scale problems satisfying<br />our assumptions.<br />nlogn<br />d<br />´αin (6) achieves<br />the fastest rate for ε, with minimal computation time. We can then use the asymptotic equivalences<br />d<br />ε1/αlog1<br />ε. Setting the fourth column expressions to Tmaxand solving for ǫ yields<br />These results clearly show that the generalization performance of large-scale learning systems de-<br />pends on both the statistical properties of the objective function and the computational properties of<br />the chosen optimization algorithm. Their combination leads to surprising consequences:<br />• The SGD and 2SGD results do not depend on the estimation rate α. When the estimation<br />rate is poor, there is less need to optimize accurately. That leaves time to process more<br />examples. A potentially more useful interpretation leverages the fact that (11) is already a<br />kind of generalization bound: its fast rate trumps the slower rate assumed for the estimation<br />error.<br />• Second order algorithms bring little asymptotical improvements in ε. Although the super-<br />linear 2GD algorithm improves the logarithmic term, all four algorithms are dominated by<br />the polynomial term in (1/ε). However, there are important variations in the influence of<br />the constants d, κ and ν. These constants are very important in practice.<br />• Stochastic algorithms (SGD, 2SGD) yield the best generalization performance despite be-<br />ing the worst optimization algorithms. This had been described before [18] and observed<br />in experiments.<br />In contrast, since the optimization error Eoptof small-scale learning systems can be reduced to<br />insignificantlevels, theirgeneralizationperformanceissolelydeterminedbythestatisticalproperties<br />of the objective function.</p>  <p>Page 8</p> <p>4 Conclusion<br />Taking in account budget constraints on both the number of examples and the computation time,<br />we find qualitative differences between the generalization performance of small-scale learning sys-<br />tems and large-scale learning systems. The generalization properties of large-scale learning systems<br />depend on both the statistical properties of the objective function and the computational proper-<br />ties of the optimization algorithm. We illustrate this fact with some asymptotic results on gradient<br />algorithms.<br />Considerable refinements of this framework can be expected. Extending the analysis to regular-<br />ized risk formulations would make results on the complexity of primal and dual optimization algo-<br />rithms [19, 20] directly exploitable. The choice of surrogate loss function [7, 12] could also have a<br />non-trivial impact in the large-scale case.<br />Acknowledgments<br />Part of this work was funded by NSF grant CCR-0325463.<br />References<br />[1] Leslie G. Valiant. A theory of learnable. Proc. of the 1984 STOC, pages 436–445, 1984.<br />[2] Vladimir N. Vapnik. Estimation of Dependences Based on Empirical Data. Springer Series in Statistics.<br />Springer-Verlag, Berlin, 1982.<br />[3] St´ ephane Boucheron, Olivier Bousquet, and G´ abor Lugosi. Theory of classification: a survey of recent<br />advances. ESAIM: Probability and Statistics, 9:323–375, 2005.<br />[4] Peter L. Bartlett and Shahar Mendelson. Empirical minimization. Probability Theory and Related Fields,<br />135(3):311–334, 2006.<br />[5] J. Stephen Judd. On the complexity of loading shallow neural networks. Journal of Complexity, 4(3):177–<br />192, 1988.<br />[6] Richard O. Duda and Peter E. Hart. Pattern Classification And Scene Analysis. Wiley and Son, 1973.<br />[7] Tong Zhang. Statistical behavior and consistency of classification methods based on convex risk mini-<br />mization. The Annals of Statistics, 32:56–85, 2004.<br />[8] Clint Scovel and Ingo Steinwart. Fast rates for support vector machines. In Peter Auer and Ron Meir,<br />editors, Proceedings of the 18th Conference on Learning Theory (COLT 2005), volume 3559 of Lecture<br />Notes in Computer Science, pages 279–294, Bertinoro, Italy, June 2005. Springer-Verlag.<br />[9] Vladimir N. Vapnik, Esther Levin, and Yann LeCun. Measuring the VC-dimension of a learning machine.<br />Neural Computation, 6(5):851–876, 1994.<br />[10] Olivier Bousquet. Concentration Inequalities and Empirical Processes Theory Applied to the Analysis of<br />Learning Algorithms. PhD thesis, Ecole Polytechnique, 2002.<br />[11] Alexandre B. Tsybakov. Optimal aggregation of classifiers in statistical learning. Annals of Statististics,<br />32(1), 2004.<br />[12] Peter L. Bartlett, Michael I. Jordan, and Jon D. McAuliffe. Convexity, classification and risk bounds.<br />Journal of the American Statistical Association, 101(473):138–156, March 2006.<br />[13] Pascal Massart. Some applications of concentration inequalities to statistics. Annales de la Facult´ e des<br />Sciences de Toulouse, (2):245–303, 2000.<br />[14] Wee S. Lee, Peter L. Bartlett, and Robert C. Williamson. The importance of convexity in learning with<br />squared loss. IEEE Transactions on Information Theory, 44(5):1974–1980, 1998.<br />[15] Shahar Mendelson. A few notes on statistical learning theory. In Shahar Mendelson and Alexander J.<br />Smola, editors, Advanced Lectures in Machine Learning, volume 2600 of Lecture Notes in Computer<br />Science, pages 1–40. Springer-Verlag, Berlin, 2003.<br />[16] John E. Dennis, Jr. and Robert B. Schnabel. Numerical Methods For Unconstrained Optimization and<br />Nonlinear Equations. Prentice-Hall, Inc., Englewood Cliffs, New Jersey, 1983.<br />[17] Noboru Murata. A statistical study of on-line learning. In David Saad, editor, Online Learning and Neural<br />Networks. Cambridge University Press, Cambridge, UK, 1998.<br />[18] L´ eon Bottou and Yann LeCun. Large scale online learning. In Sebastian Thrun, Lawrence Saul, and Bern-<br />hard Sch¨ olkopf, editors, Advances in Neural Information Processing Systems 16. MIT Press, Cambridge,<br />MA, 2004.<br />[19] Thorsten Joachims. Training linear svms in linear time. In Proceedings of KDD’06, Philadelphia, PA,<br />USA, August 20-23 2006. ACM.<br />[20] Don Hush, Patrick Kelly, Clint Scovel, and Ingo Steinwart. QP algorithms with guaranteed accuracy and<br />run time for support vector machines. Journal of Machine Learning Research, 7:733–769, 2006.</p>  <a href="https://www.researchgate.net/profile/Olivier_Bousquet/publication/221618614_The_Tradeoffs_of_Large_Scale_Learning/links/004635219281099d85000000.pdf">Download full-text</a> </div> <div id="rgw18_56ab9e8f16567" class="c-box pub-resource-container js-toggle" style=""> <h4 class="lf js-expand-list"><small><a href="javascript:" class="lf">View other sources <span class="ico-expand-list"></span></a></small></h4> <h4 class="lf js-collapse-list hidden"><small><a href="javascript:" class="lf">Hide other sources <span class="ico-collapse-list"></span></a></small></h4> <div class="clear"></div> <div class="scroll-wrapper hidden"> <ul class="files-list c-list" id="rgw19_56ab9e8f16567">  <li class="c-list-item pub-resource-item"  data-type="fulltext" id="rgw20_56ab9e8f16567"> <span class="ico-pub"></span> <div class="file-content"> <div class="download"> <a href="profile/Olivier_Bousquet/publication/221618614_The_Tradeoffs_of_Large_Scale_Learning/links/004635219281099d85000000.pdf" class="publication-viewer" title="004635219281099d85000000.pdf">004635219281099d85000000.pdf</a> </div>  <div class="details">  <span> Available from <a href="profile/Olivier_Bousquet">Olivier Bousquet</a> &middot; Jun 5, 2014 </span>   </div>    </div> </li>  <li class="c-list-item pub-resource-item"  data-type="fulltext" id="rgw21_56ab9e8f16567"> <span class="ico-pub"></span> <div class="file-content"> <div class="download"> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.168.5389&amp;amp;rep=rep1&amp;amp;type=pdf" target="_blank" rel="nofollow" class="publication-viewer" title="The Tradeoffs of Large Scale Learning.">The Tradeoffs of Large Scale Learning.</a> </div>  <div class="details">   Available from <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.168.5389&amp;amp;rep=rep1&amp;amp;type=pdf" target="_blank" rel="nofollow">psu.edu</a>  </div>    </div> </li>  </ul> </div> </div> </noscript> <div class="clearfix"> <div class="action-container">  </div> <div class="pub-legal"> Data provided are for informational purposes only. Although carefully collected, accuracy cannot be guaranteed. The impact factor represents a rough estimation of the journal's impact factor and does not reflect the actual current impact factor. Publisher conditions are provided by RoMEO. Differing provisions from the publisher's actual policy or licence agreement may be applicable. </div>   </div> </div> <div class="clearfix">     <div id="rgw23_56ab9e8f16567" class="c-box pub-resource-container js-toggle" style="display: none;"> <h4 class="lf js-expand-list"><small><a href="javascript:" class="lf">View other sources <span class="ico-expand-list"></span></a></small></h4> <h4 class="lf js-collapse-list hidden"><small><a href="javascript:" class="lf">Hide other sources <span class="ico-collapse-list"></span></a></small></h4> <div class="clear"></div> <div class="scroll-wrapper hidden"> <ul class="files-list c-list" id="rgw24_56ab9e8f16567">  </ul> </div> </div>   <div id="rgw14_56ab9e8f16567" class="similar-publications"> <h2>Similar Publications</h2> <ul class="list-bordered">  <li class="c-list-item li-publication-teaser" id="rgw15_56ab9e8f16567"> <div> <h5> <a href="publication/291419030_Determination_of_full_piezoelectric_complex_parameters_using_gradient-based_optimization_algorithm" class="color-inherit ga-similar-publication-title"><span class="publication-title">Determination of full piezoelectric complex parameters using gradient-based optimization algorithm</span></a>  </h5>  <div class="authors"> <a href="researcher/2049618089_C_Y_Kiyono" class="authors ga-similar-publication-author">C Y Kiyono</a>, <a href="researcher/75152600_N_Perez" class="authors ga-similar-publication-author">N Pérez</a>, <a href="researcher/6618272_E_C_N_Silva" class="authors ga-similar-publication-author">E C N Silva</a>  </div>  </div> <div class="clear"></div> </li>  <li class="c-list-item li-publication-teaser" id="rgw16_56ab9e8f16567"> <div> <h5> <a href="publication/292077460_A_family_of_honey-bee_optimization_algorithms_for_Max-CSPs" class="color-inherit ga-similar-publication-title"><span class="publication-title">A family of honey-bee optimization algorithms for Max-CSPs</span></a>  </h5>  <div class="authors"> <a href="researcher/2096067985_Ines_Mathlouthi" class="authors ga-similar-publication-author">Ines Mathlouthi</a>, <a href="researcher/2096058155_Sadok_Bouamama" class="authors ga-similar-publication-author">Sadok Bouamama</a>  </div>  </div> <div class="clear"></div> </li>  <li class="c-list-item li-publication-teaser" id="rgw17_56ab9e8f16567"> <div> <h5> <a href="publication/291369789_An_improved_artificial_fish_swarm_algorithm_optimized_by_particle_swarm_optimization_algorithm_with_extended_memory" class="color-inherit ga-similar-publication-title"><span class="publication-title">An improved artificial fish swarm algorithm optimized by particle swarm optimization algorithm with extended memory</span></a>  </h5>  <div class="authors"> <a href="researcher/69867767_Qichang_Duan" class="authors ga-similar-publication-author">Qichang Duan</a>, <a href="researcher/2081635333_Mingxuan_Mao" class="authors ga-similar-publication-author">Mingxuan Mao</a>, <a href="researcher/70988676_Pan_Duan" class="authors ga-similar-publication-author">Pan Duan</a>, <a href="researcher/2081620257_Bei_Hu" class="authors ga-similar-publication-author">Bei Hu</a>  </div>  </div> <div class="clear"></div> </li>  </ul> </div> </div> </div> </div> </div></div></div>
<div class="clear"></div><div id="rgw37_56ab9e8f16567" class="default-footer"> <div id="footer" class="clearfix"> <span class="footer-left"> &copy; 2008&dash;2016 researchgate.net. All rights reserved. </span> <span class="footer-right"> <a href="https://www.researchgate.net/about">About us</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="https://www.researchgate.net/contact">Contact us</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="careers">Careers</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="developers">Developers</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="blog" target="_blank">News</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="application.PrivacyPolicy.html">Privacy</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="application.TermsAndConditions.html">Terms</a> <span class="footer-link-separator" style="padding: 0 5px;">&nbsp;|&nbsp;</span> <a href="advertising?_ref=ft">Advertising</a> <span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="recruiters?_ref=ft">Recruiting</a> </span> </div>  </div></div>
<div id="rgw38_56ab9e8f16567">  <div class="header-wrapper-logged-out"> <div id="header"> <div class="header-content"> <a href="" class="g-l-logo"> <svg width="149" height="19"> <image xlink:href="https://c5.rgstatic.net/m/235107188705592/images/template/brand-header-logo.svg" src="https://c5.rgstatic.net/m/238113351022438/images/template/brand-header-logo.png" width="149" height="19"/> </svg> </a> <a href="" class="g-l-logo-ico"> <svg width="127" height="17" viewbox="0 0 127 22"> <image xlink:href="https://c5.rgstatic.net/m/235107188705592/images/template/brand-header-logo.svg" src="https://c5.rgstatic.net/m/238113351022438/images/template/brand-header-logo.png" width="127" height="17"/> </svg> </a> <div id="rgw39_56ab9e8f16567" class="header-login-wrapper js-header-login"> <div class="dropdown-right-align"> <div class="login-signup-container lf"> <a href="https://www.researchgate.net/signup.SignUp.html?ev=su_chnl_index&amp;hdrsu=1&amp;_sg=M9_jbru8ppsBL9yAeA2lg2LG2VfHIXmqDGzzsgdEOIEhv6-XY7PMf-e-qG2pWtd6" class="dropdown-toggle lf">Join for free</a> </div> <div class="dropdown lf" style="height: 20px;"> <a href="https://www.researchgate.net/application.Login.html" class="js-login-url dropdown-toggle lf">Log in <span class="caret"></span></a> <div class="dropdown-menu"> <div class="header-login-form-wrapper"> <!--[if IE 6]><p class="box-warning" style="margin-bottom: 0;">Sorry, ResearchGate no longer supports the version of Internet Explorer you are using. <a href="http://whatbrowser.org/" rel="nofollow" target="_blank">Update your web browser</a> and then log in. </p><![endif]--> <form method="post" action="https://www.researchgate.net/application.Login.html" class="form-big header-login-form js-login-form" name="loginForm" id="headerLoginForm"> <input type="hidden" name="request_token" value="M4dUNyOj0KHKTF4x+LFhxCQmxh+7dr5/ts/a89geL/p2jhgodqdmJpubs36bOxNPubjTcsjpCgwpMvmSuygB64XD9OzGzLekeJOWcyv+4/2LUZtW34skkduFYzqeANnj61qXT9UZ64Bsk/zbq5EwRpTkWjLE8wOngHFrA9U85zb501qWOTludWRKthkzNqZm8Mmhzo1DtQuEFgzsGCtLp51ctzNX4XmKirnsyzmd+YyUsVUwiQYcm0MP7HCVsVIALrDXxB6HU6tB4BMmHU7GdQsAswomOsFss9y5NPRySiA="/> <input type="hidden" name="urlAfterLogin" value="publication/221618614_The_Tradeoffs_of_Large_Scale_Learning"/> <input type="hidden" name="invalidPasswordCount" value="0"/> <input type="hidden" name="headerLogin" value="yes"/> <label for="input-header-login">Email</label> <div class="login-input"> <div class="info-tip-wrapper"> <span class="ico-info js-info"></span> </div> <input type="email" value="" name="login" class="login js-login-input text" id="input-header-login" tabindex="1"/> </div> <div class="clear"></div> <label class="lf" for="input-header-password"> Password </label> <a class="rf forgot-password js-forgot-password" href="application.LostPassword.html">Forgot password?</a> <div class="clear"></div> <input type="password" value="" name="password" class="password js-password-input text" id="input-header-password" tabindex="2"/> <div class="clear"></div> <label class="remember-me" for="headerLoginCookie"> <input type="checkbox" checked="checked" value="yes" name="setLoginCookie" class="lf checkbox" id="headerLoginCookie" tabindex="3"/> Keep me logged in </label> <div class="clear"></div> <input value="Log in" name="loginSubmit" class="btn btn-promote btn-fullwidth btn-large allow-leave js-submit-button" type="submit" tabindex="4"/> </form> <div class="connectors"> <div class="text">or log in with</div> <div class="connector-actions"> <a href="connector/linkedin/" class="li-connect js-li-connect" data-redirect-url="cHVibGljYXRpb24vMjIxNjE4NjE0X1RoZV9UcmFkZW9mZnNfb2ZfTGFyZ2VfU2NhbGVfTGVhcm5pbmc%3D"> <span class="icon ico-linkedin-round-grey"></span> <span class="icon ico-linkedin-round"></span> </a> <a href="connector/facebook/" class="fb-connect middle js-fb-connect" data-redirect-url="cHVibGljYXRpb24vMjIxNjE4NjE0X1RoZV9UcmFkZW9mZnNfb2ZfTGFyZ2VfU2NhbGVfTGVhcm5pbmc%3D"> <span class="icon ico-facebook-round-grey"></span> <span class="icon ico-facebook-round"></span> </a> <a href="connector/google/" class="g-connect js-g-connect" data-redirect-url="cHVibGljYXRpb24vMjIxNjE4NjE0X1RoZV9UcmFkZW9mZnNfb2ZfTGFyZ2VfU2NhbGVfTGVhcm5pbmc%3D"> <span class="icon ico-google-round-grey"></span> <span class="icon ico-google-round"></span> </a> </div> </div> </div> </div> </div> </div> </div> </div> </div> <script type="application/ld+json">
{ "@context" : "http://schema.org",
  "@type" : "Organization",
  "name" : "ResearchGate",
  "url" : "http://www.researchgate.net",
  "logo" : "http://www.researchgate.net/images/template/rg_logo_square_brand.png",
  "sameAs" : [ "https://www.facebook.com/ResearchGate",
    "https://twitter.com/ResearchGate",
    "https://plus.google.com/+researchgate",
    "https://www.linkedin.com/company/researchgate"] 
}
</script> </div> </div><div class="c-signup-bar" id="rgw40_56ab9e8f16567"> <div class="banner-contents">   <span class="message">ResearchGate is the professional network for scientists and researchers.</span> <a href="signup.SignUp.html?ev=su_banner" class="btn btn-large btn-promote">Join for free</a>  </div> </div></div>
<script>
rgConfig.backendTime = 304;
</script>
<script src="//c5.rgstatic.net/m/2277196935388619/javascript/lib/yui3/yui/yui-min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/21832295316281274/javascript/yuiLoaderConfig-min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/23178613132105398/javascript/vendor/babel-core/browser-polyfill.min.js" type="text/javascript"></script>
<script>
(function (){
if (typeof YRG === "undefined") {
var xmlHttpRequest = new XMLHttpRequest();
xmlHttpRequest.open("post", "go.Error.html");
xmlHttpRequest.setRequestHeader("Content-Type", "application/json");
xmlHttpRequest.setRequestHeader("Accept", "application/json"); var loadedScripts = "";
if (window.performance && window.performance.getEntriesByType) {
    var result = [];
    var resources = performance.getEntriesByType("resource");
    for (var i in resources) {
        if (resources.hasOwnProperty(i)) {
            result.push({
                name: resources[i].name,
                duration: resources[i].duration
            });
        }
    }
    loadedScripts += "&loadedScripts=" + encodeURIComponent(JSON.stringify(result));
}
if (typeof YUI === "undefined") {
    loadedScripts += "&yuiLoaded=false";
} else {
    loadedScripts += "&yuiLoaded=true";
}
xmlHttpRequest.send("Type=InformationException&message=" + encodeURIComponent("Error loading YUI") + loadedScripts);
}
})();
</script>
<script>if (typeof YRG !== 'undefined') { YRG.use('rg-base',function(Y){Y.applyConfig({ignore: ["css-rg","css-rg2","css-ie","css-modules-publicprofile","css-pow-publicliterature-FollowPublicationPromo","css-pow-application-PdfJsReader","css-pow-publicliterature-PublicationInlineReader"]});Y.use(["rg.core.pagespeed.Monitoring"],function(Y){(function(){Y.rg.createInitialWidget({"data":{"content":{"data":{"profileSmallHeader":{"data":{"profileBadge":{"data":{"fullname":"Olivier Bousquet","imageUrl":"https:\/\/i1.rgstatic.net\/ii\/profile.image\/AS%3A276948442992654%401443041062828_m","profileStats":[],"profileFollowButton":null,"profileReputationScoreNumber":null,"profileUrl":"profile\/Olivier_Bousquet","institution":"Google Inc.","institutionUrl":false,"widgetId":"rgw4_56ab9e8f16567"},"id":"rgw4_56ab9e8f16567","partials":[],"templateName":"publicprofile\/stubs\/ProfileBadge.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicprofile.ProfileBadge.html?accountId=3408664","viewClass":null,"yuiModules":["css-modules-publicprofile"],"stylesheets":["modules\/publicprofile.css"],"_isYUI":true},"widgetId":"rgw3_56ab9e8f16567"},"id":"rgw3_56ab9e8f16567","partials":[],"templateName":"publicprofile\/stubs\/ProfileSmallHeader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicprofile.ProfileSmallHeader.html?publicationUid=221618614","viewClass":null,"yuiModules":["css-modules-publicprofile"],"stylesheets":["modules\/publicprofile.css"],"_isYUI":true},"publication":{"data":{"publicationUid":221618614,"title":"The Tradeoffs of Large Scale Learning.","journalTitle":false,"journalDetailsTooltip":false,"affiliation":false,"type":"Conference Paper","details":{"conferenceInfos":"Conference: Advances in Neural Information Processing Systems 20, Proceedings of the Twenty-First Annual Conference on Neural Information Processing Systems, Vancouver, British Columbia, Canada, December 3-6, 2007"},"source":{"sourceUrl":"http:\/\/dblp.uni-trier.de\/db\/conf\/nips\/nips2007.html#BottouB07","sourceName":"DBLP"},"publicationActions":null,"publicationCoins":{"data":{"tags":[{"key":"ctx_ver","value":"Z39.88-2004"},{"key":"rft_val_fmt","value":"info:ofi\/fmt:kev:mtx:journal"},{"key":"rfr_id","value":"info:sid\/researchgate.net:researchgate"},{"key":"rft.atitle","value":"The Tradeoffs of Large Scale Learning."},{"key":"rft.title","value":"Optimization for Machine Learning"},{"key":"rft.jtitle","value":"Optimization for Machine Learning"},{"key":"rft.volume","value":"20"},{"key":"rft.date","value":"2007"},{"key":"rft.au","value":"L\u00e9on Bottou,Olivier Bousquet"},{"key":"rft.genre","value":"inProceedings"}],"widgetId":"rgw6_56ab9e8f16567"},"id":"rgw6_56ab9e8f16567","partials":[],"templateName":"publicliterature\/stubs\/PublicationCoins.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationCoins.html?publicationUid=221618614","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationAuthors":{"data":{"publicationUid":221618614,"peopleItems":[{"data":{"authorUrl":"researcher\/7871008_Leon_Bottou","authorNameOnPublication":"L\u00e9on Bottou","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg","imageSize":"s","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"L\u00e9on Bottou","profile":{"professionalInstitution":{"professionalInstitutionName":false,"professionalInstitutionUrl":null}},"professionalInstitutionName":false,"professionalInstitutionUrl":null,"url":"researcher\/7871008_Leon_Bottou","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":true,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":false,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"widgetId":"rgw9_56ab9e8f16567"},"id":"rgw9_56ab9e8f16567","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAuthorItem.html?entityId=7871008&imageSize=l&enableAuthorInviteButton=0","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"largeTooltip":false,"useRebrandedImageStyle":null,"widgetId":"rgw8_56ab9e8f16567"},"id":"rgw8_56ab9e8f16567","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorItem.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorItem.html?authorUid=7871008&authorNameOnPublication=L%C3%A9on%20Bottou","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true},{"data":{"authorNameOnPublication":"Olivier Bousquet","accountUrl":"profile\/Olivier_Bousquet","accountKey":"Olivier_Bousquet","imageUrl":"https:\/\/i1.rgstatic.net\/ii\/profile.image\/AS%3A276948442992654%401443041062828_m","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Olivier Bousquet","profile":{"professionalInstitution":{"professionalInstitutionName":"Google Inc.","professionalInstitutionUrl":"institution\/Google_Inc"}},"professionalInstitutionName":"Google Inc.","professionalInstitutionUrl":"institution\/Google_Inc","url":"profile\/Olivier_Bousquet","imageUrl":"https:\/\/i1.rgstatic.net\/ii\/profile.image\/AS%3A276948442992654%401443041062828_l","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":false,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":true,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"accountKey":"Olivier_Bousquet","hasInfoPopup":false,"hasTeaserPopup":true,"showContactAuthorButton":true,"widgetId":"rgw11_56ab9e8f16567"},"id":"rgw11_56ab9e8f16567","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAccountItem.html?entityId=3408664&enableUnfollow=0&imageSize=l&enableFollowButton=0&showContactAuthorButton=1","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"accountInstitution":"Google Inc.","score":null,"largeTooltip":false,"useRebrandedImageStyle":null,"authorCount":2,"accountCount":1,"publicationUid":221618614,"widgetId":"rgw10_56ab9e8f16567"},"id":"rgw10_56ab9e8f16567","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAccountItem.html","templateExtensions":[],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAccountItem.html?accountId=3408664&context=pubdetail_authors_xflw&showContactAuthorButton=1&authorCount=2&accountCount=1&publicationUid=221618614","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true}],"hasMore":false,"nextOffset":6,"useRebrandedImageStyle":null,"widgetId":"rgw7_56ab9e8f16567"},"id":"rgw7_56ab9e8f16567","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorList.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorList.html?publicationUid=221618614&context=pubdetail_authors_xflw&showContactAuthorButton=1","viewClass":"views.publicliterature.PublicationDetailAuthorListView","yuiModules":["rg.views.publicliterature.PublicationDetailAuthorListView"],"stylesheets":[],"_isYUI":true},"publicationAbstract":{"data":{"publicationUid":221618614,"abstract":"<noscript><\/noscript><div>This contribution develops a theoretical framework that takes into account the effect of approximate optimization on learning algorithms. The analysis shows distinct tradeoffs for the case of small-scale and large-sc ale learning problems. Small-scale learning problems are subject to the usual approximation-estimation tradeoff. Large-scale learning problems are subject to a qualitatively different tradeoff involving the computational complexity of the underlying optimization algorithms in non-trivial ways.<\/div>","canEdit":false,"isAdmin":false,"isArtifact":false,"showFullAbstract":false,"widgetId":"rgw12_56ab9e8f16567"},"id":"rgw12_56ab9e8f16567","partials":[],"templateName":"publicliterature\/stubs\/PublicationAbstract.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationAbstract.html?publicationUid=221618614","viewClass":"views.publicliterature.PublicationAbstractView","yuiModules":["rg.views.publicliterature.PublicationAbstractView"],"stylesheets":[],"_isYUI":true},"publicationKeywords":null,"publicationState":null,"isGuest":true,"isAdminEditingAllowed":false,"isArtifact":false,"figureListWidget":null,"previewImage":"https:\/\/i1.rgstatic.net\/publication\/221618614_The_Tradeoffs_of_Large_Scale_Learning\/links\/004635219281099d85000000\/smallpreview.png","nativeAdDisclosure":null,"showFollowPublicationButton":false,"followPublicationPromo":{"data":{"widgetId":"rgw13_56ab9e8f16567"},"id":"rgw13_56ab9e8f16567","partials":[],"templateName":"publicliterature\/stubs\/FollowPublicationPromo.html","templateExtensions":[],"attrs":{"context":null,"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.FollowPublicationPromo.html","viewClass":null,"yuiModules":["css-pow-publicliterature-FollowPublicationPromo"],"stylesheets":["pow\/publicliterature\/FollowPublicationPromo.css"],"_isYUI":true},"widgetId":"rgw5_56ab9e8f16567"},"id":"rgw5_56ab9e8f16567","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailItem.html","templateExtensions":["generalHelpers"],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailItem.html?publicationUid=221618614&showActionBar=0&showContactAuthorButton=1&showRequestFulltextExperience=0&showNoRgAuthorsRequestFulltextExperience=0&showFollowPublicationPromo=1","viewClass":"views.publicliterature.PublicationDetailItemView","yuiModules":["rg.views.publicliterature.PublicationDetailItemView"],"stylesheets":[],"_isYUI":true},"similarPublications":{"data":{"publicationListItems":[{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":2049618089,"url":"researcher\/2049618089_C_Y_Kiyono","fullname":"C Y Kiyono","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":75152600,"url":"researcher\/75152600_N_Perez","fullname":"N P\u00e9rez","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":6618272,"url":"researcher\/6618272_E_C_N_Silva","fullname":"E C N Silva","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Feb 2016","journal":"Smart Materials and Structures","showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/291419030_Determination_of_full_piezoelectric_complex_parameters_using_gradient-based_optimization_algorithm","usePlainButton":true,"publicationUid":291419030,"feedStubs":null,"hasFeedStubs":false,"impactPoints":"2.50","url":"publication\/291419030_Determination_of_full_piezoelectric_complex_parameters_using_gradient-based_optimization_algorithm","title":"Determination of full piezoelectric complex parameters using gradient-based optimization algorithm","displayTitleAsLink":true,"authors":[{"id":2049618089,"url":"researcher\/2049618089_C_Y_Kiyono","fullname":"C Y Kiyono","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":75152600,"url":"researcher\/75152600_N_Perez","fullname":"N P\u00e9rez","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":6618272,"url":"researcher\/6618272_E_C_N_Silva","fullname":"E C N Silva","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["Smart Materials and Structures 02\/2016; 25(2):025019. DOI:10.1088\/0964-1726\/25\/2\/025019"],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/291419030_Determination_of_full_piezoelectric_complex_parameters_using_gradient-based_optimization_algorithm","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/291419030_Determination_of_full_piezoelectric_complex_parameters_using_gradient-based_optimization_algorithm\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw15_56ab9e8f16567"},"id":"rgw15_56ab9e8f16567","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=291419030","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":2096067985,"url":"researcher\/2096067985_Ines_Mathlouthi","fullname":"Ines Mathlouthi","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2096058155,"url":"researcher\/2096058155_Sadok_Bouamama","fullname":"Sadok Bouamama","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Jan 2016","journal":"International Journal of Knowledge-Based and Intelligent Engineering Systems","showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/292077460_A_family_of_honey-bee_optimization_algorithms_for_Max-CSPs","usePlainButton":true,"publicationUid":292077460,"feedStubs":null,"hasFeedStubs":false,"impactPoints":false,"url":"publication\/292077460_A_family_of_honey-bee_optimization_algorithms_for_Max-CSPs","title":"A family of honey-bee optimization algorithms for Max-CSPs","displayTitleAsLink":true,"authors":[{"id":2096067985,"url":"researcher\/2096067985_Ines_Mathlouthi","fullname":"Ines Mathlouthi","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2096058155,"url":"researcher\/2096058155_Sadok_Bouamama","fullname":"Sadok Bouamama","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["International Journal of Knowledge-Based and Intelligent Engineering Systems 01\/2016; 19(4):215-224. DOI:10.3233\/KES-150323"],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/292077460_A_family_of_honey-bee_optimization_algorithms_for_Max-CSPs","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/292077460_A_family_of_honey-bee_optimization_algorithms_for_Max-CSPs\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw16_56ab9e8f16567"},"id":"rgw16_56ab9e8f16567","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=292077460","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":69867767,"url":"researcher\/69867767_Qichang_Duan","fullname":"Qichang Duan","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2081635333,"url":"researcher\/2081635333_Mingxuan_Mao","fullname":"Mingxuan Mao","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":70988676,"url":"researcher\/70988676_Pan_Duan","fullname":"Pan Duan","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2081620257,"url":"researcher\/2081620257_Bei_Hu","fullname":"Bei Hu","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Feb 2016","journal":"Kybernetes","showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/291369789_An_improved_artificial_fish_swarm_algorithm_optimized_by_particle_swarm_optimization_algorithm_with_extended_memory","usePlainButton":true,"publicationUid":291369789,"feedStubs":null,"hasFeedStubs":false,"impactPoints":"0.43","url":"publication\/291369789_An_improved_artificial_fish_swarm_algorithm_optimized_by_particle_swarm_optimization_algorithm_with_extended_memory","title":"An improved artificial fish swarm algorithm optimized by particle swarm optimization algorithm with extended memory","displayTitleAsLink":true,"authors":[{"id":69867767,"url":"researcher\/69867767_Qichang_Duan","fullname":"Qichang Duan","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2081635333,"url":"researcher\/2081635333_Mingxuan_Mao","fullname":"Mingxuan Mao","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":70988676,"url":"researcher\/70988676_Pan_Duan","fullname":"Pan Duan","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2081620257,"url":"researcher\/2081620257_Bei_Hu","fullname":"Bei Hu","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["Kybernetes 02\/2016; 45(2):210-222. DOI:10.1108\/K-09-2014-0198"],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/291369789_An_improved_artificial_fish_swarm_algorithm_optimized_by_particle_swarm_optimization_algorithm_with_extended_memory","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/291369789_An_improved_artificial_fish_swarm_algorithm_optimized_by_particle_swarm_optimization_algorithm_with_extended_memory\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw17_56ab9e8f16567"},"id":"rgw17_56ab9e8f16567","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=291369789","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"viewClass":"sidebar","widgetId":"rgw14_56ab9e8f16567"},"id":"rgw14_56ab9e8f16567","partials":[],"templateName":"publicliterature\/stubs\/SimilarPublications.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.SimilarPublications.html?referencePublicationId=221618614&view=sidebar","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationFulltextPreview":null,"publicationResourcesFulltext":{"data":{"publicationUid":221618614,"publicationResourceList":{"data":{"publicationResourceItems":[{"data":{"publicationUid":221618614,"publicationType":"inProceedings","linkId":"004635219281099d85000000","fileName":"004635219281099d85000000.pdf","fileUrl":"profile\/Olivier_Bousquet\/publication\/221618614_The_Tradeoffs_of_Large_Scale_Learning\/links\/004635219281099d85000000.pdf","name":"Olivier Bousquet","nameUrl":"profile\/Olivier_Bousquet","canRemove":false,"fileIcon":"ico-pub","canPreview":true,"hasPublisherLink":null,"hasMetaData":true,"hide":false,"fulltext":"ico-pub","origin":"publication_list","isLastLink":false,"isUserLink":true,"uploadDate":"Jun 5, 2014","fileSize":"123.3 KB","widgetId":"rgw20_56ab9e8f16567"},"id":"rgw20_56ab9e8f16567","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceItem.html","templateExtensions":["generalHelpers"],"attrs":{"fileRequiredPublicationTypes":["code","coverPage","experimentFindings","method","negativeResults","presentation","rawData","researchProposal","workingPaper","artifact","dataset"]},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceItem.html?publicationUid=221618614&linkId=004635219281099d85000000&hide=0&disableJavascript=disableJavascript&useAlternativeTemplate=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"publicationUid":221618614,"publicationType":"inProceedings","linkId":"0ffb612a0cf29b76d37db72c","fileName":"The Tradeoffs of Large Scale Learning.","fileUrl":"http:\/\/citeseerx.ist.psu.edu\/viewdoc\/download?doi=10.1.1.168.5389&amp;rep=rep1&amp;type=pdf","name":"psu.edu","nameUrl":"http:\/\/citeseerx.ist.psu.edu\/viewdoc\/download?doi=10.1.1.168.5389&amp;rep=rep1&amp;type=pdf","canRemove":false,"fileIcon":"ico-pub","canPreview":true,"hasPublisherLink":null,"hasMetaData":true,"hide":false,"fulltext":"ico-pub","origin":"publication_list","isLastLink":false,"isUserLink":false,"widgetId":"rgw21_56ab9e8f16567"},"id":"rgw21_56ab9e8f16567","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceItem.html","templateExtensions":["generalHelpers"],"attrs":{"fileRequiredPublicationTypes":["code","coverPage","experimentFindings","method","negativeResults","presentation","rawData","researchProposal","workingPaper","artifact","dataset"]},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceItem.html?publicationUid=221618614&linkId=0ffb612a0cf29b76d37db72c&hide=0&disableJavascript=disableJavascript&useAlternativeTemplate=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"widgetId":"rgw19_56ab9e8f16567"},"id":"rgw19_56ab9e8f16567","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceList.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceList.html?publicationUid=221618614&limit=3&disableJavascript=disableJavascript&type=fulltextFile","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"resourceCount":2,"hidden":false,"showMore":false,"fulltext":true,"publicationDownloadCount":{"data":{"value":47,"valueFormatted":"47","widgetId":"rgw22_56ab9e8f16567"},"id":"rgw22_56ab9e8f16567","partials":[],"templateName":"publicliterature\/stubs\/PublicationDownloadCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDownloadCount.html?publicationUid=221618614","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw18_56ab9e8f16567"},"id":"rgw18_56ab9e8f16567","partials":[],"templateName":"publicliterature\/stubs\/PublicationResources.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResources.html?publicationUid=221618614&type=fulltextFile&disableJavascript=1","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationResourcesAttachments":{"data":{"publicationUid":221618614,"publicationResourceList":{"data":{"publicationResourceItems":[],"widgetId":"rgw24_56ab9e8f16567"},"id":"rgw24_56ab9e8f16567","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceList.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceList.html?publicationUid=221618614&limit=3&disableJavascript=disableJavascript&type=attachmentFile","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"resourceCount":0,"hidden":true,"showMore":false,"fulltext":false,"publicationDownloadCount":{"data":{"value":47,"valueFormatted":"47","widgetId":"rgw25_56ab9e8f16567"},"id":"rgw25_56ab9e8f16567","partials":[],"templateName":"publicliterature\/stubs\/PublicationDownloadCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDownloadCount.html?publicationUid=221618614","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw23_56ab9e8f16567"},"id":"rgw23_56ab9e8f16567","partials":[],"templateName":"publicliterature\/stubs\/PublicationResources.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResources.html?publicationUid=221618614&type=attachmentFile","viewClass":"views.publicliterature.PublicationResourcesView","yuiModules":["rg.views.publicliterature.PublicationResourcesView"],"stylesheets":[],"_isYUI":true},"publicationText":{"data":{"hide":false,"pages":[{"page":1,"text":"The Tradeoffs of Large Scale Learning\nL\u00b4 eon Bottou\nNEC laboratories of America\nPrinceton, NJ 08540, USA\nleon@bottou.org\nOlivier Bousquet\nGoogle Z\u00a8 urich\n8002 Zurich, Switzerland\nolivier.bousquet@m4x.org\nAbstract\nThis contribution develops a theoretical framework that takes into account the\neffect of approximate optimization on learning algorithms. The analysis shows\ndistinct tradeoffs for the case of small-scale and large-scale learning problems.\nSmall-scale learning problems are subject to the usual approximation\u2013estimation\ntradeoff. Large-scale learning problems are subject to a qualitatively different\ntradeoff involving the computational complexity of the underlying optimization\nalgorithms in non-trivial ways.\n1 Motivation\nThe computational complexity of learning algorithms has seldom been taken into account by the\nlearning theory. Valiant [1] states that a problem is \u201clearnable\u201d when there exists a probably approx-\nimatively correct learning algorithm with polynomial complexity. Whereas much progress has been\nmade on the statistical aspect (e.g., [2, 3, 4]), very little has been told about the complexity side of\nthis proposal (e.g., [5].)\nComputational complexity becomes the limiting factor when one envisions large amounts of training\ndata. Two important examples come to mind:\n\u2022 Data mining exists because competitive advantages can be achieved by analyzing the\nmasses of data that describe the life of our computerized society. Since virtually every\ncomputer generates data, the data volume is proportional to the available computing power.\nTherefore one needs learning algorithms that scale roughly linearly with the total volume\nof data.\n\u2022 Artificial intelligence attempts to emulate the cognitive capabilities of human beings. Our\nbiological brains can learn quite efficiently from the continuous streams of perceptual data\ngenerated by our six senses, using limited amounts of sugar as a source of power. This\nobservation suggests that there are learning algorithms whose computing time requirements\nscale roughly linearly with the total volume of data.\nThis contribution finds its source in the idea that approximate optimization algorithms might be\nsufficient for learning purposes. The first part proposes new decomposition of the test error where\nan additional term represents the impact of approximate optimization. In the case of small-scale\nlearning problems, this decomposition reduces to the well known tradeoff between approximation\nerror and estimation error. In the case of large-scale learning problems, the tradeoff is more com-\nplex because it involves the computational complexity of the learning algorithm. The second part\nexplores the asymptotic properties of the large-scale learning tradeoff for various prototypical learn-\ning algorithms under various assumptions regarding the statistical estimation rates associated with\nthe chosen objective functions. This part clearly shows that the best optimization algorithms are not\nnecessarily the best learning algorithms. Maybe more surprisingly, certain algorithms perform well\nregardless of the assumed rate for the statistical estimation error."},{"page":2,"text":"2 Approximate Optimization\n2.1 Setup\nFollowing [6, 2], we consider a space of input-output pairs (x,y) \u2208 X \u00d7 Y endowed with a proba-\nbility distribution P(x,y). The conditional distribution P(y|x) represents the unknown relationship\nbetween inputs and outputs. The discrepancy between the predicted output \u02c6 y and the real output\ny is measured with a loss function \u2113(\u02c6 y,y). Our benchmark is the function f\u2217that minimizes the\nexpected risk\n?\nthat is,\nf\u2217(x) = argmin\n\u02c6 y\nAlthough the distribution P(x,y) is unknown, we are given a sample S of n independently drawn\ntraining examples (xi,yi), i = 1...n. We define the empirical risk\nE(f) =\u2113(f(x),y)dP(x,y) = E[\u2113(f(x),y)],\nE[\u2113(\u02c6 y,y)|x].\nEn(f) =1\nn\nn\n?\ni=1\n\u2113(f(xi),yi) = En[\u2113(f(x),y)].\nOur first learning principle consists in choosing a family F of candidate prediction functions and\nfinding the function fn= argminf\u2208FEn(f) that minimizes the empirical risk. Well known com-\nbinatorial results (e.g., [2]) support this approach provided that the chosen family F is sufficiently\nrestrictive. Since the optimal function f\u2217is unlikely to belong to the family F, we also define\nf\u2217\nF= argminf\u2208FE(f). For simplicity, we assume that f\u2217, f\u2217\nWe can then decompose the excess error as\nFand fnare well defined and unique.\nE[E(fn) \u2212 E(f\u2217)] = E[E(f\u2217\nwhere the expectation is taken with respect to the random choice of training set. The approximation\nerror Eappmeasures how closely functions in F can approximate the optimal solution f\u2217. The\nestimation error Eestmeasures the effect of minimizing the empirical risk En(f) instead of the\nexpected risk E(f). The estimation error is determined by the number of training examples and by\nthe capacity of the family of functions [2]. Large families1of functions have smaller approximation\nerrors but lead to higher estimation errors. This tradeoff has been extensively discussed in the\nliterature [2, 3] and lead to excess errors that scale between the inverse and the inverse square root\nof the number of examples [7, 8].\nF) \u2212 E(f\u2217)] + E[E(fn) \u2212 E(f\u2217\nF)] = Eapp+ Eest,\n(1)\n2.2 Optimization Error\nFinding fnby minimizing the empirical risk En(f) is often a computationally expensive operation.\nSince the empirical risk En(f) is already an approximation of the expected risk E(f), it should\nnot be necessary to carry out this minimization with great accuracy. For instance, we could stop an\niterative optimization algorithm long before its convergence.\nLet us assume that our minimization algorithm returns an approximate solution\u02dcfnsuch that\nEn(\u02dcfn) < En(fn) + \u03c1\nwhere \u03c1 \u2265 0 is a predefined tolerance. An additional term Eopt= E?E(\u02dcfn) \u2212 E(fn)?then appears\nE=\nE[E(f\u2217\n=Eapp+ Eest+ Eopt.\nWecallthisadditionaltermoptimizationerror. Itreflectstheimpactoftheapproximateoptimization\non the generalization performance. Its magnitude is comparable to \u03c1 (see section 3.1.)\nin the decomposition of the excess error E = E?E(\u02dcfn) \u2212 E(f\u2217)?:\nF) \u2212 E(f\u2217)] + E[E(fn) \u2212 E(f\u2217\nF)] + E?E(\u02dcfn) \u2212 E(fn)?\n(2)\n1We often consider nested families of functions of the form Fc = {f \u2208 H, \u03a9(f) \u2264 c}. Then, for each\nvalue of c, function fnis obtained by minimizing the regularized empirical risk En(f) + \u03bb\u03a9(f) for a suitable\nchoice of the Lagrange coefficient \u03bb. We can then control the estimation-approximation tradeoff by choosing\n\u03bb instead of c."},{"page":3,"text":"2.3The Approximation\u2013Estimation\u2013Optimization Tradeoff\nThis decomposition leads to a more complicated compromise. It involves three variables and two\nconstraints. The constraints are the maximal number of available training example and the maximal\ncomputation time. The variables are the size of the family of functions F, the optimization accuracy\n\u03c1, and the number of examples n. This is formalized by the following optimization problem.\nmin\nF,\u03c1,n\nE = Eapp+ Eest+ Eopt\nsubject to\n?\nn\u2264\n\u2264\nnmax\nTmax\nT(F,\u03c1,n)\n(3)\nThe number n of training examples is a variable because we could choose to use only a subset of\nthe available training examples in order to complete the optimization within the alloted time. This\nhappens often in practice. Table 1 summarizes the typical evolution of the quantities of interest with\nthe three variables F, n, and \u03c1 increase.\nTable 1: Typical variations when F, n, and \u03c1 increase.\nFn\u03c1\nEapp\nEest\nEopt\nT\n(approximation error)\n(estimation error)\n(optimization error)\n(computation time)\n\u0581\n\u0580\n\u00b7\u00b7\u00b7\n\u0580\n\u0581\n\u00b7\u00b7\u00b7\n\u0580\n\u0580\n\u0581\nThe solution of the optimization program (3) depends critically of which budget constraint is active:\nconstraint n < nmaxon the number of examples, or constraint T < Tmaxon the training time.\n\u2022 We speak of small-scale learning problem when (3) is constrained by the maximal number\nof examples nmax. Since the computing time is not limited, we can reduce the optimization\nerror Eoptto insignificant levels by choosing \u03c1 arbitrarily small. The excess error is then\ndominated by the approximation and estimation errors, Eappand Eest. Taking n = nmax,\nwe recover the approximation-estimation tradeoff that is the object of abundant literature.\n\u2022 We speak of large-scale learning problem when (3) is constrained by the maximal comput-\ning time Tmax. Approximate optimization, that is, choosing \u03c1 > 0, possibly can achieve\nbetter generalization because more training examples can be processed during the allowed\ntime. The specifics depend on the computational properties of the chosen optimization\nalgorithm through the expression of the computing time T(F,\u03c1,n).\n3 The Asymptotics of Large-scale Learning\nIn the previous section, we have extended the classical approximation-estimation tradeoff by taking\ninto account the optimization error. We have given an objective criterion to distiguish small-scale\nand large-scale learning problems. In the small-scale case, we recover the classical tradeoff between\napproximation and estimation. The large-scale case is substantially different because it involves\nthe computational complexity of the learning algorithm. In order to clarify the large-scale learning\ntradeoff with sufficient generality, this section makes several simplifications:\n\u2022 We are studying upper bounds of the approximation, estimation, and optimization er-\nrors (2). It is often accepted that these upper bounds give a realistic idea of the actual\nconvergence rates [9, 10, 11, 12]. Another way to find comfort in this approach is to say\nthat we study guaranteed convergence rates instead of the possibly pathological special\ncases.\n\u2022 We are studying the asymptotic properties of the tradeoff when the problem size increases.\nInstead of carefully balancing the three terms, we write E = O(Eapp)+O(Eest)+O(Eopt)\nand only need to ensure that the three terms decrease with the same asymptotic rate.\n\u2022 We are considering a fixed family of functions F and therefore avoid taking into account\nthe approximation error Eapp. This part of the tradeoff covers a wide spectrum of practical\nrealities such as choosing models and choosing features. In the context of this work, we do"},{"page":4,"text":"not believe we can meaningfully address this without discussing, for instance, the thorny\nissue of feature selection. Instead we focus on the choice of optimization algorithm.\n\u2022 Finally, in order to keep this paper short, we consider that the family of functions F is\nlinearly parametrized by a vector w \u2208 Rd. We also assume that x, y and w are bounded,\nensuring that there is a constant B such that 0 \u2264 \u2113(fw(x),y) \u2264 B and \u2113(\u00b7,y) is Lipschitz.\nWe first explain how the uniform convergence bounds provide convergence rates that take the op-\ntimization error into account. Then we discuss and compare the asymptotic learning properties of\nseveral optimization algorithms.\n3.1 Convergence of the Estimation and Optimization Errors\nThe optimization error Eoptdepends directly on the optimization accuracy \u03c1. However, the accuracy\n\u03c1 involves the empirical quantity En(\u02dcfn) \u2212 En(fn), whereas the optimization error Eoptinvolves\nits expected counterpart E(\u02dcfn) \u2212 E(fn). This section discusses the impact on the optimization\nerror Eoptand of the optimization accuracy \u03c1 on generalization bounds that leverage the uniform\nconvergence concepts pioneered by Vapnik and Chervonenkis (e.g., [2].)\nIn this discussion, we use the letter c to refer to any positive constant. Multiple occurences of the\nletter c do not necessarily imply that the constants have identical values.\n3.1.1 Simple Uniform Convergence Bounds\nRecall that we assume that F is linearly parametrized by w \u2208 Rd. Elementary uniform convergence\nresults then state that\n\u00bb\nwhere the expectation is taken with respect to the random choice of the training set.2This result\nimmediately provides a bound on the estimation error:\nE\nsup\nf\u2208F|E(f) \u2212 En(f)|\n\u2013\n\u2264 c\nr\nd\nn,\nEest\n=\nE\u02c6 `E(fn) \u2212 En(fn)\u00b4+`En(fn) \u2212 En(f\u2217\n2 E\nsup\nF)\u00b4+`En(f\u2217\nF) \u2212 E(f\u2217\nF)\u00b4 \u02dc\n\u2264\n\u00bb\nf\u2208F|E(f) \u2212 En(f)|\n\u2013\n\u2264 c\nr\nd\nn.\nThis same result also provides a combined bound for the estimation and optimization errors:\nEest+ Eopt\n=\nE\u02c6E(\u02dcfn) \u2212 En(\u02dcfn)\u02dc+ E\u02c6En(\u02dcfn) \u2212 En(fn)\u02dc\nr\nn\n+\nE[En(fn) \u2212 En(f\u2217\nF)] + E[En(f\u2217\nF) \u2212 E(f\u2217\nF)]\n\u2264\nc\nd\nn+ \u03c1 + 0 + c\nr\nd\n= c\n \n\u03c1 +\nr\nd\nn\n!\n.\nUnfortunately, this convergence rate is known to be pessimistic in many important cases. More\nsophisticated bounds are required.\n3.1.2 Faster Rates in the Realizable Case\nWhen the loss functions \u2113(\u02c6 y,y) is positive, with probability 1\u2212e\u2212\u03c4for any \u03c4 > 0, relative uniform\nconvergence bounds state that\nsup\nf\u2208F\nE(f) \u2212 En(f)\npE(f)\n\u2264 c\nr\nd\nnlogn\nd+\u03c4\nn.\nThis result is very useful because it provides faster convergence rates O(logn\/n) in the realizable\ncase, that is when \u2113(fn(xi),yi) = 0 for all training examples (xi,yi). We have then En(fn) = 0,\nEn(\u02dcfn) \u2264 \u03c1, and we can write\nE(\u02dcfn) \u2212 \u03c1 \u2264 c\nq\nE(\u02dcfn)\nr\nd\nnlogn\nd+\u03c4\nn.\n2Although the original Vapnik-Chervonenkis bounds have the form c\nbe eliminated using the \u201cchaining\u201d technique (e.g., [10].)\nq\nd\nnlogn\nd, the logarithmic term can"},{"page":5,"text":"Viewing this as a second degree polynomial inequality in variable\n?\nE(\u02dcfn), we obtain\nE(\u02dcfn) \u2264 c\n\u201e\n\u03c1 +d\nnlogn\nd+\u03c4\nn\n\u00ab\n.\nIntegrating this inequality using a standard technique (see, e.g., [13]), we obtain a better convergence\nrate of the combined estimation and optimization error:\nEest+ Eopt = E\nh\nE(\u02dcfn) \u2212 E(f\u2217\nF)\ni\n\u2264 E\nh\nE(\u02dcfn)\ni\n= c\n\u201e\n\u03c1 +d\nnlogn\nd\n\u00ab\n.\n3.1.3Fast Rate Bounds\nMany authors (e.g., [10, 4, 12]) obtain fast statistical estimation rates in more general conditions.\nThese bounds have the general form\nEapp+ Eest\u2264 c\n?\nEapp+\n?d\nnlogn\nd\n?\u03b1?\nfor\n1\n2\u2264 \u03b1 \u2264 1.\n(4)\nThis result holds when one can establish the following variance condition:\n\u2200f \u2208 F\nE\n??\u2113(f(X),Y ) \u2212 \u2113(f\u2217\nF(X),Y )?2?\n\u2264 c\n?\nE(f) \u2212 E(f\u2217\nF)\n?2\u22121\n\u03b1\n.\n(5)\nThe convergence rate of (4) is described by the exponent \u03b1 which is determined by the quality of\nthe variance bound (5). Works on fast statistical estimation identify two main ways to establish such\na variance condition.\n\u2022 Exploiting the strict convexity of certain loss functions [12, theorem 12]. For instance, Lee\net al. [14] establish a O(logn\/n) rate using the squared loss \u2113(\u02c6 y,y) = (\u02c6 y \u2212 y)2.\n\u2022 Making assumptions on the data distribution. In the case of pattern recognition problems,\nfor instance, the \u201cTsybakov condition\u201d indicates how cleanly the posterior distributions\nP(y|x) cross near the optimal decision boundary [11, 12]. The realizable case discussed in\nsection 3.1.2 can be viewed as an extreme case of this.\nDespite their much greater complexity, fast rate estimation results can accomodate the optimization\naccuracy \u03c1 using essentially the methods illustrated in sections 3.1.1 and 3.1.2. We then obtain a\nbound of the form\nE = Eapp+ Eest+ Eopt= E\n?\nE(\u02dcfn) \u2212 E(f\u2217)\n?\n\u2264 c\n?\nEapp+\n?d\nnlogn\nd\n?\u03b1\n+ \u03c1\n?\n.\n(6)\nFor instance, a general result with \u03b1 = 1 is provided by Massart [13, theorem 4.2]. Combining this\nresult with standard bounds on the complexity of classes of linear functions (e.g., [10]) yields the\nfollowing result:\nE = Eapp+ Eest+ Eopt= E\n?\nE(\u02dcfn) \u2212 E(f\u2217)\n?\n\u2264 c\n?\nEapp+d\nnlogn\nd+ \u03c1\n?\n.\n(7)\nSee also [15, 4] for more bounds taking into account the optimization accuracy.\n3.2Gradient Optimization Algorithms\nWe now discuss and compare the asymptotic learning properties of four gradient optimization algo-\nrithms. Recall that the family of function F is linearly parametrized by w \u2208 Rd. Let w\u2217\ncorrespond to the functions f\u2217\nfunctions w ?\u2192 \u2113(fw(x),y) are convex and twice differentiable with continuous second derivatives.\nConvexity ensures that the empirical const function C(w) = En(fw) has a single minimum.\nTwo matrices play an important role in the analysis: the Hessian matrix H and the gradient covari-\nance matrix G, both measured at the empirical optimum wn.\n\u22022C\n\u2202w2(wn) = En\n??\u2202\u2113(fwn(x),y)\nFand wn\nFand fndefined in section 2.1. In this section, we assume that the\nH=\n?\u22022\u2113(fwn(x),y)\n??\u2202\u2113(fwn(x),y)\n\u2202w2\n?\n,\n(8)\nG=\nEn\n\u2202w \u2202w\n?\u2032?\n.\n(9)"},{"page":6,"text":"The relation between these two matrices depends on the chosen loss function. In order to summarize\nthem, we assume that there are constants \u03bbmax\u2265 \u03bbmin> 0 and \u03bd > 0 such that, for any \u03b7 > 0,\nwe can choose the number of examples n large enough to ensure that the following assertion is true\nwith probability greater than 1 \u2212 \u03b7 :\ntr(G H\u22121) \u2264 \u03bd\nand\nEigenSpectrum(H) \u2282 [\u03bbmin, \u03bbmax]\n(10)\nThe condition number \u03ba = \u03bbmax\/\u03bbmincharacterizes the optimisation difficulty (e.g., [16].)\nThe condition \u03bbmin > 0 avoids complications with stochastic gradient algorithms. Note that this\ncondition only implies strict convexity around the optimum. For instance, consider a loss function\nobtained by smoothing the well known hinge loss \u2113(z,y) = max{0,1\u2212yz} in a small neighborhood\nof its non-differentiable points. Function C(w) is then piecewise linear with smoothed edges and\nvertices. It is not strictly convex. However its minimum is likely to be on a smoothed vertex with a\nnon singular Hessian. When we have strict convexity, the argument of [12, theorem 12] yields fast\nestimation rates \u03b1 \u2248 1 in (4) and (6). This is not necessarily the case here.\nThe four algorithm considered in this paper use information about the gradient of the cost function\nto iteratively update their current estimate w(t) of the parameter vector.\n\u2022 Gradient Descent (GD) iterates\nw(t + 1) = w(t) \u2212 \u03b7\u2202C\n\u2202w(w(t)) = w(t) \u2212 \u03b71\nn\nn\n?\ni=1\n\u2202\n\u2202w\u2113?fw(t)(xi),yi\n?\nwhere \u03b7 > 0 is a small enough gain. GD is an algorithm with linear convergence [16]:\nwhen \u03b7 = 1\/\u03bbmax, this algorithm requires O(\u03balog(1\/\u03c1)) iterations to reach accuracy \u03c1.\nThe exact number of iterations depends on the choice of the initial parameter vector.\n\u2022 Second Order Gradient Descent (2GD) iterates\nw(t + 1) = w(t) \u2212 H\u22121\u2202C\n\u2202w(w(t)) = w(t) \u22121\nnH\u22121\nn\n?\ni=1\n\u2202\n\u2202w\u2113?fw(t)(xi),yi\n?\nwhere matrix H\u22121is the inverse of the Hessian matrix (8). This is more favorable than\nNewton\u2019s algorithm because we do not evaluate the local Hessian at each iteration but\nsimply assume that we know in advance the Hessian at the optimum. 2GD is a superlinear\noptimization algorithm with quadratic convergence [16]. When the cost is quadratic, a\nsingle iteration is sufficient. In the general case, O(loglog(1\/\u03c1)) iterations are required to\nreach accuracy \u03c1.\n\u2022 Stochastic Gradient Descent (SGD) picks a random training example (xt,yt) at each\niteration and updates the parameter w on the basis of this example only,\nw(t + 1) = w(t) \u2212\u03b7\nt\n\u2202\n\u2202w\u2113?fw(t)(xt),yt\n?.\nMurata [17, section 2.2], characterizes the mean ES[w(t)] and variance VarS[w(t)] with\nrespect to the distribution implied by the random examples drawn from a given training\nset S at each iteration. Applying this result to the discrete training set distribution for\n\u03b7 = 1\/\u03bbmin, we have \u03b4w(t)2= O(1\/t) where \u03b4w(t) is a shorthand notation for w(t)\u2212wn.\nWe can then write\nES[C(w(t)) \u2212 inf C ]=\nES\n\u02c6tr`H \u03b4w(t)\u03b4w(t)\u2032\u00b4\u02dc+ o`1\ntr`H ES[\u03b4w(t)]ES[\u03b4w(t)]\u2032+ H VarS[w(t)]\u00b4+ o`1\nt\n+ o`1\nt\n\u00b4\n=\nt\n\u00b4\n\u2264\ntr(GH)\nt\n\u00b4\n\u2264\n\u03bd\u03ba2\nt\n+ o`1\nt\n\u00b4.\n(11)\nTherefore the SGD algorithm reaches accuracy \u03c1 after less than \u03bd\u03ba2\/\u03c1 + o(1\/\u03c1) iterations\non average. The SGD convergence is essentially limited by the stochastic noise induced\nby the random choice of one example at each iteration. Neither the initial value of the\nparameter vector w nor the total number of examples n appear in the dominant term of this\nbound! When the training set is large, one could reach the desired accuracy \u03c1 measured on\nthe whole training set without even visiting all the training examples. This is in fact a kind\nof generalization bound."},{"page":7,"text":"Table 2: Asymptotic results for gradient algorithms (with probability 1). Compare the second\nlast column (time to optimize) with the last column (time to reach the excess test error \u01eb).\nLegend: n number of examples; d parameter dimension; \u03ba, \u03bd see equation (10).\nAlgorithm Cost of one\niteration\nIterations\nto reach \u03c1\nTime to reach\naccuracy \u03c1\nTime to reach\nE \u2264 c(Eapp+ \u03b5)\nGD\nO(nd)O\n?\nloglog1\n\u03balog1\n\u03c1\n?\n\u03c1\n?\n?\nO\n?\nnd\u03balog1\n\u03c1\n?\nO\n?\nd2\u03ba\n\u03b51\/\u03b1log2 1\n\u03b5\n?\n2GD\nO?d2+ nd?\nO(d)\nO\n?\n\u03c1+ o\n?\nO\n??d2+ nd?loglog1\nO\n?\nO\n?\n\u03c1\n?\nO\n?\nd2\n\u03b51\/\u03b1log1\n\u03b5loglog1\n?\nd2\u03bd\n\u03b5\n\u03b5\n?\nSGD\n\u03bd\u03ba2\n?\n1\n\u03c1\n1\n\u03c1\nd\u03bd\u03ba2\n\u03c1\n?\n?\nO\n?\nd\u03bd \u03ba2\n\u03b5\n?\n2SGD\nO?d2?\n\u03bd\n\u03c1+ o\n?\nd2\u03bd\n\u03c1\nO\n?\n\u2022 Second Order Stochastic Gradient Descent (2SGD) replaces the gain \u03b7 by the inverse of\nthe Hessian matrix H:\nw(t + 1) = w(t) \u22121\ntH\u22121\u2202\n\u2202w\u2113?fw(t)(xt),yt\n?.\nUnlike standard gradient algorithms, using the second order information does not change\nthe influence of \u03c1 on the convergence rate but improves the constants. Using again [17,\ntheorem 4], accuracy \u03c1 is reached after \u03bd\/\u03c1 + o(1\/\u03c1) iterations.\nFor each of the four gradient algorithms, the first three columns of table 2 report the time for a single\niteration, the number of iterations needed to reach a predefined accuracy \u03c1, and their product, the\ntime needed to reach accuracy \u03c1. These asymptotic results are valid with probability 1, since the\nprobability of their complement is smaller than \u03b7 for any \u03b7 > 0.\nThe fourth column bounds the time necessary to reduce the excess error E below c(Eapp+\u03b5) where c\nis the constant from (6). This is computed by observing that choosing \u03c1 \u223c`d\n\u03c1 \u223c \u03b5 and n \u223c\nthe best excess error achieved by each algorithm within the limited time Tmax. This provides the\nasymptotic solution of the Estimation\u2013Optimization tradeoff (3) for large scale problems satisfying\nour assumptions.\nnlogn\nd\n\u00b4\u03b1in (6) achieves\nthe fastest rate for \u03b5, with minimal computation time. We can then use the asymptotic equivalences\nd\n\u03b51\/\u03b1log1\n\u03b5. Setting the fourth column expressions to Tmaxand solving for \u01eb yields\nThese results clearly show that the generalization performance of large-scale learning systems de-\npends on both the statistical properties of the objective function and the computational properties of\nthe chosen optimization algorithm. Their combination leads to surprising consequences:\n\u2022 The SGD and 2SGD results do not depend on the estimation rate \u03b1. When the estimation\nrate is poor, there is less need to optimize accurately. That leaves time to process more\nexamples. A potentially more useful interpretation leverages the fact that (11) is already a\nkind of generalization bound: its fast rate trumps the slower rate assumed for the estimation\nerror.\n\u2022 Second order algorithms bring little asymptotical improvements in \u03b5. Although the super-\nlinear 2GD algorithm improves the logarithmic term, all four algorithms are dominated by\nthe polynomial term in (1\/\u03b5). However, there are important variations in the influence of\nthe constants d, \u03ba and \u03bd. These constants are very important in practice.\n\u2022 Stochastic algorithms (SGD, 2SGD) yield the best generalization performance despite be-\ning the worst optimization algorithms. This had been described before [18] and observed\nin experiments.\nIn contrast, since the optimization error Eoptof small-scale learning systems can be reduced to\ninsignificantlevels, theirgeneralizationperformanceissolelydeterminedbythestatisticalproperties\nof the objective function."},{"page":8,"text":"4 Conclusion\nTaking in account budget constraints on both the number of examples and the computation time,\nwe find qualitative differences between the generalization performance of small-scale learning sys-\ntems and large-scale learning systems. The generalization properties of large-scale learning systems\ndepend on both the statistical properties of the objective function and the computational proper-\nties of the optimization algorithm. We illustrate this fact with some asymptotic results on gradient\nalgorithms.\nConsiderable refinements of this framework can be expected. Extending the analysis to regular-\nized risk formulations would make results on the complexity of primal and dual optimization algo-\nrithms [19, 20] directly exploitable. The choice of surrogate loss function [7, 12] could also have a\nnon-trivial impact in the large-scale case.\nAcknowledgments\nPart of this work was funded by NSF grant CCR-0325463.\nReferences\n[1] Leslie G. Valiant. A theory of learnable. Proc. of the 1984 STOC, pages 436\u2013445, 1984.\n[2] Vladimir N. Vapnik. Estimation of Dependences Based on Empirical Data. Springer Series in Statistics.\nSpringer-Verlag, Berlin, 1982.\n[3] St\u00b4 ephane Boucheron, Olivier Bousquet, and G\u00b4 abor Lugosi. Theory of classification: a survey of recent\nadvances. ESAIM: Probability and Statistics, 9:323\u2013375, 2005.\n[4] Peter L. Bartlett and Shahar Mendelson. Empirical minimization. Probability Theory and Related Fields,\n135(3):311\u2013334, 2006.\n[5] J. Stephen Judd. On the complexity of loading shallow neural networks. Journal of Complexity, 4(3):177\u2013\n192, 1988.\n[6] Richard O. Duda and Peter E. Hart. Pattern Classification And Scene Analysis. Wiley and Son, 1973.\n[7] Tong Zhang. Statistical behavior and consistency of classification methods based on convex risk mini-\nmization. The Annals of Statistics, 32:56\u201385, 2004.\n[8] Clint Scovel and Ingo Steinwart. Fast rates for support vector machines. In Peter Auer and Ron Meir,\neditors, Proceedings of the 18th Conference on Learning Theory (COLT 2005), volume 3559 of Lecture\nNotes in Computer Science, pages 279\u2013294, Bertinoro, Italy, June 2005. Springer-Verlag.\n[9] Vladimir N. Vapnik, Esther Levin, and Yann LeCun. Measuring the VC-dimension of a learning machine.\nNeural Computation, 6(5):851\u2013876, 1994.\n[10] Olivier Bousquet. Concentration Inequalities and Empirical Processes Theory Applied to the Analysis of\nLearning Algorithms. PhD thesis, Ecole Polytechnique, 2002.\n[11] Alexandre B. Tsybakov. Optimal aggregation of classifiers in statistical learning. Annals of Statististics,\n32(1), 2004.\n[12] Peter L. Bartlett, Michael I. Jordan, and Jon D. McAuliffe. Convexity, classification and risk bounds.\nJournal of the American Statistical Association, 101(473):138\u2013156, March 2006.\n[13] Pascal Massart. Some applications of concentration inequalities to statistics. Annales de la Facult\u00b4 e des\nSciences de Toulouse, (2):245\u2013303, 2000.\n[14] Wee S. Lee, Peter L. Bartlett, and Robert C. Williamson. The importance of convexity in learning with\nsquared loss. IEEE Transactions on Information Theory, 44(5):1974\u20131980, 1998.\n[15] Shahar Mendelson. A few notes on statistical learning theory. In Shahar Mendelson and Alexander J.\nSmola, editors, Advanced Lectures in Machine Learning, volume 2600 of Lecture Notes in Computer\nScience, pages 1\u201340. Springer-Verlag, Berlin, 2003.\n[16] John E. Dennis, Jr. and Robert B. Schnabel. Numerical Methods For Unconstrained Optimization and\nNonlinear Equations. Prentice-Hall, Inc., Englewood Cliffs, New Jersey, 1983.\n[17] Noboru Murata. A statistical study of on-line learning. In David Saad, editor, Online Learning and Neural\nNetworks. Cambridge University Press, Cambridge, UK, 1998.\n[18] L\u00b4 eon Bottou and Yann LeCun. Large scale online learning. In Sebastian Thrun, Lawrence Saul, and Bern-\nhard Sch\u00a8 olkopf, editors, Advances in Neural Information Processing Systems 16. MIT Press, Cambridge,\nMA, 2004.\n[19] Thorsten Joachims. Training linear svms in linear time. In Proceedings of KDD\u201906, Philadelphia, PA,\nUSA, August 20-23 2006. ACM.\n[20] Don Hush, Patrick Kelly, Clint Scovel, and Ingo Steinwart. QP algorithms with guaranteed accuracy and\nrun time for support vector machines. Journal of Machine Learning Research, 7:733\u2013769, 2006."}],"fullTextUrl":"https:\/\/www.researchgate.net\/profile\/Olivier_Bousquet\/publication\/221618614_The_Tradeoffs_of_Large_Scale_Learning\/links\/004635219281099d85000000.pdf","widgetId":"rgw26_56ab9e8f16567"},"id":"rgw26_56ab9e8f16567","partials":[],"templateName":"publicliterature\/stubs\/PublicationText.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationText.html?publicationUid=221618614&hide=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationDetailAd":{"data":{"googleDfpSlot":null,"widgetId":"rgw27_56ab9e8f16567"},"id":"rgw27_56ab9e8f16567","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAd.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAd.html?publicationUid=221618614&slotId=336x280_Publications_ATF_Right&collapseSlotMode=never&fallbackContainerEnabled=1","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationRelations":null,"publicationRelationsReverse":null,"publicationUid":221618614,"showSignUpDialog":false,"selectNewSignUpDialog":false,"publicationQuestions":null,"publicationCitations":null,"publicationReviewPromo":null,"publicationUsedInReviews":null,"publicationPdfJsReader":{"data":{"isPreview":false,"licenseUrl":null,"licenseInfo":null,"defaultLinkData":{"linkId":"004635219281099d85000000","name":"Olivier Bousquet","date":null,"nameLink":"profile\/Olivier_Bousquet","filename":"","downloadLink":"https:\/\/www.researchgate.net\/profile\/Olivier_Bousquet\/publication\/221618614_The_Tradeoffs_of_Large_Scale_Learning\/links\/004635219281099d85000000.pdf?inViewer=0&pdfJsDownload=0&origin=publication_detail","viewerUrl":"https:\/\/www.researchgate.net\/profile\/Olivier_Bousquet\/publication\/221618614_The_Tradeoffs_of_Large_Scale_Learning\/links\/004635219281099d85000000.pdf?inViewer=1&pdfJsDownload=1&origin=publication_detail","downloadHash":"c84e823f553b85e18d610177d46443a1","showFileSizeNote":false,"fileSize":"123.3 KB","noFollow":false,"isDefault":true,"doi":null},"displayableLinks":[{"linkId":"004635219281099d85000000","name":"Olivier Bousquet","date":null,"nameLink":"profile\/Olivier_Bousquet","filename":"","downloadLink":"https:\/\/www.researchgate.net\/profile\/Olivier_Bousquet\/publication\/221618614_The_Tradeoffs_of_Large_Scale_Learning\/links\/004635219281099d85000000.pdf?inViewer=0&pdfJsDownload=0&origin=publication_detail","viewerUrl":"https:\/\/www.researchgate.net\/profile\/Olivier_Bousquet\/publication\/221618614_The_Tradeoffs_of_Large_Scale_Learning\/links\/004635219281099d85000000.pdf?inViewer=1&pdfJsDownload=1&origin=publication_detail","downloadHash":"c84e823f553b85e18d610177d46443a1","showFileSizeNote":false,"fileSize":"123.3 KB","noFollow":false,"isDefault":true,"doi":null}],"hasDisplayableLinks":false,"reader":{"data":{"pdfCommentsActive":false,"publicationType":"Conference Paper","onlyRenderFirstPage":false,"readMoreExperimentGoal":"goalPublicationPdfClicksReadMore","readMoreExperimentViewId":null,"comments":null,"figures":[],"figureAssetIds":[],"figureOverlayUrls":{"clickOnOverlay":"publication.PublicationFigures.html?_sg=RRC4GDn4kZIz6GTP5HVJztD4UUekMGtsrL5imhykMItimpS2q21mK1Csb0SkjHkGdG4nHEDunVobriSyB_VYhQ.Pyjjb2CuJGyxCIa56JaXyLRM4Owqc36lEl078oZFOY1KQP8BmaUtkYWmwovc0_PJBVGwdMQAsLIR_956LUSYMw","clickOnPill":"publication.PublicationFigures.html?_sg=1b6FpsSoLmMD7YUVrRWD0r6-p7cEvjGYQDpBCTsnFNWixOgoPhR-I3HsaHJ5YgajcLLD44xpN0odUTpv4OxSeA.xjRK8_wc5PYe7yIgUIcPLeY1AoG_BQjUlaPjOWCBxCHmjRbG3rgL_3pRmIkdQmUtiYSWoSBCdYtzEZsDNRcJkA"},"canSelect":false,"javascriptPath":"https:\/\/www.researchgate.net\/c\/o1q2er\/","downloadUrl":"https%3A%2F%2Fwww.researchgate.net%2Fprofile%2FOlivier_Bousquet%2Fpublication%2F221618614_The_Tradeoffs_of_Large_Scale_Learning%2Flinks%2F004635219281099d85000000.pdf%3FinViewer%3D1%26pdfJsDownload%3D1%26origin%3Dpublication_detail","viewerUrl":"https:\/\/www.researchgate.net\/c\/o1q2er\/javascript\/lib\/pdfjs\/web\/viewer.html","commentEndpoint":"https:\/\/www.researchgate.net\/rgformat\/api\/comment","experimentEndpoint":"https:\/\/www.researchgate.net\/rgformat\/api\/experiment?key=rfzf5LfPK5-VMQ0C_CSdLf2u5HgEr0hNDb6HmNQxvp07pj_a857w9ZiIw8ShhBWFGCSPTt46bPlACaX8NKNSnQ","urlHash":"3c2dd2da7fd70ebfd38df9098be523af","downloadTrackUrl":"application.PdfJsReader.ajaxTrackDownload.html?msrp=pnQReDTolMSI5KAbMpeUd5buRVbgADOea85hJWDqjrfG2kkYCujvkJZ91WY8E1IJwHbAfv8hlbJ3-ih_TQywUz2o1pYgLw877hCiso75O8g.cJb79-f9GAJFSNalsqSYrw2mN1DctP9Cga6wF97p2PydsmdWikClmKFE5sc-aO0zAlYsVJsh_lAFmd9qONIQsA.4D0-MZbJHx6UNYjOrKMukACXacA6JM-dC4ipvap6n5XWMuN8kioBSTpSl1vNq_vr-HKTrjEuKcc2Q7JCHmykOw","viewportMilestoneTrackUrl":"application.PdfJsReader.ajaxTrackViewportMilestone.html","linkId":"004635219281099d85000000","trackedDownloads":{"004635219281099d85000000":{"v":false,"d":false}},"assetId":"AS:104620034625540@1401954768782","readerDocId":null,"assetType":"fulltext","interactionType":{"comment":"comment","highlight":"highlight"},"publicationUid":221618614,"commentCursorPromo":null,"widgetId":"rgw29_56ab9e8f16567"},"id":"rgw29_56ab9e8f16567","partials":[],"templateName":"application\/stubs\/PdfJsReader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PdfJsReader.html?fileHref=https%3A%2F%2Fwww.researchgate.net%2Fprofile%2FOlivier_Bousquet%2Fpublication%2F221618614_The_Tradeoffs_of_Large_Scale_Learning%2Flinks%2F004635219281099d85000000.pdf%3FinViewer%3D1%26pdfJsDownload%3D1%26origin%3Dpublication_detail&assetId=AS%3A104620034625540%401401954768782&publicationUid=221618614&linkId=004635219281099d85000000&onlyShowFirstPage=0","viewClass":null,"yuiModules":["css-pow-application-PdfJsReader"],"stylesheets":["pow\/application\/PdfJsReader.css"],"_isYUI":true},"showHeader":true,"title":"The Tradeoffs of Large Scale Learning.","publicationType":"Conference Paper","downloadTrackUrl":"publicliterature.PublicationInlineReader.ajaxTrackDownload.html?msrp=MRkw_VU67Xrmv3yDVcm0mJLTVAiNOX54s-UUt6MQZReKqFXiEHTa7CIwAFgPnCsqD6qKo3r2NIDKnH87u945iQuoy27yflaJgnnoJ-AGCLo.-dt4YKQ_3e0_b5Da3VXDME5WFKj-xKkCzp5srAQJbksrmzVDM2HsWICD1DUOC2kWYFriMe_zWpgAxvUnBWMh4w.Ni4OBfz01P2emRAjsU-mLkvmhWZm4JzYdnp3cQ9dZsso_0O35z3H_Q_mXxPsgtNqxECxZRB3SazFiW8YzPpcfg","publicationUid":221618614,"trackedDownloads":{"004635219281099d85000000":{"v":false,"d":false}},"inlinePdf":false,"publicationComments":null,"showDownloadButton":true,"socialShare":{"data":{"shareItems":[{"data":{"name":"Facebook","url":"http:\/\/www.facebook.com\/share.php?u={{url}}{{#title}}&t={{title}}{{\/title}}","width":600,"height":350,"useUtmTags":true,"utmSource":"facebook","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareFacebook.ajaxTrackSocialShare.html","widgetId":"rgw31_56ab9e8f16567"},"id":"rgw31_56ab9e8f16567","partials":{"shareIcon":"application\/stubs\/partials\/shareFacebookBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareFacebook.html?provider=Facebook&shareIcon=shareIconBlog&utmSource=facebook&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"Twitter","url":"http:\/\/twitter.com\/intent\/tweet?text={{#title}}{{title}}: {{\/title}}{{url}}&via=researchgate","width":600,"height":350,"useUtmTags":true,"utmSource":"twitter","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareTwitter.ajaxTrackSocialShare.html","widgetId":"rgw32_56ab9e8f16567"},"id":"rgw32_56ab9e8f16567","partials":{"shareIcon":"application\/stubs\/partials\/shareTwitterBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareTwitter.html?provider=Twitter&shareIcon=shareIconBlog&utmSource=twitter&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"Google+","url":"https:\/\/plus.google.com\/share?url={{url}}","width":600,"height":600,"useUtmTags":true,"utmSource":"googleplus","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareGooglePlus.ajaxTrackSocialShare.html","widgetId":"rgw33_56ab9e8f16567"},"id":"rgw33_56ab9e8f16567","partials":{"shareIcon":"application\/stubs\/partials\/shareGooglePlusBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareGooglePlus.html?provider=Google%2B&shareIcon=shareIconBlog&utmSource=googleplus&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"LinkedIn","url":"http:\/\/www.linkedin.com\/shareArticle?mini=true&url={{url}}{{#title}}&title={{title}}{{\/title}}&source=ResearchGate","width":520,"height":570,"useUtmTags":true,"utmSource":"linkedin","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareLinkedIn.ajaxTrackSocialShare.html","widgetId":"rgw34_56ab9e8f16567"},"id":"rgw34_56ab9e8f16567","partials":{"shareIcon":"application\/stubs\/partials\/shareLinkedInBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareLinkedIn.html?provider=LinkedIn&shareIcon=shareIconBlog&utmSource=linkedin&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"Reddit","url":"https:\/\/www.reddit.com\/submit?url={{url}}{{#title}}&title={{title}}{{\/title}}","width":600,"height":600,"useUtmTags":true,"utmSource":"reddit","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareReddit.ajaxTrackSocialShare.html","widgetId":"rgw35_56ab9e8f16567"},"id":"rgw35_56ab9e8f16567","partials":{"shareIcon":"application\/stubs\/partials\/shareRedditBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareReddit.html?provider=Reddit&shareIcon=shareIconBlog&utmSource=reddit&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true}],"widgetId":"rgw30_56ab9e8f16567"},"id":"rgw30_56ab9e8f16567","partials":[],"templateName":"application\/stubs\/SocialShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.SocialShare.html?campaign=shareFullTextPublication&trackClick=1&shareIcon=shareIconBlog","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw28_56ab9e8f16567"},"id":"rgw28_56ab9e8f16567","partials":[],"templateName":"publicliterature\/stubs\/PublicationInlineReader.html","templateExtensions":["generalHelpers"],"attrs":{"showFulltextDownloadedSignupDialog":true,"preSignUpDialogContext":null,"requestFulltext":false},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationInlineReader.html","viewClass":"views.publicliterature.PublicationInlineReaderView","yuiModules":["rg.views.publicliterature.PublicationInlineReaderView","css-pow-publicliterature-PublicationInlineReader"],"stylesheets":["pow\/publicliterature\/PublicationInlineReader.css"],"_isYUI":true},"useFulltextOptimizedLayout":false,"publicationActions":null,"requestFulltextPromo":null,"currentUrl":"publication\/221618614_The_Tradeoffs_of_Large_Scale_Learning","isLeaderboardAd":false,"enableStickyBox":null,"googleDfpSlotMobileBottom":null,"fullTextExitPopup":null,"showExitPopupDialog":false,"widgetId":"rgw2_56ab9e8f16567"},"id":"rgw2_56ab9e8f16567","partials":{"romeo_legal_notice":"publicliterature\/stubs\/partials\/romeo_legal_notice.html"},"templateName":"publicliterature\/stubs\/PublicPublicationDetails_NewLayout.html","templateExtensions":["generalHelpers"],"attrs":{"publicationUid":221618614},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicPublicationDetailsOld.html?publicationUid=221618614&isTestOldDesign=0","viewClass":"views.publicliterature.PublicPublicationDetailsOldView","yuiModules":["rg.views.publicliterature.PublicPublicationDetailsOldView"],"stylesheets":[],"_isYUI":true},"widgetId":"rgw1_56ab9e8f16567"},"id":"rgw1_56ab9e8f16567","partials":[],"templateName":"publicliterature\/stubs\/PublicPublicationDetails.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicPublicationDetails.html","viewClass":"views.publicliterature.PublicPublicationDetailsView","yuiModules":["rg.views.publicliterature.PublicPublicationDetailsView"],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"uaClass":"","headPrefix":[],"rootUrl":"https:\/\/www.researchgate.net\/","requestToken":"sGaA14RDmVKrzjONOvwEalBfO77upML1vMTcuX6U4dc9mhLH559miLMxSvBKg89L+Uc4zjHncN9iM69PnPAshhmD7St92pywFo5fFO5MVxnqCo0qHKpE23HPrHqFnm2IG7mPEV2bZTqPnzrrTUaUdBfJmXuD2D0A5EudB+qGVa3mYtk7SAyirypV2RGoyuu+loCqMsZ1Xtmj6F1Z+d4JqJJQ+bIiRqgQ4f+KmZHVoNPoFgRq6yxY06Qdk2jsuRyTNYT2ZSIz1YkcuLgaSD0EnAVqqQFPNfQdvr+BQTj4xAA=","faviconCdnUrl":"https:\/\/c5.rgstatic.net\/m\/2390829798215018\/images\/favicon.ico","headerOutput":"<noscript><\/noscript><link rel=\"canonical\" href=\"https:\/\/www.researchgate.net\/publication\/221618614_The_Tradeoffs_of_Large_Scale_Learning\" \/>\n<link rel=\"dns-prefetch\" href=\"\/\/c5.rgstatic.net\" \/>\n<link rel=\"dns-prefetch\" href=\"\/\/i1.rgstatic.net\" \/>\n<meta property=\"twitter:card\" content=\"summary\" \/>\n<meta property=\"twitter:site\" content=\"@ResearchGate\" \/>\n<meta property=\"og:title\" content=\"The Tradeoffs of Large Scale Learning.\" \/>\n<meta property=\"og:description\" content=\"This contribution develops a theoretical framework that takes into account the effect of approximate optimization on learning algorithms. The analysis shows distinct tradeoffs for the case of...\" \/>\n<meta property=\"og:site_name\" content=\"ResearchGate\" \/>\n<meta property=\"og:image\" content=\"https:\/\/i1.rgstatic.net\/publication\/221618614_The_Tradeoffs_of_Large_Scale_Learning\/links\/004635219281099d85000000\/smallpreview.png\" \/>\n<meta property=\"og:url\" content=\"https:\/\/www.researchgate.net\/publication\/221618614_The_Tradeoffs_of_Large_Scale_Learning\" \/>\n<meta property=\"rg:id\" content=\"PB:221618614\" \/>\n<meta name=\"DC.identifier\" scheme=\"DCTERMS.URI\" content=\"http:\/\/dx.doi.org\/\" \/>\n<meta name=\"gs_meta_revision\" content=\"1.1\" \/>\n<meta name=\"citation_title\" content=\"The Tradeoffs of Large Scale Learning.\" \/>\n<meta name=\"citation_author\" content=\"L\u00e9on Bottou\" \/>\n<meta name=\"citation_author\" content=\"Olivier Bousquet\" \/>\n<meta name=\"citation_conference_title\" content=\"Advances in Neural Information Processing Systems 20, Proceedings of the Twenty-First Annual Conference on Neural Information Processing Systems, Vancouver, British Columbia, Canada, December 3-6, 2007\" \/>\n<meta name=\"citation_publication_date\" content=\"2007\/01\/01\" \/>\n<meta name=\"citation_volume\" content=\"20\" \/>\n<meta name=\"citation_pdf_url\" content=\"https:\/\/www.researchgate.net\/profile\/Olivier_Bousquet\/publication\/221618614_The_Tradeoffs_of_Large_Scale_Learning\/links\/004635219281099d85000000.pdf\" \/>\n<meta name=\"citation_abstract_html_url\" content=\"https:\/\/www.researchgate.net\/publication\/221618614_The_Tradeoffs_of_Large_Scale_Learning\" \/>\n<meta name=\"citation_fulltext_html_url\" content=\"https:\/\/www.researchgate.net\/publication\/221618614_The_Tradeoffs_of_Large_Scale_Learning\" \/>\n<meta name=\"viewport\" content=\"width=device-width,initial-scale=1\" \/>\n<link href=\"\/\/c5.rgstatic.net\/m\/22664197317151888\/styles\/rg.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/21004998181197492\/styles\/rg2.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<!--[if lt IE 9]><link href=\"\/\/c5.rgstatic.net\/m\/238176252723686\/styles\/ie.css\" type=\"text\/css\" rel=\"stylesheet\"\/><![endif]-->\n<link href=\"\/\/c5.rgstatic.net\/m\/217752362214895\/styles\/modules\/publicprofile.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/21993347442549\/styles\/pow\/publicliterature\/FollowPublicationPromo.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/282514599719602\/styles\/pow\/application\/PdfJsReader.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/23819663151220\/styles\/pow\/publicliterature\/PublicationInlineReader.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<script src=\"\/\/c5.rgstatic.net\/m\/2321000301012716\/javascript\/vendor\/webfontloader\/webfontloader.js\" type=\"text\/javascript\"><\/script>\n <script>(function(i,s,o,g,r,a,m){i[\"GoogleAnalyticsObject\"]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,\"script\",\"\/\/www.google-analytics.com\/analytics.js\",\"ga\");\n ga(\"create\",\"UA-58591210-1\");ga(\"set\",\"anonymizeIp\",true);ga('set', 'dimension1', 'publication full-text');ga('set', 'dimension2', 'Conference Paper');ga('set', 'dimension3', 'Logged out');ga('set', 'dimension4', 'https');ga(\"send\",\"pageview\");<\/script>\n","webfont":"<noscript><\/noscript><script> WebFontConfig = { custom: { families: ['source_sans_pro_italic', 'source_sans_pro_bold', 'source_sans_pro', 'martel'], urls : ['\/\/c5.rgstatic.net\/m\/231392577336386\/styles\/fonts.css'] } }; WebFont.load(WebFontConfig); <\/script>\n","correlationId":"rgreq-305537ad-0791-4b0a-b6e3-6ed6a0606899","accountId":null,"module":"publicliterature","action":"publicliterature.PublicPublicationDetails","page":"publicationDetail","product":"publications","backendTime":289,"continent":"Asia","stylesHome":"\/\/c5.rgstatic.net\/m\/","staticHost":"c5.rgstatic.net","useEarlyFlush":false,"longRunningRequestIdentifier":"LongRunningRequest.publicliterature.PublicPublicationDetails","longRunningRequestFp":"e9e5bbe1366c7ee8c8e41d02f793c884ac9be19b","widgetId":"rgw36_56ab9e8f16567"},"id":"rgw36_56ab9e8f16567","partials":[],"templateName":"application\/stubs\/StaticHeader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.StaticHeader.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){
            Y.rg.core.pagespeed.Monitoring.monitorPage("\/\/glassmoni.researchgate.net", "publicliterature.PublicPublicationDetails.run.html.loggedOut.get", "59de9668d07aeb77ab4de5f24d382b5d199d2437", "rgreq-305537ad-0791-4b0a-b6e3-6ed6a0606899", "d47807b8f38721f5db57a5cf22233243005c1edd");
        
            Y.rg.core.pagespeed.Monitoring.monitorPage("\/\/glassmoni.researchgate.net", "publicationDetail.loggedOut", "ed1993d9e20f6cefa83edacaa24401a18c071aea", "rgreq-305537ad-0791-4b0a-b6e3-6ed6a0606899", "d47807b8f38721f5db57a5cf22233243005c1edd");
        })();
(function(){Y.rg.createInitialWidget({"data":{"year":"2016","inlinePromo":null,"isAdmin":false,"contactUrl":"https:\/\/www.researchgate.net\/contact","aboutUsUrl":"https:\/\/www.researchgate.net\/about","widgetId":"rgw37_56ab9e8f16567"},"id":"rgw37_56ab9e8f16567","partials":[],"templateName":"application\/stubs\/DefaultFooter.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.DefaultFooter.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"headerLogin":{"data":{"urlAfterLogin":"publication\/221618614_The_Tradeoffs_of_Large_Scale_Learning","requestToken":"M4dUNyOj0KHKTF4x+LFhxCQmxh+7dr5\/ts\/a89geL\/p2jhgodqdmJpubs36bOxNPubjTcsjpCgwpMvmSuygB64XD9OzGzLekeJOWcyv+4\/2LUZtW34skkduFYzqeANnj61qXT9UZ64Bsk\/zbq5EwRpTkWjLE8wOngHFrA9U85zb501qWOTludWRKthkzNqZm8Mmhzo1DtQuEFgzsGCtLp51ctzNX4XmKirnsyzmd+YyUsVUwiQYcm0MP7HCVsVIALrDXxB6HU6tB4BMmHU7GdQsAswomOsFss9y5NPRySiA=","loginUrl":"https:\/\/www.researchgate.net\/application.Login.html","signupUrl":"https:\/\/www.researchgate.net\/signup.SignUp.html?ev=su_chnl_index&hdrsu=1&_sg=M9_jbru8ppsBL9yAeA2lg2LG2VfHIXmqDGzzsgdEOIEhv6-XY7PMf-e-qG2pWtd6","encodedUrlAfterLogin":"cHVibGljYXRpb24vMjIxNjE4NjE0X1RoZV9UcmFkZW9mZnNfb2ZfTGFyZ2VfU2NhbGVfTGVhcm5pbmc%3D","signupCallToAction":"Join for free","widgetId":"rgw39_56ab9e8f16567"},"id":"rgw39_56ab9e8f16567","partials":{"partial":"application\/stubs\/partials\/headerLoginDefault.html"},"templateName":"application\/stubs\/HeaderLogin.html","templateExtensions":[],"attrs":{"goal":"milestoneHeaderLoginSeen"},"widgetUrl":"https:\/\/www.researchgate.net\/application.HeaderLogin.html","viewClass":"views.application.HeaderLoginView","yuiModules":["rg.views.application.HeaderLoginView"],"stylesheets":[],"_isYUI":true},"cookieConsent":null,"logoSvgSrc":"https:\/\/c5.rgstatic.net\/m\/235107188705592\/images\/template\/brand-header-logo.svg","logoFallbackSrc":"https:\/\/c5.rgstatic.net\/m\/238113351022438\/images\/template\/brand-header-logo.png","widgetId":"rgw38_56ab9e8f16567"},"id":"rgw38_56ab9e8f16567","partials":{"schemaSocialProfiles":"application\/stubs\/partials\/schemaSocialProfiles.html"},"templateName":"application\/stubs\/HeaderLoggedOut.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.HeaderLoggedOut.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"logEvent":"su_banner","specialCopy":false,"widgetId":"rgw40_56ab9e8f16567"},"id":"rgw40_56ab9e8f16567","partials":[],"templateName":"application\/stubs\/LoggedOutBanner.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.LoggedOutBanner.html","viewClass":"views.application.LoggedOutBannerView","yuiModules":["rg.views.application.LoggedOutBannerView"],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.core.util.ParameterFilter.filter(["ev","cp","ch","ref","dbw","pli","loginT","uid","claimChannel","enrichId","enrichSource","utm_source","utm_medium","utm_campaign","el","ci"]);})();
});}); } else { throw 'YRG was not loaded when attaching widgets'; }</script><script> dataLayer = [{"pageCategory":"publication full-text","publicationType":"Conference Paper","eventCategory":"Publication page"}]; </script> <noscript><iframe src="//www.googletagmanager.com/ns.html?id=GTM-MKVKH7" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-MKVKH7');</script><script>(function(e){function n(n,t,o,a){"use strict";var i=e.document.createElement("link"),r=t||e.document.getElementsByTagName("script")[0],d=e.document.styleSheets;return i.rel="stylesheet",i.href=n,i.media="only x",a&&(i.onload=a),r.parentNode.insertBefore(i,r),i.onloadcssdefined=function(e){for(var t,o=0;d.length>o;o++)d[o].href&&d[o].href.indexOf(n)>-1&&(t=!0);t?e():setTimeout(function(){i.onloadcssdefined(e)})},i.onloadcssdefined(function(){i.media=o||"all"}),i}function t(e,n){e.onload=function(){e.onload=null,n&&n.call(e)},"isApplicationInstalled"in navigator&&"onloadcssdefined"in e&&e.onloadcssdefined(n)}var o=function(a,i){"use strict";if(a&&3===a.length){var r=e.Image,d=!(!document.createElementNS||!document.createElementNS("http://www.w3.org/2000/svg","svg").createSVGRect||!document.implementation.hasFeature("http://www.w3.org/TR/SVG11/feature#Image","1.1")||e.opera&&-1===navigator.userAgent.indexOf("Chrome")||-1!==navigator.userAgent.indexOf("Series40")),c=new r;c.onerror=function(){o.method="png",o.href=a[2],n(a[2])},c.onload=function(){var e=1===c.width&&1===c.height,r=a[e&&d?0:e?1:2];o.method=e&&d?"svg":e?"datapng":"png",o.href=r,t(n(r),i)},c.src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///ywAAAAAAQABAAACAUwAOw==",document.documentElement.className+=" grunticon"}};o.loadCSS=n,o.onloadCSS=t,e.grunticon=o})(this);grunticon(["https://c5.rgstatic.net/c/o1q2er/styles/icons/_header-ico.svg.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_header-ico.png.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_header-ico.fallback.scss"]);grunticon(["https://c5.rgstatic.net/c/o1q2er/styles/icons/_admin-ico.svg.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_admin-ico.png.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_admin-ico.fallback.scss"]);grunticon(["https://c5.rgstatic.net/c/o1q2er/styles/icons/_ico.svg.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_ico.png.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_ico.fallback.scss"]);</script></body>
</html>
