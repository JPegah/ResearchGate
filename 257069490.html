<!DOCTYPE html> <html lang="en" class="" id="rgw50_56ab1eda73233"> <head > <meta charset="utf-8"/> <meta http-equiv="content-type" content="text/html; charset=UTF-8"/> <meta name="Rg-Request-Token" id="Rg-Request-Token" content="bacnBvQAUwFdJTpzUsRxU7yDNoP8yxs4g82MOk/4sGeaG3wKGVObHHN1R/wy19Ad5N6SqzIiVzdF+46ofc/xwBTTe7g3antp8zY3Qr90YZGsAAfK2tfA9XLHwCUwMIlKf6yhemesPWYJO0QFcjJYWlpd39np/chB2/Qjskq/aNbTL6nh9LMcs+ItyEcAWZ4fqL2c3ztFXTSoR1K6xPApauIlr0A0PT/gHyERICoJQwng7hkSqYGhHMf12xPdYyagkKBn57EHF9A9fHxnl612ITyrTCDL04SoiARvzOKFWCc="/> <meta http-equiv="expires" content="0"/> <link rel="apple-touch-icon" sizes="57x57" href="https://www.researchgate.net/apple-touch-icon-57x57.png"> <link rel="apple-touch-icon" sizes="60x60" href="https://www.researchgate.net/apple-touch-icon-60x60.png"> <link rel="apple-touch-icon" sizes="72x72" href="https://www.researchgate.net/apple-touch-icon-72x72.png"> <link rel="apple-touch-icon" sizes="76x76" href="https://www.researchgate.net/apple-touch-icon-76x76.png"> <link rel="apple-touch-icon" sizes="114x114" href="https://www.researchgate.net/apple-touch-icon-114x114.png"> <link rel="apple-touch-icon" sizes="120x120" href="https://www.researchgate.net/apple-touch-icon-120x120.png"> <link rel="apple-touch-icon" sizes="144x144" href="https://www.researchgate.net/apple-touch-icon-144x144.png"> <link rel="apple-touch-icon" sizes="152x152" href="https://www.researchgate.net/apple-touch-icon-152x152.png"> <link rel="apple-touch-icon" sizes="180x180" href="https://www.researchgate.net/apple-touch-icon-180x180.png"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-32x32.png" sizes="32x32"> <link rel="icon" type="image/png" href="https://www.researchgate.net/android-chrome-192x192.png" sizes="192x192"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-96x96.png" sizes="96x96"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-16x16.png" sizes="16x16"> <link rel="shortcut icon" type="image/x-icon" href="https://c5.rgstatic.net/m/2390829798215018/images/favicon.ico"/> <link rel="manifest" href="https://www.researchgate.net/manifest.json"> <meta name="msapplication-TileColor" content="#da532c"> <meta name="msapplication-TileImage" content="https://www.researchgate.net/mstile-144x144.png"> <meta name="theme-color" content="#444444"> <link rel="search" type="application/opensearchdescription+xml" title="ResearchGate search" href="https://www.researchgate.net/application.DownloadOpenSearchPlugin.html"/> <link rel="meta" type="application/rdf+xml" title="ICRA labels" href="https://www.researchgate.net/application.DownloadLabels.html"/> <link rel="http://oexchange.org/spec/0.8/rel/related-target" type="application/xrd+xml" href="https://www.researchgate.net/application.DownloadOExchange.html"/> <base href="https://www.researchgate.net/"/> <script>
    var rgConfig = {
        correlationId: "rgreq-1a48599c-f4de-4a1e-b613-0499675d44cb",
        accountId: "",
        module: "publicliterature",
        action: "publicliterature.PublicPublicationDetails",
        page: "publicationDetail",
        product: "publications",
        continent: "Asia",
        stylesHome: "//c5.rgstatic.net/m/",
        staticHost: "c5.rgstatic.net",
        longRunningRequestIdentifier: "LongRunningRequest.publicliterature.PublicPublicationDetails",
        longRunningRequestFp: "e9e5bbe1366c7ee8c8e41d02f793c884ac9be19b"
    };
    window.rootUrl = "https://www.researchgate.net/";
</script> <link rel="canonical" href="https://www.researchgate.net/publication/257069490_Gaussian_Processes_for_Big_Data" />
<link rel="dns-prefetch" href="//c5.rgstatic.net" />
<link rel="dns-prefetch" href="//i1.rgstatic.net" />
<meta property="twitter:card" content="summary" />
<meta property="twitter:site" content="@ResearchGate" />
<meta property="og:title" content="Gaussian Processes for Big Data" />
<meta property="og:description" content="We introduce stochastic variational inference for Gaussian process models.
This enables the application of Gaussian process (GP) models to data sets
containing millions of data points. We show how..." />
<meta property="og:site_name" content="ResearchGate" />
<meta property="og:image" content="https://i1.rgstatic.net/publication/257069490_Gaussian_Processes_for_Big_Data/links/55adfd9508ae98e661a45327/smallpreview.png" />
<meta property="og:url" content="https://www.researchgate.net/publication/257069490_Gaussian_Processes_for_Big_Data" />
<meta property="rg:id" content="PB:257069490" />
<meta name="DC.identifier" scheme="DCTERMS.URI" content="http://dx.doi.org/" />
<meta name="gs_meta_revision" content="1.1" />
<meta name="citation_title" content="Gaussian Processes for Big Data" />
<meta name="citation_author" content="James Hensman" />
<meta name="citation_author" content="Nicolo Fusi" />
<meta name="citation_author" content="Neil D. Lawrence" />
<meta name="citation_publication_date" content="2013/09/26" />
<meta name="citation_pdf_url" content="https://www.researchgate.net/profile/James_Hensman/publication/257069490_Gaussian_Processes_for_Big_Data/links/55adfd9508ae98e661a45327.pdf" />
<meta name="citation_abstract_html_url" content="https://www.researchgate.net/publication/257069490_Gaussian_Processes_for_Big_Data" />
<meta name="citation_fulltext_html_url" content="https://www.researchgate.net/publication/257069490_Gaussian_Processes_for_Big_Data" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<link href="//c5.rgstatic.net/m/22664197317151888/styles/rg.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/21004998181197492/styles/rg2.css" type="text/css" rel="stylesheet"/>
<!--[if lt IE 9]><link href="//c5.rgstatic.net/m/238176252723686/styles/ie.css" type="text/css" rel="stylesheet"/><![endif]-->
<link href="//c5.rgstatic.net/m/217752362214895/styles/modules/publicprofile.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/215868066921738/styles/pow/publicliterature/FigureList.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/21993347442549/styles/pow/publicliterature/FollowPublicationPromo.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/282514599719602/styles/pow/application/PdfJsReader.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/23819663151220/styles/pow/publicliterature/PublicationInlineReader.css" type="text/css" rel="stylesheet"/>
<script src="//c5.rgstatic.net/m/2321000301012716/javascript/vendor/webfontloader/webfontloader.js" type="text/javascript"></script>
 <script>(function(i,s,o,g,r,a,m){i["GoogleAnalyticsObject"]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,"script","//www.google-analytics.com/analytics.js","ga");
 ga("create","UA-58591210-1");ga("set","anonymizeIp",true);ga('set', 'dimension1', 'publication full-text');ga('set', 'dimension2', 'Article');ga('set', 'dimension3', 'Logged out');ga('set', 'dimension4', 'https');ga("send","pageview");</script>
  <script> WebFontConfig = { custom: { families: ['source_sans_pro_italic', 'source_sans_pro_bold', 'source_sans_pro', 'martel'], urls : ['//c5.rgstatic.net/m/231392577336386/styles/fonts.css'] } }; WebFont.load(WebFontConfig); </script><noscript></noscript>

<title>Gaussian Processes for Big Data (PDF Download Available)</title>
<meta name="description" content="Official Full-Text Publication: Gaussian Processes for Big Data on ResearchGate, the professional network for scientists."/>
<meta name="keywords" content="scientific network, scientific platform, scientific community, research partner, research collaboration, journal articles, international collaboration, find researcher, lifescience researcher, interdisciplinary research, research collaboration"/>
</head>
<body class="use-svg-icons logged-out">
<div id="page-container">
<script type="text/javascript">var googletag = googletag || {}; googletag.cmd = googletag.cmd || [];
(function() { var gads = document.createElement("script"); gads.async = true; gads.type = "text/javascript"; var useSSL = "https:" == document.location.protocol; gads.src = (useSSL ? "https:" : "http:") + "//www.googletagservices.com/tag/js/gpt.js"; var node =document.getElementsByTagName("script")[0]; node.parentNode.insertBefore(gads, node); })();</script><div id="main" class="logged-out-header-support">
<div id="content" class="">

<noscript>
<div class="c-box-warning full-width-element" style="text-align: center; ">
    <div style="margin: auto; padding:10px;" class="container">
        <b>For full functionality of ResearchGate it is necessary to enable JavaScript.
            Here are the <a href="http://www.enable-javascript.com/" rel="nofollow" target="_blank">
                instructions how to enable JavaScript in your web browser</a>.</b>
    </div>
</div>
</noscript>

<div id="rgw1_56ab1eda73233" itemscope itemtype="http://schema.org/ScholarlyArticle"><div class="publication-wrapper publication-wrapper-onecol" id="rgw2_56ab1eda73233" itemscope itemtype="http://schema.org/ScholarlyArticle"> <div class="c-col-content"> <div class="c-content"> <div class="clearfix">  <div class="publication-header"> <div id="rgw5_56ab1eda73233">  <div class="type-label"> Article   </div> <span class="Z3988" title="ctx_ver=Z39.88-2004&rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&rfr_id=info%3Asid%2Fresearchgate.net%3Aresearchgate&rft.atitle=Gaussian%20Processes%20for%20Big%20Data&rft.title=Uncertainty%20in%20Artificial%20Intelligence%20-%20Proceedings%20of%20the%2029th%20Conference%2C%20UAI%202013&rft.jtitle=Uncertainty%20in%20Artificial%20Intelligence%20-%20Proceedings%20of%20the%2029th%20Conference%2C%20UAI%202013&rft.date=2013&rft.au=James%20Hensman%2CNicolo%20Fusi%2CNeil%20D.%20Lawrence&rft.genre=article"></span> <h1 class="pub-title" itemprop="name">Gaussian Processes for Big Data</h1> <meta itemprop="headline" content="Gaussian Processes for Big Data">  <meta itemprop="image" content="https://i1.rgstatic.net/publication/257069490_Gaussian_Processes_for_Big_Data/links/55adfd9508ae98e661a45327/smallpreview.png">  <div id="rgw7_56ab1eda73233" class="publication-detail-author-list"> <div> <ul class="clearfix js-people-list">  <li id="rgw8_56ab1eda73233" itemprop="author" itemscope itemtype="http://schema.org/Person"> <a itemprop="sameAs" href="profile/James_Hensman" class="pub-detail-item account-item"> <div class="indent-left"> <div class="people-img"> <img  src="https://i1.rgstatic.net/ii/profile.image/AS%3A277099177889798%401443077000994_m" title="James Hensman" alt="James Hensman" height="20px" width="20px" style="height: 20px;"/> </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">James Hensman</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item  remove-action-indent   " id="rgw9_56ab1eda73233" data-account-key="James_Hensman">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="profile/James_Hensman"> <img class="lazyload" data-src="https://i1.rgstatic.net/ii/profile.image/AS%3A277099177889798%401443077000994_l" title="James Hensman" alt="James Hensman" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">     </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="profile/James_Hensman" class="display-name">James Hensman</a>    </h5> <div class="truncate-single-line meta">   <a class="meta ga-top-coauthor-institution" href="institution/Lancaster_University" title="Lancaster University">Lancaster University</a>     </div>  <a href="javascript:" class="btn btn-promote btn-large people-item-contact-author js-contact-author">Message author</a>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>  <li id="rgw10_56ab1eda73233"> <a href="researcher/71650991_Nicolo_Fusi" class="pub-detail-item author-item" itemprop="author" itemscope itemtype="http://schema.org/Person"> <div class="indent-left"> <div class="people-img">  <img src="https://c5.rgstatic.net/m/2951093203564/images/template/default/profile/profile_default_s.jpg" title="Nicolo Fusi" alt="Nicolo Fusi" height="20px" width="20px" style="height: 20px;"/>  </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Nicolo Fusi</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item   not-claimed " id="rgw11_56ab1eda73233">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="researcher/71650991_Nicolo_Fusi"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="Nicolo Fusi" alt="Nicolo Fusi" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">       </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="researcher/71650991_Nicolo_Fusi" class="display-name">Nicolo Fusi</a>    </h5> <div class="truncate-single-line meta">   </div>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>  <li id="rgw12_56ab1eda73233"> <a href="researcher/39663468_Neil_D_Lawrence" class="pub-detail-item author-item" itemprop="author" itemscope itemtype="http://schema.org/Person"> <div class="indent-left"> <div class="people-img">  <img src="https://c5.rgstatic.net/m/2951093203564/images/template/default/profile/profile_default_s.jpg" title="Neil D. Lawrence" alt="Neil D. Lawrence" height="20px" width="20px" style="height: 20px;"/>  </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Neil D. Lawrence</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item   not-claimed " id="rgw13_56ab1eda73233">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="researcher/39663468_Neil_D_Lawrence"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="Neil D. Lawrence" alt="Neil D. Lawrence" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">       </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="researcher/39663468_Neil_D_Lawrence" class="display-name">Neil D. Lawrence</a>    </h5> <div class="truncate-single-line meta">   </div>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>   </ul> <div class="js-loading"></div>  </div> </div> <div class="pub-details js-pub-details">     Uncertainty in Artificial Intelligence - Proceedings of the 29th Conference, UAI 2013   <meta itemprop="datePublished" content="2013-09">  09/2013;               <div class="pub-source"> Source: <a href="http://arxiv.org/abs/1309.6835" rel="nofollow">arXiv</a> </div>  </div> <div id="rgw14_56ab1eda73233" class="pub-abstract">  <div class="clearfix">   <div style="max-height: 54px;" class="js-expander-container js-expander-collapsed">  <p itemprop="description"> <strong>ABSTRACT</strong> <div>We introduce stochastic variational inference for Gaussian process models.<br />
This enables the application of Gaussian process (GP) models to data sets<br />
containing millions of data points. We show how GPs can be vari- ationally<br />
decomposed to depend on a set of globally relevant inducing variables which<br />
factorize the model in the necessary manner to perform variational inference.<br />
Our ap- proach is readily extended to models with non-Gaussian likelihoods and<br />
latent variable models based around Gaussian processes. We demonstrate the<br />
approach on a simple toy problem and two real world data sets.</div> </p>  </div>  </div>   </div>     <div id="rgw15_56ab1eda73233" class="figure-carousel"> <div class="carousel-hd"> Figures in this publication </div> <div class="carousel-bd"> <ul class="clearfix">  <li> <a href="/figure/257069490_fig1_Figure-2-Stochastic-variational-inference-on-a-trivial-GP-regression-problem-Each-pane" class=" fig-frame js-click-link "  rel="tooltip" data-tooltip="Figure 2: Stochastic variational inference on a trivial GP regression..." data-key="257069490_fig1_Figure-2-Stochastic-variational-inference-on-a-trivial-GP-regression-problem-Each-pane"> <img class="fig" src="https://www.researchgate.net/profile/James_Hensman/publication/257069490/figure/fig1/Figure-2-Stochastic-variational-inference-on-a-trivial-GP-regression-problem-Each-pane_small.png" alt="Figure 2: Stochastic variational inference on a trivial GP regression..." title="Figure 2: Stochastic variational inference on a trivial GP regression..."/> </a> </li>  </ul> </div> </div> <div class="action-container"> <div id="rgw16_56ab1eda73233" class="follow-publication-promo"> <table> <tr> <td class="follow-publication-promo-text-cell"> <p>Get notified about updates to this publication</p> <a class="btn btn-large btn-promote js-follow-publication ga-follow-publication-new-promo">Follow publication</a> </td> <td> <div class="follow-publication-publication-image"></div> </td> </tr> </table> </div>  <div class="clear"></div> <div class="share-dialog-container" style="display: none;">  </div> </div> </div> <div style="margin-left: -20px; margin-right: -20px;">  </div> </div>  <div class="publication-detail-dfp-container rf"> <div id="rgw30_56ab1eda73233">  </div> </div>  </div>  <div class="clearfix"> <div class="pdf-js-container clearfix " id="rgw42_56ab1eda73233">  <div class="pdf-js-header js-sticky-header clear">  <a class="blue-link js-download rf btn btn-promote" href="https://www.researchgate.net/profile/James_Hensman/publication/257069490_Gaussian_Processes_for_Big_Data/links/55adfd9508ae98e661a45327.pdf?inViewer=0&amp;pdfJsDownload=0&amp;origin=publication_detail">Download full-text</a>  <h3>Full-text</h3> <span class="publication-info">  <span class="js-doi-container" style="display: none;"> DOI: <span class="js-doi"></span> &middot; </span> Available from: <a class="js-name" href="profile/James_Hensman">James Hensman</a>, <span class="js-publication-date"> Jul 21, 2015 </span>   </span>  </div>  <div class="social-share-container"><div id="rgw44_56ab1eda73233" class="social-share js-social-share"> <div class="social-share-heading">Share</div>  <a id="rgw45_56ab1eda73233" href="javascript:" title="Share on Facebook" class="link-nostyle js-share-item share-icon "  data-url="http://www.facebook.com/share.php?u={{url}}{{#title}}&amp;t={{title}}{{/title}}" data-width="600" data-height="350" data-name="Facebook"> <span class="share-icon ico-share-facebook-round reset-background ga-share-blog-facebook"></span> </a>  <a id="rgw46_56ab1eda73233" href="javascript:" title="Share on Twitter" class="link-nostyle js-share-item share-icon "  data-url="http://twitter.com/intent/tweet?text={{#title}}{{title}}: {{/title}}{{url}}&amp;via=researchgate" data-width="600" data-height="350" data-name="Twitter"> <span class="share-icon ico-share-twitter-round reset-background ga-share-blog-twitter"></span> </a>  <a id="rgw47_56ab1eda73233" href="javascript:" title="Share on Google+" class="link-nostyle js-share-item share-icon "  data-url="https://plus.google.com/share?url={{url}}" data-width="600" data-height="600" data-name="Google+"> <span class="share-icon ico-share-gplus-round reset-background ga-share-blog-gplus"></span> </a>  <a id="rgw48_56ab1eda73233" href="javascript:" title="Share on LinkedIn" class="link-nostyle js-share-item share-icon "  data-url="http://www.linkedin.com/shareArticle?mini=true&amp;url={{url}}{{#title}}&amp;title={{title}}{{/title}}&amp;source=ResearchGate" data-width="520" data-height="570" data-name="LinkedIn"> <span class="share-icon ico-share-linkedin-round reset-background ga-share-blog-linkedin"></span> </a>  <a id="rgw49_56ab1eda73233" href="javascript:" title="Share on Reddit" class="link-nostyle js-share-item share-icon "  data-url="https://www.reddit.com/submit?url={{url}}{{#title}}&amp;title={{title}}{{/title}}" data-width="600" data-height="600" data-name="Reddit"> <span class="share-icon ico-share-reddit reset-background ga-share-blog-reddit"></span> </a>  </div></div>    <iframe id="rgw43_56ab1eda73233" src="https://www.researchgate.net/c/o1o9o3/javascript/lib/pdfjs/web/viewer.html?file=https%3A%2F%2Fwww.researchgate.net%2Fprofile%2FJames_Hensman%2Fpublication%2F257069490_Gaussian_Processes_for_Big_Data%2Flinks%2F55adfd9508ae98e661a45327.pdf%3FinViewer%3D1%26pdfJsDownload%3D1%26origin%3Dpublication_detail" allowfullscreen frameborder="0" style="width: 100%; height: 100%; box-sizing: border-box;"></iframe>    </div> <noscript> <div id="rgw29_56ab1eda73233"  itemprop="articleBody">  <p>Page 1</p> <p>Gaussian Processes for Big Data<br />James Hensman∗<br />Dept. Computer Science<br />The University of Sheffield<br />Sheffield, UK<br />Nicol` o Fusi∗<br />Dept. Computer Science<br />The University of Sheffield<br />Sheffield, UK<br />Neil D. Lawrence∗<br />Dept. Computer Science<br />The University of Sheffield<br />Sheffield, UK<br />Abstract<br />We introduce stochastic variational inference<br />for Gaussian process models. This enables<br />the application of Gaussian process (GP)<br />models to data sets containing millions of<br />data points. We show how GPs can be vari-<br />ationally decomposed to depend on a set<br />of globally relevant inducing variables which<br />factorize the model in the necessary manner<br />to perform variational inference.<br />proach is readily extended to models with<br />non-Gaussian likelihoods and latent variable<br />models based around Gaussian processes. We<br />demonstrate the approach on a simple toy<br />problem and two real world data sets.<br />Our ap-<br />1Introduction<br />Gaussian processes [GPs, Rasmussen and Williams,<br />2006] are perhaps the dominant approach for inference<br />on functions. They underpin a range of algorithms<br />for regression, classification and unsupervised learn-<br />ing. Unfortunately, when applying a Gaussian process<br />to a data set of size n exact inference has complexity<br />O(n3) with storage demands of O(n2). This hinders<br />the application of these models for many domains. In<br />particular, large spatiotemporal data sets, video, large<br />social network data (e.g. from Facebook), population<br />scale medical data sets, models that correlate across<br />multiple outputs or tasks (for these models complex-<br />ity is O(n3p3) and storage is O(n2p2) where p is the<br />number of outputs or tasks). Collectively we can think<br />of these applications as belonging to the domain of ‘big<br />data’.<br />Traditionally in Gaussian process a large data set is<br />one that contains over a few thousand data points.<br />∗Also at Sheffield Institute for Translational Neuro-<br />science, SITraN<br />Even to accommodate these data sets, various approx-<br />imate techniques are required. One approach is to par-<br />tition the data set into separate groups [e.g. Snelson<br />and Ghahramani, 2007, Urtasun and Darrell, 2008].<br />An alternative is to build a low rank approximation<br />to the covariance matrix based around ‘inducing vari-<br />ables’ [see e.g. Csat´ o and Opper, 2002, Seeger et al.,<br />2003, Qui˜ nonero Candela and Rasmussen, 2005, Tit-<br />sias, 2009]. These approaches lead to a computational<br />complexity of O(nm2) and storage demands of O(nm)<br />where m is a user selected parameter governing the<br />number of inducing variables.<br />reduced storage are prohibitive for big data, where<br />n can be many millions or billions. For parametric<br />models, stochastic gradient descent is often applied to<br />resolve this storage issue, but in the GP domain, it<br />hasn’t been clear how this should be performed. In<br />this paper we show how recent advances in variational<br />inference [Hensman et al., 2012, Hoffman et al., 2012]<br />can be combined with the idea of inducing variables<br />to develop a practical algorithm for fitting GPs using<br />stochastic variational inference (SVI).<br />However, even these<br />2Sparse GPs Revisited<br />We start with a succinct rederivation of the variational<br />approach to inducing variables of Titsias [2009]. This<br />allows us to introduce notation and derive expressions<br />which allow for the formulation of a SVI algorithm.<br />Consider a data vector1y, where each entry yi is a<br />noisy observation of the function f(xi), for all the<br />points X = {xi}n<br />dependent Gaussian with precision β. Introducing a<br />Gaussian process prior over f(·), let the vector f con-<br />tain values of the function at the points X. We shall<br />also introduce a set of inducing variables: let the vec-<br />tor u contain values of the function f at the points<br />Z = {zi}m<br />1Our derivation trivially extends to multiple indepen-<br />dent output dimensions, but we omit them here for clarity.<br />i=1. We consider the noise to be in-<br />i=1which live in the same space as X. Us-</p>  <p>Page 2</p> <p>ing standard Gaussian process methodologies, we can<br />write<br />p(y|f) =N?y|f,β−1I?,<br />p(f |u) =N<br />p(u) =N (u|0,Kmm),<br />where Kmm is the covariance function evaluated be-<br />tween all the inducing points and Knmis the covari-<br />ance function between all inducing points and train-<br />ing points and we have defined with?K = Knn−<br />We first apply Jensen’s inequality on the conditional<br />probability p(y|u):<br />logp(y|u) =log?p(y|f)?p(f |u)<br />≥?logp(y|f)?p(f |u)? L1.<br />?<br />f|KnmK−1<br />mmu,?K<br />?<br />,<br />KnmK−1<br />mmKmn.<br />(1)<br />where ?·?p(x)denotes an expectation under p(x). For<br />Gaussian noise taking the expectation inside the log<br />is tractable, but it results in an expression containing<br />K−1<br />Bringing the expectation outside the log gives a lower<br />bound, L1, which can be computed with has complex-<br />ity O(m3). Further, when p(y|f) factorises across the<br />data,<br />n<br />?<br />then this lower bound can be shown to be separable<br />across y giving<br />nn, which has a computational complexity of O(n3).<br />p(y|f) =<br />i=1<br />p(yi|fi),<br />exp(L1) =<br />n<br />?<br />i=1<br />N?yi|µi,β−1?exp<br />mmu and˜ki,i is the ith diagonal<br />element of?K. Note that the difference between our<br />Kullback Leibler (KL) divergence between the poste-<br />rior over the mapping function given the data and the<br />inducing variables and the posterior of the mapping<br />function given the inducing variables only,<br />?<br />−1<br />2β˜ki,i<br />?<br />(2)<br />where µ = KnmK−1<br />bound and the original log likelihood is given by the<br />KL(p(f|u)?p(f|u,y)).<br />This KL divergence is minimized when there are<br />m = n inducing variables and they are placed at<br />the training data locations. This means that u = f,<br />Kmm=Knm=Knn meaning that?K=0. In this case<br />equality because p(f|u) is degenerate. However, since<br />m = n and that there would be no computational<br />or storage advantage from the representation. When<br />m &lt; n the bound can be maximised with respect to<br />Z (which are variational parameters). This minimises<br />we recover exp(L1) = p(y|f) and the bound becomes<br />the KL divergence and ensures that Z are distributed<br />amongst the training data X such that all˜ki,i are<br />small. In practice this means that the expectations in<br />(1) are only taken across a narrow domain (˜ki,iis the<br />marginal variance of p(fi|u)), keeping Jensen’s bound<br />tight.<br />Before deriving the expressions for stochastic varia-<br />tional inference using L1, we recover the bound of Tit-<br />sias [2009] by marginalising the inducing variables,<br />?<br />≥log<br />which with some linear algebraic manipulation leads<br />to<br />L2= logN?y|0,KnmK−1<br />matching the result of Titsias, with the implicit ap-<br />proximating distribution q(u) having precision<br />logp(y|X) =logp(y|u)p(u)du<br />?<br />exp{L1}p(u)du ? L2,(3)<br />mmKmn+ β−1I?−1<br />2βtr<br />??K<br />?<br />,<br />Λ = βK−1<br />mmKmnKnmK−1<br />mm+ K−1<br />mm<br />and mean<br />ˆ u = βΛ−1K−1<br />mmKmny.<br />3 SVI for GPs<br />One of the novelties of the Titsias bound was that,<br />rather than explicitly representing a variational distri-<br />bution for q(u), these variables are ‘collapsed’ [Hens-<br />man et al., 2012]. However, for stochastic variational<br />inference to work on Gaussian processes, it turns out<br />we need to maintain an explicit representation of these<br />inducing variables.<br />Stochastic variational inference (SVI) allows varia-<br />tional inference for very large data sets, but it can<br />only be applied to probabilistic models which have a<br />set of global variables, and which factorise in the ob-<br />servations and latent variables as Figure 1(a). Gaus-<br />sian Processes do not have global variables and exhibit<br />no such factorisation (Figure 1(b)). By introducing<br />inducing variables u, we have an appropriate model<br />for SVI (Figure 1(c)). Unfortunately, marginalising u<br />re-introduces dependencies between the observations,<br />and eliminates the global parameters. In the following,<br />we derive a lower bound on L2which includes an ex-<br />plicit variational distribution q(u), enabling SVI. We<br />then derive the required natural gradients and discuss<br />how latent variables might be used.<br />Because there are a fixed number of inducing variables<br />(specified by the user at algorithm design time) we<br />can perform stochastic variational inference, greatly<br />increasing the size of data sets to which we can apply<br />Gaussian processes.</p>  <p>Page 3</p> <p>(a) Requirements for SVI(b) Gaussian Process regression(c) Variational GP regression<br />Figure 1: Graphical models showing (a) the reqired form for a probabilistic model for SVI (reproduced from<br />[Hoffman et al., 2012]), with global variables g and latent variables z. (b) The graphical model corresponding to<br />Gaussian process regression, where connectivity between the values of the function fiis denoted by a loop around<br />the plate. (c) The graphical model corresponding to the sparse GP model, with inducing variables u working as<br />global variables, and the term L1acting as logp(yi|u,xi). Marginalisation of u leads to the variational DTC<br />formulation, introducing dependencies between the observations.<br />3.1 Global Variables<br />To apply stochastic variational inference to a Gaussian<br />process model, we must have a set of global variables.<br />The variables u will perform this role, and we intro-<br />duce a variational distribution q(u), and use it to lower<br />bound the quantity p(y|X).<br />logp(y|X) ≥ ?L1+ logp(u) − logq(u)?q(u)? L3.<br />From the above we know that the optimal distribu-<br />tion is Gaussian, and we parametrise it as q(u) =<br />N(u|m,S). The bound L3becomes<br />n<br />?<br />−1<br />− KL(q(u)?p(u))<br />with kibeing a vector of the ithcolumn of Kmnand<br />Λi= βK−1<br />spect to the parameters of q(u) are<br />L3=<br />i=1<br />?<br />logN?yi|k?<br />2β?ki,i−1<br />iK−1<br />mmm,β−1?<br />2tr(SΛi)<br />?<br />(4)<br />mmkik?<br />iK−1<br />mm. The gradients of L3with re-<br />∂L3<br />∂m= βK−1<br />∂L3<br />∂S<br />mmKmny − Λm,<br />2S−1−1<br />=1<br />2Λ. (5)<br />Setting the derivatives to zero recovers the optimal<br />solution found in the previous section, namely S=Λ−1,<br />m=ˆ u. It follows that L2≥ L3, with equality at this<br />unique maximum.<br />The key propery of L3 is that is can be written as<br />a sum of n terms, each corresponding to one input-<br />output pair {xi,yi}: we have induced the necessary<br />factorisation to perform stochastic gradient methods<br />on the distribution q(u).<br />3.2Natural Gradients<br />Stochastic variational inference works by taking steps<br />in the direction of the approximate natural gradient<br />? g(θ), which is given by the usual gradient re-scaled<br />To work with the natural gradients of the distribution<br />q(u), we first recall the canonical and expectation pa-<br />rameters<br />θ1=S−1m,<br />by the inverse Fisher information: ? g(θ)=G(θ)−1 ∂L<br />∂θ.<br />θ2=−1<br />2S−1<br />and<br />η1=m,η2=mm?+S.<br />In the exponential family, properties of the Fisher in-<br />formation reveal the following simplification of the nat-<br />ural gradient [Hensman et al., 2012],<br />? g(θ) = G(θ)−1∂L3<br />∂θ<br />=∂L3<br />∂η.(6)<br />A step of length ? in the natural gradient direction,<br />using θ(t+1)= θ(t)+ ?dL3<br />dη, yields<br />θ2(t+1)= −1<br />2S−1<br />(t+1)<br />= −1<br />2S−1<br />(t)+ ?<br />?<br />−1<br />2Λ +1<br />2S−1<br />(t)<br />?<br />,<br />θ1(t+1)= S−1<br />(t+1)m(t+1)<br />= S−1<br />(t)m(t)+ ?<br />?<br />βK−1<br />mmKmny − S−1<br />(t)m(t)<br />?<br />,<br />and taking a step of unit length then recovers the same<br />solution as above by either (3) or (5). This confirms<br />the result discussed in Hensman et al. [2012], Hoffman<br />et al. [2012], that taking this unit step is the same as</p>  <p>Page 4</p> <p>performing a VB update. We can now obtain stochas-<br />tic approximations to the natural gradient by consid-<br />ering the data either individually or in mini-batches.<br />We note the convenient result that the natural gradi-<br />ent for θ2is positive definite (note Λ = K−1<br />This means that taking a step in that direction always<br />leads to a positive definite matrix, and our implemen-<br />tation need not parameterise S in any way so as to<br />ensure positive-definiteness, cf. standard gradient ap-<br />proaches on covariance matrices.<br />mm+?<br />iΛi).<br />To optimise the kernel hyper-parameters and noise<br />precision β, we take derivatives of the bound L3and<br />perform standard stochastic gradient descent along-<br />side the variational parameters. An illustration is pre-<br />sented in Figure 2.<br />3.3Latent Variables<br />The above derivations enable online learning for Gaus-<br />sian process regression using SVI. Several GP based<br />models involve inference of X, such as the GP latent<br />variable model [Lawrence, 2005, Titsias and Lawrence,<br />2010] and its extensions [e.g. Damianou et al., 2011,<br />2012].<br />To perform stochastic variational inference with latent<br />variables, we require a factorisation as illustrated by<br />Figure 1(a): this factorisation is provided by (4). To<br />get a model like the Bayesian GPLVM, we need a lower<br />bound on logp(y). In Titsias and Lawrence [2010] this<br />was achieved through approximate marginalisation of<br />L2, w.r.t. X, which leads to an expression depending<br />only on the parameters of q(X). However this formu-<br />lation scales poorly, and the variables of the optimisa-<br />tion are closely connected due to the marginalisation<br />of u. The above enables a lower bound to which SVI<br />is immediately applicable:<br />?<br />≥<br />logp(y) =log p(y|X)p(X)dX<br />q(X)?L3+ logp(X) − logq(X)?dX.<br />It is straightforward to introduce p output dimensions<br />for the data Y, and following Titsias and Lawrence<br />[2010], we use a factorising normal distribution q(X) =<br />?n<br />To perform SVI in this model, we now alternate be-<br />tween selecting a minibatch of data, and optimisting<br />the relevant variables of q(X) with q(u) fixed, and up-<br />dating q(u) using the approximate natural gradient.<br />We note that the form of (4) means that each of the<br />latent variable distributions may be updated individ-<br />ually, enabling parallelisation across the minibatch.<br />?<br />i=1q(xi).<br />tractable for various choices of covariance function.<br />The relevant expectations of L3 are<br />3.4Non-Gaussian likelihoods<br />Another advantage of the factorisation of (4) is that<br />it enables a simple routine for inference with non-<br />Gaussian likelihoods. The usual procedure for fitting<br />GPs with non-Gaussian likelihoods is to approximate<br />the likelihood using either a local variational lower<br />bound [Gibbs and MacKay, 2000], or by expectation<br />propagation [Kuss and Rasmussen, 2005]. These ap-<br />proximations to the likelihood are required because of<br />the connections between the variables f.<br />In L3, the bound factorises in such a way that some<br />non-Gaussian likelihoods may be marginalised exactly,<br />given the existing approximations. To see this, con-<br />sider that we are presented not with the vector y, but<br />by a binary vector t with ti∈ {0,1}, and the likelihood<br />p(t|y) =?n<br />using p(t|X) ≥?p(t|y)exp{L3}dy which involves n<br />torising nature of L3. For the probit likelihood each<br />of these integrals is tractable.<br />i=1σ(yi)ti(1−σ(yi))(1−ti), as in the case of<br />classification. We can bound the marginal likelihood<br />independent one dimensional integrals due to the fac-<br />This kind of approximation, where the likelihood is in-<br />tegrated exactly is amenable to SVI in the same man-<br />ner as the regression case above through computation<br />of the natural gradient.<br />4Experiments<br />4.1Toy Data<br />To demonstrate our algorithm we begin with two sim-<br />ple toy datasets based on sinusoidal functions. In the<br />first experiment we show how the approximation con-<br />verges towards the true solution as mini-batches are<br />included. Figure 2 shows the nature of our approxi-<br />mation: the variational approximation to the inducing<br />function variables is shown.<br />The second toy problem (Figure 3) illustrates the con-<br />vergence of the algorithm on a two dimensional prob-<br />lem, again based on sinusoids. Here, we start with<br />a random initialisation for q(u), and the model con-<br />verges after 2000 iterations. We found empirically that<br />holding the covariance parameters fixed for the first<br />epoch results in more reliable convergence, as can be<br />seen in Figure 4<br />4.2UK Apartment Price Data<br />Our<br />els<br />UK.<br />data<br />2012<br />first<br />the<br />We<br />for<br />large<br />changing<br />downloaded<br />the<br />from<br />scale<br />cost<br />Gaussian<br />of<br />the<br />February<br />http://data.gov.uk/dataset/<br />processmod-<br />the<br />paid<br />apartments<br />monthly<br />in<br />price<br />toperiodOctober</p>  <p>Page 5</p> <p>Figure 2: Stochastic variational inference on a trivial GP regression problem. Each pane shows the posterior of<br />the GP after a batch of data, marked as solid points. Previoulsy seen (and discarded) data are marked as empty<br />points, the distribution q(u) is represented by vertical errorbars.<br />(a) Initial condition(b) Condition at 2000 iterations<br />Figure 3: A two dimensional toy demo, showing the initial condition and final condition of the model. Data are<br />marked as colored points, and the model’s prediction is shown as (similarly colored) contour lines. The positions<br />of the inducing variables are marked as empty circles.</p>  <p>Page 6</p> <p>Figure 4: Convergence of the SVIGP algorithm on the<br />two dimensional toy data<br />land-registry-monthly-price-paid-data/, which<br />covers England and Wales, and filtered for apart-<br />ments. This resulted in a data set with 75,000 entries,<br />which we cross referenced against a postcode database<br />to get lattitude and longitude, on which we regressed<br />the normalised logarithm of the apartment prices.<br />Randomly selecting 10,000 data as a test set, we build<br />a GP as described with a covariance function k(·,·)<br />consisting of four parts: two squared exponential co-<br />variances, initialised with different length scales were<br />used to account for national and regional variations in<br />property prices, a constant (or ’bias’) term allowed for<br />non-zero mean data, and a noise variance accounted<br />for variation that could not be modelled using simply<br />latitude and longitude.<br />We selected 800 inducing input sites using a k-means<br />algorithm, and optimised the parameters of the co-<br />variance function alongside the variational parameters.<br />We performed some manual tuning of the learning<br />rates: empirically we found that the step length should<br />be much higher for the variational parameters of q(u)<br />than for the values of the covariance function parame-<br />ters. We used 0.01 and 1 × 10−5. Also, we included a<br />momentum term for the covariance function parame-<br />ters (set to 0.9). We tried including momentum terms<br />for the variational parameters, but we found this hin-<br />dered performance. A large mini-batch size (1000) re-<br />duced the stochasticity of the gradient computations.<br />We judged that the algorithm had converged after 750<br />iterations, as the stochastic estimate of the marginal<br />lower bound on the marginal likelihood failed to in-<br />crease further.<br />For comparison to our model, we constructed a se-<br />ries of GPs on subsets of the training data. Splitting<br />the data into sets of 500, 800, 1000 and 1200, we fit-<br />Figure 5: Variability of apartment price (logarithmi-<br />cally!) throughout England and Wales.<br />ted a GP with the same covariance function as our<br />stochastic GP. Parameters of the covariance function<br />were optimised using type-II maximum likelihood for<br />each batch. Table 1 reports the mean squared error in<br />our model’s prediction of the held out prices, as well<br />as the same for the random sub-set approach (along<br />with two standard deviations of the inter-sub-set vari-<br />ability).<br />Table 1: Mean squared errors in predicting the log-<br />apartment prices across England and Wales by latti-<br />tude and longitude<br />Mean square Error<br />SVIGP0.426<br />Random sub-set (N=500)<br />Random sub-set (N=800)<br />Random sub-set (N=1000)<br />Random sub-set (N=1200)<br />0.522 +/- 0.018<br />0.510 +/- 0.015<br />0.503 +/- 0.011<br />0.502 +/- 1.012<br />4.3Airline Delays<br />The second large scale dataset we considered consists<br />of flight arrival and departure times for every commer-<br />cial flight in the USA from January 2008 to April 2008.<br />This dataset contains extensive information about al-<br />most 2 million flights, including the delay (in minutes)<br />in reaching the destination. The average delay of a<br />flight in the first 4 months of 2008 was of 30 minutes.<br />Of course, much better estimates can be given by ex-<br />ploiting the enourmous wealth of data available, but<br />rich models are often overlooked in these cases due</p>  <p>Page 7</p> <p>Figure 6: Posterior variance of apartment prices.<br />to the sheer size of the dataset. We randomly selected<br />800,000 datapoints2, using a random subset of 700,000<br />samples to train the model and 100,000 to test it. We<br />chose to include into our model 8 of the many variables<br />available for this dataset: the age of the aircraft (num-<br />ber of years since deployment), distance that needs to<br />be covered, airtime, departure time, arrival time, day<br />of the week, day of the month and month.<br />We built a Gaussian process with a squared exponen-<br />tial covariance function with a bias and noise term.<br />In order to discard irrelevant input dimensions, we al-<br />lowed a separate lengthscale for each input. For our<br />experiments, we used m = 1000 inducing inputs and<br />a mini-batch size of 5000. The learning rate for the<br />variational parameters of q(u) was set to 0.01, while<br />the learning rate for the covariance function parame-<br />ters was set to 1 × 10−5. We also used a momentum<br />term of 0.9 for the covariance parameters.<br />For the purpose of comparison, we fitted several GPs<br />with an identical covariance function on subsets of the<br />data. We split the data into sets of 800, 1000 and 1200<br />samples and optimised the parameters using type-II<br />maximum likelihood. We repeated this procedure 10<br />times.<br />The left pane of Figure 7 shows the root mean squared<br />error (RMSE) obtained by fitting GPs on subsets of<br />the data. The right pane of figure 7 shows the RMSE<br />obtained by fitting 10 SVI GPs as a function of the<br />iteration. The individual runs are shown in light gray,<br />while the blue line shows the average RMSE across<br />2Subsampling wasn’t technically necessary, but we<br />didn’t want to overburden the memory of a shared compute<br />node just before a submission deadline.<br />Figure 8: Root mean square errors for models with<br />different numbers of inducing variables.<br />Figure 9: Automatic relevance determination param-<br />eters for the features used for predicting flight delays.<br />runs.<br />One of the main advantages of the approach presented<br />here is that the computational complexity is indepen-<br />dent from the number of samples n. This allowed us<br />to use a much larger number of inducing inputs than<br />has traditionally been possible. Conventional sparse<br />GPs have a computational complexity of O(nm2), so<br />for large n the typical upper bound for m is between 50<br />and 100. The impact on the prediction performance is<br />quite significant, as highlighted in Figure 8, where we<br />fit several SVI GPs using different numbers of inducing<br />inputs.<br />Looking at the inverse lengthscales in Figure 9, it’s<br />possible to get a better idea of the relevance of the<br />different features available in this dataset. The most<br />relevant variable turned out to be the time of departure<br />of the flight, closely followed by the distance that needs</p>  <p>Page 8</p> <p>Figure 7: Root mean squared errors in predicting flight delays using information about the flight.<br />to be covered. Distance and airtime should in theory<br />be correlated, but they have very different relevances.<br />This can be intuitively explained by considering that<br />on longer flights it’s easier to make up for delays at<br />departure.<br />5Discussion<br />We have presented a method for inference in Gaussian<br />process models using stochastic variational inference.<br />These expressions allow for the transfer of a multitude<br />of Gaussian process techniques to big data.<br />We note several interesting results.<br />derivation disusses the bound on p(y|u) in detail,<br />showing that it becomes tight when Z = X.<br />First, the our<br />Also, we have that there is a unique solution for the pa-<br />rameters of q(u) such that the bound associated with<br />the standard variational sparse GP [Titsias, 2009] is<br />recovered.<br />Further, since the complexity of our model is now<br />O(m3) rather than O(nm2), we are free to increase<br />m to much greater values than the sparse GP repre-<br />sentation. The effect of this is that we can have much<br />richer models: for a squared exponential covariance<br />function, we have far more basis-functions with which<br />to model the data. In our UK apartment price exam-<br />ple, we had no difficulty setting m to 800, much higher<br />than experience tells us is feasible with the sparse GP.<br />The ability to increase the number of inducing vari-<br />ables and the applicability to unlimited data make our<br />method suitable for multiple output GPs [´Alvarez and<br />Lawrence, 2011]. We have also briefly discussed how<br />this framework fits with other Gaussian process based<br />models such as the GPLVM and GP classification. We<br />leave the details of these implementations to future<br />work.<br />In all our experiments our algorithm was run on a<br />single CPU using the GPy Gaussian process toolkit<br />https://github.com/SheffieldML/GPy.<br />References<br />Mauricio A.´Alvarez and Neil D. Lawrence. Compu-<br />tationally efficient convolved multiple output Gaus-<br />sian processes. Journal of Machine Learning Re-<br />search, 12:1425–1466, May 2011.<br />Lehel Csat´ o and Manfred Opper. Sparse on-line Gaus-<br />sian processes. Neural Computation, 14(3):641–668,<br />2002.<br />Andreas Damianou, Michalis K. Titsias, and Neil D.<br />Lawrence. Variational Gaussian process dynamical<br />systems. In Peter Bartlett, Fernando Peirrera, Chris<br />Williams, and John Lafferty, editors, Advances in<br />Neural Information Processing Systems, volume 24,<br />Cambridge, MA, 2011. MIT Press.<br />Andreas Damianou, Carl Henrik Ek, Michalis K. Tit-<br />sias, and Neil D. Lawrence. Manifold relevance de-<br />termination. In John Langford and Joelle Pineau,<br />editors, Proceedings of the International Conference<br />in Machine Learning, volume 29, San Francisco, CA,<br />2012. Morgan Kauffman. To appear.<br />Mark N. Gibbs and David J. C. MacKay. Variational<br />Gaussian process classifiers. IEEE Transactions on<br />Neural Networks, 11(6):1458–1464, 2000.<br />James Hensman,Magnus Rattray,and Neil D.</p>  <p>Page 9</p> <p>Lawrence. Fast variational inference in the expo-<br />nential family. NIPS 2012, 2012.<br />Matthew Hoffman, David M. Blei, Chong Wang, and<br />John Paisley. Stochastic variational inference. arXiv<br />preprint arXiv:1206.7051, 2012.<br />Malte Kuss and Carl Edward Rasmussen.<br />ing approximate inference for binary Gaussian pro-<br />cess classification. Journal of Machine Learning Re-<br />search, 6:1679–1704, 2005.<br />Assess-<br />Neil D. Lawrence. Probabilistic non-linear principal<br />component analysis with Gaussian process latent<br />variable models. Journal of Machine Learning Re-<br />search, 6:1783–1816, 11 2005.<br />Joaquin Qui˜ nonero Candela and Carl Edward Ras-<br />mussen.A unifying view of sparse approximate<br />Gaussian process regression.<br />Learning Research, 6:1939–1959, 2005.<br />Journal of Machine<br />Carl Edward Rasmussen and Christopher K. I.<br />Williams. Gaussian Processes for Machine Learn-<br />ing. MIT Press, Cambridge, MA, 2006. ISBN 0-<br />262-18253-X.<br />Matthias Seeger, Christopher K. I. Williams, and<br />Neil D. Lawrence. Fast forward selection to speed<br />up sparse Gaussian process regression. In Christo-<br />pher M. Bishop and Brendan J. Frey, editors, Pro-<br />ceedings of the Ninth International Workshop on Ar-<br />tificial Intelligence and Statistics, Key West, FL, 3–6<br />Jan 2003.<br />Edward Snelson and Zoubin Ghahramani. Local and<br />global sparse Gaussian process approximations. In<br />Marina Meila and Xiaotong Shen, editors, Proceed-<br />ings of the Eleventh International Workshop on Ar-<br />tificial Intelligence and Statistics, San Juan, Puerto<br />Rico, 21-24 March 2007. Omnipress.<br />Michalis K. Titsias. Variational learning of inducing<br />variables in sparse Gaussian processes.<br />van Dyk and Max Welling, editors, Proceedings of<br />the Twelfth International Workshop on Artificial In-<br />telligence and Statistics, volume 5, pages 567–574,<br />Clearwater Beach, FL, 16-18 April 2009. JMLR<br />W&amp;CP 5.<br />In David<br />Michalis K. Titsias and Neil D. Lawrence. Bayesian<br />Gaussian process latent variable model.<br />Yee Whye Teh and D. Michael Titterington, editors,<br />Proceedings of the Thirteenth International Work-<br />shop on Artificial Intelligence and Statistics, vol-<br />ume 9, pages 844–851, Chia Laguna Resort, Sar-<br />dinia, Italy, 13-16 May 2010. JMLR W&amp;CP 9.<br />In<br />Raquel Urtasun and Trevor Darrell. Local probabilis-<br />tic regression for activity-independent human pose<br />inference. In Proceedings of the IEEE Computer So-<br />ciety Conference on Computer Vision and Pattern<br />Recognition, Anchorage, Alaska, 2008.</p>  <a href="https://www.researchgate.net/profile/James_Hensman/publication/257069490_Gaussian_Processes_for_Big_Data/links/55adfd9508ae98e661a45327.pdf">Download full-text</a> </div> <div id="rgw21_56ab1eda73233" class="c-box pub-resource-container js-toggle" style=""> <h4 class="lf js-expand-list"><small><a href="javascript:" class="lf">View other sources <span class="ico-expand-list"></span></a></small></h4> <h4 class="lf js-collapse-list hidden"><small><a href="javascript:" class="lf">Hide other sources <span class="ico-collapse-list"></span></a></small></h4> <div class="clear"></div> <div class="scroll-wrapper hidden"> <ul class="files-list c-list" id="rgw22_56ab1eda73233">  <li class="c-list-item pub-resource-item"  data-type="fulltext" id="rgw23_56ab1eda73233"> <span class="ico-pub"></span> <div class="file-content"> <div class="download"> <a href="profile/James_Hensman/publication/257069490_Gaussian_Processes_for_Big_Data/links/55adfd9508ae98e661a45327.pdf" class="publication-viewer" title="55adfd9508ae98e661a45327.pdf">55adfd9508ae98e661a45327.pdf</a> </div>  <div class="details">  <span> Available from <a href="profile/James_Hensman">James Hensman</a> &middot; Jul 21, 2015 </span>   </div>    </div> </li>  <li class="c-list-item pub-resource-item"  data-type="fulltext" id="rgw24_56ab1eda73233"> <span class="ico-pub"></span> <div class="file-content"> <div class="download"> <a href="http://export.arxiv.org/pdf/1309.6835" target="_blank" rel="nofollow" class="publication-viewer" title="Gaussian Processes for Big Data">Gaussian Processes for Big Data</a> </div>  <div class="details">   Available from <a href="http://export.arxiv.org/pdf/1309.6835" target="_blank" rel="nofollow">export.arxiv.org</a>  </div>    </div> </li>  </ul> </div> </div> </noscript> <div class="clearfix"> <div class="action-container">  </div> <div class="pub-legal"> Data provided are for informational purposes only. Although carefully collected, accuracy cannot be guaranteed. The impact factor represents a rough estimation of the journal's impact factor and does not reflect the actual current impact factor. Publisher conditions are provided by RoMEO. Differing provisions from the publisher's actual policy or licence agreement may be applicable. </div>  <div id="rgw31_56ab1eda73233" class="citations-container"> <div class="tab-container"> <ul class="tab-list"> <li class="lf tab-item  js-citations"> <a href="javascript:void(0);" class="tab-link"> References  </small> </a> </li>  <li class="lf tab-item tab-item-active js-cited-in js-cited-in-tooltip"> <a href="javascript:void(0);" class="tab-link"> Cited In <small> (31) </small> </a> </li>    <li class="rf"> <div class="dropdown js-citations-sorter dropdown-right-align" style="position: relative; bottom: -1px;display:none;"> <a href="javascript:void(0);" class="dropdown-toggle"> Sorted by: <strong class="js-current-sorting"> Order of availability  </strong> <span class="caret"></span> </a> <ul class="dropdown-menu"> <li><a href="javascript:void(0);" data-sort="normal">Order of availability</a></li> <li><a href="javascript:void(0);" data-sort="original">Appearance in publication</a></li> </ul> </div> </li>  </ul> <div class="tab-section tab-section-active js-citations-list-container"> <div id="rgw32_56ab1eda73233" class="pub-citations-list">  <ul class="c-list">  <li class="c-list-item li-publication   includes-citation-list"  id="rgw33_56ab1eda73233" >  <div class="indent-left">  <div id="rgw34_56ab1eda73233" class="js-publication-item-fulltext fulltext-thumb">    <a class="publication-preview ga-publication-viewer js-publication-item-fulltext-content" href="publication/283532531_Thoughts_on_Massively_Scalable_Gaussian_Processes">       </a>   <div class="preview-source-info"> <a class="details js-show-source ga-source-url" href="profile/Hannes_Nickisch" >Source</a>  <div class="tooltip-content" style="display: none"> Available from: Hannes Nickisch </div> </div>   </div>  </div>  <div class="indent-right">      </div>  <ul class="citation-contexts" id="rgw35_56ab1eda73233">  <li class="citation-context-item"> "Moreover, for computational tractability, these approaches require m n, which can severely affect predictive performance, limit representational power, and the ability for kernel learning, which is most needed on large datasets (Wilson , 2014). New directions for scalable Gaussian processes have involved mini-batches of data through stochastic variational inference (Hensman et al., 2013) and distributed learning (Deisenroth and Ng, 2015). While these approaches are promising, inference can undergo severe approximations, and a small number of inducing points are still required. " </li>  </ul>   <div  style="margin-top: -2px">  <h5 class="pub-type-and-title">  <span class="publication-type">Article:</span>    <a class="js-publication-title-link js-go-to-publication ga-publication-item" href="publication/283532531_Thoughts_on_Massively_Scalable_Gaussian_Processes"> <span class="publication-title js-publication-title">Thoughts on Massively Scalable Gaussian Processes</span> </a>     </h5>  </div>    <div class="authors">     <a href="researcher/2068767308_Andrew_Gordon_Wilson" class="authors js-author-name ga-publications-authors">Andrew Gordon Wilson</a> &middot;     <a href="researcher/2083724812_Christoph_Dann" class="authors js-author-name ga-publications-authors">Christoph Dann</a> &middot;     <a href="researcher/45244854_Hannes_Nickisch" class="authors js-author-name ga-publications-authors">Hannes Nickisch</a>      </div>        <div class="abstract"> <span class="shorten"> <a href="javascript:" class="js-toggle-abstract">[Show abstract]</a> </span> <span class="full"> <a href="javascript:" class="js-toggle-abstract">[Hide abstract]</a><br/>  <strong>ABSTRACT:</strong> We introduce a framework and early results for massively scalable Gaussian
processes (MSGP), significantly extending the KISS-GP approach of Wilson and
Nickisch (2015). The MSGP framework enables the use of Gaussian processes (GPs)
on billions of datapoints, without requiring distributed inference, or severe
assumptions. In particular, MSGP reduces the standard $O(n^3)$ complexity of GP
learning and inference to $O(n)$, and the standard $O(n^2)$ complexity per test
point prediction to $O(1)$. MSGP involves 1) decomposing covariance matrices as
Kronecker products of Toeplitz matrices approximated by circulant matrices.
This multi-level circulant approximation allows one to unify the orthogonal
computational benefits of fast Kronecker and Toeplitz approaches, and is
significantly faster than either approach in isolation; 2) local kernel
interpolation and inducing points to allow for arbitrarily located data inputs,
and $O(1)$ test time predictions; 3) exploiting block-Toeplitz Toeplitz-block
structure (BTTB), which enables fast inference and learning when
multidimensional Kronecker structure is not present; and 4) projections of the
input space to flexibly model correlated inputs and high dimensional data. The
ability to handle many ($m \approx n$) inducing points allows for near-exact
accuracy and large scale kernel learning. </span> </div>    <div class="publication-meta publication-meta">   <span class="ico-publication-fulltext reset-background"></span> Full-text   &middot; Article &middot; Nov 2015  </div>        <div class="publication-actions"> <div class="btn-group">  <a class="btn btn-plain action-download primary  open-viewer" href="profile/Hannes_Nickisch/publication/283532531_Thoughts_on_Massively_Scalable_Gaussian_Processes/links/568a8a8008ae051f9afa595b.pdf?origin=publication_list">  <span class="js-btn-label">Download</span> </a>    </div> </div>      </li>  <li class="c-list-item li-publication   includes-citation-list"  id="rgw36_56ab1eda73233" >  <div class="indent-left">  <div id="rgw37_56ab1eda73233" class="js-publication-item-fulltext fulltext-thumb">    <a class="publication-preview ga-publication-viewer js-publication-item-fulltext-content" href="publication/283335187_Blitzkriging_Kronecker-structured_Stochastic_Gaussian_Processes">       </a>   <div class="preview-source-info"> <a class="details js-show-source ga-source-url" href="deref/http%3A%2F%2Fde.arxiv.org%2Fpdf%2F1510.07965" target="_blank" >Source</a>  <div class="tooltip-content" style="display: none"> Available from: de.arxiv.org </div> </div>   </div>  </div>  <div class="indent-right">      </div>  <ul class="citation-contexts" id="rgw38_56ab1eda73233">  <li class="citation-context-item"> "Additionally, the likelihood can not be split up over the data, precluding the use of stochastic gradient methods that allow learning on large datasets, through cheap but noisy observations of the gradient of the objective function on minibatches (small subsets) of the full data. Both of these issues have been solved in Hensman et al. [6] with their stochastic variational GP (SVGP) and a generalisation to all inducing methods by Hoang et al. [7]. We concentrate on the SVGP here, for the ease of testing against the popular GPy library [1]. " </li>  </ul>   <div  style="margin-top: -2px">  <h5 class="pub-type-and-title">  <span class="publication-type">Article:</span>    <a class="js-publication-title-link js-go-to-publication ga-publication-item" href="publication/283335187_Blitzkriging_Kronecker-structured_Stochastic_Gaussian_Processes"> <span class="publication-title js-publication-title">Blitzkriging: Kronecker-structured Stochastic Gaussian Processes</span> </a>     </h5>  </div>    <div class="authors">     <a href="researcher/2052101055_Thomas_Nickson" class="authors js-author-name ga-publications-authors">Thomas Nickson</a> &middot;     <a href="researcher/2051950921_Tom_Gunter" class="authors js-author-name ga-publications-authors">Tom Gunter</a> &middot;     <a href="researcher/2051935693_Chris_Lloyd" class="authors js-author-name ga-publications-authors">Chris Lloyd</a> &middot;     <a href="researcher/2051939493_Michael_A_Osborne" class="authors js-author-name ga-publications-authors">Michael A Osborne</a> &middot;     <a href="researcher/2083725021_Stephen_Roberts" class="authors js-author-name ga-publications-authors">Stephen Roberts</a>      </div>        <div class="abstract"> <span class="shorten"> <a href="javascript:" class="js-toggle-abstract">[Show abstract]</a> </span> <span class="full"> <a href="javascript:" class="js-toggle-abstract">[Hide abstract]</a><br/>  <strong>ABSTRACT:</strong> We present Blitzkriging, a new approach to fast inference for Gaussian
processes, applicable to regression, optimisation and classification.
State-of-the-art (stochastic) inference for Gaussian processes on very large
datasets scales cubically in the number of &#39;inducing inputs&#39;, variables
introduced to factorise the model. Blitzkriging shares state-of-the-art scaling
with data, but reduces the scaling in the number of inducing points to
approximately linear. Further, in contrast to other methods, Blitzkriging: does
not force the data to conform to any particular structure (including
grid-like); reduces reliance on error-prone optimisation of inducing point
locations; and is able to learn rich (covariance) structure from the data. We
demonstrate the benefits of our approach on real data in regression,
time-series prediction and signal-interpolation experiments. </span> </div>    <div class="publication-meta publication-meta">  <span class="ico-publication-preview reset-background"></span> Preview    &middot; Article &middot; Oct 2015  </div>        <div class="publication-actions"> <div class="btn-group">  <a class="btn btn-plain action-request-external  " href="javascript:;" data-context="pubCit">  <span class="js-btn-label">Request full-text</span> </a>    </div> </div>      </li>  <li class="c-list-item li-publication   includes-citation-list"  id="rgw39_56ab1eda73233" >  <div class="indent-left">  <div id="rgw40_56ab1eda73233" class="js-publication-item-fulltext fulltext-thumb">    <a class="publication-preview ga-publication-viewer js-publication-item-fulltext-content" href="publication/282359718_Asymmetric_Transfer_Learning_with_Deep_Gaussian_Processes">       </a>   <div class="preview-source-info"> <a class="details js-show-source ga-source-url" href="profile/Melih_Kandemir" >Source</a>  <div class="tooltip-content" style="display: none"> Available from: Melih Kandemir </div> </div>   </div>  </div>  <div class="indent-right">      </div>  <ul class="citation-contexts" id="rgw41_56ab1eda73233">  <li class="citation-context-item"> "tection application. For all sparse GP components, we use 10 inducing points that are initialized to cluster centroids found by k-means, as in Hensman et al. (2013). We set the inducing points of the first layer GPs to instances chosen from the training set at random, and learn them from data for the second layer GPs. " </li>  </ul>   <div  style="margin-top: -2px">  <h5 class="pub-type-and-title">  <span class="publication-type">Conference Paper:</span>    <a class="js-publication-title-link js-go-to-publication ga-publication-item" href="publication/282359718_Asymmetric_Transfer_Learning_with_Deep_Gaussian_Processes"> <span class="publication-title js-publication-title">Asymmetric Transfer Learning with Deep Gaussian Processes</span> </a>     </h5>  </div>    <div class="authors">     <a href="researcher/48088163_Melih_Kandemir" class="authors js-author-name ga-publications-authors">Melih Kandemir</a>      </div>        <div class="abstract"> <span class="shorten"> <a href="javascript:" class="js-toggle-abstract">[Show abstract]</a> </span> <span class="full"> <a href="javascript:" class="js-toggle-abstract">[Hide abstract]</a><br/>  <strong>ABSTRACT:</strong> We introduce a novel Gaussian process based Bayesian model for asymmetric transfer learning. We adopt a two-layer feed-forward deep Gaussian process as the task learner of source and target domains. The first layer projects the data onto a separate non-linear manifold for each task. We perform knowledge transfer by projecting the target data also onto the source domain and linearly combining its representations on the source and target domain manifolds. Our approach achieves the state-of-the-art in a benchmark real-world image categorization task, and improves on it in cross-tissue tumor detection from histopathology tissue slide images. </span> </div>    <div class="publication-meta publication-meta">   <span class="ico-publication-fulltext reset-background"></span> Full-text   &middot; Conference Paper &middot; Jul 2015  </div>        <div class="publication-actions"> <div class="btn-group">  <a class="btn btn-plain action-download primary  open-viewer" href="profile/Melih_Kandemir/publication/282359718_Asymmetric_Transfer_Learning_with_Deep_Gaussian_Processes/links/560e6b4108ae0fc513ed33be.pdf?origin=publication_list">  <span class="js-btn-label">Download</span> </a>    </div> </div>      </li>  </ul>    <a class="show-more-rebranded js-show-more rf text-gray-lighter">Show more</a> <span class="ajax-loading-small list-loading" style="display: none"></span>  <div class="clearfix"></div>  <div class="publication-detail-sidebar-legal">Note: This list is based on the publications in our database and might not be exhaustive.</div> <div class="clearfix"></div>  </div> </div> </div> </div> </div> </div> <div class="clearfix">     <div id="rgw26_56ab1eda73233" class="c-box pub-resource-container js-toggle" style="display: none;"> <h4 class="lf js-expand-list"><small><a href="javascript:" class="lf">View other sources <span class="ico-expand-list"></span></a></small></h4> <h4 class="lf js-collapse-list hidden"><small><a href="javascript:" class="lf">Hide other sources <span class="ico-collapse-list"></span></a></small></h4> <div class="clear"></div> <div class="scroll-wrapper hidden"> <ul class="files-list c-list" id="rgw27_56ab1eda73233">  </ul> </div> </div>   <div id="rgw17_56ab1eda73233" class="similar-publications"> <h2>Similar Publications</h2> <ul class="list-bordered">  <li class="c-list-item li-publication-teaser" id="rgw18_56ab1eda73233"> <div> <h5> <a href="publication/290497659_Big_Data_Big_Challenges" class="color-inherit ga-similar-publication-title"><span class="publication-title">Big Data, Big Challenges</span></a>  </h5>  <div class="authors"> <a href="researcher/2094022954_Michael_V_Boland" class="authors ga-similar-publication-author">Michael V. Boland</a>  </div>  </div> <div class="clear"></div> </li>  <li class="c-list-item li-publication-teaser" id="rgw19_56ab1eda73233"> <div> <h5> <a href="publication/291392678_Big_Data_Gets_Personal" class="color-inherit ga-similar-publication-title"><span class="publication-title">&quot;Big Data&quot; Gets Personal</span></a>  </h5>  <div class="authors"> <a href="researcher/2095354651_M_S_Lebo" class="authors ga-similar-publication-author">M. S. Lebo</a>, <a href="researcher/2095341679_S_Sutti" class="authors ga-similar-publication-author">S. Sutti</a>, <a href="researcher/2095302301_R_C_Green" class="authors ga-similar-publication-author">R. C. Green</a>  </div>  </div> <div class="clear"></div> </li>  <li class="c-list-item li-publication-teaser" id="rgw20_56ab1eda73233"> <div> <h5> <a href="publication/291387589_Editor%27s_Page_Got_Big_Data" class="color-inherit ga-similar-publication-title"><span class="publication-title">Editor&#39;s Page: Got Big Data?</span></a>  </h5>  <div class="authors"> <a href="researcher/39839277_Paul_J_Hauptman" class="authors ga-similar-publication-author">Paul J. Hauptman</a>  </div>  </div> <div class="clear"></div> </li>  </ul> </div> </div> </div> </div> </div></div></div>
<div class="clear"></div><div id="rgw51_56ab1eda73233" class="default-footer"> <div id="footer" class="clearfix"> <span class="footer-left"> &copy; 2008&dash;2016 researchgate.net. All rights reserved. </span> <span class="footer-right"> <a href="https://www.researchgate.net/about">About us</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="https://www.researchgate.net/contact">Contact us</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="careers">Careers</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="developers">Developers</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="blog" target="_blank">News</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="application.PrivacyPolicy.html">Privacy</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="application.TermsAndConditions.html">Terms</a> <span class="footer-link-separator" style="padding: 0 5px;">&nbsp;|&nbsp;</span> <a href="advertising?_ref=ft">Advertising</a> <span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="recruiters?_ref=ft">Recruiting</a> </span> </div>  </div></div>
<div id="rgw52_56ab1eda73233">  <div class="header-wrapper-logged-out"> <div id="header"> <div class="header-content"> <a href="" class="g-l-logo"> <svg width="149" height="19"> <image xlink:href="https://c5.rgstatic.net/m/235107188705592/images/template/brand-header-logo.svg" src="https://c5.rgstatic.net/m/238113351022438/images/template/brand-header-logo.png" width="149" height="19"/> </svg> </a> <a href="" class="g-l-logo-ico"> <svg width="127" height="17" viewbox="0 0 127 22"> <image xlink:href="https://c5.rgstatic.net/m/235107188705592/images/template/brand-header-logo.svg" src="https://c5.rgstatic.net/m/238113351022438/images/template/brand-header-logo.png" width="127" height="17"/> </svg> </a> <div id="rgw53_56ab1eda73233" class="header-login-wrapper js-header-login"> <div class="dropdown-right-align"> <div class="login-signup-container lf"> <a href="https://www.researchgate.net/signup.SignUp.html?ev=su_chnl_index&amp;hdrsu=1&amp;_sg=22S8LgvPRiI2HL3TdVY-6Q8Becb4YUrVo7DYbfXyR3c1pnK929k6Zgwwh9iNO93P" class="dropdown-toggle lf">Join for free</a> </div> <div class="dropdown lf" style="height: 20px;"> <a href="https://www.researchgate.net/application.Login.html" class="js-login-url dropdown-toggle lf">Log in <span class="caret"></span></a> <div class="dropdown-menu"> <div class="header-login-form-wrapper"> <!--[if IE 6]><p class="box-warning" style="margin-bottom: 0;">Sorry, ResearchGate no longer supports the version of Internet Explorer you are using. <a href="http://whatbrowser.org/" rel="nofollow" target="_blank">Update your web browser</a> and then log in. </p><![endif]--> <form method="post" action="https://www.researchgate.net/application.Login.html" class="form-big header-login-form js-login-form" name="loginForm" id="headerLoginForm"> <input type="hidden" name="request_token" value="KCsshlO+3iy46Cxk5s0/rFnr5+eYKmRipmaVii4SvKHjnLPmF7t8TtIpPj5ZPCF2kioscIPmdrCFD4EepCO1sXSy8UYP2kVcid+a94UZApb7gGY21h6oyYCxAJoD0oQdPI/PZumJ4k9g/7REq53X4tu30N3Zq3y8aA9lfYy1isXsUg4Zw3r+WItxE0ODpBYGS3iDEPdhoAvEeJgq6QzLnJPvApBKpFmqUoM+Fl4IGjNBOCOlnnBND35kMdnOdE9Ncoe2iSLGCcmYabzb3cy1BiZ+NHaxR/LgZFmSJa6J9OQ="/> <input type="hidden" name="urlAfterLogin" value="publication/257069490_Gaussian_Processes_for_Big_Data"/> <input type="hidden" name="invalidPasswordCount" value="0"/> <input type="hidden" name="headerLogin" value="yes"/> <label for="input-header-login">Email</label> <div class="login-input"> <div class="info-tip-wrapper"> <span class="ico-info js-info"></span> </div> <input type="email" value="" name="login" class="login js-login-input text" id="input-header-login" tabindex="1"/> </div> <div class="clear"></div> <label class="lf" for="input-header-password"> Password </label> <a class="rf forgot-password js-forgot-password" href="application.LostPassword.html">Forgot password?</a> <div class="clear"></div> <input type="password" value="" name="password" class="password js-password-input text" id="input-header-password" tabindex="2"/> <div class="clear"></div> <label class="remember-me" for="headerLoginCookie"> <input type="checkbox" checked="checked" value="yes" name="setLoginCookie" class="lf checkbox" id="headerLoginCookie" tabindex="3"/> Keep me logged in </label> <div class="clear"></div> <input value="Log in" name="loginSubmit" class="btn btn-promote btn-fullwidth btn-large allow-leave js-submit-button" type="submit" tabindex="4"/> </form> <div class="connectors"> <div class="text">or log in with</div> <div class="connector-actions"> <a href="connector/linkedin/" class="li-connect js-li-connect" data-redirect-url="cHVibGljYXRpb24vMjU3MDY5NDkwX0dhdXNzaWFuX1Byb2Nlc3Nlc19mb3JfQmlnX0RhdGE%3D"> <span class="icon ico-linkedin-round-grey"></span> <span class="icon ico-linkedin-round"></span> </a> <a href="connector/facebook/" class="fb-connect middle js-fb-connect" data-redirect-url="cHVibGljYXRpb24vMjU3MDY5NDkwX0dhdXNzaWFuX1Byb2Nlc3Nlc19mb3JfQmlnX0RhdGE%3D"> <span class="icon ico-facebook-round-grey"></span> <span class="icon ico-facebook-round"></span> </a> <a href="connector/google/" class="g-connect js-g-connect" data-redirect-url="cHVibGljYXRpb24vMjU3MDY5NDkwX0dhdXNzaWFuX1Byb2Nlc3Nlc19mb3JfQmlnX0RhdGE%3D"> <span class="icon ico-google-round-grey"></span> <span class="icon ico-google-round"></span> </a> </div> </div> </div> </div> </div> </div> </div> </div> </div> <script type="application/ld+json">
{ "@context" : "http://schema.org",
  "@type" : "Organization",
  "name" : "ResearchGate",
  "url" : "http://www.researchgate.net",
  "logo" : "http://www.researchgate.net/images/template/rg_logo_square_brand.png",
  "sameAs" : [ "https://www.facebook.com/ResearchGate",
    "https://twitter.com/ResearchGate",
    "https://plus.google.com/+researchgate",
    "https://www.linkedin.com/company/researchgate"] 
}
</script> </div> </div><div class="c-signup-bar" id="rgw54_56ab1eda73233"> <div class="banner-contents">   <span class="message">ResearchGate is the professional network for scientists and researchers.</span> <a href="signup.SignUp.html?ev=su_banner" class="btn btn-large btn-promote">Join for free</a>  </div> </div></div>
<script>
rgConfig.backendTime = 506;
</script>
<script src="//c5.rgstatic.net/m/2277196935388619/javascript/lib/yui3/yui/yui-min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/2448732603281275/javascript/yuiLoaderConfig-min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/23178613132105398/javascript/vendor/babel-core/browser-polyfill.min.js" type="text/javascript"></script>
<script>
(function (){
if (typeof YRG === "undefined") {
var xmlHttpRequest = new XMLHttpRequest();
xmlHttpRequest.open("post", "go.Error.html");
xmlHttpRequest.setRequestHeader("Content-Type", "application/json");
xmlHttpRequest.setRequestHeader("Accept", "application/json"); var loadedScripts = "";
if (window.performance && window.performance.getEntriesByType) {
    var result = [];
    var resources = performance.getEntriesByType("resource");
    for (var i in resources) {
        if (resources.hasOwnProperty(i)) {
            result.push({
                name: resources[i].name,
                duration: resources[i].duration
            });
        }
    }
    loadedScripts += "&loadedScripts=" + encodeURIComponent(JSON.stringify(result));
}
if (typeof YUI === "undefined") {
    loadedScripts += "&yuiLoaded=false";
} else {
    loadedScripts += "&yuiLoaded=true";
}
xmlHttpRequest.send("Type=InformationException&message=" + encodeURIComponent("Error loading YUI") + loadedScripts);
}
})();
</script>
<script>if (typeof YRG !== 'undefined') { YRG.use('rg-base',function(Y){Y.applyConfig({ignore: ["css-rg","css-rg2","css-ie","css-modules-publicprofile","css-pow-publicliterature-FigureList","css-pow-publicliterature-FollowPublicationPromo","css-pow-application-PdfJsReader","css-pow-publicliterature-PublicationInlineReader"]});Y.use(["rg.core.pagespeed.Monitoring"],function(Y){(function(){Y.rg.createInitialWidget({"data":{"content":{"data":{"profileSmallHeader":{"data":{"profileBadge":{"data":{"fullname":"James Hensman","imageUrl":"https:\/\/i1.rgstatic.net\/ii\/profile.image\/AS%3A277099177889798%401443077000994_m","profileStats":[],"profileFollowButton":null,"profileReputationScoreNumber":null,"profileUrl":"profile\/James_Hensman","institution":"Lancaster University","institutionUrl":false,"widgetId":"rgw4_56ab1eda73233"},"id":"rgw4_56ab1eda73233","partials":[],"templateName":"publicprofile\/stubs\/ProfileBadge.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicprofile.ProfileBadge.html?accountId=3686694","viewClass":null,"yuiModules":["css-modules-publicprofile"],"stylesheets":["modules\/publicprofile.css"],"_isYUI":true},"widgetId":"rgw3_56ab1eda73233"},"id":"rgw3_56ab1eda73233","partials":[],"templateName":"publicprofile\/stubs\/ProfileSmallHeader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicprofile.ProfileSmallHeader.html?publicationUid=257069490","viewClass":null,"yuiModules":["css-modules-publicprofile"],"stylesheets":["modules\/publicprofile.css"],"_isYUI":true},"publication":{"data":{"publicationUid":257069490,"title":"Gaussian Processes for Big Data","journalTitle":false,"journalDetailsTooltip":false,"affiliation":false,"type":"Article","details":{"journalInfos":{"journal":"Uncertainty in Artificial Intelligence - Proceedings of the 29th Conference, UAI 2013","publicationDate":"09\/2013;","publicationDateRobot":"2013-09","article":""}},"source":{"sourceUrl":"http:\/\/arxiv.org\/abs\/1309.6835","sourceName":"arXiv"},"publicationActions":null,"publicationCoins":{"data":{"tags":[{"key":"ctx_ver","value":"Z39.88-2004"},{"key":"rft_val_fmt","value":"info:ofi\/fmt:kev:mtx:journal"},{"key":"rfr_id","value":"info:sid\/researchgate.net:researchgate"},{"key":"rft.atitle","value":"Gaussian Processes for Big Data"},{"key":"rft.title","value":"Uncertainty in Artificial Intelligence - Proceedings of the 29th Conference, UAI 2013"},{"key":"rft.jtitle","value":"Uncertainty in Artificial Intelligence - Proceedings of the 29th Conference, UAI 2013"},{"key":"rft.date","value":"2013"},{"key":"rft.au","value":"James Hensman,Nicolo Fusi,Neil D. Lawrence"},{"key":"rft.genre","value":"article"}],"widgetId":"rgw6_56ab1eda73233"},"id":"rgw6_56ab1eda73233","partials":[],"templateName":"publicliterature\/stubs\/PublicationCoins.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationCoins.html?publicationUid=257069490","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationAuthors":{"data":{"publicationUid":257069490,"peopleItems":[{"data":{"authorNameOnPublication":"James Hensman","accountUrl":"profile\/James_Hensman","accountKey":"James_Hensman","imageUrl":"https:\/\/i1.rgstatic.net\/ii\/profile.image\/AS%3A277099177889798%401443077000994_m","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"James Hensman","profile":{"professionalInstitution":{"professionalInstitutionName":"Lancaster University","professionalInstitutionUrl":"institution\/Lancaster_University"}},"professionalInstitutionName":"Lancaster University","professionalInstitutionUrl":"institution\/Lancaster_University","url":"profile\/James_Hensman","imageUrl":"https:\/\/i1.rgstatic.net\/ii\/profile.image\/AS%3A277099177889798%401443077000994_l","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":false,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":true,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"accountKey":"James_Hensman","hasInfoPopup":false,"hasTeaserPopup":true,"showContactAuthorButton":true,"widgetId":"rgw9_56ab1eda73233"},"id":"rgw9_56ab1eda73233","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAccountItem.html?entityId=3686694&enableUnfollow=0&imageSize=l&enableFollowButton=0&showContactAuthorButton=1","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"accountInstitution":"Lancaster University","score":null,"largeTooltip":false,"useRebrandedImageStyle":null,"authorCount":3,"accountCount":1,"publicationUid":257069490,"widgetId":"rgw8_56ab1eda73233"},"id":"rgw8_56ab1eda73233","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAccountItem.html","templateExtensions":[],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAccountItem.html?accountId=3686694&context=pubdetail_authors_xflw&showContactAuthorButton=1&authorCount=3&accountCount=1&publicationUid=257069490","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true},{"data":{"authorUrl":"researcher\/71650991_Nicolo_Fusi","authorNameOnPublication":"Nicolo Fusi","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg","imageSize":"s","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Nicolo Fusi","profile":{"professionalInstitution":{"professionalInstitutionName":false,"professionalInstitutionUrl":null}},"professionalInstitutionName":false,"professionalInstitutionUrl":null,"url":"researcher\/71650991_Nicolo_Fusi","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":true,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":false,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"widgetId":"rgw11_56ab1eda73233"},"id":"rgw11_56ab1eda73233","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAuthorItem.html?entityId=71650991&imageSize=l&enableAuthorInviteButton=0","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"largeTooltip":false,"useRebrandedImageStyle":null,"widgetId":"rgw10_56ab1eda73233"},"id":"rgw10_56ab1eda73233","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorItem.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorItem.html?authorUid=71650991&authorNameOnPublication=Nicolo%20Fusi","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true},{"data":{"authorUrl":"researcher\/39663468_Neil_D_Lawrence","authorNameOnPublication":"Neil D. Lawrence","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg","imageSize":"s","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Neil D. Lawrence","profile":{"professionalInstitution":{"professionalInstitutionName":false,"professionalInstitutionUrl":null}},"professionalInstitutionName":false,"professionalInstitutionUrl":null,"url":"researcher\/39663468_Neil_D_Lawrence","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":true,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":false,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"widgetId":"rgw13_56ab1eda73233"},"id":"rgw13_56ab1eda73233","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAuthorItem.html?entityId=39663468&imageSize=l&enableAuthorInviteButton=0","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"largeTooltip":false,"useRebrandedImageStyle":null,"widgetId":"rgw12_56ab1eda73233"},"id":"rgw12_56ab1eda73233","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorItem.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorItem.html?authorUid=39663468&authorNameOnPublication=Neil%20D.%20Lawrence","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true}],"hasMore":false,"nextOffset":6,"useRebrandedImageStyle":null,"widgetId":"rgw7_56ab1eda73233"},"id":"rgw7_56ab1eda73233","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorList.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorList.html?publicationUid=257069490&context=pubdetail_authors_xflw&showContactAuthorButton=1","viewClass":"views.publicliterature.PublicationDetailAuthorListView","yuiModules":["rg.views.publicliterature.PublicationDetailAuthorListView"],"stylesheets":[],"_isYUI":true},"publicationAbstract":{"data":{"publicationUid":257069490,"abstract":"<noscript><\/noscript><div>We introduce stochastic variational inference for Gaussian process models.<br \/>\nThis enables the application of Gaussian process (GP) models to data sets<br \/>\ncontaining millions of data points. We show how GPs can be vari- ationally<br \/>\ndecomposed to depend on a set of globally relevant inducing variables which<br \/>\nfactorize the model in the necessary manner to perform variational inference.<br \/>\nOur ap- proach is readily extended to models with non-Gaussian likelihoods and<br \/>\nlatent variable models based around Gaussian processes. We demonstrate the<br \/>\napproach on a simple toy problem and two real world data sets.<\/div>","canEdit":false,"isAdmin":false,"isArtifact":false,"showFullAbstract":false,"widgetId":"rgw14_56ab1eda73233"},"id":"rgw14_56ab1eda73233","partials":[],"templateName":"publicliterature\/stubs\/PublicationAbstract.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationAbstract.html?publicationUid=257069490","viewClass":"views.publicliterature.PublicationAbstractView","yuiModules":["rg.views.publicliterature.PublicationAbstractView"],"stylesheets":[],"_isYUI":true},"publicationKeywords":null,"publicationState":null,"isGuest":true,"isAdminEditingAllowed":false,"isArtifact":false,"figureListWidget":{"data":{"figures":[{"imageUrl":"https:\/\/www.researchgate.net\/profile\/James_Hensman\/publication\/257069490\/figure\/fig1\/Figure-2-Stochastic-variational-inference-on-a-trivial-GP-regression-problem-Each-pane.png","previewImageUrl":"https:\/\/www.researchgate.net\/profile\/James_Hensman\/publication\/257069490\/figure\/fig1\/Figure-2-Stochastic-variational-inference-on-a-trivial-GP-regression-problem-Each-pane_small.png","figureUrl":"\/figure\/257069490_fig1_Figure-2-Stochastic-variational-inference-on-a-trivial-GP-regression-problem-Each-pane","selected":false,"title":"Figure 2: Stochastic variational inference on a trivial GP regression...","key":"257069490_fig1_Figure-2-Stochastic-variational-inference-on-a-trivial-GP-regression-problem-Each-pane"}],"readerDocId":"5421520","linkBehaviour":"dialog","isDialog":true,"headerText":"Figures in this publication","isNewPublicationDesign":false,"widgetId":"rgw15_56ab1eda73233"},"id":"rgw15_56ab1eda73233","partials":[],"templateName":"publicliterature\/stubs\/FigureList.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.FigureList.html?readerDocId=5421520&isDialog=1&linkBehaviour=dialog","viewClass":"views.publicliterature.FigureListView","yuiModules":["rg.views.publicliterature.FigureListView","css-pow-publicliterature-FigureList"],"stylesheets":["pow\/publicliterature\/FigureList.css"],"_isYUI":true},"previewImage":"https:\/\/i1.rgstatic.net\/publication\/257069490_Gaussian_Processes_for_Big_Data\/links\/55adfd9508ae98e661a45327\/smallpreview.png","nativeAdDisclosure":null,"showFollowPublicationButton":false,"followPublicationPromo":{"data":{"widgetId":"rgw16_56ab1eda73233"},"id":"rgw16_56ab1eda73233","partials":[],"templateName":"publicliterature\/stubs\/FollowPublicationPromo.html","templateExtensions":[],"attrs":{"context":null,"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.FollowPublicationPromo.html","viewClass":null,"yuiModules":["css-pow-publicliterature-FollowPublicationPromo"],"stylesheets":["pow\/publicliterature\/FollowPublicationPromo.css"],"_isYUI":true},"widgetId":"rgw5_56ab1eda73233"},"id":"rgw5_56ab1eda73233","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailItem.html","templateExtensions":["generalHelpers"],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailItem.html?publicationUid=257069490&showActionBar=0&showContactAuthorButton=1&showRequestFulltextExperience=0&showNoRgAuthorsRequestFulltextExperience=0&showFollowPublicationPromo=1","viewClass":"views.publicliterature.PublicationDetailItemView","yuiModules":["rg.views.publicliterature.PublicationDetailItemView"],"stylesheets":[],"_isYUI":true},"similarPublications":{"data":{"publicationListItems":[{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore","clickThrough":"experimentMilestoneClickedToPublicationFromReferenceWithNoFulltext","clickThroughWithContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":2094022954,"url":"researcher\/2094022954_Michael_V_Boland","fullname":"Michael V. Boland","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Jan 2016","journal":"Ophthalmology","showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/290497659_Big_Data_Big_Challenges","usePlainButton":true,"publicationUid":290497659,"feedStubs":null,"hasFeedStubs":false,"impactPoints":"6.14","url":"publication\/290497659_Big_Data_Big_Challenges","title":"Big Data, Big Challenges","displayTitleAsLink":true,"authors":[{"id":2094022954,"url":"researcher\/2094022954_Michael_V_Boland","fullname":"Michael V. Boland","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["Ophthalmology 01\/2016; 123(1):7-8. DOI:10.1016\/j.ophtha.2015.08.041"],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/290497659_Big_Data_Big_Challenges","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/290497659_Big_Data_Big_Challenges\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw18_56ab1eda73233"},"id":"rgw18_56ab1eda73233","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=290497659","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore","clickThrough":"experimentMilestoneClickedToPublicationFromReferenceWithNoFulltext","clickThroughWithContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":2095354651,"url":"researcher\/2095354651_M_S_Lebo","fullname":"M. S. Lebo","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2095341679,"url":"researcher\/2095341679_S_Sutti","fullname":"S. Sutti","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2095302301,"url":"researcher\/2095302301_R_C_Green","fullname":"R. C. Green","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Jan 2016","journal":"Science translational medicine","showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/291392678_Big_Data_Gets_Personal","usePlainButton":true,"publicationUid":291392678,"feedStubs":null,"hasFeedStubs":false,"impactPoints":"15.84","url":"publication\/291392678_Big_Data_Gets_Personal","title":"\"Big Data\" Gets Personal","displayTitleAsLink":true,"authors":[{"id":2095354651,"url":"researcher\/2095354651_M_S_Lebo","fullname":"M. S. Lebo","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2095341679,"url":"researcher\/2095341679_S_Sutti","fullname":"S. Sutti","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2095302301,"url":"researcher\/2095302301_R_C_Green","fullname":"R. C. Green","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["Science translational medicine 01\/2016; 8(322):322fs3-323fs3. DOI:10.1126\/scitranslmed.aad9460"],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/291392678_Big_Data_Gets_Personal","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/291392678_Big_Data_Gets_Personal\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw19_56ab1eda73233"},"id":"rgw19_56ab1eda73233","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=291392678","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore","clickThrough":"experimentMilestoneClickedToPublicationFromReferenceWithNoFulltext","clickThroughWithContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":39839277,"url":"researcher\/39839277_Paul_J_Hauptman","fullname":"Paul J. Hauptman","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Jan 2016","journal":"Journal of cardiac failure","showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/291387589_Editor's_Page_Got_Big_Data","usePlainButton":true,"publicationUid":291387589,"feedStubs":null,"hasFeedStubs":false,"impactPoints":"3.05","url":"publication\/291387589_Editor%27s_Page_Got_Big_Data","title":"Editor's Page: Got Big Data?","displayTitleAsLink":true,"authors":[{"id":39839277,"url":"researcher\/39839277_Paul_J_Hauptman","fullname":"Paul J. Hauptman","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["Journal of cardiac failure 01\/2016;  DOI:10.1016\/j.cardfail.2016.01.010"],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/291387589_Editor's_Page_Got_Big_Data","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/291387589_Editor's_Page_Got_Big_Data\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw20_56ab1eda73233"},"id":"rgw20_56ab1eda73233","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=291387589","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"viewClass":"sidebar","widgetId":"rgw17_56ab1eda73233"},"id":"rgw17_56ab1eda73233","partials":[],"templateName":"publicliterature\/stubs\/SimilarPublications.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.SimilarPublications.html?referencePublicationId=257069490&view=sidebar","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationFulltextPreview":null,"publicationResourcesFulltext":{"data":{"publicationUid":257069490,"publicationResourceList":{"data":{"publicationResourceItems":[{"data":{"publicationUid":257069490,"publicationType":"article","linkId":"55adfd9508ae98e661a45327","fileName":"55adfd9508ae98e661a45327.pdf","fileUrl":"profile\/James_Hensman\/publication\/257069490_Gaussian_Processes_for_Big_Data\/links\/55adfd9508ae98e661a45327.pdf","name":"James Hensman","nameUrl":"profile\/James_Hensman","canRemove":false,"fileIcon":"ico-pub","canPreview":true,"hasPublisherLink":null,"hasMetaData":true,"hide":false,"fulltext":"ico-pub","origin":"publication_list","isLastLink":false,"isUserLink":true,"uploadDate":"Jul 21, 2015","fileSize":"1.4 MB","widgetId":"rgw23_56ab1eda73233"},"id":"rgw23_56ab1eda73233","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceItem.html","templateExtensions":["generalHelpers"],"attrs":{"fileRequiredPublicationTypes":["code","coverPage","experimentFindings","method","negativeResults","presentation","rawData","researchProposal","workingPaper","artifact","dataset"]},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceItem.html?publicationUid=257069490&linkId=55adfd9508ae98e661a45327&hide=0&disableJavascript=disableJavascript&useAlternativeTemplate=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"publicationUid":257069490,"publicationType":"article","linkId":"02f48cdd0cf21189773bf031","fileName":"Gaussian Processes for Big Data","fileUrl":"http:\/\/export.arxiv.org\/pdf\/1309.6835","name":"export.arxiv.org","nameUrl":"http:\/\/export.arxiv.org\/pdf\/1309.6835","canRemove":false,"fileIcon":"ico-pub","canPreview":true,"hasPublisherLink":null,"hasMetaData":true,"hide":false,"fulltext":"ico-pub","origin":"publication_list","isLastLink":false,"isUserLink":false,"widgetId":"rgw24_56ab1eda73233"},"id":"rgw24_56ab1eda73233","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceItem.html","templateExtensions":["generalHelpers"],"attrs":{"fileRequiredPublicationTypes":["code","coverPage","experimentFindings","method","negativeResults","presentation","rawData","researchProposal","workingPaper","artifact","dataset"]},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceItem.html?publicationUid=257069490&linkId=02f48cdd0cf21189773bf031&hide=0&disableJavascript=disableJavascript&useAlternativeTemplate=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"widgetId":"rgw22_56ab1eda73233"},"id":"rgw22_56ab1eda73233","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceList.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceList.html?publicationUid=257069490&limit=3&disableJavascript=disableJavascript&type=fulltextFile","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"resourceCount":2,"hidden":false,"showMore":false,"fulltext":true,"publicationDownloadCount":{"data":{"value":22,"valueFormatted":"22","widgetId":"rgw25_56ab1eda73233"},"id":"rgw25_56ab1eda73233","partials":[],"templateName":"publicliterature\/stubs\/PublicationDownloadCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDownloadCount.html?publicationUid=257069490","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw21_56ab1eda73233"},"id":"rgw21_56ab1eda73233","partials":[],"templateName":"publicliterature\/stubs\/PublicationResources.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResources.html?publicationUid=257069490&type=fulltextFile&disableJavascript=1","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationResourcesAttachments":{"data":{"publicationUid":257069490,"publicationResourceList":{"data":{"publicationResourceItems":[],"widgetId":"rgw27_56ab1eda73233"},"id":"rgw27_56ab1eda73233","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceList.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceList.html?publicationUid=257069490&limit=3&disableJavascript=disableJavascript&type=attachmentFile","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"resourceCount":0,"hidden":true,"showMore":false,"fulltext":false,"publicationDownloadCount":{"data":{"value":22,"valueFormatted":"22","widgetId":"rgw28_56ab1eda73233"},"id":"rgw28_56ab1eda73233","partials":[],"templateName":"publicliterature\/stubs\/PublicationDownloadCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDownloadCount.html?publicationUid=257069490","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw26_56ab1eda73233"},"id":"rgw26_56ab1eda73233","partials":[],"templateName":"publicliterature\/stubs\/PublicationResources.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResources.html?publicationUid=257069490&type=attachmentFile","viewClass":"views.publicliterature.PublicationResourcesView","yuiModules":["rg.views.publicliterature.PublicationResourcesView"],"stylesheets":[],"_isYUI":true},"publicationText":{"data":{"hide":false,"pages":[{"page":1,"text":"Gaussian Processes for Big Data\nJames Hensman\u2217\nDept. Computer Science\nThe University of Sheffield\nSheffield, UK\nNicol` o Fusi\u2217\nDept. Computer Science\nThe University of Sheffield\nSheffield, UK\nNeil D. Lawrence\u2217\nDept. Computer Science\nThe University of Sheffield\nSheffield, UK\nAbstract\nWe introduce stochastic variational inference\nfor Gaussian process models. This enables\nthe application of Gaussian process (GP)\nmodels to data sets containing millions of\ndata points. We show how GPs can be vari-\nationally decomposed to depend on a set\nof globally relevant inducing variables which\nfactorize the model in the necessary manner\nto perform variational inference.\nproach is readily extended to models with\nnon-Gaussian likelihoods and latent variable\nmodels based around Gaussian processes. We\ndemonstrate the approach on a simple toy\nproblem and two real world data sets.\nOur ap-\n1Introduction\nGaussian processes [GPs, Rasmussen and Williams,\n2006] are perhaps the dominant approach for inference\non functions. They underpin a range of algorithms\nfor regression, classification and unsupervised learn-\ning. Unfortunately, when applying a Gaussian process\nto a data set of size n exact inference has complexity\nO(n3) with storage demands of O(n2). This hinders\nthe application of these models for many domains. In\nparticular, large spatiotemporal data sets, video, large\nsocial network data (e.g. from Facebook), population\nscale medical data sets, models that correlate across\nmultiple outputs or tasks (for these models complex-\nity is O(n3p3) and storage is O(n2p2) where p is the\nnumber of outputs or tasks). Collectively we can think\nof these applications as belonging to the domain of \u2018big\ndata\u2019.\nTraditionally in Gaussian process a large data set is\none that contains over a few thousand data points.\n\u2217Also at Sheffield Institute for Translational Neuro-\nscience, SITraN\nEven to accommodate these data sets, various approx-\nimate techniques are required. One approach is to par-\ntition the data set into separate groups [e.g. Snelson\nand Ghahramani, 2007, Urtasun and Darrell, 2008].\nAn alternative is to build a low rank approximation\nto the covariance matrix based around \u2018inducing vari-\nables\u2019 [see e.g. Csat\u00b4 o and Opper, 2002, Seeger et al.,\n2003, Qui\u02dc nonero Candela and Rasmussen, 2005, Tit-\nsias, 2009]. These approaches lead to a computational\ncomplexity of O(nm2) and storage demands of O(nm)\nwhere m is a user selected parameter governing the\nnumber of inducing variables.\nreduced storage are prohibitive for big data, where\nn can be many millions or billions. For parametric\nmodels, stochastic gradient descent is often applied to\nresolve this storage issue, but in the GP domain, it\nhasn\u2019t been clear how this should be performed. In\nthis paper we show how recent advances in variational\ninference [Hensman et al., 2012, Hoffman et al., 2012]\ncan be combined with the idea of inducing variables\nto develop a practical algorithm for fitting GPs using\nstochastic variational inference (SVI).\nHowever, even these\n2Sparse GPs Revisited\nWe start with a succinct rederivation of the variational\napproach to inducing variables of Titsias [2009]. This\nallows us to introduce notation and derive expressions\nwhich allow for the formulation of a SVI algorithm.\nConsider a data vector1y, where each entry yi is a\nnoisy observation of the function f(xi), for all the\npoints X = {xi}n\ndependent Gaussian with precision \u03b2. Introducing a\nGaussian process prior over f(\u00b7), let the vector f con-\ntain values of the function at the points X. We shall\nalso introduce a set of inducing variables: let the vec-\ntor u contain values of the function f at the points\nZ = {zi}m\n1Our derivation trivially extends to multiple indepen-\ndent output dimensions, but we omit them here for clarity.\ni=1. We consider the noise to be in-\ni=1which live in the same space as X. Us-"},{"page":2,"text":"ing standard Gaussian process methodologies, we can\nwrite\np(y|f) =N?y|f,\u03b2\u22121I?,\np(f |u) =N\np(u) =N (u|0,Kmm),\nwhere Kmm is the covariance function evaluated be-\ntween all the inducing points and Knmis the covari-\nance function between all inducing points and train-\ning points and we have defined with?K = Knn\u2212\nWe first apply Jensen\u2019s inequality on the conditional\nprobability p(y|u):\nlogp(y|u) =log?p(y|f)?p(f |u)\n\u2265?logp(y|f)?p(f |u)? L1.\n?\nf|KnmK\u22121\nmmu,?K\n?\n,\nKnmK\u22121\nmmKmn.\n(1)\nwhere ?\u00b7?p(x)denotes an expectation under p(x). For\nGaussian noise taking the expectation inside the log\nis tractable, but it results in an expression containing\nK\u22121\nBringing the expectation outside the log gives a lower\nbound, L1, which can be computed with has complex-\nity O(m3). Further, when p(y|f) factorises across the\ndata,\nn\n?\nthen this lower bound can be shown to be separable\nacross y giving\nnn, which has a computational complexity of O(n3).\np(y|f) =\ni=1\np(yi|fi),\nexp(L1) =\nn\n?\ni=1\nN?yi|\u00b5i,\u03b2\u22121?exp\nmmu and\u02dcki,i is the ith diagonal\nelement of?K. Note that the difference between our\nKullback Leibler (KL) divergence between the poste-\nrior over the mapping function given the data and the\ninducing variables and the posterior of the mapping\nfunction given the inducing variables only,\n?\n\u22121\n2\u03b2\u02dcki,i\n?\n(2)\nwhere \u00b5 = KnmK\u22121\nbound and the original log likelihood is given by the\nKL(p(f|u)?p(f|u,y)).\nThis KL divergence is minimized when there are\nm = n inducing variables and they are placed at\nthe training data locations. This means that u = f,\nKmm=Knm=Knn meaning that?K=0. In this case\nequality because p(f|u) is degenerate. However, since\nm = n and that there would be no computational\nor storage advantage from the representation. When\nm < n the bound can be maximised with respect to\nZ (which are variational parameters). This minimises\nwe recover exp(L1) = p(y|f) and the bound becomes\nthe KL divergence and ensures that Z are distributed\namongst the training data X such that all\u02dcki,i are\nsmall. In practice this means that the expectations in\n(1) are only taken across a narrow domain (\u02dcki,iis the\nmarginal variance of p(fi|u)), keeping Jensen\u2019s bound\ntight.\nBefore deriving the expressions for stochastic varia-\ntional inference using L1, we recover the bound of Tit-\nsias [2009] by marginalising the inducing variables,\n?\n\u2265log\nwhich with some linear algebraic manipulation leads\nto\nL2= logN?y|0,KnmK\u22121\nmatching the result of Titsias, with the implicit ap-\nproximating distribution q(u) having precision\nlogp(y|X) =logp(y|u)p(u)du\n?\nexp{L1}p(u)du ? L2,(3)\nmmKmn+ \u03b2\u22121I?\u22121\n2\u03b2tr\n??K\n?\n,\n\u039b = \u03b2K\u22121\nmmKmnKnmK\u22121\nmm+ K\u22121\nmm\nand mean\n\u02c6 u = \u03b2\u039b\u22121K\u22121\nmmKmny.\n3 SVI for GPs\nOne of the novelties of the Titsias bound was that,\nrather than explicitly representing a variational distri-\nbution for q(u), these variables are \u2018collapsed\u2019 [Hens-\nman et al., 2012]. However, for stochastic variational\ninference to work on Gaussian processes, it turns out\nwe need to maintain an explicit representation of these\ninducing variables.\nStochastic variational inference (SVI) allows varia-\ntional inference for very large data sets, but it can\nonly be applied to probabilistic models which have a\nset of global variables, and which factorise in the ob-\nservations and latent variables as Figure 1(a). Gaus-\nsian Processes do not have global variables and exhibit\nno such factorisation (Figure 1(b)). By introducing\ninducing variables u, we have an appropriate model\nfor SVI (Figure 1(c)). Unfortunately, marginalising u\nre-introduces dependencies between the observations,\nand eliminates the global parameters. In the following,\nwe derive a lower bound on L2which includes an ex-\nplicit variational distribution q(u), enabling SVI. We\nthen derive the required natural gradients and discuss\nhow latent variables might be used.\nBecause there are a fixed number of inducing variables\n(specified by the user at algorithm design time) we\ncan perform stochastic variational inference, greatly\nincreasing the size of data sets to which we can apply\nGaussian processes."},{"page":3,"text":"(a) Requirements for SVI(b) Gaussian Process regression(c) Variational GP regression\nFigure 1: Graphical models showing (a) the reqired form for a probabilistic model for SVI (reproduced from\n[Hoffman et al., 2012]), with global variables g and latent variables z. (b) The graphical model corresponding to\nGaussian process regression, where connectivity between the values of the function fiis denoted by a loop around\nthe plate. (c) The graphical model corresponding to the sparse GP model, with inducing variables u working as\nglobal variables, and the term L1acting as logp(yi|u,xi). Marginalisation of u leads to the variational DTC\nformulation, introducing dependencies between the observations.\n3.1 Global Variables\nTo apply stochastic variational inference to a Gaussian\nprocess model, we must have a set of global variables.\nThe variables u will perform this role, and we intro-\nduce a variational distribution q(u), and use it to lower\nbound the quantity p(y|X).\nlogp(y|X) \u2265 ?L1+ logp(u) \u2212 logq(u)?q(u)? L3.\nFrom the above we know that the optimal distribu-\ntion is Gaussian, and we parametrise it as q(u) =\nN(u|m,S). The bound L3becomes\nn\n?\n\u22121\n\u2212 KL(q(u)?p(u))\nwith kibeing a vector of the ithcolumn of Kmnand\n\u039bi= \u03b2K\u22121\nspect to the parameters of q(u) are\nL3=\ni=1\n?\nlogN?yi|k?\n2\u03b2?ki,i\u22121\niK\u22121\nmmm,\u03b2\u22121?\n2tr(S\u039bi)\n?\n(4)\nmmkik?\niK\u22121\nmm. The gradients of L3with re-\n\u2202L3\n\u2202m= \u03b2K\u22121\n\u2202L3\n\u2202S\nmmKmny \u2212 \u039bm,\n2S\u22121\u22121\n=1\n2\u039b. (5)\nSetting the derivatives to zero recovers the optimal\nsolution found in the previous section, namely S=\u039b\u22121,\nm=\u02c6 u. It follows that L2\u2265 L3, with equality at this\nunique maximum.\nThe key propery of L3 is that is can be written as\na sum of n terms, each corresponding to one input-\noutput pair {xi,yi}: we have induced the necessary\nfactorisation to perform stochastic gradient methods\non the distribution q(u).\n3.2Natural Gradients\nStochastic variational inference works by taking steps\nin the direction of the approximate natural gradient\n? g(\u03b8), which is given by the usual gradient re-scaled\nTo work with the natural gradients of the distribution\nq(u), we first recall the canonical and expectation pa-\nrameters\n\u03b81=S\u22121m,\nby the inverse Fisher information: ? g(\u03b8)=G(\u03b8)\u22121 \u2202L\n\u2202\u03b8.\n\u03b82=\u22121\n2S\u22121\nand\n\u03b71=m,\u03b72=mm?+S.\nIn the exponential family, properties of the Fisher in-\nformation reveal the following simplification of the nat-\nural gradient [Hensman et al., 2012],\n? g(\u03b8) = G(\u03b8)\u22121\u2202L3\n\u2202\u03b8\n=\u2202L3\n\u2202\u03b7.(6)\nA step of length ? in the natural gradient direction,\nusing \u03b8(t+1)= \u03b8(t)+ ?dL3\nd\u03b7, yields\n\u03b82(t+1)= \u22121\n2S\u22121\n(t+1)\n= \u22121\n2S\u22121\n(t)+ ?\n?\n\u22121\n2\u039b +1\n2S\u22121\n(t)\n?\n,\n\u03b81(t+1)= S\u22121\n(t+1)m(t+1)\n= S\u22121\n(t)m(t)+ ?\n?\n\u03b2K\u22121\nmmKmny \u2212 S\u22121\n(t)m(t)\n?\n,\nand taking a step of unit length then recovers the same\nsolution as above by either (3) or (5). This confirms\nthe result discussed in Hensman et al. [2012], Hoffman\net al. [2012], that taking this unit step is the same as"},{"page":4,"text":"performing a VB update. We can now obtain stochas-\ntic approximations to the natural gradient by consid-\nering the data either individually or in mini-batches.\nWe note the convenient result that the natural gradi-\nent for \u03b82is positive definite (note \u039b = K\u22121\nThis means that taking a step in that direction always\nleads to a positive definite matrix, and our implemen-\ntation need not parameterise S in any way so as to\nensure positive-definiteness, cf. standard gradient ap-\nproaches on covariance matrices.\nmm+?\ni\u039bi).\nTo optimise the kernel hyper-parameters and noise\nprecision \u03b2, we take derivatives of the bound L3and\nperform standard stochastic gradient descent along-\nside the variational parameters. An illustration is pre-\nsented in Figure 2.\n3.3Latent Variables\nThe above derivations enable online learning for Gaus-\nsian process regression using SVI. Several GP based\nmodels involve inference of X, such as the GP latent\nvariable model [Lawrence, 2005, Titsias and Lawrence,\n2010] and its extensions [e.g. Damianou et al., 2011,\n2012].\nTo perform stochastic variational inference with latent\nvariables, we require a factorisation as illustrated by\nFigure 1(a): this factorisation is provided by (4). To\nget a model like the Bayesian GPLVM, we need a lower\nbound on logp(y). In Titsias and Lawrence [2010] this\nwas achieved through approximate marginalisation of\nL2, w.r.t. X, which leads to an expression depending\nonly on the parameters of q(X). However this formu-\nlation scales poorly, and the variables of the optimisa-\ntion are closely connected due to the marginalisation\nof u. The above enables a lower bound to which SVI\nis immediately applicable:\n?\n\u2265\nlogp(y) =log p(y|X)p(X)dX\nq(X)?L3+ logp(X) \u2212 logq(X)?dX.\nIt is straightforward to introduce p output dimensions\nfor the data Y, and following Titsias and Lawrence\n[2010], we use a factorising normal distribution q(X) =\n?n\nTo perform SVI in this model, we now alternate be-\ntween selecting a minibatch of data, and optimisting\nthe relevant variables of q(X) with q(u) fixed, and up-\ndating q(u) using the approximate natural gradient.\nWe note that the form of (4) means that each of the\nlatent variable distributions may be updated individ-\nually, enabling parallelisation across the minibatch.\n?\ni=1q(xi).\ntractable for various choices of covariance function.\nThe relevant expectations of L3 are\n3.4Non-Gaussian likelihoods\nAnother advantage of the factorisation of (4) is that\nit enables a simple routine for inference with non-\nGaussian likelihoods. The usual procedure for fitting\nGPs with non-Gaussian likelihoods is to approximate\nthe likelihood using either a local variational lower\nbound [Gibbs and MacKay, 2000], or by expectation\npropagation [Kuss and Rasmussen, 2005]. These ap-\nproximations to the likelihood are required because of\nthe connections between the variables f.\nIn L3, the bound factorises in such a way that some\nnon-Gaussian likelihoods may be marginalised exactly,\ngiven the existing approximations. To see this, con-\nsider that we are presented not with the vector y, but\nby a binary vector t with ti\u2208 {0,1}, and the likelihood\np(t|y) =?n\nusing p(t|X) \u2265?p(t|y)exp{L3}dy which involves n\ntorising nature of L3. For the probit likelihood each\nof these integrals is tractable.\ni=1\u03c3(yi)ti(1\u2212\u03c3(yi))(1\u2212ti), as in the case of\nclassification. We can bound the marginal likelihood\nindependent one dimensional integrals due to the fac-\nThis kind of approximation, where the likelihood is in-\ntegrated exactly is amenable to SVI in the same man-\nner as the regression case above through computation\nof the natural gradient.\n4Experiments\n4.1Toy Data\nTo demonstrate our algorithm we begin with two sim-\nple toy datasets based on sinusoidal functions. In the\nfirst experiment we show how the approximation con-\nverges towards the true solution as mini-batches are\nincluded. Figure 2 shows the nature of our approxi-\nmation: the variational approximation to the inducing\nfunction variables is shown.\nThe second toy problem (Figure 3) illustrates the con-\nvergence of the algorithm on a two dimensional prob-\nlem, again based on sinusoids. Here, we start with\na random initialisation for q(u), and the model con-\nverges after 2000 iterations. We found empirically that\nholding the covariance parameters fixed for the first\nepoch results in more reliable convergence, as can be\nseen in Figure 4\n4.2UK Apartment Price Data\nOur\nels\nUK.\ndata\n2012\nfirst\nthe\nWe\nfor\nlarge\nchanging\ndownloaded\nthe\nfrom\nscale\ncost\nGaussian\nof\nthe\nFebruary\nhttp:\/\/data.gov.uk\/dataset\/\nprocessmod-\nthe\npaid\napartments\nmonthly\nin\nprice\ntoperiodOctober"},{"page":5,"text":"Figure 2: Stochastic variational inference on a trivial GP regression problem. Each pane shows the posterior of\nthe GP after a batch of data, marked as solid points. Previoulsy seen (and discarded) data are marked as empty\npoints, the distribution q(u) is represented by vertical errorbars.\n(a) Initial condition(b) Condition at 2000 iterations\nFigure 3: A two dimensional toy demo, showing the initial condition and final condition of the model. Data are\nmarked as colored points, and the model\u2019s prediction is shown as (similarly colored) contour lines. The positions\nof the inducing variables are marked as empty circles."},{"page":6,"text":"Figure 4: Convergence of the SVIGP algorithm on the\ntwo dimensional toy data\nland-registry-monthly-price-paid-data\/, which\ncovers England and Wales, and filtered for apart-\nments. This resulted in a data set with 75,000 entries,\nwhich we cross referenced against a postcode database\nto get lattitude and longitude, on which we regressed\nthe normalised logarithm of the apartment prices.\nRandomly selecting 10,000 data as a test set, we build\na GP as described with a covariance function k(\u00b7,\u00b7)\nconsisting of four parts: two squared exponential co-\nvariances, initialised with different length scales were\nused to account for national and regional variations in\nproperty prices, a constant (or \u2019bias\u2019) term allowed for\nnon-zero mean data, and a noise variance accounted\nfor variation that could not be modelled using simply\nlatitude and longitude.\nWe selected 800 inducing input sites using a k-means\nalgorithm, and optimised the parameters of the co-\nvariance function alongside the variational parameters.\nWe performed some manual tuning of the learning\nrates: empirically we found that the step length should\nbe much higher for the variational parameters of q(u)\nthan for the values of the covariance function parame-\nters. We used 0.01 and 1 \u00d7 10\u22125. Also, we included a\nmomentum term for the covariance function parame-\nters (set to 0.9). We tried including momentum terms\nfor the variational parameters, but we found this hin-\ndered performance. A large mini-batch size (1000) re-\nduced the stochasticity of the gradient computations.\nWe judged that the algorithm had converged after 750\niterations, as the stochastic estimate of the marginal\nlower bound on the marginal likelihood failed to in-\ncrease further.\nFor comparison to our model, we constructed a se-\nries of GPs on subsets of the training data. Splitting\nthe data into sets of 500, 800, 1000 and 1200, we fit-\nFigure 5: Variability of apartment price (logarithmi-\ncally!) throughout England and Wales.\nted a GP with the same covariance function as our\nstochastic GP. Parameters of the covariance function\nwere optimised using type-II maximum likelihood for\neach batch. Table 1 reports the mean squared error in\nour model\u2019s prediction of the held out prices, as well\nas the same for the random sub-set approach (along\nwith two standard deviations of the inter-sub-set vari-\nability).\nTable 1: Mean squared errors in predicting the log-\napartment prices across England and Wales by latti-\ntude and longitude\nMean square Error\nSVIGP0.426\nRandom sub-set (N=500)\nRandom sub-set (N=800)\nRandom sub-set (N=1000)\nRandom sub-set (N=1200)\n0.522 +\/- 0.018\n0.510 +\/- 0.015\n0.503 +\/- 0.011\n0.502 +\/- 1.012\n4.3Airline Delays\nThe second large scale dataset we considered consists\nof flight arrival and departure times for every commer-\ncial flight in the USA from January 2008 to April 2008.\nThis dataset contains extensive information about al-\nmost 2 million flights, including the delay (in minutes)\nin reaching the destination. The average delay of a\nflight in the first 4 months of 2008 was of 30 minutes.\nOf course, much better estimates can be given by ex-\nploiting the enourmous wealth of data available, but\nrich models are often overlooked in these cases due"},{"page":7,"text":"Figure 6: Posterior variance of apartment prices.\nto the sheer size of the dataset. We randomly selected\n800,000 datapoints2, using a random subset of 700,000\nsamples to train the model and 100,000 to test it. We\nchose to include into our model 8 of the many variables\navailable for this dataset: the age of the aircraft (num-\nber of years since deployment), distance that needs to\nbe covered, airtime, departure time, arrival time, day\nof the week, day of the month and month.\nWe built a Gaussian process with a squared exponen-\ntial covariance function with a bias and noise term.\nIn order to discard irrelevant input dimensions, we al-\nlowed a separate lengthscale for each input. For our\nexperiments, we used m = 1000 inducing inputs and\na mini-batch size of 5000. The learning rate for the\nvariational parameters of q(u) was set to 0.01, while\nthe learning rate for the covariance function parame-\nters was set to 1 \u00d7 10\u22125. We also used a momentum\nterm of 0.9 for the covariance parameters.\nFor the purpose of comparison, we fitted several GPs\nwith an identical covariance function on subsets of the\ndata. We split the data into sets of 800, 1000 and 1200\nsamples and optimised the parameters using type-II\nmaximum likelihood. We repeated this procedure 10\ntimes.\nThe left pane of Figure 7 shows the root mean squared\nerror (RMSE) obtained by fitting GPs on subsets of\nthe data. The right pane of figure 7 shows the RMSE\nobtained by fitting 10 SVI GPs as a function of the\niteration. The individual runs are shown in light gray,\nwhile the blue line shows the average RMSE across\n2Subsampling wasn\u2019t technically necessary, but we\ndidn\u2019t want to overburden the memory of a shared compute\nnode just before a submission deadline.\nFigure 8: Root mean square errors for models with\ndifferent numbers of inducing variables.\nFigure 9: Automatic relevance determination param-\neters for the features used for predicting flight delays.\nruns.\nOne of the main advantages of the approach presented\nhere is that the computational complexity is indepen-\ndent from the number of samples n. This allowed us\nto use a much larger number of inducing inputs than\nhas traditionally been possible. Conventional sparse\nGPs have a computational complexity of O(nm2), so\nfor large n the typical upper bound for m is between 50\nand 100. The impact on the prediction performance is\nquite significant, as highlighted in Figure 8, where we\nfit several SVI GPs using different numbers of inducing\ninputs.\nLooking at the inverse lengthscales in Figure 9, it\u2019s\npossible to get a better idea of the relevance of the\ndifferent features available in this dataset. The most\nrelevant variable turned out to be the time of departure\nof the flight, closely followed by the distance that needs"},{"page":8,"text":"Figure 7: Root mean squared errors in predicting flight delays using information about the flight.\nto be covered. Distance and airtime should in theory\nbe correlated, but they have very different relevances.\nThis can be intuitively explained by considering that\non longer flights it\u2019s easier to make up for delays at\ndeparture.\n5Discussion\nWe have presented a method for inference in Gaussian\nprocess models using stochastic variational inference.\nThese expressions allow for the transfer of a multitude\nof Gaussian process techniques to big data.\nWe note several interesting results.\nderivation disusses the bound on p(y|u) in detail,\nshowing that it becomes tight when Z = X.\nFirst, the our\nAlso, we have that there is a unique solution for the pa-\nrameters of q(u) such that the bound associated with\nthe standard variational sparse GP [Titsias, 2009] is\nrecovered.\nFurther, since the complexity of our model is now\nO(m3) rather than O(nm2), we are free to increase\nm to much greater values than the sparse GP repre-\nsentation. The effect of this is that we can have much\nricher models: for a squared exponential covariance\nfunction, we have far more basis-functions with which\nto model the data. In our UK apartment price exam-\nple, we had no difficulty setting m to 800, much higher\nthan experience tells us is feasible with the sparse GP.\nThe ability to increase the number of inducing vari-\nables and the applicability to unlimited data make our\nmethod suitable for multiple output GPs [\u00b4Alvarez and\nLawrence, 2011]. We have also briefly discussed how\nthis framework fits with other Gaussian process based\nmodels such as the GPLVM and GP classification. We\nleave the details of these implementations to future\nwork.\nIn all our experiments our algorithm was run on a\nsingle CPU using the GPy Gaussian process toolkit\nhttps:\/\/github.com\/SheffieldML\/GPy.\nReferences\nMauricio A.\u00b4Alvarez and Neil D. Lawrence. Compu-\ntationally efficient convolved multiple output Gaus-\nsian processes. Journal of Machine Learning Re-\nsearch, 12:1425\u20131466, May 2011.\nLehel Csat\u00b4 o and Manfred Opper. Sparse on-line Gaus-\nsian processes. Neural Computation, 14(3):641\u2013668,\n2002.\nAndreas Damianou, Michalis K. Titsias, and Neil D.\nLawrence. Variational Gaussian process dynamical\nsystems. In Peter Bartlett, Fernando Peirrera, Chris\nWilliams, and John Lafferty, editors, Advances in\nNeural Information Processing Systems, volume 24,\nCambridge, MA, 2011. MIT Press.\nAndreas Damianou, Carl Henrik Ek, Michalis K. Tit-\nsias, and Neil D. Lawrence. Manifold relevance de-\ntermination. In John Langford and Joelle Pineau,\neditors, Proceedings of the International Conference\nin Machine Learning, volume 29, San Francisco, CA,\n2012. Morgan Kauffman. To appear.\nMark N. Gibbs and David J. C. MacKay. Variational\nGaussian process classifiers. IEEE Transactions on\nNeural Networks, 11(6):1458\u20131464, 2000.\nJames Hensman,Magnus Rattray,and Neil D."},{"page":9,"text":"Lawrence. Fast variational inference in the expo-\nnential family. NIPS 2012, 2012.\nMatthew Hoffman, David M. Blei, Chong Wang, and\nJohn Paisley. Stochastic variational inference. arXiv\npreprint arXiv:1206.7051, 2012.\nMalte Kuss and Carl Edward Rasmussen.\ning approximate inference for binary Gaussian pro-\ncess classification. Journal of Machine Learning Re-\nsearch, 6:1679\u20131704, 2005.\nAssess-\nNeil D. Lawrence. Probabilistic non-linear principal\ncomponent analysis with Gaussian process latent\nvariable models. Journal of Machine Learning Re-\nsearch, 6:1783\u20131816, 11 2005.\nJoaquin Qui\u02dc nonero Candela and Carl Edward Ras-\nmussen.A unifying view of sparse approximate\nGaussian process regression.\nLearning Research, 6:1939\u20131959, 2005.\nJournal of Machine\nCarl Edward Rasmussen and Christopher K. I.\nWilliams. Gaussian Processes for Machine Learn-\ning. MIT Press, Cambridge, MA, 2006. ISBN 0-\n262-18253-X.\nMatthias Seeger, Christopher K. I. Williams, and\nNeil D. Lawrence. Fast forward selection to speed\nup sparse Gaussian process regression. In Christo-\npher M. Bishop and Brendan J. Frey, editors, Pro-\nceedings of the Ninth International Workshop on Ar-\ntificial Intelligence and Statistics, Key West, FL, 3\u20136\nJan 2003.\nEdward Snelson and Zoubin Ghahramani. Local and\nglobal sparse Gaussian process approximations. In\nMarina Meila and Xiaotong Shen, editors, Proceed-\nings of the Eleventh International Workshop on Ar-\ntificial Intelligence and Statistics, San Juan, Puerto\nRico, 21-24 March 2007. Omnipress.\nMichalis K. Titsias. Variational learning of inducing\nvariables in sparse Gaussian processes.\nvan Dyk and Max Welling, editors, Proceedings of\nthe Twelfth International Workshop on Artificial In-\ntelligence and Statistics, volume 5, pages 567\u2013574,\nClearwater Beach, FL, 16-18 April 2009. JMLR\nW&CP 5.\nIn David\nMichalis K. Titsias and Neil D. Lawrence. Bayesian\nGaussian process latent variable model.\nYee Whye Teh and D. Michael Titterington, editors,\nProceedings of the Thirteenth International Work-\nshop on Artificial Intelligence and Statistics, vol-\nume 9, pages 844\u2013851, Chia Laguna Resort, Sar-\ndinia, Italy, 13-16 May 2010. JMLR W&CP 9.\nIn\nRaquel Urtasun and Trevor Darrell. Local probabilis-\ntic regression for activity-independent human pose\ninference. In Proceedings of the IEEE Computer So-\nciety Conference on Computer Vision and Pattern\nRecognition, Anchorage, Alaska, 2008."}],"fullTextUrl":"https:\/\/www.researchgate.net\/profile\/James_Hensman\/publication\/257069490_Gaussian_Processes_for_Big_Data\/links\/55adfd9508ae98e661a45327.pdf","widgetId":"rgw29_56ab1eda73233"},"id":"rgw29_56ab1eda73233","partials":[],"templateName":"publicliterature\/stubs\/PublicationText.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationText.html?publicationUid=257069490&hide=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationDetailAd":{"data":{"googleDfpSlot":null,"widgetId":"rgw30_56ab1eda73233"},"id":"rgw30_56ab1eda73233","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAd.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAd.html?publicationUid=257069490&slotId=336x280_Publications_ATF_Right&collapseSlotMode=never&fallbackContainerEnabled=1","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationRelations":null,"publicationRelationsReverse":null,"publicationUid":257069490,"showSignUpDialog":false,"selectNewSignUpDialog":false,"publicationQuestions":null,"publicationCitations":{"data":{"publicationUid":257069490,"publicationCitationsList":{"data":{"citationItems":[{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore","clickThrough":"experimentMilestoneClickedToPublicationFromCitationWithFulltext","clickThroughWithContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextSlurp","nextPublicationViewId":null,"authorsPartOne":[{"id":2068767308,"url":"researcher\/2068767308_Andrew_Gordon_Wilson","fullname":"Andrew Gordon Wilson","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2083724812,"url":"researcher\/2083724812_Christoph_Dann","fullname":"Christoph Dann","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":45244854,"url":"researcher\/45244854_Hannes_Nickisch","fullname":"Hannes Nickisch","last":true,"imageUrl":"https:\/\/i1.rgstatic.net\/ii\/profile.image\/AS%3A272392765309003%401441954904967_m\/Hannes_Nickisch.png"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":[["includes-citation-list"]],"isFulltext":true,"isSlurp":false,"isNoText":false,"publicationType":"Article","publicationDate":"Nov 2015","journal":null,"showEnrichedPublicationItem":false,"citationCount":1,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/283532531_Thoughts_on_Massively_Scalable_Gaussian_Processes","usePlainButton":true,"publicationUid":283532531,"feedStubs":null,"hasFeedStubs":false,"impactPoints":false,"url":"publication\/283532531_Thoughts_on_Massively_Scalable_Gaussian_Processes","title":"Thoughts on Massively Scalable Gaussian Processes","displayTitleAsLink":true,"authors":[{"id":2068767308,"url":"researcher\/2068767308_Andrew_Gordon_Wilson","fullname":"Andrew Gordon Wilson","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2083724812,"url":"researcher\/2083724812_Christoph_Dann","fullname":"Christoph Dann","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":45244854,"url":"researcher\/45244854_Hannes_Nickisch","fullname":"Hannes Nickisch","last":true,"imageUrl":"https:\/\/i1.rgstatic.net\/ii\/profile.image\/AS%3A272392765309003%401441954904967_m\/Hannes_Nickisch.png"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":[],"abstract":"We introduce a framework and early results for massively scalable Gaussian\nprocesses (MSGP), significantly extending the KISS-GP approach of Wilson and\nNickisch (2015). The MSGP framework enables the use of Gaussian processes (GPs)\non billions of datapoints, without requiring distributed inference, or severe\nassumptions. In particular, MSGP reduces the standard $O(n^3)$ complexity of GP\nlearning and inference to $O(n)$, and the standard $O(n^2)$ complexity per test\npoint prediction to $O(1)$. MSGP involves 1) decomposing covariance matrices as\nKronecker products of Toeplitz matrices approximated by circulant matrices.\nThis multi-level circulant approximation allows one to unify the orthogonal\ncomputational benefits of fast Kronecker and Toeplitz approaches, and is\nsignificantly faster than either approach in isolation; 2) local kernel\ninterpolation and inducing points to allow for arbitrarily located data inputs,\nand $O(1)$ test time predictions; 3) exploiting block-Toeplitz Toeplitz-block\nstructure (BTTB), which enables fast inference and learning when\nmultidimensional Kronecker structure is not present; and 4) projections of the\ninput space to flexibly model correlated inputs and high dimensional data. The\nability to handle many ($m \\approx n$) inducing points allows for near-exact\naccuracy and large scale kernel learning.","description":false,"swapJournalAndAuthorPositions":false,"showAbstract":true,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/283532531_Thoughts_on_Massively_Scalable_Gaussian_Processes","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":true,"actions":[{"type":"download","text":"Download","url":"profile\/Hannes_Nickisch\/publication\/283532531_Thoughts_on_Massively_Scalable_Gaussian_Processes\/links\/568a8a8008ae051f9afa595b.pdf?origin=publication_list","active":false,"primary":true,"extraClass":"open-viewer","icon":null,"data":[]}],"actionWidgets":[],"publicationItemFulltext":{"data":{"isDataset":false,"isResearch":false,"isFulltext":true,"source":{"isPreview":false,"sourceUrl":"profile\/Hannes_Nickisch","sourceName":"Hannes Nickisch","hasSourceUrl":true},"publicationUid":283532531,"publicationUrl":"publication\/283532531_Thoughts_on_Massively_Scalable_Gaussian_Processes","eventCode":"","citationCount":0,"additionalContentWidgets":[],"disableViewer":true,"showLoggedOutRequestButton":false,"context":null,"previewUrl":"https:\/\/i1.rgstatic.net\/publication\/283532531_Thoughts_on_Massively_Scalable_Gaussian_Processes\/links\/568a8a8008ae051f9afa595b\/smallpreview.png","linkId":"568a8a8008ae051f9afa595b","origin":"publication_list","showRequestCount":false,"publish":false,"request":false,"showAction":false,"displayAsLink":true,"documentViewerUrl":"publicliterature.PublicLiteratureDocumentViewer.html?publicationId=283532531&reference=568a8a8008ae051f9afa595b&eventCode=&origin=publication_list","widgetId":"rgw34_56ab1eda73233"},"id":"rgw34_56ab1eda73233","partials":[],"templateName":"publicliterature\/stubs\/PublicationItemFulltext.html","templateExtensions":["generalHelpers"],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItemFulltext.html?publicationUid=283532531&showAction=1&eventCode=&hideSource=0&displayAsLink=1&showPublishAsSelectFile=0","viewClass":"views.publicliterature.PublicationItemFulltextView","yuiModules":["rg.views.publicliterature.PublicationItemFulltextView"],"stylesheets":[],"_isYUI":true},"linkId":"568a8a8008ae051f9afa595b","context":null,"contextId":null,"eventCode":"","isCitation":true,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":257069490,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/283532531_Thoughts_on_Massively_Scalable_Gaussian_Processes\/review","additionalRightSideTopWidgets":[{"data":{"citationContexts":["Moreover, for computational tractability, these approaches require m n, which can severely affect predictive performance, limit representational power, and the ability for kernel learning, which is most needed on large datasets (Wilson , 2014). New directions for scalable Gaussian processes have involved mini-batches of data through stochastic variational inference (Hensman et al., 2013) and distributed learning (Deisenroth and Ng, 2015). While these approaches are promising, inference can undergo severe approximations, and a small number of inducing points are still required. "],"widgetId":"rgw35_56ab1eda73233"},"id":"rgw35_56ab1eda73233","partials":[],"templateName":"publicliterature\/stubs\/PublicationItemCitationContexts.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItemCitationContexts.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":true,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read full-text","widgetId":"rgw33_56ab1eda73233"},"id":"rgw33_56ab1eda73233","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":true,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItem.html?showEnrichedPublicationItem=0&showRequestButton=1&publicationUid=283532531&additionalCssClasses%5B0%5D=includes-citation-list&citationContextItemVersion=old&isIncomingCitation=1","viewClass":"views.publicliterature.PublicationItemView","yuiModules":["rg.views.publicliterature.PublicationItemView"],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore","clickThrough":"experimentMilestoneClickedToPublicationFromCitationWithSlurp","clickThroughWithContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextSlurp","nextPublicationViewId":null,"authorsPartOne":[{"id":2052101055,"url":"researcher\/2052101055_Thomas_Nickson","fullname":"Thomas Nickson","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2051950921,"url":"researcher\/2051950921_Tom_Gunter","fullname":"Tom Gunter","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2051935693,"url":"researcher\/2051935693_Chris_Lloyd","fullname":"Chris Lloyd","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":{"id":2051939493,"url":"researcher\/2051939493_Michael_A_Osborne","fullname":"Michael A Osborne","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},"surplusAuthors":1,"additionalCssClasses":[["includes-citation-list"]],"isFulltext":false,"isSlurp":true,"isNoText":false,"publicationType":"Article","publicationDate":"Oct 2015","journal":null,"showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/283335187_Blitzkriging_Kronecker-structured_Stochastic_Gaussian_Processes","usePlainButton":true,"publicationUid":283335187,"feedStubs":null,"hasFeedStubs":false,"impactPoints":false,"url":"publication\/283335187_Blitzkriging_Kronecker-structured_Stochastic_Gaussian_Processes","title":"Blitzkriging: Kronecker-structured Stochastic Gaussian Processes","displayTitleAsLink":true,"authors":[{"id":2052101055,"url":"researcher\/2052101055_Thomas_Nickson","fullname":"Thomas Nickson","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2051950921,"url":"researcher\/2051950921_Tom_Gunter","fullname":"Tom Gunter","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2051935693,"url":"researcher\/2051935693_Chris_Lloyd","fullname":"Chris Lloyd","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2051939493,"url":"researcher\/2051939493_Michael_A_Osborne","fullname":"Michael A Osborne","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2083725021,"url":"researcher\/2083725021_Stephen_Roberts","fullname":"Stephen Roberts","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":[],"abstract":"We present Blitzkriging, a new approach to fast inference for Gaussian\nprocesses, applicable to regression, optimisation and classification.\nState-of-the-art (stochastic) inference for Gaussian processes on very large\ndatasets scales cubically in the number of 'inducing inputs', variables\nintroduced to factorise the model. Blitzkriging shares state-of-the-art scaling\nwith data, but reduces the scaling in the number of inducing points to\napproximately linear. Further, in contrast to other methods, Blitzkriging: does\nnot force the data to conform to any particular structure (including\ngrid-like); reduces reliance on error-prone optimisation of inducing point\nlocations; and is able to learn rich (covariance) structure from the data. We\ndemonstrate the benefits of our approach on real data in regression,\ntime-series prediction and signal-interpolation experiments.","description":false,"swapJournalAndAuthorPositions":false,"showAbstract":true,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/283335187_Blitzkriging_Kronecker-structured_Stochastic_Gaussian_Processes","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":false,"actions":[{"type":"request-external","text":"Request full-text","url":"javascript:;","active":false,"primary":false,"extraClass":null,"icon":null,"data":[{"key":"context","value":"pubCit"}]}],"actionWidgets":[],"publicationItemFulltext":{"data":{"isDataset":false,"isResearch":false,"isFulltext":true,"source":{"isPreview":true,"sourceUrl":"deref\/http%3A%2F%2Fde.arxiv.org%2Fpdf%2F1510.07965","sourceName":"de.arxiv.org","hasSourceUrl":true},"publicationUid":283335187,"publicationUrl":"publication\/283335187_Blitzkriging_Kronecker-structured_Stochastic_Gaussian_Processes","eventCode":"","citationCount":0,"additionalContentWidgets":[],"disableViewer":true,"showLoggedOutRequestButton":false,"context":null,"previewUrl":"https:\/\/i1.rgstatic.net\/publication\/283335187_Blitzkriging_Kronecker-structured_Stochastic_Gaussian_Processes\/links\/563bf2b808ae405111a77d9e\/smallpreview.png","linkId":"563bf2b808ae405111a77d9e","origin":"publication_list","showRequestCount":false,"publish":false,"request":false,"showAction":false,"displayAsLink":true,"documentViewerUrl":"publicliterature.PublicLiteratureDocumentViewer.html?publicationId=283335187&reference=563bf2b808ae405111a77d9e&eventCode=&origin=publication_list","widgetId":"rgw37_56ab1eda73233"},"id":"rgw37_56ab1eda73233","partials":[],"templateName":"publicliterature\/stubs\/PublicationItemFulltext.html","templateExtensions":["generalHelpers"],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItemFulltext.html?publicationUid=283335187&showAction=1&eventCode=&hideSource=0&displayAsLink=1&showPublishAsSelectFile=0","viewClass":"views.publicliterature.PublicationItemFulltextView","yuiModules":["rg.views.publicliterature.PublicationItemFulltextView"],"stylesheets":[],"_isYUI":true},"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":true,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":257069490,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/283335187_Blitzkriging_Kronecker-structured_Stochastic_Gaussian_Processes\/review","additionalRightSideTopWidgets":[{"data":{"citationContexts":["Additionally, the likelihood can not be split up over the data, precluding the use of stochastic gradient methods that allow learning on large datasets, through cheap but noisy observations of the gradient of the objective function on minibatches (small subsets) of the full data. Both of these issues have been solved in Hensman et al. [6] with their stochastic variational GP (SVGP) and a generalisation to all inducing methods by Hoang et al. [7]. We concentrate on the SVGP here, for the ease of testing against the popular GPy library [1]. "],"widgetId":"rgw38_56ab1eda73233"},"id":"rgw38_56ab1eda73233","partials":[],"templateName":"publicliterature\/stubs\/PublicationItemCitationContexts.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItemCitationContexts.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":true,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw36_56ab1eda73233"},"id":"rgw36_56ab1eda73233","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":true,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItem.html?showEnrichedPublicationItem=0&showRequestButton=1&publicationUid=283335187&additionalCssClasses%5B0%5D=includes-citation-list&citationContextItemVersion=old&isIncomingCitation=1","viewClass":"views.publicliterature.PublicationItemView","yuiModules":["rg.views.publicliterature.PublicationItemView"],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore","clickThrough":"experimentMilestoneClickedToPublicationFromCitationWithFulltext","clickThroughWithContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":48088163,"url":"researcher\/48088163_Melih_Kandemir","fullname":"Melih Kandemir","last":true,"imageUrl":"https:\/\/i1.rgstatic.net\/ii\/profile.image\/AS%3A273686771007490%401442263419341_m"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":[["includes-citation-list"]],"isFulltext":true,"isSlurp":false,"isNoText":false,"publicationType":"Conference Paper","publicationDate":"Jul 2015","journal":null,"showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/282359718_Asymmetric_Transfer_Learning_with_Deep_Gaussian_Processes","usePlainButton":true,"publicationUid":282359718,"feedStubs":null,"hasFeedStubs":false,"impactPoints":false,"url":"publication\/282359718_Asymmetric_Transfer_Learning_with_Deep_Gaussian_Processes","title":"Asymmetric Transfer Learning with Deep Gaussian Processes","displayTitleAsLink":true,"authors":[{"id":48088163,"url":"researcher\/48088163_Melih_Kandemir","fullname":"Melih Kandemir","last":true,"imageUrl":"https:\/\/i1.rgstatic.net\/ii\/profile.image\/AS%3A273686771007490%401442263419341_m"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["International Conference on Machine Learning (ICML); 07\/2015"],"abstract":"We introduce a novel Gaussian process based Bayesian model for asymmetric transfer learning. We adopt a two-layer feed-forward deep Gaussian process as the task learner of source and target domains. The first layer projects the data onto a separate non-linear manifold for each task. We perform knowledge transfer by projecting the target data also onto the source domain and linearly combining its representations on the source and target domain manifolds. Our approach achieves the state-of-the-art in a benchmark real-world image categorization task, and improves on it in cross-tissue tumor detection from histopathology tissue slide images.","description":false,"swapJournalAndAuthorPositions":false,"showAbstract":true,"type":"Conference Paper","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/282359718_Asymmetric_Transfer_Learning_with_Deep_Gaussian_Processes","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":true,"actions":[{"type":"download","text":"Download","url":"profile\/Melih_Kandemir\/publication\/282359718_Asymmetric_Transfer_Learning_with_Deep_Gaussian_Processes\/links\/560e6b4108ae0fc513ed33be.pdf?origin=publication_list","active":false,"primary":true,"extraClass":"open-viewer","icon":null,"data":[]}],"actionWidgets":[],"publicationItemFulltext":{"data":{"isDataset":false,"isResearch":false,"isFulltext":true,"source":{"isPreview":false,"sourceUrl":"profile\/Melih_Kandemir","sourceName":"Melih Kandemir","hasSourceUrl":true},"publicationUid":282359718,"publicationUrl":"publication\/282359718_Asymmetric_Transfer_Learning_with_Deep_Gaussian_Processes","eventCode":"","citationCount":0,"additionalContentWidgets":[],"disableViewer":true,"showLoggedOutRequestButton":false,"context":null,"previewUrl":"https:\/\/i1.rgstatic.net\/publication\/282359718_Asymmetric_Transfer_Learning_with_Deep_Gaussian_Processes\/links\/560e6b4108ae0fc513ed33be\/smallpreview.png","linkId":"560e6b4108ae0fc513ed33be","origin":"publication_list","showRequestCount":false,"publish":false,"request":false,"showAction":false,"displayAsLink":true,"documentViewerUrl":"publicliterature.PublicLiteratureDocumentViewer.html?publicationId=282359718&reference=560e6b4108ae0fc513ed33be&eventCode=&origin=publication_list","widgetId":"rgw40_56ab1eda73233"},"id":"rgw40_56ab1eda73233","partials":[],"templateName":"publicliterature\/stubs\/PublicationItemFulltext.html","templateExtensions":["generalHelpers"],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItemFulltext.html?publicationUid=282359718&showAction=1&eventCode=&hideSource=0&displayAsLink=1&showPublishAsSelectFile=0","viewClass":"views.publicliterature.PublicationItemFulltextView","yuiModules":["rg.views.publicliterature.PublicationItemFulltextView"],"stylesheets":[],"_isYUI":true},"linkId":"560e6b4108ae0fc513ed33be","context":null,"contextId":null,"eventCode":"","isCitation":true,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":257069490,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/282359718_Asymmetric_Transfer_Learning_with_Deep_Gaussian_Processes\/review","additionalRightSideTopWidgets":[{"data":{"citationContexts":["tection application. For all sparse GP components, we use 10 inducing points that are initialized to cluster centroids found by k-means, as in Hensman et al. (2013). We set the inducing points of the first layer GPs to instances chosen from the training set at random, and learn them from data for the second layer GPs. "],"widgetId":"rgw41_56ab1eda73233"},"id":"rgw41_56ab1eda73233","partials":[],"templateName":"publicliterature\/stubs\/PublicationItemCitationContexts.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItemCitationContexts.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":true,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read full-text","widgetId":"rgw39_56ab1eda73233"},"id":"rgw39_56ab1eda73233","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":true,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItem.html?showEnrichedPublicationItem=0&showRequestButton=1&publicationUid=282359718&additionalCssClasses%5B0%5D=includes-citation-list&citationContextItemVersion=old&isIncomingCitation=1","viewClass":"views.publicliterature.PublicationItemView","yuiModules":["rg.views.publicliterature.PublicationItemView"],"stylesheets":[],"_isYUI":true}],"hasCitations":true,"isPublicationAuthor":false,"isPublicationVisitor":false,"publicationUid":257069490,"publicationLink":"publication\/257069490_Gaussian_Processes_for_Big_Data","hasShowMore":true,"newOffset":3,"pageSize":10,"widgetId":"rgw32_56ab1eda73233"},"id":"rgw32_56ab1eda73233","partials":[],"templateName":"publicliterature\/stubs\/PublicationIncomingCitationsList.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationIncomingCitationsList.html?publicationUid=257069490&citedInPage=1&swapJournalAndAuthorPositions=0&showAbstract=1&showType=1&showPublicationPreview=1&totalCount=31","viewClass":"views.publicliterature.PublicationIncomingCitationsListView","yuiModules":["rg.views.publicliterature.PublicationIncomingCitationsListView"],"stylesheets":[],"_isYUI":true},"hasCitations":false,"citationsCount":0,"hasIncomingCitations":true,"incomingCitationsCount":31,"showCitationsSorter":true,"showAbstract":true,"showType":true,"showPublicationPreview":true,"swapJournalAndAuthorPositions":false,"sort":"","sortOriginal":false,"citationList":"incoming","showsIncoming":true,"showSorting":false,"usePlainButton":null,"useEnrichedContext":null,"widgetId":"rgw31_56ab1eda73233"},"id":"rgw31_56ab1eda73233","partials":[],"templateName":"publicliterature\/stubs\/PublicationCitations.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationCitations.html?publicationUid=257069490&citationList=&citedInPage=1&sort=","viewClass":"views.publicliterature.PublicationCitationsView","yuiModules":["rg.views.publicliterature.PublicationCitationsView"],"stylesheets":[],"_isYUI":true},"publicationReviewPromo":null,"publicationUsedInReviews":null,"publicationPdfJsReader":{"data":{"isPreview":false,"licenseUrl":null,"licenseInfo":null,"defaultLinkData":{"linkId":"55adfd9508ae98e661a45327","name":"James Hensman","date":"Jul 21, 2015 ","nameLink":"profile\/James_Hensman","filename":"","downloadLink":"https:\/\/www.researchgate.net\/profile\/James_Hensman\/publication\/257069490_Gaussian_Processes_for_Big_Data\/links\/55adfd9508ae98e661a45327.pdf?inViewer=0&pdfJsDownload=0&origin=publication_detail","viewerUrl":"https:\/\/www.researchgate.net\/profile\/James_Hensman\/publication\/257069490_Gaussian_Processes_for_Big_Data\/links\/55adfd9508ae98e661a45327.pdf?inViewer=1&pdfJsDownload=1&origin=publication_detail","downloadHash":"eab331519759b2083ae0625339dc516d","showFileSizeNote":false,"fileSize":"1.4 MB","noFollow":false,"isDefault":true,"doi":null},"displayableLinks":[{"linkId":"55adfd9508ae98e661a45327","name":"James Hensman","date":"Jul 21, 2015 ","nameLink":"profile\/James_Hensman","filename":"","downloadLink":"https:\/\/www.researchgate.net\/profile\/James_Hensman\/publication\/257069490_Gaussian_Processes_for_Big_Data\/links\/55adfd9508ae98e661a45327.pdf?inViewer=0&pdfJsDownload=0&origin=publication_detail","viewerUrl":"https:\/\/www.researchgate.net\/profile\/James_Hensman\/publication\/257069490_Gaussian_Processes_for_Big_Data\/links\/55adfd9508ae98e661a45327.pdf?inViewer=1&pdfJsDownload=1&origin=publication_detail","downloadHash":"eab331519759b2083ae0625339dc516d","showFileSizeNote":false,"fileSize":"1.4 MB","noFollow":false,"isDefault":true,"doi":null}],"hasDisplayableLinks":false,"reader":{"data":{"pdfCommentsActive":false,"publicationType":"Article","onlyRenderFirstPage":false,"readMoreExperimentGoal":"goalPublicationPdfClicksReadMore","readMoreExperimentViewId":null,"comments":null,"figures":[{"props":{"position":"float","orientation":"portrait","coords":"pag:5:rect:75.60,298.88,486.00,32.76","ordinal":"2"},"assetId":"AS:297331485364225@1447900758443"}],"figureAssetIds":["AS:297331485364225@1447900758443"],"figureOverlayUrls":{"clickOnOverlay":"publication.PublicationFigures.html?_sg=TP4_Nsy_ZcL3APQ7Cbf3nX11iOY-QKGQy7cbqXDy9-zHXuujF_Ve_rmOTdsnyOFO5jPPEYV6-nruIHbNekUSKQ.J9nRieLS7qCrMPumj7WoIpYPlTkYJS2kA61JOASz7QppPlpgCt9yMWlYHRlfsRFWHWgwdk1jdEm6XUzEPm4Vuw","clickOnPill":"publication.PublicationFigures.html?_sg=MX_QCcZkzbz1PUNrv_kEtLykVn6i0y2tkzT0en3k2l_nVE1T_2QmFHObZG1DRsUMFdO33ruf94tO8VivqsZRnA.9v2ZQie9pASgRf1taKjiFqdwZorRjPH-a8IoCqDZPUZIcYRpyNCDm80WHjvLXJmYiyuSz089bq_KWWRo9MZW5A"},"canSelect":false,"javascriptPath":"https:\/\/www.researchgate.net\/c\/o1o9o3\/","downloadUrl":"https%3A%2F%2Fwww.researchgate.net%2Fprofile%2FJames_Hensman%2Fpublication%2F257069490_Gaussian_Processes_for_Big_Data%2Flinks%2F55adfd9508ae98e661a45327.pdf%3FinViewer%3D1%26pdfJsDownload%3D1%26origin%3Dpublication_detail","viewerUrl":"https:\/\/www.researchgate.net\/c\/o1o9o3\/javascript\/lib\/pdfjs\/web\/viewer.html","commentEndpoint":"https:\/\/www.researchgate.net\/rgformat\/api\/comment","experimentEndpoint":"https:\/\/www.researchgate.net\/rgformat\/api\/experiment?key=IRsY_s0ZvpZL_jGHBjGRyfJcW1p6B3XvD049cQWp5SuDhPSP8uIPmh6QWJsdpamILOtWgpd3y5bXPCswOIduBQ","urlHash":"3412b7fbb6f574665590f43bf6a6049a","downloadTrackUrl":"application.PdfJsReader.ajaxTrackDownload.html?msrp=g4MsuFtR5tFtE-LMZ7HQwBa-jr4IJtC8acmfwvSlQLLXaab9XB30fSlrJhxjfOrKUOsECy_tjVjLb1KCLmZXFvtT_PwbFg-HNsDVIhySiSc.hWpow0hMq0h-konmRom0vusFJ19gQ3sQlEjlE0YT-SvXKh2ZDU3oNaFTUAM0rVBb2t9f9zRSiBr0mWINe-GYVg.sSax8qIuxujRdQL-B-0cOWk0ZedxYE667lxQpA5rNWe6O556pLOwqVZgn6kUzujiU2ODg5C5jML_k5-LSbgTvQ","viewportMilestoneTrackUrl":"application.PdfJsReader.ajaxTrackViewportMilestone.html","linkId":"55adfd9508ae98e661a45327","trackedDownloads":{"55adfd9508ae98e661a45327":{"v":false,"d":false}},"assetId":"AS:253564958277633@1437466005644","readerDocId":"5421520","assetType":"fulltext","interactionType":{"comment":"comment","highlight":"highlight"},"publicationUid":257069490,"commentCursorPromo":null,"widgetId":"rgw43_56ab1eda73233"},"id":"rgw43_56ab1eda73233","partials":[],"templateName":"application\/stubs\/PdfJsReader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PdfJsReader.html?fileHref=https%3A%2F%2Fwww.researchgate.net%2Fprofile%2FJames_Hensman%2Fpublication%2F257069490_Gaussian_Processes_for_Big_Data%2Flinks%2F55adfd9508ae98e661a45327.pdf%3FinViewer%3D1%26pdfJsDownload%3D1%26origin%3Dpublication_detail&assetId=AS%3A253564958277633%401437466005644&publicationUid=257069490&linkId=55adfd9508ae98e661a45327&onlyShowFirstPage=0","viewClass":null,"yuiModules":["css-pow-application-PdfJsReader"],"stylesheets":["pow\/application\/PdfJsReader.css"],"_isYUI":true},"showHeader":true,"title":"Gaussian Processes for Big Data","publicationType":"Article","downloadTrackUrl":"publicliterature.PublicationInlineReader.ajaxTrackDownload.html?msrp=vT8c6YCxqIrcJw1OqtjrrcM3ANyu6zstjRl8zeVLJk0AWb4MBmsxAIWy5Tk5lbvjMupuslNPJKStE1mVMqCe6zy1bzRt5OQM_OZnmDLkPw8.t2s7Cm6PeIp9SWYLIygWs3RaBsV4fxS2C42_l-AxsPerd9iwHOwngvtmi_9PGjXWpvbGe4iwQTbuB2bGHhEIDQ.1tqdIh1eBjPcVIlRd2JEKD63bazEEuFvHyHCE1bxgM6TpuVVQFG4XKiNXJk5HoIdo94FrE7Q-bOKpHnP5AO0IQ","publicationUid":257069490,"trackedDownloads":{"55adfd9508ae98e661a45327":{"v":false,"d":false}},"inlinePdf":false,"publicationComments":null,"showDownloadButton":true,"socialShare":{"data":{"shareItems":[{"data":{"name":"Facebook","url":"http:\/\/www.facebook.com\/share.php?u={{url}}{{#title}}&t={{title}}{{\/title}}","width":600,"height":350,"useUtmTags":true,"utmSource":"facebook","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareFacebook.ajaxTrackSocialShare.html","widgetId":"rgw45_56ab1eda73233"},"id":"rgw45_56ab1eda73233","partials":{"shareIcon":"application\/stubs\/partials\/shareFacebookBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareFacebook.html?provider=Facebook&shareIcon=shareIconBlog&utmSource=facebook&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"Twitter","url":"http:\/\/twitter.com\/intent\/tweet?text={{#title}}{{title}}: {{\/title}}{{url}}&via=researchgate","width":600,"height":350,"useUtmTags":true,"utmSource":"twitter","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareTwitter.ajaxTrackSocialShare.html","widgetId":"rgw46_56ab1eda73233"},"id":"rgw46_56ab1eda73233","partials":{"shareIcon":"application\/stubs\/partials\/shareTwitterBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareTwitter.html?provider=Twitter&shareIcon=shareIconBlog&utmSource=twitter&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"Google+","url":"https:\/\/plus.google.com\/share?url={{url}}","width":600,"height":600,"useUtmTags":true,"utmSource":"googleplus","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareGooglePlus.ajaxTrackSocialShare.html","widgetId":"rgw47_56ab1eda73233"},"id":"rgw47_56ab1eda73233","partials":{"shareIcon":"application\/stubs\/partials\/shareGooglePlusBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareGooglePlus.html?provider=Google%2B&shareIcon=shareIconBlog&utmSource=googleplus&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"LinkedIn","url":"http:\/\/www.linkedin.com\/shareArticle?mini=true&url={{url}}{{#title}}&title={{title}}{{\/title}}&source=ResearchGate","width":520,"height":570,"useUtmTags":true,"utmSource":"linkedin","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareLinkedIn.ajaxTrackSocialShare.html","widgetId":"rgw48_56ab1eda73233"},"id":"rgw48_56ab1eda73233","partials":{"shareIcon":"application\/stubs\/partials\/shareLinkedInBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareLinkedIn.html?provider=LinkedIn&shareIcon=shareIconBlog&utmSource=linkedin&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"Reddit","url":"https:\/\/www.reddit.com\/submit?url={{url}}{{#title}}&title={{title}}{{\/title}}","width":600,"height":600,"useUtmTags":true,"utmSource":"reddit","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareReddit.ajaxTrackSocialShare.html","widgetId":"rgw49_56ab1eda73233"},"id":"rgw49_56ab1eda73233","partials":{"shareIcon":"application\/stubs\/partials\/shareRedditBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareReddit.html?provider=Reddit&shareIcon=shareIconBlog&utmSource=reddit&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true}],"widgetId":"rgw44_56ab1eda73233"},"id":"rgw44_56ab1eda73233","partials":[],"templateName":"application\/stubs\/SocialShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.SocialShare.html?campaign=shareFullTextPublication&trackClick=1&shareIcon=shareIconBlog","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw42_56ab1eda73233"},"id":"rgw42_56ab1eda73233","partials":[],"templateName":"publicliterature\/stubs\/PublicationInlineReader.html","templateExtensions":["generalHelpers"],"attrs":{"showFulltextDownloadedSignupDialog":true,"preSignUpDialogContext":null,"requestFulltext":false},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationInlineReader.html","viewClass":"views.publicliterature.PublicationInlineReaderView","yuiModules":["rg.views.publicliterature.PublicationInlineReaderView","css-pow-publicliterature-PublicationInlineReader"],"stylesheets":["pow\/publicliterature\/PublicationInlineReader.css"],"_isYUI":true},"useFulltextOptimizedLayout":false,"publicationActions":null,"requestFulltextPromo":null,"currentUrl":"publication\/257069490_Gaussian_Processes_for_Big_Data","isLeaderboardAd":false,"enableStickyBox":null,"googleDfpSlotMobileBottom":null,"fullTextExitPopup":null,"showExitPopupDialog":false,"widgetId":"rgw2_56ab1eda73233"},"id":"rgw2_56ab1eda73233","partials":{"romeo_legal_notice":"publicliterature\/stubs\/partials\/romeo_legal_notice.html"},"templateName":"publicliterature\/stubs\/PublicPublicationDetails_NewLayout.html","templateExtensions":["generalHelpers"],"attrs":{"publicationUid":257069490},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicPublicationDetailsOld.html?publicationUid=257069490&isTestOldDesign=0","viewClass":"views.publicliterature.PublicPublicationDetailsOldView","yuiModules":["rg.views.publicliterature.PublicPublicationDetailsOldView"],"stylesheets":[],"_isYUI":true},"widgetId":"rgw1_56ab1eda73233"},"id":"rgw1_56ab1eda73233","partials":[],"templateName":"publicliterature\/stubs\/PublicPublicationDetails.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicPublicationDetails.html","viewClass":"views.publicliterature.PublicPublicationDetailsView","yuiModules":["rg.views.publicliterature.PublicPublicationDetailsView"],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"uaClass":"","headPrefix":[],"rootUrl":"https:\/\/www.researchgate.net\/","requestToken":"bacnBvQAUwFdJTpzUsRxU7yDNoP8yxs4g82MOk\/4sGeaG3wKGVObHHN1R\/wy19Ad5N6SqzIiVzdF+46ofc\/xwBTTe7g3antp8zY3Qr90YZGsAAfK2tfA9XLHwCUwMIlKf6yhemesPWYJO0QFcjJYWlpd39np\/chB2\/Qjskq\/aNbTL6nh9LMcs+ItyEcAWZ4fqL2c3ztFXTSoR1K6xPApauIlr0A0PT\/gHyERICoJQwng7hkSqYGhHMf12xPdYyagkKBn57EHF9A9fHxnl612ITyrTCDL04SoiARvzOKFWCc=","faviconCdnUrl":"https:\/\/c5.rgstatic.net\/m\/2390829798215018\/images\/favicon.ico","headerOutput":"<noscript><\/noscript><link rel=\"canonical\" href=\"https:\/\/www.researchgate.net\/publication\/257069490_Gaussian_Processes_for_Big_Data\" \/>\n<link rel=\"dns-prefetch\" href=\"\/\/c5.rgstatic.net\" \/>\n<link rel=\"dns-prefetch\" href=\"\/\/i1.rgstatic.net\" \/>\n<meta property=\"twitter:card\" content=\"summary\" \/>\n<meta property=\"twitter:site\" content=\"@ResearchGate\" \/>\n<meta property=\"og:title\" content=\"Gaussian Processes for Big Data\" \/>\n<meta property=\"og:description\" content=\"We introduce stochastic variational inference for Gaussian process models.\nThis enables the application of Gaussian process (GP) models to data sets\ncontaining millions of data points. We show how...\" \/>\n<meta property=\"og:site_name\" content=\"ResearchGate\" \/>\n<meta property=\"og:image\" content=\"https:\/\/i1.rgstatic.net\/publication\/257069490_Gaussian_Processes_for_Big_Data\/links\/55adfd9508ae98e661a45327\/smallpreview.png\" \/>\n<meta property=\"og:url\" content=\"https:\/\/www.researchgate.net\/publication\/257069490_Gaussian_Processes_for_Big_Data\" \/>\n<meta property=\"rg:id\" content=\"PB:257069490\" \/>\n<meta name=\"DC.identifier\" scheme=\"DCTERMS.URI\" content=\"http:\/\/dx.doi.org\/\" \/>\n<meta name=\"gs_meta_revision\" content=\"1.1\" \/>\n<meta name=\"citation_title\" content=\"Gaussian Processes for Big Data\" \/>\n<meta name=\"citation_author\" content=\"James Hensman\" \/>\n<meta name=\"citation_author\" content=\"Nicolo Fusi\" \/>\n<meta name=\"citation_author\" content=\"Neil D. Lawrence\" \/>\n<meta name=\"citation_publication_date\" content=\"2013\/09\/26\" \/>\n<meta name=\"citation_pdf_url\" content=\"https:\/\/www.researchgate.net\/profile\/James_Hensman\/publication\/257069490_Gaussian_Processes_for_Big_Data\/links\/55adfd9508ae98e661a45327.pdf\" \/>\n<meta name=\"citation_abstract_html_url\" content=\"https:\/\/www.researchgate.net\/publication\/257069490_Gaussian_Processes_for_Big_Data\" \/>\n<meta name=\"citation_fulltext_html_url\" content=\"https:\/\/www.researchgate.net\/publication\/257069490_Gaussian_Processes_for_Big_Data\" \/>\n<meta name=\"viewport\" content=\"width=device-width,initial-scale=1\" \/>\n<link href=\"\/\/c5.rgstatic.net\/m\/22664197317151888\/styles\/rg.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/21004998181197492\/styles\/rg2.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<!--[if lt IE 9]><link href=\"\/\/c5.rgstatic.net\/m\/238176252723686\/styles\/ie.css\" type=\"text\/css\" rel=\"stylesheet\"\/><![endif]-->\n<link href=\"\/\/c5.rgstatic.net\/m\/217752362214895\/styles\/modules\/publicprofile.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/215868066921738\/styles\/pow\/publicliterature\/FigureList.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/21993347442549\/styles\/pow\/publicliterature\/FollowPublicationPromo.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/282514599719602\/styles\/pow\/application\/PdfJsReader.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/23819663151220\/styles\/pow\/publicliterature\/PublicationInlineReader.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<script src=\"\/\/c5.rgstatic.net\/m\/2321000301012716\/javascript\/vendor\/webfontloader\/webfontloader.js\" type=\"text\/javascript\"><\/script>\n <script>(function(i,s,o,g,r,a,m){i[\"GoogleAnalyticsObject\"]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,\"script\",\"\/\/www.google-analytics.com\/analytics.js\",\"ga\");\n ga(\"create\",\"UA-58591210-1\");ga(\"set\",\"anonymizeIp\",true);ga('set', 'dimension1', 'publication full-text');ga('set', 'dimension2', 'Article');ga('set', 'dimension3', 'Logged out');ga('set', 'dimension4', 'https');ga(\"send\",\"pageview\");<\/script>\n","webfont":"<noscript><\/noscript><script> WebFontConfig = { custom: { families: ['source_sans_pro_italic', 'source_sans_pro_bold', 'source_sans_pro', 'martel'], urls : ['\/\/c5.rgstatic.net\/m\/231392577336386\/styles\/fonts.css'] } }; WebFont.load(WebFontConfig); <\/script>\n","correlationId":"rgreq-1a48599c-f4de-4a1e-b613-0499675d44cb","accountId":null,"module":"publicliterature","action":"publicliterature.PublicPublicationDetails","page":"publicationDetail","product":"publications","backendTime":488,"continent":"Asia","stylesHome":"\/\/c5.rgstatic.net\/m\/","staticHost":"c5.rgstatic.net","useEarlyFlush":false,"longRunningRequestIdentifier":"LongRunningRequest.publicliterature.PublicPublicationDetails","longRunningRequestFp":"e9e5bbe1366c7ee8c8e41d02f793c884ac9be19b","widgetId":"rgw50_56ab1eda73233"},"id":"rgw50_56ab1eda73233","partials":[],"templateName":"application\/stubs\/StaticHeader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.StaticHeader.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){
            Y.rg.core.pagespeed.Monitoring.monitorPage("\/\/glassmoni.researchgate.net", "publicliterature.PublicPublicationDetails.run.html.loggedOut.get", "59de9668d07aeb77ab4de5f24d382b5d199d2437", "rgreq-1a48599c-f4de-4a1e-b613-0499675d44cb", "9ddbc14eec19cb29c87efd1931fb8021027c8f9f");
        
            Y.rg.core.pagespeed.Monitoring.monitorPage("\/\/glassmoni.researchgate.net", "publicationDetail.loggedOut", "ed1993d9e20f6cefa83edacaa24401a18c071aea", "rgreq-1a48599c-f4de-4a1e-b613-0499675d44cb", "9ddbc14eec19cb29c87efd1931fb8021027c8f9f");
        })();
(function(){Y.rg.createInitialWidget({"data":{"year":"2016","inlinePromo":null,"isAdmin":false,"contactUrl":"https:\/\/www.researchgate.net\/contact","aboutUsUrl":"https:\/\/www.researchgate.net\/about","widgetId":"rgw51_56ab1eda73233"},"id":"rgw51_56ab1eda73233","partials":[],"templateName":"application\/stubs\/DefaultFooter.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.DefaultFooter.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"headerLogin":{"data":{"urlAfterLogin":"publication\/257069490_Gaussian_Processes_for_Big_Data","requestToken":"KCsshlO+3iy46Cxk5s0\/rFnr5+eYKmRipmaVii4SvKHjnLPmF7t8TtIpPj5ZPCF2kioscIPmdrCFD4EepCO1sXSy8UYP2kVcid+a94UZApb7gGY21h6oyYCxAJoD0oQdPI\/PZumJ4k9g\/7REq53X4tu30N3Zq3y8aA9lfYy1isXsUg4Zw3r+WItxE0ODpBYGS3iDEPdhoAvEeJgq6QzLnJPvApBKpFmqUoM+Fl4IGjNBOCOlnnBND35kMdnOdE9Ncoe2iSLGCcmYabzb3cy1BiZ+NHaxR\/LgZFmSJa6J9OQ=","loginUrl":"https:\/\/www.researchgate.net\/application.Login.html","signupUrl":"https:\/\/www.researchgate.net\/signup.SignUp.html?ev=su_chnl_index&hdrsu=1&_sg=22S8LgvPRiI2HL3TdVY-6Q8Becb4YUrVo7DYbfXyR3c1pnK929k6Zgwwh9iNO93P","encodedUrlAfterLogin":"cHVibGljYXRpb24vMjU3MDY5NDkwX0dhdXNzaWFuX1Byb2Nlc3Nlc19mb3JfQmlnX0RhdGE%3D","signupCallToAction":"Join for free","widgetId":"rgw53_56ab1eda73233"},"id":"rgw53_56ab1eda73233","partials":{"partial":"application\/stubs\/partials\/headerLoginDefault.html"},"templateName":"application\/stubs\/HeaderLogin.html","templateExtensions":[],"attrs":{"goal":"milestoneHeaderLoginSeen"},"widgetUrl":"https:\/\/www.researchgate.net\/application.HeaderLogin.html","viewClass":"views.application.HeaderLoginView","yuiModules":["rg.views.application.HeaderLoginView"],"stylesheets":[],"_isYUI":true},"cookieConsent":null,"logoSvgSrc":"https:\/\/c5.rgstatic.net\/m\/235107188705592\/images\/template\/brand-header-logo.svg","logoFallbackSrc":"https:\/\/c5.rgstatic.net\/m\/238113351022438\/images\/template\/brand-header-logo.png","widgetId":"rgw52_56ab1eda73233"},"id":"rgw52_56ab1eda73233","partials":{"schemaSocialProfiles":"application\/stubs\/partials\/schemaSocialProfiles.html"},"templateName":"application\/stubs\/HeaderLoggedOut.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.HeaderLoggedOut.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"logEvent":"su_banner","specialCopy":false,"widgetId":"rgw54_56ab1eda73233"},"id":"rgw54_56ab1eda73233","partials":[],"templateName":"application\/stubs\/LoggedOutBanner.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.LoggedOutBanner.html","viewClass":"views.application.LoggedOutBannerView","yuiModules":["rg.views.application.LoggedOutBannerView"],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.core.util.ParameterFilter.filter(["ev","cp","ch","ref","dbw","pli","loginT","uid","claimChannel","enrichId","enrichSource","utm_source","utm_medium","utm_campaign","el","ci"]);})();
});}); } else { throw 'YRG was not loaded when attaching widgets'; }</script><script> dataLayer = [{"pageCategory":"publication full-text","publicationType":"Article","eventCategory":"Publication page"}]; </script> <noscript><iframe src="//www.googletagmanager.com/ns.html?id=GTM-MKVKH7" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-MKVKH7');</script><script>(function(e){function n(n,t,o,a){"use strict";var i=e.document.createElement("link"),r=t||e.document.getElementsByTagName("script")[0],d=e.document.styleSheets;return i.rel="stylesheet",i.href=n,i.media="only x",a&&(i.onload=a),r.parentNode.insertBefore(i,r),i.onloadcssdefined=function(e){for(var t,o=0;d.length>o;o++)d[o].href&&d[o].href.indexOf(n)>-1&&(t=!0);t?e():setTimeout(function(){i.onloadcssdefined(e)})},i.onloadcssdefined(function(){i.media=o||"all"}),i}function t(e,n){e.onload=function(){e.onload=null,n&&n.call(e)},"isApplicationInstalled"in navigator&&"onloadcssdefined"in e&&e.onloadcssdefined(n)}var o=function(a,i){"use strict";if(a&&3===a.length){var r=e.Image,d=!(!document.createElementNS||!document.createElementNS("http://www.w3.org/2000/svg","svg").createSVGRect||!document.implementation.hasFeature("http://www.w3.org/TR/SVG11/feature#Image","1.1")||e.opera&&-1===navigator.userAgent.indexOf("Chrome")||-1!==navigator.userAgent.indexOf("Series40")),c=new r;c.onerror=function(){o.method="png",o.href=a[2],n(a[2])},c.onload=function(){var e=1===c.width&&1===c.height,r=a[e&&d?0:e?1:2];o.method=e&&d?"svg":e?"datapng":"png",o.href=r,t(n(r),i)},c.src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///ywAAAAAAQABAAACAUwAOw==",document.documentElement.className+=" grunticon"}};o.loadCSS=n,o.onloadCSS=t,e.grunticon=o})(this);grunticon(["https://c5.rgstatic.net/c/o1o9o3/styles/icons/_header-ico.svg.css", "https://c5.rgstatic.net/c/o1o9o3/styles/icons/_header-ico.png.css", "https://c5.rgstatic.net/c/o1o9o3/styles/icons/_header-ico.fallback.scss"]);grunticon(["https://c5.rgstatic.net/c/o1o9o3/styles/icons/_admin-ico.svg.css", "https://c5.rgstatic.net/c/o1o9o3/styles/icons/_admin-ico.png.css", "https://c5.rgstatic.net/c/o1o9o3/styles/icons/_admin-ico.fallback.scss"]);grunticon(["https://c5.rgstatic.net/c/o1o9o3/styles/icons/_ico.svg.css", "https://c5.rgstatic.net/c/o1o9o3/styles/icons/_ico.png.css", "https://c5.rgstatic.net/c/o1o9o3/styles/icons/_ico.fallback.scss"]);</script></body>
</html>
