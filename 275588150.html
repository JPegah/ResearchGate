<!DOCTYPE html> <html lang="en" class="" id="rgw44_56ab1e25595c3"> <head > <meta charset="utf-8"/> <meta http-equiv="content-type" content="text/html; charset=UTF-8"/> <meta name="Rg-Request-Token" id="Rg-Request-Token" content="sx9m+uy+AIyRjtcr4Fk0aQqQDXhPO9G0CMqS+n3q8rh9labpV/k+iRDU0hlrnHNZuRKWlekqHcRljZePEdPfprmyeyF3ZPWdiAY+QWb6Ice/HFc9IU/zRC0kYH0Zrpu9o7e/s3aUoyDy2HIrJYw/Xkh4fgc2XCcTDGYgLRinRYt64xbc0+dO5qBdvvMjA2h+C7YNYV2vtlRobE4Usy/YKhzMyxLly/nJaBhZqPtQiZMiCAtptp4IcPf/J0CitaMOMT1FDHaur8tkDU1gPiITF9Lkjng68P/GssPOcvbl7LM="/> <meta http-equiv="expires" content="0"/> <link rel="apple-touch-icon" sizes="57x57" href="https://www.researchgate.net/apple-touch-icon-57x57.png"> <link rel="apple-touch-icon" sizes="60x60" href="https://www.researchgate.net/apple-touch-icon-60x60.png"> <link rel="apple-touch-icon" sizes="72x72" href="https://www.researchgate.net/apple-touch-icon-72x72.png"> <link rel="apple-touch-icon" sizes="76x76" href="https://www.researchgate.net/apple-touch-icon-76x76.png"> <link rel="apple-touch-icon" sizes="114x114" href="https://www.researchgate.net/apple-touch-icon-114x114.png"> <link rel="apple-touch-icon" sizes="120x120" href="https://www.researchgate.net/apple-touch-icon-120x120.png"> <link rel="apple-touch-icon" sizes="144x144" href="https://www.researchgate.net/apple-touch-icon-144x144.png"> <link rel="apple-touch-icon" sizes="152x152" href="https://www.researchgate.net/apple-touch-icon-152x152.png"> <link rel="apple-touch-icon" sizes="180x180" href="https://www.researchgate.net/apple-touch-icon-180x180.png"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-32x32.png" sizes="32x32"> <link rel="icon" type="image/png" href="https://www.researchgate.net/android-chrome-192x192.png" sizes="192x192"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-96x96.png" sizes="96x96"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-16x16.png" sizes="16x16"> <link rel="shortcut icon" type="image/x-icon" href="https://c5.rgstatic.net/m/2390829798215018/images/favicon.ico"/> <link rel="manifest" href="https://www.researchgate.net/manifest.json"> <meta name="msapplication-TileColor" content="#da532c"> <meta name="msapplication-TileImage" content="https://www.researchgate.net/mstile-144x144.png"> <meta name="theme-color" content="#444444"> <link rel="search" type="application/opensearchdescription+xml" title="ResearchGate search" href="https://www.researchgate.net/application.DownloadOpenSearchPlugin.html"/> <link rel="meta" type="application/rdf+xml" title="ICRA labels" href="https://www.researchgate.net/application.DownloadLabels.html"/> <link rel="http://oexchange.org/spec/0.8/rel/related-target" type="application/xrd+xml" href="https://www.researchgate.net/application.DownloadOExchange.html"/> <base href="https://www.researchgate.net/"/> <script>
    var rgConfig = {
        correlationId: "rgreq-b35215a7-1a1d-4ec6-817e-f6eba97b9542",
        accountId: "",
        module: "publicliterature",
        action: "publicliterature.PublicPublicationDetails",
        page: "publicationDetail",
        product: "publications",
        continent: "Asia",
        stylesHome: "//c5.rgstatic.net/m/",
        staticHost: "c5.rgstatic.net",
        longRunningRequestIdentifier: "LongRunningRequest.publicliterature.PublicPublicationDetails",
        longRunningRequestFp: "e9e5bbe1366c7ee8c8e41d02f793c884ac9be19b"
    };
    window.rootUrl = "https://www.researchgate.net/";
</script> <link rel="canonical" href="https://www.researchgate.net/publication/275588150_On_Sparse_variational_methods_and_the_Kullback-Leibler_divergence_between_stochastic_processes" />
<link rel="dns-prefetch" href="//c5.rgstatic.net" />
<link rel="dns-prefetch" href="//i1.rgstatic.net" />
<meta property="twitter:card" content="summary" />
<meta property="twitter:site" content="@ResearchGate" />
<meta property="og:title" content="On Sparse variational methods and the Kullback-Leibler divergence between stochastic processes" />
<meta property="og:description" content="The variational framework for learning inducing variables Titsias (2009) has
had a large impact on the Gaussian process literature. The framework may be
interpreted as minimizing a rigorously..." />
<meta property="og:site_name" content="ResearchGate" />
<meta property="og:image" content="https://i1.rgstatic.net/publication/275588150_On_Sparse_variational_methods_and_the_Kullback-Leibler_divergence_between_stochastic_processes/links/55adfd8f08aed9b7dcdb08a0/smallpreview.png" />
<meta property="og:url" content="https://www.researchgate.net/publication/275588150_On_Sparse_variational_methods_and_the_Kullback-Leibler_divergence_between_stochastic_processes" />
<meta property="rg:id" content="PB:275588150" />
<meta name="DC.identifier" scheme="DCTERMS.URI" content="http://dx.doi.org/" />
<meta name="gs_meta_revision" content="1.1" />
<meta name="citation_title" content="On Sparse variational methods and the Kullback-Leibler divergence between stochastic processes" />
<meta name="citation_author" content="Alexander G. de G. Matthews" />
<meta name="citation_author" content="James Hensman" />
<meta name="citation_author" content="Richard E. Turner" />
<meta name="citation_author" content="Zoubin Ghahramani" />
<meta name="citation_publication_date" content="2015/04/27" />
<meta name="citation_pdf_url" content="https://www.researchgate.net/profile/James_Hensman/publication/275588150_On_Sparse_variational_methods_and_the_Kullback-Leibler_divergence_between_stochastic_processes/links/55adfd8f08aed9b7dcdb08a0.pdf" />
<meta name="citation_abstract_html_url" content="https://www.researchgate.net/publication/275588150_On_Sparse_variational_methods_and_the_Kullback-Leibler_divergence_between_stochastic_processes" />
<meta name="citation_fulltext_html_url" content="https://www.researchgate.net/publication/275588150_On_Sparse_variational_methods_and_the_Kullback-Leibler_divergence_between_stochastic_processes" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<link href="//c5.rgstatic.net/m/22664197317151888/styles/rg.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/21004998181197492/styles/rg2.css" type="text/css" rel="stylesheet"/>
<!--[if lt IE 9]><link href="//c5.rgstatic.net/m/238176252723686/styles/ie.css" type="text/css" rel="stylesheet"/><![endif]-->
<link href="//c5.rgstatic.net/m/217752362214895/styles/modules/publicprofile.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/21993347442549/styles/pow/publicliterature/FollowPublicationPromo.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/282514599719602/styles/pow/application/PdfJsReader.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/23819663151220/styles/pow/publicliterature/PublicationInlineReader.css" type="text/css" rel="stylesheet"/>
<script src="//c5.rgstatic.net/m/2321000301012716/javascript/vendor/webfontloader/webfontloader.js" type="text/javascript"></script>
 <script>(function(i,s,o,g,r,a,m){i["GoogleAnalyticsObject"]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,"script","//www.google-analytics.com/analytics.js","ga");
 ga("create","UA-58591210-1");ga("set","anonymizeIp",true);ga('set', 'dimension1', 'publication full-text');ga('set', 'dimension2', 'Article');ga('set', 'dimension3', 'Logged out');ga('set', 'dimension4', 'https');ga("send","pageview");</script>
  <script> WebFontConfig = { custom: { families: ['source_sans_pro_italic', 'source_sans_pro_bold', 'source_sans_pro', 'martel'], urls : ['//c5.rgstatic.net/m/231392577336386/styles/fonts.css'] } }; WebFont.load(WebFontConfig); </script><noscript></noscript>

<title>On Sparse variational methods and the Kullback-Leibler divergence between stochastic processes (PDF Download Available)</title>
<meta name="description" content="Official Full-Text Publication: On Sparse variational methods and the Kullback-Leibler divergence between stochastic processes on ResearchGate, the professional network for scientists."/>
<meta name="keywords" content="scientific network, scientific platform, scientific community, research partner, research collaboration, journal articles, international collaboration, find researcher, lifescience researcher, interdisciplinary research, research collaboration"/>
</head>
<body class="use-svg-icons logged-out">
<div id="page-container">
<script type="text/javascript">var googletag = googletag || {}; googletag.cmd = googletag.cmd || [];
(function() { var gads = document.createElement("script"); gads.async = true; gads.type = "text/javascript"; var useSSL = "https:" == document.location.protocol; gads.src = (useSSL ? "https:" : "http:") + "//www.googletagservices.com/tag/js/gpt.js"; var node =document.getElementsByTagName("script")[0]; node.parentNode.insertBefore(gads, node); })();</script><div id="main" class="logged-out-header-support">
<div id="content" class="">

<noscript>
<div class="c-box-warning full-width-element" style="text-align: center; ">
    <div style="margin: auto; padding:10px;" class="container">
        <b>For full functionality of ResearchGate it is necessary to enable JavaScript.
            Here are the <a href="http://www.enable-javascript.com/" rel="nofollow" target="_blank">
                instructions how to enable JavaScript in your web browser</a>.</b>
    </div>
</div>
</noscript>

<div id="rgw1_56ab1e25595c3" itemscope itemtype="http://schema.org/ScholarlyArticle"><div class="publication-wrapper publication-wrapper-onecol" id="rgw2_56ab1e25595c3" itemscope itemtype="http://schema.org/ScholarlyArticle"> <div class="c-col-content"> <div class="c-content"> <div class="clearfix">  <div class="publication-header"> <div id="rgw5_56ab1e25595c3">  <div class="type-label"> Article   </div> <span class="Z3988" title="ctx_ver=Z39.88-2004&rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&rfr_id=info%3Asid%2Fresearchgate.net%3Aresearchgate&rft.atitle=On%20Sparse%20variational%20methods%20and%20the%20Kullback-Leibler%20divergence%20between%20stochastic%20processes&rft.date=2015&rft.au=Alexander%20G.%20de%20G.%20Matthews%2CJames%20Hensman%2CRichard%20E.%20Turner%2CZoubin%20Ghahramani&rft.genre=article"></span> <h1 class="pub-title" itemprop="name">On Sparse variational methods and the Kullback-Leibler divergence between stochastic processes</h1> <meta itemprop="headline" content="On Sparse variational methods and the Kullback-Leibler divergence between stochastic processes">  <meta itemprop="image" content="https://i1.rgstatic.net/publication/275588150_On_Sparse_variational_methods_and_the_Kullback-Leibler_divergence_between_stochastic_processes/links/55adfd8f08aed9b7dcdb08a0/smallpreview.png">  <div id="rgw7_56ab1e25595c3" class="publication-detail-author-list"> <div> <ul class="clearfix js-people-list">  <li id="rgw8_56ab1e25595c3"> <a href="researcher/2048369253_Alexander_G_de_G_Matthews" class="pub-detail-item author-item" itemprop="author" itemscope itemtype="http://schema.org/Person"> <div class="indent-left"> <div class="people-img">  <img src="https://c5.rgstatic.net/m/2951093203564/images/template/default/profile/profile_default_s.jpg" title="Alexander G. de G. Matthews" alt="Alexander G. de G. Matthews" height="20px" width="20px" style="height: 20px;"/>  </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Alexander G. de G. Matthews</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item   not-claimed " id="rgw9_56ab1e25595c3">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="researcher/2048369253_Alexander_G_de_G_Matthews"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="Alexander G. de G. Matthews" alt="Alexander G. de G. Matthews" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">       </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="researcher/2048369253_Alexander_G_de_G_Matthews" class="display-name">Alexander G. de G. Matthews</a>    </h5> <div class="truncate-single-line meta">   </div>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>  <li id="rgw10_56ab1e25595c3" itemprop="author" itemscope itemtype="http://schema.org/Person"> <a itemprop="sameAs" href="profile/James_Hensman" class="pub-detail-item account-item"> <div class="indent-left"> <div class="people-img"> <img  src="https://i1.rgstatic.net/ii/profile.image/AS%3A277099177889798%401443077000994_m" title="James Hensman" alt="James Hensman" height="20px" width="20px" style="height: 20px;"/> </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">James Hensman</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item  remove-action-indent   " id="rgw11_56ab1e25595c3" data-account-key="James_Hensman">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="profile/James_Hensman"> <img class="lazyload" data-src="https://i1.rgstatic.net/ii/profile.image/AS%3A277099177889798%401443077000994_l" title="James Hensman" alt="James Hensman" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">     </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="profile/James_Hensman" class="display-name">James Hensman</a>    </h5> <div class="truncate-single-line meta">   <a class="meta ga-top-coauthor-institution" href="institution/Lancaster_University" title="Lancaster University">Lancaster University</a>     </div>  <a href="javascript:" class="btn btn-promote btn-large people-item-contact-author js-contact-author">Message author</a>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>  <li id="rgw12_56ab1e25595c3" itemprop="author" itemscope itemtype="http://schema.org/Person"> <a itemprop="sameAs" href="profile/Richard_Turner18" class="pub-detail-item account-item"> <div class="indent-left"> <div class="people-img"> <img  src="https://i1.rgstatic.net/ii/profile.image/AS%3A279424772657156%401443631465203_m/Richard_Turner18.png" title="Richard E. Turner" alt="Richard E. Turner" height="20px" width="20px" style="height: 20px;"/> </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Richard E. Turner</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item  remove-action-indent   " id="rgw13_56ab1e25595c3" data-account-key="Richard_Turner18">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="profile/Richard_Turner18"> <img class="lazyload" data-src="https://i1.rgstatic.net/ii/profile.image/AS%3A279424772657156%401443631465203_l/Richard_Turner18.png" title="Richard E. Turner" alt="Richard E. Turner" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">     </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="profile/Richard_Turner18" class="display-name">Richard E. Turner</a>    </h5> <div class="truncate-single-line meta">   <a class="meta ga-top-coauthor-institution" href="institution/University_of_Cambridge" title="University of Cambridge">University of Cambridge</a>     </div>  <a href="javascript:" class="btn btn-promote btn-large people-item-contact-author js-contact-author">Message author</a>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>  <li id="rgw14_56ab1e25595c3"> <a href="researcher/8159937_Zoubin_Ghahramani" class="pub-detail-item author-item" itemprop="author" itemscope itemtype="http://schema.org/Person"> <div class="indent-left"> <div class="people-img">  <img src="https://c5.rgstatic.net/m/2951093203564/images/template/default/profile/profile_default_s.jpg" title="Zoubin Ghahramani" alt="Zoubin Ghahramani" height="20px" width="20px" style="height: 20px;"/>  </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Zoubin Ghahramani</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item   not-claimed " id="rgw15_56ab1e25595c3">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="researcher/8159937_Zoubin_Ghahramani"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="Zoubin Ghahramani" alt="Zoubin Ghahramani" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">       </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="researcher/8159937_Zoubin_Ghahramani" class="display-name">Zoubin Ghahramani</a>    </h5> <div class="truncate-single-line meta">   </div>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>   </ul> <div class="js-loading"></div>  </div> </div> <div class="pub-details js-pub-details">        <meta itemprop="datePublished" content="2015-04">  04/2015;               <div class="pub-source"> Source: <a href="http://arxiv.org/abs/1504.07027" rel="nofollow">arXiv</a> </div>  </div> <div id="rgw16_56ab1e25595c3" class="pub-abstract">  <div class="clearfix">   <div style="max-height: 54px;" class="js-expander-container js-expander-collapsed">  <p itemprop="description"> <strong>ABSTRACT</strong> <div>The variational framework for learning inducing variables Titsias (2009) has<br />
had a large impact on the Gaussian process literature. The framework may be<br />
interpreted as minimizing a rigorously defined Kullback-Leibler divergence<br />
between the approximate and posterior processes. To our knowledge this<br />
connection has thus far gone unremarked in the literature. Many of the<br />
technical requirements for such a result were derived in the pioneering work of<br />
Seeger (2003,2003b). In this work we give a relatively gentle and largely<br />
self-contained explanation of the result. The result is important in<br />
understanding the variational inducing framework and could lead to principled<br />
novel generalizations.</div> </p>  </div>  </div>   </div>      <div class="action-container"> <div id="rgw17_56ab1e25595c3" class="follow-publication-promo"> <table> <tr> <td class="follow-publication-promo-text-cell"> <p>Get notified about updates to this publication</p> <a class="btn btn-large btn-promote js-follow-publication ga-follow-publication-new-promo">Follow publication</a> </td> <td> <div class="follow-publication-publication-image"></div> </td> </tr> </table> </div>  <div class="clear"></div> <div class="share-dialog-container" style="display: none;">  </div> </div> </div> <div style="margin-left: -20px; margin-right: -20px;">  </div> </div>  <div class="publication-detail-dfp-container rf"> <div id="rgw31_56ab1e25595c3">  </div> </div>  </div>  <div class="clearfix"> <div class="pdf-js-container clearfix " id="rgw36_56ab1e25595c3">  <div class="pdf-js-header js-sticky-header clear">  <a class="blue-link js-download rf btn btn-promote" href="https://www.researchgate.net/profile/James_Hensman/publication/275588150_On_Sparse_variational_methods_and_the_Kullback-Leibler_divergence_between_stochastic_processes/links/55adfd8f08aed9b7dcdb08a0.pdf?inViewer=0&amp;pdfJsDownload=0&amp;origin=publication_detail">Download full-text</a>  <h3>Full-text</h3> <span class="publication-info">  <span class="js-doi-container" style="display: none;"> DOI: <span class="js-doi"></span> &middot; </span> Available from: <a class="js-name" href="profile/James_Hensman">James Hensman</a>, <span class="js-publication-date"> Jul 21, 2015 </span>   </span>  </div>  <div class="social-share-container"><div id="rgw38_56ab1e25595c3" class="social-share js-social-share"> <div class="social-share-heading">Share</div>  <a id="rgw39_56ab1e25595c3" href="javascript:" title="Share on Facebook" class="link-nostyle js-share-item share-icon "  data-url="http://www.facebook.com/share.php?u={{url}}{{#title}}&amp;t={{title}}{{/title}}" data-width="600" data-height="350" data-name="Facebook"> <span class="share-icon ico-share-facebook-round reset-background ga-share-blog-facebook"></span> </a>  <a id="rgw40_56ab1e25595c3" href="javascript:" title="Share on Twitter" class="link-nostyle js-share-item share-icon "  data-url="http://twitter.com/intent/tweet?text={{#title}}{{title}}: {{/title}}{{url}}&amp;via=researchgate" data-width="600" data-height="350" data-name="Twitter"> <span class="share-icon ico-share-twitter-round reset-background ga-share-blog-twitter"></span> </a>  <a id="rgw41_56ab1e25595c3" href="javascript:" title="Share on Google+" class="link-nostyle js-share-item share-icon "  data-url="https://plus.google.com/share?url={{url}}" data-width="600" data-height="600" data-name="Google+"> <span class="share-icon ico-share-gplus-round reset-background ga-share-blog-gplus"></span> </a>  <a id="rgw42_56ab1e25595c3" href="javascript:" title="Share on LinkedIn" class="link-nostyle js-share-item share-icon "  data-url="http://www.linkedin.com/shareArticle?mini=true&amp;url={{url}}{{#title}}&amp;title={{title}}{{/title}}&amp;source=ResearchGate" data-width="520" data-height="570" data-name="LinkedIn"> <span class="share-icon ico-share-linkedin-round reset-background ga-share-blog-linkedin"></span> </a>  <a id="rgw43_56ab1e25595c3" href="javascript:" title="Share on Reddit" class="link-nostyle js-share-item share-icon "  data-url="https://www.reddit.com/submit?url={{url}}{{#title}}&amp;title={{title}}{{/title}}" data-width="600" data-height="600" data-name="Reddit"> <span class="share-icon ico-share-reddit reset-background ga-share-blog-reddit"></span> </a>  </div></div>    <iframe id="rgw37_56ab1e25595c3" src="https://www.researchgate.net/c/o1o9o3/javascript/lib/pdfjs/web/viewer.html?file=https%3A%2F%2Fwww.researchgate.net%2Fprofile%2FJames_Hensman%2Fpublication%2F275588150_On_Sparse_variational_methods_and_the_Kullback-Leibler_divergence_between_stochastic_processes%2Flinks%2F55adfd8f08aed9b7dcdb08a0.pdf%3FinViewer%3D1%26pdfJsDownload%3D1%26origin%3Dpublication_detail" allowfullscreen frameborder="0" style="width: 100%; height: 100%; box-sizing: border-box;"></iframe>    </div> <noscript> <div id="rgw30_56ab1e25595c3"  itemprop="articleBody">  <p>Page 1</p> <p>arXiv:1504.07027v1  [stat.ML]  27 Apr 2015<br />On Sparse variational methods and the Kullback-Leibler divergence<br />between stochastic processes<br />Alexander G. de G. Matthews1, James Hensman2, Richard E. Turner1, Zoubin Ghahramani1<br />1University of Cambridge,2University of Sheffield<br />April 30, 2015<br />Abstract<br />The variational framework for learning inducing variables (Titsias, 2009) has had a large impact on the<br />Gaussian process literature. The framework may be interpreted as minimizing a rigorously defined Kullback-<br />Leibler divergence between the approximate and posterior processes. To our knowledge this connection has thus<br />far gone unremarked in the literature. Many of the technical requirements for such a result were derived in the<br />pioneering work of Seeger (2003a; 2003b). In this work we give a relatively gentle and largely self-contained<br />explanation of the result. The result is important in understanding the variational inducing framework and could<br />lead to principled novel generalizations.<br />1 Introduction<br />The variational approach to inducing point selection of Titsias (2009) has been highly influential in the active<br />research area of scalable Gaussian process approximations. The chief advantage of this particular framework is that<br />the inducing points positions are variational parameters rather than models parameters and as such are protected<br />from overfitting. The original framework is applied to conjugate likelihoods and has been extended to non-conjugate<br />likelihoods (Chai, 2012; Hensman et al., 2015). An important advance in the use of variational methods was their<br />combination with stochastic gradient descent (Hoffman et al., 2013) and the variational inducing point framework has<br />been combined with such methods in the conjugate (Hensman et al., 2013) and non-conjugate cases (Hensman et al.,<br />2015).<br />The approach has also been successfully used to perform scalable inference in more complex models such as the<br />Gaussian process latent variable model (Titsias and Lawrence, 2010; Damianou et al., 2014) and the related Deep<br />Gaussian process (Damianou and Lawrence, 2012; Hensman and Lawrence, 2014).<br />To be more concrete let us setup some notation, consider a function f mapping an index set X to the set of real<br />numbers<br />f : X ?→ R.<br />(1)<br />Entirely equivalently we may write f ∈ RXor use sequence notation (f(x))x∈X.<br />We also define set indexing of the function. If S ⊆ X is some subset of the index set then<br />fS:= (f(x))x∈S<br />(2)<br />and we may straightforwardly extend this definition to single elements of the index set fx:= f{x}. We can put this<br />notation to immediate use by defining a subset D ⊆ X of the index set, of size N, that corresponds to those input<br />points for which we have observed data. The corresponding function values will then be denoted fD. For simplicity<br />we will assume that we have one, possibly noisy, possibly non-conjugate observation y per input data point which<br />will together form a set Y .<br />1</p>  <p>Page 2</p> <p>Gaussian processes allow us to define a prior over functions f. After we observe the data we will have some<br />posterior which we wish to approximate with a sparse distribution. At the heart of the variational inducing point<br />approximation is the idea of ‘augmentation’ that appears in the original paper and many subsequent ones. We choose<br />to monitor a set Z ⊆ X of size M. These points may have some overlap with the input data points D but to give a<br />computational speed up M will need to be less than the number of data points N. The Kullback-Leibler divergence<br />given as an optimization criterion in Titsias’ original paper is<br />KL[q(fD\Z,fZ)||p(fD\Z,fZ|Y )]<br />?<br />=<br />?<br />q(fD\Z,fZ)log<br />q(fD\Z,fZ)<br />p(fD\Z,fZ|Y )<br />?<br />dfD\ZdfZ<br />(3)<br />The variational distribution at those data points which are not also inducing points is taken to have the form:<br />q(fD\Z,fZ) := p(fD\Z|fZ)q(fZ) (4)<br />where p(fD\Z|fZ) is the prior conditional and q(fZ) is a variational distribution on the inducing points only. Under<br />this factorization, for a conjugate likelihood, the optimal q(fZ) has an analytic Gaussian solution (Titsias, 2009).<br />The non-conjugate case was then studied in subsequent work (Chai, 2012; Hensman et al., 2015). In both cases the<br />sparse approximation requires only O(NM2) rather than the O(N3) required by exact methods in the conjugate<br />case or many commonly used non-conjugate approximations that don’t assume sparsity.<br />The augmentation is justified by arguing that the model remains marginally the same when the inducing points<br />are added. Thus the inducing point positions can be considered to be variational parameters and are consequently<br />protected from overfitting.<br />Without this justification, however, the KL-divergence in equation could seem to be a strange optimization target.<br />The KL-divergence has the inducing variables on both sides. Thus it might seem that in optimizing the inducing<br />point positions we are trying to hit a ‘moving target’. It would thus seem desirable to rigorously formulate a ‘one<br />sided’ KL-divergence that leads to Titsias’ formulation. Such a derivation could be viewed as a rigorous mathematical<br />proof of the augmentation argument and could help correctly generalize this elegant framework. Such a derivation<br />is the topic of this article. As we shall see it requires some fairly technical mathematical machinery which will also<br />be elucidated from the various necessary sources.<br />In terms of existing work the major other references are the early work of Seeger (2003a; 2003b). In particular<br />Seeger identifies the KL-divergence between processes (more commonly referred to as a relative entropy in those<br />texts) as a measure of similarity and applies it to PAC-Bayes and to subset of data sparse methods. Crucially Seeger<br />outlines the rigorous formulation of such a KL-divergence which is a large technical obstacle. The explanation of<br />this point is somewhat distributed over the work and its references. One of the aims of this article is to pull a large<br />proportion of the necessary knowledge together and to give more detail where helpful or expedient. Further, we<br />extend the stochastic process formulation to inducing points which are not necessarily selected from the data and<br />show that this is equivalent to Titsias’ formulation. In so far as we are aware this relationship has not previously<br />been noted in the literature. The idea of using the KL-divergence between processes is also mentioned in the early<br />work of Csato and Opper (2002; 2002) but the transition from finite dimensional multivariate Gaussians to infinite<br />dimensional Gaussian processes is not covered at the level of detail discussed here. An optimization target that in<br />intent seems to be similar to a KL-divergence between stochastic process is briefly mentioned in the work of Alvarez<br />(2011). The notation used suggests that the integration is with respect to an ‘infinite dimensional dimensional<br />Lebesgue measure’, which as we shall see is an argument that arrives at the right answer via a mathematically flawed<br />route. Chai (2012) seems to have been at least partly aware of Seeger’s KL-divergence theorems (Seeger, 2003b) but<br />instead uses them to bound the finite joint predictive probability of a non sparse process.<br />This article proceeds by first discussing the finite dimensional version of the full argument. This requires consid-<br />erably less mathematical machinery and much of the intuition can be gained from this case. After reviewing some of<br />the mathematical background we then proceed to give the full measure theoretic formulation. Finally we conclude.<br />2</p>  <p>Page 3</p> <p>2Finite index set case<br />Consider the case where X if finite. We introduce a new set ∗ := X\(D ∪ Z), in words: all points that are in the<br />index set that aren’t inducing points or data points. These points might be of practical interest for instance when<br />making predictions on hold out data.<br />We extend the variational distribution to include these points:<br />q(f∗,fD\Z,fZ) := p(f∗,fD\Z|fZ)q(fZ).<br />(5)<br />We then consider the KL-divergence between this extended variational distribution and the full posterior distri-<br />bution p(f|Y )<br />KL[q(f∗,fD\Z,fZ)||p(f|Y )]<br />=KL[q(f∗,fD\Z,fZ)||p(f∗,fD\Z,fZ|Y )]<br />?<br />=<br />q(f∗,fD\Z,fZ)log<br />q(f∗,fD\Z,fZ)<br />p(f∗,fD\Z,fZ|Y )df∗dfD\ZdfZ<br />(6)<br />Now we substitute the definitions of q(f∗,fD\Z,fZ) and p(f∗,fD\Z,fZ|Y ) in terms of conditional distributions<br />into the integral, observing some cancellation:<br />=<br />?<br />p(f∗,fD\Z|fZ)q(fZ)log<br />?<br />p(f∗|fD\Z,fZ)p(fD\Z|fZ)q(fZ)p(Y )<br />p(f∗|fD\Z,fZ)p(fD\Z|fZ)p(fZ)p(Y |fD)<br />p(fD\Z|fZ)q(fZ)p(Y )<br />p(fD\Z|fZ)p(fZ)p(Y |fD)<br />?<br />df∗dfD\ZdfZ<br />=<br />?<br />p(f∗,fD\Z|fZ)q(fZ)log<br />?<br />?<br />df∗dfD\ZdfZ<br />(7)<br />(8)<br />Next we exploit the marginalization property of the Gaussian process:<br />=<br />?<br />p(fD\Z|fZ)q(fZ)log<br />?<br />p(fD\Z|fZ)q(fZ)p(Y )<br />p(fD\Z|fZ)p(fZ)p(Y |fD)<br />q(fD\Z,fZ)<br />p(fD\Z,fZ|Y )<br />?<br />dfD\ZdfZ<br />(9)<br />=<br />?<br />q(fD\Z,fZ)log<br />?<br />?<br />dfD\ZdfZ<br />(10)<br />(11)<br />The last line is exactly the KL-divergence used by Titsias (2009) that we already described in equation 3. We thus<br />see that for finite index sets considering the KL-divergence between the two distributions is equivalent to Titsias’<br />KL-divergence.<br />We might choose to optimize our choice of the M by selecting them from the |X| possible values in the index set<br />and comparing the KL-divergence between distributions given in equation 6. The equivalence with equation 3 that<br />we have just derived shows us that in this case the appearance of the inducing values on both sides of the equation<br />is just a question of ‘accounting’. That is to say whilst we are in fact optimizing the KL-divergence between the full<br />distributions, we only need to keep track of the distribution over function values fZand fD\Z. All the other function<br />values f∗marginalize. For different choices of inducing points we will need to keep track of different function values<br />and be able to safely ignore different values f∗.<br />3Infinite index set case<br />3.1 There is no useful infinite dimensional Lebesgue measure<br />One might hope to cope with not only finite index sets but also infinite index sets in the way discussed in section<br />2. Unfortunately when X and hence f∗are infinite sets we cannot integrate with respect to a ‘infinite dimensional<br />vector’. That is to say the notation?(·)df∗can no longer be correctly used.<br />3</p>  <p>Page 4</p> <p>For a discussion of this see, for example, Hunt et al (1992). The crux of the issue is that to give sensible answers<br />such a measure would need to be translation invariant and locally finite. Unfortunately the only measure that obeys<br />these two properties is the zero measure which assigns zero to every input set.<br />Thus we see that it will be necessary to rethink our approach to a KL-divergence between stochastic processes.<br />It will turn out that a reasonable definition will require the full apparatus of measure theory.<br />3.2Measure spaces and Lebesgue integral.<br />In this section we discuss the fundamental definitions in measure theory. Readers familiar with this material may<br />safely skip to the next section, although they may wish to review the notation used. Readers looking for a fuller<br />exposition may wish to consult a textbook (Billingsley, 1995; Capinski and Kopp, 2004).<br />A σ-algebra Σ on a set Ω is a set of subsets E of Ω that obey the following axioms:<br />1. It contains the full set. Ω ∈ Σ<br />2. It is closed under complementation. E ∈ Σ =⇒ Ω\E ∈ Σ<br />3. It is closed under countable unions. Ei∈ Σ, i ∈ I ⊆ N =⇒<br />?<br />i∈I<br />Ei∈ Σ<br />Consider a set of subsets G of Ω which is not necessarily a σ-algebra. The σ-algebra generated by G is the unique<br />smallest σ-algebra containing every element of G. It is denoted σ(G). As an example of such a generated σ-algebra<br />we give the Borel σ-algebra B on the real numbers R which is generated by the set of all open intervals (a,b) of the<br />real line. The Borel σ-algebra may be extended to multiple dimensions.<br />A measure is a function mapping elements of a σ-algebra, Σ, to the extended real number line R ∪ {∞,−∞}. It<br />obeys the following axioms:<br />1. It is non-negative. ∀E ∈ Σ, µ(E) ≥ 0<br />2. The measure of the empty set ∅ is zero. µ(∅) = 0<br />3. The measure is countably additive. For I ⊆ N, µ(?<br />It is possible to extend this definition to signed measures but we will not require this in what follows. A probability<br />measure is a measure for which µ(Ω) = 1. The triple (Ω,Σ,µ) is called a measure space.<br />Given two σ-algebras on two different sets, namely Σ1on Ω1and Σ2on Ω2a function g : Ω1?→ Ω2is called a<br />measurable function if for any set E ∈ Σ2the pre-image of that set g−1(E) = {ω ∈ Ω1: g(ω) ∈ Σ2} is a member of<br />Σ1.<br />In all cases that we discuss in the text the range of the function of interest Ω2will be the set of real numbers<br />R and the corresponding σ-algebra Σ2 will be the Borel σ-algebra. Measurability in this case is equivalent to the<br />pre-image of all intervals of the form (x,∞) being members of Σ1.<br />The Lebesgue integral is a measure theoretic formulation of the notion of integral. A non-negative measurable<br />function ψ : Ω1?→ R is a simple function if its range is a finite set {y1,y2...yC}. We may write:<br />i∈I<br />Ei) =?<br />i∈I<br />µ(Ei).<br />ψ(ω) =<br />C<br />?<br />i=1<br />yi<br />?Ai(ω)(12)<br />where the sets Ai= ψ−1(yi), i = 1,...,C are by assumption a sequence of measurable sets and<br />function.<br />The integral of a simple function with respect to a measure µ on Σ1and some element E ∈ Σ1is:<br />? is the indicator<br />?<br />E<br />ψdµ =<br />C<br />?<br />i=1<br />yiµ(Ai∩ E)(13)<br />Using the definition for simple functions we extend the definition of Lebesgue integral to general non-negative<br />measurable functions g thus:<br />4</p>  <p>Page 5</p> <p>?<br />E<br />gdµ = sup<br />??<br />E<br />ψdµ : 0 ≤ ψ ≤ g,ψ is simple<br />?<br />(14)<br />For those readers more familiar with the Riemann integral it may be helpful to give an intuitive motivation of<br />the relationship between the two. In the case of the Riemann integral we partition the domain of the function into<br />increasingly small sets. We then evaluate the function to provide an increasingly accurate approximation of the area<br />under the curve. In the case of the Lebesgue integral we divide the range of the function into increasingly small sets,<br />take the pre-image of each element of the partition and then use the measure µ to measure it. The Lebesgue integral<br />will make it possible for us to take the integral with respect to relatively complex probability measures such as those<br />corresponding to Gaussian processes, as we shall see in the sections that follow.<br />Consider two measures µ,η on (Ω,Σ). µ is absolutely continuous with respect to η if the null sets of η are null<br />sets of µ that is to say η(A) = 0 =⇒ µ(A) = 0. If both measures allocate finite measure to the whole space, as<br />will be the case with probability measures, then it is a consequence of the Radon-Nikodym theorem that there exists<br />some measurable function<br />dη: Ω ?→ [0,∞) known as the Radon-Nikodym derivative with the property that for all<br />E ∈ Σ:<br />dµ<br />µ(E) =<br />?<br />E<br />dµ<br />dηdη<br />(15)<br />Suppose we have a third measure λ with the property:<br />η(E) =<br />?<br />E<br />dη<br />dλdλ,<br />(16)<br />then the following relation holds:<br />µ(E) =<br />?<br />E<br />dµ<br />dη<br />dη<br />dλdλ<br />(17)<br />3.3The product σ-algebra and the Kolmogorov extension theorem<br />The presentation in this section follows the notes of Sengupta (2014) fairly closely. We now return to considering<br />functions from an index set to the reals f : X ?→ R which we can also denote in sequence notation (f(x))x∈X.<br />Consider a projection map πU→V that for V ⊂ U ⊆ X has the following property:<br />πU→V : RU?→ RV: (f(x))x∈U?→ (f(x))x∈V<br />(18)<br />A cylinder set is the pre-image of the projection πX→V of a Borel set E ∈ RVfor finite V , denoted:<br />π−1<br />X→V(E).<br />(19)<br />Clearly it is a subset of the set of all functions from X to R. Let C be the set of all cylinder sets. We may generate<br />a σ-algebra using this set which we denote σ(C). This σ-algebra is known as the product σ-algebra.<br />The Kolmogorov extension theorem concerns circumstances under which a collection of consistent distributions<br />on functions for finite index sets U ⊂ X implies the existence of a corresponding probability measure on functions<br />with countably or uncountably infinite index set X. To be more concrete consider a family of Borel probability<br />measures, labelled by their corresponding finite index set, µV : B(V ) ?→ [0,1] which obeys the following consistency<br />relation for all V ⊂ X and all second finite index sets with U ⊃ V :<br />µU(π−1<br />U→V(E)) = µV(E) (20)<br />over all Borel sets E ⊂ RV. If such a set of consistent finite dimensional distributions exists then Kolmogorov’s<br />theorem states that there is a unique probability measure on the product σ-algebra, µX : σ(C) ?→ [0,1] with the<br />property:<br />µX(π−1<br />X→V(E)) = µV(E)(21)<br />5</p>  <p>Page 6</p> <p>for all finite index sets V and Borel sets E ⊂ RV.<br />A common example of the application of this theorem is to argue for the existence of a Gaussian process with a<br />given mean and covariance function on the basis of the marginalization property of multivariate Gaussian distribu-<br />tions.<br />3.4The KL-divergence between processes<br />We have now reviewed all the mathematical background necessary and we can return to the original questions: “How<br />does one rigorously define the KL-divergence between stochastic processes” and “How does this relate to Titsias’<br />KL-divergence?” which are answered in the next two sections.<br />Suppose we have two measures µ and η for (Ω,Σ) and that µ is absolutely continuous with respect to η. Then<br />there exists a Radon-Nikodyn derivativedµ<br />dηand the correct definition for KL-divergence between these measures is:<br />KL[µ||η] =<br />?<br />Ω<br />log<br />?dµ<br />dη<br />?<br />dµ<br />(22)<br />In the case where µ is not absolutely continuous with respect to η we let KL[µ||η] = ∞. In the case where the<br />measure is Borel on RBfor some finite B and both measures are dominated by Lebesgue measure m this reduces to<br />the more familiar definition:<br />KL[µ||η] =<br />?<br />Ω<br />ulog<br />?u<br />v<br />?<br />dm<br />(23)<br />where u and v are the respective densities with respect to Lebesgue measure. The first definition is more general<br />and allows us to deal with the problem of there being no sensible infinite dimensional Lebesgue measure by instead<br />integrating with respect to the measure µ.<br />3.5Recovering the sparse variational inducing framework<br />In this section we are now interested in three types of probability measure on sets of functions f : X ?→ R. The first<br />is the prior measure P which will be assumed to be a Gaussian process. The second is the approximating measure<br />Q which will be assumed to be a sparse Gaussian process and the third is the posterior processˆP which may be<br />Gaussian or non-Gaussian depending on whether we have a conjugate likelihood. We specify the densities q with<br />respect to Lebesgue measure on any finite index set V ⊂ X to avoid ever trying to express a density with respect<br />to infinite dimensional Lebesgue measure. The Kolmogorov extension theorem then straightforwardly confirms the<br />existence of the measures in question on the product σ-algebra.<br />To compute the KL-divergence between the approximating process and the posterior we need to find the Radon-<br />Nikodym derivative. We start with the answer and then show that it is correct. The Radon-Nikodym derivative<br />is:<br />dQ<br />dˆP(f) =<br />q(fD\Z,fZ)<br />p(fD\Z,fZ|Y ).<br />(24)<br />Here q and p are the corresponding densities with respect to Lebesgue measure of the corresponding finite<br />dimensional marginals. In this case the Radon-Nikodym derivative only depends on finitely many of the function<br />points, namely the values at the data points and the inducing points.<br />We break the proof that this is the correct Radon-Nikodym derivative into two parts. First we need to show that<br />our candidate function is measurable, then we show that when integrated with respect toˆP over all members of the<br />product σ-algebra it gives the approximating measure Q.<br />To show that<br />p(fD\Z,fZ|Y )is measurable we need to show that the pre-images of all intervals (x,∞) lie in the<br />product σ-algebra denoted σ(C). To do this we note that the function only depends on the finite set of function<br />values fZ∪D. The pre-images are thus precisely cylinder sets of the form π−1<br />be Borel for allˆP and Q we consider.<br />Next we need to show that the measure ˆ µ defined by:<br />q(fD\Z,fZ)<br />X→V(E) where E ⊂ RZ∪Dwill certainly<br />6</p>  <p>Page 7</p> <p>ˆ µ(E) =<br />?<br />E<br />q(fD\Z,fZ)<br />p(fD\Z,fZ|Y )dˆP<br />(25)<br />where E ∈ σ(C), is equal to the measure Q. We can show this if we can show that both measures have the same finite<br />dimensional marginals, since we can appeal to the uniqueness of the Kolmogorov extension. Thus consider any finite<br />index subset V ⊂ X, a Borel set C ∈ RVand the corresponding cylinder set π−1<br />assume that V ⊇ Z ∪D but by careful, though not difficult, book keeping this may be extended to the general case.<br />We have<br />X→V(C). For clarity of exposition we<br />ˆ µ(π−1<br />X→V(C)) =<br />?<br />π−1<br />X→V(C))<br />?<br />C<br />q(fD\Z,fZ)<br />p(fD\Z,fZ|Y )dˆP<br />=⇒ ˆ µV(C) =<br />q(fD\Z,fZ)<br />p(fD\Z,fZ|Y )dˆPV<br />(26)<br />where the subscripting of the measures indicates the relevant finite dimensional measure on RV. Now that we have<br />a measure for a finite index set it is is dominated by Lebesgue measure mV on RVand thus we may write<br />ˆ µV(C) =<br />?<br />?<br />C<br />q(fD\Z,fZ)<br />p(fD\Z,fZ|Y )p(fD\Z,fZ|Y )p(fV \(Z∪D)|fD\Z,fZ)dmV<br />=<br />C<br />q(fD\Z,fZ)p(fV \(Z∪D)|fD\Z,fZ)dmV<br />= QV(C)(27)<br />as required. Now that we have confirmed we have the correct Radon-Nikodym derivative we show that the KL-<br />divergence between stochastic processes reduces to the KL-divergence of Titsias.<br />KL[Q||ˆP] =<br />?<br />?<br />RXlog<br />?dQ<br />dˆP<br />?<br />p(fD\Z,fZ|Y )<br />?<br />p(fD\Z,fZ|Y )<br />?<br />dQ<br />=<br />RXlog<br />q(fD\Z,fZ)<br />?<br />dQ<br />=<br />?<br />RZ∪Dlog<br />q(fD\Z,fZ)<br />?<br />dQZ∪D<br />=<br />?<br />RZ∪Dq(fD\Z,fZ)log<br />?<br />q(fD\Z,fZ)<br />p(fD\Z,fZ|Y )<br />?<br />dmZ∪D<br />(28)<br />QED.<br />4Conclusion and acknowledgements<br />In this work we have elucidated the connection between the variational inducing point framework (Titsias, 2009) and<br />a rigorously defined KL-divergence between stochastic processes. As will be evident, many of the required technical<br />results were derived early on in the use of Gaussian processes for machine learning by Seeger (2003a; 2003b).<br />It seems reasonableto hope that elucidating the measure theoretic roots of the formulation will help the community<br />to generalise the framework and lead to even better practical results.<br />The authors wish to thank Matthias Seeger and the anonymous reviewer of a previous paper. AM and ZG would<br />EPSRC grant EP/I036575/1, and a Google Focused Research award. JH was supported by a MRC fellowship.<br />7</p>  <p>Page 8</p> <p>References<br />Alvarez, M. A. (2011). Convolved Gaussian process priors for multivariate regression with applications to dynamical<br />systems. PhD thesis, University of Manchester.<br />Billingsley, P. (1995). Probability and Measure. Wiley-Interscience, 3 edition.<br />Capinski, M. and Kopp, P. (2004). Measure, Integral and Probability. Springer Undergraduate Mathematics Series.<br />Springer London.<br />Chai, K. M. A. (2012). Variational multinomial logit Gaussian process. J. Mach. Learn. Res., 13(1):1745–1808.<br />Csat´ o, L. (2002). Gaussian processes: iterative sparse approximations. PhD thesis, Aston University.<br />Csat´ o, L. and Opper, M. (2002). Sparse on-line gaussian processes. Neural computation, 14(3):641–668.<br />Damianou, A. C., K., M., Titsias, and Lawrence, N. D. (2014). Variational inference for uncertainty on the inputs<br />of Gaussian process models. arXiv preprint arXiv:1409.2287.<br />Damianou, A. C. and Lawrence, N. D. (2012). Deep gaussian processes. arXiv preprint arXiv:1211.0358.<br />Hensman, J., Fusi, N., and Lawrence, N. D. (2013). Gaussian processes for Big Data. In Conference on Uncertainty<br />in Artificial Intellegence, pages 282–290. auai.org.<br />Hensman, J. and Lawrence, N. D. (2014). Nested Variational Compression in Deep Gaussian Processes. ArXiv<br />e-prints.<br />Hensman, J., Matthews, A. G. D. G., and Ghahramani, Z. (2015). Scalable Variational Gaussian Process Classifica-<br />tion. In 18th International Conference on Artificial Intelligence and Statistics, pages 1–9, San Diego, California,<br />USA.<br />Hoffman, M. D., Blei, D. M., Wang, C., and Paisley, J. (2013). Stochastic variational inference. Journal of Machine<br />Learning Research, 14:1303–1347.<br />Hunt, B. R., Sauer, T., James, and Yorke, A. (1992). Prevalence: A translation-invariant almost every on infinite-<br />dimensional spaces. Bulletin of the Amer. Math. Soc, pages 217–238.<br />Seeger, M. (2003a).<br />approximations. PhD thesis, University of Edinburgh.<br />Bayesian Gaussian process models: PAC-Bayesian generalisation error bounds and sparse<br />Seeger, M. (2003b). Pac-Bayesian generalisation error bounds for Gaussian process classification. J. Mach. Learn.<br />Res., 3:233–269.<br />Sengupta, A. N. (2014). The kolmogorov extension theorem.<br />Titsias, M. K. (2009). Variational learning of inducing variables in sparse Gaussian processes. In In International<br />Conference on Artificial Intelligence and Statistics 12, pages 567–574.<br />Titsias, M. K. and Lawrence, N. D. (2010). Bayesian Gaussian process latent variable model. In Thirteenth Inter-<br />national Conference on Artificial Intelligence and Statistics.<br />8</p>  <a href="https://www.researchgate.net/profile/James_Hensman/publication/275588150_On_Sparse_variational_methods_and_the_Kullback-Leibler_divergence_between_stochastic_processes/links/55adfd8f08aed9b7dcdb08a0.pdf">Download full-text</a> </div> <div id="rgw22_56ab1e25595c3" class="c-box pub-resource-container js-toggle" style=""> <h4 class="lf js-expand-list"><small><a href="javascript:" class="lf">View other sources <span class="ico-expand-list"></span></a></small></h4> <h4 class="lf js-collapse-list hidden"><small><a href="javascript:" class="lf">Hide other sources <span class="ico-collapse-list"></span></a></small></h4> <div class="clear"></div> <div class="scroll-wrapper hidden"> <ul class="files-list c-list" id="rgw23_56ab1e25595c3">  <li class="c-list-item pub-resource-item"  data-type="fulltext" id="rgw24_56ab1e25595c3"> <span class="ico-pub"></span> <div class="file-content"> <div class="download"> <a href="profile/James_Hensman/publication/275588150_On_Sparse_variational_methods_and_the_Kullback-Leibler_divergence_between_stochastic_processes/links/55adfd8f08aed9b7dcdb08a0.pdf" class="publication-viewer" title="55adfd8f08aed9b7dcdb08a0.pdf">55adfd8f08aed9b7dcdb08a0.pdf</a> </div>  <div class="details">  <span> Available from <a href="profile/James_Hensman">James Hensman</a> &middot; Jul 21, 2015 </span>   </div>    </div> </li>  <li class="c-list-item pub-resource-item"  data-type="fulltext" id="rgw25_56ab1e25595c3"> <span class="ico-pub"></span> <div class="file-content"> <div class="download"> <a href="http://de.arxiv.org/pdf/1504.07027" target="_blank" rel="nofollow" class="publication-viewer" title="On Sparse variational methods and the Kullback-Leibler divergence between stochastic processes">On Sparse variational methods and the Kullback-Lei...</a> </div>  <div class="details">   Available from <a href="http://de.arxiv.org/pdf/1504.07027" target="_blank" rel="nofollow">de.arxiv.org</a>  </div>    </div> </li>  </ul> </div> </div> </noscript> <div class="clearfix"> <div class="action-container">  </div> <div class="pub-legal"> Data provided are for informational purposes only. Although carefully collected, accuracy cannot be guaranteed. The impact factor represents a rough estimation of the journal's impact factor and does not reflect the actual current impact factor. Publisher conditions are provided by RoMEO. Differing provisions from the publisher's actual policy or licence agreement may be applicable. </div>  <div id="rgw32_56ab1e25595c3" class="citations-container"> <div class="tab-container"> <ul class="tab-list"> <li class="lf tab-item  js-citations"> <a href="javascript:void(0);" class="tab-link"> References  </small> </a> </li>  <li class="lf tab-item tab-item-active js-cited-in js-cited-in-tooltip"> <a href="javascript:void(0);" class="tab-link"> Cited In <small> (1) </small> </a> </li>    <li class="rf"> <div class="dropdown js-citations-sorter dropdown-right-align" style="position: relative; bottom: -1px;display:none;"> <a href="javascript:void(0);" class="dropdown-toggle"> Sorted by: <strong class="js-current-sorting"> Order of availability  </strong> <span class="caret"></span> </a> <ul class="dropdown-menu"> <li><a href="javascript:void(0);" data-sort="normal">Order of availability</a></li> <li><a href="javascript:void(0);" data-sort="original">Appearance in publication</a></li> </ul> </div> </li>  </ul> <div class="tab-section tab-section-active js-citations-list-container"> <div id="rgw33_56ab1e25595c3" class="pub-citations-list">  <ul class="c-list">  <li class="c-list-item li-publication   "  id="rgw34_56ab1e25595c3" >  <div class="indent-left">  <div id="rgw35_56ab1e25595c3" class="js-publication-item-fulltext fulltext-thumb">    <a class="publication-preview ga-publication-viewer js-publication-item-fulltext-content" href="publication/278332447_MCMC_for_Variationally_Sparse_Gaussian_Processes">       </a>   <div class="preview-source-info"> <a class="details js-show-source ga-source-url" href="profile/Maurizio_Filippone" >Source</a>  <div class="tooltip-content" style="display: none"> Available from: Maurizio Filippone </div> </div>   </div>  </div>  <div class="indent-right">      </div>   <div  style="margin-top: -2px">  <h5 class="pub-type-and-title">  <span class="publication-type">Article:</span>    <a class="js-publication-title-link js-go-to-publication ga-publication-item" href="publication/278332447_MCMC_for_Variationally_Sparse_Gaussian_Processes"> <span class="publication-title js-publication-title">MCMC for Variationally Sparse Gaussian Processes</span> </a>     </h5>  </div>    <div class="authors">     <a href="researcher/71410443_James_Hensman" class="authors js-author-name ga-publications-authors">James Hensman</a> &middot;     <a href="researcher/2048369253_Alexander_G_de_G_Matthews" class="authors js-author-name ga-publications-authors">Alexander G. de G. Matthews</a> &middot;     <a href="researcher/70871340_Maurizio_Filippone" class="authors js-author-name ga-publications-authors">Maurizio Filippone</a> &middot;     <a href="researcher/8159937_Zoubin_Ghahramani" class="authors js-author-name ga-publications-authors">Zoubin Ghahramani</a>      </div>        <div class="abstract"> <span class="shorten"> <a href="javascript:" class="js-toggle-abstract">[Show abstract]</a> </span> <span class="full"> <a href="javascript:" class="js-toggle-abstract">[Hide abstract]</a><br/>  <strong>ABSTRACT:</strong> Gaussian process (GP) models form a core part of probabilistic machine
learning. Considerable research effort has been made into attacking three
issues with GP models: how to compute efficiently when the number of data is
large; how to approximate the posterior when the likelihood is not Gaussian and
how to estimate covariance function parameter posteriors. This paper
simultaneously addresses these, using a variational approximation to the
posterior which is sparse in support of the function but otherwise free-form.
The result is a Hybrid Monte-Carlo sampling scheme which allows for a
non-Gaussian approximation over the function values and covariance parameters
simultaneously, with efficient computations based on inducing-point sparse GPs.
Code to replicate each experiment in this paper will be available shortly. </span> </div>    <div class="publication-meta publication-meta">   <span class="ico-publication-fulltext reset-background"></span> Full-text   &middot; Article &middot; Jun 2015  </div>        <div class="publication-actions"> <div class="btn-group">  <a class="btn btn-plain action-download primary  open-viewer" href="profile/Maurizio_Filippone/publication/278332447_MCMC_for_Variationally_Sparse_Gaussian_Processes/links/558a857008aee1fc9174ea84.pdf?origin=publication_list">  <span class="js-btn-label">Download</span> </a>    </div> </div>      </li>  </ul>    <div class="clearfix"></div>  </div> </div> </div> </div> </div> </div> <div class="clearfix">     <div id="rgw27_56ab1e25595c3" class="c-box pub-resource-container js-toggle" style="display: none;"> <h4 class="lf js-expand-list"><small><a href="javascript:" class="lf">View other sources <span class="ico-expand-list"></span></a></small></h4> <h4 class="lf js-collapse-list hidden"><small><a href="javascript:" class="lf">Hide other sources <span class="ico-collapse-list"></span></a></small></h4> <div class="clear"></div> <div class="scroll-wrapper hidden"> <ul class="files-list c-list" id="rgw28_56ab1e25595c3">  </ul> </div> </div>   <div id="rgw18_56ab1e25595c3" class="similar-publications"> <h2>Similar Publications</h2> <ul class="list-bordered">  <li class="c-list-item li-publication-teaser" id="rgw19_56ab1e25595c3"> <div> <h5> <a href="publication/281312399_Decomposition_and_limit_theorems_for_a_class_of_self-similar_Gaussian_processes" class="color-inherit ga-similar-publication-title"><span class="publication-title">Decomposition and limit theorems for a class of self-similar Gaussian processes</span></a>  </h5>  <div class="authors"> <a href="researcher/59250530_Daniel_Harnett" class="authors ga-similar-publication-author">Daniel Harnett</a>, <a href="researcher/2024270470_David_Nualart" class="authors ga-similar-publication-author">David Nualart</a>  </div>  </div> <div class="clear"></div> </li>  <li class="c-list-item li-publication-teaser" id="rgw20_56ab1e25595c3"> <div> <h5> <a href="publication/282623866_The_uniqueness_of_signature_problem_in_the_non-Markov_setting" class="color-inherit ga-similar-publication-title"><span class="publication-title">The uniqueness of signature problem in the non-Markov setting</span></a>  </h5>  <div class="authors"> <a href="researcher/2045104220_H_Boedihardjo" class="authors ga-similar-publication-author">H. Boedihardjo</a>, <a href="researcher/2029977261_X_Geng" class="authors ga-similar-publication-author">X. Geng</a>  </div>  </div> <div class="clear"></div> </li>  <li class="c-list-item li-publication-teaser" id="rgw21_56ab1e25595c3"> <div> <h5> <a href="publication/280772850_Ergodicity_breaking_in_random_media_and_the_foundation_of_fractional_kinetics" class="color-inherit ga-similar-publication-title"><span class="publication-title">Ergodicity breaking in random media and the foundation of fractional kinetics</span></a>  </h5>  <div class="authors"> <a href="researcher/13328041_Gianni_Pagnini" class="authors ga-similar-publication-author">Gianni Pagnini</a>, <a href="researcher/2061240306_Daniel_Molina-Garcia" class="authors ga-similar-publication-author">Daniel Molina-García</a>, <a href="researcher/2079188896_Carlo_Manzo" class="authors ga-similar-publication-author">Carlo Manzo</a>, <a href="researcher/71787130_Paolo_Paradisi" class="authors ga-similar-publication-author">Paolo Paradisi</a>  </div>  </div> <div class="clear"></div> </li>  </ul> </div> </div> </div> </div> </div></div></div>
<div class="clear"></div><div id="rgw45_56ab1e25595c3" class="default-footer"> <div id="footer" class="clearfix"> <span class="footer-left"> &copy; 2008&dash;2016 researchgate.net. All rights reserved. </span> <span class="footer-right"> <a href="https://www.researchgate.net/about">About us</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="https://www.researchgate.net/contact">Contact us</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="careers">Careers</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="developers">Developers</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="blog" target="_blank">News</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="application.PrivacyPolicy.html">Privacy</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="application.TermsAndConditions.html">Terms</a> <span class="footer-link-separator" style="padding: 0 5px;">&nbsp;|&nbsp;</span> <a href="advertising?_ref=ft">Advertising</a> <span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="recruiters?_ref=ft">Recruiting</a> </span> </div>  </div></div>
<div id="rgw46_56ab1e25595c3">  <div class="header-wrapper-logged-out"> <div id="header"> <div class="header-content"> <a href="" class="g-l-logo"> <svg width="149" height="19"> <image xlink:href="https://c5.rgstatic.net/m/235107188705592/images/template/brand-header-logo.svg" src="https://c5.rgstatic.net/m/238113351022438/images/template/brand-header-logo.png" width="149" height="19"/> </svg> </a> <a href="" class="g-l-logo-ico"> <svg width="127" height="17" viewbox="0 0 127 22"> <image xlink:href="https://c5.rgstatic.net/m/235107188705592/images/template/brand-header-logo.svg" src="https://c5.rgstatic.net/m/238113351022438/images/template/brand-header-logo.png" width="127" height="17"/> </svg> </a> <div id="rgw47_56ab1e25595c3" class="header-login-wrapper js-header-login"> <div class="dropdown-right-align"> <div class="login-signup-container lf"> <a href="https://www.researchgate.net/signup.SignUp.html?ev=su_chnl_index&amp;hdrsu=1&amp;_sg=eF6qyvSZeL_yLxxaX8f8YqJvMoTofOGGvIFhE2vyLHoi5to8ZLEkdGLczTvtXuTV" class="dropdown-toggle lf">Join for free</a> </div> <div class="dropdown lf" style="height: 20px;"> <a href="https://www.researchgate.net/application.Login.html" class="js-login-url dropdown-toggle lf">Log in <span class="caret"></span></a> <div class="dropdown-menu"> <div class="header-login-form-wrapper"> <!--[if IE 6]><p class="box-warning" style="margin-bottom: 0;">Sorry, ResearchGate no longer supports the version of Internet Explorer you are using. <a href="http://whatbrowser.org/" rel="nofollow" target="_blank">Update your web browser</a> and then log in. </p><![endif]--> <form method="post" action="https://www.researchgate.net/application.Login.html" class="form-big header-login-form js-login-form" name="loginForm" id="headerLoginForm"> <input type="hidden" name="request_token" value="KacwHk18/uaAEieAhZXwrGkQUjWmSKOYzlNd/J1UMgqjZZuD4zgwYTiYa+Qh1P+fr/MvSdTFVL5UwqXeAkiBmilkA1PWayS7R69S1WuJKYKA2ttma9zSy8Wz6MpabyAKVjK9WGiUcUX6LJLLBXchOdlaaRHszoLEwgIjWonWIZSVYwobQj05UxuGyuTb5Cht9BYpyrqwfhBC1tPvOu1gKHx76XuUoMRYMK1Lwz403/KRLJkKez0xONpB6XA/W5CpqXxlO7NQWWRCcmgxIddZK0k4dqLgjmFaklWxEIGOe3I="/> <input type="hidden" name="urlAfterLogin" value="publication/275588150_On_Sparse_variational_methods_and_the_Kullback-Leibler_divergence_between_stochastic_processes"/> <input type="hidden" name="invalidPasswordCount" value="0"/> <input type="hidden" name="headerLogin" value="yes"/> <label for="input-header-login">Email</label> <div class="login-input"> <div class="info-tip-wrapper"> <span class="ico-info js-info"></span> </div> <input type="email" value="" name="login" class="login js-login-input text" id="input-header-login" tabindex="1"/> </div> <div class="clear"></div> <label class="lf" for="input-header-password"> Password </label> <a class="rf forgot-password js-forgot-password" href="application.LostPassword.html">Forgot password?</a> <div class="clear"></div> <input type="password" value="" name="password" class="password js-password-input text" id="input-header-password" tabindex="2"/> <div class="clear"></div> <label class="remember-me" for="headerLoginCookie"> <input type="checkbox" checked="checked" value="yes" name="setLoginCookie" class="lf checkbox" id="headerLoginCookie" tabindex="3"/> Keep me logged in </label> <div class="clear"></div> <input value="Log in" name="loginSubmit" class="btn btn-promote btn-fullwidth btn-large allow-leave js-submit-button" type="submit" tabindex="4"/> </form> <div class="connectors"> <div class="text">or log in with</div> <div class="connector-actions"> <a href="connector/linkedin/" class="li-connect js-li-connect" data-redirect-url="cHVibGljYXRpb24vMjc1NTg4MTUwX09uX1NwYXJzZV92YXJpYXRpb25hbF9tZXRob2RzX2FuZF90aGVfS3VsbGJhY2stTGVpYmxlcl9kaXZlcmdlbmNlX2JldHdlZW5fc3RvY2hhc3RpY19wcm9jZXNzZXM%3D"> <span class="icon ico-linkedin-round-grey"></span> <span class="icon ico-linkedin-round"></span> </a> <a href="connector/facebook/" class="fb-connect middle js-fb-connect" data-redirect-url="cHVibGljYXRpb24vMjc1NTg4MTUwX09uX1NwYXJzZV92YXJpYXRpb25hbF9tZXRob2RzX2FuZF90aGVfS3VsbGJhY2stTGVpYmxlcl9kaXZlcmdlbmNlX2JldHdlZW5fc3RvY2hhc3RpY19wcm9jZXNzZXM%3D"> <span class="icon ico-facebook-round-grey"></span> <span class="icon ico-facebook-round"></span> </a> <a href="connector/google/" class="g-connect js-g-connect" data-redirect-url="cHVibGljYXRpb24vMjc1NTg4MTUwX09uX1NwYXJzZV92YXJpYXRpb25hbF9tZXRob2RzX2FuZF90aGVfS3VsbGJhY2stTGVpYmxlcl9kaXZlcmdlbmNlX2JldHdlZW5fc3RvY2hhc3RpY19wcm9jZXNzZXM%3D"> <span class="icon ico-google-round-grey"></span> <span class="icon ico-google-round"></span> </a> </div> </div> </div> </div> </div> </div> </div> </div> </div> <script type="application/ld+json">
{ "@context" : "http://schema.org",
  "@type" : "Organization",
  "name" : "ResearchGate",
  "url" : "http://www.researchgate.net",
  "logo" : "http://www.researchgate.net/images/template/rg_logo_square_brand.png",
  "sameAs" : [ "https://www.facebook.com/ResearchGate",
    "https://twitter.com/ResearchGate",
    "https://plus.google.com/+researchgate",
    "https://www.linkedin.com/company/researchgate"] 
}
</script> </div> </div><div class="c-signup-bar" id="rgw48_56ab1e25595c3"> <div class="banner-contents">   <span class="message">ResearchGate is the professional network for scientists and researchers.</span> <a href="signup.SignUp.html?ev=su_banner" class="btn btn-large btn-promote">Join for free</a>  </div> </div></div>
<script>
rgConfig.backendTime = 728;
</script>
<script src="//c5.rgstatic.net/m/2277196935388619/javascript/lib/yui3/yui/yui-min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/2448732603281275/javascript/yuiLoaderConfig-min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/23178613132105398/javascript/vendor/babel-core/browser-polyfill.min.js" type="text/javascript"></script>
<script>
(function (){
if (typeof YRG === "undefined") {
var xmlHttpRequest = new XMLHttpRequest();
xmlHttpRequest.open("post", "go.Error.html");
xmlHttpRequest.setRequestHeader("Content-Type", "application/json");
xmlHttpRequest.setRequestHeader("Accept", "application/json"); var loadedScripts = "";
if (window.performance && window.performance.getEntriesByType) {
    var result = [];
    var resources = performance.getEntriesByType("resource");
    for (var i in resources) {
        if (resources.hasOwnProperty(i)) {
            result.push({
                name: resources[i].name,
                duration: resources[i].duration
            });
        }
    }
    loadedScripts += "&loadedScripts=" + encodeURIComponent(JSON.stringify(result));
}
if (typeof YUI === "undefined") {
    loadedScripts += "&yuiLoaded=false";
} else {
    loadedScripts += "&yuiLoaded=true";
}
xmlHttpRequest.send("Type=InformationException&message=" + encodeURIComponent("Error loading YUI") + loadedScripts);
}
})();
</script>
<script>if (typeof YRG !== 'undefined') { YRG.use('rg-base',function(Y){Y.applyConfig({ignore: ["css-rg","css-rg2","css-ie","css-modules-publicprofile","css-pow-publicliterature-FollowPublicationPromo","css-pow-application-PdfJsReader","css-pow-publicliterature-PublicationInlineReader"]});Y.use(["rg.core.pagespeed.Monitoring"],function(Y){(function(){Y.rg.createInitialWidget({"data":{"content":{"data":{"profileSmallHeader":{"data":{"profileBadge":{"data":{"fullname":"James Hensman","imageUrl":"https:\/\/i1.rgstatic.net\/ii\/profile.image\/AS%3A277099177889798%401443077000994_m","profileStats":[],"profileFollowButton":null,"profileReputationScoreNumber":null,"profileUrl":"profile\/James_Hensman","institution":"Lancaster University","institutionUrl":false,"widgetId":"rgw4_56ab1e25595c3"},"id":"rgw4_56ab1e25595c3","partials":[],"templateName":"publicprofile\/stubs\/ProfileBadge.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicprofile.ProfileBadge.html?accountId=3686694","viewClass":null,"yuiModules":["css-modules-publicprofile"],"stylesheets":["modules\/publicprofile.css"],"_isYUI":true},"widgetId":"rgw3_56ab1e25595c3"},"id":"rgw3_56ab1e25595c3","partials":[],"templateName":"publicprofile\/stubs\/ProfileSmallHeader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicprofile.ProfileSmallHeader.html?publicationUid=275588150","viewClass":null,"yuiModules":["css-modules-publicprofile"],"stylesheets":["modules\/publicprofile.css"],"_isYUI":true},"publication":{"data":{"publicationUid":275588150,"title":"On Sparse variational methods and the Kullback-Leibler divergence between stochastic processes","journalTitle":false,"journalDetailsTooltip":false,"affiliation":false,"type":"Article","details":{"journalInfos":{"journal":"","publicationDate":"04\/2015;","publicationDateRobot":"2015-04","article":""}},"source":{"sourceUrl":"http:\/\/arxiv.org\/abs\/1504.07027","sourceName":"arXiv"},"publicationActions":null,"publicationCoins":{"data":{"tags":[{"key":"ctx_ver","value":"Z39.88-2004"},{"key":"rft_val_fmt","value":"info:ofi\/fmt:kev:mtx:journal"},{"key":"rfr_id","value":"info:sid\/researchgate.net:researchgate"},{"key":"rft.atitle","value":"On Sparse variational methods and the Kullback-Leibler divergence between stochastic processes"},{"key":"rft.date","value":"2015"},{"key":"rft.au","value":"Alexander G. de G. Matthews,James Hensman,Richard E. Turner,Zoubin Ghahramani"},{"key":"rft.genre","value":"article"}],"widgetId":"rgw6_56ab1e25595c3"},"id":"rgw6_56ab1e25595c3","partials":[],"templateName":"publicliterature\/stubs\/PublicationCoins.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationCoins.html?publicationUid=275588150","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationAuthors":{"data":{"publicationUid":275588150,"peopleItems":[{"data":{"authorUrl":"researcher\/2048369253_Alexander_G_de_G_Matthews","authorNameOnPublication":"Alexander G. de G. Matthews","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg","imageSize":"s","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Alexander G. de G. Matthews","profile":{"professionalInstitution":{"professionalInstitutionName":false,"professionalInstitutionUrl":null}},"professionalInstitutionName":false,"professionalInstitutionUrl":null,"url":"researcher\/2048369253_Alexander_G_de_G_Matthews","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":true,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":false,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"widgetId":"rgw9_56ab1e25595c3"},"id":"rgw9_56ab1e25595c3","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAuthorItem.html?entityId=2048369253&imageSize=l&enableAuthorInviteButton=0","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"largeTooltip":false,"useRebrandedImageStyle":null,"widgetId":"rgw8_56ab1e25595c3"},"id":"rgw8_56ab1e25595c3","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorItem.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorItem.html?authorUid=2048369253&authorNameOnPublication=Alexander%20G.%20de%20G.%20Matthews","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true},{"data":{"authorNameOnPublication":"James Hensman","accountUrl":"profile\/James_Hensman","accountKey":"James_Hensman","imageUrl":"https:\/\/i1.rgstatic.net\/ii\/profile.image\/AS%3A277099177889798%401443077000994_m","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"James Hensman","profile":{"professionalInstitution":{"professionalInstitutionName":"Lancaster University","professionalInstitutionUrl":"institution\/Lancaster_University"}},"professionalInstitutionName":"Lancaster University","professionalInstitutionUrl":"institution\/Lancaster_University","url":"profile\/James_Hensman","imageUrl":"https:\/\/i1.rgstatic.net\/ii\/profile.image\/AS%3A277099177889798%401443077000994_l","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":false,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":true,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"accountKey":"James_Hensman","hasInfoPopup":false,"hasTeaserPopup":true,"showContactAuthorButton":true,"widgetId":"rgw11_56ab1e25595c3"},"id":"rgw11_56ab1e25595c3","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAccountItem.html?entityId=3686694&enableUnfollow=0&imageSize=l&enableFollowButton=0&showContactAuthorButton=1","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"accountInstitution":"Lancaster University","score":null,"largeTooltip":false,"useRebrandedImageStyle":null,"authorCount":4,"accountCount":2,"publicationUid":275588150,"widgetId":"rgw10_56ab1e25595c3"},"id":"rgw10_56ab1e25595c3","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAccountItem.html","templateExtensions":[],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAccountItem.html?accountId=3686694&context=pubdetail_authors_xflw&showContactAuthorButton=1&authorCount=4&accountCount=2&publicationUid=275588150","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true},{"data":{"authorNameOnPublication":"Richard E. Turner","accountUrl":"profile\/Richard_Turner18","accountKey":"Richard_Turner18","imageUrl":"https:\/\/i1.rgstatic.net\/ii\/profile.image\/AS%3A279424772657156%401443631465203_m\/Richard_Turner18.png","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Richard E. Turner","profile":{"professionalInstitution":{"professionalInstitutionName":"University of Cambridge","professionalInstitutionUrl":"institution\/University_of_Cambridge"}},"professionalInstitutionName":"University of Cambridge","professionalInstitutionUrl":"institution\/University_of_Cambridge","url":"profile\/Richard_Turner18","imageUrl":"https:\/\/i1.rgstatic.net\/ii\/profile.image\/AS%3A279424772657156%401443631465203_l\/Richard_Turner18.png","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":false,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":true,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"accountKey":"Richard_Turner18","hasInfoPopup":false,"hasTeaserPopup":true,"showContactAuthorButton":true,"widgetId":"rgw13_56ab1e25595c3"},"id":"rgw13_56ab1e25595c3","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAccountItem.html?entityId=6978466&enableUnfollow=0&imageSize=l&enableFollowButton=0&showContactAuthorButton=1","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"accountInstitution":"University of Cambridge","score":null,"largeTooltip":false,"useRebrandedImageStyle":null,"authorCount":4,"accountCount":2,"publicationUid":275588150,"widgetId":"rgw12_56ab1e25595c3"},"id":"rgw12_56ab1e25595c3","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAccountItem.html","templateExtensions":[],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAccountItem.html?accountId=6978466&context=pubdetail_authors_xflw&showContactAuthorButton=1&authorCount=4&accountCount=2&publicationUid=275588150","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true},{"data":{"authorUrl":"researcher\/8159937_Zoubin_Ghahramani","authorNameOnPublication":"Zoubin Ghahramani","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg","imageSize":"s","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Zoubin Ghahramani","profile":{"professionalInstitution":{"professionalInstitutionName":false,"professionalInstitutionUrl":null}},"professionalInstitutionName":false,"professionalInstitutionUrl":null,"url":"researcher\/8159937_Zoubin_Ghahramani","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":true,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":false,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"widgetId":"rgw15_56ab1e25595c3"},"id":"rgw15_56ab1e25595c3","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAuthorItem.html?entityId=8159937&imageSize=l&enableAuthorInviteButton=0","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"largeTooltip":false,"useRebrandedImageStyle":null,"widgetId":"rgw14_56ab1e25595c3"},"id":"rgw14_56ab1e25595c3","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorItem.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorItem.html?authorUid=8159937&authorNameOnPublication=Zoubin%20Ghahramani","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true}],"hasMore":false,"nextOffset":6,"useRebrandedImageStyle":null,"widgetId":"rgw7_56ab1e25595c3"},"id":"rgw7_56ab1e25595c3","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorList.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorList.html?publicationUid=275588150&context=pubdetail_authors_xflw&showContactAuthorButton=1","viewClass":"views.publicliterature.PublicationDetailAuthorListView","yuiModules":["rg.views.publicliterature.PublicationDetailAuthorListView"],"stylesheets":[],"_isYUI":true},"publicationAbstract":{"data":{"publicationUid":275588150,"abstract":"<noscript><\/noscript><div>The variational framework for learning inducing variables Titsias (2009) has<br \/>\nhad a large impact on the Gaussian process literature. The framework may be<br \/>\ninterpreted as minimizing a rigorously defined Kullback-Leibler divergence<br \/>\nbetween the approximate and posterior processes. To our knowledge this<br \/>\nconnection has thus far gone unremarked in the literature. Many of the<br \/>\ntechnical requirements for such a result were derived in the pioneering work of<br \/>\nSeeger (2003,2003b). In this work we give a relatively gentle and largely<br \/>\nself-contained explanation of the result. The result is important in<br \/>\nunderstanding the variational inducing framework and could lead to principled<br \/>\nnovel generalizations.<\/div>","canEdit":false,"isAdmin":false,"isArtifact":false,"showFullAbstract":false,"widgetId":"rgw16_56ab1e25595c3"},"id":"rgw16_56ab1e25595c3","partials":[],"templateName":"publicliterature\/stubs\/PublicationAbstract.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationAbstract.html?publicationUid=275588150","viewClass":"views.publicliterature.PublicationAbstractView","yuiModules":["rg.views.publicliterature.PublicationAbstractView"],"stylesheets":[],"_isYUI":true},"publicationKeywords":null,"publicationState":null,"isGuest":true,"isAdminEditingAllowed":false,"isArtifact":false,"figureListWidget":null,"previewImage":"https:\/\/i1.rgstatic.net\/publication\/275588150_On_Sparse_variational_methods_and_the_Kullback-Leibler_divergence_between_stochastic_processes\/links\/55adfd8f08aed9b7dcdb08a0\/smallpreview.png","nativeAdDisclosure":null,"showFollowPublicationButton":false,"followPublicationPromo":{"data":{"widgetId":"rgw17_56ab1e25595c3"},"id":"rgw17_56ab1e25595c3","partials":[],"templateName":"publicliterature\/stubs\/FollowPublicationPromo.html","templateExtensions":[],"attrs":{"context":null,"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.FollowPublicationPromo.html","viewClass":null,"yuiModules":["css-pow-publicliterature-FollowPublicationPromo"],"stylesheets":["pow\/publicliterature\/FollowPublicationPromo.css"],"_isYUI":true},"widgetId":"rgw5_56ab1e25595c3"},"id":"rgw5_56ab1e25595c3","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailItem.html","templateExtensions":["generalHelpers"],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailItem.html?publicationUid=275588150&showActionBar=0&showContactAuthorButton=1&showRequestFulltextExperience=0&showNoRgAuthorsRequestFulltextExperience=0&showFollowPublicationPromo=1","viewClass":"views.publicliterature.PublicationDetailItemView","yuiModules":["rg.views.publicliterature.PublicationDetailItemView"],"stylesheets":[],"_isYUI":true},"similarPublications":{"data":{"publicationListItems":[{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore","clickThrough":"experimentMilestoneClickedToPublicationFromReferenceWithNoFulltext","clickThroughWithContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":59250530,"url":"researcher\/59250530_Daniel_Harnett","fullname":"Daniel Harnett","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2024270470,"url":"researcher\/2024270470_David_Nualart","fullname":"David Nualart","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Aug 2015","journal":null,"showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/281312399_Decomposition_and_limit_theorems_for_a_class_of_self-similar_Gaussian_processes","usePlainButton":true,"publicationUid":281312399,"feedStubs":null,"hasFeedStubs":false,"impactPoints":false,"url":"publication\/281312399_Decomposition_and_limit_theorems_for_a_class_of_self-similar_Gaussian_processes","title":"Decomposition and limit theorems for a class of self-similar Gaussian processes","displayTitleAsLink":true,"authors":[{"id":59250530,"url":"researcher\/59250530_Daniel_Harnett","fullname":"Daniel Harnett","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2024270470,"url":"researcher\/2024270470_David_Nualart","fullname":"David Nualart","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":[],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/281312399_Decomposition_and_limit_theorems_for_a_class_of_self-similar_Gaussian_processes","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/281312399_Decomposition_and_limit_theorems_for_a_class_of_self-similar_Gaussian_processes\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw19_56ab1e25595c3"},"id":"rgw19_56ab1e25595c3","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=281312399","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore","clickThrough":"experimentMilestoneClickedToPublicationFromReferenceWithNoFulltext","clickThroughWithContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":2045104220,"url":"researcher\/2045104220_H_Boedihardjo","fullname":"H. Boedihardjo","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2029977261,"url":"researcher\/2029977261_X_Geng","fullname":"X. Geng","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Aug 2015","journal":"Stochastic Processes and their Applications","showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/282623866_The_uniqueness_of_signature_problem_in_the_non-Markov_setting","usePlainButton":true,"publicationUid":282623866,"feedStubs":null,"hasFeedStubs":false,"impactPoints":"1.06","url":"publication\/282623866_The_uniqueness_of_signature_problem_in_the_non-Markov_setting","title":"The uniqueness of signature problem in the non-Markov setting","displayTitleAsLink":true,"authors":[{"id":2045104220,"url":"researcher\/2045104220_H_Boedihardjo","fullname":"H. Boedihardjo","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2029977261,"url":"researcher\/2029977261_X_Geng","fullname":"X. Geng","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["Stochastic Processes and their Applications 08\/2015; 125(12). DOI:10.1016\/j.spa.2015.07.012"],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/282623866_The_uniqueness_of_signature_problem_in_the_non-Markov_setting","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/282623866_The_uniqueness_of_signature_problem_in_the_non-Markov_setting\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw20_56ab1e25595c3"},"id":"rgw20_56ab1e25595c3","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=282623866","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore","clickThrough":"experimentMilestoneClickedToPublicationFromReferenceWithNoFulltext","clickThroughWithContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":13328041,"url":"researcher\/13328041_Gianni_Pagnini","fullname":"Gianni Pagnini","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2061240306,"url":"researcher\/2061240306_Daniel_Molina-Garcia","fullname":"Daniel Molina-Garc\u00eda","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2079188896,"url":"researcher\/2079188896_Carlo_Manzo","fullname":"Carlo Manzo","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":71787130,"url":"researcher\/71787130_Paolo_Paradisi","fullname":"Paolo Paradisi","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Aug 2015","journal":null,"showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/280772850_Ergodicity_breaking_in_random_media_and_the_foundation_of_fractional_kinetics","usePlainButton":true,"publicationUid":280772850,"feedStubs":null,"hasFeedStubs":false,"impactPoints":false,"url":"publication\/280772850_Ergodicity_breaking_in_random_media_and_the_foundation_of_fractional_kinetics","title":"Ergodicity breaking in random media and the foundation of fractional kinetics","displayTitleAsLink":true,"authors":[{"id":13328041,"url":"researcher\/13328041_Gianni_Pagnini","fullname":"Gianni Pagnini","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2061240306,"url":"researcher\/2061240306_Daniel_Molina-Garcia","fullname":"Daniel Molina-Garc\u00eda","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2079188896,"url":"researcher\/2079188896_Carlo_Manzo","fullname":"Carlo Manzo","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":71787130,"url":"researcher\/71787130_Paolo_Paradisi","fullname":"Paolo Paradisi","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":[],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/280772850_Ergodicity_breaking_in_random_media_and_the_foundation_of_fractional_kinetics","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/280772850_Ergodicity_breaking_in_random_media_and_the_foundation_of_fractional_kinetics\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw21_56ab1e25595c3"},"id":"rgw21_56ab1e25595c3","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=280772850","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"viewClass":"sidebar","widgetId":"rgw18_56ab1e25595c3"},"id":"rgw18_56ab1e25595c3","partials":[],"templateName":"publicliterature\/stubs\/SimilarPublications.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.SimilarPublications.html?referencePublicationId=275588150&view=sidebar","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationFulltextPreview":null,"publicationResourcesFulltext":{"data":{"publicationUid":275588150,"publicationResourceList":{"data":{"publicationResourceItems":[{"data":{"publicationUid":275588150,"publicationType":"article","linkId":"55adfd8f08aed9b7dcdb08a0","fileName":"55adfd8f08aed9b7dcdb08a0.pdf","fileUrl":"profile\/James_Hensman\/publication\/275588150_On_Sparse_variational_methods_and_the_Kullback-Leibler_divergence_between_stochastic_processes\/links\/55adfd8f08aed9b7dcdb08a0.pdf","name":"James Hensman","nameUrl":"profile\/James_Hensman","canRemove":false,"fileIcon":"ico-pub","canPreview":true,"hasPublisherLink":null,"hasMetaData":true,"hide":false,"fulltext":"ico-pub","origin":"publication_list","isLastLink":false,"isUserLink":true,"uploadDate":"Jul 21, 2015","fileSize":"144.53 KB","widgetId":"rgw24_56ab1e25595c3"},"id":"rgw24_56ab1e25595c3","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceItem.html","templateExtensions":["generalHelpers"],"attrs":{"fileRequiredPublicationTypes":["code","coverPage","experimentFindings","method","negativeResults","presentation","rawData","researchProposal","workingPaper","artifact","dataset"]},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceItem.html?publicationUid=275588150&linkId=55adfd8f08aed9b7dcdb08a0&hide=0&disableJavascript=disableJavascript&useAlternativeTemplate=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"publicationUid":275588150,"publicationType":"article","linkId":"5542c7c10cf23ff716836e14","fileName":"On Sparse variational methods and the Kullback-Leibler divergence between stochastic processes","fileUrl":"http:\/\/de.arxiv.org\/pdf\/1504.07027","name":"de.arxiv.org","nameUrl":"http:\/\/de.arxiv.org\/pdf\/1504.07027","canRemove":false,"fileIcon":"ico-pub","canPreview":true,"hasPublisherLink":null,"hasMetaData":true,"hide":false,"fulltext":"ico-pub","origin":"publication_list","isLastLink":false,"isUserLink":false,"widgetId":"rgw25_56ab1e25595c3"},"id":"rgw25_56ab1e25595c3","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceItem.html","templateExtensions":["generalHelpers"],"attrs":{"fileRequiredPublicationTypes":["code","coverPage","experimentFindings","method","negativeResults","presentation","rawData","researchProposal","workingPaper","artifact","dataset"]},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceItem.html?publicationUid=275588150&linkId=5542c7c10cf23ff716836e14&hide=0&disableJavascript=disableJavascript&useAlternativeTemplate=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"widgetId":"rgw23_56ab1e25595c3"},"id":"rgw23_56ab1e25595c3","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceList.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceList.html?publicationUid=275588150&limit=3&disableJavascript=disableJavascript&type=fulltextFile","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"resourceCount":2,"hidden":false,"showMore":false,"fulltext":true,"publicationDownloadCount":{"data":{"value":8,"valueFormatted":"8","widgetId":"rgw26_56ab1e25595c3"},"id":"rgw26_56ab1e25595c3","partials":[],"templateName":"publicliterature\/stubs\/PublicationDownloadCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDownloadCount.html?publicationUid=275588150","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw22_56ab1e25595c3"},"id":"rgw22_56ab1e25595c3","partials":[],"templateName":"publicliterature\/stubs\/PublicationResources.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResources.html?publicationUid=275588150&type=fulltextFile&disableJavascript=1","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationResourcesAttachments":{"data":{"publicationUid":275588150,"publicationResourceList":{"data":{"publicationResourceItems":[],"widgetId":"rgw28_56ab1e25595c3"},"id":"rgw28_56ab1e25595c3","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceList.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceList.html?publicationUid=275588150&limit=3&disableJavascript=disableJavascript&type=attachmentFile","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"resourceCount":0,"hidden":true,"showMore":false,"fulltext":false,"publicationDownloadCount":{"data":{"value":8,"valueFormatted":"8","widgetId":"rgw29_56ab1e25595c3"},"id":"rgw29_56ab1e25595c3","partials":[],"templateName":"publicliterature\/stubs\/PublicationDownloadCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDownloadCount.html?publicationUid=275588150","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw27_56ab1e25595c3"},"id":"rgw27_56ab1e25595c3","partials":[],"templateName":"publicliterature\/stubs\/PublicationResources.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResources.html?publicationUid=275588150&type=attachmentFile","viewClass":"views.publicliterature.PublicationResourcesView","yuiModules":["rg.views.publicliterature.PublicationResourcesView"],"stylesheets":[],"_isYUI":true},"publicationText":{"data":{"hide":false,"pages":[{"page":1,"text":"arXiv:1504.07027v1  [stat.ML]  27 Apr 2015\nOn Sparse variational methods and the Kullback-Leibler divergence\nbetween stochastic processes\nAlexander G. de G. Matthews1, James Hensman2, Richard E. Turner1, Zoubin Ghahramani1\n1University of Cambridge,2University of Sheffield\nApril 30, 2015\nAbstract\nThe variational framework for learning inducing variables (Titsias, 2009) has had a large impact on the\nGaussian process literature. The framework may be interpreted as minimizing a rigorously defined Kullback-\nLeibler divergence between the approximate and posterior processes. To our knowledge this connection has thus\nfar gone unremarked in the literature. Many of the technical requirements for such a result were derived in the\npioneering work of Seeger (2003a; 2003b). In this work we give a relatively gentle and largely self-contained\nexplanation of the result. The result is important in understanding the variational inducing framework and could\nlead to principled novel generalizations.\n1 Introduction\nThe variational approach to inducing point selection of Titsias (2009) has been highly influential in the active\nresearch area of scalable Gaussian process approximations. The chief advantage of this particular framework is that\nthe inducing points positions are variational parameters rather than models parameters and as such are protected\nfrom overfitting. The original framework is applied to conjugate likelihoods and has been extended to non-conjugate\nlikelihoods (Chai, 2012; Hensman et al., 2015). An important advance in the use of variational methods was their\ncombination with stochastic gradient descent (Hoffman et al., 2013) and the variational inducing point framework has\nbeen combined with such methods in the conjugate (Hensman et al., 2013) and non-conjugate cases (Hensman et al.,\n2015).\nThe approach has also been successfully used to perform scalable inference in more complex models such as the\nGaussian process latent variable model (Titsias and Lawrence, 2010; Damianou et al., 2014) and the related Deep\nGaussian process (Damianou and Lawrence, 2012; Hensman and Lawrence, 2014).\nTo be more concrete let us setup some notation, consider a function f mapping an index set X to the set of real\nnumbers\nf : X ?\u2192 R.\n(1)\nEntirely equivalently we may write f \u2208 RXor use sequence notation (f(x))x\u2208X.\nWe also define set indexing of the function. If S \u2286 X is some subset of the index set then\nfS:= (f(x))x\u2208S\n(2)\nand we may straightforwardly extend this definition to single elements of the index set fx:= f{x}. We can put this\nnotation to immediate use by defining a subset D \u2286 X of the index set, of size N, that corresponds to those input\npoints for which we have observed data. The corresponding function values will then be denoted fD. For simplicity\nwe will assume that we have one, possibly noisy, possibly non-conjugate observation y per input data point which\nwill together form a set Y .\n1"},{"page":2,"text":"Gaussian processes allow us to define a prior over functions f. After we observe the data we will have some\nposterior which we wish to approximate with a sparse distribution. At the heart of the variational inducing point\napproximation is the idea of \u2018augmentation\u2019 that appears in the original paper and many subsequent ones. We choose\nto monitor a set Z \u2286 X of size M. These points may have some overlap with the input data points D but to give a\ncomputational speed up M will need to be less than the number of data points N. The Kullback-Leibler divergence\ngiven as an optimization criterion in Titsias\u2019 original paper is\nKL[q(fD\\Z,fZ)||p(fD\\Z,fZ|Y )]\n?\n=\n?\nq(fD\\Z,fZ)log\nq(fD\\Z,fZ)\np(fD\\Z,fZ|Y )\n?\ndfD\\ZdfZ\n(3)\nThe variational distribution at those data points which are not also inducing points is taken to have the form:\nq(fD\\Z,fZ) := p(fD\\Z|fZ)q(fZ) (4)\nwhere p(fD\\Z|fZ) is the prior conditional and q(fZ) is a variational distribution on the inducing points only. Under\nthis factorization, for a conjugate likelihood, the optimal q(fZ) has an analytic Gaussian solution (Titsias, 2009).\nThe non-conjugate case was then studied in subsequent work (Chai, 2012; Hensman et al., 2015). In both cases the\nsparse approximation requires only O(NM2) rather than the O(N3) required by exact methods in the conjugate\ncase or many commonly used non-conjugate approximations that don\u2019t assume sparsity.\nThe augmentation is justified by arguing that the model remains marginally the same when the inducing points\nare added. Thus the inducing point positions can be considered to be variational parameters and are consequently\nprotected from overfitting.\nWithout this justification, however, the KL-divergence in equation could seem to be a strange optimization target.\nThe KL-divergence has the inducing variables on both sides. Thus it might seem that in optimizing the inducing\npoint positions we are trying to hit a \u2018moving target\u2019. It would thus seem desirable to rigorously formulate a \u2018one\nsided\u2019 KL-divergence that leads to Titsias\u2019 formulation. Such a derivation could be viewed as a rigorous mathematical\nproof of the augmentation argument and could help correctly generalize this elegant framework. Such a derivation\nis the topic of this article. As we shall see it requires some fairly technical mathematical machinery which will also\nbe elucidated from the various necessary sources.\nIn terms of existing work the major other references are the early work of Seeger (2003a; 2003b). In particular\nSeeger identifies the KL-divergence between processes (more commonly referred to as a relative entropy in those\ntexts) as a measure of similarity and applies it to PAC-Bayes and to subset of data sparse methods. Crucially Seeger\noutlines the rigorous formulation of such a KL-divergence which is a large technical obstacle. The explanation of\nthis point is somewhat distributed over the work and its references. One of the aims of this article is to pull a large\nproportion of the necessary knowledge together and to give more detail where helpful or expedient. Further, we\nextend the stochastic process formulation to inducing points which are not necessarily selected from the data and\nshow that this is equivalent to Titsias\u2019 formulation. In so far as we are aware this relationship has not previously\nbeen noted in the literature. The idea of using the KL-divergence between processes is also mentioned in the early\nwork of Csato and Opper (2002; 2002) but the transition from finite dimensional multivariate Gaussians to infinite\ndimensional Gaussian processes is not covered at the level of detail discussed here. An optimization target that in\nintent seems to be similar to a KL-divergence between stochastic process is briefly mentioned in the work of Alvarez\n(2011). The notation used suggests that the integration is with respect to an \u2018infinite dimensional dimensional\nLebesgue measure\u2019, which as we shall see is an argument that arrives at the right answer via a mathematically flawed\nroute. Chai (2012) seems to have been at least partly aware of Seeger\u2019s KL-divergence theorems (Seeger, 2003b) but\ninstead uses them to bound the finite joint predictive probability of a non sparse process.\nThis article proceeds by first discussing the finite dimensional version of the full argument. This requires consid-\nerably less mathematical machinery and much of the intuition can be gained from this case. After reviewing some of\nthe mathematical background we then proceed to give the full measure theoretic formulation. Finally we conclude.\n2"},{"page":3,"text":"2Finite index set case\nConsider the case where X if finite. We introduce a new set \u2217 := X\\(D \u222a Z), in words: all points that are in the\nindex set that aren\u2019t inducing points or data points. These points might be of practical interest for instance when\nmaking predictions on hold out data.\nWe extend the variational distribution to include these points:\nq(f\u2217,fD\\Z,fZ) := p(f\u2217,fD\\Z|fZ)q(fZ).\n(5)\nWe then consider the KL-divergence between this extended variational distribution and the full posterior distri-\nbution p(f|Y )\nKL[q(f\u2217,fD\\Z,fZ)||p(f|Y )]\n=KL[q(f\u2217,fD\\Z,fZ)||p(f\u2217,fD\\Z,fZ|Y )]\n?\n=\nq(f\u2217,fD\\Z,fZ)log\nq(f\u2217,fD\\Z,fZ)\np(f\u2217,fD\\Z,fZ|Y )df\u2217dfD\\ZdfZ\n(6)\nNow we substitute the definitions of q(f\u2217,fD\\Z,fZ) and p(f\u2217,fD\\Z,fZ|Y ) in terms of conditional distributions\ninto the integral, observing some cancellation:\n=\n?\np(f\u2217,fD\\Z|fZ)q(fZ)log\n?\np(f\u2217|fD\\Z,fZ)p(fD\\Z|fZ)q(fZ)p(Y )\np(f\u2217|fD\\Z,fZ)p(fD\\Z|fZ)p(fZ)p(Y |fD)\np(fD\\Z|fZ)q(fZ)p(Y )\np(fD\\Z|fZ)p(fZ)p(Y |fD)\n?\ndf\u2217dfD\\ZdfZ\n=\n?\np(f\u2217,fD\\Z|fZ)q(fZ)log\n?\n?\ndf\u2217dfD\\ZdfZ\n(7)\n(8)\nNext we exploit the marginalization property of the Gaussian process:\n=\n?\np(fD\\Z|fZ)q(fZ)log\n?\np(fD\\Z|fZ)q(fZ)p(Y )\np(fD\\Z|fZ)p(fZ)p(Y |fD)\nq(fD\\Z,fZ)\np(fD\\Z,fZ|Y )\n?\ndfD\\ZdfZ\n(9)\n=\n?\nq(fD\\Z,fZ)log\n?\n?\ndfD\\ZdfZ\n(10)\n(11)\nThe last line is exactly the KL-divergence used by Titsias (2009) that we already described in equation 3. We thus\nsee that for finite index sets considering the KL-divergence between the two distributions is equivalent to Titsias\u2019\nKL-divergence.\nWe might choose to optimize our choice of the M by selecting them from the |X| possible values in the index set\nand comparing the KL-divergence between distributions given in equation 6. The equivalence with equation 3 that\nwe have just derived shows us that in this case the appearance of the inducing values on both sides of the equation\nis just a question of \u2018accounting\u2019. That is to say whilst we are in fact optimizing the KL-divergence between the full\ndistributions, we only need to keep track of the distribution over function values fZand fD\\Z. All the other function\nvalues f\u2217marginalize. For different choices of inducing points we will need to keep track of different function values\nand be able to safely ignore different values f\u2217.\n3Infinite index set case\n3.1 There is no useful infinite dimensional Lebesgue measure\nOne might hope to cope with not only finite index sets but also infinite index sets in the way discussed in section\n2. Unfortunately when X and hence f\u2217are infinite sets we cannot integrate with respect to a \u2018infinite dimensional\nvector\u2019. That is to say the notation?(\u00b7)df\u2217can no longer be correctly used.\n3"},{"page":4,"text":"For a discussion of this see, for example, Hunt et al (1992). The crux of the issue is that to give sensible answers\nsuch a measure would need to be translation invariant and locally finite. Unfortunately the only measure that obeys\nthese two properties is the zero measure which assigns zero to every input set.\nThus we see that it will be necessary to rethink our approach to a KL-divergence between stochastic processes.\nIt will turn out that a reasonable definition will require the full apparatus of measure theory.\n3.2Measure spaces and Lebesgue integral.\nIn this section we discuss the fundamental definitions in measure theory. Readers familiar with this material may\nsafely skip to the next section, although they may wish to review the notation used. Readers looking for a fuller\nexposition may wish to consult a textbook (Billingsley, 1995; Capinski and Kopp, 2004).\nA \u03c3-algebra \u03a3 on a set \u03a9 is a set of subsets E of \u03a9 that obey the following axioms:\n1. It contains the full set. \u03a9 \u2208 \u03a3\n2. It is closed under complementation. E \u2208 \u03a3 =\u21d2 \u03a9\\E \u2208 \u03a3\n3. It is closed under countable unions. Ei\u2208 \u03a3, i \u2208 I \u2286 N =\u21d2\n?\ni\u2208I\nEi\u2208 \u03a3\nConsider a set of subsets G of \u03a9 which is not necessarily a \u03c3-algebra. The \u03c3-algebra generated by G is the unique\nsmallest \u03c3-algebra containing every element of G. It is denoted \u03c3(G). As an example of such a generated \u03c3-algebra\nwe give the Borel \u03c3-algebra B on the real numbers R which is generated by the set of all open intervals (a,b) of the\nreal line. The Borel \u03c3-algebra may be extended to multiple dimensions.\nA measure is a function mapping elements of a \u03c3-algebra, \u03a3, to the extended real number line R \u222a {\u221e,\u2212\u221e}. It\nobeys the following axioms:\n1. It is non-negative. \u2200E \u2208 \u03a3, \u00b5(E) \u2265 0\n2. The measure of the empty set \u2205 is zero. \u00b5(\u2205) = 0\n3. The measure is countably additive. For I \u2286 N, \u00b5(?\nIt is possible to extend this definition to signed measures but we will not require this in what follows. A probability\nmeasure is a measure for which \u00b5(\u03a9) = 1. The triple (\u03a9,\u03a3,\u00b5) is called a measure space.\nGiven two \u03c3-algebras on two different sets, namely \u03a31on \u03a91and \u03a32on \u03a92a function g : \u03a91?\u2192 \u03a92is called a\nmeasurable function if for any set E \u2208 \u03a32the pre-image of that set g\u22121(E) = {\u03c9 \u2208 \u03a91: g(\u03c9) \u2208 \u03a32} is a member of\n\u03a31.\nIn all cases that we discuss in the text the range of the function of interest \u03a92will be the set of real numbers\nR and the corresponding \u03c3-algebra \u03a32 will be the Borel \u03c3-algebra. Measurability in this case is equivalent to the\npre-image of all intervals of the form (x,\u221e) being members of \u03a31.\nThe Lebesgue integral is a measure theoretic formulation of the notion of integral. A non-negative measurable\nfunction \u03c8 : \u03a91?\u2192 R is a simple function if its range is a finite set {y1,y2...yC}. We may write:\ni\u2208I\nEi) =?\ni\u2208I\n\u00b5(Ei).\n\u03c8(\u03c9) =\nC\n?\ni=1\nyi\n?Ai(\u03c9)(12)\nwhere the sets Ai= \u03c8\u22121(yi), i = 1,...,C are by assumption a sequence of measurable sets and\nfunction.\nThe integral of a simple function with respect to a measure \u00b5 on \u03a31and some element E \u2208 \u03a31is:\n? is the indicator\n?\nE\n\u03c8d\u00b5 =\nC\n?\ni=1\nyi\u00b5(Ai\u2229 E)(13)\nUsing the definition for simple functions we extend the definition of Lebesgue integral to general non-negative\nmeasurable functions g thus:\n4"},{"page":5,"text":"?\nE\ngd\u00b5 = sup\n??\nE\n\u03c8d\u00b5 : 0 \u2264 \u03c8 \u2264 g,\u03c8 is simple\n?\n(14)\nFor those readers more familiar with the Riemann integral it may be helpful to give an intuitive motivation of\nthe relationship between the two. In the case of the Riemann integral we partition the domain of the function into\nincreasingly small sets. We then evaluate the function to provide an increasingly accurate approximation of the area\nunder the curve. In the case of the Lebesgue integral we divide the range of the function into increasingly small sets,\ntake the pre-image of each element of the partition and then use the measure \u00b5 to measure it. The Lebesgue integral\nwill make it possible for us to take the integral with respect to relatively complex probability measures such as those\ncorresponding to Gaussian processes, as we shall see in the sections that follow.\nConsider two measures \u00b5,\u03b7 on (\u03a9,\u03a3). \u00b5 is absolutely continuous with respect to \u03b7 if the null sets of \u03b7 are null\nsets of \u00b5 that is to say \u03b7(A) = 0 =\u21d2 \u00b5(A) = 0. If both measures allocate finite measure to the whole space, as\nwill be the case with probability measures, then it is a consequence of the Radon-Nikodym theorem that there exists\nsome measurable function\nd\u03b7: \u03a9 ?\u2192 [0,\u221e) known as the Radon-Nikodym derivative with the property that for all\nE \u2208 \u03a3:\nd\u00b5\n\u00b5(E) =\n?\nE\nd\u00b5\nd\u03b7d\u03b7\n(15)\nSuppose we have a third measure \u03bb with the property:\n\u03b7(E) =\n?\nE\nd\u03b7\nd\u03bbd\u03bb,\n(16)\nthen the following relation holds:\n\u00b5(E) =\n?\nE\nd\u00b5\nd\u03b7\nd\u03b7\nd\u03bbd\u03bb\n(17)\n3.3The product \u03c3-algebra and the Kolmogorov extension theorem\nThe presentation in this section follows the notes of Sengupta (2014) fairly closely. We now return to considering\nfunctions from an index set to the reals f : X ?\u2192 R which we can also denote in sequence notation (f(x))x\u2208X.\nConsider a projection map \u03c0U\u2192V that for V \u2282 U \u2286 X has the following property:\n\u03c0U\u2192V : RU?\u2192 RV: (f(x))x\u2208U?\u2192 (f(x))x\u2208V\n(18)\nA cylinder set is the pre-image of the projection \u03c0X\u2192V of a Borel set E \u2208 RVfor finite V , denoted:\n\u03c0\u22121\nX\u2192V(E).\n(19)\nClearly it is a subset of the set of all functions from X to R. Let C be the set of all cylinder sets. We may generate\na \u03c3-algebra using this set which we denote \u03c3(C). This \u03c3-algebra is known as the product \u03c3-algebra.\nThe Kolmogorov extension theorem concerns circumstances under which a collection of consistent distributions\non functions for finite index sets U \u2282 X implies the existence of a corresponding probability measure on functions\nwith countably or uncountably infinite index set X. To be more concrete consider a family of Borel probability\nmeasures, labelled by their corresponding finite index set, \u00b5V : B(V ) ?\u2192 [0,1] which obeys the following consistency\nrelation for all V \u2282 X and all second finite index sets with U \u2283 V :\n\u00b5U(\u03c0\u22121\nU\u2192V(E)) = \u00b5V(E) (20)\nover all Borel sets E \u2282 RV. If such a set of consistent finite dimensional distributions exists then Kolmogorov\u2019s\ntheorem states that there is a unique probability measure on the product \u03c3-algebra, \u00b5X : \u03c3(C) ?\u2192 [0,1] with the\nproperty:\n\u00b5X(\u03c0\u22121\nX\u2192V(E)) = \u00b5V(E)(21)\n5"},{"page":6,"text":"for all finite index sets V and Borel sets E \u2282 RV.\nA common example of the application of this theorem is to argue for the existence of a Gaussian process with a\ngiven mean and covariance function on the basis of the marginalization property of multivariate Gaussian distribu-\ntions.\n3.4The KL-divergence between processes\nWe have now reviewed all the mathematical background necessary and we can return to the original questions: \u201cHow\ndoes one rigorously define the KL-divergence between stochastic processes\u201d and \u201cHow does this relate to Titsias\u2019\nKL-divergence?\u201d which are answered in the next two sections.\nSuppose we have two measures \u00b5 and \u03b7 for (\u03a9,\u03a3) and that \u00b5 is absolutely continuous with respect to \u03b7. Then\nthere exists a Radon-Nikodyn derivatived\u00b5\nd\u03b7and the correct definition for KL-divergence between these measures is:\nKL[\u00b5||\u03b7] =\n?\n\u03a9\nlog\n?d\u00b5\nd\u03b7\n?\nd\u00b5\n(22)\nIn the case where \u00b5 is not absolutely continuous with respect to \u03b7 we let KL[\u00b5||\u03b7] = \u221e. In the case where the\nmeasure is Borel on RBfor some finite B and both measures are dominated by Lebesgue measure m this reduces to\nthe more familiar definition:\nKL[\u00b5||\u03b7] =\n?\n\u03a9\nulog\n?u\nv\n?\ndm\n(23)\nwhere u and v are the respective densities with respect to Lebesgue measure. The first definition is more general\nand allows us to deal with the problem of there being no sensible infinite dimensional Lebesgue measure by instead\nintegrating with respect to the measure \u00b5.\n3.5Recovering the sparse variational inducing framework\nIn this section we are now interested in three types of probability measure on sets of functions f : X ?\u2192 R. The first\nis the prior measure P which will be assumed to be a Gaussian process. The second is the approximating measure\nQ which will be assumed to be a sparse Gaussian process and the third is the posterior process\u02c6P which may be\nGaussian or non-Gaussian depending on whether we have a conjugate likelihood. We specify the densities q with\nrespect to Lebesgue measure on any finite index set V \u2282 X to avoid ever trying to express a density with respect\nto infinite dimensional Lebesgue measure. The Kolmogorov extension theorem then straightforwardly confirms the\nexistence of the measures in question on the product \u03c3-algebra.\nTo compute the KL-divergence between the approximating process and the posterior we need to find the Radon-\nNikodym derivative. We start with the answer and then show that it is correct. The Radon-Nikodym derivative\nis:\ndQ\nd\u02c6P(f) =\nq(fD\\Z,fZ)\np(fD\\Z,fZ|Y ).\n(24)\nHere q and p are the corresponding densities with respect to Lebesgue measure of the corresponding finite\ndimensional marginals. In this case the Radon-Nikodym derivative only depends on finitely many of the function\npoints, namely the values at the data points and the inducing points.\nWe break the proof that this is the correct Radon-Nikodym derivative into two parts. First we need to show that\nour candidate function is measurable, then we show that when integrated with respect to\u02c6P over all members of the\nproduct \u03c3-algebra it gives the approximating measure Q.\nTo show that\np(fD\\Z,fZ|Y )is measurable we need to show that the pre-images of all intervals (x,\u221e) lie in the\nproduct \u03c3-algebra denoted \u03c3(C). To do this we note that the function only depends on the finite set of function\nvalues fZ\u222aD. The pre-images are thus precisely cylinder sets of the form \u03c0\u22121\nbe Borel for all\u02c6P and Q we consider.\nNext we need to show that the measure \u02c6 \u00b5 defined by:\nq(fD\\Z,fZ)\nX\u2192V(E) where E \u2282 RZ\u222aDwill certainly\n6"},{"page":7,"text":"\u02c6 \u00b5(E) =\n?\nE\nq(fD\\Z,fZ)\np(fD\\Z,fZ|Y )d\u02c6P\n(25)\nwhere E \u2208 \u03c3(C), is equal to the measure Q. We can show this if we can show that both measures have the same finite\ndimensional marginals, since we can appeal to the uniqueness of the Kolmogorov extension. Thus consider any finite\nindex subset V \u2282 X, a Borel set C \u2208 RVand the corresponding cylinder set \u03c0\u22121\nassume that V \u2287 Z \u222aD but by careful, though not difficult, book keeping this may be extended to the general case.\nWe have\nX\u2192V(C). For clarity of exposition we\n\u02c6 \u00b5(\u03c0\u22121\nX\u2192V(C)) =\n?\n\u03c0\u22121\nX\u2192V(C))\n?\nC\nq(fD\\Z,fZ)\np(fD\\Z,fZ|Y )d\u02c6P\n=\u21d2 \u02c6 \u00b5V(C) =\nq(fD\\Z,fZ)\np(fD\\Z,fZ|Y )d\u02c6PV\n(26)\nwhere the subscripting of the measures indicates the relevant finite dimensional measure on RV. Now that we have\na measure for a finite index set it is is dominated by Lebesgue measure mV on RVand thus we may write\n\u02c6 \u00b5V(C) =\n?\n?\nC\nq(fD\\Z,fZ)\np(fD\\Z,fZ|Y )p(fD\\Z,fZ|Y )p(fV \\(Z\u222aD)|fD\\Z,fZ)dmV\n=\nC\nq(fD\\Z,fZ)p(fV \\(Z\u222aD)|fD\\Z,fZ)dmV\n= QV(C)(27)\nas required. Now that we have confirmed we have the correct Radon-Nikodym derivative we show that the KL-\ndivergence between stochastic processes reduces to the KL-divergence of Titsias.\nKL[Q||\u02c6P] =\n?\n?\nRXlog\n?dQ\nd\u02c6P\n?\np(fD\\Z,fZ|Y )\n?\np(fD\\Z,fZ|Y )\n?\ndQ\n=\nRXlog\nq(fD\\Z,fZ)\n?\ndQ\n=\n?\nRZ\u222aDlog\nq(fD\\Z,fZ)\n?\ndQZ\u222aD\n=\n?\nRZ\u222aDq(fD\\Z,fZ)log\n?\nq(fD\\Z,fZ)\np(fD\\Z,fZ|Y )\n?\ndmZ\u222aD\n(28)\nQED.\n4Conclusion and acknowledgements\nIn this work we have elucidated the connection between the variational inducing point framework (Titsias, 2009) and\na rigorously defined KL-divergence between stochastic processes. As will be evident, many of the required technical\nresults were derived early on in the use of Gaussian processes for machine learning by Seeger (2003a; 2003b).\nIt seems reasonableto hope that elucidating the measure theoretic roots of the formulation will help the community\nto generalise the framework and lead to even better practical results.\nThe authors wish to thank Matthias Seeger and the anonymous reviewer of a previous paper. AM and ZG would\nEPSRC grant EP\/I036575\/1, and a Google Focused Research award. JH was supported by a MRC fellowship.\n7"},{"page":8,"text":"References\nAlvarez, M. A. (2011). Convolved Gaussian process priors for multivariate regression with applications to dynamical\nsystems. PhD thesis, University of Manchester.\nBillingsley, P. (1995). Probability and Measure. Wiley-Interscience, 3 edition.\nCapinski, M. and Kopp, P. (2004). Measure, Integral and Probability. Springer Undergraduate Mathematics Series.\nSpringer London.\nChai, K. M. A. (2012). Variational multinomial logit Gaussian process. J. Mach. Learn. Res., 13(1):1745\u20131808.\nCsat\u00b4 o, L. (2002). Gaussian processes: iterative sparse approximations. PhD thesis, Aston University.\nCsat\u00b4 o, L. and Opper, M. (2002). Sparse on-line gaussian processes. Neural computation, 14(3):641\u2013668.\nDamianou, A. C., K., M., Titsias, and Lawrence, N. D. (2014). Variational inference for uncertainty on the inputs\nof Gaussian process models. arXiv preprint arXiv:1409.2287.\nDamianou, A. C. and Lawrence, N. D. (2012). Deep gaussian processes. arXiv preprint arXiv:1211.0358.\nHensman, J., Fusi, N., and Lawrence, N. D. (2013). Gaussian processes for Big Data. In Conference on Uncertainty\nin Artificial Intellegence, pages 282\u2013290. auai.org.\nHensman, J. and Lawrence, N. D. (2014). Nested Variational Compression in Deep Gaussian Processes. ArXiv\ne-prints.\nHensman, J., Matthews, A. G. D. G., and Ghahramani, Z. (2015). Scalable Variational Gaussian Process Classifica-\ntion. In 18th International Conference on Artificial Intelligence and Statistics, pages 1\u20139, San Diego, California,\nUSA.\nHoffman, M. D., Blei, D. M., Wang, C., and Paisley, J. (2013). Stochastic variational inference. Journal of Machine\nLearning Research, 14:1303\u20131347.\nHunt, B. R., Sauer, T., James, and Yorke, A. (1992). Prevalence: A translation-invariant almost every on infinite-\ndimensional spaces. Bulletin of the Amer. Math. Soc, pages 217\u2013238.\nSeeger, M. (2003a).\napproximations. PhD thesis, University of Edinburgh.\nBayesian Gaussian process models: PAC-Bayesian generalisation error bounds and sparse\nSeeger, M. (2003b). Pac-Bayesian generalisation error bounds for Gaussian process classification. J. Mach. Learn.\nRes., 3:233\u2013269.\nSengupta, A. N. (2014). The kolmogorov extension theorem.\nTitsias, M. K. (2009). Variational learning of inducing variables in sparse Gaussian processes. In In International\nConference on Artificial Intelligence and Statistics 12, pages 567\u2013574.\nTitsias, M. K. and Lawrence, N. D. (2010). Bayesian Gaussian process latent variable model. In Thirteenth Inter-\nnational Conference on Artificial Intelligence and Statistics.\n8"}],"fullTextUrl":"https:\/\/www.researchgate.net\/profile\/James_Hensman\/publication\/275588150_On_Sparse_variational_methods_and_the_Kullback-Leibler_divergence_between_stochastic_processes\/links\/55adfd8f08aed9b7dcdb08a0.pdf","widgetId":"rgw30_56ab1e25595c3"},"id":"rgw30_56ab1e25595c3","partials":[],"templateName":"publicliterature\/stubs\/PublicationText.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationText.html?publicationUid=275588150&hide=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationDetailAd":{"data":{"googleDfpSlot":null,"widgetId":"rgw31_56ab1e25595c3"},"id":"rgw31_56ab1e25595c3","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAd.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAd.html?publicationUid=275588150&slotId=336x280_Publications_ATF_Right&collapseSlotMode=never&fallbackContainerEnabled=1","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationRelations":null,"publicationRelationsReverse":null,"publicationUid":275588150,"showSignUpDialog":false,"selectNewSignUpDialog":false,"publicationQuestions":null,"publicationCitations":{"data":{"publicationUid":275588150,"publicationCitationsList":{"data":{"citationItems":[{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore","clickThrough":"experimentMilestoneClickedToPublicationFromCitationWithFulltext","clickThroughWithContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextSlurp","nextPublicationViewId":null,"authorsPartOne":[{"id":71410443,"url":"researcher\/71410443_James_Hensman","fullname":"James Hensman","last":false,"imageUrl":"https:\/\/i1.rgstatic.net\/ii\/profile.image\/AS%3A277099177889798%401443077000994_m"},{"id":2048369253,"url":"researcher\/2048369253_Alexander_G_de_G_Matthews","fullname":"Alexander G. de G. Matthews","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":70871340,"url":"researcher\/70871340_Maurizio_Filippone","fullname":"Maurizio Filippone","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":8159937,"url":"researcher\/8159937_Zoubin_Ghahramani","fullname":"Zoubin Ghahramani","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":[[]],"isFulltext":true,"isSlurp":false,"isNoText":false,"publicationType":"Article","publicationDate":"Jun 2015","journal":null,"showEnrichedPublicationItem":false,"citationCount":1,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/278332447_MCMC_for_Variationally_Sparse_Gaussian_Processes","usePlainButton":true,"publicationUid":278332447,"feedStubs":null,"hasFeedStubs":false,"impactPoints":false,"url":"publication\/278332447_MCMC_for_Variationally_Sparse_Gaussian_Processes","title":"MCMC for Variationally Sparse Gaussian Processes","displayTitleAsLink":true,"authors":[{"id":71410443,"url":"researcher\/71410443_James_Hensman","fullname":"James Hensman","last":false,"imageUrl":"https:\/\/i1.rgstatic.net\/ii\/profile.image\/AS%3A277099177889798%401443077000994_m"},{"id":2048369253,"url":"researcher\/2048369253_Alexander_G_de_G_Matthews","fullname":"Alexander G. de G. Matthews","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":70871340,"url":"researcher\/70871340_Maurizio_Filippone","fullname":"Maurizio Filippone","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":8159937,"url":"researcher\/8159937_Zoubin_Ghahramani","fullname":"Zoubin Ghahramani","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":[],"abstract":"Gaussian process (GP) models form a core part of probabilistic machine\nlearning. Considerable research effort has been made into attacking three\nissues with GP models: how to compute efficiently when the number of data is\nlarge; how to approximate the posterior when the likelihood is not Gaussian and\nhow to estimate covariance function parameter posteriors. This paper\nsimultaneously addresses these, using a variational approximation to the\nposterior which is sparse in support of the function but otherwise free-form.\nThe result is a Hybrid Monte-Carlo sampling scheme which allows for a\nnon-Gaussian approximation over the function values and covariance parameters\nsimultaneously, with efficient computations based on inducing-point sparse GPs.\nCode to replicate each experiment in this paper will be available shortly.","description":false,"swapJournalAndAuthorPositions":false,"showAbstract":true,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/278332447_MCMC_for_Variationally_Sparse_Gaussian_Processes","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":true,"actions":[{"type":"download","text":"Download","url":"profile\/Maurizio_Filippone\/publication\/278332447_MCMC_for_Variationally_Sparse_Gaussian_Processes\/links\/558a857008aee1fc9174ea84.pdf?origin=publication_list","active":false,"primary":true,"extraClass":"open-viewer","icon":null,"data":[]}],"actionWidgets":[],"publicationItemFulltext":{"data":{"isDataset":false,"isResearch":false,"isFulltext":true,"source":{"isPreview":false,"sourceUrl":"profile\/Maurizio_Filippone","sourceName":"Maurizio Filippone","hasSourceUrl":true},"publicationUid":278332447,"publicationUrl":"publication\/278332447_MCMC_for_Variationally_Sparse_Gaussian_Processes","eventCode":"","citationCount":0,"additionalContentWidgets":[],"disableViewer":true,"showLoggedOutRequestButton":false,"context":null,"previewUrl":"https:\/\/i1.rgstatic.net\/publication\/278332447_MCMC_for_Variationally_Sparse_Gaussian_Processes\/links\/558a857008aee1fc9174ea84\/smallpreview.png","linkId":"558a857008aee1fc9174ea84","origin":"publication_list","showRequestCount":false,"publish":false,"request":false,"showAction":false,"displayAsLink":true,"documentViewerUrl":"publicliterature.PublicLiteratureDocumentViewer.html?publicationId=278332447&reference=558a857008aee1fc9174ea84&eventCode=&origin=publication_list","widgetId":"rgw35_56ab1e25595c3"},"id":"rgw35_56ab1e25595c3","partials":[],"templateName":"publicliterature\/stubs\/PublicationItemFulltext.html","templateExtensions":["generalHelpers"],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItemFulltext.html?publicationUid=278332447&showAction=1&eventCode=&hideSource=0&displayAsLink=1&showPublishAsSelectFile=0","viewClass":"views.publicliterature.PublicationItemFulltextView","yuiModules":["rg.views.publicliterature.PublicationItemFulltextView"],"stylesheets":[],"_isYUI":true},"linkId":"558a857008aee1fc9174ea84","context":null,"contextId":null,"eventCode":"","isCitation":true,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":275588150,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/278332447_MCMC_for_Variationally_Sparse_Gaussian_Processes\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":true,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read full-text","widgetId":"rgw34_56ab1e25595c3"},"id":"rgw34_56ab1e25595c3","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":true,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItem.html?showEnrichedPublicationItem=0&showRequestButton=1&publicationUid=278332447&citationContextItemVersion=old&isIncomingCitation=1","viewClass":"views.publicliterature.PublicationItemView","yuiModules":["rg.views.publicliterature.PublicationItemView"],"stylesheets":[],"_isYUI":true}],"hasCitations":true,"isPublicationAuthor":false,"isPublicationVisitor":false,"publicationUid":275588150,"publicationLink":"publication\/275588150_On_Sparse_variational_methods_and_the_Kullback-Leibler_divergence_between_stochastic_processes","hasShowMore":false,"newOffset":3,"pageSize":10,"widgetId":"rgw33_56ab1e25595c3"},"id":"rgw33_56ab1e25595c3","partials":[],"templateName":"publicliterature\/stubs\/PublicationIncomingCitationsList.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationIncomingCitationsList.html?publicationUid=275588150&citedInPage=1&swapJournalAndAuthorPositions=0&showAbstract=1&showType=1&showPublicationPreview=1&totalCount=1","viewClass":"views.publicliterature.PublicationIncomingCitationsListView","yuiModules":["rg.views.publicliterature.PublicationIncomingCitationsListView"],"stylesheets":[],"_isYUI":true},"hasCitations":false,"citationsCount":0,"hasIncomingCitations":true,"incomingCitationsCount":1,"showCitationsSorter":true,"showAbstract":true,"showType":true,"showPublicationPreview":true,"swapJournalAndAuthorPositions":false,"sort":"","sortOriginal":false,"citationList":"incoming","showsIncoming":true,"showSorting":false,"usePlainButton":null,"useEnrichedContext":null,"widgetId":"rgw32_56ab1e25595c3"},"id":"rgw32_56ab1e25595c3","partials":[],"templateName":"publicliterature\/stubs\/PublicationCitations.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationCitations.html?publicationUid=275588150&citationList=&citedInPage=1&sort=","viewClass":"views.publicliterature.PublicationCitationsView","yuiModules":["rg.views.publicliterature.PublicationCitationsView"],"stylesheets":[],"_isYUI":true},"publicationReviewPromo":null,"publicationUsedInReviews":null,"publicationPdfJsReader":{"data":{"isPreview":false,"licenseUrl":null,"licenseInfo":null,"defaultLinkData":{"linkId":"55adfd8f08aed9b7dcdb08a0","name":"James Hensman","date":"Jul 21, 2015 ","nameLink":"profile\/James_Hensman","filename":"","downloadLink":"https:\/\/www.researchgate.net\/profile\/James_Hensman\/publication\/275588150_On_Sparse_variational_methods_and_the_Kullback-Leibler_divergence_between_stochastic_processes\/links\/55adfd8f08aed9b7dcdb08a0.pdf?inViewer=0&pdfJsDownload=0&origin=publication_detail","viewerUrl":"https:\/\/www.researchgate.net\/profile\/James_Hensman\/publication\/275588150_On_Sparse_variational_methods_and_the_Kullback-Leibler_divergence_between_stochastic_processes\/links\/55adfd8f08aed9b7dcdb08a0.pdf?inViewer=1&pdfJsDownload=1&origin=publication_detail","downloadHash":"5a65fdb5d3339e6c3cf1903dd6be6278","showFileSizeNote":false,"fileSize":"144.53 KB","noFollow":false,"isDefault":true,"doi":null},"displayableLinks":[{"linkId":"55adfd8f08aed9b7dcdb08a0","name":"James Hensman","date":"Jul 21, 2015 ","nameLink":"profile\/James_Hensman","filename":"","downloadLink":"https:\/\/www.researchgate.net\/profile\/James_Hensman\/publication\/275588150_On_Sparse_variational_methods_and_the_Kullback-Leibler_divergence_between_stochastic_processes\/links\/55adfd8f08aed9b7dcdb08a0.pdf?inViewer=0&pdfJsDownload=0&origin=publication_detail","viewerUrl":"https:\/\/www.researchgate.net\/profile\/James_Hensman\/publication\/275588150_On_Sparse_variational_methods_and_the_Kullback-Leibler_divergence_between_stochastic_processes\/links\/55adfd8f08aed9b7dcdb08a0.pdf?inViewer=1&pdfJsDownload=1&origin=publication_detail","downloadHash":"5a65fdb5d3339e6c3cf1903dd6be6278","showFileSizeNote":false,"fileSize":"144.53 KB","noFollow":false,"isDefault":true,"doi":null}],"hasDisplayableLinks":false,"reader":{"data":{"pdfCommentsActive":false,"publicationType":"Article","onlyRenderFirstPage":false,"readMoreExperimentGoal":"goalPublicationPdfClicksReadMore","readMoreExperimentViewId":null,"comments":null,"figures":[],"figureAssetIds":[],"figureOverlayUrls":{"clickOnOverlay":"publication.PublicationFigures.html?_sg=4_wgMotKfwbn08AfarBaOnHvdjPX1Gr7nmJVjW42WmwGmvN50ef04kz9FHbpW9Q_LYQq_3nRW_BONR6qTqc2Ag.xnRXjAcZGW_yktO56UsueA_auyQMuFt14-iPUFKen7GXW7645v_kg8pAHeWN2JgLIxKMfEUoJ4XCVWGyCToC3Q","clickOnPill":"publication.PublicationFigures.html?_sg=cdSyhGGqRchpD8MwQxzG1C0oEtLtnMeuU1ZI6dnQqxIE5OUnBxGgg_uLqQAqUeffNf7iU2w4YWkVdJA36AzPKA.bT5zlyWFmjmniIpxZjFYsHImqIwb7hO6ravGieTqEVWqoE6LLZwhwt672tlqm0xLoAs0f6bBuCan9fW53xjXKA"},"canSelect":false,"javascriptPath":"https:\/\/www.researchgate.net\/c\/o1o9o3\/","downloadUrl":"https%3A%2F%2Fwww.researchgate.net%2Fprofile%2FJames_Hensman%2Fpublication%2F275588150_On_Sparse_variational_methods_and_the_Kullback-Leibler_divergence_between_stochastic_processes%2Flinks%2F55adfd8f08aed9b7dcdb08a0.pdf%3FinViewer%3D1%26pdfJsDownload%3D1%26origin%3Dpublication_detail","viewerUrl":"https:\/\/www.researchgate.net\/c\/o1o9o3\/javascript\/lib\/pdfjs\/web\/viewer.html","commentEndpoint":"https:\/\/www.researchgate.net\/rgformat\/api\/comment","experimentEndpoint":"https:\/\/www.researchgate.net\/rgformat\/api\/experiment?key=np53Jbl5BYftugfm0TImsu0KDZUOulzl-zd7oqkXZ4Vo-gRvzJl0Lgv1vfX8roapSAoWNAGXgdkoyHSpnRQ_3A","urlHash":"b70c45c17aeeaaed8476e4c39fe82a11","downloadTrackUrl":"application.PdfJsReader.ajaxTrackDownload.html?msrp=eYqqxsI1bjUuVBy-YIjpppLCd6F1ovAFVUUFIFC47PQ1EjLG2yJ7HsxEHVWZfrg16N5NyOntvMwgMSZfph2KzFMjZFARZDVZccEn-uPrgo4.QdGlmTMHIQ1MpwfEuEy80SCO4_f4gImt8BgvnYmcCAW8G6gkD7vONYq5xjDrenYP1ZAqZlKwZUkychzan7QO4w.Mqb6Xyxws2WtffZ3T6JbkFu_Mb_l_KmnU4zEJ77m_wg-YxwHJ-UpGgTDt7obyWqPinSYaFiFsiUV8PMZeeA_aA","viewportMilestoneTrackUrl":"application.PdfJsReader.ajaxTrackViewportMilestone.html","linkId":"55adfd8f08aed9b7dcdb08a0","trackedDownloads":{"55adfd8f08aed9b7dcdb08a0":{"v":false,"d":false}},"assetId":"AS:253564933111808@1437465999584","readerDocId":null,"assetType":"fulltext","interactionType":{"comment":"comment","highlight":"highlight"},"publicationUid":275588150,"commentCursorPromo":null,"widgetId":"rgw37_56ab1e25595c3"},"id":"rgw37_56ab1e25595c3","partials":[],"templateName":"application\/stubs\/PdfJsReader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PdfJsReader.html?fileHref=https%3A%2F%2Fwww.researchgate.net%2Fprofile%2FJames_Hensman%2Fpublication%2F275588150_On_Sparse_variational_methods_and_the_Kullback-Leibler_divergence_between_stochastic_processes%2Flinks%2F55adfd8f08aed9b7dcdb08a0.pdf%3FinViewer%3D1%26pdfJsDownload%3D1%26origin%3Dpublication_detail&assetId=AS%3A253564933111808%401437465999584&publicationUid=275588150&linkId=55adfd8f08aed9b7dcdb08a0&onlyShowFirstPage=0","viewClass":null,"yuiModules":["css-pow-application-PdfJsReader"],"stylesheets":["pow\/application\/PdfJsReader.css"],"_isYUI":true},"showHeader":true,"title":"On Sparse variational methods and the Kullback-Leibler divergence between stochastic processes","publicationType":"Article","downloadTrackUrl":"publicliterature.PublicationInlineReader.ajaxTrackDownload.html?msrp=D-k8pvBVHWuZlrbRDvWt2br9pnCM5N0kyQpv1GU5p2NFrgqEbehqbcm_p3xS1TP5sr754wJ5MszrLgwK_tNwTT_dhhXi7SE8rJHK78i2r6M.cwc-mEE1BDnLp2huA9nWLEZhssRJHET6oRnBhSqSzbG8x8AdAt-dBWGfUImkT8mUiyB7-Ylc4TKcyhn7dvPgTA.GOz86twSrjYhWRm1voL968ubX_r5ZGwwu4Gc1S9J_YWLcUquxPTMHtqLCRJ5vk-cuYFoe-pw3Y8f0CZ1FJRDyA","publicationUid":275588150,"trackedDownloads":{"55adfd8f08aed9b7dcdb08a0":{"v":false,"d":false}},"inlinePdf":false,"publicationComments":null,"showDownloadButton":true,"socialShare":{"data":{"shareItems":[{"data":{"name":"Facebook","url":"http:\/\/www.facebook.com\/share.php?u={{url}}{{#title}}&t={{title}}{{\/title}}","width":600,"height":350,"useUtmTags":true,"utmSource":"facebook","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareFacebook.ajaxTrackSocialShare.html","widgetId":"rgw39_56ab1e25595c3"},"id":"rgw39_56ab1e25595c3","partials":{"shareIcon":"application\/stubs\/partials\/shareFacebookBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareFacebook.html?provider=Facebook&shareIcon=shareIconBlog&utmSource=facebook&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"Twitter","url":"http:\/\/twitter.com\/intent\/tweet?text={{#title}}{{title}}: {{\/title}}{{url}}&via=researchgate","width":600,"height":350,"useUtmTags":true,"utmSource":"twitter","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareTwitter.ajaxTrackSocialShare.html","widgetId":"rgw40_56ab1e25595c3"},"id":"rgw40_56ab1e25595c3","partials":{"shareIcon":"application\/stubs\/partials\/shareTwitterBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareTwitter.html?provider=Twitter&shareIcon=shareIconBlog&utmSource=twitter&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"Google+","url":"https:\/\/plus.google.com\/share?url={{url}}","width":600,"height":600,"useUtmTags":true,"utmSource":"googleplus","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareGooglePlus.ajaxTrackSocialShare.html","widgetId":"rgw41_56ab1e25595c3"},"id":"rgw41_56ab1e25595c3","partials":{"shareIcon":"application\/stubs\/partials\/shareGooglePlusBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareGooglePlus.html?provider=Google%2B&shareIcon=shareIconBlog&utmSource=googleplus&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"LinkedIn","url":"http:\/\/www.linkedin.com\/shareArticle?mini=true&url={{url}}{{#title}}&title={{title}}{{\/title}}&source=ResearchGate","width":520,"height":570,"useUtmTags":true,"utmSource":"linkedin","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareLinkedIn.ajaxTrackSocialShare.html","widgetId":"rgw42_56ab1e25595c3"},"id":"rgw42_56ab1e25595c3","partials":{"shareIcon":"application\/stubs\/partials\/shareLinkedInBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareLinkedIn.html?provider=LinkedIn&shareIcon=shareIconBlog&utmSource=linkedin&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"Reddit","url":"https:\/\/www.reddit.com\/submit?url={{url}}{{#title}}&title={{title}}{{\/title}}","width":600,"height":600,"useUtmTags":true,"utmSource":"reddit","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareReddit.ajaxTrackSocialShare.html","widgetId":"rgw43_56ab1e25595c3"},"id":"rgw43_56ab1e25595c3","partials":{"shareIcon":"application\/stubs\/partials\/shareRedditBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareReddit.html?provider=Reddit&shareIcon=shareIconBlog&utmSource=reddit&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true}],"widgetId":"rgw38_56ab1e25595c3"},"id":"rgw38_56ab1e25595c3","partials":[],"templateName":"application\/stubs\/SocialShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.SocialShare.html?campaign=shareFullTextPublication&trackClick=1&shareIcon=shareIconBlog","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw36_56ab1e25595c3"},"id":"rgw36_56ab1e25595c3","partials":[],"templateName":"publicliterature\/stubs\/PublicationInlineReader.html","templateExtensions":["generalHelpers"],"attrs":{"showFulltextDownloadedSignupDialog":true,"preSignUpDialogContext":null,"requestFulltext":false},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationInlineReader.html","viewClass":"views.publicliterature.PublicationInlineReaderView","yuiModules":["rg.views.publicliterature.PublicationInlineReaderView","css-pow-publicliterature-PublicationInlineReader"],"stylesheets":["pow\/publicliterature\/PublicationInlineReader.css"],"_isYUI":true},"useFulltextOptimizedLayout":false,"publicationActions":null,"requestFulltextPromo":null,"currentUrl":"publication\/275588150_On_Sparse_variational_methods_and_the_Kullback-Leibler_divergence_between_stochastic_processes","isLeaderboardAd":false,"enableStickyBox":null,"googleDfpSlotMobileBottom":null,"fullTextExitPopup":null,"showExitPopupDialog":false,"widgetId":"rgw2_56ab1e25595c3"},"id":"rgw2_56ab1e25595c3","partials":{"romeo_legal_notice":"publicliterature\/stubs\/partials\/romeo_legal_notice.html"},"templateName":"publicliterature\/stubs\/PublicPublicationDetails_NewLayout.html","templateExtensions":["generalHelpers"],"attrs":{"publicationUid":275588150},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicPublicationDetailsOld.html?publicationUid=275588150&isTestOldDesign=0","viewClass":"views.publicliterature.PublicPublicationDetailsOldView","yuiModules":["rg.views.publicliterature.PublicPublicationDetailsOldView"],"stylesheets":[],"_isYUI":true},"widgetId":"rgw1_56ab1e25595c3"},"id":"rgw1_56ab1e25595c3","partials":[],"templateName":"publicliterature\/stubs\/PublicPublicationDetails.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicPublicationDetails.html","viewClass":"views.publicliterature.PublicPublicationDetailsView","yuiModules":["rg.views.publicliterature.PublicPublicationDetailsView"],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"uaClass":"","headPrefix":[],"rootUrl":"https:\/\/www.researchgate.net\/","requestToken":"sx9m+uy+AIyRjtcr4Fk0aQqQDXhPO9G0CMqS+n3q8rh9labpV\/k+iRDU0hlrnHNZuRKWlekqHcRljZePEdPfprmyeyF3ZPWdiAY+QWb6Ice\/HFc9IU\/zRC0kYH0Zrpu9o7e\/s3aUoyDy2HIrJYw\/Xkh4fgc2XCcTDGYgLRinRYt64xbc0+dO5qBdvvMjA2h+C7YNYV2vtlRobE4Usy\/YKhzMyxLly\/nJaBhZqPtQiZMiCAtptp4IcPf\/J0CitaMOMT1FDHaur8tkDU1gPiITF9Lkjng68P\/GssPOcvbl7LM=","faviconCdnUrl":"https:\/\/c5.rgstatic.net\/m\/2390829798215018\/images\/favicon.ico","headerOutput":"<noscript><\/noscript><link rel=\"canonical\" href=\"https:\/\/www.researchgate.net\/publication\/275588150_On_Sparse_variational_methods_and_the_Kullback-Leibler_divergence_between_stochastic_processes\" \/>\n<link rel=\"dns-prefetch\" href=\"\/\/c5.rgstatic.net\" \/>\n<link rel=\"dns-prefetch\" href=\"\/\/i1.rgstatic.net\" \/>\n<meta property=\"twitter:card\" content=\"summary\" \/>\n<meta property=\"twitter:site\" content=\"@ResearchGate\" \/>\n<meta property=\"og:title\" content=\"On Sparse variational methods and the Kullback-Leibler divergence between stochastic processes\" \/>\n<meta property=\"og:description\" content=\"The variational framework for learning inducing variables Titsias (2009) has\nhad a large impact on the Gaussian process literature. The framework may be\ninterpreted as minimizing a rigorously...\" \/>\n<meta property=\"og:site_name\" content=\"ResearchGate\" \/>\n<meta property=\"og:image\" content=\"https:\/\/i1.rgstatic.net\/publication\/275588150_On_Sparse_variational_methods_and_the_Kullback-Leibler_divergence_between_stochastic_processes\/links\/55adfd8f08aed9b7dcdb08a0\/smallpreview.png\" \/>\n<meta property=\"og:url\" content=\"https:\/\/www.researchgate.net\/publication\/275588150_On_Sparse_variational_methods_and_the_Kullback-Leibler_divergence_between_stochastic_processes\" \/>\n<meta property=\"rg:id\" content=\"PB:275588150\" \/>\n<meta name=\"DC.identifier\" scheme=\"DCTERMS.URI\" content=\"http:\/\/dx.doi.org\/\" \/>\n<meta name=\"gs_meta_revision\" content=\"1.1\" \/>\n<meta name=\"citation_title\" content=\"On Sparse variational methods and the Kullback-Leibler divergence between stochastic processes\" \/>\n<meta name=\"citation_author\" content=\"Alexander G. de G. Matthews\" \/>\n<meta name=\"citation_author\" content=\"James Hensman\" \/>\n<meta name=\"citation_author\" content=\"Richard E. Turner\" \/>\n<meta name=\"citation_author\" content=\"Zoubin Ghahramani\" \/>\n<meta name=\"citation_publication_date\" content=\"2015\/04\/27\" \/>\n<meta name=\"citation_pdf_url\" content=\"https:\/\/www.researchgate.net\/profile\/James_Hensman\/publication\/275588150_On_Sparse_variational_methods_and_the_Kullback-Leibler_divergence_between_stochastic_processes\/links\/55adfd8f08aed9b7dcdb08a0.pdf\" \/>\n<meta name=\"citation_abstract_html_url\" content=\"https:\/\/www.researchgate.net\/publication\/275588150_On_Sparse_variational_methods_and_the_Kullback-Leibler_divergence_between_stochastic_processes\" \/>\n<meta name=\"citation_fulltext_html_url\" content=\"https:\/\/www.researchgate.net\/publication\/275588150_On_Sparse_variational_methods_and_the_Kullback-Leibler_divergence_between_stochastic_processes\" \/>\n<meta name=\"viewport\" content=\"width=device-width,initial-scale=1\" \/>\n<link href=\"\/\/c5.rgstatic.net\/m\/22664197317151888\/styles\/rg.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/21004998181197492\/styles\/rg2.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<!--[if lt IE 9]><link href=\"\/\/c5.rgstatic.net\/m\/238176252723686\/styles\/ie.css\" type=\"text\/css\" rel=\"stylesheet\"\/><![endif]-->\n<link href=\"\/\/c5.rgstatic.net\/m\/217752362214895\/styles\/modules\/publicprofile.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/21993347442549\/styles\/pow\/publicliterature\/FollowPublicationPromo.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/282514599719602\/styles\/pow\/application\/PdfJsReader.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/23819663151220\/styles\/pow\/publicliterature\/PublicationInlineReader.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<script src=\"\/\/c5.rgstatic.net\/m\/2321000301012716\/javascript\/vendor\/webfontloader\/webfontloader.js\" type=\"text\/javascript\"><\/script>\n <script>(function(i,s,o,g,r,a,m){i[\"GoogleAnalyticsObject\"]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,\"script\",\"\/\/www.google-analytics.com\/analytics.js\",\"ga\");\n ga(\"create\",\"UA-58591210-1\");ga(\"set\",\"anonymizeIp\",true);ga('set', 'dimension1', 'publication full-text');ga('set', 'dimension2', 'Article');ga('set', 'dimension3', 'Logged out');ga('set', 'dimension4', 'https');ga(\"send\",\"pageview\");<\/script>\n","webfont":"<noscript><\/noscript><script> WebFontConfig = { custom: { families: ['source_sans_pro_italic', 'source_sans_pro_bold', 'source_sans_pro', 'martel'], urls : ['\/\/c5.rgstatic.net\/m\/231392577336386\/styles\/fonts.css'] } }; WebFont.load(WebFontConfig); <\/script>\n","correlationId":"rgreq-b35215a7-1a1d-4ec6-817e-f6eba97b9542","accountId":null,"module":"publicliterature","action":"publicliterature.PublicPublicationDetails","page":"publicationDetail","product":"publications","backendTime":710,"continent":"Asia","stylesHome":"\/\/c5.rgstatic.net\/m\/","staticHost":"c5.rgstatic.net","useEarlyFlush":false,"longRunningRequestIdentifier":"LongRunningRequest.publicliterature.PublicPublicationDetails","longRunningRequestFp":"e9e5bbe1366c7ee8c8e41d02f793c884ac9be19b","widgetId":"rgw44_56ab1e25595c3"},"id":"rgw44_56ab1e25595c3","partials":[],"templateName":"application\/stubs\/StaticHeader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.StaticHeader.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){
            Y.rg.core.pagespeed.Monitoring.monitorPage("\/\/glassmoni.researchgate.net", "publicliterature.PublicPublicationDetails.run.html.loggedOut.get", "59de9668d07aeb77ab4de5f24d382b5d199d2437", "rgreq-b35215a7-1a1d-4ec6-817e-f6eba97b9542", "5b233a046ddb7f4f2ba757a97e7d1de62d7a682f");
        
            Y.rg.core.pagespeed.Monitoring.monitorPage("\/\/glassmoni.researchgate.net", "publicationDetail.loggedOut", "ed1993d9e20f6cefa83edacaa24401a18c071aea", "rgreq-b35215a7-1a1d-4ec6-817e-f6eba97b9542", "5b233a046ddb7f4f2ba757a97e7d1de62d7a682f");
        })();
(function(){Y.rg.createInitialWidget({"data":{"year":"2016","inlinePromo":null,"isAdmin":false,"contactUrl":"https:\/\/www.researchgate.net\/contact","aboutUsUrl":"https:\/\/www.researchgate.net\/about","widgetId":"rgw45_56ab1e25595c3"},"id":"rgw45_56ab1e25595c3","partials":[],"templateName":"application\/stubs\/DefaultFooter.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.DefaultFooter.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"headerLogin":{"data":{"urlAfterLogin":"publication\/275588150_On_Sparse_variational_methods_and_the_Kullback-Leibler_divergence_between_stochastic_processes","requestToken":"KacwHk18\/uaAEieAhZXwrGkQUjWmSKOYzlNd\/J1UMgqjZZuD4zgwYTiYa+Qh1P+fr\/MvSdTFVL5UwqXeAkiBmilkA1PWayS7R69S1WuJKYKA2ttma9zSy8Wz6MpabyAKVjK9WGiUcUX6LJLLBXchOdlaaRHszoLEwgIjWonWIZSVYwobQj05UxuGyuTb5Cht9BYpyrqwfhBC1tPvOu1gKHx76XuUoMRYMK1Lwz403\/KRLJkKez0xONpB6XA\/W5CpqXxlO7NQWWRCcmgxIddZK0k4dqLgjmFaklWxEIGOe3I=","loginUrl":"https:\/\/www.researchgate.net\/application.Login.html","signupUrl":"https:\/\/www.researchgate.net\/signup.SignUp.html?ev=su_chnl_index&hdrsu=1&_sg=eF6qyvSZeL_yLxxaX8f8YqJvMoTofOGGvIFhE2vyLHoi5to8ZLEkdGLczTvtXuTV","encodedUrlAfterLogin":"cHVibGljYXRpb24vMjc1NTg4MTUwX09uX1NwYXJzZV92YXJpYXRpb25hbF9tZXRob2RzX2FuZF90aGVfS3VsbGJhY2stTGVpYmxlcl9kaXZlcmdlbmNlX2JldHdlZW5fc3RvY2hhc3RpY19wcm9jZXNzZXM%3D","signupCallToAction":"Join for free","widgetId":"rgw47_56ab1e25595c3"},"id":"rgw47_56ab1e25595c3","partials":{"partial":"application\/stubs\/partials\/headerLoginDefault.html"},"templateName":"application\/stubs\/HeaderLogin.html","templateExtensions":[],"attrs":{"goal":"milestoneHeaderLoginSeen"},"widgetUrl":"https:\/\/www.researchgate.net\/application.HeaderLogin.html","viewClass":"views.application.HeaderLoginView","yuiModules":["rg.views.application.HeaderLoginView"],"stylesheets":[],"_isYUI":true},"cookieConsent":null,"logoSvgSrc":"https:\/\/c5.rgstatic.net\/m\/235107188705592\/images\/template\/brand-header-logo.svg","logoFallbackSrc":"https:\/\/c5.rgstatic.net\/m\/238113351022438\/images\/template\/brand-header-logo.png","widgetId":"rgw46_56ab1e25595c3"},"id":"rgw46_56ab1e25595c3","partials":{"schemaSocialProfiles":"application\/stubs\/partials\/schemaSocialProfiles.html"},"templateName":"application\/stubs\/HeaderLoggedOut.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.HeaderLoggedOut.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"logEvent":"su_banner","specialCopy":false,"widgetId":"rgw48_56ab1e25595c3"},"id":"rgw48_56ab1e25595c3","partials":[],"templateName":"application\/stubs\/LoggedOutBanner.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.LoggedOutBanner.html","viewClass":"views.application.LoggedOutBannerView","yuiModules":["rg.views.application.LoggedOutBannerView"],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.core.util.ParameterFilter.filter(["ev","cp","ch","ref","dbw","pli","loginT","uid","claimChannel","enrichId","enrichSource","utm_source","utm_medium","utm_campaign","el","ci"]);})();
});}); } else { throw 'YRG was not loaded when attaching widgets'; }</script><script> dataLayer = [{"pageCategory":"publication full-text","publicationType":"Article","eventCategory":"Publication page"}]; </script> <noscript><iframe src="//www.googletagmanager.com/ns.html?id=GTM-MKVKH7" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-MKVKH7');</script><script>(function(e){function n(n,t,o,a){"use strict";var i=e.document.createElement("link"),r=t||e.document.getElementsByTagName("script")[0],d=e.document.styleSheets;return i.rel="stylesheet",i.href=n,i.media="only x",a&&(i.onload=a),r.parentNode.insertBefore(i,r),i.onloadcssdefined=function(e){for(var t,o=0;d.length>o;o++)d[o].href&&d[o].href.indexOf(n)>-1&&(t=!0);t?e():setTimeout(function(){i.onloadcssdefined(e)})},i.onloadcssdefined(function(){i.media=o||"all"}),i}function t(e,n){e.onload=function(){e.onload=null,n&&n.call(e)},"isApplicationInstalled"in navigator&&"onloadcssdefined"in e&&e.onloadcssdefined(n)}var o=function(a,i){"use strict";if(a&&3===a.length){var r=e.Image,d=!(!document.createElementNS||!document.createElementNS("http://www.w3.org/2000/svg","svg").createSVGRect||!document.implementation.hasFeature("http://www.w3.org/TR/SVG11/feature#Image","1.1")||e.opera&&-1===navigator.userAgent.indexOf("Chrome")||-1!==navigator.userAgent.indexOf("Series40")),c=new r;c.onerror=function(){o.method="png",o.href=a[2],n(a[2])},c.onload=function(){var e=1===c.width&&1===c.height,r=a[e&&d?0:e?1:2];o.method=e&&d?"svg":e?"datapng":"png",o.href=r,t(n(r),i)},c.src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///ywAAAAAAQABAAACAUwAOw==",document.documentElement.className+=" grunticon"}};o.loadCSS=n,o.onloadCSS=t,e.grunticon=o})(this);grunticon(["https://c5.rgstatic.net/c/o1o9o3/styles/icons/_header-ico.svg.css", "https://c5.rgstatic.net/c/o1o9o3/styles/icons/_header-ico.png.css", "https://c5.rgstatic.net/c/o1o9o3/styles/icons/_header-ico.fallback.scss"]);grunticon(["https://c5.rgstatic.net/c/o1o9o3/styles/icons/_admin-ico.svg.css", "https://c5.rgstatic.net/c/o1o9o3/styles/icons/_admin-ico.png.css", "https://c5.rgstatic.net/c/o1o9o3/styles/icons/_admin-ico.fallback.scss"]);grunticon(["https://c5.rgstatic.net/c/o1o9o3/styles/icons/_ico.svg.css", "https://c5.rgstatic.net/c/o1o9o3/styles/icons/_ico.png.css", "https://c5.rgstatic.net/c/o1o9o3/styles/icons/_ico.fallback.scss"]);</script></body>
</html>
