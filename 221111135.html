<!DOCTYPE html> <html lang="en" class="" id="rgw51_56ab1aecd0c82"> <head > <meta charset="utf-8"/> <meta http-equiv="content-type" content="text/html; charset=UTF-8"/> <meta name="Rg-Request-Token" id="Rg-Request-Token" content="nl9CPdndArZXo8jZ2ClbdSK+pmMSCkyRs0L+lY3tN2BybRIHVqPSoB0VP+8XYfe9AiFDCzJC3oj1nuXxnChaDyGWil6rgs+MqixSwWeqa+zr0YzTSrTsGuShldZNYKYvQUCICKSQ6vVTUbXWwi3PR1cZsVyO7wy4LWFwl/OcudE+QYy4SpdAeUHZKoQ35K2OOPsv0dRDCV4om2psK4ivDT453Rq0Bb1FvAqvkIBJ/vbmeyE3FtKOfqjerQUkZLG8PiuYo6AoN7McV6VWODfDbDYfWeQb2wU21IqUzpG6Q+Y="/> <meta http-equiv="expires" content="0"/> <link rel="apple-touch-icon" sizes="57x57" href="https://www.researchgate.net/apple-touch-icon-57x57.png"> <link rel="apple-touch-icon" sizes="60x60" href="https://www.researchgate.net/apple-touch-icon-60x60.png"> <link rel="apple-touch-icon" sizes="72x72" href="https://www.researchgate.net/apple-touch-icon-72x72.png"> <link rel="apple-touch-icon" sizes="76x76" href="https://www.researchgate.net/apple-touch-icon-76x76.png"> <link rel="apple-touch-icon" sizes="114x114" href="https://www.researchgate.net/apple-touch-icon-114x114.png"> <link rel="apple-touch-icon" sizes="120x120" href="https://www.researchgate.net/apple-touch-icon-120x120.png"> <link rel="apple-touch-icon" sizes="144x144" href="https://www.researchgate.net/apple-touch-icon-144x144.png"> <link rel="apple-touch-icon" sizes="152x152" href="https://www.researchgate.net/apple-touch-icon-152x152.png"> <link rel="apple-touch-icon" sizes="180x180" href="https://www.researchgate.net/apple-touch-icon-180x180.png"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-32x32.png" sizes="32x32"> <link rel="icon" type="image/png" href="https://www.researchgate.net/android-chrome-192x192.png" sizes="192x192"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-96x96.png" sizes="96x96"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-16x16.png" sizes="16x16"> <link rel="shortcut icon" type="image/x-icon" href="https://c5.rgstatic.net/m/2390829798215018/images/favicon.ico"/> <link rel="manifest" href="https://www.researchgate.net/manifest.json"> <meta name="msapplication-TileColor" content="#da532c"> <meta name="msapplication-TileImage" content="https://www.researchgate.net/mstile-144x144.png"> <meta name="theme-color" content="#444444"> <link rel="search" type="application/opensearchdescription+xml" title="ResearchGate search" href="https://www.researchgate.net/application.DownloadOpenSearchPlugin.html"/> <link rel="meta" type="application/rdf+xml" title="ICRA labels" href="https://www.researchgate.net/application.DownloadLabels.html"/> <link rel="http://oexchange.org/spec/0.8/rel/related-target" type="application/xrd+xml" href="https://www.researchgate.net/application.DownloadOExchange.html"/> <base href="https://www.researchgate.net/"/> <script>
    var rgConfig = {
        correlationId: "rgreq-26103183-92c3-446c-8447-43301513f984",
        accountId: "",
        module: "publicliterature",
        action: "publicliterature.PublicPublicationDetails",
        page: "publicationDetail",
        product: "publications",
        continent: "Asia",
        stylesHome: "//c5.rgstatic.net/m/",
        staticHost: "c5.rgstatic.net",
        longRunningRequestIdentifier: "LongRunningRequest.publicliterature.PublicPublicationDetails",
        longRunningRequestFp: "e9e5bbe1366c7ee8c8e41d02f793c884ac9be19b"
    };
    window.rootUrl = "https://www.researchgate.net/";
</script> <link rel="canonical" href="https://www.researchgate.net/publication/221111135_Perturb-and-MAP_random_fields_Using_discrete_optimization_to_learn_and_sample_from_energy_models" />
<link rel="dns-prefetch" href="//c5.rgstatic.net" />
<link rel="dns-prefetch" href="//i1.rgstatic.net" />
<meta property="twitter:card" content="summary" />
<meta property="twitter:site" content="@ResearchGate" />
<meta property="og:title" content="Perturb-and-MAP random fields: Using discrete optimization to learn and sample from energy models" />
<meta property="og:description" content="We propose a novel way to induce a random field from an energy function on discrete labels. It amounts to locally injecting noise to the energy potentials, followed by finding the global minimum..." />
<meta property="og:site_name" content="ResearchGate" />
<meta property="og:image" content="https://i1.rgstatic.net/publication/221111135_Perturb-and-MAP_random_fields_Using_discrete_optimization_to_learn_and_sample_from_energy_models/links/02bfe50dbb9bed4be7000000/smallpreview.png" />
<meta property="og:url" content="https://www.researchgate.net/publication/221111135_Perturb-and-MAP_random_fields_Using_discrete_optimization_to_learn_and_sample_from_energy_models" />
<meta property="rg:id" content="PB:221111135" />
<meta name="DC.identifier" scheme="DCTERMS.URI" content="http://dx.doi.org/10.1109/ICCV.2011.6126242" />
<meta name="gs_meta_revision" content="1.1" />
<meta name="citation_title" content="Perturb-and-MAP random fields: Using discrete optimization to learn and sample from energy models" />
<meta name="citation_author" content="George Papandreou" />
<meta name="citation_author" content="Alan L. Yuille" />
<meta name="citation_conference_title" content="IEEE International Conference on Computer Vision, ICCV 2011, Barcelona, Spain, November 6-13, 2011" />
<meta name="citation_publication_date" content="2011/11/01" />
<meta name="citation_journal_title" content="Proceedings / IEEE International Conference on Computer Vision. IEEE International Conference on Computer Vision" />
<meta name="citation_issn" content="1550-5499" />
<meta name="citation_firstpage" content="193" />
<meta name="citation_lastpage" content="200" />
<meta name="citation_doi" content="10.1109/ICCV.2011.6126242" />
<meta name="citation_pdf_url" content="https://www.researchgate.net/profile/George_Papandreou/publication/221111135_Perturb-and-MAP_random_fields_Using_discrete_optimization_to_learn_and_sample_from_energy_models/links/02bfe50dbb9bed4be7000000.pdf" />
<meta name="citation_abstract_html_url" content="https://www.researchgate.net/publication/221111135_Perturb-and-MAP_random_fields_Using_discrete_optimization_to_learn_and_sample_from_energy_models" />
<meta name="citation_fulltext_html_url" content="https://www.researchgate.net/publication/221111135_Perturb-and-MAP_random_fields_Using_discrete_optimization_to_learn_and_sample_from_energy_models" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<link href="//c5.rgstatic.net/m/22664197317151888/styles/rg.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/21004998181197492/styles/rg2.css" type="text/css" rel="stylesheet"/>
<!--[if lt IE 9]><link href="//c5.rgstatic.net/m/238176252723686/styles/ie.css" type="text/css" rel="stylesheet"/><![endif]-->
<link href="//c5.rgstatic.net/m/217752362214895/styles/modules/publicprofile.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/21993347442549/styles/pow/publicliterature/FollowPublicationPromo.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/282514599719602/styles/pow/application/PdfJsReader.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/23819663151220/styles/pow/publicliterature/PublicationInlineReader.css" type="text/css" rel="stylesheet"/>
<script src="//c5.rgstatic.net/m/2321000301012716/javascript/vendor/webfontloader/webfontloader.js" type="text/javascript"></script>
 <script>(function(i,s,o,g,r,a,m){i["GoogleAnalyticsObject"]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,"script","//www.google-analytics.com/analytics.js","ga");
 ga("create","UA-58591210-1");ga("set","anonymizeIp",true);ga('set', 'dimension1', 'publication full-text');ga('set', 'dimension2', 'Conference Paper');ga('set', 'dimension3', 'Logged out');ga('set', 'dimension4', 'https');ga("send","pageview");</script>
  <script> WebFontConfig = { custom: { families: ['source_sans_pro_italic', 'source_sans_pro_bold', 'source_sans_pro', 'martel'], urls : ['//c5.rgstatic.net/m/231392577336386/styles/fonts.css'] } }; WebFont.load(WebFontConfig); </script><noscript></noscript>

<title>Perturb-and-MAP random fields: Using discrete optimization to learn and sample from energy models (PDF Download Available)</title>
<meta name="description" content="Official Full-Text Publication: Perturb-and-MAP random fields: Using discrete optimization to learn and sample from energy models on ResearchGate, the professional network for scientists."/>
<meta name="keywords" content="scientific network, scientific platform, scientific community, research partner, research collaboration, journal articles, international collaboration, find researcher, lifescience researcher, interdisciplinary research, research collaboration"/>
</head>
<body class="use-svg-icons logged-out">
<div id="page-container">
<script type="text/javascript">var googletag = googletag || {}; googletag.cmd = googletag.cmd || [];
(function() { var gads = document.createElement("script"); gads.async = true; gads.type = "text/javascript"; var useSSL = "https:" == document.location.protocol; gads.src = (useSSL ? "https:" : "http:") + "//www.googletagservices.com/tag/js/gpt.js"; var node =document.getElementsByTagName("script")[0]; node.parentNode.insertBefore(gads, node); })();</script><div id="main" class="logged-out-header-support">
<div id="content" class="">

<noscript>
<div class="c-box-warning full-width-element" style="text-align: center; ">
    <div style="margin: auto; padding:10px;" class="container">
        <b>For full functionality of ResearchGate it is necessary to enable JavaScript.
            Here are the <a href="http://www.enable-javascript.com/" rel="nofollow" target="_blank">
                instructions how to enable JavaScript in your web browser</a>.</b>
    </div>
</div>
</noscript>

<div id="rgw1_56ab1aecd0c82" itemscope itemtype="http://schema.org/ScholarlyArticle"><div class="publication-wrapper publication-wrapper-onecol" id="rgw2_56ab1aecd0c82" itemscope itemtype="http://schema.org/ScholarlyArticle"> <div class="c-col-content"> <div class="c-content"> <div class="clearfix">  <div class="publication-header"> <div id="rgw5_56ab1aecd0c82">  <div class="type-label"> Conference Paper   </div> <span class="Z3988" title="ctx_ver=Z39.88-2004&rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&rfr_id=info%3Asid%2Fresearchgate.net%3Aresearchgate&rft_id=info%3Adoi%2F10.1109%2FICCV.2011.6126242&rft.atitle=Perturb-and-MAP%20random%20fields%3A%20Using%20discrete%20optimization%20to%20learn%20and%20sample%20from%20energy%20models&rft.title=Proceedings%20of%20the%20IEEE%20International%20Conference%20on%20Computer%20Vision&rft.jtitle=Proceedings%20of%20the%20IEEE%20International%20Conference%20on%20Computer%20Vision&rft.date=2011&rft.pages=193-200&rft.issn=1550-5499&rft.au=George%20Papandreou%2CAlan%20L.%20Yuille&rft.genre=inProceedings"></span> <h1 class="pub-title" itemprop="name">Perturb-and-MAP random fields: Using discrete optimization to learn and sample from energy models</h1> <meta itemprop="headline" content="Perturb-and-MAP random fields: Using discrete optimization to learn and sample from energy models">  <meta itemprop="image" content="https://i1.rgstatic.net/publication/221111135_Perturb-and-MAP_random_fields_Using_discrete_optimization_to_learn_and_sample_from_energy_models/links/02bfe50dbb9bed4be7000000/smallpreview.png">  <div id="rgw8_56ab1aecd0c82" class="publication-detail-author-list"> <div> <ul class="clearfix js-people-list">  <li id="rgw9_56ab1aecd0c82" itemprop="author" itemscope itemtype="http://schema.org/Person"> <a itemprop="sameAs" href="profile/George_Papandreou" class="pub-detail-item account-item"> <div class="indent-left"> <div class="people-img"> <img  src="https://c5.rgstatic.net/m/2671872220764/images/template/default/profile/profile_default_m.jpg" title="George Papandreou" alt="George Papandreou" height="20px" width="20px" style="height: 20px;"/> </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">George Papandreou</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item  remove-action-indent   " id="rgw10_56ab1aecd0c82" data-account-key="George_Papandreou">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="profile/George_Papandreou"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="George Papandreou" alt="George Papandreou" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">     </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="profile/George_Papandreou" class="display-name">George Papandreou</a>    </h5> <div class="truncate-single-line meta">   <a class="meta ga-top-coauthor-institution" href="institution/Toyota_Technological_Institute_at_Chicago" title="Toyota Technological Institute at Chicago">Toyota Technological Institute at Chicago</a>     </div>  <a href="javascript:" class="btn btn-promote btn-large people-item-contact-author js-contact-author">Message author</a>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>  <li id="rgw11_56ab1aecd0c82"> <a href="researcher/38628756_Alan_L_Yuille" class="pub-detail-item author-item" itemprop="author" itemscope itemtype="http://schema.org/Person"> <div class="indent-left"> <div class="people-img">  <img src="https://c5.rgstatic.net/m/2951093203564/images/template/default/profile/profile_default_s.jpg" title="Alan L. Yuille" alt="Alan L. Yuille" height="20px" width="20px" style="height: 20px;"/>  </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Alan L. Yuille</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item   not-claimed " id="rgw12_56ab1aecd0c82">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="researcher/38628756_Alan_L_Yuille"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="Alan L. Yuille" alt="Alan L. Yuille" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">       </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="researcher/38628756_Alan_L_Yuille" class="display-name">Alan L. Yuille</a>    </h5> <div class="truncate-single-line meta">   </div>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>   </ul> <div class="js-loading"></div>  </div> </div> <div class="pub-details js-pub-details">      DOI:&nbsp;10.1109/ICCV.2011.6126242     Conference: IEEE International Conference on Computer Vision, ICCV 2011, Barcelona, Spain, November 6-13, 2011      <div class="pub-source"> Source: <a href="http://dblp.uni-trier.de/db/conf/iccv/iccv2011.html#PapandreouY11" rel="nofollow">DBLP</a> </div>  </div> <div id="rgw13_56ab1aecd0c82" class="pub-abstract">  <div class="clearfix">   <p itemprop="description"> <strong>ABSTRACT</strong> <div>We propose a novel way to induce a random field from an energy function on discrete labels. It amounts to locally injecting noise to the energy potentials, followed by finding the global minimum of the perturbed energy function. The resulting Perturb-and-MAP random fields harness the power of modern discrete energy minimization algorithms, effectively transforming them into efficient random sampling algorithms, thus extending their scope beyond the usual deterministic setting. In this fashion we can enjoy the benefits of a sound probabilistic framework, such as the ability to represent the solution uncertainty or learn model parameters from training data, while completely bypassing costly Markov-chain Monte-Carlo procedures typically associated with discrete label Gibbs Markov random fields (MRFs). We study some interesting theoretical properties of the proposed model in juxtaposition to those of Gibbs MRFs and address the issue of principled design of the perturbation process. We present experimental results in image segmentation and scene labeling that illustrate the new qualitative aspects and the potential of the proposed model for practical computer vision applications.</div> </p>  </div>   </div>      <div class="action-container"> <div id="rgw14_56ab1aecd0c82" class="follow-publication-promo"> <table> <tr> <td class="follow-publication-promo-text-cell"> <p>Get notified about updates to this publication</p> <a class="btn btn-large btn-promote js-follow-publication ga-follow-publication-new-promo">Follow publication</a> </td> <td> <div class="follow-publication-publication-image"></div> </td> </tr> </table> </div>  <div class="clear"></div> <div class="share-dialog-container" style="display: none;">  </div> </div> </div> <div style="margin-left: -20px; margin-right: -20px;">  </div> </div>  <div class="publication-detail-dfp-container rf"> <div id="rgw31_56ab1aecd0c82">  </div> </div>  </div>  <div class="clearfix"> <div class="pdf-js-container clearfix " id="rgw43_56ab1aecd0c82">  <div class="pdf-js-header js-sticky-header clear">  <a class="blue-link js-download rf btn btn-promote" href="https://www.researchgate.net/profile/George_Papandreou/publication/221111135_Perturb-and-MAP_random_fields_Using_discrete_optimization_to_learn_and_sample_from_energy_models/links/02bfe50dbb9bed4be7000000.pdf?inViewer=0&amp;pdfJsDownload=0&amp;origin=publication_detail">Download full-text</a>  <h3>Full-text</h3> <span class="publication-info">  <span class="js-doi-container" style="display: none;"> DOI: <span class="js-doi"></span> &middot; </span> Available from: <a class="js-name" href="profile/George_Papandreou">George Papandreou</a>   </span>  </div>  <div class="social-share-container"><div id="rgw45_56ab1aecd0c82" class="social-share js-social-share"> <div class="social-share-heading">Share</div>  <a id="rgw46_56ab1aecd0c82" href="javascript:" title="Share on Facebook" class="link-nostyle js-share-item share-icon "  data-url="http://www.facebook.com/share.php?u={{url}}{{#title}}&amp;t={{title}}{{/title}}" data-width="600" data-height="350" data-name="Facebook"> <span class="share-icon ico-share-facebook-round reset-background ga-share-blog-facebook"></span> </a>  <a id="rgw47_56ab1aecd0c82" href="javascript:" title="Share on Twitter" class="link-nostyle js-share-item share-icon "  data-url="http://twitter.com/intent/tweet?text={{#title}}{{title}}: {{/title}}{{url}}&amp;via=researchgate" data-width="600" data-height="350" data-name="Twitter"> <span class="share-icon ico-share-twitter-round reset-background ga-share-blog-twitter"></span> </a>  <a id="rgw48_56ab1aecd0c82" href="javascript:" title="Share on Google+" class="link-nostyle js-share-item share-icon "  data-url="https://plus.google.com/share?url={{url}}" data-width="600" data-height="600" data-name="Google+"> <span class="share-icon ico-share-gplus-round reset-background ga-share-blog-gplus"></span> </a>  <a id="rgw49_56ab1aecd0c82" href="javascript:" title="Share on LinkedIn" class="link-nostyle js-share-item share-icon "  data-url="http://www.linkedin.com/shareArticle?mini=true&amp;url={{url}}{{#title}}&amp;title={{title}}{{/title}}&amp;source=ResearchGate" data-width="520" data-height="570" data-name="LinkedIn"> <span class="share-icon ico-share-linkedin-round reset-background ga-share-blog-linkedin"></span> </a>  <a id="rgw50_56ab1aecd0c82" href="javascript:" title="Share on Reddit" class="link-nostyle js-share-item share-icon "  data-url="https://www.reddit.com/submit?url={{url}}{{#title}}&amp;title={{title}}{{/title}}" data-width="600" data-height="600" data-name="Reddit"> <span class="share-icon ico-share-reddit reset-background ga-share-blog-reddit"></span> </a>  </div></div>    <iframe id="rgw44_56ab1aecd0c82" src="https://www.researchgate.net/c/o1o9o3/javascript/lib/pdfjs/web/viewer.html?file=https%3A%2F%2Fwww.researchgate.net%2Fprofile%2FGeorge_Papandreou%2Fpublication%2F221111135_Perturb-and-MAP_random_fields_Using_discrete_optimization_to_learn_and_sample_from_energy_models%2Flinks%2F02bfe50dbb9bed4be7000000.pdf%3FinViewer%3D1%26pdfJsDownload%3D1%26origin%3Dpublication_detail" allowfullscreen frameborder="0" style="width: 100%; height: 100%; box-sizing: border-box;"></iframe>    </div> <noscript> <div id="rgw30_56ab1aecd0c82"  itemprop="articleBody">  <p>Page 1</p> <p>Perturb-and-MAP Random Fields: Using Discrete Optimization<br />to Learn and Sample from Energy Models<br />George Papandreou1and Alan L. Yuille1,2<br />1Department of Statistics, University of California, Los Angeles<br />2Department of Brain and Cognitive Engineering, Korea University, Seoul, Korea<br />[gpapan,yuille]@stat.ucla.edu<br />Abstract<br />We propose a novel way to induce a random field from<br />an energy function on discrete labels. It amounts to lo-<br />cally injecting noise to the energy potentials, followed by<br />finding the global minimum of the perturbed energy func-<br />tion. The resulting Perturb-and-MAP random fields harness<br />the power of modern discrete energy minimization algo-<br />rithms, effectively transforming them into efficient random<br />sampling algorithms, thus extending their scope beyond the<br />usual deterministic setting. In this fashion we can enjoy<br />the benefits of a sound probabilistic framework, such as the<br />ability to represent the solution uncertainty or learn model<br />parameters from training data, while completely bypassing<br />costly Markov-chain Monte-Carlo procedures typically as-<br />sociated with discrete label Gibbs Markov random fields<br />(MRFs). We study some interesting theoretical properties<br />of the proposed model in juxtaposition to those of Gibbs<br />MRFs and address the issue of principled design of the per-<br />turbation process. We present experimental results in im-<br />age segmentation and scene labeling that illustrate the new<br />qualitative aspects and the potential of the proposed model<br />for practical computer vision applications.<br />1. Introduction<br />Discrete label Markov random fields (MRFs), going<br />back to the classic Ising and Potts models in statistical<br />physics, offer a natural and sound probabilistic modeling<br />framework for a host of image analysis and computer vi-<br />sion problems involving discrete labels, such as image seg-<br />mentation, texture synthesis, and deep learning [2,7,10,15,<br />31]. Exact probabilistic inference and maximum likelihood<br />model parameter fitting is intractable in general MRFs de-<br />fined on 2-D domains and one has to employ random sam-<br />pling schemes to perform these tasks [7, 10]. Beyond its<br />role in inference, random sampling from MRFs can be a<br />goal in itself when the generative MRF properties are ex-<br />ploited, as in texture synthesis or inpainting [24,31]. How-<br />ever, Markov-chain Monte-Carlo (MCMC) sampling algo-<br />rithms such as Gibbs sampling can be computationally too<br />expensive for many practical computer vision applications.<br />Recent powerful discrete energy minimization algo-<br />rithms such as graph cuts, linear programming relaxations,<br />or loopy belief propagation [5,15–17] can efficiently find<br />or well approximate the most probable (MAP) configura-<br />tion for certain important classes of MRFs and have had<br />big impact on several computer vision applications. Be-<br />yond MAP computation, energy minimization algorithms<br />can be used for estimating model parameters using max-<br />margin criteria [26]. However, the deterministic viewpoint<br />on MRF modeling as energy minimization problem has im-<br />portant limitations as it does not provide the right concep-<br />tual framework for probabilistically characterizing the so-<br />lution uncertainty or learning the model parameters from<br />training data by maximum likelihood.<br />In this work we attempt to somehow bridge the gap be-<br />tween the probabilistic and the energy minimization ap-<br />proaches to MRF modeling. We propose a novel way to<br />induce a discrete label random field model from an energy<br />function, which amounts to locally injecting additive ran-<br />dom noise to the continuous energy potentials, followed<br />by finding the global (approximate) minimum configura-<br />tion of the perturbed energy function. This Perturb-and-<br />MAP (PM) random field is a legitimate probabilistic model<br />which delegates the non-trivial global interactions involved<br />in sampling to an efficient energy minimization routine, and<br />thus allows rapid sampling from a wide range of energy<br />functions widely used in practice.<br />From the probabilistic MRF perspective, the proposed<br />technique can be seen as a one-shot approximate random<br />sampling algorithm that completely bypasses MCMC. We<br />study the problem of designing the perturbation process<br />so as the Perturb-and-MAP random field be a good ap-<br />proximation tothecorresponding GibbsMRF. Interestingly,<br />we identify a specific perturbation density under which the<br />Perturb-and-MAP model is identical to its Gibbs counter-</p>  <p>Page 2</p> <p>part. Although this ideal perturbation is not practically ap-<br />plicable since it effectively destroys the local Markov struc-<br />ture of the energy, it suggests low-order perturbations that<br />only introduce noise to the unary (order-1) or a subset of the<br />pairwise (order-2) potential tables, resulting in perturbed<br />energies that are effectively as easy to minimize as the orig-<br />inal unperturbed one, while producing random samples vir-<br />tually indistinguishable from exact Gibbs MRF samples.<br />Perturb-and-MAP random fields allow qualitatively new<br />applicationsofenergyminimizationalgorithmsincomputer<br />vision. First, accompanying the MAP solution with sev-<br />eral typical posterior samples drawn from the model allows<br />us to quantify our confidence in the solution, which can be<br />useful in guiding the user’s attention in interactive appli-<br />cations, propagating uncertainty in further processing steps<br />of a more complex computer vision pipeline, or assessing<br />the generative properties of a particular MRF model. Sec-<br />ond, our efficient sampling algorithm allows learning of<br />MRF or CRF parameters using the moment matching rule,<br />in which the model parameters are updated until the gen-<br />erated samples reproduce the (weighted) sufficient statis-<br />tics of the observed data. This approach is very popular<br />for learning of patch-based models [10,19], but the use of<br />perturbed sampling instead of contrastive divergence is cru-<br />cial for fast training in our applications. Similar to Gibbs<br />MRFs, such greedy parameter update is justified because<br />the log-likelihood of the Perturb-and-MAP model turns out<br />to be concave. We illustrate these ideas in experiments on<br />image segmentation and scene labeling.<br />Related work<br />crete random field model has been motivated by the exact<br />Gaussian MRF sampling algorithm popularized by [20,24]<br />and especially its local factor perturbation interpretation<br />highlighted by [20]. While the underlying mathematics and<br />methods are completely different in the discrete setup we<br />consider here, we show that the intuition of local perturba-<br />tions followed by global optimization can also lead to pow-<br />erful sampling algorithms for discrete label MRFs.<br />Herding [29] builds a deterministic dynamical system on<br />the model parameters designed so as to reproduce the data<br />sufficient statistics, which is similar in spirit to the moment-<br />matching algorithm we use for learning. However, herding<br />is still not a probabilistic model and cannot summarize the<br />data into a concise set of model parameters.<br />The limitations of MAP-based inference in discrete<br />MRFs are nicely illustrated in [30]. They impose extra<br />global constraints in the energy minimization problem to<br />mitigate the tendency of MAP inference to produce singular<br />solutions. However, they still adhere to a deterministic set-<br />ting which is not suited for parameter learning. Further, op-<br />timizing the resulting modified energy functions is far more<br />challenging than minimizing the original energy.<br />Our research on the Perturb-and-MAP dis-<br />Averaging over multiple samples, our approach allows<br />efficiently estimating (sum-) marginal densities and thus<br />quantifyingtheper-nodesolutionuncertaintyeveningraphs<br />with loops. Max-product belief propagation [28] and dy-<br />namic graph-cuts [14] can compute max-marginals, which<br />give some indication of the uncertainty in label assignments<br />[14] but cannot directly estimate marginal densities.<br />In the context of binary image segmentation, the<br />sampling-based marginal confidence maps we produce re-<br />semble the soft segmentation maps of the random walker<br />model [8], although the underlying probabilistic underpin-<br />nings of the two methods are completely different.<br />2. Energy functions and Gibbs MRFs<br />Our starting point is a deterministic energy function<br />e(x;θ) = ?θ,φ(x)?,<br />(1)<br />where x ∈ LNis a length-N state configuration vector with<br />entries xiin a discrete label set L, θ ∈ RMis a real param-<br />eter vector of length M, and φ(x) = (φ1(x),...,φM(x))T<br />is a vector of potentials or “sufficient statistics”. We can in-<br />terpret θjas the weight assigned to the feature φj(x): we<br />have many different design goals or sources of information<br />(e.g., smoothness prior, measurements), each giving rise to<br />some features. We merge everything together into a single<br />objective function which we want to optimize so as to re-<br />cover the best/minimum energy configuration x.<br />The weights θ are selected in a way that the model as-<br />signs low energies to desirable configurations and high en-<br />ergies to “everything else”. When the number of parameters<br />M is small, we can set them to reasonable values by hand.<br />A more principled way is to learn the parameters from a la-<br />beled training set {xk}K<br />k=1by discriminative criteria such<br />as structured max-margin [15,19,26,27]. Computationally,<br />one typically ends up with efficient iterative algorithms that<br />require MAP inference at each parameter update step.<br />The Gibbs distribution is the standard way to induce a<br />probabilistic model from the energy function e(x;θ). It de-<br />fines a Markov random field whose probability mass func-<br />tion has the exponential family form<br />fG(x;θ) = Z−1(θ)exp(−e(x;θ)),<br />(2)<br />where Z(θ) =?<br />In the probabilistic setting, maximum (penalized) likeli-<br />hood (ML) is the natural criterion for learning the weights.<br />Given the labeled training set {xk}K<br />ters θ by maximizing the log-likelihood function LG(θ) =<br />−logZ(θ) − (1/K)?K<br />ing an extra penalty term regularizing the weights. For<br />fully observed models and energies of the form (1) the<br />log-likelihood is a concave function of the weights θ and<br />thus the global maximum can be found by gradient ascent<br />xexp(−e(x;θ)) is the partition function.<br />k=1, we fit the parame-<br />k=1e(xk;θ), possibly also includ-</p>  <p>Page 3</p> <p>[11, 15, 31]. The gradient is ∂LG/∂θj = EG<br />ED{φj(x)}. Here EG<br />−∂(logZ)/∂θj and ED{φj(x)} ? (1/K)?K<br />are, respectively, the sufficient statistics under the Gibbs<br />model and the data. Upon convergence, EG<br />ED{φj(x)}. Thus, ML estimation of the Gibbs model can<br />be thought of as moment matching: random samples drawn<br />fromthetrainedmodelreproducethesufficientstatisticsob-<br />served in the training data.<br />The chief computational challenge in ML parameter<br />learning of the Gibbs model lies in estimating the model<br />sufficient statistics EG<br />θ{φj(x)}. Note that this inference<br />step needs to be repeated at each parameter update step.<br />The model sufficient statistics can be computed exactly in<br />tree-structured (and low tree-width) graphs, but in general<br />graphs one needs to resort to MCMC techniques for approx-<br />imating them [10,11,31], an avenue considered too costly<br />for many computer vision applications. Deterministic ap-<br />proximations such as variational techniques or loopy sum-<br />product belief propagation do exist, but often are not accu-<br />rate enough. Simplified criteria such as pseudo-likelihood<br />[3] have been applied as substitutes to ML, but they can<br />sometimes give results grossly different to ML.<br />Beyond model training, random sampling is very useful<br />in itself, to reveal what are typical instances of the model –<br />what the model has in its “mind” – and in applications such<br />as texture synthesis [31]. Further, we might be interested<br />not only in the global minimum energy configuration, but<br />in the marginal densities or posterior means as well [24].<br />In loopy graphs these quantities are typically intractable to<br />compute, the only viable way being through sampling. Our<br />Perturb-and-MAP random field model is designed specifi-<br />cally so as to be amenable to rapid sampling.<br />θ{φj(x)} −<br />θ{φj(x)} ??<br />xfG(x;θ)φj(x) =<br />k=1φj(xk)<br />θ{φj(x)} =<br />3. Perturb-and-MAP random fields<br />We propose a novel way to induce a probabilistic model<br />from an energy function:<br />Definition. The Perturb-and-MAP random field is defined<br />by x(ǫ) = argminqe(q;θ + ǫ), where ǫ is a random real-<br />valued additive parameter perturbation vector.<br />In other words, we inject noise to the model parameters<br />˜θ = θ + ǫ, followed by finding the least energy configura-<br />tion x(ǫ) of the perturbed energy function. While Perturb-<br />and-MAP random fields can also be built on energies de-<br />fined over continuous labels [20], our focus in this paper<br />will be on random fields over discrete labels.<br />The main motivation for defining a probabilistic model<br />in such a way is that for certain energy functions e(x;θ)<br />there exist powerful algorithms which can find the MAP<br />state efficiently. Thus, by construction, we can efficiently<br />draw exact one-shot samples from the Perturb-and-MAP<br />model without resorting to expensive MCMC techniques.<br />ǫ1<br />ǫ2<br />ǫ2= −β2+ λ<br />ǫ1= −β1− λ<br />ǫ1+ ǫ2= −β1− β2<br />ǫ2= −β2− λ<br />ǫ1= −β1+ λ<br />??<br />(−β1,−β2)<br />x = (−1,1)<br />x = (1,1)<br />x = (−1,−1)<br />x = (1,−1)<br />Figure 1. Perturb-and-MAP geometry under the Ising energy with<br />N = 2 nodes and perturbations only in the unary terms,˜βi =<br />βi+ ǫi, for parameter values β1 = −1, β2 = 0, and λ = 1. The<br />ǫ-space is split into four polyhedra, with x(ǫ) = x iff ǫ ∈ Px−θ.<br />3.1. Weight space geometry<br />A particular state x ∈ LNwill be minimizing the deter-<br />ministic energy (1) if, and only if, e(x;θ) ≤ e(q;θ),∀q ∈<br />LN. This set of |L|Nlinear inequalities defines a polyhe-<br />dron Pxin the weight space<br />Px= {θ ∈ RM: ?θ,φ(x)−φ(q)? ≤ 0,∀q ∈ LN}. (3)<br />Actually, Pxis a polyhedral cone [4], since θ ∈ Pximplies<br />αθ ∈ Px, for all α ≥ 0. The polyhedra Pxsplit the weight<br />space RMinto regions of influence of each discrete state<br />x ∈ LN. Under the Perturb-and-MAP model, x(ǫ) will be<br />assigned to a particular state x if, and only if, θ + ǫ ∈ Px<br />or, equivalently, ǫ ∈ Px− θ ? {ǫ ∈ RM: θ + ǫ ∈ Px}.<br />In other words, if a specific instantiation of the perturbation<br />ǫ falls in the shifted polyhedron Px− θ, then the Perturb-<br />and-MAP model generates x as sample.<br />We assume that perturbations are drawn from a density<br />fǫ(ǫ) which does not depend on the parameters θ. The<br />probability mass of a state x under the Perturb-and-MAP<br />model is then the weighted volume of the corresponding<br />shifted polyhedron under the perturbation measure<br />fPM(x;θ) =<br />?<br />Px−θ<br />fǫ(ǫ)dǫ,<br />(4)<br />which is the counterpart of the Gibbs density in Eq. (2). It<br />is intractable (NP-hard) to compute the volume of general<br />polyhedra in a high-dimensional space; see, e.g., [1, p. 29].<br />However, for the class of perturbed energy functions which<br />can be globally minimized efficiently, we can readily draw<br />exact samples from the Perturb-and-MAP model, without<br />ever explicitly evaluating the integrals in Eq. (4).<br />Example: Perturb-and-MAP Ising model<br />sider the Ising energy e(x;θ)<br />Let us con-<br />?N<br />=<br />−1<br />2<br />i=1<br />?βixi +</p>  <p>Page 4</p> <p>?N<br />here βiis the external field strength (βi&gt; 0 favors xi= 1)<br />and λii′ is the coupling strength (attractive coupling λii′ &gt;<br />0 favors the same spin for xiand xi′). This energy function<br />can be written in the standard inner product form (1) with<br />θ = ({βi},{λii′})Tand φ(x) =−1<br />MRF defined by (2) is the Ising Gibbs random field.<br />Defining a Perturb-and-MAP Ising random field requires<br />specifying the perturbation density. In this example, we<br />leave the binary term parameters λii′ intact and only perturb<br />the unary term parameters βi. In particular, for each unary<br />factor, we set˜βi = βi+ ǫi, with ǫiIID samples from the<br />logistic distribution with density l(z) =<br />corresponds to the order-1 Gumbel perturbation we discuss<br />in Sec. 4 and ensures that if a particular node xiis com-<br />pletely isolated, it will then follow the same Bernoulli dis-<br />tribution Pr{xi= 1} = 1/(1 + e−βi) as in the Gibbs case.<br />The ǫ-space geometry in the case of two labels (N = 2) un-<br />der the Ising energy e(x;θ) = −0.5(β1x1+β2x2+λx1x2)<br />for a specific value of the parameters θ and perturbations<br />only to unary terms is depicted in Fig. 1. We show in Fig. 2<br />some statistics comparing the Gibbs and Perturb-and-MAP<br />random fields for a toy Ising energy involving 9 variables<br />and randomly generated parameters. The probability land-<br />scape under the two models looks quite similar.<br />i′=i+1λii′xixi′?over the discrete “spins” xi∈ {−1,1};<br />2({xi},{xixi′})T. The<br />1<br />4sech2(z<br />2). This<br /> <br /> <br />−4<br />−3.5<br />−3<br />−2.5<br />−2<br />−1.5<br />−1<br />(a)<br /> <br /> <br />−4<br />−3.5<br />−3<br />−2.5<br />−2<br />−1.5<br />−1<br />(b)<br />−5−4−3−2−1<br />−4<br />−3<br />−2<br />−1<br />log10fG(x)<br />log10fPM(x)<br />(c)<br />100 200<br />GIBBS RANK<br />300 400500<br />100<br />200<br />300<br />400<br />500<br />PERTURB−MAP RANK<br />(d)<br />Figure 2. Ising energy on 3×3 grid, with βi and λii′ IID from<br />N(0,1). We compare the Gibbs (exact computation) and PM (106<br />Monte-Carlo runs) random fields. (a) log10fG(x) and fG(xi =<br />1). (b) log10fPM(x) and fPM(xi = 1). Scatter-plot of state log<br />probabilities (c) and state ranking (d) under the two models.<br />3.2. Parameter estimation<br />We would like to estimate the parameters θ of the<br />Perturb-and-MAP model from a labeled training set<br />{xk}K<br />k=1by maximizing the log-likelihood<br />LPM(θ) = (1/K)<br />?K<br />k=1logfPM(xk;θ).<br />(5)<br />Although we will not explore this further, we can<br />also perform parameter estimation from partially observed<br />data using expectation maximization, as in standard Gibbs<br />MRFs [15], using Perturb-and-MAP sampling at the E-step.<br />We can design the perturbations so as the Perturb-and-<br />MAP log-likelihood LPMis a concave function of θ. This<br />ensures that the likelihood landscape is well-behaved and<br />allows the use of local search techniques for parameter esti-<br />mation, exactly as in the Gibbs case. Specifically (see sup-<br />plementary material for all proofs in the paper):<br />Proposition 1. If the perturbations ǫ are drawn from a log-<br />concave density fǫ(ǫ), the log-likelihood LPM(θ) is a con-<br />cave function of the energy parameters θ.<br />The family of log-concave distributions [4],<br />logfǫ(ǫ) is a concave function of ǫ, includes the Gaussian,<br />the logistic, and other commonly used distributions.<br />The gradient of LPM(θ) is in general hard to com-<br />pute. Motivated by the parameter update formula in the<br />Gibbs case, we opt for the moment matching learning rule,<br />θj(t + 1) = θj(t) + r(t)∆θj, where<br />i.e.,<br />∆θj= EPM<br />θ<br />{φj(x)} − ED{φj(x)}.<br />(6)<br />Here EPM<br />pected sufficient statistic under the Perturb-and-MAP<br />model for the current parameter values θ, which we can<br />efficiently estimate by drawing exact samples from it. We<br />typically adjust the learning rate by a Robbins-Monro type<br />schedule, e.g., r(t) = r1/(r2+ t). Figure 5 illustrates pa-<br />rameter learning by moment matching in a spatially homo-<br />geneous Perturb-and-MAP Ising model.<br />Changing the parameters θ under the moment matching<br />rule (6) indeed reduces the discrepancy between the model<br />and data sufficient statistics. Specifically:<br />θ<br />{φj(x)} ?<br />?<br />xfPM(x;θ)φj(x) is the ex-<br />Proposition 2. If θ′and θ differ only in the j-element, with<br />θ′<br />j&gt; θj, then EPM<br />θ′ {φj(x)} ≤ EPM<br />θ<br />{φj(x)}.<br />The inequality in Proposition 2 will be strict if the per-<br />turbation density satisfies some mild conditions – see sup-<br />plementary material. To see the effect of parameter up-<br />date in the Perturb-and-MAP Ising model of Fig. 1, as-<br />sume that EPM<br />θ<br />{φ3(x)} = EPM<br />ED{φ3(x)}. Under (6), we increase the coupling strength<br />θ3= λ; we see from Fig. 1 that the polyhedra of states x =<br />(1,1) and x = (−1,−1) expand over those of x = (1,−1)<br />and x = (−1,1), thus decreasing EPM<br />Unlike the Gibbs case, the fixed points of the Perturb-<br />and-MAP moment matching criterion do not need to be ex-<br />act minima of the log-likelihood (5). However, some re-<br />assurance is provided by the fact that the M-projection of<br />fPM(θMM) (Perturb-and-MAP model trained by moment<br />matching) is fG(θML) (Gibbs model trained by ML/MM)<br />[15, Th. 8.6]. Specifically, D(fPM(θMM)?fG(θML)) ≤<br />D(fPM(θMM)?fG(θ)),∀θ ∈ RM, where D(·?·) is the<br />Kullback-Leibler divergence between two distributions.<br />θ<br />{−1<br />2x1x2} is larger than<br />θ<br />{φ3(x)}.</p>  <p>Page 5</p> <p>4. Perturb-and-MAP perturbation design<br />Although any perturbation density induces a legitimate<br />Perturb-and-MAP model, it is desirable to carefully de-<br />sign it so as the Perturb-and-MAP model approximates<br />as closely as possible the corresponding Gibbs MRF. The<br />Gibbs MRF has important structural properties that are not<br />automatically satisfied by the Perturb-and-MAP model un-<br />der arbitrary perturbations: (a) Unlike the Gibbs MRF, the<br />Perturb-and-MAP model is not guaranteed to respect the<br />state ranking induced by the energy, i.e., e(x) ≤ e(x′) does<br />not necessarily imply fPM(x) ≥ fPM(x′), see Fig. 2(d).<br />(b) The Markov dependence structure of the Gibbs MRF<br />follows directly from the support of the potentials φj(x),<br />while the Perturb-and-MAP might give rise to longer-range<br />probabilistic dependencies. (c) The maximum entropy dis-<br />tribution under moment constraints E{φj(x)} =¯φjhas the<br />Gibbs form; the Perturb-and-MAP model trained by mo-<br />ment matching can reproduce these moments but will in<br />general have smaller entropy than its Gibbs counterpart.<br />0.2<br />02-2-4<br />z<br />g(z)<br />0.5<br />1.0<br />02-2-4<br />z<br />G(z)<br />Figure 3. Gumbel probability density and cumulative distribution.<br />The Gumbel distribution arising in extreme value the-<br />ory [25] turns out to play an important role in our effort<br />to design a perturbation mechanism that yields a Perturb-<br />and-MAP model closely resembling the Gibbs MRF. It is a<br />continuous univariate distribution with log-concave density<br />g(z) = exp(−(−z + ez)), plotted in Fig. 3. We can ef-<br />ficiently draw independent Gumbel variates by transform-<br />ing standard uniform samples by u → log(−log(u)). The<br />Gumbel density naturally fits into the Perturb-and-MAP<br />model, thanks to the following key Lemma – c.f. [18]:<br />Lemma 1. Let (θ1,...,θm), with θn ∈ R. We additively<br />perturb them by˜θn= θn+ǫn, with ǫnIID Gumbel samples.<br />Then the probability that˜θnattains the minimum value is<br />Pr{argmin(˜θ1,...,˜θm) = n} = e−θn/?m<br />Gumbel perturbation on fully-expanded potential table<br />The Gibbs random field on N sites xi, i = 1,...,N, each<br />allowed to take a value from the discrete label set L can be<br />considered as a discrete distribution with |L|Nstates. This<br />can be made explicit if we enumerate {xj,j = 1,...,¯<br />|L|N} all the states and consider the maximal equivalent<br />re-parameterization of Eq. (1)<br />n′=1e−θn′.<br />M =<br />¯ e(x;¯θ) ? ?¯θ,¯φ(x)? = ?θ,φ(x)?,<br />(7)<br />where¯θj = e(xj;θ) = ?θ,φ(xj)?, j = 1,...,¯<br />the fully-expanded potential table and¯φj(x) is the indica-<br />M, is<br />(a) (b)(c)<br />Figure 4. Reduced-order Gumbel perturbation. Perturbed poten-<br />tials are denoted with double line. (a) Graph of the original en-<br />ergy involving unary and pairwise potentials on a 4-neighborhood<br />graph. (b) Order-1 perturbation. (c) Order-2 perturbation.<br />tor function of the state xj(i.e., equals 1, if x = xjand 0<br />otherwise). Using Lemma 1 we can show:<br />Proposition 3. If we perturb each entry of the fully ex-<br />panded LNpotential table with IID Gumbel noise samples<br />ǫj,j = 1,...,¯<br />M, then the Perturb-and-MAP and Gibbs<br />models coincide, i.e., fPM(x;θ) = fG(x;θ).<br />This order-N perturbation is not practically applicable<br />when N is large since it independently perturbs all¯<br />|L|Nentries of the fully expanded potential table and ef-<br />fectively destroys the local Markov structure of the energy<br />function, rendering it too hard to minimize. Nevertheless,<br />it shows that it is possible to design a Perturb-and-MAP<br />model that exactly replicates the Gibbs MRF and paves the<br />way for the design of reduced-order Gumbel perturbations.<br />M =<br />Reduced-order Gumbel perturbation<br />employlow-orderGumbelperturbations, typicallyonlyper-<br />turbing the unary (order-1) or a subset of the pairwise<br />(order-2) potential tables. This yields perturbed energies<br />effectively as easy to minimize as the original unperturbed<br />one, while producing random samples closely resembling<br />Gibbs MRF samples. We emphasize that even the order-1<br />Perturb-and-MAP model is able to reproduce the sufficient<br />statistics of the data and is thus far more accurate than a<br />mean-field approximation of the Gibbs MRF. Thanks to the<br />log-concavity of the Gumbel density, the log-likelihood of<br />the Perturb-and-MAP model remains concave for Gumbel<br />perturbations of any order, as follows from Proposition 1.<br />To be more specific, consider the second-order energy<br />In practice, we<br />e(x;θ) =<br />N<br />?<br />i=1<br />?<br />Vi(xi) +<br />?<br />i′∈N(i)<br />Vii′(xi,xi′)<br />?<br />(8)<br />where each site xican take a discrete label in L. This is<br />a generalization of the Ising model considered in Sec. 3.1,<br />where |L| = 2. Each Viis a |L|×1 unary potential table and<br />each Vii′ is a |L|×|L| pairwise potential table.<br />The order-1 perturbation, illustrated in Fig. 4(b),<br />amounts to adding IID Gumbel noise to each entry of ev-<br />ery unary potential table Vi. This requires generating |L|N</p>  <p>Page 6</p> <p>(a)(b)(c)(d)<br />0 10 2030<br />−0.2<br />−0.1<br />0<br />0.1<br />0.2<br />0.3<br />0.4<br />Iteration<br />Moment Values<br /> <br /> <br />Em{xi!=xj}<br />Ed{xi!=xj}<br />Em{xi}<br />Ed{xi}<br />(e)<br />Figure 5. Low-order Perturb-and-MAP Ising random field parameter learning. The two model parameters, the global coupling strength<br />λ and field strength β are fitted by moment matching. (a) One of the 10 Gibbs Ising model samples just below the critical temperature<br />(λ = 0.88, β = 0, 256×256 grid) that we used as training data. (b) Perturb-and-MAP Ising sample at initial parameter values. (c) Order-1<br />Perturb-and-MAP sample at fitted parameter values. (d) Order-2 Perturb-and-MAP sample at fitted parameter values. (e) Model moments<br />of the order-2 Perturb-and-MAP model as they progress towards the training data moments during moment matching learning.<br />IID Gumbel samples. Note that in the special case of the<br />Ising model, the order-1 Gumbel perturbation is equivalent<br />to adding logistic noise to the unary factor parameter βi,<br />since the difference of two IID Gumbel samples follows a<br />logistic distribution [25].<br />In the order-2 perturbation, illustrated in Fig. 4(c), we<br />add IID Gumbel noise to each entry of a subset of the pair-<br />wise potential tables Vii′. We make sure that at most one<br />of the pairwise potentials adjacent to any node is perturbed.<br />If none of the pairwise potentials adjacent to a node can<br />be perturbed, then we perturb its associated unary potential.<br />In total, the perturbation process requires generating at most<br />(N/2)|L|2IID Gumbel samples. Higher-order Gumbel per-<br />turbations involving clusters of 3 or more variables can be<br />similarly defined.<br />It is desirable to select the strongest among the pair-<br />wise potentials adjacent to each node for order-2 per-<br />turbation.For energies defined on 4-connected planar<br />graphs, we globally find an optimal subset of strongest<br />links by solving a stable marriage (also called stable<br />matching) problem on the corresponding Red-Black bi-<br />partite graph using the Gale-Shapley algorithm.<br />[13] and particularly [9] for a description of the Gale-<br />Shapley algorithm as it applies to sets of men/women<br />of unequal size, as can happen in our case.<br />cate the mating preferences of each node xi, we rank its<br />neighbors in decreasing order of pairwise mutual infor-<br />mation Iii′ =<br />?<br />pii′(xi,xi′)∝exp(−Vi(xi) − Vi′(xi′) − Vii′(xi,xi′)) and<br />pi(xi) =?<br />creases with the edge strength |λii′|. When producing mul-<br />tiple samples, we perform link selection only once. The<br />computational cost is around 0.1 sec for 300×300 images<br />with our implementation of the Gale-Shapley algorithm.<br />See<br />To indi-<br />xi,xi′pii′(xi,xi′)log<br />pii′(xi,xi′)<br />pi(xi)pi′(xi′), with<br />xi′pii′(xi,xi′). For the Ising model, Iii′ in-<br />While the order-1 perturbation preserves submodularity<br />[17], order-2 perturbation can yield non-submodular func-<br />tions even when the original energy is submodular. For the<br />Ising model we can compute in closed form the probability<br />that a single pairwise link of strength λ will be submodular<br />after order-2 Gumbel perturbation Pr{˜λ ≥ 0} = e2λ(e2λ−<br />2λ − 1)/(e2λ− 1)2; e.g., for λ = 4, Pr{˜λ ≥ 0} ≈ 0.998.<br />Thus, if the links selected for perturbation are sufficiently<br />strong (and the link selection process described in the pre-<br />vious paragraph contributes to this goal), then most of the<br />perturbed pairwise potentials will remain submodular and<br />theperturbedenergycanefficientlybeminimizedwithtech-<br />niques such as QPBO [16] which gracefully handle the few<br />non-submodular links. This is the approach we follow in<br />the interactive image segmentation application. Otherwise,<br />for weak links the order-1 perturbation should be preferred,<br />which is anyway accurate enough in this case.<br />In Fig. 5 we juxtapose Perturb-and-MAP samples pro-<br />duced by order-1 and order-2 Gumbel perturbations with a<br />GibbsMRFsamplefromtheIsingmodel, producedwiththe<br />Propp-Wilson exact sampling algorithm [21]. We have fit-<br />ted the parameters of the Perturb-and-MAP models by mo-<br />ment matching so that they reproduce the first and second<br />order statistics of the Gibbs sample. We see that even the<br />order-1 Gumbel perturbation captures quite well the overall<br />appearance of the exact Gibbs sample. The order-2 sample<br />further improves the approximation quality, better capturing<br />the appearance of same-spin clusters in the Gibbs sample.<br />5. Applications and experiments<br />We present experiments with the Perturb-and-MAP<br />model applied to image segmentation and scene labeling.<br />Further results are included in the supplementary material.<br />Software is available from the first author’s web home page.<br />5.1. Interactive image segmentation<br />We first report interactive segmentation experiments,<br />performed on the Grabcut dataset which includes human<br />annotated ground truth segmentations [22]. The task is to<br />segment a foreground object, given a relatively tight tri-map<br />imitating user input obtained by a lasso or pen tool.<br />This is a relatively small dataset (50 images) not split<br />into training and test sets and carefully optimized tech-<br />niques which exploit the regularities of the dataset are</p>  <p>Page 7</p> <p>achieving extremely low pixel misclassification results<br />(around 4.5% using adaptive thresholding on the output of<br />the random walker model [8]) – see [23] for a recent review.<br />In our implementation we closely follow the CRF for-<br />mulation of [23], using the same parameters for defining<br />the image-based CRF terms and considering pixel interac-<br />tions in a 8-neighborhood. We used our Perturb-and-MAP<br />sampling algorithm with order-2 Gumbel perturbation and<br />QPBO optimization [16] to learn the weights of the poten-<br />tials – 5 weights in total, one for the unary and one for each<br />of the 4 pairwise connections of the center pixel with its S,<br />E, NE, SE neighbors. Using these parameters, we obtained<br />a classification error rate of 5.6% with the global MAP de-<br />cision rule. This is similar to the best results attainable with<br />the particular CRF model and hand-tuned weights.<br />In Fig. 6 we illustrate the ability of the Perturb-and-MAP<br />model to produce soft segmentation maps. The soft seg-<br />mentation map (average over 20 posterior samples) gives a<br />qualitatively accurate estimate of the segmentation uncer-<br />tainty, which could potentially be useful in guiding user in-<br />teraction in an interactive segmentation application.<br />Figure 6. Interactive image segmentation results on the Grabcut<br />dataset. Parameters learned by PM moment matching. Top: the<br />original image and the least energy MAP solution. Bottom: soft<br />Perturb-and-MAP segmentation and the corresponding mask.<br />5.2. Scene layout labeling<br />We next consider an application of Perturb-and-MAP<br />random fields in scene layout labeling [12]. We use the<br />tiered layout model of [6], which allows exact global infer-<br />ence by efficient dynamic programming [6]. The model has<br />a relatively large number of parameters, making it difficult<br />to hand tune. Training them with the proposed techniques<br />illustrates our ability to effectively learn model parameters<br />from labeled data.<br />We closely follow the evaluation approach of [6] in set-<br />ting up the experiment: We use the dataset of 300 out-<br />door images (and the standard cross-validation splits into<br />training/test sets) with ground truth from [12] for our ex-<br />periments. Similarly to [6], we use five labels: T (sky),<br />B (ground), and three labels for the middle region, L (fac-<br />ing left), R (facing right), C (front facing). We also do not<br />include in our label set the classes “porous” and “solid”.<br />The per-pixel class confidences used as unary terms are pro-<br />duced using classifiers that we trained using the dataset and<br />software provided by [12] following the standard five-fold<br />cross-validation protocol.The small difference between<br />the baseline confidence-only classification results reported<br />by [6] and our baseline result should be attributed to our use<br />of the newer version of Hoiem’s software.<br />We first fit the tiered scene model parameters (pair-<br />wise compatibility tables between the different classes) on<br />the training data using Perturb-and-MAP moment matching<br />(order-1 Gumbel perturbation). Weights are initialized as<br />Potts CRF potentials and refined by moment matching rule;<br />we separated the training set in batches of 10 images each<br />and stopped after 50 epochs over the training set.<br />The following tables report row-normalized confusion<br />matrices for MAP (least energy configuration) and marginal<br />MODE (i.e., assign each pixel to the label that appears most<br />frequentlyin20randomPerturb-And-Mapconditionalsam-<br />ples from the model); in both cases the learned weights are<br />used. Our results are better than the confidence-only base-<br />linemeanaccuracyof82.1%[12], andtheMAPandMODE<br />results of 82.1% and 81.8%, respectively, that we obtained<br />with the hand-set weights of [6].<br />MAP (acc 82.7%)<br />B<br />B 95.3<br />L22.9<br />C 24.3<br />R 16.0<br />T 1.1<br />LC<br />3.3<br />21.9<br />52.5<br />24.8<br />3.1<br />R<br />0.5<br />6.6<br />11.4<br />49.4<br />0.7<br />T<br />0.5<br />46.7<br />6.7<br />4.4<br />0.6<br />0.5<br />1.9<br />5.0<br />5.4<br />94.4<br />Marginal MODE (acc 82.6%)<br />BL<br />B 95.30.5<br />L 23.046.9<br />C24.66.9<br />R16.54.5<br />T1.00.6<br />C<br />3.2<br />21.7<br />51.5<br />24.2<br />3.0<br />R<br />0.5<br />6.6<br />11.7<br />49.1<br />0.8<br />T<br />0.5<br />1.9<br />5.3<br />5.7<br />94.7<br />Table 1. Tiered labeling confusion matrices (learned weights).<br />In Fig. 7 we show some indicative examples of different<br />scene layout labelings obtained by the confidence-only, the<br />MAP, and the Perturb-and-MAP model. The uncertainty of<br />the solution is indicated by entropy maps.<br />6. Perspective<br />The work of Geman and Geman [7] showed that sam-<br />pling coupled with artificial temperature annealing can be<br />used as a general purpose method for finding the least en-<br />ergy configuration in discrete label MRFs. The advent of<br />much faster deterministic energy minimization techniques<br />has decreased interest in sampling as an intermediary for<br />MAP computation.Interestingly, the Perturb-and-MAP<br />model works in the opposite direction to simulated anneal-<br />ing, allowing powerful algorithms for MAP computation to<br />act as intermediaries for MRF sampling. We hope that this<br />researchwillhelpestablishdiscreteoptimizationtechniques<br />as tools for probabilistic modeling in computer vision.</p>  <p>Page 8</p> <p>Figure 7. Tiered scene labeling results with pairwise potentials learned by our Perturb-and-MAP moment matching algorithm. Left to right:<br />image; confidence-only result; least energy MAP solution; single Perturb-and-MAP sample; PM marginal mode; PM marginal entropy.<br />Acknowledgments<br />This work was supported by the U.S. Office of Naval Re-<br />search under the MURI grant N000141010933 and by the<br />Korean Ministry of Education, Science, and Technology,<br />under the National Research Foundation WCU program<br />R31-10008. We thank X. He, I. Kokkinos, and M. Raptis<br />for their feedback and help at various stages of this project.<br />References<br />[1] A. Ben-Tal, L. El Ghaoui, and A. Nemirovski. Robust Opti-<br />mization. Princeton Univ. Press, 2009.<br />[2] J. Besag. Spatial interaction and the statistical analysis of<br />lattice systems. JRSS (B), 36(2):192–236, 1974.<br />[3] J. Besag. Statistical analysis of non-lattice data. The Statis-<br />tician, 24(3):179–195, 1975.<br />[4] S. Boyd and L. Vandenberghe. Convex Optimization. Cam-<br />bridge Univ. Press, 2004.<br />[5] Y. Boykov, O. Veksler, and R. Zabih.<br />energy minimization via graph cuts.<br />23(11):1222–1239, 2001.<br />[6] P. Felzenszwalb and O. Veksler. Tiered scene labeling with<br />dynamic programming. In Proc. CVPR, 2010.<br />[7] S. Geman and D. Geman. Stochastic relaxation, Gibbs distri-<br />butions, and the Bayesian restoration of images. IEEE Trans.<br />PAMI, 6(6):721–741, 1984.<br />[8] L. Grady. Random walks for image segmentation. IEEE<br />Trans. PAMI, 28(11):1768–1783, 2006.<br />[9] D. Gusfield and R. Irving. The Stable Marriage Problem.<br />MIT Press, 1989.<br />[10] G. Hinton. Training products of experts by minimizing con-<br />trastive divergence. Neur. Comp., 14(8):1771–1800, 2002.<br />[11] G. Hinton and T. Sejnowski. Optimal perceptual inference.<br />In Proc. CVPR, pages 448–453, 1983.<br />[12] D. Hoiem, A. Efros, and M. Hebert. Recovering surface lay-<br />out from an image. IJCV, 75(1):151–172, 2007.<br />[13] J. Kleinberg and E. Tardos. Algorithm Design. Addison-<br />Wesley, 2006.<br />[14] P. Kohli and P. Torr. Measuring uncertainty in graph cut so-<br />lutions. Comp. Vision Image Underst., 112(1):30–38, 2008.<br />[15] D. Koller and N. Friedman. Probabilistic Graphical Models.<br />MIT Press, 2009.<br />Fast approximate<br />IEEE Trans. PAMI,<br />[16] V. Kolmogorov and C. Rother. Minimizing non-submodular<br />functions with graph cuts – a review. IEEE Trans. PAMI,<br />29(7):1274–1279, July 2007.<br />[17] V. Kolmogorov and R. Zabih. What energy functions can be<br />minimized via graph cuts? IEEE Trans. PAMI, 26(2):147–<br />159, 2004.<br />[18] D. Kuzmin and M. K. Warmuth. Optimum follow the leader<br />algorithm. In Proc. COLT, pages 684–686, 2005.<br />[19] Y. LeCun, S. Chopra, R. Hadsell, M. Ranzato, and F.-J.<br />Huang. A tutorial on energy-based learning. In Predicting<br />Structured Data. MIT Press, 2007.<br />[20] G. Papandreou and A. Yuille. Gaussian sampling by local<br />perturbations. In Proc. NIPS, 2010.<br />[21] J. Propp and D. Wilson.<br />Markov chains and applications to statistical mechanics.<br />Random Struc. Algor., 9(1):223–252, 1996.<br />[22] C. Rother, V. Kolmogorov, and A. Blake. Grabcut: Interac-<br />tive foreground extraction using iterated graph cuts. In Proc.<br />SIGGRAPH, pages 309–314, 2004.<br />[23] C. Rother, V. Kolmogorov, Y. Boykov, and A. Blake. Inter-<br />active foreground extraction using graph cut. In Advances<br />in Markov Random Fields for Vision and Image Processing.<br />MIT Press, 2011.<br />[24] U. Schmidt, Q. Gao, and S. Roth. A generative perspective<br />on MRFs in low-level vision. In Proc. CVPR, 2010.<br />[25] F. Steutel and K. Van Harn. Infinite divisibility of probability<br />distributions on the real line. Dekker, 2004.<br />[26] M. Szummer, P. Kohli, and D. Hoiem. Learning CRFs using<br />graph cuts. In Proc. ECCV, pages 582–595, 2008.<br />[27] B. Taskar, C. Guestrin, and D. Koller. Max-margin Markov<br />networks. In Proc. NIPS, 2003.<br />[28] M. Wainwright, T. Jaakkola, and A. Willsky.<br />mation via agreement on trees: Message-passing and linear<br />programming. IEEE Trans. Inf. Theory, 51(11):3697–3717,<br />2005.<br />[29] M. Welling. Herding dynamical weights to learn. In Proc.<br />ICML, pages 1121–1128, 2009.<br />[30] O. Woodford, C. Rother, and V. Kolmogorov. A global per-<br />spective on MAP inference for low-level vision. In Proc.<br />ICCV, pages 2319–2326, 2009.<br />[31] S.-C. Zhu, Y. Wu, and D. Mumford. Filters, random fields<br />and maximum entropy (FRAME): Towards a unified theory<br />for texture modeling. IJCV, 27(2):107–126, 1998.<br />Exact sampling with coupled<br />MAP esti-</p>  <a href="https://www.researchgate.net/profile/George_Papandreou/publication/221111135_Perturb-and-MAP_random_fields_Using_discrete_optimization_to_learn_and_sample_from_energy_models/links/02bfe50dbb9bed4be7000000.pdf">Download full-text</a> </div> <div id="rgw19_56ab1aecd0c82" class="c-box pub-resource-container js-toggle" style=""> <h4 class="lf js-expand-list"><small><a href="javascript:" class="lf">View other sources <span class="ico-expand-list"></span></a></small></h4> <h4 class="lf js-collapse-list hidden"><small><a href="javascript:" class="lf">Hide other sources <span class="ico-collapse-list"></span></a></small></h4> <div class="clear"></div> <div class="scroll-wrapper hidden"> <ul class="files-list c-list" id="rgw20_56ab1aecd0c82">  <li class="c-list-item pub-resource-item"  data-type="fulltext" id="rgw21_56ab1aecd0c82"> <span class="ico-pub"></span> <div class="file-content"> <div class="download"> <a href="profile/George_Papandreou/publication/221111135_Perturb-and-MAP_random_fields_Using_discrete_optimization_to_learn_and_sample_from_energy_models/links/02bfe50dbb9bed4be7000000.pdf" class="publication-viewer" title="02bfe50dbb9bed4be7000000.pdf">02bfe50dbb9bed4be7000000.pdf</a> </div>  <div class="details">  <span> Available from <a href="profile/George_Papandreou">George Papandreou</a> &middot; Jun 4, 2014 </span>   </div>    </div> </li>  <li class="c-list-item pub-resource-item"  data-type="fulltext" id="rgw22_56ab1aecd0c82"> <span class="ico-pub"></span> <div class="file-content"> <div class="download"> <a href="http://www.stat.ucla.edu/~gpapan/pubs/confr/PapandreouYuille_PerturbAndMap_ieee-c-iccv11.pdf" target="_blank" rel="nofollow" class="publication-viewer" title="Perturb-and-MAP random fields: Using discrete optimization to learn and sample from energy models">Perturb-and-MAP random fields: Using discrete opti...</a> </div>  <div class="details">   Available from <a href="http://www.stat.ucla.edu/~gpapan/pubs/confr/PapandreouYuille_PerturbAndMap_ieee-c-iccv11.pdf" target="_blank" rel="nofollow">ucla.edu</a>  </div>    </div> </li>  <li class="c-list-item pub-resource-item"  data-type="fulltext" id="rgw23_56ab1aecd0c82"> <span class="ico-pub"></span> <div class="file-content"> <div class="download"> <a href="http://www.stat.ucla.edu/~gpapan/pubs/confr/PapandreouYuille_PerturbAndMap_ieee-c-iccv11.pdf" target="_blank" rel="nofollow" class="publication-viewer" title="Perturb-and-MAP random fields: Using discrete optimization to learn and sample from energy models">Perturb-and-MAP random fields: Using discrete opti...</a> </div>  <div class="details">   Available from <a href="http://www.stat.ucla.edu/~gpapan/pubs/confr/PapandreouYuille_PerturbAndMap_ieee-c-iccv11.pdf" target="_blank" rel="nofollow">ucla.edu</a>  </div>    </div> </li>  <li class="c-list-item pub-resource-item" style="display: none;" data-type="fulltext" id="rgw24_56ab1aecd0c82"> <span class="ico-pub"></span> <div class="file-content"> <div class="download"> <a href="http://www.stat.ucla.edu/~gpapan/pubs/confr/PapandreouYuille_PerturbAndMap_ieee-c-iccv11.pdf" target="_blank" rel="nofollow" class="publication-viewer" title="Perturb-and-MAP random fields: Using discrete optimization to learn and sample from energy models">Perturb-and-MAP random fields: Using discrete opti...</a> </div>  <div class="details">   Available from <a href="http://www.stat.ucla.edu/~gpapan/pubs/confr/PapandreouYuille_PerturbAndMap_ieee-c-iccv11.pdf" target="_blank" rel="nofollow">ucla.edu</a>  </div>    </div> </li>  <li class="c-list-item pub-resource-item" style="display: none;" data-type="fulltext" id="rgw25_56ab1aecd0c82"> <span class="ico-pub"></span> <div class="file-content"> <div class="download"> <a href="http://www.stat.ucla.edu/~gpapan/pubs/confr/PapandreouYuille_PerturbAndMap_ieee-c-iccv11.pdf" target="_blank" rel="nofollow" class="publication-viewer" title="Perturb-and-MAP random fields: Using discrete optimization to learn and sample from energy models">Perturb-and-MAP random fields: Using discrete opti...</a> </div>  <div class="details">   Available from <a href="http://www.stat.ucla.edu/~gpapan/pubs/confr/PapandreouYuille_PerturbAndMap_ieee-c-iccv11.pdf" target="_blank" rel="nofollow">ucla.edu</a>  </div>    </div> </li>  </ul> </div> </div> </noscript> <div class="clearfix"> <div class="action-container">  </div> <div class="pub-legal"> Data provided are for informational purposes only. Although carefully collected, accuracy cannot be guaranteed. The impact factor represents a rough estimation of the journal's impact factor and does not reflect the actual current impact factor. Publisher conditions are provided by RoMEO. Differing provisions from the publisher's actual policy or licence agreement may be applicable. </div>  <div id="rgw32_56ab1aecd0c82" class="citations-container"> <div class="tab-container"> <ul class="tab-list"> <li class="lf tab-item  js-citations"> <a href="javascript:void(0);" class="tab-link"> References  </small> </a> </li>  <li class="lf tab-item tab-item-active js-cited-in js-cited-in-tooltip"> <a href="javascript:void(0);" class="tab-link"> Cited In <small> (19) </small> </a> </li>    <li class="rf"> <div class="dropdown js-citations-sorter dropdown-right-align" style="position: relative; bottom: -1px;display:none;"> <a href="javascript:void(0);" class="dropdown-toggle"> Sorted by: <strong class="js-current-sorting"> Order of availability  </strong> <span class="caret"></span> </a> <ul class="dropdown-menu"> <li><a href="javascript:void(0);" data-sort="normal">Order of availability</a></li> <li><a href="javascript:void(0);" data-sort="original">Appearance in publication</a></li> </ul> </div> </li>  </ul> <div class="tab-section tab-section-active js-citations-list-container"> <div id="rgw33_56ab1aecd0c82" class="pub-citations-list">  <ul class="c-list">  <li class="c-list-item li-publication   includes-citation-list"  id="rgw34_56ab1aecd0c82" >  <div class="indent-left">  <div id="rgw35_56ab1aecd0c82" class="js-publication-item-fulltext fulltext-thumb">    <a class="publication-preview ga-publication-viewer js-publication-item-fulltext-content" href="publication/285598250_A_Randomized_Ensemble_Approach_to_Industrial_CT_Segmentation">       </a>   <div class="preview-source-info"> <a class="details js-show-source ga-source-url" href="profile/Peer-Timo_Bremer" >Source</a>  <div class="tooltip-content" style="display: none"> Available from: Peer-Timo Bremer </div> </div>   </div>  </div>  <div class="indent-right">      </div>  <ul class="citation-contexts" id="rgw36_56ab1aecd0c82">  <li class="citation-context-item"> "Batra et al. [4] developed a sequential model selection technique that emphasized the diversity of the solutions and showed it can produce significantly better results. An alternative approach to generating multiple hypotheses is to use sampling strategies that perturb the parameters of a segmentation algorithm [6] [18] [17]. However, refining these solutions can be challenging if the data is sensitive to the parameter settings. " </li>  </ul>   <div  style="margin-top: -2px">  <h5 class="pub-type-and-title">  <span class="publication-type">Conference Paper:</span>    <a class="js-publication-title-link js-go-to-publication ga-publication-item" href="publication/285598250_A_Randomized_Ensemble_Approach_to_Industrial_CT_Segmentation"> <span class="publication-title js-publication-title">A Randomized Ensemble Approach to Industrial CT Segmentation</span> </a>     </h5>  </div>    <div class="authors">     <a href="researcher/2086945186_Hyojin_Kim" class="authors js-author-name ga-publications-authors">Hyojin Kim</a> &middot;     <a href="researcher/38658732_Peer-Timo_Bremer" class="authors js-author-name ga-publications-authors">Peer-Timo Bremer</a> &middot;     <a href="researcher/70250322_Jayaraman_J_Thiagarajan" class="authors js-author-name ga-publications-authors">Jayaraman J. Thiagarajan</a>      </div>        <div class="abstract"> <span class="shorten"> <a href="javascript:" class="js-toggle-abstract">[Show abstract]</a> </span> <span class="full"> <a href="javascript:" class="js-toggle-abstract">[Hide abstract]</a><br/>  <strong>ABSTRACT:</strong> Tuning the models and parameters of common segmen-tation approaches is challenging especially in the presence of noise and artifacts. Ensemble-based techniques attempt to compensate by randomly varying models and/or parameters to create a diverse set of hypotheses, which are subsequently ranked to arrive at the best solution. However, these methods have been restricted to cases where the underlying models are well established, e.g. natural images. In practice , it is difficult to determine a suitable base-model and the amount of randomization required. Furthermore, for multi-object scenes no single hypothesis may perform well for all objects, reducing the overall quality of the results. This paper presents a new ensemble-based segmenta-tion framework for industrial CT images demonstrating that comparatively simple models and randomization strategies can significantly improve the result over existing techniques. Furthermore, we introduce a per-object based ranking , followed by a consensus inference that can outperform even the best case scenario of existing hypothesis ranking approaches. We demonstrate the effectiveness of our approach using a set of noise and artifact rich CT images from baggage security and show that it significantly outperforms existing solutions in this area. </span> </div>    <div class="publication-meta publication-meta">   <span class="ico-publication-fulltext reset-background"></span> Full-text   &middot; Conference Paper &middot; Dec 2015  </div>        <div class="publication-actions"> <div class="btn-group">  <a class="btn btn-plain action-download primary  open-viewer" href="profile/Peer-Timo_Bremer/publication/285598250_A_Randomized_Ensemble_Approach_to_Industrial_CT_Segmentation/links/5661c7aa08ae15e7462ddd7c.pdf?origin=publication_list">  <span class="js-btn-label">Download</span> </a>    </div> </div>      </li>  <li class="c-list-item li-publication   includes-citation-list"  id="rgw37_56ab1aecd0c82" >  <div class="indent-left">  <div id="rgw38_56ab1aecd0c82" class="js-publication-item-fulltext fulltext-thumb">    <a class="publication-preview ga-publication-viewer js-publication-item-fulltext-content" href="publication/282613694_Inferring_M-Best_Diverse_Labelings_in_a_Single_One">       </a>   <div class="preview-source-info"> <a class="details js-show-source ga-source-url" href="profile/Bogdan_Savchynskyy" >Source</a>  <div class="tooltip-content" style="display: none"> Available from: Bogdan Savchynskyy </div> </div>   </div>  </div>  <div class="indent-right">      </div>  <ul class="citation-contexts" id="rgw39_56ab1aecd0c82">  <li class="citation-context-item"> "Gibbs sampling [12] may take prohibitively long to transfer between modes of the underlying distribution. Perturband-map [23] does not have these drawbacks, but is limited " </li>  </ul>   <div  style="margin-top: -2px">  <h5 class="pub-type-and-title">  <span class="publication-type">Conference Paper:</span>    <a class="js-publication-title-link js-go-to-publication ga-publication-item" href="publication/282613694_Inferring_M-Best_Diverse_Labelings_in_a_Single_One"> <span class="publication-title js-publication-title">Inferring M-Best Diverse Labelings in a Single One</span> </a>     </h5>  </div>    <div class="authors">     <a href="researcher/2082332237_Alexander_Kirillov" class="authors js-author-name ga-publications-authors">Alexander Kirillov</a> &middot;     <a href="researcher/70093259_Bogdan_Savchynskyy" class="authors js-author-name ga-publications-authors">Bogdan Savchynskyy</a> &middot;     <a href="researcher/59293579_Dmitrij_Schlesinger" class="authors js-author-name ga-publications-authors">Dmitrij Schlesinger</a> &middot;     <a href="researcher/2082333728_Dmitry_Vetrov" class="authors js-author-name ga-publications-authors">Dmitry Vetrov</a> &middot;     <a href="researcher/38896161_Carsten_Rother" class="authors js-author-name ga-publications-authors">Carsten Rother</a>      </div>        <div class="abstract"> <span class="shorten"> <a href="javascript:" class="js-toggle-abstract">[Show abstract]</a> </span> <span class="full"> <a href="javascript:" class="js-toggle-abstract">[Hide abstract]</a><br/>  <strong>ABSTRACT:</strong> We consider the task of finding M-best diverse solutions in a graphical model. In a previous work by Batra et al. an algorithmic approach for finding such solutions was proposed , and its usefulness was shown in numerous applications. Contrary to previous work we propose a novel formulation of the problem in form of a single energy minimization problem in a specially constructed graphical model. We show that the method of Batra et al. can be considered as a greedy approximate algorithm for our model, whereas we introduce an efficient specialized optimization technique for it, based on alpha-expansion. We evaluate our method on two application scenarios, interactive and semantic image segmentation, with binary and multiple labels. In both cases we achieve considerably better error rates than state-of-the art diversity methods. Furthermore, we empirically discover that in the binary label case we were able to reach global optimality for all test instances. </span> </div>    <div class="publication-meta publication-meta">   <span class="ico-publication-fulltext reset-background"></span> Full-text   &middot; Conference Paper &middot; Dec 2015  </div>        <div class="publication-actions"> <div class="btn-group">  <a class="btn btn-plain action-download primary  open-viewer" href="profile/Bogdan_Savchynskyy/publication/282613694_Inferring_M-Best_Diverse_Labelings_in_a_Single_One/links/561437c408ae4ce3cc639665.pdf?origin=publication_list">  <span class="js-btn-label">Download</span> </a>    </div> </div>      </li>  <li class="c-list-item li-publication   includes-citation-list"  id="rgw40_56ab1aecd0c82" >  <div class="indent-left">  <div id="rgw41_56ab1aecd0c82" class="js-publication-item-fulltext fulltext-thumb">    <a class="publication-preview ga-publication-viewer js-publication-item-fulltext-content" href="publication/277723496_A_Framework_for_Efficient_Structured_Max-Margin_Learning_of_High-Order_MRF_models">       </a>   <div class="preview-source-info"> <a class="details js-show-source ga-source-url" href="deref/https%3A%2F%2Fhal.inria.fr%2Fhal-01090971%2Ffile%2FRR-8645.pdf" target="_blank" >Source</a>  <div class="tooltip-content" style="display: none"> Available from: hal.inria.fr </div> </div>   </div>  </div>  <div class="indent-right">      </div>  <ul class="citation-contexts" id="rgw42_56ab1aecd0c82">  <li class="citation-context-item"> "It should be mentioned at this point that, over the last years, additional types of structured prediction training methods have been proposed that can make use of various other types of learning objective functions and losses, as well as optimization algorithms [ 10, 15, 39, 41, 42, 47, 49, 50, 60, 62]. This also includes recent cases such as the inference-machines framework proposed in [43], as well as various types of randomized models such as the &quot; Perturb-and-MAP&quot; framework [48] or the &quot; randomized optimum models&quot; described in [61]. Also, a pseudo-max approach to structured learning (inspired by the pseudo-likelihood method) is proposed in [ 57], where the authors also analyze for which cases such an approach leads to consistent training. " </li>  </ul>   <div  style="margin-top: -2px">  <h5 class="pub-type-and-title">  <span class="publication-type">Article:</span>    <a class="js-publication-title-link js-go-to-publication ga-publication-item" href="publication/277723496_A_Framework_for_Efficient_Structured_Max-Margin_Learning_of_High-Order_MRF_models"> <span class="publication-title js-publication-title">A Framework for Efficient Structured Max-Margin Learning of High-Order MRF models</span> </a>     </h5>  </div>    <div class="authors">     <a href="researcher/39738510_Nikos_Komodakis" class="authors js-author-name ga-publications-authors">Nikos Komodakis</a> &middot;     <a href="researcher/71080186_Bo_Xiang" class="authors js-author-name ga-publications-authors">Bo Xiang</a> &middot;     <a href="researcher/38411370_Nikos_Paragios" class="authors js-author-name ga-publications-authors">Nikos Paragios</a>      </div>        <div class="abstract"> <span class="shorten"> <a href="javascript:" class="js-toggle-abstract">[Show abstract]</a> </span> <span class="full"> <a href="javascript:" class="js-toggle-abstract">[Hide abstract]</a><br/>  <strong>ABSTRACT:</strong> We present a very general algorithm for structured prediction learning that is able to efficiently handle discrete MRFs/CRFs (including both pairwise and higher-order models) so long as they can admit a decomposition into tractable subproblems. At its core, it relies on a dual decomposition principle that has been recently employed in the task of MRF optimization. By properly combining such an approach with a max-margin learning method, the proposed framework manages to reduce the training of a complex high-order MRF to the parallel training of a series of simple slave MRFs that are much easier to handle. This leads to a very efficient and general learning scheme that relies on solid mathematical principles. We thoroughly analyze its theoretical properties, and also show that it can yield learning algorithms of increasing accuracy since it naturally allows a hierarchy of convex relaxations to be used for loss-augmented MAP-MRF inference within a max-margin learning approach. Furthermore, it can be easily adapted to take advantage of the special structure that may be present in a given class of MRFs. We demonstrate the generality and flexibility of our approach by testing it on a variety of scenarios, including training of pairwise and higher-order MRFs, training by using different types of regularizers and/or different types of dissimilarity loss functions, as well as by learning of appropriate models for a variety of vision tasks (including high-order models for compact pose-invariant shape priors, knowledge-based segmentation, image denoising, stereo matching as well as high-order Potts MRFs). </span> </div>    <div class="publication-meta publication-meta">  <span class="ico-publication-preview reset-background"></span> Preview    &middot; Article &middot; Jul 2015  &middot; IEEE Transactions on Pattern Analysis and Machine Intelligence  </div>        <div class="publication-actions"> <div class="btn-group">  <a class="btn btn-plain action-request-external  " href="javascript:;" data-context="pubCit">  <span class="js-btn-label">Request full-text</span> </a>    </div> </div>      </li>  </ul>    <a class="show-more-rebranded js-show-more rf text-gray-lighter">Show more</a> <span class="ajax-loading-small list-loading" style="display: none"></span>  <div class="clearfix"></div>  <div class="publication-detail-sidebar-legal">Note: This list is based on the publications in our database and might not be exhaustive.</div> <div class="clearfix"></div>  </div> </div> </div> </div> </div> </div> <div class="clearfix">     <div id="rgw27_56ab1aecd0c82" class="c-box pub-resource-container js-toggle" style="display: none;"> <h4 class="lf js-expand-list"><small><a href="javascript:" class="lf">View other sources <span class="ico-expand-list"></span></a></small></h4> <h4 class="lf js-collapse-list hidden"><small><a href="javascript:" class="lf">Hide other sources <span class="ico-collapse-list"></span></a></small></h4> <div class="clear"></div> <div class="scroll-wrapper hidden"> <ul class="files-list c-list" id="rgw28_56ab1aecd0c82">  </ul> </div> </div>   <div id="rgw15_56ab1aecd0c82" class="similar-publications"> <h2>Similar Publications</h2> <ul class="list-bordered">  <li class="c-list-item li-publication-teaser" id="rgw16_56ab1aecd0c82"> <div> <h5> <a href="publication/282556143_Image_Segmentation_via_Improving_Clustering_Algorithms_with_Density_and_Distance" class="color-inherit ga-similar-publication-title"><span class="publication-title">Image Segmentation via Improving Clustering Algorithms with Density and Distance</span></a>  </h5>  <div class="authors"> <a href="researcher/2082288016_Zhensong_Chen" class="authors ga-similar-publication-author">Zhensong Chen</a>, <a href="researcher/2082235606_Zhiquan_Qi" class="authors ga-similar-publication-author">Zhiquan Qi</a>, <a href="researcher/2082219266_Fan_Meng" class="authors ga-similar-publication-author">Fan Meng</a>, <a href="researcher/2048923776_Limeng_Cui" class="authors ga-similar-publication-author">Limeng Cui</a>, <a href="researcher/2071664448_Yong_Shi" class="authors ga-similar-publication-author">Yong Shi</a>  </div>  </div> <div class="clear"></div> </li>  <li class="c-list-item li-publication-teaser" id="rgw17_56ab1aecd0c82"> <div> <h5> <a href="publication/277947759_Computer_Aided_Melanoma_Skin_Cancer_Detection_Using_Image_Processing" class="color-inherit ga-similar-publication-title"><span class="publication-title">Computer Aided Melanoma Skin Cancer Detection Using Image Processing</span></a>  </h5>  <div class="authors"> <a href="researcher/2075397633_Shivangi_Jain" class="authors ga-similar-publication-author">Shivangi Jain</a>, <a href="researcher/2075383204_Vandana_jagtap" class="authors ga-similar-publication-author">Vandana jagtap</a>, <a href="researcher/2075435824_Nitin_Pise" class="authors ga-similar-publication-author">Nitin Pise</a>  </div>  </div> <div class="clear"></div> </li>  <li class="c-list-item li-publication-teaser" id="rgw18_56ab1aecd0c82"> <div> <h5> <a href="publication/281720522_An_enhanced_image_restoration_of_broken_characters_based_on_thresholding_techniques" class="color-inherit ga-similar-publication-title"><span class="publication-title">An enhanced image restoration of broken characters based on thresholding techniques</span></a>  </h5>  <div class="authors"> <a href="researcher/2080885282_QO_Mosa" class="authors ga-similar-publication-author">Q.O. Mosa</a>, <a href="researcher/2080869027_MF_Nasrudin" class="authors ga-similar-publication-author">M.F. Nasrudin</a>  </div>  </div> <div class="clear"></div> </li>  </ul> </div> </div> </div> </div> </div></div></div>
<div class="clear"></div><div id="rgw52_56ab1aecd0c82" class="default-footer"> <div id="footer" class="clearfix"> <span class="footer-left"> &copy; 2008&dash;2016 researchgate.net. All rights reserved. </span> <span class="footer-right"> <a href="https://www.researchgate.net/about">About us</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="https://www.researchgate.net/contact">Contact us</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="careers">Careers</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="developers">Developers</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="blog" target="_blank">News</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="application.PrivacyPolicy.html">Privacy</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="application.TermsAndConditions.html">Terms</a> <span class="footer-link-separator" style="padding: 0 5px;">&nbsp;|&nbsp;</span> <a href="advertising?_ref=ft">Advertising</a> <span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="recruiters?_ref=ft">Recruiting</a> </span> </div>  </div></div>
<div id="rgw53_56ab1aecd0c82">  <div class="header-wrapper-logged-out"> <div id="header"> <div class="header-content"> <a href="" class="g-l-logo"> <svg width="149" height="19"> <image xlink:href="https://c5.rgstatic.net/m/235107188705592/images/template/brand-header-logo.svg" src="https://c5.rgstatic.net/m/238113351022438/images/template/brand-header-logo.png" width="149" height="19"/> </svg> </a> <a href="" class="g-l-logo-ico"> <svg width="127" height="17" viewbox="0 0 127 22"> <image xlink:href="https://c5.rgstatic.net/m/235107188705592/images/template/brand-header-logo.svg" src="https://c5.rgstatic.net/m/238113351022438/images/template/brand-header-logo.png" width="127" height="17"/> </svg> </a> <div id="rgw54_56ab1aecd0c82" class="header-login-wrapper js-header-login"> <div class="dropdown-right-align"> <div class="login-signup-container lf"> <a href="https://www.researchgate.net/signup.SignUp.html?ev=su_chnl_index&amp;hdrsu=1&amp;_sg=bFbpAUf8v5WEoKKz5cLtd4UN4xC1Ftf4uYYVkTVUcfOU0WwxB0SArEpMcTdHfA1v" class="dropdown-toggle lf">Join for free</a> </div> <div class="dropdown lf" style="height: 20px;"> <a href="https://www.researchgate.net/application.Login.html" class="js-login-url dropdown-toggle lf">Log in <span class="caret"></span></a> <div class="dropdown-menu"> <div class="header-login-form-wrapper"> <!--[if IE 6]><p class="box-warning" style="margin-bottom: 0;">Sorry, ResearchGate no longer supports the version of Internet Explorer you are using. <a href="http://whatbrowser.org/" rel="nofollow" target="_blank">Update your web browser</a> and then log in. </p><![endif]--> <form method="post" action="https://www.researchgate.net/application.Login.html" class="form-big header-login-form js-login-form" name="loginForm" id="headerLoginForm"> <input type="hidden" name="request_token" value="ddtKJ2Crxh5t60BqNOjFag7sQLF3HvHQut7Fbk0RLE5KLwbA8g7NkTRDHabC2Ql/bT3BIbqSGb24fL4rxNVAXS11n2FvoCzb34Y4WzXzAqpAUMGka+0qJMJq+qKoSXaNhG4MaMOMhT0Dybfo48HHFmazewKvQZeGIGJHxVbpkzgACTCYJtOBdA5QGp4be6rRXK7G7pNEF8hq8yIhnk+svQHat+Ko2IY8z8OqpcntGWMoRETG18w7WPfNEQBWOdHnACPSoSLr3PHeChcJPc6ms4cDYGQ+qsuJ+2MSb4nIR7I="/> <input type="hidden" name="urlAfterLogin" value="publication/221111135_Perturb-and-MAP_random_fields_Using_discrete_optimization_to_learn_and_sample_from_energy_models"/> <input type="hidden" name="invalidPasswordCount" value="0"/> <input type="hidden" name="headerLogin" value="yes"/> <label for="input-header-login">Email</label> <div class="login-input"> <div class="info-tip-wrapper"> <span class="ico-info js-info"></span> </div> <input type="email" value="" name="login" class="login js-login-input text" id="input-header-login" tabindex="1"/> </div> <div class="clear"></div> <label class="lf" for="input-header-password"> Password </label> <a class="rf forgot-password js-forgot-password" href="application.LostPassword.html">Forgot password?</a> <div class="clear"></div> <input type="password" value="" name="password" class="password js-password-input text" id="input-header-password" tabindex="2"/> <div class="clear"></div> <label class="remember-me" for="headerLoginCookie"> <input type="checkbox" checked="checked" value="yes" name="setLoginCookie" class="lf checkbox" id="headerLoginCookie" tabindex="3"/> Keep me logged in </label> <div class="clear"></div> <input value="Log in" name="loginSubmit" class="btn btn-promote btn-fullwidth btn-large allow-leave js-submit-button" type="submit" tabindex="4"/> </form> <div class="connectors"> <div class="text">or log in with</div> <div class="connector-actions"> <a href="connector/linkedin/" class="li-connect js-li-connect" data-redirect-url="cHVibGljYXRpb24vMjIxMTExMTM1X1BlcnR1cmItYW5kLU1BUF9yYW5kb21fZmllbGRzX1VzaW5nX2Rpc2NyZXRlX29wdGltaXphdGlvbl90b19sZWFybl9hbmRfc2FtcGxlX2Zyb21fZW5lcmd5X21vZGVscw%3D%3D"> <span class="icon ico-linkedin-round-grey"></span> <span class="icon ico-linkedin-round"></span> </a> <a href="connector/facebook/" class="fb-connect middle js-fb-connect" data-redirect-url="cHVibGljYXRpb24vMjIxMTExMTM1X1BlcnR1cmItYW5kLU1BUF9yYW5kb21fZmllbGRzX1VzaW5nX2Rpc2NyZXRlX29wdGltaXphdGlvbl90b19sZWFybl9hbmRfc2FtcGxlX2Zyb21fZW5lcmd5X21vZGVscw%3D%3D"> <span class="icon ico-facebook-round-grey"></span> <span class="icon ico-facebook-round"></span> </a> <a href="connector/google/" class="g-connect js-g-connect" data-redirect-url="cHVibGljYXRpb24vMjIxMTExMTM1X1BlcnR1cmItYW5kLU1BUF9yYW5kb21fZmllbGRzX1VzaW5nX2Rpc2NyZXRlX29wdGltaXphdGlvbl90b19sZWFybl9hbmRfc2FtcGxlX2Zyb21fZW5lcmd5X21vZGVscw%3D%3D"> <span class="icon ico-google-round-grey"></span> <span class="icon ico-google-round"></span> </a> </div> </div> </div> </div> </div> </div> </div> </div> </div> <script type="application/ld+json">
{ "@context" : "http://schema.org",
  "@type" : "Organization",
  "name" : "ResearchGate",
  "url" : "http://www.researchgate.net",
  "logo" : "http://www.researchgate.net/images/template/rg_logo_square_brand.png",
  "sameAs" : [ "https://www.facebook.com/ResearchGate",
    "https://twitter.com/ResearchGate",
    "https://plus.google.com/+researchgate",
    "https://www.linkedin.com/company/researchgate"] 
}
</script> </div> </div><div class="c-signup-bar" id="rgw55_56ab1aecd0c82"> <div class="banner-contents">   <span class="message">ResearchGate is the professional network for scientists and researchers.</span> <a href="signup.SignUp.html?ev=su_banner" class="btn btn-large btn-promote">Join for free</a>  </div> </div></div>
<script>
rgConfig.backendTime = 835;
</script>
<script src="//c5.rgstatic.net/m/2277196935388619/javascript/lib/yui3/yui/yui-min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/2448732603281275/javascript/yuiLoaderConfig-min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/23178613132105398/javascript/vendor/babel-core/browser-polyfill.min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/2198378204065/javascript/min/lib/error_logging.js" type="text/javascript"></script>
<script>
(function (){
if (typeof YRG === "undefined") {
var xmlHttpRequest = new XMLHttpRequest();
xmlHttpRequest.open("post", "go.Error.html");
xmlHttpRequest.setRequestHeader("Content-Type", "application/json");
xmlHttpRequest.setRequestHeader("Accept", "application/json"); var loadedScripts = "";
if (window.performance && window.performance.getEntriesByType) {
    var result = [];
    var resources = performance.getEntriesByType("resource");
    for (var i in resources) {
        if (resources.hasOwnProperty(i)) {
            result.push({
                name: resources[i].name,
                duration: resources[i].duration
            });
        }
    }
    loadedScripts += "&loadedScripts=" + encodeURIComponent(JSON.stringify(result));
}
if (typeof YUI === "undefined") {
    loadedScripts += "&yuiLoaded=false";
} else {
    loadedScripts += "&yuiLoaded=true";
}
xmlHttpRequest.send("Type=InformationException&message=" + encodeURIComponent("Error loading YUI") + loadedScripts);
}
})();
</script>
<script>if (typeof YRG !== 'undefined') { YRG.use('rg-base',function(Y){Y.applyConfig({ignore: ["css-rg","css-rg2","css-ie","css-modules-publicprofile","css-pow-publicliterature-FollowPublicationPromo","css-pow-application-PdfJsReader","css-pow-publicliterature-PublicationInlineReader"]});Y.use(["rg.core.pagespeed.Monitoring"],function(Y){(function(){Y.rg.createInitialWidget({"data":{"content":{"data":{"profileSmallHeader":{"data":{"profileBadge":{"data":{"fullname":"George Papandreou","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2671872220764\/images\/template\/default\/profile\/profile_default_m.jpg","profileStats":[],"profileFollowButton":null,"profileReputationScoreNumber":null,"profileUrl":"profile\/George_Papandreou","institution":"Toyota Technological Institute at Chicago","institutionUrl":false,"widgetId":"rgw4_56ab1aecd0c82"},"id":"rgw4_56ab1aecd0c82","partials":[],"templateName":"publicprofile\/stubs\/ProfileBadge.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicprofile.ProfileBadge.html?accountId=2492803","viewClass":null,"yuiModules":["css-modules-publicprofile"],"stylesheets":["modules\/publicprofile.css"],"_isYUI":true},"widgetId":"rgw3_56ab1aecd0c82"},"id":"rgw3_56ab1aecd0c82","partials":[],"templateName":"publicprofile\/stubs\/ProfileSmallHeader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicprofile.ProfileSmallHeader.html?publicationUid=221111135","viewClass":null,"yuiModules":["css-modules-publicprofile"],"stylesheets":["modules\/publicprofile.css"],"_isYUI":true},"publication":{"data":{"publicationUid":221111135,"title":"Perturb-and-MAP random fields: Using discrete optimization to learn and sample from energy models","journalTitle":"Proceedings \/ IEEE International Conference on Computer Vision. IEEE International Conference on Computer Vision","journalDetailsTooltip":{"data":{"journalTitle":"Proceedings \/ IEEE International Conference on Computer Vision. IEEE International Conference on Computer Vision","journalAbbrev":null,"publisher":"IEEE International Conference on Computer Vision; IEEE Computer Society","issn":"1550-5499","impactFactor":"0.00","fiveYearImpactFactor":"0.00","citedHalfLife":"0.00","immediacyIndex":"0.00","eigenFactor":"0.00","articleInfluence":"0.00","widgetId":"rgw6_56ab1aecd0c82"},"id":"rgw6_56ab1aecd0c82","partials":[],"templateName":"publicliterature\/stubs\/JournalInfo.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.JournalInfo.html?issn=1550-5499","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"affiliation":false,"type":"Conference Paper","details":{"doi":"10.1109\/ICCV.2011.6126242","conferenceInfos":"Conference: IEEE International Conference on Computer Vision, ICCV 2011, Barcelona, Spain, November 6-13, 2011"},"source":{"sourceUrl":"http:\/\/dblp.uni-trier.de\/db\/conf\/iccv\/iccv2011.html#PapandreouY11","sourceName":"DBLP"},"publicationActions":null,"publicationCoins":{"data":{"tags":[{"key":"ctx_ver","value":"Z39.88-2004"},{"key":"rft_val_fmt","value":"info:ofi\/fmt:kev:mtx:journal"},{"key":"rfr_id","value":"info:sid\/researchgate.net:researchgate"},{"key":"rft_id","value":"info:doi\/10.1109\/ICCV.2011.6126242"},{"key":"rft.atitle","value":"Perturb-and-MAP random fields: Using discrete optimization to learn and sample from energy models"},{"key":"rft.title","value":"Proceedings of the IEEE International Conference on Computer Vision"},{"key":"rft.jtitle","value":"Proceedings of the IEEE International Conference on Computer Vision"},{"key":"rft.date","value":"2011"},{"key":"rft.pages","value":"193-200"},{"key":"rft.issn","value":"1550-5499"},{"key":"rft.au","value":"George Papandreou,Alan L. Yuille"},{"key":"rft.genre","value":"inProceedings"}],"widgetId":"rgw7_56ab1aecd0c82"},"id":"rgw7_56ab1aecd0c82","partials":[],"templateName":"publicliterature\/stubs\/PublicationCoins.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationCoins.html?publicationUid=221111135","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationAuthors":{"data":{"publicationUid":221111135,"peopleItems":[{"data":{"authorNameOnPublication":"George Papandreou","accountUrl":"profile\/George_Papandreou","accountKey":"George_Papandreou","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2671872220764\/images\/template\/default\/profile\/profile_default_m.jpg","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"George Papandreou","profile":{"professionalInstitution":{"professionalInstitutionName":"Toyota Technological Institute at Chicago","professionalInstitutionUrl":"institution\/Toyota_Technological_Institute_at_Chicago"}},"professionalInstitutionName":"Toyota Technological Institute at Chicago","professionalInstitutionUrl":"institution\/Toyota_Technological_Institute_at_Chicago","url":"profile\/George_Papandreou","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":false,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":true,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"accountKey":"George_Papandreou","hasInfoPopup":false,"hasTeaserPopup":true,"showContactAuthorButton":true,"widgetId":"rgw10_56ab1aecd0c82"},"id":"rgw10_56ab1aecd0c82","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAccountItem.html?entityId=2492803&enableUnfollow=0&imageSize=l&enableFollowButton=0&showContactAuthorButton=1","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"accountInstitution":"Toyota Technological Institute at Chicago","score":null,"largeTooltip":false,"useRebrandedImageStyle":null,"authorCount":2,"accountCount":1,"publicationUid":221111135,"widgetId":"rgw9_56ab1aecd0c82"},"id":"rgw9_56ab1aecd0c82","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAccountItem.html","templateExtensions":[],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAccountItem.html?accountId=2492803&context=pubdetail_authors_xflw&showContactAuthorButton=1&authorCount=2&accountCount=1&publicationUid=221111135","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true},{"data":{"authorUrl":"researcher\/38628756_Alan_L_Yuille","authorNameOnPublication":"Alan L. Yuille","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg","imageSize":"s","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Alan L. Yuille","profile":{"professionalInstitution":{"professionalInstitutionName":false,"professionalInstitutionUrl":null}},"professionalInstitutionName":false,"professionalInstitutionUrl":null,"url":"researcher\/38628756_Alan_L_Yuille","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":true,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":false,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"widgetId":"rgw12_56ab1aecd0c82"},"id":"rgw12_56ab1aecd0c82","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAuthorItem.html?entityId=38628756&imageSize=l&enableAuthorInviteButton=0","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"largeTooltip":false,"useRebrandedImageStyle":null,"widgetId":"rgw11_56ab1aecd0c82"},"id":"rgw11_56ab1aecd0c82","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorItem.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorItem.html?authorUid=38628756&authorNameOnPublication=Alan%20L.%20Yuille","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true}],"hasMore":false,"nextOffset":6,"useRebrandedImageStyle":null,"widgetId":"rgw8_56ab1aecd0c82"},"id":"rgw8_56ab1aecd0c82","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorList.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorList.html?publicationUid=221111135&context=pubdetail_authors_xflw&showContactAuthorButton=1","viewClass":"views.publicliterature.PublicationDetailAuthorListView","yuiModules":["rg.views.publicliterature.PublicationDetailAuthorListView"],"stylesheets":[],"_isYUI":true},"publicationAbstract":{"data":{"publicationUid":221111135,"abstract":"<noscript><\/noscript><div>We propose a novel way to induce a random field from an energy function on discrete labels. It amounts to locally injecting noise to the energy potentials, followed by finding the global minimum of the perturbed energy function. The resulting Perturb-and-MAP random fields harness the power of modern discrete energy minimization algorithms, effectively transforming them into efficient random sampling algorithms, thus extending their scope beyond the usual deterministic setting. In this fashion we can enjoy the benefits of a sound probabilistic framework, such as the ability to represent the solution uncertainty or learn model parameters from training data, while completely bypassing costly Markov-chain Monte-Carlo procedures typically associated with discrete label Gibbs Markov random fields (MRFs). We study some interesting theoretical properties of the proposed model in juxtaposition to those of Gibbs MRFs and address the issue of principled design of the perturbation process. We present experimental results in image segmentation and scene labeling that illustrate the new qualitative aspects and the potential of the proposed model for practical computer vision applications.<\/div>","canEdit":false,"isAdmin":false,"isArtifact":false,"showFullAbstract":true,"widgetId":"rgw13_56ab1aecd0c82"},"id":"rgw13_56ab1aecd0c82","partials":[],"templateName":"publicliterature\/stubs\/PublicationAbstract.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationAbstract.html?publicationUid=221111135","viewClass":"views.publicliterature.PublicationAbstractView","yuiModules":["rg.views.publicliterature.PublicationAbstractView"],"stylesheets":[],"_isYUI":true},"publicationKeywords":null,"publicationState":null,"isGuest":true,"isAdminEditingAllowed":false,"isArtifact":false,"figureListWidget":null,"previewImage":"https:\/\/i1.rgstatic.net\/publication\/221111135_Perturb-and-MAP_random_fields_Using_discrete_optimization_to_learn_and_sample_from_energy_models\/links\/02bfe50dbb9bed4be7000000\/smallpreview.png","nativeAdDisclosure":null,"showFollowPublicationButton":false,"followPublicationPromo":{"data":{"widgetId":"rgw14_56ab1aecd0c82"},"id":"rgw14_56ab1aecd0c82","partials":[],"templateName":"publicliterature\/stubs\/FollowPublicationPromo.html","templateExtensions":[],"attrs":{"context":null,"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.FollowPublicationPromo.html","viewClass":null,"yuiModules":["css-pow-publicliterature-FollowPublicationPromo"],"stylesheets":["pow\/publicliterature\/FollowPublicationPromo.css"],"_isYUI":true},"widgetId":"rgw5_56ab1aecd0c82"},"id":"rgw5_56ab1aecd0c82","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailItem.html","templateExtensions":["generalHelpers"],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailItem.html?publicationUid=221111135&showActionBar=0&showContactAuthorButton=1&showRequestFulltextExperience=0&showNoRgAuthorsRequestFulltextExperience=0&showFollowPublicationPromo=1","viewClass":"views.publicliterature.PublicationDetailItemView","yuiModules":["rg.views.publicliterature.PublicationDetailItemView"],"stylesheets":[],"_isYUI":true},"similarPublications":{"data":{"publicationListItems":[{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore","clickThrough":"experimentMilestoneClickedToPublicationFromReferenceWithNoFulltext","clickThroughWithContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":2082288016,"url":"researcher\/2082288016_Zhensong_Chen","fullname":"Zhensong Chen","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2082235606,"url":"researcher\/2082235606_Zhiquan_Qi","fullname":"Zhiquan Qi","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2082219266,"url":"researcher\/2082219266_Fan_Meng","fullname":"Fan Meng","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":{"id":2048923776,"url":"researcher\/2048923776_Limeng_Cui","fullname":"Limeng Cui","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},"surplusAuthors":1,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Dec 2015","journal":"Procedia Computer Science","showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/282556143_Image_Segmentation_via_Improving_Clustering_Algorithms_with_Density_and_Distance","usePlainButton":true,"publicationUid":282556143,"feedStubs":null,"hasFeedStubs":false,"impactPoints":false,"url":"publication\/282556143_Image_Segmentation_via_Improving_Clustering_Algorithms_with_Density_and_Distance","title":"Image Segmentation via Improving Clustering Algorithms with Density and Distance","displayTitleAsLink":true,"authors":[{"id":2082288016,"url":"researcher\/2082288016_Zhensong_Chen","fullname":"Zhensong Chen","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2082235606,"url":"researcher\/2082235606_Zhiquan_Qi","fullname":"Zhiquan Qi","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2082219266,"url":"researcher\/2082219266_Fan_Meng","fullname":"Fan Meng","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2048923776,"url":"researcher\/2048923776_Limeng_Cui","fullname":"Limeng Cui","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2071664448,"url":"researcher\/2071664448_Yong_Shi","fullname":"Yong Shi","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["Procedia Computer Science 12\/2015; 55:1015-1022. DOI:10.1016\/j.procs.2015.07.096"],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/282556143_Image_Segmentation_via_Improving_Clustering_Algorithms_with_Density_and_Distance","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/282556143_Image_Segmentation_via_Improving_Clustering_Algorithms_with_Density_and_Distance\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw16_56ab1aecd0c82"},"id":"rgw16_56ab1aecd0c82","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=282556143","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore","clickThrough":"experimentMilestoneClickedToPublicationFromReferenceWithNoFulltext","clickThroughWithContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":2075397633,"url":"researcher\/2075397633_Shivangi_Jain","fullname":"Shivangi Jain","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2075383204,"url":"researcher\/2075383204_Vandana_jagtap","fullname":"Vandana jagtap","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2075435824,"url":"researcher\/2075435824_Nitin_Pise","fullname":"Nitin Pise","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Dec 2015","journal":"Procedia Computer Science","showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/277947759_Computer_Aided_Melanoma_Skin_Cancer_Detection_Using_Image_Processing","usePlainButton":true,"publicationUid":277947759,"feedStubs":null,"hasFeedStubs":false,"impactPoints":false,"url":"publication\/277947759_Computer_Aided_Melanoma_Skin_Cancer_Detection_Using_Image_Processing","title":"Computer Aided Melanoma Skin Cancer Detection Using Image Processing","displayTitleAsLink":true,"authors":[{"id":2075397633,"url":"researcher\/2075397633_Shivangi_Jain","fullname":"Shivangi Jain","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2075383204,"url":"researcher\/2075383204_Vandana_jagtap","fullname":"Vandana jagtap","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2075435824,"url":"researcher\/2075435824_Nitin_Pise","fullname":"Nitin Pise","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["Procedia Computer Science 12\/2015; 48:736-741. DOI:10.1016\/j.procs.2015.04.209"],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/277947759_Computer_Aided_Melanoma_Skin_Cancer_Detection_Using_Image_Processing","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/277947759_Computer_Aided_Melanoma_Skin_Cancer_Detection_Using_Image_Processing\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw17_56ab1aecd0c82"},"id":"rgw17_56ab1aecd0c82","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=277947759","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore","clickThrough":"experimentMilestoneClickedToPublicationFromReferenceWithNoFulltext","clickThroughWithContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":2080885282,"url":"researcher\/2080885282_QO_Mosa","fullname":"Q.O. Mosa","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2080869027,"url":"researcher\/2080869027_MF_Nasrudin","fullname":"M.F. Nasrudin","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Jan 2016","journal":null,"showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/281720522_An_enhanced_image_restoration_of_broken_characters_based_on_thresholding_techniques","usePlainButton":true,"publicationUid":281720522,"feedStubs":null,"hasFeedStubs":false,"impactPoints":false,"url":"publication\/281720522_An_enhanced_image_restoration_of_broken_characters_based_on_thresholding_techniques","title":"An enhanced image restoration of broken characters based on thresholding techniques","displayTitleAsLink":true,"authors":[{"id":2080885282,"url":"researcher\/2080885282_QO_Mosa","fullname":"Q.O. Mosa","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2080869027,"url":"researcher\/2080869027_MF_Nasrudin","fullname":"M.F. Nasrudin","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":[],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/281720522_An_enhanced_image_restoration_of_broken_characters_based_on_thresholding_techniques","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/281720522_An_enhanced_image_restoration_of_broken_characters_based_on_thresholding_techniques\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw18_56ab1aecd0c82"},"id":"rgw18_56ab1aecd0c82","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=281720522","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"viewClass":"sidebar","widgetId":"rgw15_56ab1aecd0c82"},"id":"rgw15_56ab1aecd0c82","partials":[],"templateName":"publicliterature\/stubs\/SimilarPublications.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.SimilarPublications.html?referencePublicationId=221111135&view=sidebar","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationFulltextPreview":null,"publicationResourcesFulltext":{"data":{"publicationUid":221111135,"publicationResourceList":{"data":{"publicationResourceItems":[{"data":{"publicationUid":221111135,"publicationType":"inProceedings","linkId":"02bfe50dbb9bed4be7000000","fileName":"02bfe50dbb9bed4be7000000.pdf","fileUrl":"profile\/George_Papandreou\/publication\/221111135_Perturb-and-MAP_random_fields_Using_discrete_optimization_to_learn_and_sample_from_energy_models\/links\/02bfe50dbb9bed4be7000000.pdf","name":"George Papandreou","nameUrl":"profile\/George_Papandreou","canRemove":false,"fileIcon":"ico-pub","canPreview":true,"hasPublisherLink":null,"hasMetaData":true,"hide":false,"fulltext":"ico-pub","origin":"publication_list","isLastLink":false,"isUserLink":true,"uploadDate":"Jun 4, 2014","fileSize":"507.37 KB","widgetId":"rgw21_56ab1aecd0c82"},"id":"rgw21_56ab1aecd0c82","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceItem.html","templateExtensions":["generalHelpers"],"attrs":{"fileRequiredPublicationTypes":["code","coverPage","experimentFindings","method","negativeResults","presentation","rawData","researchProposal","workingPaper","artifact","dataset"]},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceItem.html?publicationUid=221111135&linkId=02bfe50dbb9bed4be7000000&hide=0&disableJavascript=disableJavascript&useAlternativeTemplate=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"publicationUid":221111135,"publicationType":"inProceedings","linkId":"00afe9160cf2d1b855026413","fileName":"Perturb-and-MAP random fields: Using discrete optimization to learn and sample from energy models","fileUrl":"http:\/\/www.stat.ucla.edu\/~gpapan\/pubs\/confr\/PapandreouYuille_PerturbAndMap_ieee-c-iccv11.pdf","name":"ucla.edu","nameUrl":"http:\/\/www.stat.ucla.edu\/~gpapan\/pubs\/confr\/PapandreouYuille_PerturbAndMap_ieee-c-iccv11.pdf","canRemove":false,"fileIcon":"ico-pub","canPreview":true,"hasPublisherLink":null,"hasMetaData":true,"hide":false,"fulltext":"ico-pub","origin":"publication_list","isLastLink":false,"isUserLink":false,"widgetId":"rgw22_56ab1aecd0c82"},"id":"rgw22_56ab1aecd0c82","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceItem.html","templateExtensions":["generalHelpers"],"attrs":{"fileRequiredPublicationTypes":["code","coverPage","experimentFindings","method","negativeResults","presentation","rawData","researchProposal","workingPaper","artifact","dataset"]},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceItem.html?publicationUid=221111135&linkId=00afe9160cf2d1b855026413&hide=0&disableJavascript=disableJavascript&useAlternativeTemplate=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"publicationUid":221111135,"publicationType":"inProceedings","linkId":"00afe9160cf202ff646032fa","fileName":"Perturb-and-MAP random fields: Using discrete optimization to learn and sample from energy models","fileUrl":"http:\/\/www.stat.ucla.edu\/~gpapan\/pubs\/confr\/PapandreouYuille_PerturbAndMap_ieee-c-iccv11.pdf","name":"ucla.edu","nameUrl":"http:\/\/www.stat.ucla.edu\/~gpapan\/pubs\/confr\/PapandreouYuille_PerturbAndMap_ieee-c-iccv11.pdf","canRemove":false,"fileIcon":"ico-pub","canPreview":true,"hasPublisherLink":null,"hasMetaData":true,"hide":false,"fulltext":"ico-pub","origin":"publication_list","isLastLink":false,"isUserLink":false,"widgetId":"rgw23_56ab1aecd0c82"},"id":"rgw23_56ab1aecd0c82","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceItem.html","templateExtensions":["generalHelpers"],"attrs":{"fileRequiredPublicationTypes":["code","coverPage","experimentFindings","method","negativeResults","presentation","rawData","researchProposal","workingPaper","artifact","dataset"]},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceItem.html?publicationUid=221111135&linkId=00afe9160cf202ff646032fa&hide=0&disableJavascript=disableJavascript&useAlternativeTemplate=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"publicationUid":221111135,"publicationType":"inProceedings","linkId":"00afe9160cf22e182257c49c","fileName":"Perturb-and-MAP random fields: Using discrete optimization to learn and sample from energy models","fileUrl":"http:\/\/www.stat.ucla.edu\/~gpapan\/pubs\/confr\/PapandreouYuille_PerturbAndMap_ieee-c-iccv11.pdf","name":"ucla.edu","nameUrl":"http:\/\/www.stat.ucla.edu\/~gpapan\/pubs\/confr\/PapandreouYuille_PerturbAndMap_ieee-c-iccv11.pdf","canRemove":false,"fileIcon":"ico-pub","canPreview":true,"hasPublisherLink":null,"hasMetaData":true,"hide":true,"fulltext":"ico-pub","origin":"publication_list","isLastLink":false,"isUserLink":false,"widgetId":"rgw24_56ab1aecd0c82"},"id":"rgw24_56ab1aecd0c82","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceItem.html","templateExtensions":["generalHelpers"],"attrs":{"fileRequiredPublicationTypes":["code","coverPage","experimentFindings","method","negativeResults","presentation","rawData","researchProposal","workingPaper","artifact","dataset"]},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceItem.html?publicationUid=221111135&linkId=00afe9160cf22e182257c49c&hide=1&disableJavascript=disableJavascript&useAlternativeTemplate=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"publicationUid":221111135,"publicationType":"inProceedings","linkId":"00afe9160cf245659d0058d3","fileName":"Perturb-and-MAP random fields: Using discrete optimization to learn and sample from energy models","fileUrl":"http:\/\/www.stat.ucla.edu\/~gpapan\/pubs\/confr\/PapandreouYuille_PerturbAndMap_ieee-c-iccv11.pdf","name":"ucla.edu","nameUrl":"http:\/\/www.stat.ucla.edu\/~gpapan\/pubs\/confr\/PapandreouYuille_PerturbAndMap_ieee-c-iccv11.pdf","canRemove":false,"fileIcon":"ico-pub","canPreview":true,"hasPublisherLink":null,"hasMetaData":true,"hide":true,"fulltext":"ico-pub","origin":"publication_list","isLastLink":false,"isUserLink":false,"widgetId":"rgw25_56ab1aecd0c82"},"id":"rgw25_56ab1aecd0c82","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceItem.html","templateExtensions":["generalHelpers"],"attrs":{"fileRequiredPublicationTypes":["code","coverPage","experimentFindings","method","negativeResults","presentation","rawData","researchProposal","workingPaper","artifact","dataset"]},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceItem.html?publicationUid=221111135&linkId=00afe9160cf245659d0058d3&hide=1&disableJavascript=disableJavascript&useAlternativeTemplate=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"widgetId":"rgw20_56ab1aecd0c82"},"id":"rgw20_56ab1aecd0c82","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceList.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceList.html?publicationUid=221111135&limit=3&disableJavascript=disableJavascript&type=fulltextFile","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"resourceCount":5,"hidden":false,"showMore":true,"fulltext":true,"publicationDownloadCount":{"data":{"value":202,"valueFormatted":"202","widgetId":"rgw26_56ab1aecd0c82"},"id":"rgw26_56ab1aecd0c82","partials":[],"templateName":"publicliterature\/stubs\/PublicationDownloadCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDownloadCount.html?publicationUid=221111135","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw19_56ab1aecd0c82"},"id":"rgw19_56ab1aecd0c82","partials":[],"templateName":"publicliterature\/stubs\/PublicationResources.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResources.html?publicationUid=221111135&type=fulltextFile&disableJavascript=1","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationResourcesAttachments":{"data":{"publicationUid":221111135,"publicationResourceList":{"data":{"publicationResourceItems":[],"widgetId":"rgw28_56ab1aecd0c82"},"id":"rgw28_56ab1aecd0c82","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceList.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceList.html?publicationUid=221111135&limit=3&disableJavascript=disableJavascript&type=attachmentFile","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"resourceCount":0,"hidden":true,"showMore":false,"fulltext":false,"publicationDownloadCount":{"data":{"value":202,"valueFormatted":"202","widgetId":"rgw29_56ab1aecd0c82"},"id":"rgw29_56ab1aecd0c82","partials":[],"templateName":"publicliterature\/stubs\/PublicationDownloadCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDownloadCount.html?publicationUid=221111135","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw27_56ab1aecd0c82"},"id":"rgw27_56ab1aecd0c82","partials":[],"templateName":"publicliterature\/stubs\/PublicationResources.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResources.html?publicationUid=221111135&type=attachmentFile","viewClass":"views.publicliterature.PublicationResourcesView","yuiModules":["rg.views.publicliterature.PublicationResourcesView"],"stylesheets":[],"_isYUI":true},"publicationText":{"data":{"hide":false,"pages":[{"page":1,"text":"Perturb-and-MAP Random Fields: Using Discrete Optimization\nto Learn and Sample from Energy Models\nGeorge Papandreou1and Alan L. Yuille1,2\n1Department of Statistics, University of California, Los Angeles\n2Department of Brain and Cognitive Engineering, Korea University, Seoul, Korea\n[gpapan,yuille]@stat.ucla.edu\nAbstract\nWe propose a novel way to induce a random field from\nan energy function on discrete labels. It amounts to lo-\ncally injecting noise to the energy potentials, followed by\nfinding the global minimum of the perturbed energy func-\ntion. The resulting Perturb-and-MAP random fields harness\nthe power of modern discrete energy minimization algo-\nrithms, effectively transforming them into efficient random\nsampling algorithms, thus extending their scope beyond the\nusual deterministic setting. In this fashion we can enjoy\nthe benefits of a sound probabilistic framework, such as the\nability to represent the solution uncertainty or learn model\nparameters from training data, while completely bypassing\ncostly Markov-chain Monte-Carlo procedures typically as-\nsociated with discrete label Gibbs Markov random fields\n(MRFs). We study some interesting theoretical properties\nof the proposed model in juxtaposition to those of Gibbs\nMRFs and address the issue of principled design of the per-\nturbation process. We present experimental results in im-\nage segmentation and scene labeling that illustrate the new\nqualitative aspects and the potential of the proposed model\nfor practical computer vision applications.\n1. Introduction\nDiscrete label Markov random fields (MRFs), going\nback to the classic Ising and Potts models in statistical\nphysics, offer a natural and sound probabilistic modeling\nframework for a host of image analysis and computer vi-\nsion problems involving discrete labels, such as image seg-\nmentation, texture synthesis, and deep learning [2,7,10,15,\n31]. Exact probabilistic inference and maximum likelihood\nmodel parameter fitting is intractable in general MRFs de-\nfined on 2-D domains and one has to employ random sam-\npling schemes to perform these tasks [7, 10]. Beyond its\nrole in inference, random sampling from MRFs can be a\ngoal in itself when the generative MRF properties are ex-\nploited, as in texture synthesis or inpainting [24,31]. How-\never, Markov-chain Monte-Carlo (MCMC) sampling algo-\nrithms such as Gibbs sampling can be computationally too\nexpensive for many practical computer vision applications.\nRecent powerful discrete energy minimization algo-\nrithms such as graph cuts, linear programming relaxations,\nor loopy belief propagation [5,15\u201317] can efficiently find\nor well approximate the most probable (MAP) configura-\ntion for certain important classes of MRFs and have had\nbig impact on several computer vision applications. Be-\nyond MAP computation, energy minimization algorithms\ncan be used for estimating model parameters using max-\nmargin criteria [26]. However, the deterministic viewpoint\non MRF modeling as energy minimization problem has im-\nportant limitations as it does not provide the right concep-\ntual framework for probabilistically characterizing the so-\nlution uncertainty or learning the model parameters from\ntraining data by maximum likelihood.\nIn this work we attempt to somehow bridge the gap be-\ntween the probabilistic and the energy minimization ap-\nproaches to MRF modeling. We propose a novel way to\ninduce a discrete label random field model from an energy\nfunction, which amounts to locally injecting additive ran-\ndom noise to the continuous energy potentials, followed\nby finding the global (approximate) minimum configura-\ntion of the perturbed energy function. This Perturb-and-\nMAP (PM) random field is a legitimate probabilistic model\nwhich delegates the non-trivial global interactions involved\nin sampling to an efficient energy minimization routine, and\nthus allows rapid sampling from a wide range of energy\nfunctions widely used in practice.\nFrom the probabilistic MRF perspective, the proposed\ntechnique can be seen as a one-shot approximate random\nsampling algorithm that completely bypasses MCMC. We\nstudy the problem of designing the perturbation process\nso as the Perturb-and-MAP random field be a good ap-\nproximation tothecorresponding GibbsMRF. Interestingly,\nwe identify a specific perturbation density under which the\nPerturb-and-MAP model is identical to its Gibbs counter-"},{"page":2,"text":"part. Although this ideal perturbation is not practically ap-\nplicable since it effectively destroys the local Markov struc-\nture of the energy, it suggests low-order perturbations that\nonly introduce noise to the unary (order-1) or a subset of the\npairwise (order-2) potential tables, resulting in perturbed\nenergies that are effectively as easy to minimize as the orig-\ninal unperturbed one, while producing random samples vir-\ntually indistinguishable from exact Gibbs MRF samples.\nPerturb-and-MAP random fields allow qualitatively new\napplicationsofenergyminimizationalgorithmsincomputer\nvision. First, accompanying the MAP solution with sev-\neral typical posterior samples drawn from the model allows\nus to quantify our confidence in the solution, which can be\nuseful in guiding the user\u2019s attention in interactive appli-\ncations, propagating uncertainty in further processing steps\nof a more complex computer vision pipeline, or assessing\nthe generative properties of a particular MRF model. Sec-\nond, our efficient sampling algorithm allows learning of\nMRF or CRF parameters using the moment matching rule,\nin which the model parameters are updated until the gen-\nerated samples reproduce the (weighted) sufficient statis-\ntics of the observed data. This approach is very popular\nfor learning of patch-based models [10,19], but the use of\nperturbed sampling instead of contrastive divergence is cru-\ncial for fast training in our applications. Similar to Gibbs\nMRFs, such greedy parameter update is justified because\nthe log-likelihood of the Perturb-and-MAP model turns out\nto be concave. We illustrate these ideas in experiments on\nimage segmentation and scene labeling.\nRelated work\ncrete random field model has been motivated by the exact\nGaussian MRF sampling algorithm popularized by [20,24]\nand especially its local factor perturbation interpretation\nhighlighted by [20]. While the underlying mathematics and\nmethods are completely different in the discrete setup we\nconsider here, we show that the intuition of local perturba-\ntions followed by global optimization can also lead to pow-\nerful sampling algorithms for discrete label MRFs.\nHerding [29] builds a deterministic dynamical system on\nthe model parameters designed so as to reproduce the data\nsufficient statistics, which is similar in spirit to the moment-\nmatching algorithm we use for learning. However, herding\nis still not a probabilistic model and cannot summarize the\ndata into a concise set of model parameters.\nThe limitations of MAP-based inference in discrete\nMRFs are nicely illustrated in [30]. They impose extra\nglobal constraints in the energy minimization problem to\nmitigate the tendency of MAP inference to produce singular\nsolutions. However, they still adhere to a deterministic set-\nting which is not suited for parameter learning. Further, op-\ntimizing the resulting modified energy functions is far more\nchallenging than minimizing the original energy.\nOur research on the Perturb-and-MAP dis-\nAveraging over multiple samples, our approach allows\nefficiently estimating (sum-) marginal densities and thus\nquantifyingtheper-nodesolutionuncertaintyeveningraphs\nwith loops. Max-product belief propagation [28] and dy-\nnamic graph-cuts [14] can compute max-marginals, which\ngive some indication of the uncertainty in label assignments\n[14] but cannot directly estimate marginal densities.\nIn the context of binary image segmentation, the\nsampling-based marginal confidence maps we produce re-\nsemble the soft segmentation maps of the random walker\nmodel [8], although the underlying probabilistic underpin-\nnings of the two methods are completely different.\n2. Energy functions and Gibbs MRFs\nOur starting point is a deterministic energy function\ne(x;\u03b8) = ?\u03b8,\u03c6(x)?,\n(1)\nwhere x \u2208 LNis a length-N state configuration vector with\nentries xiin a discrete label set L, \u03b8 \u2208 RMis a real param-\neter vector of length M, and \u03c6(x) = (\u03c61(x),...,\u03c6M(x))T\nis a vector of potentials or \u201csufficient statistics\u201d. We can in-\nterpret \u03b8jas the weight assigned to the feature \u03c6j(x): we\nhave many different design goals or sources of information\n(e.g., smoothness prior, measurements), each giving rise to\nsome features. We merge everything together into a single\nobjective function which we want to optimize so as to re-\ncover the best\/minimum energy configuration x.\nThe weights \u03b8 are selected in a way that the model as-\nsigns low energies to desirable configurations and high en-\nergies to \u201ceverything else\u201d. When the number of parameters\nM is small, we can set them to reasonable values by hand.\nA more principled way is to learn the parameters from a la-\nbeled training set {xk}K\nk=1by discriminative criteria such\nas structured max-margin [15,19,26,27]. Computationally,\none typically ends up with efficient iterative algorithms that\nrequire MAP inference at each parameter update step.\nThe Gibbs distribution is the standard way to induce a\nprobabilistic model from the energy function e(x;\u03b8). It de-\nfines a Markov random field whose probability mass func-\ntion has the exponential family form\nfG(x;\u03b8) = Z\u22121(\u03b8)exp(\u2212e(x;\u03b8)),\n(2)\nwhere Z(\u03b8) =?\nIn the probabilistic setting, maximum (penalized) likeli-\nhood (ML) is the natural criterion for learning the weights.\nGiven the labeled training set {xk}K\nters \u03b8 by maximizing the log-likelihood function LG(\u03b8) =\n\u2212logZ(\u03b8) \u2212 (1\/K)?K\ning an extra penalty term regularizing the weights. For\nfully observed models and energies of the form (1) the\nlog-likelihood is a concave function of the weights \u03b8 and\nthus the global maximum can be found by gradient ascent\nxexp(\u2212e(x;\u03b8)) is the partition function.\nk=1, we fit the parame-\nk=1e(xk;\u03b8), possibly also includ-"},{"page":3,"text":"[11, 15, 31]. The gradient is \u2202LG\/\u2202\u03b8j = EG\nED{\u03c6j(x)}. Here EG\n\u2212\u2202(logZ)\/\u2202\u03b8j and ED{\u03c6j(x)} ? (1\/K)?K\nare, respectively, the sufficient statistics under the Gibbs\nmodel and the data. Upon convergence, EG\nED{\u03c6j(x)}. Thus, ML estimation of the Gibbs model can\nbe thought of as moment matching: random samples drawn\nfromthetrainedmodelreproducethesufficientstatisticsob-\nserved in the training data.\nThe chief computational challenge in ML parameter\nlearning of the Gibbs model lies in estimating the model\nsufficient statistics EG\n\u03b8{\u03c6j(x)}. Note that this inference\nstep needs to be repeated at each parameter update step.\nThe model sufficient statistics can be computed exactly in\ntree-structured (and low tree-width) graphs, but in general\ngraphs one needs to resort to MCMC techniques for approx-\nimating them [10,11,31], an avenue considered too costly\nfor many computer vision applications. Deterministic ap-\nproximations such as variational techniques or loopy sum-\nproduct belief propagation do exist, but often are not accu-\nrate enough. Simplified criteria such as pseudo-likelihood\n[3] have been applied as substitutes to ML, but they can\nsometimes give results grossly different to ML.\nBeyond model training, random sampling is very useful\nin itself, to reveal what are typical instances of the model \u2013\nwhat the model has in its \u201cmind\u201d \u2013 and in applications such\nas texture synthesis [31]. Further, we might be interested\nnot only in the global minimum energy configuration, but\nin the marginal densities or posterior means as well [24].\nIn loopy graphs these quantities are typically intractable to\ncompute, the only viable way being through sampling. Our\nPerturb-and-MAP random field model is designed specifi-\ncally so as to be amenable to rapid sampling.\n\u03b8{\u03c6j(x)} \u2212\n\u03b8{\u03c6j(x)} ??\nxfG(x;\u03b8)\u03c6j(x) =\nk=1\u03c6j(xk)\n\u03b8{\u03c6j(x)} =\n3. Perturb-and-MAP random fields\nWe propose a novel way to induce a probabilistic model\nfrom an energy function:\nDefinition. The Perturb-and-MAP random field is defined\nby x(\u01eb) = argminqe(q;\u03b8 + \u01eb), where \u01eb is a random real-\nvalued additive parameter perturbation vector.\nIn other words, we inject noise to the model parameters\n\u02dc\u03b8 = \u03b8 + \u01eb, followed by finding the least energy configura-\ntion x(\u01eb) of the perturbed energy function. While Perturb-\nand-MAP random fields can also be built on energies de-\nfined over continuous labels [20], our focus in this paper\nwill be on random fields over discrete labels.\nThe main motivation for defining a probabilistic model\nin such a way is that for certain energy functions e(x;\u03b8)\nthere exist powerful algorithms which can find the MAP\nstate efficiently. Thus, by construction, we can efficiently\ndraw exact one-shot samples from the Perturb-and-MAP\nmodel without resorting to expensive MCMC techniques.\n\u01eb1\n\u01eb2\n\u01eb2= \u2212\u03b22+ \u03bb\n\u01eb1= \u2212\u03b21\u2212 \u03bb\n\u01eb1+ \u01eb2= \u2212\u03b21\u2212 \u03b22\n\u01eb2= \u2212\u03b22\u2212 \u03bb\n\u01eb1= \u2212\u03b21+ \u03bb\n??\n(\u2212\u03b21,\u2212\u03b22)\nx = (\u22121,1)\nx = (1,1)\nx = (\u22121,\u22121)\nx = (1,\u22121)\nFigure 1. Perturb-and-MAP geometry under the Ising energy with\nN = 2 nodes and perturbations only in the unary terms,\u02dc\u03b2i =\n\u03b2i+ \u01ebi, for parameter values \u03b21 = \u22121, \u03b22 = 0, and \u03bb = 1. The\n\u01eb-space is split into four polyhedra, with x(\u01eb) = x iff \u01eb \u2208 Px\u2212\u03b8.\n3.1. Weight space geometry\nA particular state x \u2208 LNwill be minimizing the deter-\nministic energy (1) if, and only if, e(x;\u03b8) \u2264 e(q;\u03b8),\u2200q \u2208\nLN. This set of |L|Nlinear inequalities defines a polyhe-\ndron Pxin the weight space\nPx= {\u03b8 \u2208 RM: ?\u03b8,\u03c6(x)\u2212\u03c6(q)? \u2264 0,\u2200q \u2208 LN}. (3)\nActually, Pxis a polyhedral cone [4], since \u03b8 \u2208 Pximplies\n\u03b1\u03b8 \u2208 Px, for all \u03b1 \u2265 0. The polyhedra Pxsplit the weight\nspace RMinto regions of influence of each discrete state\nx \u2208 LN. Under the Perturb-and-MAP model, x(\u01eb) will be\nassigned to a particular state x if, and only if, \u03b8 + \u01eb \u2208 Px\nor, equivalently, \u01eb \u2208 Px\u2212 \u03b8 ? {\u01eb \u2208 RM: \u03b8 + \u01eb \u2208 Px}.\nIn other words, if a specific instantiation of the perturbation\n\u01eb falls in the shifted polyhedron Px\u2212 \u03b8, then the Perturb-\nand-MAP model generates x as sample.\nWe assume that perturbations are drawn from a density\nf\u01eb(\u01eb) which does not depend on the parameters \u03b8. The\nprobability mass of a state x under the Perturb-and-MAP\nmodel is then the weighted volume of the corresponding\nshifted polyhedron under the perturbation measure\nfPM(x;\u03b8) =\n?\nPx\u2212\u03b8\nf\u01eb(\u01eb)d\u01eb,\n(4)\nwhich is the counterpart of the Gibbs density in Eq. (2). It\nis intractable (NP-hard) to compute the volume of general\npolyhedra in a high-dimensional space; see, e.g., [1, p. 29].\nHowever, for the class of perturbed energy functions which\ncan be globally minimized efficiently, we can readily draw\nexact samples from the Perturb-and-MAP model, without\never explicitly evaluating the integrals in Eq. (4).\nExample: Perturb-and-MAP Ising model\nsider the Ising energy e(x;\u03b8)\nLet us con-\n?N\n=\n\u22121\n2\ni=1\n?\u03b2ixi +"},{"page":4,"text":"?N\nhere \u03b2iis the external field strength (\u03b2i> 0 favors xi= 1)\nand \u03bbii\u2032 is the coupling strength (attractive coupling \u03bbii\u2032 >\n0 favors the same spin for xiand xi\u2032). This energy function\ncan be written in the standard inner product form (1) with\n\u03b8 = ({\u03b2i},{\u03bbii\u2032})Tand \u03c6(x) =\u22121\nMRF defined by (2) is the Ising Gibbs random field.\nDefining a Perturb-and-MAP Ising random field requires\nspecifying the perturbation density. In this example, we\nleave the binary term parameters \u03bbii\u2032 intact and only perturb\nthe unary term parameters \u03b2i. In particular, for each unary\nfactor, we set\u02dc\u03b2i = \u03b2i+ \u01ebi, with \u01ebiIID samples from the\nlogistic distribution with density l(z) =\ncorresponds to the order-1 Gumbel perturbation we discuss\nin Sec. 4 and ensures that if a particular node xiis com-\npletely isolated, it will then follow the same Bernoulli dis-\ntribution Pr{xi= 1} = 1\/(1 + e\u2212\u03b2i) as in the Gibbs case.\nThe \u01eb-space geometry in the case of two labels (N = 2) un-\nder the Ising energy e(x;\u03b8) = \u22120.5(\u03b21x1+\u03b22x2+\u03bbx1x2)\nfor a specific value of the parameters \u03b8 and perturbations\nonly to unary terms is depicted in Fig. 1. We show in Fig. 2\nsome statistics comparing the Gibbs and Perturb-and-MAP\nrandom fields for a toy Ising energy involving 9 variables\nand randomly generated parameters. The probability land-\nscape under the two models looks quite similar.\ni\u2032=i+1\u03bbii\u2032xixi\u2032?over the discrete \u201cspins\u201d xi\u2208 {\u22121,1};\n2({xi},{xixi\u2032})T. The\n1\n4sech2(z\n2). This\n \n \n\u22124\n\u22123.5\n\u22123\n\u22122.5\n\u22122\n\u22121.5\n\u22121\n(a)\n \n \n\u22124\n\u22123.5\n\u22123\n\u22122.5\n\u22122\n\u22121.5\n\u22121\n(b)\n\u22125\u22124\u22123\u22122\u22121\n\u22124\n\u22123\n\u22122\n\u22121\nlog10fG(x)\nlog10fPM(x)\n(c)\n100 200\nGIBBS RANK\n300 400500\n100\n200\n300\n400\n500\nPERTURB\u2212MAP RANK\n(d)\nFigure 2. Ising energy on 3\u00d73 grid, with \u03b2i and \u03bbii\u2032 IID from\nN(0,1). We compare the Gibbs (exact computation) and PM (106\nMonte-Carlo runs) random fields. (a) log10fG(x) and fG(xi =\n1). (b) log10fPM(x) and fPM(xi = 1). Scatter-plot of state log\nprobabilities (c) and state ranking (d) under the two models.\n3.2. Parameter estimation\nWe would like to estimate the parameters \u03b8 of the\nPerturb-and-MAP model from a labeled training set\n{xk}K\nk=1by maximizing the log-likelihood\nLPM(\u03b8) = (1\/K)\n?K\nk=1logfPM(xk;\u03b8).\n(5)\nAlthough we will not explore this further, we can\nalso perform parameter estimation from partially observed\ndata using expectation maximization, as in standard Gibbs\nMRFs [15], using Perturb-and-MAP sampling at the E-step.\nWe can design the perturbations so as the Perturb-and-\nMAP log-likelihood LPMis a concave function of \u03b8. This\nensures that the likelihood landscape is well-behaved and\nallows the use of local search techniques for parameter esti-\nmation, exactly as in the Gibbs case. Specifically (see sup-\nplementary material for all proofs in the paper):\nProposition 1. If the perturbations \u01eb are drawn from a log-\nconcave density f\u01eb(\u01eb), the log-likelihood LPM(\u03b8) is a con-\ncave function of the energy parameters \u03b8.\nThe family of log-concave distributions [4],\nlogf\u01eb(\u01eb) is a concave function of \u01eb, includes the Gaussian,\nthe logistic, and other commonly used distributions.\nThe gradient of LPM(\u03b8) is in general hard to com-\npute. Motivated by the parameter update formula in the\nGibbs case, we opt for the moment matching learning rule,\n\u03b8j(t + 1) = \u03b8j(t) + r(t)\u2206\u03b8j, where\ni.e.,\n\u2206\u03b8j= EPM\n\u03b8\n{\u03c6j(x)} \u2212 ED{\u03c6j(x)}.\n(6)\nHere EPM\npected sufficient statistic under the Perturb-and-MAP\nmodel for the current parameter values \u03b8, which we can\nefficiently estimate by drawing exact samples from it. We\ntypically adjust the learning rate by a Robbins-Monro type\nschedule, e.g., r(t) = r1\/(r2+ t). Figure 5 illustrates pa-\nrameter learning by moment matching in a spatially homo-\ngeneous Perturb-and-MAP Ising model.\nChanging the parameters \u03b8 under the moment matching\nrule (6) indeed reduces the discrepancy between the model\nand data sufficient statistics. Specifically:\n\u03b8\n{\u03c6j(x)} ?\n?\nxfPM(x;\u03b8)\u03c6j(x) is the ex-\nProposition 2. If \u03b8\u2032and \u03b8 differ only in the j-element, with\n\u03b8\u2032\nj> \u03b8j, then EPM\n\u03b8\u2032 {\u03c6j(x)} \u2264 EPM\n\u03b8\n{\u03c6j(x)}.\nThe inequality in Proposition 2 will be strict if the per-\nturbation density satisfies some mild conditions \u2013 see sup-\nplementary material. To see the effect of parameter up-\ndate in the Perturb-and-MAP Ising model of Fig. 1, as-\nsume that EPM\n\u03b8\n{\u03c63(x)} = EPM\nED{\u03c63(x)}. Under (6), we increase the coupling strength\n\u03b83= \u03bb; we see from Fig. 1 that the polyhedra of states x =\n(1,1) and x = (\u22121,\u22121) expand over those of x = (1,\u22121)\nand x = (\u22121,1), thus decreasing EPM\nUnlike the Gibbs case, the fixed points of the Perturb-\nand-MAP moment matching criterion do not need to be ex-\nact minima of the log-likelihood (5). However, some re-\nassurance is provided by the fact that the M-projection of\nfPM(\u03b8MM) (Perturb-and-MAP model trained by moment\nmatching) is fG(\u03b8ML) (Gibbs model trained by ML\/MM)\n[15, Th. 8.6]. Specifically, D(fPM(\u03b8MM)?fG(\u03b8ML)) \u2264\nD(fPM(\u03b8MM)?fG(\u03b8)),\u2200\u03b8 \u2208 RM, where D(\u00b7?\u00b7) is the\nKullback-Leibler divergence between two distributions.\n\u03b8\n{\u22121\n2x1x2} is larger than\n\u03b8\n{\u03c63(x)}."},{"page":5,"text":"4. Perturb-and-MAP perturbation design\nAlthough any perturbation density induces a legitimate\nPerturb-and-MAP model, it is desirable to carefully de-\nsign it so as the Perturb-and-MAP model approximates\nas closely as possible the corresponding Gibbs MRF. The\nGibbs MRF has important structural properties that are not\nautomatically satisfied by the Perturb-and-MAP model un-\nder arbitrary perturbations: (a) Unlike the Gibbs MRF, the\nPerturb-and-MAP model is not guaranteed to respect the\nstate ranking induced by the energy, i.e., e(x) \u2264 e(x\u2032) does\nnot necessarily imply fPM(x) \u2265 fPM(x\u2032), see Fig. 2(d).\n(b) The Markov dependence structure of the Gibbs MRF\nfollows directly from the support of the potentials \u03c6j(x),\nwhile the Perturb-and-MAP might give rise to longer-range\nprobabilistic dependencies. (c) The maximum entropy dis-\ntribution under moment constraints E{\u03c6j(x)} =\u00af\u03c6jhas the\nGibbs form; the Perturb-and-MAP model trained by mo-\nment matching can reproduce these moments but will in\ngeneral have smaller entropy than its Gibbs counterpart.\n0.2\n02-2-4\nz\ng(z)\n0.5\n1.0\n02-2-4\nz\nG(z)\nFigure 3. Gumbel probability density and cumulative distribution.\nThe Gumbel distribution arising in extreme value the-\nory [25] turns out to play an important role in our effort\nto design a perturbation mechanism that yields a Perturb-\nand-MAP model closely resembling the Gibbs MRF. It is a\ncontinuous univariate distribution with log-concave density\ng(z) = exp(\u2212(\u2212z + ez)), plotted in Fig. 3. We can ef-\nficiently draw independent Gumbel variates by transform-\ning standard uniform samples by u \u2192 log(\u2212log(u)). The\nGumbel density naturally fits into the Perturb-and-MAP\nmodel, thanks to the following key Lemma \u2013 c.f. [18]:\nLemma 1. Let (\u03b81,...,\u03b8m), with \u03b8n \u2208 R. We additively\nperturb them by\u02dc\u03b8n= \u03b8n+\u01ebn, with \u01ebnIID Gumbel samples.\nThen the probability that\u02dc\u03b8nattains the minimum value is\nPr{argmin(\u02dc\u03b81,...,\u02dc\u03b8m) = n} = e\u2212\u03b8n\/?m\nGumbel perturbation on fully-expanded potential table\nThe Gibbs random field on N sites xi, i = 1,...,N, each\nallowed to take a value from the discrete label set L can be\nconsidered as a discrete distribution with |L|Nstates. This\ncan be made explicit if we enumerate {xj,j = 1,...,\u00af\n|L|N} all the states and consider the maximal equivalent\nre-parameterization of Eq. (1)\nn\u2032=1e\u2212\u03b8n\u2032.\nM =\n\u00af e(x;\u00af\u03b8) ? ?\u00af\u03b8,\u00af\u03c6(x)? = ?\u03b8,\u03c6(x)?,\n(7)\nwhere\u00af\u03b8j = e(xj;\u03b8) = ?\u03b8,\u03c6(xj)?, j = 1,...,\u00af\nthe fully-expanded potential table and\u00af\u03c6j(x) is the indica-\nM, is\n(a) (b)(c)\nFigure 4. Reduced-order Gumbel perturbation. Perturbed poten-\ntials are denoted with double line. (a) Graph of the original en-\nergy involving unary and pairwise potentials on a 4-neighborhood\ngraph. (b) Order-1 perturbation. (c) Order-2 perturbation.\ntor function of the state xj(i.e., equals 1, if x = xjand 0\notherwise). Using Lemma 1 we can show:\nProposition 3. If we perturb each entry of the fully ex-\npanded LNpotential table with IID Gumbel noise samples\n\u01ebj,j = 1,...,\u00af\nM, then the Perturb-and-MAP and Gibbs\nmodels coincide, i.e., fPM(x;\u03b8) = fG(x;\u03b8).\nThis order-N perturbation is not practically applicable\nwhen N is large since it independently perturbs all\u00af\n|L|Nentries of the fully expanded potential table and ef-\nfectively destroys the local Markov structure of the energy\nfunction, rendering it too hard to minimize. Nevertheless,\nit shows that it is possible to design a Perturb-and-MAP\nmodel that exactly replicates the Gibbs MRF and paves the\nway for the design of reduced-order Gumbel perturbations.\nM =\nReduced-order Gumbel perturbation\nemploylow-orderGumbelperturbations, typicallyonlyper-\nturbing the unary (order-1) or a subset of the pairwise\n(order-2) potential tables. This yields perturbed energies\neffectively as easy to minimize as the original unperturbed\none, while producing random samples closely resembling\nGibbs MRF samples. We emphasize that even the order-1\nPerturb-and-MAP model is able to reproduce the sufficient\nstatistics of the data and is thus far more accurate than a\nmean-field approximation of the Gibbs MRF. Thanks to the\nlog-concavity of the Gumbel density, the log-likelihood of\nthe Perturb-and-MAP model remains concave for Gumbel\nperturbations of any order, as follows from Proposition 1.\nTo be more specific, consider the second-order energy\nIn practice, we\ne(x;\u03b8) =\nN\n?\ni=1\n?\nVi(xi) +\n?\ni\u2032\u2208N(i)\nVii\u2032(xi,xi\u2032)\n?\n(8)\nwhere each site xican take a discrete label in L. This is\na generalization of the Ising model considered in Sec. 3.1,\nwhere |L| = 2. Each Viis a |L|\u00d71 unary potential table and\neach Vii\u2032 is a |L|\u00d7|L| pairwise potential table.\nThe order-1 perturbation, illustrated in Fig. 4(b),\namounts to adding IID Gumbel noise to each entry of ev-\nery unary potential table Vi. This requires generating |L|N"},{"page":6,"text":"(a)(b)(c)(d)\n0 10 2030\n\u22120.2\n\u22120.1\n0\n0.1\n0.2\n0.3\n0.4\nIteration\nMoment Values\n \n \nEm{xi!=xj}\nEd{xi!=xj}\nEm{xi}\nEd{xi}\n(e)\nFigure 5. Low-order Perturb-and-MAP Ising random field parameter learning. The two model parameters, the global coupling strength\n\u03bb and field strength \u03b2 are fitted by moment matching. (a) One of the 10 Gibbs Ising model samples just below the critical temperature\n(\u03bb = 0.88, \u03b2 = 0, 256\u00d7256 grid) that we used as training data. (b) Perturb-and-MAP Ising sample at initial parameter values. (c) Order-1\nPerturb-and-MAP sample at fitted parameter values. (d) Order-2 Perturb-and-MAP sample at fitted parameter values. (e) Model moments\nof the order-2 Perturb-and-MAP model as they progress towards the training data moments during moment matching learning.\nIID Gumbel samples. Note that in the special case of the\nIsing model, the order-1 Gumbel perturbation is equivalent\nto adding logistic noise to the unary factor parameter \u03b2i,\nsince the difference of two IID Gumbel samples follows a\nlogistic distribution [25].\nIn the order-2 perturbation, illustrated in Fig. 4(c), we\nadd IID Gumbel noise to each entry of a subset of the pair-\nwise potential tables Vii\u2032. We make sure that at most one\nof the pairwise potentials adjacent to any node is perturbed.\nIf none of the pairwise potentials adjacent to a node can\nbe perturbed, then we perturb its associated unary potential.\nIn total, the perturbation process requires generating at most\n(N\/2)|L|2IID Gumbel samples. Higher-order Gumbel per-\nturbations involving clusters of 3 or more variables can be\nsimilarly defined.\nIt is desirable to select the strongest among the pair-\nwise potentials adjacent to each node for order-2 per-\nturbation.For energies defined on 4-connected planar\ngraphs, we globally find an optimal subset of strongest\nlinks by solving a stable marriage (also called stable\nmatching) problem on the corresponding Red-Black bi-\npartite graph using the Gale-Shapley algorithm.\n[13] and particularly [9] for a description of the Gale-\nShapley algorithm as it applies to sets of men\/women\nof unequal size, as can happen in our case.\ncate the mating preferences of each node xi, we rank its\nneighbors in decreasing order of pairwise mutual infor-\nmation Iii\u2032 =\n?\npii\u2032(xi,xi\u2032)\u221dexp(\u2212Vi(xi) \u2212 Vi\u2032(xi\u2032) \u2212 Vii\u2032(xi,xi\u2032)) and\npi(xi) =?\ncreases with the edge strength |\u03bbii\u2032|. When producing mul-\ntiple samples, we perform link selection only once. The\ncomputational cost is around 0.1 sec for 300\u00d7300 images\nwith our implementation of the Gale-Shapley algorithm.\nSee\nTo indi-\nxi,xi\u2032pii\u2032(xi,xi\u2032)log\npii\u2032(xi,xi\u2032)\npi(xi)pi\u2032(xi\u2032), with\nxi\u2032pii\u2032(xi,xi\u2032). For the Ising model, Iii\u2032 in-\nWhile the order-1 perturbation preserves submodularity\n[17], order-2 perturbation can yield non-submodular func-\ntions even when the original energy is submodular. For the\nIsing model we can compute in closed form the probability\nthat a single pairwise link of strength \u03bb will be submodular\nafter order-2 Gumbel perturbation Pr{\u02dc\u03bb \u2265 0} = e2\u03bb(e2\u03bb\u2212\n2\u03bb \u2212 1)\/(e2\u03bb\u2212 1)2; e.g., for \u03bb = 4, Pr{\u02dc\u03bb \u2265 0} \u2248 0.998.\nThus, if the links selected for perturbation are sufficiently\nstrong (and the link selection process described in the pre-\nvious paragraph contributes to this goal), then most of the\nperturbed pairwise potentials will remain submodular and\ntheperturbedenergycanefficientlybeminimizedwithtech-\nniques such as QPBO [16] which gracefully handle the few\nnon-submodular links. This is the approach we follow in\nthe interactive image segmentation application. Otherwise,\nfor weak links the order-1 perturbation should be preferred,\nwhich is anyway accurate enough in this case.\nIn Fig. 5 we juxtapose Perturb-and-MAP samples pro-\nduced by order-1 and order-2 Gumbel perturbations with a\nGibbsMRFsamplefromtheIsingmodel, producedwiththe\nPropp-Wilson exact sampling algorithm [21]. We have fit-\nted the parameters of the Perturb-and-MAP models by mo-\nment matching so that they reproduce the first and second\norder statistics of the Gibbs sample. We see that even the\norder-1 Gumbel perturbation captures quite well the overall\nappearance of the exact Gibbs sample. The order-2 sample\nfurther improves the approximation quality, better capturing\nthe appearance of same-spin clusters in the Gibbs sample.\n5. Applications and experiments\nWe present experiments with the Perturb-and-MAP\nmodel applied to image segmentation and scene labeling.\nFurther results are included in the supplementary material.\nSoftware is available from the first author\u2019s web home page.\n5.1. Interactive image segmentation\nWe first report interactive segmentation experiments,\nperformed on the Grabcut dataset which includes human\nannotated ground truth segmentations [22]. The task is to\nsegment a foreground object, given a relatively tight tri-map\nimitating user input obtained by a lasso or pen tool.\nThis is a relatively small dataset (50 images) not split\ninto training and test sets and carefully optimized tech-\nniques which exploit the regularities of the dataset are"},{"page":7,"text":"achieving extremely low pixel misclassification results\n(around 4.5% using adaptive thresholding on the output of\nthe random walker model [8]) \u2013 see [23] for a recent review.\nIn our implementation we closely follow the CRF for-\nmulation of [23], using the same parameters for defining\nthe image-based CRF terms and considering pixel interac-\ntions in a 8-neighborhood. We used our Perturb-and-MAP\nsampling algorithm with order-2 Gumbel perturbation and\nQPBO optimization [16] to learn the weights of the poten-\ntials \u2013 5 weights in total, one for the unary and one for each\nof the 4 pairwise connections of the center pixel with its S,\nE, NE, SE neighbors. Using these parameters, we obtained\na classification error rate of 5.6% with the global MAP de-\ncision rule. This is similar to the best results attainable with\nthe particular CRF model and hand-tuned weights.\nIn Fig. 6 we illustrate the ability of the Perturb-and-MAP\nmodel to produce soft segmentation maps. The soft seg-\nmentation map (average over 20 posterior samples) gives a\nqualitatively accurate estimate of the segmentation uncer-\ntainty, which could potentially be useful in guiding user in-\nteraction in an interactive segmentation application.\nFigure 6. Interactive image segmentation results on the Grabcut\ndataset. Parameters learned by PM moment matching. Top: the\noriginal image and the least energy MAP solution. Bottom: soft\nPerturb-and-MAP segmentation and the corresponding mask.\n5.2. Scene layout labeling\nWe next consider an application of Perturb-and-MAP\nrandom fields in scene layout labeling [12]. We use the\ntiered layout model of [6], which allows exact global infer-\nence by efficient dynamic programming [6]. The model has\na relatively large number of parameters, making it difficult\nto hand tune. Training them with the proposed techniques\nillustrates our ability to effectively learn model parameters\nfrom labeled data.\nWe closely follow the evaluation approach of [6] in set-\nting up the experiment: We use the dataset of 300 out-\ndoor images (and the standard cross-validation splits into\ntraining\/test sets) with ground truth from [12] for our ex-\nperiments. Similarly to [6], we use five labels: T (sky),\nB (ground), and three labels for the middle region, L (fac-\ning left), R (facing right), C (front facing). We also do not\ninclude in our label set the classes \u201cporous\u201d and \u201csolid\u201d.\nThe per-pixel class confidences used as unary terms are pro-\nduced using classifiers that we trained using the dataset and\nsoftware provided by [12] following the standard five-fold\ncross-validation protocol.The small difference between\nthe baseline confidence-only classification results reported\nby [6] and our baseline result should be attributed to our use\nof the newer version of Hoiem\u2019s software.\nWe first fit the tiered scene model parameters (pair-\nwise compatibility tables between the different classes) on\nthe training data using Perturb-and-MAP moment matching\n(order-1 Gumbel perturbation). Weights are initialized as\nPotts CRF potentials and refined by moment matching rule;\nwe separated the training set in batches of 10 images each\nand stopped after 50 epochs over the training set.\nThe following tables report row-normalized confusion\nmatrices for MAP (least energy configuration) and marginal\nMODE (i.e., assign each pixel to the label that appears most\nfrequentlyin20randomPerturb-And-Mapconditionalsam-\nples from the model); in both cases the learned weights are\nused. Our results are better than the confidence-only base-\nlinemeanaccuracyof82.1%[12], andtheMAPandMODE\nresults of 82.1% and 81.8%, respectively, that we obtained\nwith the hand-set weights of [6].\nMAP (acc 82.7%)\nB\nB 95.3\nL22.9\nC 24.3\nR 16.0\nT 1.1\nLC\n3.3\n21.9\n52.5\n24.8\n3.1\nR\n0.5\n6.6\n11.4\n49.4\n0.7\nT\n0.5\n46.7\n6.7\n4.4\n0.6\n0.5\n1.9\n5.0\n5.4\n94.4\nMarginal MODE (acc 82.6%)\nBL\nB 95.30.5\nL 23.046.9\nC24.66.9\nR16.54.5\nT1.00.6\nC\n3.2\n21.7\n51.5\n24.2\n3.0\nR\n0.5\n6.6\n11.7\n49.1\n0.8\nT\n0.5\n1.9\n5.3\n5.7\n94.7\nTable 1. Tiered labeling confusion matrices (learned weights).\nIn Fig. 7 we show some indicative examples of different\nscene layout labelings obtained by the confidence-only, the\nMAP, and the Perturb-and-MAP model. The uncertainty of\nthe solution is indicated by entropy maps.\n6. Perspective\nThe work of Geman and Geman [7] showed that sam-\npling coupled with artificial temperature annealing can be\nused as a general purpose method for finding the least en-\nergy configuration in discrete label MRFs. The advent of\nmuch faster deterministic energy minimization techniques\nhas decreased interest in sampling as an intermediary for\nMAP computation.Interestingly, the Perturb-and-MAP\nmodel works in the opposite direction to simulated anneal-\ning, allowing powerful algorithms for MAP computation to\nact as intermediaries for MRF sampling. We hope that this\nresearchwillhelpestablishdiscreteoptimizationtechniques\nas tools for probabilistic modeling in computer vision."},{"page":8,"text":"Figure 7. Tiered scene labeling results with pairwise potentials learned by our Perturb-and-MAP moment matching algorithm. Left to right:\nimage; confidence-only result; least energy MAP solution; single Perturb-and-MAP sample; PM marginal mode; PM marginal entropy.\nAcknowledgments\nThis work was supported by the U.S. Office of Naval Re-\nsearch under the MURI grant N000141010933 and by the\nKorean Ministry of Education, Science, and Technology,\nunder the National Research Foundation WCU program\nR31-10008. We thank X. He, I. Kokkinos, and M. Raptis\nfor their feedback and help at various stages of this project.\nReferences\n[1] A. Ben-Tal, L. El Ghaoui, and A. Nemirovski. Robust Opti-\nmization. Princeton Univ. Press, 2009.\n[2] J. Besag. Spatial interaction and the statistical analysis of\nlattice systems. JRSS (B), 36(2):192\u2013236, 1974.\n[3] J. Besag. Statistical analysis of non-lattice data. The Statis-\ntician, 24(3):179\u2013195, 1975.\n[4] S. Boyd and L. Vandenberghe. Convex Optimization. Cam-\nbridge Univ. Press, 2004.\n[5] Y. Boykov, O. Veksler, and R. Zabih.\nenergy minimization via graph cuts.\n23(11):1222\u20131239, 2001.\n[6] P. Felzenszwalb and O. Veksler. Tiered scene labeling with\ndynamic programming. In Proc. CVPR, 2010.\n[7] S. Geman and D. Geman. Stochastic relaxation, Gibbs distri-\nbutions, and the Bayesian restoration of images. IEEE Trans.\nPAMI, 6(6):721\u2013741, 1984.\n[8] L. Grady. Random walks for image segmentation. IEEE\nTrans. PAMI, 28(11):1768\u20131783, 2006.\n[9] D. Gusfield and R. Irving. The Stable Marriage Problem.\nMIT Press, 1989.\n[10] G. Hinton. Training products of experts by minimizing con-\ntrastive divergence. Neur. Comp., 14(8):1771\u20131800, 2002.\n[11] G. Hinton and T. Sejnowski. Optimal perceptual inference.\nIn Proc. CVPR, pages 448\u2013453, 1983.\n[12] D. Hoiem, A. Efros, and M. Hebert. Recovering surface lay-\nout from an image. IJCV, 75(1):151\u2013172, 2007.\n[13] J. Kleinberg and E. Tardos. Algorithm Design. Addison-\nWesley, 2006.\n[14] P. Kohli and P. Torr. Measuring uncertainty in graph cut so-\nlutions. Comp. Vision Image Underst., 112(1):30\u201338, 2008.\n[15] D. Koller and N. Friedman. Probabilistic Graphical Models.\nMIT Press, 2009.\nFast approximate\nIEEE Trans. PAMI,\n[16] V. Kolmogorov and C. Rother. Minimizing non-submodular\nfunctions with graph cuts \u2013 a review. IEEE Trans. PAMI,\n29(7):1274\u20131279, July 2007.\n[17] V. Kolmogorov and R. Zabih. What energy functions can be\nminimized via graph cuts? IEEE Trans. PAMI, 26(2):147\u2013\n159, 2004.\n[18] D. Kuzmin and M. K. Warmuth. Optimum follow the leader\nalgorithm. In Proc. COLT, pages 684\u2013686, 2005.\n[19] Y. LeCun, S. Chopra, R. Hadsell, M. Ranzato, and F.-J.\nHuang. A tutorial on energy-based learning. In Predicting\nStructured Data. MIT Press, 2007.\n[20] G. Papandreou and A. Yuille. Gaussian sampling by local\nperturbations. In Proc. NIPS, 2010.\n[21] J. Propp and D. Wilson.\nMarkov chains and applications to statistical mechanics.\nRandom Struc. Algor., 9(1):223\u2013252, 1996.\n[22] C. Rother, V. Kolmogorov, and A. Blake. Grabcut: Interac-\ntive foreground extraction using iterated graph cuts. In Proc.\nSIGGRAPH, pages 309\u2013314, 2004.\n[23] C. Rother, V. Kolmogorov, Y. Boykov, and A. Blake. Inter-\nactive foreground extraction using graph cut. In Advances\nin Markov Random Fields for Vision and Image Processing.\nMIT Press, 2011.\n[24] U. Schmidt, Q. Gao, and S. Roth. A generative perspective\non MRFs in low-level vision. In Proc. CVPR, 2010.\n[25] F. Steutel and K. Van Harn. Infinite divisibility of probability\ndistributions on the real line. Dekker, 2004.\n[26] M. Szummer, P. Kohli, and D. Hoiem. Learning CRFs using\ngraph cuts. In Proc. ECCV, pages 582\u2013595, 2008.\n[27] B. Taskar, C. Guestrin, and D. Koller. Max-margin Markov\nnetworks. In Proc. NIPS, 2003.\n[28] M. Wainwright, T. Jaakkola, and A. Willsky.\nmation via agreement on trees: Message-passing and linear\nprogramming. IEEE Trans. Inf. Theory, 51(11):3697\u20133717,\n2005.\n[29] M. Welling. Herding dynamical weights to learn. In Proc.\nICML, pages 1121\u20131128, 2009.\n[30] O. Woodford, C. Rother, and V. Kolmogorov. A global per-\nspective on MAP inference for low-level vision. In Proc.\nICCV, pages 2319\u20132326, 2009.\n[31] S.-C. Zhu, Y. Wu, and D. Mumford. Filters, random fields\nand maximum entropy (FRAME): Towards a unified theory\nfor texture modeling. IJCV, 27(2):107\u2013126, 1998.\nExact sampling with coupled\nMAP esti-"}],"fullTextUrl":"https:\/\/www.researchgate.net\/profile\/George_Papandreou\/publication\/221111135_Perturb-and-MAP_random_fields_Using_discrete_optimization_to_learn_and_sample_from_energy_models\/links\/02bfe50dbb9bed4be7000000.pdf","widgetId":"rgw30_56ab1aecd0c82"},"id":"rgw30_56ab1aecd0c82","partials":[],"templateName":"publicliterature\/stubs\/PublicationText.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationText.html?publicationUid=221111135&hide=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationDetailAd":{"data":{"googleDfpSlot":null,"widgetId":"rgw31_56ab1aecd0c82"},"id":"rgw31_56ab1aecd0c82","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAd.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAd.html?publicationUid=221111135&slotId=336x280_Publications_ATF_Right&collapseSlotMode=never&fallbackContainerEnabled=1","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationRelations":null,"publicationRelationsReverse":null,"publicationUid":221111135,"showSignUpDialog":false,"selectNewSignUpDialog":false,"publicationQuestions":null,"publicationCitations":{"data":{"publicationUid":221111135,"publicationCitationsList":{"data":{"citationItems":[{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore","clickThrough":"experimentMilestoneClickedToPublicationFromCitationWithFulltext","clickThroughWithContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":2086945186,"url":"researcher\/2086945186_Hyojin_Kim","fullname":"Hyojin Kim","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":38658732,"url":"researcher\/38658732_Peer-Timo_Bremer","fullname":"Peer-Timo Bremer","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":70250322,"url":"researcher\/70250322_Jayaraman_J_Thiagarajan","fullname":"Jayaraman J. Thiagarajan","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":[["includes-citation-list"]],"isFulltext":true,"isSlurp":false,"isNoText":false,"publicationType":"Conference Paper","publicationDate":"Dec 2015","journal":null,"showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/285598250_A_Randomized_Ensemble_Approach_to_Industrial_CT_Segmentation","usePlainButton":true,"publicationUid":285598250,"feedStubs":null,"hasFeedStubs":false,"impactPoints":false,"url":"publication\/285598250_A_Randomized_Ensemble_Approach_to_Industrial_CT_Segmentation","title":"A Randomized Ensemble Approach to Industrial CT Segmentation","displayTitleAsLink":true,"authors":[{"id":2086945186,"url":"researcher\/2086945186_Hyojin_Kim","fullname":"Hyojin Kim","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":38658732,"url":"researcher\/38658732_Peer-Timo_Bremer","fullname":"Peer-Timo Bremer","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":70250322,"url":"researcher\/70250322_Jayaraman_J_Thiagarajan","fullname":"Jayaraman J. Thiagarajan","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["International Conference on Computing Vision; 12\/2015"],"abstract":"Tuning the models and parameters of common segmen-tation approaches is challenging especially in the presence of noise and artifacts. Ensemble-based techniques attempt to compensate by randomly varying models and\/or parameters to create a diverse set of hypotheses, which are subsequently ranked to arrive at the best solution. However, these methods have been restricted to cases where the underlying models are well established, e.g. natural images. In practice , it is difficult to determine a suitable base-model and the amount of randomization required. Furthermore, for multi-object scenes no single hypothesis may perform well for all objects, reducing the overall quality of the results. This paper presents a new ensemble-based segmenta-tion framework for industrial CT images demonstrating that comparatively simple models and randomization strategies can significantly improve the result over existing techniques. Furthermore, we introduce a per-object based ranking , followed by a consensus inference that can outperform even the best case scenario of existing hypothesis ranking approaches. We demonstrate the effectiveness of our approach using a set of noise and artifact rich CT images from baggage security and show that it significantly outperforms existing solutions in this area.","description":false,"swapJournalAndAuthorPositions":false,"showAbstract":true,"type":"Conference Paper","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/285598250_A_Randomized_Ensemble_Approach_to_Industrial_CT_Segmentation","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":true,"actions":[{"type":"download","text":"Download","url":"profile\/Peer-Timo_Bremer\/publication\/285598250_A_Randomized_Ensemble_Approach_to_Industrial_CT_Segmentation\/links\/5661c7aa08ae15e7462ddd7c.pdf?origin=publication_list","active":false,"primary":true,"extraClass":"open-viewer","icon":null,"data":[]}],"actionWidgets":[],"publicationItemFulltext":{"data":{"isDataset":false,"isResearch":false,"isFulltext":true,"source":{"isPreview":false,"sourceUrl":"profile\/Peer-Timo_Bremer","sourceName":"Peer-Timo Bremer","hasSourceUrl":true},"publicationUid":285598250,"publicationUrl":"publication\/285598250_A_Randomized_Ensemble_Approach_to_Industrial_CT_Segmentation","eventCode":"","citationCount":0,"additionalContentWidgets":[],"disableViewer":true,"showLoggedOutRequestButton":false,"context":null,"previewUrl":"https:\/\/i1.rgstatic.net\/publication\/285598250_A_Randomized_Ensemble_Approach_to_Industrial_CT_Segmentation\/links\/5661c7aa08ae15e7462ddd7c\/smallpreview.png","linkId":"5661c7aa08ae15e7462ddd7c","origin":"publication_list","showRequestCount":false,"publish":false,"request":false,"showAction":false,"displayAsLink":true,"documentViewerUrl":"publicliterature.PublicLiteratureDocumentViewer.html?publicationId=285598250&reference=5661c7aa08ae15e7462ddd7c&eventCode=&origin=publication_list","widgetId":"rgw35_56ab1aecd0c82"},"id":"rgw35_56ab1aecd0c82","partials":[],"templateName":"publicliterature\/stubs\/PublicationItemFulltext.html","templateExtensions":["generalHelpers"],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItemFulltext.html?publicationUid=285598250&showAction=1&eventCode=&hideSource=0&displayAsLink=1&showPublishAsSelectFile=0","viewClass":"views.publicliterature.PublicationItemFulltextView","yuiModules":["rg.views.publicliterature.PublicationItemFulltextView"],"stylesheets":[],"_isYUI":true},"linkId":"5661c7aa08ae15e7462ddd7c","context":null,"contextId":null,"eventCode":"","isCitation":true,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":221111135,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/285598250_A_Randomized_Ensemble_Approach_to_Industrial_CT_Segmentation\/review","additionalRightSideTopWidgets":[{"data":{"citationContexts":["Batra et al. [4] developed a sequential model selection technique that emphasized the diversity of the solutions and showed it can produce significantly better results. An alternative approach to generating multiple hypotheses is to use sampling strategies that perturb the parameters of a segmentation algorithm [6] [18] [17]. However, refining these solutions can be challenging if the data is sensitive to the parameter settings. "],"widgetId":"rgw36_56ab1aecd0c82"},"id":"rgw36_56ab1aecd0c82","partials":[],"templateName":"publicliterature\/stubs\/PublicationItemCitationContexts.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItemCitationContexts.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":true,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read full-text","widgetId":"rgw34_56ab1aecd0c82"},"id":"rgw34_56ab1aecd0c82","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":true,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItem.html?showEnrichedPublicationItem=0&showRequestButton=1&publicationUid=285598250&additionalCssClasses%5B0%5D=includes-citation-list&citationContextItemVersion=old&isIncomingCitation=1","viewClass":"views.publicliterature.PublicationItemView","yuiModules":["rg.views.publicliterature.PublicationItemView"],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore","clickThrough":"experimentMilestoneClickedToPublicationFromCitationWithFulltext","clickThroughWithContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":2082332237,"url":"researcher\/2082332237_Alexander_Kirillov","fullname":"Alexander Kirillov","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":70093259,"url":"researcher\/70093259_Bogdan_Savchynskyy","fullname":"Bogdan Savchynskyy","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":59293579,"url":"researcher\/59293579_Dmitrij_Schlesinger","fullname":"Dmitrij Schlesinger","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":{"id":2082333728,"url":"researcher\/2082333728_Dmitry_Vetrov","fullname":"Dmitry Vetrov","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},"surplusAuthors":1,"additionalCssClasses":[["includes-citation-list"]],"isFulltext":true,"isSlurp":false,"isNoText":false,"publicationType":"Conference Paper","publicationDate":"Dec 2015","journal":null,"showEnrichedPublicationItem":false,"citationCount":1,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/282613694_Inferring_M-Best_Diverse_Labelings_in_a_Single_One","usePlainButton":true,"publicationUid":282613694,"feedStubs":null,"hasFeedStubs":false,"impactPoints":false,"url":"publication\/282613694_Inferring_M-Best_Diverse_Labelings_in_a_Single_One","title":"Inferring M-Best Diverse Labelings in a Single One","displayTitleAsLink":true,"authors":[{"id":2082332237,"url":"researcher\/2082332237_Alexander_Kirillov","fullname":"Alexander Kirillov","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":70093259,"url":"researcher\/70093259_Bogdan_Savchynskyy","fullname":"Bogdan Savchynskyy","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":59293579,"url":"researcher\/59293579_Dmitrij_Schlesinger","fullname":"Dmitrij Schlesinger","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2082333728,"url":"researcher\/2082333728_Dmitry_Vetrov","fullname":"Dmitry Vetrov","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":38896161,"url":"researcher\/38896161_Carsten_Rother","fullname":"Carsten Rother","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["ICCV 2015; 12\/2015"],"abstract":"We consider the task of finding M-best diverse solutions in a graphical model. In a previous work by Batra et al. an algorithmic approach for finding such solutions was proposed , and its usefulness was shown in numerous applications. Contrary to previous work we propose a novel formulation of the problem in form of a single energy minimization problem in a specially constructed graphical model. We show that the method of Batra et al. can be considered as a greedy approximate algorithm for our model, whereas we introduce an efficient specialized optimization technique for it, based on alpha-expansion. We evaluate our method on two application scenarios, interactive and semantic image segmentation, with binary and multiple labels. In both cases we achieve considerably better error rates than state-of-the art diversity methods. Furthermore, we empirically discover that in the binary label case we were able to reach global optimality for all test instances.","description":false,"swapJournalAndAuthorPositions":false,"showAbstract":true,"type":"Conference Paper","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/282613694_Inferring_M-Best_Diverse_Labelings_in_a_Single_One","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":true,"actions":[{"type":"download","text":"Download","url":"profile\/Bogdan_Savchynskyy\/publication\/282613694_Inferring_M-Best_Diverse_Labelings_in_a_Single_One\/links\/561437c408ae4ce3cc639665.pdf?origin=publication_list","active":false,"primary":true,"extraClass":"open-viewer","icon":null,"data":[]}],"actionWidgets":[],"publicationItemFulltext":{"data":{"isDataset":false,"isResearch":false,"isFulltext":true,"source":{"isPreview":false,"sourceUrl":"profile\/Bogdan_Savchynskyy","sourceName":"Bogdan Savchynskyy","hasSourceUrl":true},"publicationUid":282613694,"publicationUrl":"publication\/282613694_Inferring_M-Best_Diverse_Labelings_in_a_Single_One","eventCode":"","citationCount":0,"additionalContentWidgets":[],"disableViewer":true,"showLoggedOutRequestButton":false,"context":null,"previewUrl":"https:\/\/i1.rgstatic.net\/publication\/282613694_Inferring_M-Best_Diverse_Labelings_in_a_Single_One\/links\/561437c408ae4ce3cc639665\/smallpreview.png","linkId":"561437c408ae4ce3cc639665","origin":"publication_list","showRequestCount":false,"publish":false,"request":false,"showAction":false,"displayAsLink":true,"documentViewerUrl":"publicliterature.PublicLiteratureDocumentViewer.html?publicationId=282613694&reference=561437c408ae4ce3cc639665&eventCode=&origin=publication_list","widgetId":"rgw38_56ab1aecd0c82"},"id":"rgw38_56ab1aecd0c82","partials":[],"templateName":"publicliterature\/stubs\/PublicationItemFulltext.html","templateExtensions":["generalHelpers"],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItemFulltext.html?publicationUid=282613694&showAction=1&eventCode=&hideSource=0&displayAsLink=1&showPublishAsSelectFile=0","viewClass":"views.publicliterature.PublicationItemFulltextView","yuiModules":["rg.views.publicliterature.PublicationItemFulltextView"],"stylesheets":[],"_isYUI":true},"linkId":"561437c408ae4ce3cc639665","context":null,"contextId":null,"eventCode":"","isCitation":true,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":221111135,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/282613694_Inferring_M-Best_Diverse_Labelings_in_a_Single_One\/review","additionalRightSideTopWidgets":[{"data":{"citationContexts":["Gibbs sampling [12] may take prohibitively long to transfer between modes of the underlying distribution. Perturband-map [23] does not have these drawbacks, but is limited "],"widgetId":"rgw39_56ab1aecd0c82"},"id":"rgw39_56ab1aecd0c82","partials":[],"templateName":"publicliterature\/stubs\/PublicationItemCitationContexts.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItemCitationContexts.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":true,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read full-text","widgetId":"rgw37_56ab1aecd0c82"},"id":"rgw37_56ab1aecd0c82","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":true,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItem.html?showEnrichedPublicationItem=0&showRequestButton=1&publicationUid=282613694&additionalCssClasses%5B0%5D=includes-citation-list&citationContextItemVersion=old&isIncomingCitation=1","viewClass":"views.publicliterature.PublicationItemView","yuiModules":["rg.views.publicliterature.PublicationItemView"],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore","clickThrough":"experimentMilestoneClickedToPublicationFromCitationWithSlurp","clickThroughWithContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextSlurp","nextPublicationViewId":null,"authorsPartOne":[{"id":39738510,"url":"researcher\/39738510_Nikos_Komodakis","fullname":"Nikos Komodakis","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":71080186,"url":"researcher\/71080186_Bo_Xiang","fullname":"Bo Xiang","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":38411370,"url":"researcher\/38411370_Nikos_Paragios","fullname":"Nikos Paragios","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":[["includes-citation-list"]],"isFulltext":false,"isSlurp":true,"isNoText":false,"publicationType":"Article","publicationDate":"Jul 2015","journal":"IEEE Transactions on Pattern Analysis and Machine Intelligence","showEnrichedPublicationItem":false,"citationCount":1,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/277723496_A_Framework_for_Efficient_Structured_Max-Margin_Learning_of_High-Order_MRF_models","usePlainButton":true,"publicationUid":277723496,"feedStubs":null,"hasFeedStubs":false,"impactPoints":"5.78","url":"publication\/277723496_A_Framework_for_Efficient_Structured_Max-Margin_Learning_of_High-Order_MRF_models","title":"A Framework for Efficient Structured Max-Margin Learning of High-Order MRF models","displayTitleAsLink":true,"authors":[{"id":39738510,"url":"researcher\/39738510_Nikos_Komodakis","fullname":"Nikos Komodakis","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":71080186,"url":"researcher\/71080186_Bo_Xiang","fullname":"Bo Xiang","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":38411370,"url":"researcher\/38411370_Nikos_Paragios","fullname":"Nikos Paragios","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["IEEE Transactions on Pattern Analysis and Machine Intelligence 07\/2015; 37(7):1425-1441. DOI:10.1109\/TPAMI.2014.2368990"],"abstract":"We present a very general algorithm for structured prediction learning that is able to efficiently handle discrete MRFs\/CRFs (including both pairwise and higher-order models) so long as they can admit a decomposition into tractable subproblems. At its core, it relies on a dual decomposition principle that has been recently employed in the task of MRF optimization. By properly combining such an approach with a max-margin learning method, the proposed framework manages to reduce the training of a complex high-order MRF to the parallel training of a series of simple slave MRFs that are much easier to handle. This leads to a very efficient and general learning scheme that relies on solid mathematical principles. We thoroughly analyze its theoretical properties, and also show that it can yield learning algorithms of increasing accuracy since it naturally allows a hierarchy of convex relaxations to be used for loss-augmented MAP-MRF inference within a max-margin learning approach. Furthermore, it can be easily adapted to take advantage of the special structure that may be present in a given class of MRFs. We demonstrate the generality and flexibility of our approach by testing it on a variety of scenarios, including training of pairwise and higher-order MRFs, training by using different types of regularizers and\/or different types of dissimilarity loss functions, as well as by learning of appropriate models for a variety of vision tasks (including high-order models for compact pose-invariant shape priors, knowledge-based segmentation, image denoising, stereo matching as well as high-order Potts MRFs).","description":false,"swapJournalAndAuthorPositions":false,"showAbstract":true,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/277723496_A_Framework_for_Efficient_Structured_Max-Margin_Learning_of_High-Order_MRF_models","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":false,"actions":[{"type":"request-external","text":"Request full-text","url":"javascript:;","active":false,"primary":false,"extraClass":null,"icon":null,"data":[{"key":"context","value":"pubCit"}]}],"actionWidgets":[],"publicationItemFulltext":{"data":{"isDataset":false,"isResearch":false,"isFulltext":true,"source":{"isPreview":true,"sourceUrl":"deref\/https%3A%2F%2Fhal.inria.fr%2Fhal-01090971%2Ffile%2FRR-8645.pdf","sourceName":"hal.inria.fr","hasSourceUrl":true},"publicationUid":277723496,"publicationUrl":"publication\/277723496_A_Framework_for_Efficient_Structured_Max-Margin_Learning_of_High-Order_MRF_models","eventCode":"","citationCount":0,"additionalContentWidgets":[],"disableViewer":true,"showLoggedOutRequestButton":false,"context":null,"previewUrl":"https:\/\/i1.rgstatic.net\/publication\/277723496_A_Framework_for_Efficient_Structured_Max-Margin_Learning_of_High-Order_MRF_models\/links\/560c2eb408aed543358d248f\/smallpreview.png","linkId":"560c2eb408aed543358d248f","origin":"publication_list","showRequestCount":false,"publish":false,"request":false,"showAction":false,"displayAsLink":true,"documentViewerUrl":"publicliterature.PublicLiteratureDocumentViewer.html?publicationId=277723496&reference=560c2eb408aed543358d248f&eventCode=&origin=publication_list","widgetId":"rgw41_56ab1aecd0c82"},"id":"rgw41_56ab1aecd0c82","partials":[],"templateName":"publicliterature\/stubs\/PublicationItemFulltext.html","templateExtensions":["generalHelpers"],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItemFulltext.html?publicationUid=277723496&showAction=1&eventCode=&hideSource=0&displayAsLink=1&showPublishAsSelectFile=0","viewClass":"views.publicliterature.PublicationItemFulltextView","yuiModules":["rg.views.publicliterature.PublicationItemFulltextView"],"stylesheets":[],"_isYUI":true},"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":true,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":221111135,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/277723496_A_Framework_for_Efficient_Structured_Max-Margin_Learning_of_High-Order_MRF_models\/review","additionalRightSideTopWidgets":[{"data":{"citationContexts":["It should be mentioned at this point that, over the last years, additional types of structured prediction training methods have been proposed that can make use of various other types of learning objective functions and losses, as well as optimization algorithms [ 10, 15, 39, 41, 42, 47, 49, 50, 60, 62]. This also includes recent cases such as the inference-machines framework proposed in [43], as well as various types of randomized models such as the \" Perturb-and-MAP\" framework [48] or the \" randomized optimum models\" described in [61]. Also, a pseudo-max approach to structured learning (inspired by the pseudo-likelihood method) is proposed in [ 57], where the authors also analyze for which cases such an approach leads to consistent training. "],"widgetId":"rgw42_56ab1aecd0c82"},"id":"rgw42_56ab1aecd0c82","partials":[],"templateName":"publicliterature\/stubs\/PublicationItemCitationContexts.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItemCitationContexts.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":true,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw40_56ab1aecd0c82"},"id":"rgw40_56ab1aecd0c82","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":true,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItem.html?showEnrichedPublicationItem=0&showRequestButton=1&publicationUid=277723496&additionalCssClasses%5B0%5D=includes-citation-list&citationContextItemVersion=old&isIncomingCitation=1","viewClass":"views.publicliterature.PublicationItemView","yuiModules":["rg.views.publicliterature.PublicationItemView"],"stylesheets":[],"_isYUI":true}],"hasCitations":true,"isPublicationAuthor":false,"isPublicationVisitor":false,"publicationUid":221111135,"publicationLink":"publication\/221111135_Perturb-and-MAP_random_fields_Using_discrete_optimization_to_learn_and_sample_from_energy_models","hasShowMore":true,"newOffset":3,"pageSize":10,"widgetId":"rgw33_56ab1aecd0c82"},"id":"rgw33_56ab1aecd0c82","partials":[],"templateName":"publicliterature\/stubs\/PublicationIncomingCitationsList.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationIncomingCitationsList.html?publicationUid=221111135&citedInPage=1&swapJournalAndAuthorPositions=0&showAbstract=1&showType=1&showPublicationPreview=1&totalCount=19","viewClass":"views.publicliterature.PublicationIncomingCitationsListView","yuiModules":["rg.views.publicliterature.PublicationIncomingCitationsListView"],"stylesheets":[],"_isYUI":true},"hasCitations":false,"citationsCount":0,"hasIncomingCitations":true,"incomingCitationsCount":19,"showCitationsSorter":true,"showAbstract":true,"showType":true,"showPublicationPreview":true,"swapJournalAndAuthorPositions":false,"sort":"","sortOriginal":false,"citationList":"incoming","showsIncoming":true,"showSorting":false,"usePlainButton":null,"useEnrichedContext":null,"widgetId":"rgw32_56ab1aecd0c82"},"id":"rgw32_56ab1aecd0c82","partials":[],"templateName":"publicliterature\/stubs\/PublicationCitations.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationCitations.html?publicationUid=221111135&citationList=&citedInPage=1&sort=","viewClass":"views.publicliterature.PublicationCitationsView","yuiModules":["rg.views.publicliterature.PublicationCitationsView"],"stylesheets":[],"_isYUI":true},"publicationReviewPromo":null,"publicationUsedInReviews":null,"publicationPdfJsReader":{"data":{"isPreview":false,"licenseUrl":null,"licenseInfo":null,"defaultLinkData":{"linkId":"02bfe50dbb9bed4be7000000","name":"George Papandreou","date":null,"nameLink":"profile\/George_Papandreou","filename":"","downloadLink":"https:\/\/www.researchgate.net\/profile\/George_Papandreou\/publication\/221111135_Perturb-and-MAP_random_fields_Using_discrete_optimization_to_learn_and_sample_from_energy_models\/links\/02bfe50dbb9bed4be7000000.pdf?inViewer=0&pdfJsDownload=0&origin=publication_detail","viewerUrl":"https:\/\/www.researchgate.net\/profile\/George_Papandreou\/publication\/221111135_Perturb-and-MAP_random_fields_Using_discrete_optimization_to_learn_and_sample_from_energy_models\/links\/02bfe50dbb9bed4be7000000.pdf?inViewer=1&pdfJsDownload=1&origin=publication_detail","downloadHash":"2a3917f4cbaaa4b06ee0d6d571eb435c","showFileSizeNote":false,"fileSize":"507.37 KB","noFollow":false,"isDefault":true,"doi":null},"displayableLinks":[{"linkId":"02bfe50dbb9bed4be7000000","name":"George Papandreou","date":null,"nameLink":"profile\/George_Papandreou","filename":"","downloadLink":"https:\/\/www.researchgate.net\/profile\/George_Papandreou\/publication\/221111135_Perturb-and-MAP_random_fields_Using_discrete_optimization_to_learn_and_sample_from_energy_models\/links\/02bfe50dbb9bed4be7000000.pdf?inViewer=0&pdfJsDownload=0&origin=publication_detail","viewerUrl":"https:\/\/www.researchgate.net\/profile\/George_Papandreou\/publication\/221111135_Perturb-and-MAP_random_fields_Using_discrete_optimization_to_learn_and_sample_from_energy_models\/links\/02bfe50dbb9bed4be7000000.pdf?inViewer=1&pdfJsDownload=1&origin=publication_detail","downloadHash":"2a3917f4cbaaa4b06ee0d6d571eb435c","showFileSizeNote":false,"fileSize":"507.37 KB","noFollow":false,"isDefault":true,"doi":null}],"hasDisplayableLinks":false,"reader":{"data":{"pdfCommentsActive":false,"publicationType":"Conference Paper","onlyRenderFirstPage":false,"readMoreExperimentGoal":"goalPublicationPdfClicksReadMore","readMoreExperimentViewId":null,"comments":null,"figures":[],"figureAssetIds":[],"figureOverlayUrls":{"clickOnOverlay":"publication.PublicationFigures.html?_sg=t293zNY0f6KWv9gf-0fHH3pxLW0495mvBBZsOzvoYnRxnP8dRIKD6LzS4G42Wpmw2VQvuvkoJkoB5ZZMgeCtkQ.SuQLKrcb0U3xYqHE65k7DQAtVBT9dgpGNdj778KJyn5VCO01aiGWTqZbNb9GU1Ht0Res2fKQpwP7DQb6MPS2eg","clickOnPill":"publication.PublicationFigures.html?_sg=l0JNNJ2-yHbDkVbbGdfGw81VrA5WjTQQk6Qo2eNVd53wXgEMmIzuDLP7jBrTYqd6cnSof0hDPvBjiExqXVwDQA.Le9YaShuqy11CInd4cuV6dVBOVY97Sg7_J2ANkgJhc9h5zf1ac5lyUHAFU1uP71PNmww-DcHrA8ervJ5N0IPAA"},"canSelect":false,"javascriptPath":"https:\/\/www.researchgate.net\/c\/o1o9o3\/","downloadUrl":"https%3A%2F%2Fwww.researchgate.net%2Fprofile%2FGeorge_Papandreou%2Fpublication%2F221111135_Perturb-and-MAP_random_fields_Using_discrete_optimization_to_learn_and_sample_from_energy_models%2Flinks%2F02bfe50dbb9bed4be7000000.pdf%3FinViewer%3D1%26pdfJsDownload%3D1%26origin%3Dpublication_detail","viewerUrl":"https:\/\/www.researchgate.net\/c\/o1o9o3\/javascript\/lib\/pdfjs\/web\/viewer.html","commentEndpoint":"https:\/\/www.researchgate.net\/rgformat\/api\/comment","experimentEndpoint":"https:\/\/www.researchgate.net\/rgformat\/api\/experiment?key=RQ3uN1V_v4eoigcG80Yt0-rI5xHyKKVcV0JPHwqPDGHGvHHd73wZWWw5t1wkI9AvpTnsqk4MXK4aNTVX5DZ0zA","urlHash":"c319b3aecedf4b3806ae9e682ee9d023","downloadTrackUrl":"application.PdfJsReader.ajaxTrackDownload.html?msrp=3dw0CZJO_GeW4ZRJ7jKmKhe1Fpr2rAM9PH2uu0xp-RIBFwIhQXYcTos5AKVjFckt3e8gacrEgvSDRnye2DrD_Tz6R28bk2t4Qg-vdDIHygM.q5sXgFUKkR6zEV0saNIkYXws7NE05CSn45B3cS5U3Rl5fYufbf6LIFZAQNVUXJE5lfLxKo-TzuBVVaaq61_Kmw.hGQ7I4Vd7XzKnn5jB5vNvXtkUC7jkus_cHzTrViD_kFGhBx5LXEI54bHhcYNrYHwMXX2FSyY1JkoV3e0j5h-_g","viewportMilestoneTrackUrl":"application.PdfJsReader.ajaxTrackViewportMilestone.html","linkId":"02bfe50dbb9bed4be7000000","trackedDownloads":{"02bfe50dbb9bed4be7000000":{"v":false,"d":false}},"assetId":"AS:104203779313665@1401855525110","readerDocId":null,"assetType":"fulltext","interactionType":{"comment":"comment","highlight":"highlight"},"publicationUid":221111135,"commentCursorPromo":null,"widgetId":"rgw44_56ab1aecd0c82"},"id":"rgw44_56ab1aecd0c82","partials":[],"templateName":"application\/stubs\/PdfJsReader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PdfJsReader.html?fileHref=https%3A%2F%2Fwww.researchgate.net%2Fprofile%2FGeorge_Papandreou%2Fpublication%2F221111135_Perturb-and-MAP_random_fields_Using_discrete_optimization_to_learn_and_sample_from_energy_models%2Flinks%2F02bfe50dbb9bed4be7000000.pdf%3FinViewer%3D1%26pdfJsDownload%3D1%26origin%3Dpublication_detail&assetId=AS%3A104203779313665%401401855525110&publicationUid=221111135&linkId=02bfe50dbb9bed4be7000000&onlyShowFirstPage=0","viewClass":null,"yuiModules":["css-pow-application-PdfJsReader"],"stylesheets":["pow\/application\/PdfJsReader.css"],"_isYUI":true},"showHeader":true,"title":"Perturb-and-MAP random fields: Using discrete optimization to learn and sample from energy models","publicationType":"Conference Paper","downloadTrackUrl":"publicliterature.PublicationInlineReader.ajaxTrackDownload.html?msrp=7xpXYHzlTy2J81vOrwz4fG6DumpmxtpUgWKrEwkzvZCASzlYvksqQYm6OG0zTd6GjxxhiYXcxb_lZfGRMvt3ZJR5v8Zdb0khiY1h72ODP9M.o45qJ_k3IOd3fhRVEN0Fy5_aQGSIPw0pBAdE_0_CDLelRK6H7EtUaA0QKAMaiCxv7po7bff2eGh_-o3096sTyA.xui9-viio5cmvEf3M1ObY9EPaUoFVYx2xusNjShxM0ijErVIxJ3Han8vSXxSmM7lLS0tlevB1cjh4SeWdBJQAA","publicationUid":221111135,"trackedDownloads":{"02bfe50dbb9bed4be7000000":{"v":false,"d":false}},"inlinePdf":false,"publicationComments":null,"showDownloadButton":true,"socialShare":{"data":{"shareItems":[{"data":{"name":"Facebook","url":"http:\/\/www.facebook.com\/share.php?u={{url}}{{#title}}&t={{title}}{{\/title}}","width":600,"height":350,"useUtmTags":true,"utmSource":"facebook","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareFacebook.ajaxTrackSocialShare.html","widgetId":"rgw46_56ab1aecd0c82"},"id":"rgw46_56ab1aecd0c82","partials":{"shareIcon":"application\/stubs\/partials\/shareFacebookBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareFacebook.html?provider=Facebook&shareIcon=shareIconBlog&utmSource=facebook&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"Twitter","url":"http:\/\/twitter.com\/intent\/tweet?text={{#title}}{{title}}: {{\/title}}{{url}}&via=researchgate","width":600,"height":350,"useUtmTags":true,"utmSource":"twitter","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareTwitter.ajaxTrackSocialShare.html","widgetId":"rgw47_56ab1aecd0c82"},"id":"rgw47_56ab1aecd0c82","partials":{"shareIcon":"application\/stubs\/partials\/shareTwitterBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareTwitter.html?provider=Twitter&shareIcon=shareIconBlog&utmSource=twitter&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"Google+","url":"https:\/\/plus.google.com\/share?url={{url}}","width":600,"height":600,"useUtmTags":true,"utmSource":"googleplus","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareGooglePlus.ajaxTrackSocialShare.html","widgetId":"rgw48_56ab1aecd0c82"},"id":"rgw48_56ab1aecd0c82","partials":{"shareIcon":"application\/stubs\/partials\/shareGooglePlusBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareGooglePlus.html?provider=Google%2B&shareIcon=shareIconBlog&utmSource=googleplus&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"LinkedIn","url":"http:\/\/www.linkedin.com\/shareArticle?mini=true&url={{url}}{{#title}}&title={{title}}{{\/title}}&source=ResearchGate","width":520,"height":570,"useUtmTags":true,"utmSource":"linkedin","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareLinkedIn.ajaxTrackSocialShare.html","widgetId":"rgw49_56ab1aecd0c82"},"id":"rgw49_56ab1aecd0c82","partials":{"shareIcon":"application\/stubs\/partials\/shareLinkedInBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareLinkedIn.html?provider=LinkedIn&shareIcon=shareIconBlog&utmSource=linkedin&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"Reddit","url":"https:\/\/www.reddit.com\/submit?url={{url}}{{#title}}&title={{title}}{{\/title}}","width":600,"height":600,"useUtmTags":true,"utmSource":"reddit","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareReddit.ajaxTrackSocialShare.html","widgetId":"rgw50_56ab1aecd0c82"},"id":"rgw50_56ab1aecd0c82","partials":{"shareIcon":"application\/stubs\/partials\/shareRedditBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareReddit.html?provider=Reddit&shareIcon=shareIconBlog&utmSource=reddit&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true}],"widgetId":"rgw45_56ab1aecd0c82"},"id":"rgw45_56ab1aecd0c82","partials":[],"templateName":"application\/stubs\/SocialShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.SocialShare.html?campaign=shareFullTextPublication&trackClick=1&shareIcon=shareIconBlog","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw43_56ab1aecd0c82"},"id":"rgw43_56ab1aecd0c82","partials":[],"templateName":"publicliterature\/stubs\/PublicationInlineReader.html","templateExtensions":["generalHelpers"],"attrs":{"showFulltextDownloadedSignupDialog":true,"preSignUpDialogContext":null,"requestFulltext":false},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationInlineReader.html","viewClass":"views.publicliterature.PublicationInlineReaderView","yuiModules":["rg.views.publicliterature.PublicationInlineReaderView","css-pow-publicliterature-PublicationInlineReader"],"stylesheets":["pow\/publicliterature\/PublicationInlineReader.css"],"_isYUI":true},"useFulltextOptimizedLayout":false,"publicationActions":null,"requestFulltextPromo":null,"currentUrl":"publication\/221111135_Perturb-and-MAP_random_fields_Using_discrete_optimization_to_learn_and_sample_from_energy_models","isLeaderboardAd":false,"enableStickyBox":null,"googleDfpSlotMobileBottom":null,"fullTextExitPopup":null,"showExitPopupDialog":false,"widgetId":"rgw2_56ab1aecd0c82"},"id":"rgw2_56ab1aecd0c82","partials":{"romeo_legal_notice":"publicliterature\/stubs\/partials\/romeo_legal_notice.html"},"templateName":"publicliterature\/stubs\/PublicPublicationDetails_NewLayout.html","templateExtensions":["generalHelpers"],"attrs":{"publicationUid":221111135},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicPublicationDetailsOld.html?publicationUid=221111135&isTestOldDesign=0","viewClass":"views.publicliterature.PublicPublicationDetailsOldView","yuiModules":["rg.views.publicliterature.PublicPublicationDetailsOldView"],"stylesheets":[],"_isYUI":true},"widgetId":"rgw1_56ab1aecd0c82"},"id":"rgw1_56ab1aecd0c82","partials":[],"templateName":"publicliterature\/stubs\/PublicPublicationDetails.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicPublicationDetails.html","viewClass":"views.publicliterature.PublicPublicationDetailsView","yuiModules":["rg.views.publicliterature.PublicPublicationDetailsView"],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"uaClass":"","headPrefix":[],"rootUrl":"https:\/\/www.researchgate.net\/","requestToken":"nl9CPdndArZXo8jZ2ClbdSK+pmMSCkyRs0L+lY3tN2BybRIHVqPSoB0VP+8XYfe9AiFDCzJC3oj1nuXxnChaDyGWil6rgs+MqixSwWeqa+zr0YzTSrTsGuShldZNYKYvQUCICKSQ6vVTUbXWwi3PR1cZsVyO7wy4LWFwl\/OcudE+QYy4SpdAeUHZKoQ35K2OOPsv0dRDCV4om2psK4ivDT453Rq0Bb1FvAqvkIBJ\/vbmeyE3FtKOfqjerQUkZLG8PiuYo6AoN7McV6VWODfDbDYfWeQb2wU21IqUzpG6Q+Y=","faviconCdnUrl":"https:\/\/c5.rgstatic.net\/m\/2390829798215018\/images\/favicon.ico","headerOutput":"<noscript><\/noscript><link rel=\"canonical\" href=\"https:\/\/www.researchgate.net\/publication\/221111135_Perturb-and-MAP_random_fields_Using_discrete_optimization_to_learn_and_sample_from_energy_models\" \/>\n<link rel=\"dns-prefetch\" href=\"\/\/c5.rgstatic.net\" \/>\n<link rel=\"dns-prefetch\" href=\"\/\/i1.rgstatic.net\" \/>\n<meta property=\"twitter:card\" content=\"summary\" \/>\n<meta property=\"twitter:site\" content=\"@ResearchGate\" \/>\n<meta property=\"og:title\" content=\"Perturb-and-MAP random fields: Using discrete optimization to learn and sample from energy models\" \/>\n<meta property=\"og:description\" content=\"We propose a novel way to induce a random field from an energy function on discrete labels. It amounts to locally injecting noise to the energy potentials, followed by finding the global minimum...\" \/>\n<meta property=\"og:site_name\" content=\"ResearchGate\" \/>\n<meta property=\"og:image\" content=\"https:\/\/i1.rgstatic.net\/publication\/221111135_Perturb-and-MAP_random_fields_Using_discrete_optimization_to_learn_and_sample_from_energy_models\/links\/02bfe50dbb9bed4be7000000\/smallpreview.png\" \/>\n<meta property=\"og:url\" content=\"https:\/\/www.researchgate.net\/publication\/221111135_Perturb-and-MAP_random_fields_Using_discrete_optimization_to_learn_and_sample_from_energy_models\" \/>\n<meta property=\"rg:id\" content=\"PB:221111135\" \/>\n<meta name=\"DC.identifier\" scheme=\"DCTERMS.URI\" content=\"http:\/\/dx.doi.org\/10.1109\/ICCV.2011.6126242\" \/>\n<meta name=\"gs_meta_revision\" content=\"1.1\" \/>\n<meta name=\"citation_title\" content=\"Perturb-and-MAP random fields: Using discrete optimization to learn and sample from energy models\" \/>\n<meta name=\"citation_author\" content=\"George Papandreou\" \/>\n<meta name=\"citation_author\" content=\"Alan L. Yuille\" \/>\n<meta name=\"citation_conference_title\" content=\"IEEE International Conference on Computer Vision, ICCV 2011, Barcelona, Spain, November 6-13, 2011\" \/>\n<meta name=\"citation_publication_date\" content=\"2011\/11\/01\" \/>\n<meta name=\"citation_journal_title\" content=\"Proceedings \/ IEEE International Conference on Computer Vision. IEEE International Conference on Computer Vision\" \/>\n<meta name=\"citation_issn\" content=\"1550-5499\" \/>\n<meta name=\"citation_firstpage\" content=\"193\" \/>\n<meta name=\"citation_lastpage\" content=\"200\" \/>\n<meta name=\"citation_doi\" content=\"10.1109\/ICCV.2011.6126242\" \/>\n<meta name=\"citation_pdf_url\" content=\"https:\/\/www.researchgate.net\/profile\/George_Papandreou\/publication\/221111135_Perturb-and-MAP_random_fields_Using_discrete_optimization_to_learn_and_sample_from_energy_models\/links\/02bfe50dbb9bed4be7000000.pdf\" \/>\n<meta name=\"citation_abstract_html_url\" content=\"https:\/\/www.researchgate.net\/publication\/221111135_Perturb-and-MAP_random_fields_Using_discrete_optimization_to_learn_and_sample_from_energy_models\" \/>\n<meta name=\"citation_fulltext_html_url\" content=\"https:\/\/www.researchgate.net\/publication\/221111135_Perturb-and-MAP_random_fields_Using_discrete_optimization_to_learn_and_sample_from_energy_models\" \/>\n<meta name=\"viewport\" content=\"width=device-width,initial-scale=1\" \/>\n<link href=\"\/\/c5.rgstatic.net\/m\/22664197317151888\/styles\/rg.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/21004998181197492\/styles\/rg2.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<!--[if lt IE 9]><link href=\"\/\/c5.rgstatic.net\/m\/238176252723686\/styles\/ie.css\" type=\"text\/css\" rel=\"stylesheet\"\/><![endif]-->\n<link href=\"\/\/c5.rgstatic.net\/m\/217752362214895\/styles\/modules\/publicprofile.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/21993347442549\/styles\/pow\/publicliterature\/FollowPublicationPromo.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/282514599719602\/styles\/pow\/application\/PdfJsReader.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/23819663151220\/styles\/pow\/publicliterature\/PublicationInlineReader.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<script src=\"\/\/c5.rgstatic.net\/m\/2321000301012716\/javascript\/vendor\/webfontloader\/webfontloader.js\" type=\"text\/javascript\"><\/script>\n <script>(function(i,s,o,g,r,a,m){i[\"GoogleAnalyticsObject\"]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,\"script\",\"\/\/www.google-analytics.com\/analytics.js\",\"ga\");\n ga(\"create\",\"UA-58591210-1\");ga(\"set\",\"anonymizeIp\",true);ga('set', 'dimension1', 'publication full-text');ga('set', 'dimension2', 'Conference Paper');ga('set', 'dimension3', 'Logged out');ga('set', 'dimension4', 'https');ga(\"send\",\"pageview\");<\/script>\n","webfont":"<noscript><\/noscript><script> WebFontConfig = { custom: { families: ['source_sans_pro_italic', 'source_sans_pro_bold', 'source_sans_pro', 'martel'], urls : ['\/\/c5.rgstatic.net\/m\/231392577336386\/styles\/fonts.css'] } }; WebFont.load(WebFontConfig); <\/script>\n","correlationId":"rgreq-26103183-92c3-446c-8447-43301513f984","accountId":null,"module":"publicliterature","action":"publicliterature.PublicPublicationDetails","page":"publicationDetail","product":"publications","backendTime":816,"continent":"Asia","stylesHome":"\/\/c5.rgstatic.net\/m\/","staticHost":"c5.rgstatic.net","useEarlyFlush":false,"longRunningRequestIdentifier":"LongRunningRequest.publicliterature.PublicPublicationDetails","longRunningRequestFp":"e9e5bbe1366c7ee8c8e41d02f793c884ac9be19b","widgetId":"rgw51_56ab1aecd0c82"},"id":"rgw51_56ab1aecd0c82","partials":[],"templateName":"application\/stubs\/StaticHeader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.StaticHeader.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){
            Y.rg.core.pagespeed.Monitoring.monitorPage("\/\/glassmoni.researchgate.net", "publicliterature.PublicPublicationDetails.run.html.loggedOut.get", "59de9668d07aeb77ab4de5f24d382b5d199d2437", "rgreq-26103183-92c3-446c-8447-43301513f984", "ef1735c9e04b869cfea7d81a80a4fdadde6c2265");
        
            Y.rg.core.pagespeed.Monitoring.monitorPage("\/\/glassmoni.researchgate.net", "publicationDetail.loggedOut", "ed1993d9e20f6cefa83edacaa24401a18c071aea", "rgreq-26103183-92c3-446c-8447-43301513f984", "ef1735c9e04b869cfea7d81a80a4fdadde6c2265");
        })();
(function(){Y.rg.createInitialWidget({"data":{"year":"2016","inlinePromo":null,"isAdmin":false,"contactUrl":"https:\/\/www.researchgate.net\/contact","aboutUsUrl":"https:\/\/www.researchgate.net\/about","widgetId":"rgw52_56ab1aecd0c82"},"id":"rgw52_56ab1aecd0c82","partials":[],"templateName":"application\/stubs\/DefaultFooter.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.DefaultFooter.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"headerLogin":{"data":{"urlAfterLogin":"publication\/221111135_Perturb-and-MAP_random_fields_Using_discrete_optimization_to_learn_and_sample_from_energy_models","requestToken":"ddtKJ2Crxh5t60BqNOjFag7sQLF3HvHQut7Fbk0RLE5KLwbA8g7NkTRDHabC2Ql\/bT3BIbqSGb24fL4rxNVAXS11n2FvoCzb34Y4WzXzAqpAUMGka+0qJMJq+qKoSXaNhG4MaMOMhT0Dybfo48HHFmazewKvQZeGIGJHxVbpkzgACTCYJtOBdA5QGp4be6rRXK7G7pNEF8hq8yIhnk+svQHat+Ko2IY8z8OqpcntGWMoRETG18w7WPfNEQBWOdHnACPSoSLr3PHeChcJPc6ms4cDYGQ+qsuJ+2MSb4nIR7I=","loginUrl":"https:\/\/www.researchgate.net\/application.Login.html","signupUrl":"https:\/\/www.researchgate.net\/signup.SignUp.html?ev=su_chnl_index&hdrsu=1&_sg=bFbpAUf8v5WEoKKz5cLtd4UN4xC1Ftf4uYYVkTVUcfOU0WwxB0SArEpMcTdHfA1v","encodedUrlAfterLogin":"cHVibGljYXRpb24vMjIxMTExMTM1X1BlcnR1cmItYW5kLU1BUF9yYW5kb21fZmllbGRzX1VzaW5nX2Rpc2NyZXRlX29wdGltaXphdGlvbl90b19sZWFybl9hbmRfc2FtcGxlX2Zyb21fZW5lcmd5X21vZGVscw%3D%3D","signupCallToAction":"Join for free","widgetId":"rgw54_56ab1aecd0c82"},"id":"rgw54_56ab1aecd0c82","partials":{"partial":"application\/stubs\/partials\/headerLoginDefault.html"},"templateName":"application\/stubs\/HeaderLogin.html","templateExtensions":[],"attrs":{"goal":"milestoneHeaderLoginSeen"},"widgetUrl":"https:\/\/www.researchgate.net\/application.HeaderLogin.html","viewClass":"views.application.HeaderLoginView","yuiModules":["rg.views.application.HeaderLoginView"],"stylesheets":[],"_isYUI":true},"cookieConsent":null,"logoSvgSrc":"https:\/\/c5.rgstatic.net\/m\/235107188705592\/images\/template\/brand-header-logo.svg","logoFallbackSrc":"https:\/\/c5.rgstatic.net\/m\/238113351022438\/images\/template\/brand-header-logo.png","widgetId":"rgw53_56ab1aecd0c82"},"id":"rgw53_56ab1aecd0c82","partials":{"schemaSocialProfiles":"application\/stubs\/partials\/schemaSocialProfiles.html"},"templateName":"application\/stubs\/HeaderLoggedOut.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.HeaderLoggedOut.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"logEvent":"su_banner","specialCopy":false,"widgetId":"rgw55_56ab1aecd0c82"},"id":"rgw55_56ab1aecd0c82","partials":[],"templateName":"application\/stubs\/LoggedOutBanner.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.LoggedOutBanner.html","viewClass":"views.application.LoggedOutBannerView","yuiModules":["rg.views.application.LoggedOutBannerView"],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.core.util.ParameterFilter.filter(["ev","cp","ch","ref","dbw","pli","loginT","uid","claimChannel","enrichId","enrichSource","utm_source","utm_medium","utm_campaign","el","ci"]);})();
});}); } else { throw 'YRG was not loaded when attaching widgets'; }</script><script> dataLayer = [{"pageCategory":"publication full-text","publicationType":"Conference Paper","eventCategory":"Publication page"}]; </script> <noscript><iframe src="//www.googletagmanager.com/ns.html?id=GTM-MKVKH7" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-MKVKH7');</script><script>(function(e){function n(n,t,o,a){"use strict";var i=e.document.createElement("link"),r=t||e.document.getElementsByTagName("script")[0],d=e.document.styleSheets;return i.rel="stylesheet",i.href=n,i.media="only x",a&&(i.onload=a),r.parentNode.insertBefore(i,r),i.onloadcssdefined=function(e){for(var t,o=0;d.length>o;o++)d[o].href&&d[o].href.indexOf(n)>-1&&(t=!0);t?e():setTimeout(function(){i.onloadcssdefined(e)})},i.onloadcssdefined(function(){i.media=o||"all"}),i}function t(e,n){e.onload=function(){e.onload=null,n&&n.call(e)},"isApplicationInstalled"in navigator&&"onloadcssdefined"in e&&e.onloadcssdefined(n)}var o=function(a,i){"use strict";if(a&&3===a.length){var r=e.Image,d=!(!document.createElementNS||!document.createElementNS("http://www.w3.org/2000/svg","svg").createSVGRect||!document.implementation.hasFeature("http://www.w3.org/TR/SVG11/feature#Image","1.1")||e.opera&&-1===navigator.userAgent.indexOf("Chrome")||-1!==navigator.userAgent.indexOf("Series40")),c=new r;c.onerror=function(){o.method="png",o.href=a[2],n(a[2])},c.onload=function(){var e=1===c.width&&1===c.height,r=a[e&&d?0:e?1:2];o.method=e&&d?"svg":e?"datapng":"png",o.href=r,t(n(r),i)},c.src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///ywAAAAAAQABAAACAUwAOw==",document.documentElement.className+=" grunticon"}};o.loadCSS=n,o.onloadCSS=t,e.grunticon=o})(this);grunticon(["https://c5.rgstatic.net/c/o1o9o3/styles/icons/_header-ico.svg.css", "https://c5.rgstatic.net/c/o1o9o3/styles/icons/_header-ico.png.css", "https://c5.rgstatic.net/c/o1o9o3/styles/icons/_header-ico.fallback.scss"]);grunticon(["https://c5.rgstatic.net/c/o1o9o3/styles/icons/_admin-ico.svg.css", "https://c5.rgstatic.net/c/o1o9o3/styles/icons/_admin-ico.png.css", "https://c5.rgstatic.net/c/o1o9o3/styles/icons/_admin-ico.fallback.scss"]);grunticon(["https://c5.rgstatic.net/c/o1o9o3/styles/icons/_ico.svg.css", "https://c5.rgstatic.net/c/o1o9o3/styles/icons/_ico.png.css", "https://c5.rgstatic.net/c/o1o9o3/styles/icons/_ico.fallback.scss"]);</script></body>
</html>
