<!DOCTYPE html> <html lang="en" class="" id="rgw30_56ab9d59139cf"> <head > <meta charset="utf-8"/> <meta http-equiv="content-type" content="text/html; charset=UTF-8"/> <meta name="Rg-Request-Token" id="Rg-Request-Token" content="ypxJtycXEOjsTWS1fb2Vk7kmj3BOyROdG/516Pd7qxP3BA1a5Qt4erogCvaCDDHxpQ6HTw4MFLq5gYnoxnkG11iReGupv2tgMe+sL5+TjApigladxdtXagGd4Ke2rxvXaFVs00KkO3i8JhlWZKx3lYmJZmB1CXzxchW8qOH0G/VLCnZAmjctlZNnzncX7OuNo5N8mLzdfs/IT3vLX9kaiib6yuGmKl/GWlVsYYwSQCGaodx6mf/niI5z9dbfF8UIZhwOvbxR94j2KWiWj1mjpORfZXYJT8v2A9cGD6TOrpI="/> <meta http-equiv="expires" content="0"/> <link rel="apple-touch-icon" sizes="57x57" href="https://www.researchgate.net/apple-touch-icon-57x57.png"> <link rel="apple-touch-icon" sizes="60x60" href="https://www.researchgate.net/apple-touch-icon-60x60.png"> <link rel="apple-touch-icon" sizes="72x72" href="https://www.researchgate.net/apple-touch-icon-72x72.png"> <link rel="apple-touch-icon" sizes="76x76" href="https://www.researchgate.net/apple-touch-icon-76x76.png"> <link rel="apple-touch-icon" sizes="114x114" href="https://www.researchgate.net/apple-touch-icon-114x114.png"> <link rel="apple-touch-icon" sizes="120x120" href="https://www.researchgate.net/apple-touch-icon-120x120.png"> <link rel="apple-touch-icon" sizes="144x144" href="https://www.researchgate.net/apple-touch-icon-144x144.png"> <link rel="apple-touch-icon" sizes="152x152" href="https://www.researchgate.net/apple-touch-icon-152x152.png"> <link rel="apple-touch-icon" sizes="180x180" href="https://www.researchgate.net/apple-touch-icon-180x180.png"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-32x32.png" sizes="32x32"> <link rel="icon" type="image/png" href="https://www.researchgate.net/android-chrome-192x192.png" sizes="192x192"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-96x96.png" sizes="96x96"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-16x16.png" sizes="16x16"> <link rel="shortcut icon" type="image/x-icon" href="https://c5.rgstatic.net/m/2390829798215018/images/favicon.ico"/> <link rel="manifest" href="https://www.researchgate.net/manifest.json"> <meta name="msapplication-TileColor" content="#da532c"> <meta name="msapplication-TileImage" content="https://www.researchgate.net/mstile-144x144.png"> <meta name="theme-color" content="#444444"> <link rel="search" type="application/opensearchdescription+xml" title="ResearchGate search" href="https://www.researchgate.net/application.DownloadOpenSearchPlugin.html"/> <link rel="meta" type="application/rdf+xml" title="ICRA labels" href="https://www.researchgate.net/application.DownloadLabels.html"/> <link rel="http://oexchange.org/spec/0.8/rel/related-target" type="application/xrd+xml" href="https://www.researchgate.net/application.DownloadOExchange.html"/> <base href="https://www.researchgate.net/"/> <script>
    var rgConfig = {
        correlationId: "rgreq-0d264037-0754-4a50-8ea1-470b11632dfb",
        accountId: "",
        module: "publicliterature",
        action: "publicliterature.PublicPublicationDetails",
        page: "publicationDetail",
        product: "publications",
        continent: "Asia",
        stylesHome: "//c5.rgstatic.net/m/",
        staticHost: "c5.rgstatic.net",
        longRunningRequestIdentifier: "LongRunningRequest.publicliterature.PublicPublicationDetails",
        longRunningRequestFp: "e9e5bbe1366c7ee8c8e41d02f793c884ac9be19b"
    };
    window.rootUrl = "https://www.researchgate.net/";
</script> <link rel="canonical" href="https://www.researchgate.net/publication/277959103_Dropout_as_a_Bayesian_Approximation_Appendix" />
<link rel="dns-prefetch" href="//c5.rgstatic.net" />
<link rel="dns-prefetch" href="//i1.rgstatic.net" />
<meta property="twitter:card" content="summary" />
<meta property="twitter:site" content="@ResearchGate" />
<meta property="og:title" content="Dropout as a Bayesian Approximation: Appendix" />
<meta property="og:description" content="We show that a multilayer perceptron (MLP) with arbitrary depth and
nonlinearities, with dropout applied after every weight layer, is
mathematically equivalent to an approximation to a well known..." />
<meta property="og:site_name" content="ResearchGate" />
<meta property="og:image" content="https://i1.rgstatic.net/publication/277959103_Dropout_as_a_Bayesian_Approximation_Appendix/links/557f87e008aeb61eae261b76/smallpreview.png" />
<meta property="og:url" content="https://www.researchgate.net/publication/277959103_Dropout_as_a_Bayesian_Approximation_Appendix" />
<meta property="rg:id" content="PB:277959103" />
<meta name="DC.identifier" scheme="DCTERMS.URI" content="http://dx.doi.org/" />
<meta name="gs_meta_revision" content="1.1" />
<meta name="citation_title" content="Dropout as a Bayesian Approximation: Appendix" />
<meta name="citation_author" content="Yarin Gal" />
<meta name="citation_author" content="Zoubin Ghahramani" />
<meta name="citation_publication_date" content="2015/06/06" />
<meta name="citation_abstract_html_url" content="https://www.researchgate.net/publication/277959103_Dropout_as_a_Bayesian_Approximation_Appendix" />
<meta name="citation_fulltext_html_url" content="https://www.researchgate.net/publication/277959103_Dropout_as_a_Bayesian_Approximation_Appendix" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<link href="//c5.rgstatic.net/m/22664197317151888/styles/rg.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/21004998181197492/styles/rg2.css" type="text/css" rel="stylesheet"/>
<!--[if lt IE 9]><link href="//c5.rgstatic.net/m/238176252723686/styles/ie.css" type="text/css" rel="stylesheet"/><![endif]-->
<link href="//c5.rgstatic.net/m/217752362214895/styles/modules/publicprofile.css" type="text/css" rel="stylesheet"/>
<script src="//c5.rgstatic.net/m/2321000301012716/javascript/vendor/webfontloader/webfontloader.js" type="text/javascript"></script>
 <script>(function(i,s,o,g,r,a,m){i["GoogleAnalyticsObject"]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,"script","//www.google-analytics.com/analytics.js","ga");
 ga("create","UA-58591210-1");ga("set","anonymizeIp",true);ga('set', 'dimension1', 'publication slurped');ga('set', 'dimension2', 'Article');ga('set', 'dimension3', 'Logged out');ga('set', 'dimension4', 'https');ga("send","pageview");</script>
  <script> WebFontConfig = { custom: { families: ['source_sans_pro_italic', 'source_sans_pro_bold', 'source_sans_pro', 'martel'], urls : ['//c5.rgstatic.net/m/231392577336386/styles/fonts.css'] } }; WebFont.load(WebFontConfig); </script><noscript></noscript>

<title>Dropout as a Bayesian Approximation: Appendix</title>
<meta name="description" content="Dropout as a Bayesian Approximation: Appendix on ResearchGate, the professional network for scientists."/>
<meta name="keywords" content="scientific network, scientific platform, scientific community, research partner, research collaboration, journal articles, international collaboration, find researcher, lifescience researcher, interdisciplinary research, research collaboration"/>
</head>
<body class="use-svg-icons logged-out">
<div id="page-container">
<script type="text/javascript">var googletag = googletag || {}; googletag.cmd = googletag.cmd || [];
(function() { var gads = document.createElement("script"); gads.async = true; gads.type = "text/javascript"; var useSSL = "https:" == document.location.protocol; gads.src = (useSSL ? "https:" : "http:") + "//www.googletagservices.com/tag/js/gpt.js"; var node =document.getElementsByTagName("script")[0]; node.parentNode.insertBefore(gads, node); })();</script><div id="main" class="logged-out-header-support">
<div id="content" class="">

<noscript>
<div class="c-box-warning full-width-element" style="text-align: center; ">
    <div style="margin: auto; padding:10px;" class="container">
        <b>For full functionality of ResearchGate it is necessary to enable JavaScript.
            Here are the <a href="http://www.enable-javascript.com/" rel="nofollow" target="_blank">
                instructions how to enable JavaScript in your web browser</a>.</b>
    </div>
</div>
</noscript>

<div id="rgw1_56ab9d59139cf" itemscope itemtype="http://schema.org/ScholarlyArticle"><div class="publication-wrapper publication-wrapper-onecol" id="rgw2_56ab9d59139cf" itemscope itemtype="http://schema.org/ScholarlyArticle"> <div class="c-col-content"> <div class="c-content"> <div class="clearfix">  <div class="publication-header"> <div id="rgw7_56ab9d59139cf">  <div class="type-label"> Article   </div> <span class="Z3988" title="ctx_ver=Z39.88-2004&rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&rfr_id=info%3Asid%2Fresearchgate.net%3Aresearchgate&rft.atitle=Dropout%20as%20a%20Bayesian%20Approximation%3A%20Appendix&rft.date=2015&rft.au=Yarin%20Gal%2CZoubin%20Ghahramani&rft.genre=article"></span> <h1 class="pub-title" itemprop="name">Dropout as a Bayesian Approximation: Appendix</h1> <meta itemprop="headline" content="Dropout as a Bayesian Approximation: Appendix">  <meta itemprop="image" content="https://i1.rgstatic.net/publication/277959103_Dropout_as_a_Bayesian_Approximation_Appendix/links/557f87e008aeb61eae261b76/smallpreview.png">  <div id="rgw9_56ab9d59139cf" class="publication-detail-author-list"> <div> <ul class="clearfix js-people-list">  <li id="rgw10_56ab9d59139cf"> <a href="researcher/2069013556_Yarin_Gal" class="pub-detail-item author-item" itemprop="author" itemscope itemtype="http://schema.org/Person"> <div class="indent-left"> <div class="people-img">  <img src="https://c5.rgstatic.net/m/2951093203564/images/template/default/profile/profile_default_s.jpg" title="Yarin Gal" alt="Yarin Gal" height="20px" width="20px" style="height: 20px;"/>  </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Yarin Gal</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item   not-claimed " id="rgw11_56ab9d59139cf">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="researcher/2069013556_Yarin_Gal"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="Yarin Gal" alt="Yarin Gal" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">       </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="researcher/2069013556_Yarin_Gal" class="display-name">Yarin Gal</a>    </h5> <div class="truncate-single-line meta">   </div>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>  <li id="rgw12_56ab9d59139cf"> <a href="researcher/8159937_Zoubin_Ghahramani" class="pub-detail-item author-item" itemprop="author" itemscope itemtype="http://schema.org/Person"> <div class="indent-left"> <div class="people-img">  <img src="https://c5.rgstatic.net/m/2951093203564/images/template/default/profile/profile_default_s.jpg" title="Zoubin Ghahramani" alt="Zoubin Ghahramani" height="20px" width="20px" style="height: 20px;"/>  </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Zoubin Ghahramani</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item   not-claimed " id="rgw13_56ab9d59139cf">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="researcher/8159937_Zoubin_Ghahramani"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="Zoubin Ghahramani" alt="Zoubin Ghahramani" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">       </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="researcher/8159937_Zoubin_Ghahramani" class="display-name">Zoubin Ghahramani</a>    </h5> <div class="truncate-single-line meta">   </div>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>   </ul> <div class="js-loading"></div>  </div> </div> <div class="pub-details js-pub-details">        <meta itemprop="datePublished" content="2015-06">  06/2015;               <div class="pub-source"> Source: <a href="http://arxiv.org/abs/1506.02157" rel="nofollow">arXiv</a> </div>  </div> <div id="rgw14_56ab9d59139cf" class="pub-abstract">  <div class="clearfix">   <p itemprop="description"> <strong>ABSTRACT</strong> <div>We show that a multilayer perceptron (MLP) with arbitrary depth and<br />
nonlinearities, with dropout applied after every weight layer, is<br />
mathematically equivalent to an approximation to a well known Bayesian model.<br />
This interpretation offers an explanation to some of dropout's key properties,<br />
such as its robustness to over-fitting. Our interpretation allows us to reason<br />
about uncertainty in deep learning, and allows the introduction of the Bayesian<br />
machinery into existing deep learning frameworks in a principled way.<br />
This document is an appendix for the main paper &quot;Dropout as a Bayesian<br />
Approximation: Representing Model Uncertainty in Deep Learning&quot; by Gal and<br />
Ghahramani, 2015.</div> </p>  </div>   </div>      <div class="action-container">   <div class="clear"></div> <div class="share-dialog-container" style="display: none;">  </div> </div> </div> <div style="margin-left: -20px; margin-right: -20px;">  </div> </div>  <div class="publication-detail-dfp-container rf"> <div id="rgw27_56ab9d59139cf">  </div> </div>  </div>  <div class="clearfix">  <noscript> <div id="rgw26_56ab9d59139cf"  itemprop="articleBody">  <p>Page 1</p> <p>arXiv:1506.02157v1  [stat.ML]  6 Jun 2015<br />Dropout as a Bayesian Approximation:<br />Appendix<br />Yarin Gal<br />University of Cambridge<br />{yg279,zg201}@cam.ac.uk<br />Zoubin Ghahramani<br />Abstract<br />We show that a multilayer perceptron (MLP) with arbitrary depth and non-<br />linearities, with dropoutapplied after every weight layer, is mathematicallyequiv-<br />alent to an approximation to a well known Bayesian model. This interpretation<br />offers an explanation to some of dropout’s key properties, such as its robustness<br />to over-fitting. Our interpretation allows us to reason about uncertainty in deep<br />learning,andallows the introductionof the Bayesian machineryinto existingdeep<br />learning frameworks in a principled way.<br />This documentis an appendixfor the main paper “Dropoutas a Bayesian Approx-<br />imation: Representing Model Uncertainty in Deep Learning” by Gal and Ghahra-<br />mani, 2015.<br />1Introduction<br />Deep learning works very well in practice for many tasks, ranging from image processing<br />[Krizhevsky et al., 2012] to language modelling [Bengio et al., 2006]. However the framework has<br />some major limitations as well. Our inability to reason about uncertainty over the features is an<br />example of such. The features extracted from a dataset are often given as point estimates. These do<br />not allow us to capture how much the model is confident in its estimation. On the other hand, proba-<br />bilistic Bayesian models such as the Gaussian process [Rasmussen and Williams, 2006] offer us the<br />ability to reason about our confidence. But these often come with a price of lessened performance.<br />Another major obstacle with deep learning techniques is over-fitting. This problem has been largely<br />answeredwiththeintroductionofdropout[Hinton et al., 2012;Srivastava et al., 2014]. Indeedmany<br />modern models use dropout to avoid over-fitting in practice. Over the last several years many have<br />tried to explain why dropout helps in avoiding over-fitting, a property which is not often observed<br />in Bayesian models. Papers such as [Wager et al., 2013; Baldi and Sadowski, 2013] have suggested<br />that dropout performs stochastic gradient descent on a regularised error function, or is equivalent to<br />an L2regulariser applied after scaling the features by some estimate.<br />Here we show that a multilayer perceptron (MLP) with arbitrary depth and non-linearities, with<br />dropout applied after every weight layer, is mathematically equivalent to an approximation to the<br />probabilisticdeepGaussianprocessmodel[Damianou and Lawrence,2013]. We wouldliketostress<br />that no simplifying assumptions are made on the use of dropout in the literature, and that the results<br />derived are applicable to any network architecture that makes use of dropout exactly as it appears in<br />practicalapplications. We showthatthedropoutobjective,ineffect,minimisestheKullback–Leibler<br />divergence between an approximate model and the deep Gaussian process.<br />We survey possible applications of this new interpretation, and discuss insights shedding light on<br />dropout’s properties. This interpretation of dropout as a Bayesian model offers an explanation to<br />some of its properties, such as its ability to avoid over-fitting. Further, our insights allow us to treat<br />MLPs withdropoutasfullyBayesianmodels,andobtainuncertaintyestimates overtheirfeatures. In<br />practice, this allows the introductionof Bayesian machinery into existing deep learning frameworks<br />1</p>  <p>Page 2</p> <p>in a principled way. Lastly, our analysis suggests straightforward generalisations of dropout for<br />future research which should improve on current techniques.<br />The work presentedhere is an extensivetheoretical treatment of the above, with applicationsstudied<br />separately.<br />2Background<br />We review dropout, and survey the Gaussian process model1and approximate variational inference<br />quickly. These tools will be used in the following section to derive the main results of this work. We<br />use the following notation throughout the paper. Bold lower case letters denote vectors, bold upper<br />case letters denote matrices, and standard weight letters denote scalar quantities. We use subscripts<br />to denote either entire rows / columns (with bold letters), or specific elements. We use subscripts to<br />denotevariablesas well (suchas W1: Q×K,W2: K×D), with correspondinglowercase indices<br />to refer to specific rows / columns (wq,wkfor the first variable and wk,wdfor the second). We use<br />a second subscript to denote the element index of a specific variable: w1,qkdenotes the element at<br />row q column k of the variable W1.<br />2.1Dropout<br />We review the dropout MLP model [Hinton et al., 2012; Srivastava et al., 2014] quickly for the case<br />of a single hidden layer MLP. This is done for ease of notation, and generalisationto multiple layers<br />is straightforward. Denote by W1,W2the weight matrices connecting the first layer to the hidden<br />layer and connecting the hidden layer to the output layer respectively. These linearly transforming<br />the layers’ inputs before applying some element-wise non-linearity σ(·). Denote by b the biases<br />by which we shift the input of the non-linearity. We assume the model to output D dimensional<br />vectors while its input is Q dimensional vectors, with K hidden units. Thus W1is a Q×K matrix,<br />W2is a K × D matrix, and b is a K dimensional vector. A standard MLP model would output<br />? y = σ(xW1+ b)W2given some input x.2<br />elements of the vectors are distributed according to a Bernoulli distribution with some parameter<br />pi ∈ [0,1] for i = 1,2. Thus b1,q ∼ Bernoulli(p1) for q = 1,...,Q, and b2,k ∼ Bernoulli(p2)<br />for k = 1,...,K. Given an input x, 1 − p1 proportion of the elements of the input are set to<br />zero: x ◦ b1where ◦ signifies the Hadamard product. The output of the first layer is given by<br />σ((x ◦ b1)W1+ b) ◦ b2, which is linearly transformed to give the dropout model’s output ? y =<br />? y = σ(x(b1W1) + b)(b2W2).<br />we mean diag(b1) with the diag(·) operator mapping a vector to a diagonal matrix whose diagonal<br />is the elements of the vector.<br />Dropout is applied by sampling two binary vectors b1,b2of dimensions Q and K respectively. The<br />?(σ((x◦b1)W1+b))◦b2<br />?W2. This is equivalent to multiplyingthe weight matrices by the binary<br />vectors to zero out entire rows:<br />The process is repeated for multiple layers. Note that to keep notation clean we will write b1when<br />To use the MLP model for regression we might use the euclidean loss,<br />E =<br />1<br />2N<br />N<br />?<br />n=1<br />||yn− ? yn||2<br />2<br />(1)<br />where{y1,...,yN} are N observedoutputs,and{? y1,...,? yN} beingtheoutputsof the modelwith<br />To use the model for classification, predicting the probability of x being classified as 1,...,D, we<br />pass the output of the model ? y through an element-wise softmax function to obtain normalised<br />E = −1<br />N<br />n=1<br />where cn∈ [1,2,...,D] is the observed class of input n.<br />corresponding observed inputs {x1,...,xN}.<br />scores: ˆ pnd= exp(? ynd)/(?<br />d′exp(? ynd′)). Taking the log of this function results in a softmax loss,<br />log(ˆ pn,cn)<br />N<br />?<br />(2)<br />1For a full treatment of Gaussian Processes, see Rasmussen and Williams [2006].<br />2Note that we omit the outer-most bias term as this is equivalent to centring the output.<br />2</p>  <p>Page 3</p> <p>During optimisation, this term is scaled by the learning rate r1and a regularisation term is added.<br />We often use L2regularisation weighted by some weight decay r2(alternatively, the derivatives<br />might be scaled), resulting in a minimisation objective (often referred to as cost),<br />Ldropout:= r1E + r2<br />We sample new realisations for the binary vectors bifor every input point and every forward pass<br />thorough the model (evaluating the model’s output), and use the same values in the backward pass<br />(propagating the derivatives to the parameters).<br />?||W1||2<br />2+ ||W2||2<br />2+ ||b||2<br />2<br />?.<br />(3)<br />The dropped weights b1W1and b2W2are often scaled by<br />tude. At test time no sampling takes place. This is equivalent to initialising the weights Wiwith<br />scale<br />that the probabilities pican be optimised.<br />We will show that equations (1) to (3) arise in Gaussian process approximation as well. Next we<br />introduce the Gaussian process model.<br />1<br />pito maintain constant output magni-<br />1<br />piwith no further scaling at training time, and at test time scaling the weights Wiby pi. Note<br />2.2Gaussian Processes<br />The Gaussian process (GP) is a powerful tool in statistics that allows us to model distributions over<br />functions. It has been applied in both the supervised and unsupervised domains, for both regres-<br />sionandclassificationtasks[Rasmussen and Williams,2006;Titsias and Lawrence,2010;Gal et al.,<br />2015]. The Gaussian process offers desirable properties such as uncertainty estimates over the func-<br />tion values, robustness to over-fitting, and principled ways for hyper-parameter tuning. The use of<br />approximate variational inference for the model allows us to scale it to large data via stochastic and<br />distributed inference [Hensman et al., 2013; Gal et al., 2014].<br />Given a training dataset consisting of N inputs {x1,...,xN} and their corresponding outputs<br />{y1,...,yN}, we would like to estimate a function y = f(x) that is likely to have generated<br />our observations. We denote the inputs X ∈ RN×Qand the outputs Y ∈ RN×D.<br />What is a function that is likely to have generated our data? Following the Bayesian approach we<br />would put some prior distribution over the space of functions p(f). This distribution represents<br />our prior belief as to which functions are more likely and which are less likely to have generated<br />our data. We then look for the posterior distribution over the space of functions given our dataset<br />(X,Y):<br />p(f|X,Y) ∝ p(Y|X,f)p(f).<br />This distribution captures the most likely functions given our observed data.<br />By modelling our distribution over the space of functions with a Gaussian process we can analyti-<br />cally evaluate its corresponding posterior in regression tasks, and estimate the posterior in classifi-<br />cation tasks. In practice what this means is that for regression we place a joint Gaussian distribution<br />over all function values,<br />F | X ∼ N(0,K(X,X))<br />Y | F ∼ N(F,τ−1IN)<br />with some precisionhyper-parameterτ and where INis the identity matrix with dimensions N ×N.<br />For classification we sample from a categorical distribution with probabilities given by passing τY<br />through an element-wise softmax,<br />F | X ∼ N(0,K(X,X))<br />Y | F ∼ N(F,0 · IN)<br />?<br />for n = 1,...,N with observed class label cn. Note that we did not simply write Y = F because of<br />notational convenience that will allow us to treat regression and classification together.<br />(4)<br />(5)<br />cn| Y ∼ Categorical<br />exp(τynd)/<br />??<br />d′<br />exp(τynd′)<br />??<br />To model the data we have to choose a covariance function K(X,Y) for the Gaussian distribution.<br />This function defines the (scalar) similarity between every pair of input points K(xi,xj). Given a<br />finite dataset of size N this function induces an N × N covariance matrix which we will denote<br />K := K(X,X). For example we may choose a stationary squared exponential covariance function.<br />3</p>  <p>Page 4</p> <p>We will see below that certain non-stationary covariance functions correspond to TanH (hyperbolic<br />tangent) or ReLU (rectified linear) MLPs.<br />Evaluating the Gaussian distribution above involves an inversion of an N by N matrix, an operation<br />that requires O(N3) time complexity. Many approximations to the Gaussian process result in a<br />manageabletime complexity. Variational inference can be used for such, and will be explained next.<br />2.3 Variational Inference<br />To approximate the model above we could condition the model on a finite set of random variables<br />ω. We make a modelling assumption and assume that the model depends on these variables alone,<br />making them into sufficient statistics in our approximate model.<br />The predictive distribution for a new input point x∗is then given by<br />p(y∗|x∗,X,Y) =<br />?<br />p(y∗|x∗,ω)p(ω|X,Y) dω,<br />with y∗∈ RD. The distribution p(ω|X,Y) cannot usually be evaluated analytically. Instead we<br />define an approximating variational distribution q(ω), whose structure is easy to evaluate.<br />We would like our approximating distribution to be as close as possible to the posterior distribution<br />obtained from the full Gaussian process. We thus minimise the Kullback–Leibler (KL) divergence,<br />intuitively a measure of similarity between two distributions:<br />KL(q(ω) | p(ω|X,Y)),<br />resulting in the approximate predictive distribution<br />?<br />Minimising the Kullback–Leibler divergence is equivalent to maximising the log evidence lower<br />bound [Bishop, 2006],<br />?<br />with respect to the variational parameters defining q(ω). Note that the KL divergence in the last<br />equation is between the approximate posterior and the prior over ω. Maximising this objective<br />will result in a variational distribution q(ω) that explains the data well (as obtained from the first<br />term—the likelihood) while still being close to prior—preventing the model from over-fitting.<br />q(y∗|x∗) =p(y∗|x∗,ω)q(ω)dω.<br />(6)<br />LVI:=q(ω)logp(Y|X,ω)dω − KL(q(ω)||p(ω))<br />(7)<br />We next present a variational approximation to the Gaussian process extending on [Gal and Turner,<br />2015], which results in a model mathematically identical to the use of dropout in arbitrarily struc-<br />tured MLPs with arbitrary non-linearities.<br />3 Dropout as a Bayesian Approximation<br />We show that MLPs with dropout applied after every weight layer are mathematically equivalent<br />to approximate variational inference in the deep Gaussian process. For this we build on previous<br />work [Gal and Turner, 2015] that applied variational inference in the sparse spectrum Gaussian<br />process approximation [L´ azaro-Gredilla et al., 2010]. Starting with the full Gaussian process we<br />will developan approximationthat will be shownto be equivalentto the MLP optimisationobjective<br />with dropout(eq.(3)) with either the euclideanloss (eq.(1)) in the case of regressionor softmax loss<br />(eq. (2)) in the case of classification. This view of dropout will allow us to derive new probabilistic<br />results in deep learning.<br />3.1A Gaussian Process Approximation<br />Webeginbydefiningourcovariancefunction. Letσ besomenon-linearfunctionsuchastherectified<br />linear (ReLU) or the hyperbolic tangent function (TanH). We define K(x,y) to be<br />?<br />with p(w) a standard multivariate normal distribution of dimensionality Q and some distribution<br />p(b). It is trivial to show that this defines a valid covariance function following [Tsuda et al., 2002].<br />K(x,y) =p(w)p(b)σ(wTx + b)σ(wTy + b)dwdb<br />4</p>  <p>Page 5</p> <p>We use Monte Carlo integration with K terms to approximate the integral above. This results in<br />K<br />?<br />with wk∼ p(w) and bk∼ p(b). K will be the number of hidden units in our single hidden layer<br />MLP approximation.<br />?K(x,y) =<br />1<br />K<br />k=1<br />σ(wT<br />kx + bk)σ(wT<br />ky + bk)<br />Using?K instead of K as the covariance function of the Gaussian process yields the following gen-<br />wk∼ p(w), bk∼ p(b),<br />W1= [wk]K<br />erative model:<br />k=1,b = [bk]K<br />?<br />k=1<br />?K(x,y) =<br />F | X,W1,b ∼ N(0,?K(X,X))<br />1<br />K<br />K<br />k=1<br />σ(wT<br />kx + bk)σ(wT<br />ky + bk)<br />Y | F ∼ N(F,τ−1IN),<br />(8)<br />with W1a Q × K matrix.<br />This results in the following predictive distribution:<br />p(Y|X) =<br />?<br />p(Y|F)p(F|W1,b,X)p(W1)p(b)<br />where the integration is with respect to F,W1, and b.<br />Denoting the 1 × K row vector<br />φ(x,W1,b) =<br />?<br />1<br />Kσ(WT<br />n=1, we have?K(X,X) = ΦΦT. We rewrite<br />N(Y;0,ΦΦT+ τ−1IN)p(W1)p(b)dW1db,<br />1x + b)<br />and the N × K feature matrix Φ = [φ(xn,W1,b)]N<br />p(Y|X) as<br />p(Y|X) =<br />?<br />analytically integrating with respect to F.<br />The normal distribution of Y inside the integral above can be written as a joint normal distribution<br />over yd, the d’th columns of the N × D matrix Y, for d = 1,...,D. For each term in the joint<br />distribution, following identity [Bishop, 2006, page 93], we introduce a K × 1 auxiliary random<br />variable wd∼ N(0,IK),<br />?<br />Writing W2= [wd]D<br />?<br />where the integration is with respect to W1,W2, and b.<br />We have re-parametrised the GP model and introduced additional auxiliary random variables<br />W1,W2, and b. We next approximate the posterior over these variables with appropriate approxi-<br />mating variational distributions.<br />N(yd;0,ΦΦT+ τ−1IN) =<br />N(yd;Φwd,τ−1IN)N(wd;0,IK)dwd.<br />d=1a K × D matrix, the above is equivalent to3<br />p(Y|X) =p(Y|X,W1,W2,b)p(W1)p(W2)p(b)<br />3.2Variational Inference in the Approximate Model<br />Our sufficient statistics are W1,W2, and b. To perform variational inference in our approximate<br />model we need to define a variationaldistribution q(W1,W2,b) := q(W1)q(W2)q(b). We define<br />3This is equivalent<br />[Rasmussen and Williams, 2006].<br />to the weightedbasis function interpretationof the Gaussianprocess<br />5</p>  <p>Page 6</p> <p>q(W1) to be a Gaussian mixture distribution with two components, factorised over Q:4<br />Q<br />?<br />q(wq) = p1N(mq,σ2IK) + (1 − p1)N(0,σ2IK)<br />with some probability p1 ∈ [0,1], scalar σ &gt; 0 and mq ∈ RK. We put a similar approximating<br />distribution over W2:<br />K<br />?<br />q(wk) = p2N(mk,σ2ID) + (1 − p2)N(0,σ2ID)<br />with some probability p2∈ [0,1].<br />We put a simple Gaussian approximating distribution over b:<br />q(b) = N(m,σ2IK).<br />q(W1) =<br />q=1<br />q(wq),<br />(9)<br />q(W2) =<br />k=1<br />q(wk),<br />(10)<br />(11)<br />Next we evaluate the log evidence lower bound for the task of regression, for which we optimise<br />over M1 = [mq]Q<br />discussed later.<br />q=1, M2 = [mk]K<br />k=1, and m, to maximise Eq. (7). The task of classification is<br />3.3Evaluating the Log Evidence Lower Bound for Regression<br />We need to evaluate the log evidence lower bound:<br />?<br />LGP-VI:=q(W1,W2,b)logp(Y|X,W1,W2,b) − KL(q(W1,W2,b)||p(W1,W2,b)),<br />(12)<br />where the integration is with respect to W1,W2, and b.<br />We re-parametrise the integrand to not depend on W1,W2, and b directly, but instead on the<br />standard normal distribution and the Bernoulli distribution. Let ǫ1 ∼ N(0,IQ×K) and b1,q ∼<br />Bernoulli(p1) for q = 1,...,Q, and ǫ2∼ N(0,IK×D) and b2,k∼ Bernoulli(p2) for k = 1,...,K.<br />Finally let ǫ ∼ N(0,IK). We write<br />W1= b1(M1+ σǫ1) + (1 − b1)σǫ1<br />W2= b2(M2+ σǫ2) + (1 − b2)σǫ2<br />b = m + σǫ,<br />allowing us to re-write the integral in the above equation as<br />?<br />=q(b1,ǫ1,b2,ǫ2,ǫ)logp(Y|X,W1(b1,ǫ1),W2(b2,ǫ2),b(ǫ))dǫ1db1dǫ2db2dǫ.<br />(13)<br />q(W1,W2,b)logp(Y|X,W1,W2,b)dW1dW2db<br />?<br />We estimate the integral using Monte Carlo integration with a single sample to obtain:<br />LGP-MC:=logp(Y|X,?<br />? ǫ2∼ N(0,IK×D), and?b2,k∼ Bernoulli(p2). Following [Blei et al., 2012; Hoffman et al., 2013;<br />For the task of regression we have<br />?<br />W1,?<br />W2,?b) − KL(q(W1,W2,b)||p(W1,W2,b))<br />with?<br />Kingma and Welling, 2013; Rezende et al., 2014; Titsias and L´ azaro-Gredilla, 2014], optimisingthe<br />stochastic objective LGP-MCwe would converge to the same limit as LGP-VI.<br />W1,?<br />W2,?b defined following eq. (13) with ? ǫ1 ∼ N(0,IQ×K),?b1,q ∼ Bernoulli(p1),<br />logp(Y|X,?<br />W1,?<br />W2,?b) =<br />D<br />d=1<br />logN(yd;Φ? wd,τ−1IN)<br />4Note that this is a bi-modal distribution defined over each output dimensionality; as a result the joint<br />distribution over W1is highly multi-modal.<br />6</p>  <p>Page 7</p> <p>= −ND<br />2<br />log(2π) +ND<br />2<br />log(τ) −<br />D<br />?<br />d=1<br />τ<br />2||yd− Φ? wd||2<br />2,<br />as the output dimensions of a multi-outputGaussian process are assumed to be independent. Denote<br />?Y = ΦW2. We can then sum over the rows instead of the columns of?Y and write<br />d=1<br />Here ? yn= φ(xn,?<br />analytically. However we can perform Monte Carlo integration like in the above. A further approxi-<br />mation for large K (numberof hiddenunits) and small σ2yields a weighted sum of KL divergences<br />between the mixture components and the single Gaussian (proposition 1 in the appendix). Intu-<br />itively, this is because the entropy of a mixture of Gaussians with a large enough dimensionality<br />and randomly distributed means tends towards the sum of the Gaussians’ volumes. Following the<br />proposition, for large enough K we can approximate the KL divergence term as<br />D<br />?<br />τ<br />2||yd− ? yd||2<br />1<br />2=<br />N<br />?<br />n=1<br />τ<br />2||yn− ? yn||2<br />W2.<br />2.<br />W1,?b)?<br />W2=<br />?<br />Kσ(xn?<br />W1+?b)?<br />We can’t evaluate the KL divergence term between a mixture of Gaussians and a single Gaussian<br />KL(q(W1)||p(W1)) ≈ QK(σ2− log(σ2) − 1) +p1<br />2<br />Q<br />?<br />q=1<br />mT<br />qmq.<br />and similarly for KL(q(W2)||p(W2)). The term KL(q(b)||p(b)) can be evaluated analytically as<br />KL(q(b)||p(b)) =1<br />2<br />Next we explain the relation between the above equations and the equations brought in section 2.1.<br />?mTm + K(σ2− log(σ2) − 1)?.<br />3.4 Log Evidence Lower Bound Optimisation<br />Ignoring the constant terms τ,σ we obtain the maximisation objective<br />N<br />?<br />Note that in the Gaussian processes literature the terms τ,σ will often be optimised as well.<br />LGP-MC∝ −τ<br />2<br />n=1<br />||yn− ? yn||2<br />2−p1<br />2||M1||2<br />2−p2<br />2||M2||2<br />2−1<br />2||m||2<br />2.<br />Letting σ tend to zero, we get that the KL divergence blows-up and tends to infinity. However,<br />in real-world scenarios setting σ to be machine epsilon (10−33for example in quadruple precision<br />decimal systems) results in a constant value logσ = −76. With high probability samples from a<br />Gaussian distribution with such a small standard deviation will be represented on a computer, in<br />effect, as zero. Thus the random variable realisations?<br />Note that?<br />? yn≈<br />Scaling the optimisation objective by a positive constant γ doesn’t change the parameter values at<br />its optimum. We thus scale the objective to get<br />N<br />?<br />and we recovered equation (1) for an appropriate setting of γ and model precision τ. Maximising<br />eq. (14) results in the same optimal parameters as minimising eq. (3). Note that eq. (14) is a scaled<br />unbiased estimator of eq. (12). With correct stochastic optimisation scheduling both will converge<br />to the same limit.<br />W1,?<br />W2,?b can be approximated as<br />?<br />W1≈?b1M1, ?<br />?<br />W2≈?b2M2,?b ≈ m.<br />W1are not maximum a posteriori (MAP) estimates, but random variables realisations.<br />This gives us<br />1<br />Kσ(xn(?b1M1) + m)(?b2M2).<br />LGP-MC∝ −γτ<br />2<br />n=1<br />||yn− ? yn||2<br />2−γp1<br />2<br />||M1||2<br />2−γp2<br />2<br />||M2||2<br />2−γ<br />2||m||2<br />2<br />(14)<br />TheoptimisationofLGP-MCproceedsasfollows. We samplerealisations?b1,?b2toevaluatethelower-<br />descent step), and repeat, sampling new realisations.<br />bound and its derivatives. We perform a single optimisation step (for example a single gradient<br />7</p>  <p>Page 8</p> <p>We can make several interesting observations at this point. First, as is commonly known, the ratio<br />between the constant scaling the likelihood term in the dorpout objective (the first term, usually<br />referred to as the learning rate) and that of the regularisation terms (the rest of the terms, usually<br />referred to as the weight-decays) gives us the model precision:<br />that the weight-decayfor the dropped-outweights should be scaled by the probabilityof the weights<br />to not be dropped. This might explain why doubling the learning rate of the bias during MLP opti-<br />misation works well in practice in dropout networks with p = 0.5. Lastly, it is known that setting<br />the dropout probability to zero (p1= p2= 1) results in a standard MLP. Following the derivation<br />above, this would result in delta function approximatingdistributions on the weights (replacing eqs.<br />(9)-(11)). As was discussed in [L´ azaro-Gredilla et al., 2010] this leads to model over-fitting. Em-<br />pirically it seems that the Bernoulli approximating distribution is sufficient to considerably prevent<br />over-fitting.<br />r1<br />r2=<br />γτ/2<br />γ/2= τ. Second, it seems<br />We have presented the derivation for a single hidden layer MLP. An extension of the derivation to<br />multiple layers is given below.<br />3.5 Evaluating the Log Evidence Lower Bound for Classification<br />For classification we have an additional step in the generative model in eq. (5) compared to eq.<br />(4), sampling class assignment cngiven weight yn. We can write this generative model using the<br />auxiliary random variables introduced in section 3.1 for the regression case by<br />?<br />=p(c|Y)<br />p(Y|X,W1,W2,b)p(W1,W2,b)dW1dW2db<br />p(c|X) =p(c|Y)p(Y|X)dY<br />??<br />?<br />?<br />dY<br />where c is an N dimensional vector of categorical values. We can write the log evidence lower<br />bound in this case as (proposition 2 in the appendix)<br />?<br />− KL(q(W1,W2,b)||p(W1,W2,b)).<br />LGP-VI:=p(Y|X,W1,W2,b)q(W1,W2,b)logp(c|Y)dW1dW2dbdY<br />We can re-parametrise the integrand like in (13) to obtain<br />W1= b1(M1+ σǫ1) + (1 − b1)σǫ1<br />W2= b2(M2+ σǫ2) + (1 − b2)σǫ2<br />b = m + σǫ,<br />?<br />yn=<br />1<br />Kσ(xnW1+ b)W2.<br />(15)<br />Like before, we estimate the integral using Monte Carlo integration with a single sample to obtain:<br />LGP-MC:=logp(c|?Y(X,?<br />N<br />?<br />and the second expression as before. Scaling the objective by a positive γ again, this results in the<br />following maximisation objective,<br />? N<br />n=1<br />d′<br />identical (up to a sign flip) to that of eqs. (2), (3) for appropriate selection of γ and τ.<br />W1,?<br />W2,?b)) − KL(q(W1,W2,b)||p(W1,W2,b)).<br />??<br />We evaluate the first expression as<br />logp(c|?Y) =<br />n=1<br />τ? yncn− τ log<br />d′<br />exp(? ynd′)<br />?<br />LGP-MC∝ γτ<br />?<br />τ? yncn− log<br />??<br />exp(? ynd′)<br />??<br />−γp1<br />2<br />||M1||2<br />2−γp2<br />2<br />||M2||2<br />2−γ<br />2||m||2<br />2,<br />3.6Going Deeper than a Single Hidden Layer<br />We will demonstrate how to extend the derivation above to two hidden layers for the case of regres-<br />sion. Extension to further layers and classification is trivial.<br />8</p>  <p>Page 9</p> <p>We use the deep GP model – feeding the output of one GP to the covarianceof the next, much in the<br />same way the input is used in the covariance of the first GP. However, to match the dropout MLP<br />model, we have to select a different a covariance function for the GPs following the first one. For<br />clarity,we denotehereall quantitiesrelatedto the first GP with subscript1, andas a secondsubscript<br />denote the element index. So φ1,nkdenotes the element at row n column k of the variable Φ1, and<br />φ1,ndenotes row n of the same variable.<br />We next define the new covariancefunctionK2. Let σ2be some non-linearfunction,not necessarily<br />the same as the one used with the previous covariance function. We define K2(x,y) to be<br />?<br />with some distribution p(b2).<br />We use Monte Carlo integration with K2terms to approximate the integral above. This results in<br />K2<br />?<br />with b2,k∼ p(b2).<br />K2(x,y) =p(b2)σ2(x + b2)σ2(y + b2)db2<br />?K2(x,y) ≈<br />1<br />K2<br />k=1<br />σ(x + b2,k)σ(y + b2,k)<br />Using?K2instead as the covariance function of the second Gaussian process yields the following<br />w1,k∼ p(w1), b1,k∼ p(b1), b2,k∼ p(b2)<br />W1= [w1,k]K1<br />with W1a Q × K1matrix, b1a K1dimensional vector, and b2a K2dimensional vector. Given<br />these variables, we define the covariance functions for the two GPs:<br />K1<br />?<br />1<br />K2<br />k=1<br />generative model. First, we sample the variables for all covariance functions:<br />k=1,b1= [b1,k]K1<br />k=1,b2= [b2,k]K2<br />k=1<br />?K1(x,y) =<br />?K2(x,y) =<br />1<br />K1<br />k=1<br />?<br />σ1(wT<br />1,kx + b1,k)σ1(wT<br />1,ky + b1,k)<br />K2<br />σ2(x + b2,k)σ2(y + b2,k)<br />Conditioned on these variables, we generate the model’s output:<br />F1| X,W1,b1∼ N(0,?K1(X,X))<br />F2| X,b2∼ N(0,?K2(F1,F1))<br />Y | F2∼ N(F2,τ−1IN).<br />We introduce auxiliary random variables W2a K1× K2matrix and W3a K2× D matrix. The<br />columns of each matrix distribute according to N(0,I).<br />Like before, we write?K1(X,X) = Φ1ΦT<br />1with Φ1an N × K1matrix and?K2(X,X) = Φ2ΦT<br />1<br />K1σ1(wT<br />?<br />2<br />with Φ2an N × K2matrix:<br />φ1,nk=<br />?<br />1,kxn+ b1,k)<br />φ2,nk=<br />1<br />K2σ2(f1,nk+ b2,k).<br />We can then write F1= Φ1W2, since<br />E(F1) = Φ1E(W2) = 0<br />and<br />Cov(F1) = E(F1FT<br />1) = Φ1E(W2WT<br />?<br />2)ΦT<br />1= Φ1ΦT<br />1,<br />and similarly for F2. Note that F1is an N × K2matrix, and that F2is an N × D matrix. Thus,<br />1<br />K2σ2(wT<br />φ2,nk=<br />2,kφ1,n+ b2,k).<br />9</p>  <p>Page 10</p> <p>Finally, we can write<br />yn|X,W1,b1,W2,b2,W3 ∼ N(WT<br />3φ2,n,τ−1ID).<br />The application of variational inference continues as before.<br />4Insights and Applications<br />Our derivation suggests many applications and insights, including the representation of model un-<br />certainty in deep learning, better model regularisation, computationally efficient Bayesian convolu-<br />tional neural networks, use of dropout in recurrent neural networks, and the principled development<br />of dropout variants, to name a few. These are briefly discussed here, and studied more in depth in<br />separate work.<br />4.1Insights<br />The Gaussian process’s robustness to over-fitting can be contributed to several different aspects of<br />the model and is discussed in detail in [Rasmussen and Williams, 2006]. Our interpretation offers<br />an explanation to dropout’s ability to avoid over-fitting.<br />Our derivation also suggests that an approximating variational distribution should be placed over<br />the bias b. This could be sampled jointly with the weights W. Note that it is possible to interpret<br />dropout as doing so when used with non-linearities with σ(0) = 0. This is because the product<br />by the vector of Bernoulli random variables can be passed through the non-linearity in this case.<br />However the GP interpretation changes in this case, as the inputs are randomly set to zero rather<br />than the weights. By sampling Bernoulli variables for the bias weights as well, the model might<br />become more robust.<br />In [Srivastava et al., 2014] alternative distributions to the Bernoulli are discussed. For example, it is<br />suggested that multiplying the weights by N(1,σ2) results in similar results to dropout (although<br />this becomes a more costly operation at run time). This can be seen as an alternative approximating<br />variational distribution where we set q(wk) = mk+ mkǫ with ǫ ∼ N(0,I).<br />We noted in the text that the weight-decay for the dropped-out weights should be scaled by the<br />probability of the weights to not be dropped. This follows from the KL approximation. This might<br />explain why doubling the learning rate of the bias during MLP optimisation works well in practice<br />in dropout networks with p = 0.5.<br />We also note that the model brought in section 2.1 does not use a bias at the output layer. This is<br />equivalent to shifting the data by a constant amount and thus not treated in our derivation.<br />4.2Applications<br />Our derivationsuggests an estimate for dropoutmodels using T forward passes throughthe network<br />and averagingthe results (referredto as MC dropout, comparedto standard dropout with weight av-<br />eraging). This result has been presentedin the literaturebeforeas modelaveraging[Srivastava et al.,<br />2014]. Our interpretation suggests a new look as to why MC dropout is more sensible than the cur-<br />rent approach of averaging the weights. Furthermore, with the obtained samples we can estimate<br />the model’s confidence in its predictions and take actions accordingly. For example, in the case of<br />classification, the model might return a result with high uncertainty, in which case we might decide<br />to pass the input to a human to classify. Alternatively, one can use a weak and fast model to perform<br />classification, and use a more elaborate but slower model only on inputs for which the weak model<br />in uncertain. Uncertainty is important in reinforcement learning (RL) [Szepesv´ ari, 2010] as well.<br />With this informationan agent can decide when to exploit and when to explore its environment. Re-<br />cent advances in RL have made use of MLPs to estimate agents’ Q-value functions, a function that<br />estimates the quality of different states and actions in the environment [Mnih et al., 2013]. Epsilon<br />greedy search is often used in this setting, where an agent selects the its currently estimated best<br />action with some probability, and explores otherwise. With uncertainty estimates over the agent’s<br />Q-value function, techniques such as Thompson sampling [Thompson, 1933] can be used to train<br />the model faster. These ideas are studied in the main paper.<br />Following our interpretation, one should apply dropout after each weight layer and not only after<br />inner-product layers at the end of the model. This is to avoid parameter over-fitting on all layers as<br />the dropout model, in effect, integrates over the parameters. The use of dropout after a subset of the<br />10</p>  <p>Page 11</p> <p>layers corresponds to interleaving MAP estimates and fully Bayesian estimates. The application of<br />dropout after every weight layer is not used in practice however, as empirical results using standard<br />dropout suggest inferior performance. The use of MC dropout, however, with dropout applied after<br />every weight layer results in much better empirical performance on some MLP structures. One<br />can also interpret the approximation above as approximate variational inference in Bayesian neural<br />networks(NNs). Thus, dropoutappliedaftereveryweightlayeris equivalentto variationalinference<br />in Bayesian NNs. This allows us to develop new Bayesian NN architectures which are not directly<br />related to the Gaussian process, using operations such as pooling and convolutions. This leads to<br />a good, efficient, and trivial approximations to Bayesian convolutional neural networks (convnets).<br />We discuss these ideas with empirical evaluation in separate work.<br />Another possible application is the adaptationof dropoutto recurrentneural networks (RNNs). Cur-<br />rently, dropout is not used with these models as the repeated application of noise over potentially<br />thousands of layers results in a very weak signal at the output. GP dynamical models [Wang et al.,<br />2005] and recursive GPs with perfect integrators correspond to the ideas behind RNNs and long-<br />short-term-memory (LSTM) networks [Hochreiter and Schmidhuber, 1997]. The GP models inte-<br />grate over the parameters and thus avoid over-fitting. Seen as a GP approximationone would expect<br />there to exist a suitable dropout approximation for these tasks as well.<br />Model ensembles are often used in deep learning as well, where the same model is trained several<br />times and at test time the results of all models are averaged. This is computationally very expen-<br />sive as either training time is increased considerably, or many computational resources are used at<br />the same time. One would expect that stochastically simulating forward passes through a dropout<br />network will result in similar performance.<br />Lastly, our interpretation allows the development of principled extensions of dropout. The use of<br />non-diminishing σ2(eqs. (9) to (11)) and the use of a mixture of Gaussians with more than two<br />components is an immediate example of such. For example the use of a low rank covariance matrix<br />would allow us to capture complex relations between the weights. These approximations could<br />result in alternative uncertainty estimates to the ones obtained with MC dropout. This is subject to<br />current research.<br />5 Conclusions<br />Wehaveshownthatamultilayerperceptronwitharbitrarydepthandnon-linearitiesandwithdropout<br />applied after every weight layer is mathematically equivalent to an approximationto the deep Gaus-<br />sian process. This interpretation offers an explanation to some of dropout’s key properties. Our<br />analysis suggests straightforward generalisations of dropout for future research which should im-<br />prove on current techniques.<br />Acknowledgments<br />The authorswould like to thankMr ShaneGu, Mr Nilesh Tripuraneni,ProfYoshuaBengio, andProf<br />Phil Blunsom for helpful comments. Yarin Gal is supported by the Google European Fellowship in<br />Machine Learning.<br />References<br />Baldi, P. and Sadowski, P. J. (2013). Understanding dropout. In Advances in Neural Information<br />Processing Systems, pages 2814–2822.<br />Bengio, Y., Schwenk, H., Sen´ ecal, J.-S., Morin, F., and Gauvain, J.-L. (2006). Neural probabilistic<br />language models. In Innovations in Machine Learning, pages 137–186. Springer.<br />Bishop, C. M. (2006). Pattern Recognition and Machine Learning (Information Science and Statis-<br />tics). Springer-Verlag New York, Inc., Secaucus, NJ, USA.<br />Blei, D. M., Jordan, M. I., and Paisley, J. W. (2012). Variational Bayesian inference with stochastic<br />search. In Proceedings of the 29th International Conference on Machine Learning (ICML-12),<br />pages 1367–1374.<br />11</p>  <p>Page 12</p> <p>Blundell, C., Cornebise, J., Kavukcuoglu, K., and Wierstra, D. (2015). Weight uncertainty in neural<br />networks. arXiv preprint arXiv:1505.05424.<br />Damianou, A. and Lawrence, N. (2013). Deep Gaussian processes. In Proceedings of the Sixteenth<br />International Conference on Artificial Intelligence and Statistics, pages 207–215.<br />Gal, Y., Chen, Y., and Ghahramani, Z. (2015). Latent Gaussian processes for distribution estimation<br />of multivariate categoricaldata. In Proceedings of the 32ndInternationalConference on Machine<br />Learning (ICML-15).<br />Gal, Y. and Turner, R. (2015). Improving the Gaussian process sparse spectrum approximation by<br />representinguncertaintyinfrequencyinputs. InProceedingsofthe32ndInternationalConference<br />on Machine Learning (ICML-15).<br />Gal, Y., van der Wilk, M., and Rasmussen, C. (2014). Distributed variational inference in sparse<br />Gaussian process regression and latent variable models. In Ghahramani, Z., Welling, M., Cortes,<br />C., Lawrence, N., and Weinberger, K., editors, Advances in Neural Information Processing Sys-<br />tems 27, pages 3257–3265.Curran Associates, Inc.<br />Graves, A. (2011). Practical variational inference for neural networks. In Advances in Neural<br />Information Processing Systems, pages 2348–2356.<br />Hensman, J., Fusi, N., and Lawrence, N. D. (2013). Gaussian processes for big data. In Nicholson,<br />A. and Smyth, P., editors, UAI. AUAI Press.<br />Hinton, G. E., Srivastava, N., Krizhevsky, A., Sutskever, I., and Salakhutdinov, R. R. (2012).<br />Improving neural networks by preventing co-adaptation of feature detectors.<br />arXiv:1207.0580.<br />Hochreiter, S. and Schmidhuber, J. (1997). Long short-term memory.<br />9(8):1735–1780.<br />Hoffman, M. D., Blei, D. M., Wang, C., and Paisley, J. (2013). Stochastic variational inference. The<br />Journal of Machine Learning Research, 14(1):1303–1347.<br />Kingma, D. P. and Welling, M. (2013). Auto-encoding variational Bayes.<br />arXiv:1312.6114.<br />Krizhevsky, A., Sutskever, I., and Hinton, G. E. (2012). Imagenet classification with deep convolu-<br />tional neural networks. In Advances in neural information processing systems, pages 1097–1105.<br />L´ azaro-Gredilla, M., Qui˜ nonero-Candela, J., Rasmussen, C. E., and Figueiras-Vidal, A. R. (2010).<br />Sparse spectrum Gaussian process regression.<br />11:1865–1881.<br />MacKay, D. J. (1992). A practical Bayesian framework for backpropagation networks. Neural<br />computation, 4(3):448–472.<br />Mnih, V., Kavukcuoglu, K., Silver, D., Graves, A., Antonoglou, I., Wierstra, D., and Riedmiller, M.<br />(2013). Playing atari with deep reinforcement learning. arXiv preprint arXiv:1312.5602.<br />Neal, R. M. (1995). Bayesian learning for neural networks. PhD thesis, University of Toronto.<br />Rasmussen, C. E. and Williams, C. K. I. (2006). Gaussian Processes for Machine Learning (Adap-<br />tive Computation and Machine Learning). The MIT Press.<br />Rezende, D. J., Mohamed,S., and Wierstra, D. (2014). Stochastic backpropagationandapproximate<br />inference in deep generative models. In Proceedings of the 31st International Conference on<br />Machine Learning (ICML-14), pages 1278–1286.<br />Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., and Salakhutdinov, R. (2014). Dropout:<br />A simple way to prevent neural networks from overfitting. The Journal of Machine Learning<br />Research, 15(1):1929–1958.<br />Szepesv´ ari, C. (2010). Algorithms for reinforcement learning. Synthesis Lectures on Artificial<br />Intelligence and Machine Learning, 4(1):1–103.<br />Thompson, W. R. (1933). On the likelihood that one unknown probability exceeds another in view<br />of the evidence of two samples. Biometrika, pages 285–294.<br />Titsias, M. and Lawrence, N. (2010). Bayesian Gaussian process latent variable model. Thirteenth<br />International Conference on Artificial Intelligence and Statistics (AISTATS), 6:844–851.<br />arXiv preprint<br />Neural computation,<br />arXiv preprint<br />The Journal of Machine Learning Research,<br />12</p>  <p>Page 13</p> <p>Titsias, M. and L´ azaro-Gredilla, M. (2014). Doubly stochastic variational Bayes for non-conjugate<br />inference. In Proceedings of the 31st InternationalConference on Machine Learning (ICML-14),<br />pages 1971–1979.<br />Tsuda, K., Kin, T., and Asai, K. (2002). Marginalized kernels for biological sequences. Bioinfor-<br />matics, 18(suppl 1):S268–S275.<br />Wager, S., Wang, S., and Liang, P. S. (2013). Dropout training as adaptive regularization. In<br />Advances in Neural Information Processing Systems, pages 351–359.<br />Wang, J., Hertzmann,A., and Blei, D. M. (2005). Gaussian process dynamical models. In Advances<br />in neural information processing systems, pages 1441–1448.<br />Williams, C. K. (1997). Computing with infinite networks. Advances in neural information pro-<br />cessing systems, pages 295–301.<br />13</p>  <p>Page 14</p> <p>AKL of a Mixture of Gaussians<br />Proposition 1. Let<br />q(x) =<br />L<br />?<br />i=1<br />piN(x;µi,Σi)<br />be a mixture of Gaussians with L components and µi∈ RKnormally distributed, and let p(x) =<br />N(0,IK).<br />The KL divergence between q(x) and p(x) can be approximated as:<br />?<br />for large enough K.<br />KL(q(x)||p(x)) ≈<br />L<br />i=1<br />pi<br />2<br />?µT<br />iµi+ tr(Σi) − K − log|Σi|?<br />Proof. We have<br />KL(q(x)||p(x)) =<br />?<br />?<br />q(x)logq(x)<br />p(x)dx<br />=q(x)logq(x)dx −<br />?<br />q(x)logp(x)dx<br />= −H(q(x)) −<br />?<br />q(x)logp(x)dx<br />where H(q(x)) is the entropyof q(x). The second term in the last line can be evaluatedanalytically,<br />but the entropy term has to be approximated.<br />We begin by approximating the entropy term. We write<br />H(q(x)) = −<br />L<br />?<br />L<br />?<br />L<br />?<br />i=1<br />pi<br />?<br />?<br />?1<br />N(x;µi,Σi)logq(x)dx<br />= −<br />i=1<br />pi<br />N(ǫ;0,I)logq(µi+ Liǫ)dǫ<br />≈ −<br />i=1<br />pi<br />T<br />T<br />?<br />t=1<br />logq(µi+ Liǫit)<br />?<br />for some T &gt; 0 with LiLT<br />Now, the term inside the logarithm can be written as<br />q(µi+ Liǫit)<br />?<br />L<br />?<br />where || · ||Σis the Mahalanobis distance. Since µi,µjare assumed to be normally distributed,<br />the quantity µj− µi− Liǫitis also normally distributed. Using the expectation of the gener-<br />alised χ2distribution with K degrees of freedom, we have that for K &gt;&gt; 0 there exists that<br />||µj− µi− Liǫit||2<br />ǫT<br />i<br />L−1<br />q(µi+ Liǫit) ≈ pi(2π)−K/2|Σi|−1/2exp?−1<br />This gives us<br />H(q(x))<br />i= Σiand ǫit∼ N(0,I).<br />=<br />L<br />j=1<br />piN(µi+ Liǫit;µj,Σj)<br />=<br />j=1<br />pi(2π)−K/2|Σj|−1/2exp?−1<br />2||µj− µi− Liǫit||2<br />Σj<br />?.<br />Σj&gt;&gt; 0 for i ?= j. Finally, we have for i = j that ||µi− µi− Liǫit||2<br />iLiǫit= ǫT<br />Σi=<br />itLT<br />iL−T<br />itǫit. Therefore the last equation can be written as<br />2ǫT<br />itǫit<br />?.<br />14</p>  <p>Page 15</p> <p>≈ −<br />L<br />?<br />L<br />?<br />?<br />i=1<br />pilog<br />?1<br />T<br />T<br />?<br />t=1<br />pi(2π)−K/2|Σi|−1/2exp?−1<br />T<br />?<br />2log(2π)<br />. SinceǫT<br />2ǫT<br />itǫit<br />??<br />=<br />i=1<br />pi<br />2<br />?log|Σi| +1<br />logpi−K<br />T<br />t=1<br />?<br />ǫT<br />itǫit<br />?+ C<br />itǫitdistributesaccordingtoaχ2distribution,<br />whereC = −?L<br />it’s expectation is K, and the last term can be approximated as<br />i=1pi<br />H(q(x)) ≈<br />L<br />?<br />i=1<br />pi<br />2<br />?log|Σi| + K?+ C<br />Next, evaluating the first term of the KL divergence we get<br />?<br />for p(x) = N(0,IK) it is easy to validate that this is equivalent to −1<br />Finally, we get<br />q(x)logp(x)dx =<br />L<br />?<br />i=1<br />pi<br />?<br />N(x;µi,Σi)logp(x)dx<br />2<br />?L<br />i=1pi<br />?µT<br />iµi+ tr(Σi)?.<br />KL(q(x)||p(x)) ≈<br />L<br />?<br />i=1<br />pi<br />2<br />?µT<br />iµi+ tr(Σi) − K − log|Σi|?.<br />B Log Evidence Lower Bound for Classification<br />Proposition 2. Given<br />p(c|X) =<br />?<br />?<br />p(c|Y)p(Y|X)dY<br />??<br />=p(c|Y)<br />p(Y|X,W1,W2,b)<br />· p(W1,W2,b)dW1dW2db<br />?<br />dY<br />where c is an N dimensional vector of categorical values, we can write the log evidence lower<br />bound as<br />?<br />· logp(c|Y)dW1dW2dbdY<br />− KL(q(W1,W2,b)||p(W1,W2,b)).<br />LGP-VI:=p(Y|X,W1,W2,b)q(W1,W2,b)<br />Proof. We have<br />logp(c|X)<br />= log<br />?<br />?<br />p(c|Y)p(Y|X,W1,W2,b)<br />· p(W1,W2,b)dW1dW2dbdY<br />= logq(W1,W2,b)p(Y|X,W1,W2,b)p(c|Y)<br />·p(W1,W2,b)<br />q(W1,W2,b)dW1dW2dbdY<br />≥<br />?<br />q(W1,W2,b)p(Y|X,W1,W2,b)log<br />?<br />p(c|Y)<br />15</p>  <p>Page 16</p> <p>·p(W1,W2,b)<br />q(W1,W2,b)<br />?<br />dW1dW2dbdY<br />=<br />?<br />q(W1,W2,b)p(Y|X,W1,W2,b)<br />· logp(c|Y)dW1dW2dbdY<br />− KL(q(W1,W2,b)||p(W1,W2,b)),<br />as needed.<br />C Predictive Mean<br />Proposition 3. Given weights matrices Miof dimensions Ki× Ki−1, bias vectors miof dimen-<br />sions Ki, and binary vectors biof dimensions Ki−1for each layer i = 1,...,L, as well as the<br />approximating variational distribution<br />q(y∗|x∗) := N?y∗;? y∗(x∗,b1,...,bL),τ−1ID<br />? y∗=<br />Eq(y∗|x∗)(y∗) ≈1<br />T<br />t=1<br />with<br />?bi,t∼ Bern(pi).<br />Proof.<br />?<br />=<br />? ??<br />=<br />? y∗(x∗,b1,...,bL)Bern(b1)···Bern(bL)db1···dbL<br />≈1<br />T<br />t=1<br />?Bern(b1)···Bern(bL)<br />for some τ &gt; 0, with<br />?<br />1<br />KL(MLbL)σ<br />?<br />...<br />?<br />1<br />K1(M2b2)σ?(M1b1)x∗+ m1<br />T<br />?<br />?...<br />?<br />,<br />we have<br />? y∗(x∗,?b1,t,...,?bL,t)<br />Eq(y∗|x∗)(y∗) =<br />y∗q(y∗|x∗)dy∗<br />?<br />y∗N?y∗;? y∗(x∗,b1,...,bL),τ−1ID<br />?Bern(b1)···Bern(bL)db1···dbLdy∗<br />?dy∗<br />=<br />y∗N?y∗; ? y∗(x∗,b1,...,bL),τ−1ID<br />?<br />Bern(b1)···Bern(bL)db1···dbLdy∗<br />?<br />T<br />?<br />? y∗(x∗,?b1,t,...,?bL,t).<br />DPredictive Variance<br />Proposition 4. Given weights matrices Miof dimensions Ki× Ki−1, bias vectors miof dimen-<br />sions Ki, and binary vectors biof dimensions Ki−1for each layer i = 1,...,L, as well as the<br />approximating variational distribution<br />q(y∗|x∗) := p(y∗|x∗,ω)q(ω)<br />q(ω) = Bern(b1)···Bern(bL)<br />p(y∗|x∗,ω) = N?y∗; ? y∗(x∗,b1,...,bL),τ−1ID<br />? y∗=<br />16<br />?<br />for some τ &gt; 0, with<br />?<br />1<br />KL(MLbL)σ<br />?<br />...<br />?<br />1<br />K1(M2b2)σ?(M1b1)x∗+ m1<br />?...<br />?<br />,</p>  <p>Page 17</p> <p>we have<br />Eq(y∗|x∗)<br />?(y∗)T(y∗)?≈ τ−1ID+1<br />T<br />T<br />?<br />t=1<br />? y∗(x∗,?b1,t,...,?bL,t)T? y∗(x∗,?b1,t,...,?bL,t)<br />?bi,t∼ Bern(pi).<br />with<br />Proof.<br />Eq(y∗|x∗)<br />? ??<br />=<br />? ?<br />≈ τ−1ID+1<br />?(y∗)T(y∗)?<br />(y∗)T(y∗)p(y∗|x∗,ω)dy∗<br />=<br />?<br />q(ω)dω<br />? ?<br />Covp(y∗|x∗,ω)(y∗) + Ep(y∗|x∗,ω)(y∗)TEp(y∗|x∗,ω)(y∗)<br />?<br />q(ω)dω<br />=<br />τ−1ID+ ? y∗(x∗,b1,...,bL)T? y∗(x∗,b1,...,bL)<br />T<br />t=1<br />since p(y∗|x∗,ω) = N?y∗;? y∗(x∗,b1,...,bL),τ−1ID<br />?<br />Bern(b1)···Bern(bL)db1···dbL<br />T<br />?<br />? y∗(x∗,?b1,t,...,?bL,t)T? y∗(x∗,?b1,t,...,?bL,t)<br />?.<br />17</p>   </div> <div id="rgw19_56ab9d59139cf" class="c-box pub-resource-container js-toggle" style=""> <h4 class="lf js-expand-list"><small><a href="javascript:" class="lf">View other sources <span class="ico-expand-list"></span></a></small></h4> <h4 class="lf js-collapse-list hidden"><small><a href="javascript:" class="lf">Hide other sources <span class="ico-collapse-list"></span></a></small></h4> <div class="clear"></div> <div class="scroll-wrapper hidden"> <ul class="files-list c-list" id="rgw20_56ab9d59139cf">  <li class="c-list-item pub-resource-item"  data-type="fulltext" id="rgw21_56ab9d59139cf"> <span class="ico-pub"></span> <div class="file-content"> <div class="download"> <a href="http://de.arxiv.org/pdf/1506.02157" target="_blank" rel="nofollow" class="publication-viewer" title="Dropout as a Bayesian Approximation: Appendix">Dropout as a Bayesian Approximation: Appendix</a> </div>  <div class="details">   Available from <a href="http://de.arxiv.org/pdf/1506.02157" target="_blank" rel="nofollow">de.arxiv.org</a>  </div>    </div> </li>  </ul> </div> </div> </noscript> <div class="clearfix"> <div class="action-container">  </div> <div class="pub-legal"> Data provided are for informational purposes only. Although carefully collected, accuracy cannot be guaranteed. The impact factor represents a rough estimation of the journal's impact factor and does not reflect the actual current impact factor. Publisher conditions are provided by RoMEO. Differing provisions from the publisher's actual policy or licence agreement may be applicable. </div>  <div id="rgw28_56ab9d59139cf" class="citations-container"> <div class="tab-container"> <ul class="tab-list"> <li class="lf tab-item tab-item-active js-citations"> <a href="javascript:void(0);" class="tab-link"> References  <small> (20)  </small> </a> </li>   <li class="lf tab-item"> <div class="tab-link tab-link-disabled js-cited-in-tooltip"> Cited In <small>(0)</small></div> </li>   <li class="rf"> <div class="dropdown js-citations-sorter dropdown-right-align" style="position: relative; bottom: -1px;"> <a href="javascript:void(0);" class="dropdown-toggle"> Sorted by: <strong class="js-current-sorting"> Order of availability  </strong> <span class="caret"></span> </a> <ul class="dropdown-menu"> <li><a href="javascript:void(0);" data-sort="normal">Order of availability</a></li> <li><a href="javascript:void(0);" data-sort="original">Appearance in publication</a></li> </ul> </div> </li>  </ul> <div class="tab-section tab-section-active js-citations-list-container"> <div id="rgw29_56ab9d59139cf" class="pub-citations-list">   <div class="publication-detail-sidebar-empty">This research doesn't cite any other publications.</div>   <a class="show-more-rebranded js-show-more rf text-gray-lighter">Show more</a> <div class="ajax-loading-small list-loading" style="display: none;"></div>  <div class="clearfix"></div> </div> </div> </div> </div> </div> </div> <div class="clearfix">     <div id="rgw23_56ab9d59139cf" class="c-box pub-resource-container js-toggle" style="display: none;"> <h4 class="lf js-expand-list"><small><a href="javascript:" class="lf">View other sources <span class="ico-expand-list"></span></a></small></h4> <h4 class="lf js-collapse-list hidden"><small><a href="javascript:" class="lf">Hide other sources <span class="ico-collapse-list"></span></a></small></h4> <div class="clear"></div> <div class="scroll-wrapper hidden"> <ul class="files-list c-list" id="rgw24_56ab9d59139cf">  </ul> </div> </div>   <div id="rgw15_56ab9d59139cf" class="similar-publications"> <h2>Similar Publications</h2> <ul class="list-bordered">  <li class="c-list-item li-publication-teaser" id="rgw16_56ab9d59139cf"> <div> <h5> <a href="publication/287360760_A_dynamic_probabilistic_material_flow_modeling_method" class="color-inherit ga-similar-publication-title"><span class="publication-title">A dynamic probabilistic material flow modeling method</span></a>  </h5>  <div class="authors"> <a href="researcher/2079085366_Nikolaus_A_Bornhoeft" class="authors ga-similar-publication-author">Nikolaus A. Bornhöft</a>, <a href="researcher/2036275420_Tian_Yin_Sun" class="authors ga-similar-publication-author">Tian Yin Sun</a>, <a href="researcher/15779033_Lorenz_M_Hilty" class="authors ga-similar-publication-author">Lorenz M. Hilty</a>, <a href="researcher/9515257_Bernd_Nowack" class="authors ga-similar-publication-author">Bernd Nowack</a>  </div>  </div> <div class="clear"></div> </li>  <li class="c-list-item li-publication-teaser" id="rgw17_56ab9d59139cf"> <div> <h5> <a href="publication/291390951_Heuristic_use_of_perceptual_evidence_leads_to_dissociation_between_performance_and_metacognitive_sensitivity" class="color-inherit ga-similar-publication-title"><span class="publication-title">Heuristic use of perceptual evidence leads to dissociation between performance and metacognitive sensitivity</span></a>  </h5>  <div class="authors"> <a href="researcher/43025141_Brian_Maniscalco" class="authors ga-similar-publication-author">Brian Maniscalco</a>, <a href="researcher/59183383_Megan_A_K_Peters" class="authors ga-similar-publication-author">Megan A. K. Peters</a>, <a href="researcher/12540683_Hakwan_Lau" class="authors ga-similar-publication-author">Hakwan Lau</a>  </div>  </div> <div class="clear"></div> </li>  <li class="c-list-item li-publication-teaser" id="rgw18_56ab9d59139cf"> <div> <h5> <a href="publication/290263498_Modeling_Multivariate_Mixed-Response_Functional_Data" class="color-inherit ga-similar-publication-title"><span class="publication-title">Modeling Multivariate Mixed-Response Functional Data</span></a>  </h5>  <div class="authors"> <a href="researcher/2093660137_Beth_A_Tidemann-Miller" class="authors ga-similar-publication-author">Beth A. Tidemann-Miller</a>, <a href="researcher/2093651295_Brian_J_Reich" class="authors ga-similar-publication-author">Brian J. Reich</a>, <a href="researcher/2093781752_Ana-Maria_Staicu" class="authors ga-similar-publication-author">Ana-Maria Staicu</a>  </div>  </div> <div class="clear"></div> </li>  </ul> </div> </div> </div> </div> </div></div></div>
<div class="clear"></div><div id="rgw31_56ab9d59139cf" class="default-footer"> <div id="footer" class="clearfix"> <span class="footer-left"> &copy; 2008&dash;2016 researchgate.net. All rights reserved. </span> <span class="footer-right"> <a href="https://www.researchgate.net/about">About us</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="https://www.researchgate.net/contact">Contact us</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="careers">Careers</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="developers">Developers</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="blog" target="_blank">News</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="application.PrivacyPolicy.html">Privacy</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="application.TermsAndConditions.html">Terms</a> <span class="footer-link-separator" style="padding: 0 5px;">&nbsp;|&nbsp;</span> <a href="advertising?_ref=ft">Advertising</a> <span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="recruiters?_ref=ft">Recruiting</a> </span> </div>  </div></div>
<div id="rgw32_56ab9d59139cf">  <div class="header-wrapper-logged-out"> <div id="header"> <div class="header-content"> <a href="" class="g-l-logo"> <svg width="149" height="19"> <image xlink:href="https://c5.rgstatic.net/m/235107188705592/images/template/brand-header-logo.svg" src="https://c5.rgstatic.net/m/238113351022438/images/template/brand-header-logo.png" width="149" height="19"/> </svg> </a> <a href="" class="g-l-logo-ico"> <svg width="127" height="17" viewbox="0 0 127 22"> <image xlink:href="https://c5.rgstatic.net/m/235107188705592/images/template/brand-header-logo.svg" src="https://c5.rgstatic.net/m/238113351022438/images/template/brand-header-logo.png" width="127" height="17"/> </svg> </a> <div id="rgw33_56ab9d59139cf" class="header-login-wrapper js-header-login"> <div class="dropdown-right-align"> <div class="login-signup-container lf"> <a href="https://www.researchgate.net/signup.SignUp.html?ev=su_chnl_index&amp;hdrsu=1&amp;_sg=sgEQ8ccn7yXRp6gN0HsSDQ4z-lUa7AmKwAn9AXF5uC8rXhkJtjEFXhVGh4FutleE" class="dropdown-toggle lf">Join for free</a> </div> <div class="dropdown lf" style="height: 20px;"> <a href="https://www.researchgate.net/application.Login.html" class="js-login-url dropdown-toggle lf">Log in <span class="caret"></span></a> <div class="dropdown-menu"> <div class="header-login-form-wrapper"> <!--[if IE 6]><p class="box-warning" style="margin-bottom: 0;">Sorry, ResearchGate no longer supports the version of Internet Explorer you are using. <a href="http://whatbrowser.org/" rel="nofollow" target="_blank">Update your web browser</a> and then log in. </p><![endif]--> <form method="post" action="https://www.researchgate.net/application.Login.html" class="form-big header-login-form js-login-form" name="loginForm" id="headerLoginForm"> <input type="hidden" name="request_token" value="6zNJ0j59NvTEDty0Je5mvzjoAqJUR3vE1S35wo7dwxmXa+VsXT4L8vroNsIOekw//1jZne+kYOcKGuCIVv2g8MOUFJMHQsgQFStBrvrT9qRZHrpyUp0GOXpQGbQDbBGxUXOS+Zfb96ZWJLO8PISSY5V1N92n82zOdIcp0qAVN3COkck6Rn2lYT0bAjEk5oo+bMIny2iZjxLN9OA+3wuKnQuCpwP4FLca+BCaZINUB3eFIflnWSQMTTivVU/rY/lyXbtiqZswTxne+p7YpeQUngHQl+BEWyy+5k9UoCyJ5oI="/> <input type="hidden" name="urlAfterLogin" value="publication/277959103_Dropout_as_a_Bayesian_Approximation_Appendix?ev=auth_pub"/> <input type="hidden" name="invalidPasswordCount" value="0"/> <input type="hidden" name="headerLogin" value="yes"/> <label for="input-header-login">Email</label> <div class="login-input"> <div class="info-tip-wrapper"> <span class="ico-info js-info"></span> </div> <input type="email" value="" name="login" class="login js-login-input text" id="input-header-login" tabindex="1"/> </div> <div class="clear"></div> <label class="lf" for="input-header-password"> Password </label> <a class="rf forgot-password js-forgot-password" href="application.LostPassword.html">Forgot password?</a> <div class="clear"></div> <input type="password" value="" name="password" class="password js-password-input text" id="input-header-password" tabindex="2"/> <div class="clear"></div> <label class="remember-me" for="headerLoginCookie"> <input type="checkbox" checked="checked" value="yes" name="setLoginCookie" class="lf checkbox" id="headerLoginCookie" tabindex="3"/> Keep me logged in </label> <div class="clear"></div> <input value="Log in" name="loginSubmit" class="btn btn-promote btn-fullwidth btn-large allow-leave js-submit-button" type="submit" tabindex="4"/> </form> <div class="connectors"> <div class="text">or log in with</div> <div class="connector-actions"> <a href="connector/linkedin/" class="li-connect js-li-connect" data-redirect-url="cHVibGljYXRpb24vMjc3OTU5MTAzX0Ryb3BvdXRfYXNfYV9CYXllc2lhbl9BcHByb3hpbWF0aW9uX0FwcGVuZGl4P2V2PWF1dGhfcHVi"> <span class="icon ico-linkedin-round-grey"></span> <span class="icon ico-linkedin-round"></span> </a> <a href="connector/facebook/" class="fb-connect middle js-fb-connect" data-redirect-url="cHVibGljYXRpb24vMjc3OTU5MTAzX0Ryb3BvdXRfYXNfYV9CYXllc2lhbl9BcHByb3hpbWF0aW9uX0FwcGVuZGl4P2V2PWF1dGhfcHVi"> <span class="icon ico-facebook-round-grey"></span> <span class="icon ico-facebook-round"></span> </a> <a href="connector/google/" class="g-connect js-g-connect" data-redirect-url="cHVibGljYXRpb24vMjc3OTU5MTAzX0Ryb3BvdXRfYXNfYV9CYXllc2lhbl9BcHByb3hpbWF0aW9uX0FwcGVuZGl4P2V2PWF1dGhfcHVi"> <span class="icon ico-google-round-grey"></span> <span class="icon ico-google-round"></span> </a> </div> </div> </div> </div> </div> </div> </div> </div> </div> <script type="application/ld+json">
{ "@context" : "http://schema.org",
  "@type" : "Organization",
  "name" : "ResearchGate",
  "url" : "http://www.researchgate.net",
  "logo" : "http://www.researchgate.net/images/template/rg_logo_square_brand.png",
  "sameAs" : [ "https://www.facebook.com/ResearchGate",
    "https://twitter.com/ResearchGate",
    "https://plus.google.com/+researchgate",
    "https://www.linkedin.com/company/researchgate"] 
}
</script> </div> </div><div class="c-signup-bar" id="rgw34_56ab9d59139cf"> <div class="banner-contents">   <span class="message">ResearchGate is the professional network for scientists and researchers.</span> <a href="signup.SignUp.html?ev=su_banner" class="btn btn-large btn-promote">Join for free</a>  </div> </div></div>
<script>
rgConfig.backendTime = 737;
</script>
<script src="//c5.rgstatic.net/m/2277196935388619/javascript/lib/yui3/yui/yui-min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/21832295316281274/javascript/yuiLoaderConfig-min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/23178613132105398/javascript/vendor/babel-core/browser-polyfill.min.js" type="text/javascript"></script>
<script>
(function (){
if (typeof YRG === "undefined") {
var xmlHttpRequest = new XMLHttpRequest();
xmlHttpRequest.open("post", "go.Error.html");
xmlHttpRequest.setRequestHeader("Content-Type", "application/json");
xmlHttpRequest.setRequestHeader("Accept", "application/json"); var loadedScripts = "";
if (window.performance && window.performance.getEntriesByType) {
    var result = [];
    var resources = performance.getEntriesByType("resource");
    for (var i in resources) {
        if (resources.hasOwnProperty(i)) {
            result.push({
                name: resources[i].name,
                duration: resources[i].duration
            });
        }
    }
    loadedScripts += "&loadedScripts=" + encodeURIComponent(JSON.stringify(result));
}
if (typeof YUI === "undefined") {
    loadedScripts += "&yuiLoaded=false";
} else {
    loadedScripts += "&yuiLoaded=true";
}
xmlHttpRequest.send("Type=InformationException&message=" + encodeURIComponent("Error loading YUI") + loadedScripts);
}
})();
</script>
<script>if (typeof YRG !== 'undefined') { YRG.use('rg-base',function(Y){Y.applyConfig({ignore: ["css-rg","css-rg2","css-ie","css-modules-publicprofile"]});Y.use(["rg.core.pagespeed.Monitoring"],function(Y){(function(){Y.rg.createInitialWidget({"data":{"content":{"data":{"profileSmallHeader":{"data":{"profileBadge":{"data":{"profileUrl":"researcher\/2069013556_Yarin_Gal","fullname":"Yarin Gal","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2549355721578\/images\/template\/default\/profile\/profile_default_m.png","profileStats":[null,{"data":{"publicationCount":9,"widgetId":"rgw5_56ab9d59139cf"},"id":"rgw5_56ab9d59139cf","partials":[],"templateName":"publicliterature\/stubs\/PublicLiteratureAuthorPublicationCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicLiteratureAuthorPublicationCount.html?authorUid=2069013556","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"followerCount":1,"widgetId":"rgw6_56ab9d59139cf"},"id":"rgw6_56ab9d59139cf","partials":[],"templateName":"publicliterature\/stubs\/PublicLiteratureAuthorFollowerCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicLiteratureAuthorFollowerCount.html?authorUid=2069013556","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"widgetId":"rgw4_56ab9d59139cf"},"id":"rgw4_56ab9d59139cf","partials":[],"templateName":"publicprofile\/stubs\/ProfileBadge.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicLiteratureAuthorBadge.html?authorUid=2069013556","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw3_56ab9d59139cf"},"id":"rgw3_56ab9d59139cf","partials":[],"templateName":"publicprofile\/stubs\/ProfileSmallHeader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicprofile.ProfileSmallHeader.html?publicationUid=277959103","viewClass":null,"yuiModules":["css-modules-publicprofile"],"stylesheets":["modules\/publicprofile.css"],"_isYUI":true},"publication":{"data":{"publicationUid":277959103,"title":"Dropout as a Bayesian Approximation: Appendix","journalTitle":false,"journalDetailsTooltip":false,"affiliation":false,"type":"Article","details":{"journalInfos":{"journal":"","publicationDate":"06\/2015;","publicationDateRobot":"2015-06","article":""}},"source":{"sourceUrl":"http:\/\/arxiv.org\/abs\/1506.02157","sourceName":"arXiv"},"publicationActions":null,"publicationCoins":{"data":{"tags":[{"key":"ctx_ver","value":"Z39.88-2004"},{"key":"rft_val_fmt","value":"info:ofi\/fmt:kev:mtx:journal"},{"key":"rfr_id","value":"info:sid\/researchgate.net:researchgate"},{"key":"rft.atitle","value":"Dropout as a Bayesian Approximation: Appendix"},{"key":"rft.date","value":"2015"},{"key":"rft.au","value":"Yarin Gal,Zoubin Ghahramani"},{"key":"rft.genre","value":"article"}],"widgetId":"rgw8_56ab9d59139cf"},"id":"rgw8_56ab9d59139cf","partials":[],"templateName":"publicliterature\/stubs\/PublicationCoins.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationCoins.html?publicationUid=277959103","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationAuthors":{"data":{"publicationUid":277959103,"peopleItems":[{"data":{"authorUrl":"researcher\/2069013556_Yarin_Gal","authorNameOnPublication":"Yarin Gal","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg","imageSize":"s","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Yarin Gal","profile":{"professionalInstitution":{"professionalInstitutionName":false,"professionalInstitutionUrl":null}},"professionalInstitutionName":false,"professionalInstitutionUrl":null,"url":"researcher\/2069013556_Yarin_Gal","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":true,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":false,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"widgetId":"rgw11_56ab9d59139cf"},"id":"rgw11_56ab9d59139cf","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAuthorItem.html?entityId=2069013556&imageSize=l&enableAuthorInviteButton=0","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"largeTooltip":false,"useRebrandedImageStyle":null,"widgetId":"rgw10_56ab9d59139cf"},"id":"rgw10_56ab9d59139cf","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorItem.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorItem.html?authorUid=2069013556&authorNameOnPublication=Yarin%20Gal","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true},{"data":{"authorUrl":"researcher\/8159937_Zoubin_Ghahramani","authorNameOnPublication":"Zoubin Ghahramani","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg","imageSize":"s","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Zoubin Ghahramani","profile":{"professionalInstitution":{"professionalInstitutionName":false,"professionalInstitutionUrl":null}},"professionalInstitutionName":false,"professionalInstitutionUrl":null,"url":"researcher\/8159937_Zoubin_Ghahramani","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":true,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":false,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"widgetId":"rgw13_56ab9d59139cf"},"id":"rgw13_56ab9d59139cf","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAuthorItem.html?entityId=8159937&imageSize=l&enableAuthorInviteButton=0","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"largeTooltip":false,"useRebrandedImageStyle":null,"widgetId":"rgw12_56ab9d59139cf"},"id":"rgw12_56ab9d59139cf","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorItem.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorItem.html?authorUid=8159937&authorNameOnPublication=Zoubin%20Ghahramani","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true}],"hasMore":false,"nextOffset":6,"useRebrandedImageStyle":null,"widgetId":"rgw9_56ab9d59139cf"},"id":"rgw9_56ab9d59139cf","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorList.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorList.html?publicationUid=277959103&context=pubdetail_authors_xflw&showContactAuthorButton=1","viewClass":"views.publicliterature.PublicationDetailAuthorListView","yuiModules":["rg.views.publicliterature.PublicationDetailAuthorListView"],"stylesheets":[],"_isYUI":true},"publicationAbstract":{"data":{"publicationUid":277959103,"abstract":"<noscript><\/noscript><div>We show that a multilayer perceptron (MLP) with arbitrary depth and<br \/>\nnonlinearities, with dropout applied after every weight layer, is<br \/>\nmathematically equivalent to an approximation to a well known Bayesian model.<br \/>\nThis interpretation offers an explanation to some of dropout's key properties,<br \/>\nsuch as its robustness to over-fitting. Our interpretation allows us to reason<br \/>\nabout uncertainty in deep learning, and allows the introduction of the Bayesian<br \/>\nmachinery into existing deep learning frameworks in a principled way.<br \/>\nThis document is an appendix for the main paper &quot;Dropout as a Bayesian<br \/>\nApproximation: Representing Model Uncertainty in Deep Learning&quot; by Gal and<br \/>\nGhahramani, 2015.<\/div>","canEdit":false,"isAdmin":false,"isArtifact":false,"showFullAbstract":true,"widgetId":"rgw14_56ab9d59139cf"},"id":"rgw14_56ab9d59139cf","partials":[],"templateName":"publicliterature\/stubs\/PublicationAbstract.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationAbstract.html?publicationUid=277959103","viewClass":"views.publicliterature.PublicationAbstractView","yuiModules":["rg.views.publicliterature.PublicationAbstractView"],"stylesheets":[],"_isYUI":true},"publicationKeywords":null,"publicationState":null,"isGuest":true,"isAdminEditingAllowed":false,"isArtifact":false,"figureListWidget":null,"previewImage":"https:\/\/i1.rgstatic.net\/publication\/277959103_Dropout_as_a_Bayesian_Approximation_Appendix\/links\/557f87e008aeb61eae261b76\/smallpreview.png","nativeAdDisclosure":null,"showFollowPublicationButton":false,"followPublicationPromo":"","widgetId":"rgw7_56ab9d59139cf"},"id":"rgw7_56ab9d59139cf","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailItem.html","templateExtensions":["generalHelpers"],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailItem.html?publicationUid=277959103&showActionBar=0&showContactAuthorButton=1&showRequestFulltextExperience=0&showNoRgAuthorsRequestFulltextExperience=0&showFollowPublicationPromo=0","viewClass":"views.publicliterature.PublicationDetailItemView","yuiModules":["rg.views.publicliterature.PublicationDetailItemView"],"stylesheets":[],"_isYUI":true},"similarPublications":{"data":{"publicationListItems":[{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":2079085366,"url":"researcher\/2079085366_Nikolaus_A_Bornhoeft","fullname":"Nikolaus A. Bornh\u00f6ft","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2036275420,"url":"researcher\/2036275420_Tian_Yin_Sun","fullname":"Tian Yin Sun","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":15779033,"url":"researcher\/15779033_Lorenz_M_Hilty","fullname":"Lorenz M. Hilty","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":9515257,"url":"researcher\/9515257_Bernd_Nowack","fullname":"Bernd Nowack","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Feb 2016","journal":"Environmental Modelling and Software","showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/287360760_A_dynamic_probabilistic_material_flow_modeling_method","usePlainButton":true,"publicationUid":287360760,"feedStubs":null,"hasFeedStubs":false,"impactPoints":"4.42","url":"publication\/287360760_A_dynamic_probabilistic_material_flow_modeling_method","title":"A dynamic probabilistic material flow modeling method","displayTitleAsLink":true,"authors":[{"id":2079085366,"url":"researcher\/2079085366_Nikolaus_A_Bornhoeft","fullname":"Nikolaus A. Bornh\u00f6ft","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2036275420,"url":"researcher\/2036275420_Tian_Yin_Sun","fullname":"Tian Yin Sun","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":15779033,"url":"researcher\/15779033_Lorenz_M_Hilty","fullname":"Lorenz M. Hilty","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":9515257,"url":"researcher\/9515257_Bernd_Nowack","fullname":"Bernd Nowack","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["Environmental Modelling and Software 02\/2016; 76:69-80. DOI:10.1016\/j.envsoft.2015.11.012"],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/287360760_A_dynamic_probabilistic_material_flow_modeling_method","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/287360760_A_dynamic_probabilistic_material_flow_modeling_method\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw16_56ab9d59139cf"},"id":"rgw16_56ab9d59139cf","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=287360760","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":43025141,"url":"researcher\/43025141_Brian_Maniscalco","fullname":"Brian Maniscalco","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":59183383,"url":"researcher\/59183383_Megan_A_K_Peters","fullname":"Megan A. K. Peters","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":12540683,"url":"researcher\/12540683_Hakwan_Lau","fullname":"Hakwan Lau","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Jan 2016","journal":"Attention Perception & Psychophysics","showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/291390951_Heuristic_use_of_perceptual_evidence_leads_to_dissociation_between_performance_and_metacognitive_sensitivity","usePlainButton":true,"publicationUid":291390951,"feedStubs":null,"hasFeedStubs":false,"impactPoints":"2.17","url":"publication\/291390951_Heuristic_use_of_perceptual_evidence_leads_to_dissociation_between_performance_and_metacognitive_sensitivity","title":"Heuristic use of perceptual evidence leads to dissociation between performance and metacognitive sensitivity","displayTitleAsLink":true,"authors":[{"id":43025141,"url":"researcher\/43025141_Brian_Maniscalco","fullname":"Brian Maniscalco","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":59183383,"url":"researcher\/59183383_Megan_A_K_Peters","fullname":"Megan A. K. Peters","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":12540683,"url":"researcher\/12540683_Hakwan_Lau","fullname":"Hakwan Lau","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["Attention Perception & Psychophysics 01\/2016;  DOI:10.3758\/s13414-016-1059-x"],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/291390951_Heuristic_use_of_perceptual_evidence_leads_to_dissociation_between_performance_and_metacognitive_sensitivity","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/291390951_Heuristic_use_of_perceptual_evidence_leads_to_dissociation_between_performance_and_metacognitive_sensitivity\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw17_56ab9d59139cf"},"id":"rgw17_56ab9d59139cf","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=291390951","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":2093660137,"url":"researcher\/2093660137_Beth_A_Tidemann-Miller","fullname":"Beth A. Tidemann-Miller","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2093651295,"url":"researcher\/2093651295_Brian_J_Reich","fullname":"Brian J. Reich","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2093781752,"url":"researcher\/2093781752_Ana-Maria_Staicu","fullname":"Ana-Maria Staicu","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Jan 2016","journal":null,"showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/290263498_Modeling_Multivariate_Mixed-Response_Functional_Data","usePlainButton":true,"publicationUid":290263498,"feedStubs":null,"hasFeedStubs":false,"impactPoints":false,"url":"publication\/290263498_Modeling_Multivariate_Mixed-Response_Functional_Data","title":"Modeling Multivariate Mixed-Response Functional Data","displayTitleAsLink":true,"authors":[{"id":2093660137,"url":"researcher\/2093660137_Beth_A_Tidemann-Miller","fullname":"Beth A. Tidemann-Miller","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2093651295,"url":"researcher\/2093651295_Brian_J_Reich","fullname":"Brian J. Reich","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2093781752,"url":"researcher\/2093781752_Ana-Maria_Staicu","fullname":"Ana-Maria Staicu","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":[],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/290263498_Modeling_Multivariate_Mixed-Response_Functional_Data","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/290263498_Modeling_Multivariate_Mixed-Response_Functional_Data\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw18_56ab9d59139cf"},"id":"rgw18_56ab9d59139cf","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=290263498","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"viewClass":"sidebar","widgetId":"rgw15_56ab9d59139cf"},"id":"rgw15_56ab9d59139cf","partials":[],"templateName":"publicliterature\/stubs\/SimilarPublications.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.SimilarPublications.html?referencePublicationId=277959103&view=sidebar","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationFulltextPreview":null,"publicationResourcesFulltext":{"data":{"publicationUid":277959103,"publicationResourceList":{"data":{"publicationResourceItems":[{"data":{"publicationUid":277959103,"publicationType":"article","linkId":"557f87e008aeb61eae261b76","fileName":"Dropout as a Bayesian Approximation: Appendix","fileUrl":"http:\/\/de.arxiv.org\/pdf\/1506.02157","name":"de.arxiv.org","nameUrl":"http:\/\/de.arxiv.org\/pdf\/1506.02157","canRemove":false,"fileIcon":"ico-pub","canPreview":true,"hasPublisherLink":null,"hasMetaData":true,"hide":false,"fulltext":"ico-pub","origin":"publication_list","isLastLink":true,"isUserLink":false,"widgetId":"rgw21_56ab9d59139cf"},"id":"rgw21_56ab9d59139cf","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceItem.html","templateExtensions":["generalHelpers"],"attrs":{"fileRequiredPublicationTypes":["code","coverPage","experimentFindings","method","negativeResults","presentation","rawData","researchProposal","workingPaper","artifact","dataset"]},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceItem.html?publicationUid=277959103&linkId=557f87e008aeb61eae261b76&hide=0&disableJavascript=disableJavascript&useAlternativeTemplate=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"widgetId":"rgw20_56ab9d59139cf"},"id":"rgw20_56ab9d59139cf","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceList.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceList.html?publicationUid=277959103&limit=3&disableJavascript=disableJavascript&type=fulltextFile","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"resourceCount":1,"hidden":false,"showMore":false,"fulltext":true,"publicationDownloadCount":{"data":{"value":5,"valueFormatted":"5","widgetId":"rgw22_56ab9d59139cf"},"id":"rgw22_56ab9d59139cf","partials":[],"templateName":"publicliterature\/stubs\/PublicationDownloadCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDownloadCount.html?publicationUid=277959103","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw19_56ab9d59139cf"},"id":"rgw19_56ab9d59139cf","partials":[],"templateName":"publicliterature\/stubs\/PublicationResources.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResources.html?publicationUid=277959103&type=fulltextFile&disableJavascript=1","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationResourcesAttachments":{"data":{"publicationUid":277959103,"publicationResourceList":{"data":{"publicationResourceItems":[],"widgetId":"rgw24_56ab9d59139cf"},"id":"rgw24_56ab9d59139cf","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceList.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceList.html?publicationUid=277959103&limit=3&disableJavascript=disableJavascript&type=attachmentFile","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"resourceCount":0,"hidden":true,"showMore":false,"fulltext":false,"publicationDownloadCount":{"data":{"value":5,"valueFormatted":"5","widgetId":"rgw25_56ab9d59139cf"},"id":"rgw25_56ab9d59139cf","partials":[],"templateName":"publicliterature\/stubs\/PublicationDownloadCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDownloadCount.html?publicationUid=277959103","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw23_56ab9d59139cf"},"id":"rgw23_56ab9d59139cf","partials":[],"templateName":"publicliterature\/stubs\/PublicationResources.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResources.html?publicationUid=277959103&type=attachmentFile","viewClass":"views.publicliterature.PublicationResourcesView","yuiModules":["rg.views.publicliterature.PublicationResourcesView"],"stylesheets":[],"_isYUI":true},"publicationText":{"data":{"hide":false,"pages":[{"page":1,"text":"arXiv:1506.02157v1  [stat.ML]  6 Jun 2015\nDropout as a Bayesian Approximation:\nAppendix\nYarin Gal\nUniversity of Cambridge\n{yg279,zg201}@cam.ac.uk\nZoubin Ghahramani\nAbstract\nWe show that a multilayer perceptron (MLP) with arbitrary depth and non-\nlinearities, with dropoutapplied after every weight layer, is mathematicallyequiv-\nalent to an approximation to a well known Bayesian model. This interpretation\noffers an explanation to some of dropout\u2019s key properties, such as its robustness\nto over-fitting. Our interpretation allows us to reason about uncertainty in deep\nlearning,andallows the introductionof the Bayesian machineryinto existingdeep\nlearning frameworks in a principled way.\nThis documentis an appendixfor the main paper \u201cDropoutas a Bayesian Approx-\nimation: Representing Model Uncertainty in Deep Learning\u201d by Gal and Ghahra-\nmani, 2015.\n1Introduction\nDeep learning works very well in practice for many tasks, ranging from image processing\n[Krizhevsky et al., 2012] to language modelling [Bengio et al., 2006]. However the framework has\nsome major limitations as well. Our inability to reason about uncertainty over the features is an\nexample of such. The features extracted from a dataset are often given as point estimates. These do\nnot allow us to capture how much the model is confident in its estimation. On the other hand, proba-\nbilistic Bayesian models such as the Gaussian process [Rasmussen and Williams, 2006] offer us the\nability to reason about our confidence. But these often come with a price of lessened performance.\nAnother major obstacle with deep learning techniques is over-fitting. This problem has been largely\nansweredwiththeintroductionofdropout[Hinton et al., 2012;Srivastava et al., 2014]. Indeedmany\nmodern models use dropout to avoid over-fitting in practice. Over the last several years many have\ntried to explain why dropout helps in avoiding over-fitting, a property which is not often observed\nin Bayesian models. Papers such as [Wager et al., 2013; Baldi and Sadowski, 2013] have suggested\nthat dropout performs stochastic gradient descent on a regularised error function, or is equivalent to\nan L2regulariser applied after scaling the features by some estimate.\nHere we show that a multilayer perceptron (MLP) with arbitrary depth and non-linearities, with\ndropout applied after every weight layer, is mathematically equivalent to an approximation to the\nprobabilisticdeepGaussianprocessmodel[Damianou and Lawrence,2013]. We wouldliketostress\nthat no simplifying assumptions are made on the use of dropout in the literature, and that the results\nderived are applicable to any network architecture that makes use of dropout exactly as it appears in\npracticalapplications. We showthatthedropoutobjective,ineffect,minimisestheKullback\u2013Leibler\ndivergence between an approximate model and the deep Gaussian process.\nWe survey possible applications of this new interpretation, and discuss insights shedding light on\ndropout\u2019s properties. This interpretation of dropout as a Bayesian model offers an explanation to\nsome of its properties, such as its ability to avoid over-fitting. Further, our insights allow us to treat\nMLPs withdropoutasfullyBayesianmodels,andobtainuncertaintyestimates overtheirfeatures. In\npractice, this allows the introductionof Bayesian machinery into existing deep learning frameworks\n1"},{"page":2,"text":"in a principled way. Lastly, our analysis suggests straightforward generalisations of dropout for\nfuture research which should improve on current techniques.\nThe work presentedhere is an extensivetheoretical treatment of the above, with applicationsstudied\nseparately.\n2Background\nWe review dropout, and survey the Gaussian process model1and approximate variational inference\nquickly. These tools will be used in the following section to derive the main results of this work. We\nuse the following notation throughout the paper. Bold lower case letters denote vectors, bold upper\ncase letters denote matrices, and standard weight letters denote scalar quantities. We use subscripts\nto denote either entire rows \/ columns (with bold letters), or specific elements. We use subscripts to\ndenotevariablesas well (suchas W1: Q\u00d7K,W2: K\u00d7D), with correspondinglowercase indices\nto refer to specific rows \/ columns (wq,wkfor the first variable and wk,wdfor the second). We use\na second subscript to denote the element index of a specific variable: w1,qkdenotes the element at\nrow q column k of the variable W1.\n2.1Dropout\nWe review the dropout MLP model [Hinton et al., 2012; Srivastava et al., 2014] quickly for the case\nof a single hidden layer MLP. This is done for ease of notation, and generalisationto multiple layers\nis straightforward. Denote by W1,W2the weight matrices connecting the first layer to the hidden\nlayer and connecting the hidden layer to the output layer respectively. These linearly transforming\nthe layers\u2019 inputs before applying some element-wise non-linearity \u03c3(\u00b7). Denote by b the biases\nby which we shift the input of the non-linearity. We assume the model to output D dimensional\nvectors while its input is Q dimensional vectors, with K hidden units. Thus W1is a Q\u00d7K matrix,\nW2is a K \u00d7 D matrix, and b is a K dimensional vector. A standard MLP model would output\n? y = \u03c3(xW1+ b)W2given some input x.2\nelements of the vectors are distributed according to a Bernoulli distribution with some parameter\npi \u2208 [0,1] for i = 1,2. Thus b1,q \u223c Bernoulli(p1) for q = 1,...,Q, and b2,k \u223c Bernoulli(p2)\nfor k = 1,...,K. Given an input x, 1 \u2212 p1 proportion of the elements of the input are set to\nzero: x \u25e6 b1where \u25e6 signifies the Hadamard product. The output of the first layer is given by\n\u03c3((x \u25e6 b1)W1+ b) \u25e6 b2, which is linearly transformed to give the dropout model\u2019s output ? y =\n? y = \u03c3(x(b1W1) + b)(b2W2).\nwe mean diag(b1) with the diag(\u00b7) operator mapping a vector to a diagonal matrix whose diagonal\nis the elements of the vector.\nDropout is applied by sampling two binary vectors b1,b2of dimensions Q and K respectively. The\n?(\u03c3((x\u25e6b1)W1+b))\u25e6b2\n?W2. This is equivalent to multiplyingthe weight matrices by the binary\nvectors to zero out entire rows:\nThe process is repeated for multiple layers. Note that to keep notation clean we will write b1when\nTo use the MLP model for regression we might use the euclidean loss,\nE =\n1\n2N\nN\n?\nn=1\n||yn\u2212 ? yn||2\n2\n(1)\nwhere{y1,...,yN} are N observedoutputs,and{? y1,...,? yN} beingtheoutputsof the modelwith\nTo use the model for classification, predicting the probability of x being classified as 1,...,D, we\npass the output of the model ? y through an element-wise softmax function to obtain normalised\nE = \u22121\nN\nn=1\nwhere cn\u2208 [1,2,...,D] is the observed class of input n.\ncorresponding observed inputs {x1,...,xN}.\nscores: \u02c6 pnd= exp(? ynd)\/(?\nd\u2032exp(? ynd\u2032)). Taking the log of this function results in a softmax loss,\nlog(\u02c6 pn,cn)\nN\n?\n(2)\n1For a full treatment of Gaussian Processes, see Rasmussen and Williams [2006].\n2Note that we omit the outer-most bias term as this is equivalent to centring the output.\n2"},{"page":3,"text":"During optimisation, this term is scaled by the learning rate r1and a regularisation term is added.\nWe often use L2regularisation weighted by some weight decay r2(alternatively, the derivatives\nmight be scaled), resulting in a minimisation objective (often referred to as cost),\nLdropout:= r1E + r2\nWe sample new realisations for the binary vectors bifor every input point and every forward pass\nthorough the model (evaluating the model\u2019s output), and use the same values in the backward pass\n(propagating the derivatives to the parameters).\n?||W1||2\n2+ ||W2||2\n2+ ||b||2\n2\n?.\n(3)\nThe dropped weights b1W1and b2W2are often scaled by\ntude. At test time no sampling takes place. This is equivalent to initialising the weights Wiwith\nscale\nthat the probabilities pican be optimised.\nWe will show that equations (1) to (3) arise in Gaussian process approximation as well. Next we\nintroduce the Gaussian process model.\n1\npito maintain constant output magni-\n1\npiwith no further scaling at training time, and at test time scaling the weights Wiby pi. Note\n2.2Gaussian Processes\nThe Gaussian process (GP) is a powerful tool in statistics that allows us to model distributions over\nfunctions. It has been applied in both the supervised and unsupervised domains, for both regres-\nsionandclassificationtasks[Rasmussen and Williams,2006;Titsias and Lawrence,2010;Gal et al.,\n2015]. The Gaussian process offers desirable properties such as uncertainty estimates over the func-\ntion values, robustness to over-fitting, and principled ways for hyper-parameter tuning. The use of\napproximate variational inference for the model allows us to scale it to large data via stochastic and\ndistributed inference [Hensman et al., 2013; Gal et al., 2014].\nGiven a training dataset consisting of N inputs {x1,...,xN} and their corresponding outputs\n{y1,...,yN}, we would like to estimate a function y = f(x) that is likely to have generated\nour observations. We denote the inputs X \u2208 RN\u00d7Qand the outputs Y \u2208 RN\u00d7D.\nWhat is a function that is likely to have generated our data? Following the Bayesian approach we\nwould put some prior distribution over the space of functions p(f). This distribution represents\nour prior belief as to which functions are more likely and which are less likely to have generated\nour data. We then look for the posterior distribution over the space of functions given our dataset\n(X,Y):\np(f|X,Y) \u221d p(Y|X,f)p(f).\nThis distribution captures the most likely functions given our observed data.\nBy modelling our distribution over the space of functions with a Gaussian process we can analyti-\ncally evaluate its corresponding posterior in regression tasks, and estimate the posterior in classifi-\ncation tasks. In practice what this means is that for regression we place a joint Gaussian distribution\nover all function values,\nF | X \u223c N(0,K(X,X))\nY | F \u223c N(F,\u03c4\u22121IN)\nwith some precisionhyper-parameter\u03c4 and where INis the identity matrix with dimensions N \u00d7N.\nFor classification we sample from a categorical distribution with probabilities given by passing \u03c4Y\nthrough an element-wise softmax,\nF | X \u223c N(0,K(X,X))\nY | F \u223c N(F,0 \u00b7 IN)\n?\nfor n = 1,...,N with observed class label cn. Note that we did not simply write Y = F because of\nnotational convenience that will allow us to treat regression and classification together.\n(4)\n(5)\ncn| Y \u223c Categorical\nexp(\u03c4ynd)\/\n??\nd\u2032\nexp(\u03c4ynd\u2032)\n??\nTo model the data we have to choose a covariance function K(X,Y) for the Gaussian distribution.\nThis function defines the (scalar) similarity between every pair of input points K(xi,xj). Given a\nfinite dataset of size N this function induces an N \u00d7 N covariance matrix which we will denote\nK := K(X,X). For example we may choose a stationary squared exponential covariance function.\n3"},{"page":4,"text":"We will see below that certain non-stationary covariance functions correspond to TanH (hyperbolic\ntangent) or ReLU (rectified linear) MLPs.\nEvaluating the Gaussian distribution above involves an inversion of an N by N matrix, an operation\nthat requires O(N3) time complexity. Many approximations to the Gaussian process result in a\nmanageabletime complexity. Variational inference can be used for such, and will be explained next.\n2.3 Variational Inference\nTo approximate the model above we could condition the model on a finite set of random variables\n\u03c9. We make a modelling assumption and assume that the model depends on these variables alone,\nmaking them into sufficient statistics in our approximate model.\nThe predictive distribution for a new input point x\u2217is then given by\np(y\u2217|x\u2217,X,Y) =\n?\np(y\u2217|x\u2217,\u03c9)p(\u03c9|X,Y) d\u03c9,\nwith y\u2217\u2208 RD. The distribution p(\u03c9|X,Y) cannot usually be evaluated analytically. Instead we\ndefine an approximating variational distribution q(\u03c9), whose structure is easy to evaluate.\nWe would like our approximating distribution to be as close as possible to the posterior distribution\nobtained from the full Gaussian process. We thus minimise the Kullback\u2013Leibler (KL) divergence,\nintuitively a measure of similarity between two distributions:\nKL(q(\u03c9) | p(\u03c9|X,Y)),\nresulting in the approximate predictive distribution\n?\nMinimising the Kullback\u2013Leibler divergence is equivalent to maximising the log evidence lower\nbound [Bishop, 2006],\n?\nwith respect to the variational parameters defining q(\u03c9). Note that the KL divergence in the last\nequation is between the approximate posterior and the prior over \u03c9. Maximising this objective\nwill result in a variational distribution q(\u03c9) that explains the data well (as obtained from the first\nterm\u2014the likelihood) while still being close to prior\u2014preventing the model from over-fitting.\nq(y\u2217|x\u2217) =p(y\u2217|x\u2217,\u03c9)q(\u03c9)d\u03c9.\n(6)\nLVI:=q(\u03c9)logp(Y|X,\u03c9)d\u03c9 \u2212 KL(q(\u03c9)||p(\u03c9))\n(7)\nWe next present a variational approximation to the Gaussian process extending on [Gal and Turner,\n2015], which results in a model mathematically identical to the use of dropout in arbitrarily struc-\ntured MLPs with arbitrary non-linearities.\n3 Dropout as a Bayesian Approximation\nWe show that MLPs with dropout applied after every weight layer are mathematically equivalent\nto approximate variational inference in the deep Gaussian process. For this we build on previous\nwork [Gal and Turner, 2015] that applied variational inference in the sparse spectrum Gaussian\nprocess approximation [L\u00b4 azaro-Gredilla et al., 2010]. Starting with the full Gaussian process we\nwill developan approximationthat will be shownto be equivalentto the MLP optimisationobjective\nwith dropout(eq.(3)) with either the euclideanloss (eq.(1)) in the case of regressionor softmax loss\n(eq. (2)) in the case of classification. This view of dropout will allow us to derive new probabilistic\nresults in deep learning.\n3.1A Gaussian Process Approximation\nWebeginbydefiningourcovariancefunction. Let\u03c3 besomenon-linearfunctionsuchastherectified\nlinear (ReLU) or the hyperbolic tangent function (TanH). We define K(x,y) to be\n?\nwith p(w) a standard multivariate normal distribution of dimensionality Q and some distribution\np(b). It is trivial to show that this defines a valid covariance function following [Tsuda et al., 2002].\nK(x,y) =p(w)p(b)\u03c3(wTx + b)\u03c3(wTy + b)dwdb\n4"},{"page":5,"text":"We use Monte Carlo integration with K terms to approximate the integral above. This results in\nK\n?\nwith wk\u223c p(w) and bk\u223c p(b). K will be the number of hidden units in our single hidden layer\nMLP approximation.\n?K(x,y) =\n1\nK\nk=1\n\u03c3(wT\nkx + bk)\u03c3(wT\nky + bk)\nUsing?K instead of K as the covariance function of the Gaussian process yields the following gen-\nwk\u223c p(w), bk\u223c p(b),\nW1= [wk]K\nerative model:\nk=1,b = [bk]K\n?\nk=1\n?K(x,y) =\nF | X,W1,b \u223c N(0,?K(X,X))\n1\nK\nK\nk=1\n\u03c3(wT\nkx + bk)\u03c3(wT\nky + bk)\nY | F \u223c N(F,\u03c4\u22121IN),\n(8)\nwith W1a Q \u00d7 K matrix.\nThis results in the following predictive distribution:\np(Y|X) =\n?\np(Y|F)p(F|W1,b,X)p(W1)p(b)\nwhere the integration is with respect to F,W1, and b.\nDenoting the 1 \u00d7 K row vector\n\u03c6(x,W1,b) =\n?\n1\nK\u03c3(WT\nn=1, we have?K(X,X) = \u03a6\u03a6T. We rewrite\nN(Y;0,\u03a6\u03a6T+ \u03c4\u22121IN)p(W1)p(b)dW1db,\n1x + b)\nand the N \u00d7 K feature matrix \u03a6 = [\u03c6(xn,W1,b)]N\np(Y|X) as\np(Y|X) =\n?\nanalytically integrating with respect to F.\nThe normal distribution of Y inside the integral above can be written as a joint normal distribution\nover yd, the d\u2019th columns of the N \u00d7 D matrix Y, for d = 1,...,D. For each term in the joint\ndistribution, following identity [Bishop, 2006, page 93], we introduce a K \u00d7 1 auxiliary random\nvariable wd\u223c N(0,IK),\n?\nWriting W2= [wd]D\n?\nwhere the integration is with respect to W1,W2, and b.\nWe have re-parametrised the GP model and introduced additional auxiliary random variables\nW1,W2, and b. We next approximate the posterior over these variables with appropriate approxi-\nmating variational distributions.\nN(yd;0,\u03a6\u03a6T+ \u03c4\u22121IN) =\nN(yd;\u03a6wd,\u03c4\u22121IN)N(wd;0,IK)dwd.\nd=1a K \u00d7 D matrix, the above is equivalent to3\np(Y|X) =p(Y|X,W1,W2,b)p(W1)p(W2)p(b)\n3.2Variational Inference in the Approximate Model\nOur sufficient statistics are W1,W2, and b. To perform variational inference in our approximate\nmodel we need to define a variationaldistribution q(W1,W2,b) := q(W1)q(W2)q(b). We define\n3This is equivalent\n[Rasmussen and Williams, 2006].\nto the weightedbasis function interpretationof the Gaussianprocess\n5"},{"page":6,"text":"q(W1) to be a Gaussian mixture distribution with two components, factorised over Q:4\nQ\n?\nq(wq) = p1N(mq,\u03c32IK) + (1 \u2212 p1)N(0,\u03c32IK)\nwith some probability p1 \u2208 [0,1], scalar \u03c3 > 0 and mq \u2208 RK. We put a similar approximating\ndistribution over W2:\nK\n?\nq(wk) = p2N(mk,\u03c32ID) + (1 \u2212 p2)N(0,\u03c32ID)\nwith some probability p2\u2208 [0,1].\nWe put a simple Gaussian approximating distribution over b:\nq(b) = N(m,\u03c32IK).\nq(W1) =\nq=1\nq(wq),\n(9)\nq(W2) =\nk=1\nq(wk),\n(10)\n(11)\nNext we evaluate the log evidence lower bound for the task of regression, for which we optimise\nover M1 = [mq]Q\ndiscussed later.\nq=1, M2 = [mk]K\nk=1, and m, to maximise Eq. (7). The task of classification is\n3.3Evaluating the Log Evidence Lower Bound for Regression\nWe need to evaluate the log evidence lower bound:\n?\nLGP-VI:=q(W1,W2,b)logp(Y|X,W1,W2,b) \u2212 KL(q(W1,W2,b)||p(W1,W2,b)),\n(12)\nwhere the integration is with respect to W1,W2, and b.\nWe re-parametrise the integrand to not depend on W1,W2, and b directly, but instead on the\nstandard normal distribution and the Bernoulli distribution. Let \u01eb1 \u223c N(0,IQ\u00d7K) and b1,q \u223c\nBernoulli(p1) for q = 1,...,Q, and \u01eb2\u223c N(0,IK\u00d7D) and b2,k\u223c Bernoulli(p2) for k = 1,...,K.\nFinally let \u01eb \u223c N(0,IK). We write\nW1= b1(M1+ \u03c3\u01eb1) + (1 \u2212 b1)\u03c3\u01eb1\nW2= b2(M2+ \u03c3\u01eb2) + (1 \u2212 b2)\u03c3\u01eb2\nb = m + \u03c3\u01eb,\nallowing us to re-write the integral in the above equation as\n?\n=q(b1,\u01eb1,b2,\u01eb2,\u01eb)logp(Y|X,W1(b1,\u01eb1),W2(b2,\u01eb2),b(\u01eb))d\u01eb1db1d\u01eb2db2d\u01eb.\n(13)\nq(W1,W2,b)logp(Y|X,W1,W2,b)dW1dW2db\n?\nWe estimate the integral using Monte Carlo integration with a single sample to obtain:\nLGP-MC:=logp(Y|X,?\n? \u01eb2\u223c N(0,IK\u00d7D), and?b2,k\u223c Bernoulli(p2). Following [Blei et al., 2012; Hoffman et al., 2013;\nFor the task of regression we have\n?\nW1,?\nW2,?b) \u2212 KL(q(W1,W2,b)||p(W1,W2,b))\nwith?\nKingma and Welling, 2013; Rezende et al., 2014; Titsias and L\u00b4 azaro-Gredilla, 2014], optimisingthe\nstochastic objective LGP-MCwe would converge to the same limit as LGP-VI.\nW1,?\nW2,?b defined following eq. (13) with ? \u01eb1 \u223c N(0,IQ\u00d7K),?b1,q \u223c Bernoulli(p1),\nlogp(Y|X,?\nW1,?\nW2,?b) =\nD\nd=1\nlogN(yd;\u03a6? wd,\u03c4\u22121IN)\n4Note that this is a bi-modal distribution defined over each output dimensionality; as a result the joint\ndistribution over W1is highly multi-modal.\n6"},{"page":7,"text":"= \u2212ND\n2\nlog(2\u03c0) +ND\n2\nlog(\u03c4) \u2212\nD\n?\nd=1\n\u03c4\n2||yd\u2212 \u03a6? wd||2\n2,\nas the output dimensions of a multi-outputGaussian process are assumed to be independent. Denote\n?Y = \u03a6W2. We can then sum over the rows instead of the columns of?Y and write\nd=1\nHere ? yn= \u03c6(xn,?\nanalytically. However we can perform Monte Carlo integration like in the above. A further approxi-\nmation for large K (numberof hiddenunits) and small \u03c32yields a weighted sum of KL divergences\nbetween the mixture components and the single Gaussian (proposition 1 in the appendix). Intu-\nitively, this is because the entropy of a mixture of Gaussians with a large enough dimensionality\nand randomly distributed means tends towards the sum of the Gaussians\u2019 volumes. Following the\nproposition, for large enough K we can approximate the KL divergence term as\nD\n?\n\u03c4\n2||yd\u2212 ? yd||2\n1\n2=\nN\n?\nn=1\n\u03c4\n2||yn\u2212 ? yn||2\nW2.\n2.\nW1,?b)?\nW2=\n?\nK\u03c3(xn?\nW1+?b)?\nWe can\u2019t evaluate the KL divergence term between a mixture of Gaussians and a single Gaussian\nKL(q(W1)||p(W1)) \u2248 QK(\u03c32\u2212 log(\u03c32) \u2212 1) +p1\n2\nQ\n?\nq=1\nmT\nqmq.\nand similarly for KL(q(W2)||p(W2)). The term KL(q(b)||p(b)) can be evaluated analytically as\nKL(q(b)||p(b)) =1\n2\nNext we explain the relation between the above equations and the equations brought in section 2.1.\n?mTm + K(\u03c32\u2212 log(\u03c32) \u2212 1)?.\n3.4 Log Evidence Lower Bound Optimisation\nIgnoring the constant terms \u03c4,\u03c3 we obtain the maximisation objective\nN\n?\nNote that in the Gaussian processes literature the terms \u03c4,\u03c3 will often be optimised as well.\nLGP-MC\u221d \u2212\u03c4\n2\nn=1\n||yn\u2212 ? yn||2\n2\u2212p1\n2||M1||2\n2\u2212p2\n2||M2||2\n2\u22121\n2||m||2\n2.\nLetting \u03c3 tend to zero, we get that the KL divergence blows-up and tends to infinity. However,\nin real-world scenarios setting \u03c3 to be machine epsilon (10\u221233for example in quadruple precision\ndecimal systems) results in a constant value log\u03c3 = \u221276. With high probability samples from a\nGaussian distribution with such a small standard deviation will be represented on a computer, in\neffect, as zero. Thus the random variable realisations?\nNote that?\n? yn\u2248\nScaling the optimisation objective by a positive constant \u03b3 doesn\u2019t change the parameter values at\nits optimum. We thus scale the objective to get\nN\n?\nand we recovered equation (1) for an appropriate setting of \u03b3 and model precision \u03c4. Maximising\neq. (14) results in the same optimal parameters as minimising eq. (3). Note that eq. (14) is a scaled\nunbiased estimator of eq. (12). With correct stochastic optimisation scheduling both will converge\nto the same limit.\nW1,?\nW2,?b can be approximated as\n?\nW1\u2248?b1M1, ?\n?\nW2\u2248?b2M2,?b \u2248 m.\nW1are not maximum a posteriori (MAP) estimates, but random variables realisations.\nThis gives us\n1\nK\u03c3(xn(?b1M1) + m)(?b2M2).\nLGP-MC\u221d \u2212\u03b3\u03c4\n2\nn=1\n||yn\u2212 ? yn||2\n2\u2212\u03b3p1\n2\n||M1||2\n2\u2212\u03b3p2\n2\n||M2||2\n2\u2212\u03b3\n2||m||2\n2\n(14)\nTheoptimisationofLGP-MCproceedsasfollows. We samplerealisations?b1,?b2toevaluatethelower-\ndescent step), and repeat, sampling new realisations.\nbound and its derivatives. We perform a single optimisation step (for example a single gradient\n7"},{"page":8,"text":"We can make several interesting observations at this point. First, as is commonly known, the ratio\nbetween the constant scaling the likelihood term in the dorpout objective (the first term, usually\nreferred to as the learning rate) and that of the regularisation terms (the rest of the terms, usually\nreferred to as the weight-decays) gives us the model precision:\nthat the weight-decayfor the dropped-outweights should be scaled by the probabilityof the weights\nto not be dropped. This might explain why doubling the learning rate of the bias during MLP opti-\nmisation works well in practice in dropout networks with p = 0.5. Lastly, it is known that setting\nthe dropout probability to zero (p1= p2= 1) results in a standard MLP. Following the derivation\nabove, this would result in delta function approximatingdistributions on the weights (replacing eqs.\n(9)-(11)). As was discussed in [L\u00b4 azaro-Gredilla et al., 2010] this leads to model over-fitting. Em-\npirically it seems that the Bernoulli approximating distribution is sufficient to considerably prevent\nover-fitting.\nr1\nr2=\n\u03b3\u03c4\/2\n\u03b3\/2= \u03c4. Second, it seems\nWe have presented the derivation for a single hidden layer MLP. An extension of the derivation to\nmultiple layers is given below.\n3.5 Evaluating the Log Evidence Lower Bound for Classification\nFor classification we have an additional step in the generative model in eq. (5) compared to eq.\n(4), sampling class assignment cngiven weight yn. We can write this generative model using the\nauxiliary random variables introduced in section 3.1 for the regression case by\n?\n=p(c|Y)\np(Y|X,W1,W2,b)p(W1,W2,b)dW1dW2db\np(c|X) =p(c|Y)p(Y|X)dY\n??\n?\n?\ndY\nwhere c is an N dimensional vector of categorical values. We can write the log evidence lower\nbound in this case as (proposition 2 in the appendix)\n?\n\u2212 KL(q(W1,W2,b)||p(W1,W2,b)).\nLGP-VI:=p(Y|X,W1,W2,b)q(W1,W2,b)logp(c|Y)dW1dW2dbdY\nWe can re-parametrise the integrand like in (13) to obtain\nW1= b1(M1+ \u03c3\u01eb1) + (1 \u2212 b1)\u03c3\u01eb1\nW2= b2(M2+ \u03c3\u01eb2) + (1 \u2212 b2)\u03c3\u01eb2\nb = m + \u03c3\u01eb,\n?\nyn=\n1\nK\u03c3(xnW1+ b)W2.\n(15)\nLike before, we estimate the integral using Monte Carlo integration with a single sample to obtain:\nLGP-MC:=logp(c|?Y(X,?\nN\n?\nand the second expression as before. Scaling the objective by a positive \u03b3 again, this results in the\nfollowing maximisation objective,\n? N\nn=1\nd\u2032\nidentical (up to a sign flip) to that of eqs. (2), (3) for appropriate selection of \u03b3 and \u03c4.\nW1,?\nW2,?b)) \u2212 KL(q(W1,W2,b)||p(W1,W2,b)).\n??\nWe evaluate the first expression as\nlogp(c|?Y) =\nn=1\n\u03c4? yncn\u2212 \u03c4 log\nd\u2032\nexp(? ynd\u2032)\n?\nLGP-MC\u221d \u03b3\u03c4\n?\n\u03c4? yncn\u2212 log\n??\nexp(? ynd\u2032)\n??\n\u2212\u03b3p1\n2\n||M1||2\n2\u2212\u03b3p2\n2\n||M2||2\n2\u2212\u03b3\n2||m||2\n2,\n3.6Going Deeper than a Single Hidden Layer\nWe will demonstrate how to extend the derivation above to two hidden layers for the case of regres-\nsion. Extension to further layers and classification is trivial.\n8"},{"page":9,"text":"We use the deep GP model \u2013 feeding the output of one GP to the covarianceof the next, much in the\nsame way the input is used in the covariance of the first GP. However, to match the dropout MLP\nmodel, we have to select a different a covariance function for the GPs following the first one. For\nclarity,we denotehereall quantitiesrelatedto the first GP with subscript1, andas a secondsubscript\ndenote the element index. So \u03c61,nkdenotes the element at row n column k of the variable \u03a61, and\n\u03c61,ndenotes row n of the same variable.\nWe next define the new covariancefunctionK2. Let \u03c32be some non-linearfunction,not necessarily\nthe same as the one used with the previous covariance function. We define K2(x,y) to be\n?\nwith some distribution p(b2).\nWe use Monte Carlo integration with K2terms to approximate the integral above. This results in\nK2\n?\nwith b2,k\u223c p(b2).\nK2(x,y) =p(b2)\u03c32(x + b2)\u03c32(y + b2)db2\n?K2(x,y) \u2248\n1\nK2\nk=1\n\u03c3(x + b2,k)\u03c3(y + b2,k)\nUsing?K2instead as the covariance function of the second Gaussian process yields the following\nw1,k\u223c p(w1), b1,k\u223c p(b1), b2,k\u223c p(b2)\nW1= [w1,k]K1\nwith W1a Q \u00d7 K1matrix, b1a K1dimensional vector, and b2a K2dimensional vector. Given\nthese variables, we define the covariance functions for the two GPs:\nK1\n?\n1\nK2\nk=1\ngenerative model. First, we sample the variables for all covariance functions:\nk=1,b1= [b1,k]K1\nk=1,b2= [b2,k]K2\nk=1\n?K1(x,y) =\n?K2(x,y) =\n1\nK1\nk=1\n?\n\u03c31(wT\n1,kx + b1,k)\u03c31(wT\n1,ky + b1,k)\nK2\n\u03c32(x + b2,k)\u03c32(y + b2,k)\nConditioned on these variables, we generate the model\u2019s output:\nF1| X,W1,b1\u223c N(0,?K1(X,X))\nF2| X,b2\u223c N(0,?K2(F1,F1))\nY | F2\u223c N(F2,\u03c4\u22121IN).\nWe introduce auxiliary random variables W2a K1\u00d7 K2matrix and W3a K2\u00d7 D matrix. The\ncolumns of each matrix distribute according to N(0,I).\nLike before, we write?K1(X,X) = \u03a61\u03a6T\n1with \u03a61an N \u00d7 K1matrix and?K2(X,X) = \u03a62\u03a6T\n1\nK1\u03c31(wT\n?\n2\nwith \u03a62an N \u00d7 K2matrix:\n\u03c61,nk=\n?\n1,kxn+ b1,k)\n\u03c62,nk=\n1\nK2\u03c32(f1,nk+ b2,k).\nWe can then write F1= \u03a61W2, since\nE(F1) = \u03a61E(W2) = 0\nand\nCov(F1) = E(F1FT\n1) = \u03a61E(W2WT\n?\n2)\u03a6T\n1= \u03a61\u03a6T\n1,\nand similarly for F2. Note that F1is an N \u00d7 K2matrix, and that F2is an N \u00d7 D matrix. Thus,\n1\nK2\u03c32(wT\n\u03c62,nk=\n2,k\u03c61,n+ b2,k).\n9"},{"page":10,"text":"Finally, we can write\nyn|X,W1,b1,W2,b2,W3 \u223c N(WT\n3\u03c62,n,\u03c4\u22121ID).\nThe application of variational inference continues as before.\n4Insights and Applications\nOur derivation suggests many applications and insights, including the representation of model un-\ncertainty in deep learning, better model regularisation, computationally efficient Bayesian convolu-\ntional neural networks, use of dropout in recurrent neural networks, and the principled development\nof dropout variants, to name a few. These are briefly discussed here, and studied more in depth in\nseparate work.\n4.1Insights\nThe Gaussian process\u2019s robustness to over-fitting can be contributed to several different aspects of\nthe model and is discussed in detail in [Rasmussen and Williams, 2006]. Our interpretation offers\nan explanation to dropout\u2019s ability to avoid over-fitting.\nOur derivation also suggests that an approximating variational distribution should be placed over\nthe bias b. This could be sampled jointly with the weights W. Note that it is possible to interpret\ndropout as doing so when used with non-linearities with \u03c3(0) = 0. This is because the product\nby the vector of Bernoulli random variables can be passed through the non-linearity in this case.\nHowever the GP interpretation changes in this case, as the inputs are randomly set to zero rather\nthan the weights. By sampling Bernoulli variables for the bias weights as well, the model might\nbecome more robust.\nIn [Srivastava et al., 2014] alternative distributions to the Bernoulli are discussed. For example, it is\nsuggested that multiplying the weights by N(1,\u03c32) results in similar results to dropout (although\nthis becomes a more costly operation at run time). This can be seen as an alternative approximating\nvariational distribution where we set q(wk) = mk+ mk\u01eb with \u01eb \u223c N(0,I).\nWe noted in the text that the weight-decay for the dropped-out weights should be scaled by the\nprobability of the weights to not be dropped. This follows from the KL approximation. This might\nexplain why doubling the learning rate of the bias during MLP optimisation works well in practice\nin dropout networks with p = 0.5.\nWe also note that the model brought in section 2.1 does not use a bias at the output layer. This is\nequivalent to shifting the data by a constant amount and thus not treated in our derivation.\n4.2Applications\nOur derivationsuggests an estimate for dropoutmodels using T forward passes throughthe network\nand averagingthe results (referredto as MC dropout, comparedto standard dropout with weight av-\neraging). This result has been presentedin the literaturebeforeas modelaveraging[Srivastava et al.,\n2014]. Our interpretation suggests a new look as to why MC dropout is more sensible than the cur-\nrent approach of averaging the weights. Furthermore, with the obtained samples we can estimate\nthe model\u2019s confidence in its predictions and take actions accordingly. For example, in the case of\nclassification, the model might return a result with high uncertainty, in which case we might decide\nto pass the input to a human to classify. Alternatively, one can use a weak and fast model to perform\nclassification, and use a more elaborate but slower model only on inputs for which the weak model\nin uncertain. Uncertainty is important in reinforcement learning (RL) [Szepesv\u00b4 ari, 2010] as well.\nWith this informationan agent can decide when to exploit and when to explore its environment. Re-\ncent advances in RL have made use of MLPs to estimate agents\u2019 Q-value functions, a function that\nestimates the quality of different states and actions in the environment [Mnih et al., 2013]. Epsilon\ngreedy search is often used in this setting, where an agent selects the its currently estimated best\naction with some probability, and explores otherwise. With uncertainty estimates over the agent\u2019s\nQ-value function, techniques such as Thompson sampling [Thompson, 1933] can be used to train\nthe model faster. These ideas are studied in the main paper.\nFollowing our interpretation, one should apply dropout after each weight layer and not only after\ninner-product layers at the end of the model. This is to avoid parameter over-fitting on all layers as\nthe dropout model, in effect, integrates over the parameters. The use of dropout after a subset of the\n10"},{"page":11,"text":"layers corresponds to interleaving MAP estimates and fully Bayesian estimates. The application of\ndropout after every weight layer is not used in practice however, as empirical results using standard\ndropout suggest inferior performance. The use of MC dropout, however, with dropout applied after\nevery weight layer results in much better empirical performance on some MLP structures. One\ncan also interpret the approximation above as approximate variational inference in Bayesian neural\nnetworks(NNs). Thus, dropoutappliedaftereveryweightlayeris equivalentto variationalinference\nin Bayesian NNs. This allows us to develop new Bayesian NN architectures which are not directly\nrelated to the Gaussian process, using operations such as pooling and convolutions. This leads to\na good, efficient, and trivial approximations to Bayesian convolutional neural networks (convnets).\nWe discuss these ideas with empirical evaluation in separate work.\nAnother possible application is the adaptationof dropoutto recurrentneural networks (RNNs). Cur-\nrently, dropout is not used with these models as the repeated application of noise over potentially\nthousands of layers results in a very weak signal at the output. GP dynamical models [Wang et al.,\n2005] and recursive GPs with perfect integrators correspond to the ideas behind RNNs and long-\nshort-term-memory (LSTM) networks [Hochreiter and Schmidhuber, 1997]. The GP models inte-\ngrate over the parameters and thus avoid over-fitting. Seen as a GP approximationone would expect\nthere to exist a suitable dropout approximation for these tasks as well.\nModel ensembles are often used in deep learning as well, where the same model is trained several\ntimes and at test time the results of all models are averaged. This is computationally very expen-\nsive as either training time is increased considerably, or many computational resources are used at\nthe same time. One would expect that stochastically simulating forward passes through a dropout\nnetwork will result in similar performance.\nLastly, our interpretation allows the development of principled extensions of dropout. The use of\nnon-diminishing \u03c32(eqs. (9) to (11)) and the use of a mixture of Gaussians with more than two\ncomponents is an immediate example of such. For example the use of a low rank covariance matrix\nwould allow us to capture complex relations between the weights. These approximations could\nresult in alternative uncertainty estimates to the ones obtained with MC dropout. This is subject to\ncurrent research.\n5 Conclusions\nWehaveshownthatamultilayerperceptronwitharbitrarydepthandnon-linearitiesandwithdropout\napplied after every weight layer is mathematically equivalent to an approximationto the deep Gaus-\nsian process. This interpretation offers an explanation to some of dropout\u2019s key properties. Our\nanalysis suggests straightforward generalisations of dropout for future research which should im-\nprove on current techniques.\nAcknowledgments\nThe authorswould like to thankMr ShaneGu, Mr Nilesh Tripuraneni,ProfYoshuaBengio, andProf\nPhil Blunsom for helpful comments. Yarin Gal is supported by the Google European Fellowship in\nMachine Learning.\nReferences\nBaldi, P. and Sadowski, P. J. (2013). Understanding dropout. In Advances in Neural Information\nProcessing Systems, pages 2814\u20132822.\nBengio, Y., Schwenk, H., Sen\u00b4 ecal, J.-S., Morin, F., and Gauvain, J.-L. (2006). Neural probabilistic\nlanguage models. In Innovations in Machine Learning, pages 137\u2013186. Springer.\nBishop, C. M. (2006). Pattern Recognition and Machine Learning (Information Science and Statis-\ntics). Springer-Verlag New York, Inc., Secaucus, NJ, USA.\nBlei, D. M., Jordan, M. I., and Paisley, J. W. (2012). Variational Bayesian inference with stochastic\nsearch. In Proceedings of the 29th International Conference on Machine Learning (ICML-12),\npages 1367\u20131374.\n11"},{"page":12,"text":"Blundell, C., Cornebise, J., Kavukcuoglu, K., and Wierstra, D. (2015). Weight uncertainty in neural\nnetworks. arXiv preprint arXiv:1505.05424.\nDamianou, A. and Lawrence, N. (2013). Deep Gaussian processes. In Proceedings of the Sixteenth\nInternational Conference on Artificial Intelligence and Statistics, pages 207\u2013215.\nGal, Y., Chen, Y., and Ghahramani, Z. (2015). Latent Gaussian processes for distribution estimation\nof multivariate categoricaldata. In Proceedings of the 32ndInternationalConference on Machine\nLearning (ICML-15).\nGal, Y. and Turner, R. (2015). Improving the Gaussian process sparse spectrum approximation by\nrepresentinguncertaintyinfrequencyinputs. InProceedingsofthe32ndInternationalConference\non Machine Learning (ICML-15).\nGal, Y., van der Wilk, M., and Rasmussen, C. (2014). Distributed variational inference in sparse\nGaussian process regression and latent variable models. In Ghahramani, Z., Welling, M., Cortes,\nC., Lawrence, N., and Weinberger, K., editors, Advances in Neural Information Processing Sys-\ntems 27, pages 3257\u20133265.Curran Associates, Inc.\nGraves, A. (2011). Practical variational inference for neural networks. In Advances in Neural\nInformation Processing Systems, pages 2348\u20132356.\nHensman, J., Fusi, N., and Lawrence, N. D. (2013). Gaussian processes for big data. In Nicholson,\nA. and Smyth, P., editors, UAI. AUAI Press.\nHinton, G. E., Srivastava, N., Krizhevsky, A., Sutskever, I., and Salakhutdinov, R. R. (2012).\nImproving neural networks by preventing co-adaptation of feature detectors.\narXiv:1207.0580.\nHochreiter, S. and Schmidhuber, J. (1997). Long short-term memory.\n9(8):1735\u20131780.\nHoffman, M. D., Blei, D. M., Wang, C., and Paisley, J. (2013). Stochastic variational inference. The\nJournal of Machine Learning Research, 14(1):1303\u20131347.\nKingma, D. P. and Welling, M. (2013). Auto-encoding variational Bayes.\narXiv:1312.6114.\nKrizhevsky, A., Sutskever, I., and Hinton, G. E. (2012). Imagenet classification with deep convolu-\ntional neural networks. In Advances in neural information processing systems, pages 1097\u20131105.\nL\u00b4 azaro-Gredilla, M., Qui\u02dc nonero-Candela, J., Rasmussen, C. E., and Figueiras-Vidal, A. R. (2010).\nSparse spectrum Gaussian process regression.\n11:1865\u20131881.\nMacKay, D. J. (1992). A practical Bayesian framework for backpropagation networks. Neural\ncomputation, 4(3):448\u2013472.\nMnih, V., Kavukcuoglu, K., Silver, D., Graves, A., Antonoglou, I., Wierstra, D., and Riedmiller, M.\n(2013). Playing atari with deep reinforcement learning. arXiv preprint arXiv:1312.5602.\nNeal, R. M. (1995). Bayesian learning for neural networks. PhD thesis, University of Toronto.\nRasmussen, C. E. and Williams, C. K. I. (2006). Gaussian Processes for Machine Learning (Adap-\ntive Computation and Machine Learning). The MIT Press.\nRezende, D. J., Mohamed,S., and Wierstra, D. (2014). Stochastic backpropagationandapproximate\ninference in deep generative models. In Proceedings of the 31st International Conference on\nMachine Learning (ICML-14), pages 1278\u20131286.\nSrivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., and Salakhutdinov, R. (2014). Dropout:\nA simple way to prevent neural networks from overfitting. The Journal of Machine Learning\nResearch, 15(1):1929\u20131958.\nSzepesv\u00b4 ari, C. (2010). Algorithms for reinforcement learning. Synthesis Lectures on Artificial\nIntelligence and Machine Learning, 4(1):1\u2013103.\nThompson, W. R. (1933). On the likelihood that one unknown probability exceeds another in view\nof the evidence of two samples. Biometrika, pages 285\u2013294.\nTitsias, M. and Lawrence, N. (2010). Bayesian Gaussian process latent variable model. Thirteenth\nInternational Conference on Artificial Intelligence and Statistics (AISTATS), 6:844\u2013851.\narXiv preprint\nNeural computation,\narXiv preprint\nThe Journal of Machine Learning Research,\n12"},{"page":13,"text":"Titsias, M. and L\u00b4 azaro-Gredilla, M. (2014). Doubly stochastic variational Bayes for non-conjugate\ninference. In Proceedings of the 31st InternationalConference on Machine Learning (ICML-14),\npages 1971\u20131979.\nTsuda, K., Kin, T., and Asai, K. (2002). Marginalized kernels for biological sequences. Bioinfor-\nmatics, 18(suppl 1):S268\u2013S275.\nWager, S., Wang, S., and Liang, P. S. (2013). Dropout training as adaptive regularization. In\nAdvances in Neural Information Processing Systems, pages 351\u2013359.\nWang, J., Hertzmann,A., and Blei, D. M. (2005). Gaussian process dynamical models. In Advances\nin neural information processing systems, pages 1441\u20131448.\nWilliams, C. K. (1997). Computing with infinite networks. Advances in neural information pro-\ncessing systems, pages 295\u2013301.\n13"},{"page":14,"text":"AKL of a Mixture of Gaussians\nProposition 1. Let\nq(x) =\nL\n?\ni=1\npiN(x;\u00b5i,\u03a3i)\nbe a mixture of Gaussians with L components and \u00b5i\u2208 RKnormally distributed, and let p(x) =\nN(0,IK).\nThe KL divergence between q(x) and p(x) can be approximated as:\n?\nfor large enough K.\nKL(q(x)||p(x)) \u2248\nL\ni=1\npi\n2\n?\u00b5T\ni\u00b5i+ tr(\u03a3i) \u2212 K \u2212 log|\u03a3i|?\nProof. We have\nKL(q(x)||p(x)) =\n?\n?\nq(x)logq(x)\np(x)dx\n=q(x)logq(x)dx \u2212\n?\nq(x)logp(x)dx\n= \u2212H(q(x)) \u2212\n?\nq(x)logp(x)dx\nwhere H(q(x)) is the entropyof q(x). The second term in the last line can be evaluatedanalytically,\nbut the entropy term has to be approximated.\nWe begin by approximating the entropy term. We write\nH(q(x)) = \u2212\nL\n?\nL\n?\nL\n?\ni=1\npi\n?\n?\n?1\nN(x;\u00b5i,\u03a3i)logq(x)dx\n= \u2212\ni=1\npi\nN(\u01eb;0,I)logq(\u00b5i+ Li\u01eb)d\u01eb\n\u2248 \u2212\ni=1\npi\nT\nT\n?\nt=1\nlogq(\u00b5i+ Li\u01ebit)\n?\nfor some T > 0 with LiLT\nNow, the term inside the logarithm can be written as\nq(\u00b5i+ Li\u01ebit)\n?\nL\n?\nwhere || \u00b7 ||\u03a3is the Mahalanobis distance. Since \u00b5i,\u00b5jare assumed to be normally distributed,\nthe quantity \u00b5j\u2212 \u00b5i\u2212 Li\u01ebitis also normally distributed. Using the expectation of the gener-\nalised \u03c72distribution with K degrees of freedom, we have that for K >> 0 there exists that\n||\u00b5j\u2212 \u00b5i\u2212 Li\u01ebit||2\n\u01ebT\ni\nL\u22121\nq(\u00b5i+ Li\u01ebit) \u2248 pi(2\u03c0)\u2212K\/2|\u03a3i|\u22121\/2exp?\u22121\nThis gives us\nH(q(x))\ni= \u03a3iand \u01ebit\u223c N(0,I).\n=\nL\nj=1\npiN(\u00b5i+ Li\u01ebit;\u00b5j,\u03a3j)\n=\nj=1\npi(2\u03c0)\u2212K\/2|\u03a3j|\u22121\/2exp?\u22121\n2||\u00b5j\u2212 \u00b5i\u2212 Li\u01ebit||2\n\u03a3j\n?.\n\u03a3j>> 0 for i ?= j. Finally, we have for i = j that ||\u00b5i\u2212 \u00b5i\u2212 Li\u01ebit||2\niLi\u01ebit= \u01ebT\n\u03a3i=\nitLT\niL\u2212T\nit\u01ebit. Therefore the last equation can be written as\n2\u01ebT\nit\u01ebit\n?.\n14"},{"page":15,"text":"\u2248 \u2212\nL\n?\nL\n?\n?\ni=1\npilog\n?1\nT\nT\n?\nt=1\npi(2\u03c0)\u2212K\/2|\u03a3i|\u22121\/2exp?\u22121\nT\n?\n2log(2\u03c0)\n. Since\u01ebT\n2\u01ebT\nit\u01ebit\n??\n=\ni=1\npi\n2\n?log|\u03a3i| +1\nlogpi\u2212K\nT\nt=1\n?\n\u01ebT\nit\u01ebit\n?+ C\nit\u01ebitdistributesaccordingtoa\u03c72distribution,\nwhereC = \u2212?L\nit\u2019s expectation is K, and the last term can be approximated as\ni=1pi\nH(q(x)) \u2248\nL\n?\ni=1\npi\n2\n?log|\u03a3i| + K?+ C\nNext, evaluating the first term of the KL divergence we get\n?\nfor p(x) = N(0,IK) it is easy to validate that this is equivalent to \u22121\nFinally, we get\nq(x)logp(x)dx =\nL\n?\ni=1\npi\n?\nN(x;\u00b5i,\u03a3i)logp(x)dx\n2\n?L\ni=1pi\n?\u00b5T\ni\u00b5i+ tr(\u03a3i)?.\nKL(q(x)||p(x)) \u2248\nL\n?\ni=1\npi\n2\n?\u00b5T\ni\u00b5i+ tr(\u03a3i) \u2212 K \u2212 log|\u03a3i|?.\nB Log Evidence Lower Bound for Classification\nProposition 2. Given\np(c|X) =\n?\n?\np(c|Y)p(Y|X)dY\n??\n=p(c|Y)\np(Y|X,W1,W2,b)\n\u00b7 p(W1,W2,b)dW1dW2db\n?\ndY\nwhere c is an N dimensional vector of categorical values, we can write the log evidence lower\nbound as\n?\n\u00b7 logp(c|Y)dW1dW2dbdY\n\u2212 KL(q(W1,W2,b)||p(W1,W2,b)).\nLGP-VI:=p(Y|X,W1,W2,b)q(W1,W2,b)\nProof. We have\nlogp(c|X)\n= log\n?\n?\np(c|Y)p(Y|X,W1,W2,b)\n\u00b7 p(W1,W2,b)dW1dW2dbdY\n= logq(W1,W2,b)p(Y|X,W1,W2,b)p(c|Y)\n\u00b7p(W1,W2,b)\nq(W1,W2,b)dW1dW2dbdY\n\u2265\n?\nq(W1,W2,b)p(Y|X,W1,W2,b)log\n?\np(c|Y)\n15"},{"page":16,"text":"\u00b7p(W1,W2,b)\nq(W1,W2,b)\n?\ndW1dW2dbdY\n=\n?\nq(W1,W2,b)p(Y|X,W1,W2,b)\n\u00b7 logp(c|Y)dW1dW2dbdY\n\u2212 KL(q(W1,W2,b)||p(W1,W2,b)),\nas needed.\nC Predictive Mean\nProposition 3. Given weights matrices Miof dimensions Ki\u00d7 Ki\u22121, bias vectors miof dimen-\nsions Ki, and binary vectors biof dimensions Ki\u22121for each layer i = 1,...,L, as well as the\napproximating variational distribution\nq(y\u2217|x\u2217) := N?y\u2217;? y\u2217(x\u2217,b1,...,bL),\u03c4\u22121ID\n? y\u2217=\nEq(y\u2217|x\u2217)(y\u2217) \u22481\nT\nt=1\nwith\n?bi,t\u223c Bern(pi).\nProof.\n?\n=\n? ??\n=\n? y\u2217(x\u2217,b1,...,bL)Bern(b1)\u00b7\u00b7\u00b7Bern(bL)db1\u00b7\u00b7\u00b7dbL\n\u22481\nT\nt=1\n?Bern(b1)\u00b7\u00b7\u00b7Bern(bL)\nfor some \u03c4 > 0, with\n?\n1\nKL(MLbL)\u03c3\n?\n...\n?\n1\nK1(M2b2)\u03c3?(M1b1)x\u2217+ m1\nT\n?\n?...\n?\n,\nwe have\n? y\u2217(x\u2217,?b1,t,...,?bL,t)\nEq(y\u2217|x\u2217)(y\u2217) =\ny\u2217q(y\u2217|x\u2217)dy\u2217\n?\ny\u2217N?y\u2217;? y\u2217(x\u2217,b1,...,bL),\u03c4\u22121ID\n?Bern(b1)\u00b7\u00b7\u00b7Bern(bL)db1\u00b7\u00b7\u00b7dbLdy\u2217\n?dy\u2217\n=\ny\u2217N?y\u2217; ? y\u2217(x\u2217,b1,...,bL),\u03c4\u22121ID\n?\nBern(b1)\u00b7\u00b7\u00b7Bern(bL)db1\u00b7\u00b7\u00b7dbLdy\u2217\n?\nT\n?\n? y\u2217(x\u2217,?b1,t,...,?bL,t).\nDPredictive Variance\nProposition 4. Given weights matrices Miof dimensions Ki\u00d7 Ki\u22121, bias vectors miof dimen-\nsions Ki, and binary vectors biof dimensions Ki\u22121for each layer i = 1,...,L, as well as the\napproximating variational distribution\nq(y\u2217|x\u2217) := p(y\u2217|x\u2217,\u03c9)q(\u03c9)\nq(\u03c9) = Bern(b1)\u00b7\u00b7\u00b7Bern(bL)\np(y\u2217|x\u2217,\u03c9) = N?y\u2217; ? y\u2217(x\u2217,b1,...,bL),\u03c4\u22121ID\n? y\u2217=\n16\n?\nfor some \u03c4 > 0, with\n?\n1\nKL(MLbL)\u03c3\n?\n...\n?\n1\nK1(M2b2)\u03c3?(M1b1)x\u2217+ m1\n?...\n?\n,"},{"page":17,"text":"we have\nEq(y\u2217|x\u2217)\n?(y\u2217)T(y\u2217)?\u2248 \u03c4\u22121ID+1\nT\nT\n?\nt=1\n? y\u2217(x\u2217,?b1,t,...,?bL,t)T? y\u2217(x\u2217,?b1,t,...,?bL,t)\n?bi,t\u223c Bern(pi).\nwith\nProof.\nEq(y\u2217|x\u2217)\n? ??\n=\n? ?\n\u2248 \u03c4\u22121ID+1\n?(y\u2217)T(y\u2217)?\n(y\u2217)T(y\u2217)p(y\u2217|x\u2217,\u03c9)dy\u2217\n=\n?\nq(\u03c9)d\u03c9\n? ?\nCovp(y\u2217|x\u2217,\u03c9)(y\u2217) + Ep(y\u2217|x\u2217,\u03c9)(y\u2217)TEp(y\u2217|x\u2217,\u03c9)(y\u2217)\n?\nq(\u03c9)d\u03c9\n=\n\u03c4\u22121ID+ ? y\u2217(x\u2217,b1,...,bL)T? y\u2217(x\u2217,b1,...,bL)\nT\nt=1\nsince p(y\u2217|x\u2217,\u03c9) = N?y\u2217;? y\u2217(x\u2217,b1,...,bL),\u03c4\u22121ID\n?\nBern(b1)\u00b7\u00b7\u00b7Bern(bL)db1\u00b7\u00b7\u00b7dbL\nT\n?\n? y\u2217(x\u2217,?b1,t,...,?bL,t)T? y\u2217(x\u2217,?b1,t,...,?bL,t)\n?.\n17"}],"widgetId":"rgw26_56ab9d59139cf"},"id":"rgw26_56ab9d59139cf","partials":[],"templateName":"publicliterature\/stubs\/PublicationText.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationText.html?publicationUid=277959103&hide=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationDetailAd":{"data":{"googleDfpSlot":null,"widgetId":"rgw27_56ab9d59139cf"},"id":"rgw27_56ab9d59139cf","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAd.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAd.html?publicationUid=277959103&slotId=336x280_Publications_ATF_Right&collapseSlotMode=never&fallbackContainerEnabled=1","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationRelations":null,"publicationRelationsReverse":null,"publicationUid":277959103,"showSignUpDialog":false,"selectNewSignUpDialog":false,"publicationQuestions":null,"publicationCitations":{"data":{"publicationUid":277959103,"publicationCitationsList":{"data":{"citationItems":[],"hasCitations":false,"sort":"normal","sortNormal":true,"sortOriginal":false,"publicationUid":277959103,"publicationLink":"publication\/277959103_Dropout_as_a_Bayesian_Approximation_Appendix","showOriginalOrderSortingOption":true,"hasShowMore":true,"newOffset":10,"pageSize":10,"widgetId":"rgw29_56ab9d59139cf"},"id":"rgw29_56ab9d59139cf","partials":[],"templateName":"publicliterature\/stubs\/PublicationCitationsList.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationCitationsList.html?publicationUid=277959103&sort=&totalCount=20&swapJournalAndAuthorPositions=0&showAbstract=1&showType=1&showPublicationPreview=1","viewClass":"views.publicliterature.PublicationCitationsListView","yuiModules":["rg.views.publicliterature.PublicationCitationsListView"],"stylesheets":[],"_isYUI":true},"hasCitations":true,"citationsCount":20,"hasIncomingCitations":false,"incomingCitationsCount":0,"showCitationsSorter":true,"showAbstract":true,"showType":true,"showPublicationPreview":true,"swapJournalAndAuthorPositions":false,"sort":"","sortOriginal":false,"citationList":"outgoing","showsIncoming":false,"showSorting":true,"usePlainButton":null,"useEnrichedContext":null,"widgetId":"rgw28_56ab9d59139cf"},"id":"rgw28_56ab9d59139cf","partials":[],"templateName":"publicliterature\/stubs\/PublicationCitations.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationCitations.html?publicationUid=277959103&citationList=&citedInPage=1&sort=","viewClass":"views.publicliterature.PublicationCitationsView","yuiModules":["rg.views.publicliterature.PublicationCitationsView"],"stylesheets":[],"_isYUI":true},"publicationReviewPromo":null,"publicationUsedInReviews":null,"publicationPdfJsReader":null,"useFulltextOptimizedLayout":false,"publicationActions":null,"requestFulltextPromo":null,"currentUrl":"publication\/277959103_Dropout_as_a_Bayesian_Approximation_Appendix","isLeaderboardAd":false,"enableStickyBox":null,"googleDfpSlotMobileBottom":null,"fullTextExitPopup":null,"showExitPopupDialog":false,"widgetId":"rgw2_56ab9d59139cf"},"id":"rgw2_56ab9d59139cf","partials":{"romeo_legal_notice":"publicliterature\/stubs\/partials\/romeo_legal_notice.html"},"templateName":"publicliterature\/stubs\/PublicPublicationDetails_NewLayout.html","templateExtensions":["generalHelpers"],"attrs":{"publicationUid":277959103},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicPublicationDetailsOld.html?publicationUid=277959103&isTestOldDesign=0","viewClass":"views.publicliterature.PublicPublicationDetailsOldView","yuiModules":["rg.views.publicliterature.PublicPublicationDetailsOldView"],"stylesheets":[],"_isYUI":true},"widgetId":"rgw1_56ab9d59139cf"},"id":"rgw1_56ab9d59139cf","partials":[],"templateName":"publicliterature\/stubs\/PublicPublicationDetails.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicPublicationDetails.html","viewClass":"views.publicliterature.PublicPublicationDetailsView","yuiModules":["rg.views.publicliterature.PublicPublicationDetailsView"],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"uaClass":"","headPrefix":[],"rootUrl":"https:\/\/www.researchgate.net\/","requestToken":"ypxJtycXEOjsTWS1fb2Vk7kmj3BOyROdG\/516Pd7qxP3BA1a5Qt4erogCvaCDDHxpQ6HTw4MFLq5gYnoxnkG11iReGupv2tgMe+sL5+TjApigladxdtXagGd4Ke2rxvXaFVs00KkO3i8JhlWZKx3lYmJZmB1CXzxchW8qOH0G\/VLCnZAmjctlZNnzncX7OuNo5N8mLzdfs\/IT3vLX9kaiib6yuGmKl\/GWlVsYYwSQCGaodx6mf\/niI5z9dbfF8UIZhwOvbxR94j2KWiWj1mjpORfZXYJT8v2A9cGD6TOrpI=","faviconCdnUrl":"https:\/\/c5.rgstatic.net\/m\/2390829798215018\/images\/favicon.ico","headerOutput":"<noscript><\/noscript><link rel=\"canonical\" href=\"https:\/\/www.researchgate.net\/publication\/277959103_Dropout_as_a_Bayesian_Approximation_Appendix\" \/>\n<link rel=\"dns-prefetch\" href=\"\/\/c5.rgstatic.net\" \/>\n<link rel=\"dns-prefetch\" href=\"\/\/i1.rgstatic.net\" \/>\n<meta property=\"twitter:card\" content=\"summary\" \/>\n<meta property=\"twitter:site\" content=\"@ResearchGate\" \/>\n<meta property=\"og:title\" content=\"Dropout as a Bayesian Approximation: Appendix\" \/>\n<meta property=\"og:description\" content=\"We show that a multilayer perceptron (MLP) with arbitrary depth and\nnonlinearities, with dropout applied after every weight layer, is\nmathematically equivalent to an approximation to a well known...\" \/>\n<meta property=\"og:site_name\" content=\"ResearchGate\" \/>\n<meta property=\"og:image\" content=\"https:\/\/i1.rgstatic.net\/publication\/277959103_Dropout_as_a_Bayesian_Approximation_Appendix\/links\/557f87e008aeb61eae261b76\/smallpreview.png\" \/>\n<meta property=\"og:url\" content=\"https:\/\/www.researchgate.net\/publication\/277959103_Dropout_as_a_Bayesian_Approximation_Appendix\" \/>\n<meta property=\"rg:id\" content=\"PB:277959103\" \/>\n<meta name=\"DC.identifier\" scheme=\"DCTERMS.URI\" content=\"http:\/\/dx.doi.org\/\" \/>\n<meta name=\"gs_meta_revision\" content=\"1.1\" \/>\n<meta name=\"citation_title\" content=\"Dropout as a Bayesian Approximation: Appendix\" \/>\n<meta name=\"citation_author\" content=\"Yarin Gal\" \/>\n<meta name=\"citation_author\" content=\"Zoubin Ghahramani\" \/>\n<meta name=\"citation_publication_date\" content=\"2015\/06\/06\" \/>\n<meta name=\"citation_abstract_html_url\" content=\"https:\/\/www.researchgate.net\/publication\/277959103_Dropout_as_a_Bayesian_Approximation_Appendix\" \/>\n<meta name=\"citation_fulltext_html_url\" content=\"https:\/\/www.researchgate.net\/publication\/277959103_Dropout_as_a_Bayesian_Approximation_Appendix\" \/>\n<meta name=\"viewport\" content=\"width=device-width,initial-scale=1\" \/>\n<link href=\"\/\/c5.rgstatic.net\/m\/22664197317151888\/styles\/rg.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/21004998181197492\/styles\/rg2.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<!--[if lt IE 9]><link href=\"\/\/c5.rgstatic.net\/m\/238176252723686\/styles\/ie.css\" type=\"text\/css\" rel=\"stylesheet\"\/><![endif]-->\n<link href=\"\/\/c5.rgstatic.net\/m\/217752362214895\/styles\/modules\/publicprofile.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<script src=\"\/\/c5.rgstatic.net\/m\/2321000301012716\/javascript\/vendor\/webfontloader\/webfontloader.js\" type=\"text\/javascript\"><\/script>\n <script>(function(i,s,o,g,r,a,m){i[\"GoogleAnalyticsObject\"]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,\"script\",\"\/\/www.google-analytics.com\/analytics.js\",\"ga\");\n ga(\"create\",\"UA-58591210-1\");ga(\"set\",\"anonymizeIp\",true);ga('set', 'dimension1', 'publication slurped');ga('set', 'dimension2', 'Article');ga('set', 'dimension3', 'Logged out');ga('set', 'dimension4', 'https');ga(\"send\",\"pageview\");<\/script>\n","webfont":"<noscript><\/noscript><script> WebFontConfig = { custom: { families: ['source_sans_pro_italic', 'source_sans_pro_bold', 'source_sans_pro', 'martel'], urls : ['\/\/c5.rgstatic.net\/m\/231392577336386\/styles\/fonts.css'] } }; WebFont.load(WebFontConfig); <\/script>\n","correlationId":"rgreq-0d264037-0754-4a50-8ea1-470b11632dfb","accountId":null,"module":"publicliterature","action":"publicliterature.PublicPublicationDetails","page":"publicationDetail","product":"publications","backendTime":722,"continent":"Asia","stylesHome":"\/\/c5.rgstatic.net\/m\/","staticHost":"c5.rgstatic.net","useEarlyFlush":false,"longRunningRequestIdentifier":"LongRunningRequest.publicliterature.PublicPublicationDetails","longRunningRequestFp":"e9e5bbe1366c7ee8c8e41d02f793c884ac9be19b","widgetId":"rgw30_56ab9d59139cf"},"id":"rgw30_56ab9d59139cf","partials":[],"templateName":"application\/stubs\/StaticHeader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.StaticHeader.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){
            Y.rg.core.pagespeed.Monitoring.monitorPage("\/\/glassmoni.researchgate.net", "publicliterature.PublicPublicationDetails.run.html.loggedOut.get", "59de9668d07aeb77ab4de5f24d382b5d199d2437", "rgreq-0d264037-0754-4a50-8ea1-470b11632dfb", "8902d5a04baba8b190e1decd1b3a27302a08673b");
        
            Y.rg.core.pagespeed.Monitoring.monitorPage("\/\/glassmoni.researchgate.net", "publicationDetail.loggedOut", "ed1993d9e20f6cefa83edacaa24401a18c071aea", "rgreq-0d264037-0754-4a50-8ea1-470b11632dfb", "8902d5a04baba8b190e1decd1b3a27302a08673b");
        })();
(function(){Y.rg.createInitialWidget({"data":{"year":"2016","inlinePromo":null,"isAdmin":false,"contactUrl":"https:\/\/www.researchgate.net\/contact","aboutUsUrl":"https:\/\/www.researchgate.net\/about","widgetId":"rgw31_56ab9d59139cf"},"id":"rgw31_56ab9d59139cf","partials":[],"templateName":"application\/stubs\/DefaultFooter.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.DefaultFooter.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"headerLogin":{"data":{"urlAfterLogin":"publication\/277959103_Dropout_as_a_Bayesian_Approximation_Appendix?ev=auth_pub","requestToken":"6zNJ0j59NvTEDty0Je5mvzjoAqJUR3vE1S35wo7dwxmXa+VsXT4L8vroNsIOekw\/\/1jZne+kYOcKGuCIVv2g8MOUFJMHQsgQFStBrvrT9qRZHrpyUp0GOXpQGbQDbBGxUXOS+Zfb96ZWJLO8PISSY5V1N92n82zOdIcp0qAVN3COkck6Rn2lYT0bAjEk5oo+bMIny2iZjxLN9OA+3wuKnQuCpwP4FLca+BCaZINUB3eFIflnWSQMTTivVU\/rY\/lyXbtiqZswTxne+p7YpeQUngHQl+BEWyy+5k9UoCyJ5oI=","loginUrl":"https:\/\/www.researchgate.net\/application.Login.html","signupUrl":"https:\/\/www.researchgate.net\/signup.SignUp.html?ev=su_chnl_index&hdrsu=1&_sg=sgEQ8ccn7yXRp6gN0HsSDQ4z-lUa7AmKwAn9AXF5uC8rXhkJtjEFXhVGh4FutleE","encodedUrlAfterLogin":"cHVibGljYXRpb24vMjc3OTU5MTAzX0Ryb3BvdXRfYXNfYV9CYXllc2lhbl9BcHByb3hpbWF0aW9uX0FwcGVuZGl4P2V2PWF1dGhfcHVi","signupCallToAction":"Join for free","widgetId":"rgw33_56ab9d59139cf"},"id":"rgw33_56ab9d59139cf","partials":{"partial":"application\/stubs\/partials\/headerLoginDefault.html"},"templateName":"application\/stubs\/HeaderLogin.html","templateExtensions":[],"attrs":{"goal":"milestoneHeaderLoginSeen"},"widgetUrl":"https:\/\/www.researchgate.net\/application.HeaderLogin.html","viewClass":"views.application.HeaderLoginView","yuiModules":["rg.views.application.HeaderLoginView"],"stylesheets":[],"_isYUI":true},"cookieConsent":null,"logoSvgSrc":"https:\/\/c5.rgstatic.net\/m\/235107188705592\/images\/template\/brand-header-logo.svg","logoFallbackSrc":"https:\/\/c5.rgstatic.net\/m\/238113351022438\/images\/template\/brand-header-logo.png","widgetId":"rgw32_56ab9d59139cf"},"id":"rgw32_56ab9d59139cf","partials":{"schemaSocialProfiles":"application\/stubs\/partials\/schemaSocialProfiles.html"},"templateName":"application\/stubs\/HeaderLoggedOut.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.HeaderLoggedOut.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"logEvent":"su_banner","specialCopy":false,"widgetId":"rgw34_56ab9d59139cf"},"id":"rgw34_56ab9d59139cf","partials":[],"templateName":"application\/stubs\/LoggedOutBanner.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.LoggedOutBanner.html","viewClass":"views.application.LoggedOutBannerView","yuiModules":["rg.views.application.LoggedOutBannerView"],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.core.util.ParameterFilter.filter(["ev","cp","ch","ref","dbw","pli","loginT","uid","claimChannel","enrichId","enrichSource","utm_source","utm_medium","utm_campaign","el","ci"]);})();
});}); } else { throw 'YRG was not loaded when attaching widgets'; }</script><script> dataLayer = [{"pageCategory":"publication slurped","publicationType":"Article","eventCategory":"Publication page"}]; </script> <noscript><iframe src="//www.googletagmanager.com/ns.html?id=GTM-MKVKH7" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-MKVKH7');</script><script>(function(e){function n(n,t,o,a){"use strict";var i=e.document.createElement("link"),r=t||e.document.getElementsByTagName("script")[0],d=e.document.styleSheets;return i.rel="stylesheet",i.href=n,i.media="only x",a&&(i.onload=a),r.parentNode.insertBefore(i,r),i.onloadcssdefined=function(e){for(var t,o=0;d.length>o;o++)d[o].href&&d[o].href.indexOf(n)>-1&&(t=!0);t?e():setTimeout(function(){i.onloadcssdefined(e)})},i.onloadcssdefined(function(){i.media=o||"all"}),i}function t(e,n){e.onload=function(){e.onload=null,n&&n.call(e)},"isApplicationInstalled"in navigator&&"onloadcssdefined"in e&&e.onloadcssdefined(n)}var o=function(a,i){"use strict";if(a&&3===a.length){var r=e.Image,d=!(!document.createElementNS||!document.createElementNS("http://www.w3.org/2000/svg","svg").createSVGRect||!document.implementation.hasFeature("http://www.w3.org/TR/SVG11/feature#Image","1.1")||e.opera&&-1===navigator.userAgent.indexOf("Chrome")||-1!==navigator.userAgent.indexOf("Series40")),c=new r;c.onerror=function(){o.method="png",o.href=a[2],n(a[2])},c.onload=function(){var e=1===c.width&&1===c.height,r=a[e&&d?0:e?1:2];o.method=e&&d?"svg":e?"datapng":"png",o.href=r,t(n(r),i)},c.src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///ywAAAAAAQABAAACAUwAOw==",document.documentElement.className+=" grunticon"}};o.loadCSS=n,o.onloadCSS=t,e.grunticon=o})(this);grunticon(["https://c5.rgstatic.net/c/o1q2er/styles/icons/_header-ico.svg.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_header-ico.png.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_header-ico.fallback.scss"]);grunticon(["https://c5.rgstatic.net/c/o1q2er/styles/icons/_admin-ico.svg.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_admin-ico.png.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_admin-ico.fallback.scss"]);grunticon(["https://c5.rgstatic.net/c/o1q2er/styles/icons/_ico.svg.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_ico.png.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_ico.fallback.scss"]);</script></body>
</html>
