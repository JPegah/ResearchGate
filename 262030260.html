<!DOCTYPE html> <html lang="en" class="" id="rgw29_56ab9ecea4af6"> <head > <meta charset="utf-8"/> <meta http-equiv="content-type" content="text/html; charset=UTF-8"/> <meta name="Rg-Request-Token" id="Rg-Request-Token" content="BknqRXCvsqohKnk3awiDyHogarIq/S8+vI6zvKR/WsBCz2gv/aMrZvDYBlQbpGVGVj3tNtm6Mmdpc7KEQOKIyWl4+hPriHOM6c/b/TDnt70J8m3XRnF++RdCc2Iza2RLZh2Ppyi5JxxHZpYRdAsyIzvGTFtcppryOEV2o5v8O+o11IXLJVjmSUtQPNph0A13cGEHrO0onGe4zTGkt8gx1PL7EhWXORPZWGi6MfVC3emCvp9RWTEVLqokM2HHo+vZP/tyNlkPTwOiqjNXLTf3+1Mu1eGDkAQwvnrJlPgfA3E="/> <meta http-equiv="expires" content="0"/> <link rel="apple-touch-icon" sizes="57x57" href="https://www.researchgate.net/apple-touch-icon-57x57.png"> <link rel="apple-touch-icon" sizes="60x60" href="https://www.researchgate.net/apple-touch-icon-60x60.png"> <link rel="apple-touch-icon" sizes="72x72" href="https://www.researchgate.net/apple-touch-icon-72x72.png"> <link rel="apple-touch-icon" sizes="76x76" href="https://www.researchgate.net/apple-touch-icon-76x76.png"> <link rel="apple-touch-icon" sizes="114x114" href="https://www.researchgate.net/apple-touch-icon-114x114.png"> <link rel="apple-touch-icon" sizes="120x120" href="https://www.researchgate.net/apple-touch-icon-120x120.png"> <link rel="apple-touch-icon" sizes="144x144" href="https://www.researchgate.net/apple-touch-icon-144x144.png"> <link rel="apple-touch-icon" sizes="152x152" href="https://www.researchgate.net/apple-touch-icon-152x152.png"> <link rel="apple-touch-icon" sizes="180x180" href="https://www.researchgate.net/apple-touch-icon-180x180.png"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-32x32.png" sizes="32x32"> <link rel="icon" type="image/png" href="https://www.researchgate.net/android-chrome-192x192.png" sizes="192x192"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-96x96.png" sizes="96x96"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-16x16.png" sizes="16x16"> <link rel="shortcut icon" type="image/x-icon" href="https://c5.rgstatic.net/m/2390829798215018/images/favicon.ico"/> <link rel="manifest" href="https://www.researchgate.net/manifest.json"> <meta name="msapplication-TileColor" content="#da532c"> <meta name="msapplication-TileImage" content="https://www.researchgate.net/mstile-144x144.png"> <meta name="theme-color" content="#444444"> <link rel="search" type="application/opensearchdescription+xml" title="ResearchGate search" href="https://www.researchgate.net/application.DownloadOpenSearchPlugin.html"/> <link rel="meta" type="application/rdf+xml" title="ICRA labels" href="https://www.researchgate.net/application.DownloadLabels.html"/> <link rel="http://oexchange.org/spec/0.8/rel/related-target" type="application/xrd+xml" href="https://www.researchgate.net/application.DownloadOExchange.html"/> <base href="https://www.researchgate.net/"/> <script>
    var rgConfig = {
        correlationId: "rgreq-3f590742-325f-49df-9846-ed3ce0163df0",
        accountId: "",
        module: "publicliterature",
        action: "publicliterature.PublicPublicationDetails",
        page: "publicationDetail",
        product: "publications",
        continent: "Asia",
        stylesHome: "//c5.rgstatic.net/m/",
        staticHost: "c5.rgstatic.net",
        longRunningRequestIdentifier: "LongRunningRequest.publicliterature.PublicPublicationDetails",
        longRunningRequestFp: "e9e5bbe1366c7ee8c8e41d02f793c884ac9be19b"
    };
    window.rootUrl = "https://www.researchgate.net/";
</script> <link rel="canonical" href="https://www.researchgate.net/publication/262030260_Ergodicity_of_Approximate_MCMC_Chains_with_Applications_to_Large_Data_Sets" />
<link rel="dns-prefetch" href="//c5.rgstatic.net" />
<link rel="dns-prefetch" href="//i1.rgstatic.net" />
<meta property="twitter:card" content="summary" />
<meta property="twitter:site" content="@ResearchGate" />
<meta property="og:title" content="Ergodicity of Approximate MCMC Chains with Applications to Large Data Sets" />
<meta property="og:description" content="In many modern applications, difficulty in evaluating the posterior density
makes performing even a single MCMC step slow. This difficulty can be caused by
intractable likelihood functions, but..." />
<meta property="og:site_name" content="ResearchGate" />
<meta property="og:image" content="https://i1.rgstatic.net/publication/262030260_Ergodicity_of_Approximate_MCMC_Chains_with_Applications_to_Large_Data_Sets/links/54c7078b0cf22d626a361153/smallpreview.png" />
<meta property="og:url" content="https://www.researchgate.net/publication/262030260_Ergodicity_of_Approximate_MCMC_Chains_with_Applications_to_Large_Data_Sets" />
<meta property="rg:id" content="PB:262030260" />
<meta name="DC.identifier" scheme="DCTERMS.URI" content="http://dx.doi.org/" />
<meta name="gs_meta_revision" content="1.1" />
<meta name="citation_title" content="Ergodicity of Approximate MCMC Chains with Applications to Large Data Sets" />
<meta name="citation_author" content="Natesh S. Pillai" />
<meta name="citation_author" content="Aaron Smith" />
<meta name="citation_publication_date" content="2014/05/01" />
<meta name="citation_abstract_html_url" content="https://www.researchgate.net/publication/262030260_Ergodicity_of_Approximate_MCMC_Chains_with_Applications_to_Large_Data_Sets" />
<meta name="citation_fulltext_html_url" content="https://www.researchgate.net/publication/262030260_Ergodicity_of_Approximate_MCMC_Chains_with_Applications_to_Large_Data_Sets" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<link href="//c5.rgstatic.net/m/22664197317151888/styles/rg.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/21004998181197492/styles/rg2.css" type="text/css" rel="stylesheet"/>
<!--[if lt IE 9]><link href="//c5.rgstatic.net/m/238176252723686/styles/ie.css" type="text/css" rel="stylesheet"/><![endif]-->
<link href="//c5.rgstatic.net/m/217752362214895/styles/modules/publicprofile.css" type="text/css" rel="stylesheet"/>
<script src="//c5.rgstatic.net/m/2321000301012716/javascript/vendor/webfontloader/webfontloader.js" type="text/javascript"></script>
 <script>(function(i,s,o,g,r,a,m){i["GoogleAnalyticsObject"]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,"script","//www.google-analytics.com/analytics.js","ga");
 ga("create","UA-58591210-1");ga("set","anonymizeIp",true);ga('set', 'dimension1', 'publication slurped');ga('set', 'dimension2', 'Article');ga('set', 'dimension3', 'Logged out');ga('set', 'dimension4', 'https');ga("send","pageview");</script>
  <script> WebFontConfig = { custom: { families: ['source_sans_pro_italic', 'source_sans_pro_bold', 'source_sans_pro', 'martel'], urls : ['//c5.rgstatic.net/m/231392577336386/styles/fonts.css'] } }; WebFont.load(WebFontConfig); </script><noscript></noscript>

<title>Ergodicity of Approximate MCMC Chains with Applications to Large Data Sets</title>
<meta name="description" content="Ergodicity of Approximate MCMC Chains with Applications to Large Data Sets on ResearchGate, the professional network for scientists."/>
<meta name="keywords" content="scientific network, scientific platform, scientific community, research partner, research collaboration, journal articles, international collaboration, find researcher, lifescience researcher, interdisciplinary research, research collaboration"/>
</head>
<body class="use-svg-icons logged-out">
<div id="page-container">
<script type="text/javascript">var googletag = googletag || {}; googletag.cmd = googletag.cmd || [];
(function() { var gads = document.createElement("script"); gads.async = true; gads.type = "text/javascript"; var useSSL = "https:" == document.location.protocol; gads.src = (useSSL ? "https:" : "http:") + "//www.googletagservices.com/tag/js/gpt.js"; var node =document.getElementsByTagName("script")[0]; node.parentNode.insertBefore(gads, node); })();</script><div id="main" class="logged-out-header-support">
<div id="content" class="">

<noscript>
<div class="c-box-warning full-width-element" style="text-align: center; ">
    <div style="margin: auto; padding:10px;" class="container">
        <b>For full functionality of ResearchGate it is necessary to enable JavaScript.
            Here are the <a href="http://www.enable-javascript.com/" rel="nofollow" target="_blank">
                instructions how to enable JavaScript in your web browser</a>.</b>
    </div>
</div>
</noscript>

<div id="rgw1_56ab9ecea4af6" itemscope itemtype="http://schema.org/ScholarlyArticle"><div class="publication-wrapper publication-wrapper-onecol" id="rgw2_56ab9ecea4af6" itemscope itemtype="http://schema.org/ScholarlyArticle"> <div class="c-col-content"> <div class="c-content"> <div class="clearfix">  <div class="publication-header"> <div id="rgw8_56ab9ecea4af6">  <div class="type-label"> Article   </div> <span class="Z3988" title="ctx_ver=Z39.88-2004&rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&rfr_id=info%3Asid%2Fresearchgate.net%3Aresearchgate&rft.atitle=Ergodicity%20of%20Approximate%20MCMC%20Chains%20with%20Applications%20to%20Large%20Data%20Sets&rft.date=2014&rft.au=Natesh%20S.%20Pillai%2CAaron%20Smith&rft.genre=article"></span> <h1 class="pub-title" itemprop="name">Ergodicity of Approximate MCMC Chains with Applications to Large Data Sets</h1> <meta itemprop="headline" content="Ergodicity of Approximate MCMC Chains with Applications to Large Data Sets">  <meta itemprop="image" content="https://i1.rgstatic.net/publication/262030260_Ergodicity_of_Approximate_MCMC_Chains_with_Applications_to_Large_Data_Sets/links/54c7078b0cf22d626a361153/smallpreview.png">  <div id="rgw10_56ab9ecea4af6" class="publication-detail-author-list"> <div> <ul class="clearfix js-people-list">  <li id="rgw11_56ab9ecea4af6"> <a href="researcher/15521032_Natesh_S_Pillai" class="pub-detail-item author-item" itemprop="author" itemscope itemtype="http://schema.org/Person"> <div class="indent-left"> <div class="people-img">  <img src="https://c5.rgstatic.net/m/2951093203564/images/template/default/profile/profile_default_s.jpg" title="Natesh S. Pillai" alt="Natesh S. Pillai" height="20px" width="20px" style="height: 20px;"/>  </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Natesh S. Pillai</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item   not-claimed " id="rgw12_56ab9ecea4af6">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="researcher/15521032_Natesh_S_Pillai"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="Natesh S. Pillai" alt="Natesh S. Pillai" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">       </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="researcher/15521032_Natesh_S_Pillai" class="display-name">Natesh S. Pillai</a>    </h5> <div class="truncate-single-line meta">   </div>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>  <li id="rgw13_56ab9ecea4af6"> <a href="researcher/2031323220_Aaron_Smith" class="pub-detail-item author-item" itemprop="author" itemscope itemtype="http://schema.org/Person"> <div class="indent-left"> <div class="people-img">  <img src="https://c5.rgstatic.net/m/2951093203564/images/template/default/profile/profile_default_s.jpg" title="Aaron Smith" alt="Aaron Smith" height="20px" width="20px" style="height: 20px;"/>  </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Aaron Smith</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item   not-claimed " id="rgw14_56ab9ecea4af6">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="researcher/2031323220_Aaron_Smith"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="Aaron Smith" alt="Aaron Smith" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">       </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="researcher/2031323220_Aaron_Smith" class="display-name">Aaron Smith</a>    </h5> <div class="truncate-single-line meta">   </div>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>   </ul> <div class="js-loading"></div>  </div> </div> <div class="pub-details js-pub-details">        <meta itemprop="datePublished" content="2014-05">  05/2014;               <div class="pub-source"> Source: <a href="http://arxiv.org/abs/1405.0182" rel="nofollow">arXiv</a> </div>  </div> <div id="rgw15_56ab9ecea4af6" class="pub-abstract">  <div class="clearfix">   <div style="max-height: 54px;" class="js-expander-container js-expander-collapsed">  <p itemprop="description"> <strong>ABSTRACT</strong> <div>In many modern applications, difficulty in evaluating the posterior density<br />
makes performing even a single MCMC step slow. This difficulty can be caused by<br />
intractable likelihood functions, but also appears for routine problems with<br />
large data sets. Many researchers have responded by running approximate<br />
versions of MCMC algorithms. In this note, we develop quantitative bounds for<br />
showing the ergodicity of these approximate samplers. We then use these bounds<br />
to study the bias-variance trade-off of approximate MCMC algorithms. We apply<br />
our results to simple versions of recently proposed algorithms, including a<br />
variant of the &quot;austerity&quot; framework of Korratikara et al.</div> </p>  </div>  </div>   </div>      <div class="action-container">   <div class="clear"></div> <div class="share-dialog-container" style="display: none;">  </div> </div> </div> <div style="margin-left: -20px; margin-right: -20px;">  </div> </div>  <div class="publication-detail-dfp-container rf"> <div id="rgw28_56ab9ecea4af6">  </div> </div>  </div>  <div class="clearfix">  <noscript> <div id="rgw27_56ab9ecea4af6"  itemprop="articleBody">  <p>Page 1</p> <p>arXiv:1405.0182v1  [math.ST]  1 May 2014<br />ERGODICITY OF APPROXIMATE MCMC CHAINS WITH<br />APPLICATIONS TO LARGE DATA SETS<br />NATESH S. PILLAI‡AND AARON SMITH♯<br />Abstract. In many modern applications, difficulty in evaluating the posterior density<br />makes taking performing a single MCMC step slow; this difficulty can be caused by in-<br />tractable likelihood functions, but also appears for routine problems with large data sets.<br />Many researchers have responded by running approximate versions of MCMC algorithms.<br />In this note, we develop very general quantitative bounds for showing the ergodicity of these<br />approximate samplers. In particular, our bounds can be used to perform a bias-variance<br />trade-off argument to give practical guidance on the quality of approximation that should<br />be used for a given total computational budget. We present a few applications of our results<br />in recently proposed algorithms, including the “austerity” framework, Stochastic Gradient<br />Langevin Dynamics, exponential random graphs and ABC-MCMC algorithms.<br />1. Introduction<br />Markov chain Monte Carlo (MCMC) sampling is an indispensable tool for Bayesian com-<br />putation. Most of the popular Metropolis-Hastings samplers require full evaluation of the<br />posterior at two points at every step, while other MCMC samplers require even more infor-<br />mation, such as gradients of the likelihood function. In many modern applications involving<br />intractable likelihoods, the computational cost of this full evaluation of the likelihood func-<br />tion can be prohibitively expensive. For instance, a full likelihood evaluation might involve<br />processing a massive amount data, or computing the solution of a partial differential equa-<br />tion representing an underlying physical phenomenon. The result is that the inferential<br />performance of naive implementations of MCMC algorithms can deteriorate as the amount<br />of data grows, unless available computational resources grow even more quickly (see [Jor13]<br />for a broader discussion of this problem outside of the context of MCMC).<br />An increasingly common approach to circumvent this difficulty is to run only approxi-<br />mations of the desired MCMC dynamics. These approximations often rely on estimating,<br />rather than evaluating, the posterior distribution of interest - for example, doing so based<br />on a subsample of the available data [Bea03, OBB+00, WT11, KCW13, BDH14]. While<br />many approximate MCMC methods seem to be very successful in practice, they do not have<br />the same convergence guarantees as standard MCMC samplers. In this paper, we present<br />some general convergence results for such ‘approximate’ MCMC algorithms and discuss their<br />applications to some recently proposed algorithms. Our results give quantitative bounds on<br />the convergence in distribution of the Markov chain as well as convergence of finite samples<br />drawn from the Markov chain. These bounds allow us to provide advice on how to choose<br />‡pillai@fas.harvard.edu, Department of Statistics Harvard University,1 Oxford Street, Cambridge MA<br />02138, USA.<br />♯smith.aaron.matthew@gmail.com, Department of Mathematics and Statistics University of Ottawa, 585<br />King Edward Drive, Ottawa ON K1N 7N5, Canada.<br />1</p>  <p>Page 2</p> <p>parameters for various approximation schemes, and in particular to give modest conditions<br />under which approximation schemes are more efficient than their underlying MCMC algo-<br />rithms. While our examples focus on the problems posed by large data sets, our bounds are<br />also relevant to MCMC samplers targetting intractable likelihoods; see [PM+13] for applica-<br />tions of related ideas in that context.<br />Throughout the paper, we are especially interested in how approximations perform outside<br />of the simplest setting of uniformly good approximations of uniformly ergodic Markov chains<br />(see e.g., [Mit05] for bounds in that setting; heuristic arguments presented in [KCW13]<br />and [WT11] implicitly make such assumptions). It is well known that some approximation<br />schemes that have been proposed in the past can fail badly even in innocuous settings when<br />the approximations are not uniformly good (see Example 17 in [PM+13] for a sampler that<br />fails to converge to a two-valued density on [0,1] and Theorem 1 of [LL12] for one that<br />has difficulty sampling from a Gaussian). Similarly, even uniformly good approximations of<br />chains without uniform ergodicity can fail to inherit good convergence properties. To see<br />this, fix ǫ &gt; 0 and consider simple random walk on N as a uniformly good approximation of<br />simple random walk on N with drift min<br />?<br />has reasonable convergence properties; the former does not even have a stationary measure.<br />Our paper has three main contributions. The first is providing practical advice on how<br />to choose the best approximate sampler for a given computational budget. The second is<br />providing robust ergodicity results. Finally, we provide a quantitative discussion of conver-<br />gence for many approximation algorithms that cannot be easily analyzed as globally-small<br />perturbations. This includes non-reversible samplers, algorithms that are geometrically but<br />not uniformly ergodic, and approximations that can be arbitrarily bad outside of “small”<br />sets.<br />After presenting the main results, we discuss applications.<br />formalization of the austerity framework proposed in [KCW13] for discussing the problem of<br />running approximate MCMC algorithms under computational constraints imposed by data<br />volume. In [KCW13], the authors create a family of approximate samplers Kǫparameterized<br />by an error ǫ ≥ 0, with K0= K being the original MCMC sampler. Heuristically, a larger<br />value of ǫ corresponds to an algorithm that can run more steps for any given amount of<br />computer time, but has a larger asymptotic bias. For a fixed amount of computer time, the<br />goal is to choose the value of ǫ that minimizes the expected L2error of the resulting sample.<br />Although this bias-variance tradeoff is proposed in their paper, they do not provide bounds<br />relating the expected finite-time error to ǫ or the total computing time. We use our general<br />results to relate these quantities, and provide guidance as to the optimal value of ǫ for a<br />given amount of computing time when the approximation Kǫof K0is uniformly good on<br />the parameter space. We then extend these results to several large classes of base chains K<br />that are not uniformly ergodic, obtaining similar rates. We also extend our bounds to the<br />exponential random graph model, using this as a test case for non-i.i.d. data and providing<br />analogous bounds. One of the main goals of our study is to justify the fact that, for a small<br />computational budget and large amount of data, MCMC dynamics Kǫwith ǫ &gt; 0 can be more<br />efficient than the usual dynamics K0. Our approximation assumptions are stated in terms of<br />families of metrics on kernels that include those used in [KCW13, AFEB14, Mit05, BDH14],<br />and we show that our converge bounds are sharp in this generality. In examples, we also<br />0,<br />ǫ<br />log(n)<br />?<br />towards 0 at point n. The latter chain<br />Our first application is a<br />2</p>  <p>Page 3</p> <p>point out that subsampling algorithms can have additional structure under which much<br />faster convergence is possible.<br />In the following section, we apply our bounds to the Stochastic Gradient Langevin Dy-<br />namics (SGLD) of [WT11]. When these dynamics are uniformly ergodic and the SGLD<br />approximation to the usual Langevin Dynamucs are uniformly good, the bounds are similar<br />to those for the austerity framework. Unfortunately, as pointed out in [WT11, AFEB14],<br />these assumptions very rarely hold. We make progress by observing the fact that, for many<br />natural examples, the shape of the tails of the likelihood function depends very little on the<br />details of a data set. When this is the case, a subsample of data may result in very poor<br />kernel approximations of the tails, but even a subsample consisting of a single data point<br />is often enough to obtain global properties such as drift conditions. We find quantitative<br />bounds based on this idea, and apply them to examples for which the heuristic convergence<br />argument in [WT11] does not apply.<br />Our final section briefly discusses global properties that one might consider in trading bias<br />for variance in MCMC algorithms, with applications to SGLD and to ABC. Briefly, the work<br />in [KCW13] and related papers is built on the idea that one can take more steps of an MCMC<br />algorithm if one can very cheaply approximate a transition kernel; the increased number of<br />samples will decrease the variance of the resulting estimate, at some cost in bias. This is<br />a local improvement, as we only improve the speed of individual steps without thought to<br />the global properties of the algorithm. Our final section discusses a very different tradeoff,<br />where the transition kernel K is approximated by a transition kernel˜K that may be just<br />as expensive to sample from, but which has better convergence properties than K. In one<br />of our examples,˜K is geometrically ergodic while K is not. In other examples, we may<br />increase the spectral gap. In all cases, these improved convergence properties should result<br />in MCMC samplers that have a smaller variance for the same number of steps. While the<br />approach and algorithms discussed here are very different from those in [KCW13], the idea is<br />quite similar: for a quantifiable increase in bias, we can decrease the variance of our MCMC<br />sample.<br />While we were finishing this paper, closely related work was released in the preprints<br />[BDH14, AFEB14]. We feel that the preprint [BDH14] is complementary to the current<br />paper: their paper focuses on providing guarantees that a given approximate algorithm is<br />close to a base chain under certain conditions, and largely ignores what this implies for the<br />convergence of the approximate algorithm. We focus on the convergence rates of approximate<br />algorithms given guarantees of the sort found in [BDH14]; besides lemmas covering very<br />simple approximation algorithms in Sections 5 and 6, we spend little time on developing<br />such guarantees. The paper [AFEB14] is much closer to our work. Like us, the authors of<br />[AFEB14] were concerned with the convergence of various approximate versions of standard<br />MCMC algorithms, and are particularly interested in the problems associated with running<br />MCMC algorithms when it is expensive to exactly evaluate the target distribution, even up<br />to normalizing constant. Their main theoretical results are applications of the perturbation-<br />theoretic theorems found in [Mit05]. In particular, their Corollary 2.2 gives similar bounds<br />to our Lemma 3.2; like us, they give a few variations on this theme.<br />Since our main applications are very similar, we point out some important differences<br />between our papers. Their theoretical results focus on the case of uniformly ergodic ap-<br />proximating chains that are uniformly close to their target chains, and these results can<br />3</p>  <p>Page 4</p> <p>be slightly sharper than ours in that generality. In contrast, we obtain theoretical results<br />that apply to a much broader collection of chains, including approximating chains for which<br />the quality of the approximation is not uniformly bounded over the state space, as well as<br />dropping the requirement for uniform ergodicity. This allows us to provide useful bounds on<br />several algorithms, and allows us to give a partial answer to a question on the convergence<br />of stochastic gradient Langevin dynamics posed in Section 2.3 of [AFEB14]. In another<br />direction, we also examine convergence in stronger metrics, such as Wasserstein distance<br />of the empirical distribution of the chain to its target, and obtain sharper inequalities in<br />these situations. Finally, in addition to proving convergence results related to Corollary 2.2<br />of [AFEB14], we prove a tradeoff bound that describes the optimal approximation quality<br />one should use with a given computational budget, and describes the asymptotic variance<br />of an MCMC sample in terms of this computational budget. Their paper covers a wider<br />variety of examples than ours, and has several very useful simulated studies of different algo-<br />rithms. Overall, their paper focuses more on serious empirical studies than ours, while ours<br />focuses on more broadly-applicable theoretical convergence bounds and their consequences<br />for sample properties.<br />The organization of our paper is as follows. We begin by setting up some notation in<br />Section 2, and prove our main theoretical results in Section 3. In Section 4, we then study<br />the austerity framework recently proposed in [KCW13]. In Section 5, we discuss how the<br />same austerity framework extends to non-i.i.d. data by looking at exponential random graph<br />models. We discuss a related idea, the stochastic gradient Lagevin dynamics, in Section 6.<br />These dynamics were proposed in [WT11], and they are generally very far from the parent<br />algorithm outside of a small set; overcoming this difficulty is the critical step in making<br />rigorous the heuristic convergence argument presented in [WT11]. Finally, in Section 7, we<br />introduce and analyze some approximate MCMC samplers that are based on adding bias to<br />improve global mixing properties rather than local step speeds.<br />2. Preliminaries<br />For a random variable X and measure µ, X ∼ µ denotes that X is distributed according<br />to µ. Unif(A) denotes the uniform or Haar distribution on the set A as appropriate. We will<br />write f = O(g) to mean that there exists a constant C &gt; 0 so that f(x) ≤ Cg(x). We also<br />write f = o(g) if limx→∞<br />the law of X. Throughout the paper, the letter C will denote a generic positive constant.<br />By ? · ?TV we mean the total variation norm. We use the framework of curvature for<br />operators used heavily in [JO10] and introduced in [Oll09]. Throughout, we will consider<br />several kernels K on several Polish spaces (Ω,d). Associated with each kernel and Polish<br />space is a notion of curvature. Fix two measures µ,ν on Ω, and let Π(µ,ν) be the set of all<br />couplings of µ and ν. The Wasserstein distance between µ and ν is defined as<br />f(x)<br />g(x)= 0. For a random variable X, we will write L(X) to denote<br />Wd(µ,ν) =inf<br />ζ∈Π(µ,ν)<br />?<br />x,y∈Ω<br />d(x,y)ζ(dx,dy).<br />In this paper, we frequently pass between this definition of the Wasserstein distance and<br />the following version provided by the Kantorovitch-Rubinstein duality theorem (see Remark<br />4</p>  <p>Page 5</p> <p>6.5 of [Vil08]):<br />Wd(µ,ν) =sup<br />?f?Lip=1|µ(f) − ν(f)|.<br />The Ricci curvature of the kernel K at the pair of points x,y is defined to be:<br />κ(x,y) = 1 −Wd(K(x,·),K(y,·))<br />and the curvature of the entire chain is defined to be<br />d(x,y)<br />κ = inf<br />x,y∈Ωκ(x,y).<br />It is worth noting that in many cases of interest, it is sufficient to calculate κ(x,y) for<br />d(x,y) ‘small’; see, e.g., Prop 19 of [Oll09].<br />In addition to the curvature, which describes the tendency of nearby points to coallesce,<br />we also need several measures of variation from [JO10]. The eccentricity of a point x ∈ Ω is<br />given by:<br />?<br />The coarse diffusion is defined as<br />σ(x)2=1<br />2<br />y,z∈Ω<br />and the local dimension is given by<br />?<br />?<br />Finally, define the granularity to be<br />σ∞=1<br />x∈Ω<br />For a running time T ≥ 11, define<br />πT(f) =1<br />T<br />E(x) =<br />Ω<br />d(x,y)π(dy).<br />?<br />d(y,z)2K(x,dy)K(x,dz)<br />m(x) =inf<br />?f?Lip=1<br />y,z∈Ωd(y,z)2K(x,dy)K(x,dz)<br />y,z∈Ω|f(y) − f(z)|2K(x,dy)K(x,dz).<br />2sup<br />diamSupp(K(x,·)).<br />T<br />?<br />t=1<br />f(Xt) (2.1)<br />for any f : Ω ?→ R. Fix a Markov chain Xtwith associated operator K and invariant measure<br />π on the Polish space (Ω,d), and define the quantity<br />V2=<br />1<br />κTsup<br />x∈Ω<br />σ2(x)<br />m(x)κ.<br />Theorem 4 of [JO10] gives the following concentration inequality for any Lipschitz function<br />f with π(f) = 0:<br />P<br />?|πT(f) − Ex[πT(f)]|<br />?f?Lip<br />&gt; r<br />?<br />≤ 2e−r2/(16V2)<br />(2.2)<br />1Without loss of generality, we assume the burn-in time of all of the MCMC algorithms studied in this<br />paper to be 0; it is quite straightforward to modify our results including the burn-in time.<br />5</p>  <p>Page 6</p> <p>for x ∈ Ω and r &lt; rmax=4V2κT<br />denotes the initial condition of Xt.<br />3σ∞. A similar result holds for r &gt; rmax. The subscript x in Ex<br />3. Technical Results<br />3.1. Convergence of Approximate Chains under Contraction Assumptions. Next<br />we consider a general non-stationary, time inhomogeneous Markov chain Xtevolving accord-<br />ing to some sequence of kernels Ktthat approximates a kernel of interest K with stationary<br />distribution π on state space Ω. The following calculation gives quantitative bounds on the<br />mixing properties of the approximate chain Xt:<br />Lemma 3.1 (Coupling Inequality). Assume that K satisfies<br />?Kt(x,·) − π(·)?TV≤ Cx(1 − α)t<br />for some α &gt; 0 and all t &gt; 0, and also assume that<br />sup<br />1≤t≤T,x∈X?Kt(x,·) − K(x,·)?TV&lt; δ<br />for some set X. Then, if X1= x ∈ X, we have:<br />?L(XT) − π?TV≤ Cx(1 − α)T−1+ (T − 1)δ +<br />T<br />?<br />t=1<br />Kt(x,Xc). (3.1)<br />Proof of Lemma 3.1. We will couple the process {Xt}T<br />of kernels {Kt}T−1<br />kernel K. The first chain, Yt, starts at stationarity: Y1∼ π. The second chain, Y′<br />with Xt: Y′<br />We couple the Markov chains {Yt} and {Y′<br />P[YT?= Y′<br />≤ Cx(1 − α)T−1.<br />Next we construct a coupling between Y′<br />if Xt?= Y′<br />Xt+1from a distribution which satisfies<br />t=1evolving according to the sequence<br />t=1, {Y′<br />t=1with two Markov chains {Yt}T<br />t}T<br />t=1both evolving according to the<br />t, starts<br />1= x = X1.<br />t} so that<br />T] = ?L(YT) − L(Y′<br />T)?TV<br />(3.2)<br />tfrom (3.2) and Xtas follows. At every step t,<br />tor Y′<br />t/ ∈ X, choose Xt+1∼ Kt+1(Xt,·) independently of Y′<br />t+1. If Xt= Y′<br />t, choose<br />P[Xt+1?= Y′<br />t+1] = ?Kt+1(Xt,·) − K(Y′<br />t}, τ2= inf{t ≥ 1 : Y′<br />t,·)?TV.<br />Define τ1= inf{t ≥ 1 : Xt?= Y′<br />?L(XT) − π?TV= ?L(XT) − L(YT)?TV<br />t/ ∈ X} and τ = min(τ1,τ2). Then:<br />≤ P[XT?= YT]<br />≤ P[XT?= Y′<br />T<br />?<br />T<br />?<br />T] + P[Y′<br />T?= YT]<br />≤<br />t=1<br />P[τ = t] + Cx(1 − α)T−1<br />≤<br />t=1<br />(P[τ2= t] + P[τ2&gt; τ1= t]) + Cx(1 − α)T−1<br />6</p>  <p>Page 7</p> <p>≤<br />T<br />?<br />t=1<br />Kt−1(x,Xc) + (T − 1)δ + Cx(1 − α)T−1<br />and the proof is finished.<br />?<br />Next we give a similar argument in the Wasserstein topology.<br />Lemma 3.2. Fix a kernel of interest K with stationary distribution π, and let (Ω,d) be a<br />Polish space that has eccentricity E(x) &lt; ∞ with respect to π. Assume that K satisfies<br />Wd(K(x,·),K(y,·)) ≤ (1 − α)d(x,y)<br />for all x,y ∈ X for some α &gt; 0 and set X. Also assume that<br />sup<br />(3.3)<br />1≤t≤TWd(Kt(x,·),K(x,·)) &lt; δ<br />for some δ &gt; 0 and all x ∈ X. Then, with X0= x ∈ X,<br />Wd(L(XT),π) ≤δ<br />α+ (1 − α)T−1E(x) +<br />T<br />?<br />t=1<br />?<br />Kt−1(x,Xc) +<br />t−1<br />?<br />s=1<br />Ks(x,Xc)<br />?<br />.(3.4)<br />Proof of Lemma 3.2. By the triangle inequality, for any t ∈ [1,T] and any x,y ∈ X,<br />Wd(K(x,·),Kt(y,·)) ≤ Wd(K(x,·),K(y,·)) + Wd(K(y,·),Kt(y,·))<br />≤ (1 − α)d(x,y) + δ.<br />We couple our chain Xsdriven by kernel Ksand started at X1= x with a chain Ysdriven<br />by kernel K and started at Y1∼ π so that, at every step,<br />E[d(Xs+1,Ys+1)|Xs,Ys] ≤ γ + Wd(K(Xs,·),Ks(Ys,·)).<br />Then we have<br />Wd(L(XT),π) ≤ E[d(XT,YT)]<br />≤ E[δ + γ + (1 − α)E[d(XT−1,YT−1)]] + (1 − P[XT−1,YT−1∈ X])<br />≤ ...<br />≤δ + γ<br />1 − α+ (1 − α)T−1E(x) +<br />T<br />?<br />t=1<br />?<br />Kt−1(x,Xc) +<br />t−1<br />?<br />s=1<br />Ks(x,Xc)<br />?<br />.<br />Since this holds for all γ &gt; 0, the claim follows.<br />?<br />Lemma 3.2 has the immediate corollary:<br />Corollary 1. Assume that K satisfies<br />?K(x,·) − K(y,·)?TV≤ (1 − α)<br />for some α &gt; 0. Also assume that<br />sup<br />1≤t≤T?Kt(x,·) − K(x,·)?TV&lt; δ<br />for some δ &gt; 0. Then:<br />?L(XT) − π?TV≤δ<br />α+ (1 − α)T−1.(3.5)<br />7</p>  <p>Page 8</p> <p>Remark 3.3. We mention that this corollary is also immediately implied by Corollary 3.1<br />of [Mit05]; the constants are essentially the same for δ &lt; α small. Although our Lemma<br />3.2 and the results in [Mit05] both imply the same result in this restricted setting, they have<br />different emphases. Their result is based on linear algebra; ours is purely probabilistic. Their<br />result gives superior results for general uniformly ergodic chains (though, by taking powers of<br />the kernel, our result also trivially implies inequalities for general uniformly ergodic chains<br />that give similar bounds for both bias and errors of MCMC estimates); our results apply to<br />chains that are not uniformly ergodic. Finally, their result only applies for convergence in<br />Total Variation, while our results explicitly allow the use of many other Wasserstein metrics;<br />this flexibility can lead to bounds that are effectively much sharper if the metric is chosen<br />carefully.<br />This last difference is most easily seen in situations, such as Example 8, where the Markov<br />chain satisfies inequality (3.3) for some fixed α &gt; 0 throughout a non-compact state space,<br />and for which the eccentricity satisfies E(x) &lt; ∞ for each x ∈ Ω but supx∈ΩE(x) = ∞.<br />These chains are generally geometrically ergodic but not uniformly ergodic; Lemma 3.2 pro-<br />vides direct bounds on their finite-time bias while Corollary 3.1 of [Mit05] does not apply.<br />The following example shows that the bound given by Corollary 1 is sharp up to constants,<br />as a function of δ and α.<br />Example 2. Consider the family of birth and death chains on [n] = {0,1,2,...,n} with<br />transition kernels given by<br />Kα,δ(x,x + 1) = δ<br />Kα,δ(x,x) = 1 − α − δ<br />Kα,δ(x,x − 1) = δ<br />when x − 1,x + 1 ∈ [n], and 0 otherwise. Let πα,δbe the associated stationary distribution.<br />For δ &lt; α and n &gt; 2, it can be shown that<br />sup<br />x∈[n]?Kα,δ(x,·) − Kα,0(x,·)?TV= α<br />?KT<br />α,0(x,·) − πα,0?TV= O?n(1 − α)T?<br />?πα,δ− πα,0?TV≥<br />δ<br />2α+ O<br />??δ<br />α<br />2??<br />.<br />3.2. Convergence of Approximate Chains Under Drift and Minorization Assump-<br />tions. In this subsection, we consider a Metropolis-Hastings chain K on state space Ω with<br />proposal kernel L and stationary distribution π, as well as an approximating chain Kδon<br />state space Ω with proposal kernel L and stationary distribution πδ. We make the following<br />assumptions throughout this subsection:<br />(1) There exists a function V : Ω → R+and constants 0 &lt; a &lt; 1, b &lt; ∞ so that a chain<br />Ytevolving according to K satisfies<br />E[V (Yt+1)|Yt= y] ≤ (1 − a)V (y) + b.<br />8<br />(3.6)</p>  <p>Page 9</p> <p>(2) Define Vǫ(x) = V (x)<br />we have:<br />1<br />1+ǫ. Assume that there exists some ǫ0≥ 0 so that, for all ǫ &gt; ǫ0,<br />|?<br />z(Vǫ(x) − Vǫ(z))L(x,dz)|<br />Vǫ(x)<br />&lt; Cǫ&lt; ∞<br />(3.7)<br />(3) For all compact sets X ⊂ Ω, there exists some ǫ(X) &gt; 0 and measure µXwith support<br />equal to X so that, for all x ∈ X and some measure rxassociated with each point x,<br />we have:<br />K(x,·) = ǫ(X)µX(·) + (1 − ǫ(X))rx(·). (3.8)<br />Remark 3.4. We briefly discuss the strength of these assumptions.<br />(1) This assumption is fairly standard; see e.g. [RT96] for useful sufficient conditions.<br />(2) This holds for most reasonable chains. In particular, this inequality holds if our target<br />and proposal distributions are both Gaussian; it holds with ǫ0 = 0 if the proposal<br />distribution has smaller variance.<br />(3) This holds if L(x,·) has density bounded away from 0 on all compact sets, and in<br />particular it is easy to force any chain to satisfy this for small values of ǫ.<br />Under these assumptions, the drift condition is transferred to the approximate chain Kδ:<br />Lemma 3.5 (Drift and Minorization of Approximate Chains). Let K be a kernel satisfying<br />assumptions 3.2, and let Kδbe a kernel satisfying<br />||K(x,·) − Kδ(x,·)||TV &lt; δ.<br />Then a chain Xtevolving according to Kδsatisfies a drift condition of the form<br />E[Vǫ(Xt+1)|Xt= x] ≤ (1 − aδ,ǫ)Vǫ(x) + bǫ,<br />for any ǫ &gt; ǫ0, where<br />aδ,ǫ= 1 −<br />??<br />?<br />1 −a<br />2<br />?<br />1<br />1+ǫ+ Cǫδ<br />?<br />(3.9)<br />bǫ= b<br />1<br />1+ǫ<br />1 +2(1 − a)<br />a<br />?<br />1<br />1+ǫ<br />and we note that for any ǫ &gt; 0, aδ,ǫis strictly greater than 0 for δ sufficiently small.<br />Proof. By Jensen’s inequality and inequality (3.6),<br />E[Vǫ(Yt+1)|Yt= y] ≤ E[V (Yt+1)|Yt= y]<br />≤ ((1 − a)V (y) + b)<br />1<br />1+ǫ<br />1<br />1+ǫ<br />Ifa<br />?<br />2V (y) &gt; b, we have (1−a)V (y)+b ≤?1 −a<br />a<br />. Thus, continuing the above calculation,<br />2<br />?V (y). Ifa<br />2V (y) ≤ b, we have (1−a)V (y)+b ≤<br />b 1 +2(1−a)<br />?<br />E[Vǫ(Yt+1)|Yt= y] ≤<br />?<br />1 −a<br />2<br />?<br />1<br />1+ǫVǫ(y) + b<br />1<br />1+ǫ<br />?<br />1 +2(1 − a)<br />a<br />?<br />1<br />1+ǫ<br />. (3.10)<br />9</p>  <p>Page 10</p> <p>Define aǫ= 1 −?1 −a<br />E[Vǫ(Xt+1)|Xt= x] = E[Vǫ(Yt+1)|Yt= x] + E[Vǫ(Xt+1) − Vǫ(Yt+1)|Yt= Xt= x]<br />≤ (1 − aǫ)Vǫ(x) + bǫ+ E[Vǫ(Xt+1) − Vǫ(Yt+1)|Yt= Xt= x].<br />Denote by α(x,y) the acceptance probability associated with K and αδ(x,y) the acceptance<br />probability associated with Kδ. By Assumption 3.7, we have for ǫ &gt; ǫ0:<br />2<br />?<br />1<br />1+ǫand bǫ= b<br />1<br />1+ǫ<br />?<br />1 +2(1−a)<br />a<br />?<br />1<br />1+ǫ. We then calculate<br />|E[Vǫ(Xt+1) − Vǫ(Yt+1)]| = |<br />?<br />?<br />z:α(x,z)&gt;αδ(x,z)<br />(α(x,z) − αδ(x,z))(V (x) − V (z))ℓ(x,dz)<br />+ |<br />z:α(x,z)&lt;αδ(x,z)<br />(−α(x,z) + αδ(x,z))(V (z) − V (x))ℓ(x,dz)<br />?<br />≤ ||K(x,·) − Kδ(x,·)||TV|<br />≤ CǫδVǫ(x).<br />z<br />(V (x) − V (z))ℓ(x,dz)|<br />(3.11)<br />Putting together inequalities (3.10) and (3.11), we have:<br />E[Vǫ(Xt+1)|Xt= x] ≤ (1 − aǫ)Vǫ(x) + bǫ+ CǫδVǫ(x).<br />=<br />??<br />1 −a<br />2<br />?<br />1<br />1+ǫ+ Cǫδ<br />?<br />Vǫ(x) + bǫ<br />and the proof is finished.<br />?<br />For a Markov chain Xtevolving according to an approximate chain Kδ, define<br />πT,δ(f) =1<br />T<br />T<br />?<br />t=1<br />f(Xt).<br />Then this Lemma allows us to prove the following concentration result when K is uniformly<br />ergodic and Ω is countable:<br />Lemma 3.6 (Error Bounds for Approximate Chains). Let K satsify Assumptions 3.2, and<br />also assume that supxV (x) ≡ D &lt; ∞ and Ω is countable. Let Kδbe a kernel satisfying<br />?K(x,·) − Kδ(x,·)?TV&lt; δ.<br />Then for any function f with ?f?∞≤ 1 and q,r &gt; 0,<br />P[|πT,δ(f) − π(f)| &gt;<br />r<br />√T<br />+<br />δq<br />G(1 − θ)q+ (1 − G(1 − θ)q)<br />T<br />q] ≤ e−(1−θ)2r2<br />2G2<br />,<br />where G,θ are as defined in Equation (3.12) below.<br />Proof. Applying Theorem 5 of [Ros95], with bounds given by Lemma 3.5 and assumptions<br />3.2, for any ǫ &gt; ǫ0the kernel Kδis (G,θ)-uniformly ergodic with<br />?<br />(1 − θ)2= max<br />G = 2 1 +<br />bǫ<br />aδ,ǫ<br />?<br />+ D<br />sup{x : Vǫ(x) ≤2bǫ<br />?<br />(3.12)<br />?<br />ǫ<br />aδ,ǫ}<br />?<br />10<br />,(aδ,ǫ+ 4bǫ− 3aδ,ǫbǫ)(aδ,ǫ+ 6bǫ− 2aδ,ǫbǫ)<br />aδ,ǫ(aδ,ǫ+ 2bǫ)<br />?</p>  <p>Page 11</p> <p>where aδ,ǫ,bǫare given by Equation (3.9). Combining this bound with Theorem 1 of [KW13],<br />we have for these values of (G,θ) that:<br />P[|πT,δ(f) − πδ(f)| &gt;<br />r<br />√T] ≤ 2e−(1−θ)2r2<br />2G2<br />. (3.13)<br />Finally, combining Corollary 1 with Lemma 3.5, we have for all 1 ≤ q ≤ T:<br />|π(f) − πδ(f)| ≤<br />δq<br />G(1 − θ)q+ (1 − G(1 − θ)q)<br />T<br />q. (3.14)<br />Combining inequalities (3.12), (3.13) and (3.14) gives the result.<br />?<br />We then prove similar, weaker, bounds for geometrically ergodic but not uniformly ergodic<br />chains. We begin by noting that the following follows immediately from Theorem 1 of<br />[KCW13]:<br />Theorem 3 (Concentration for Geometrically Ergodic Chains). Fix a subset X of a count-<br />able space Ω and assume that the kernel K restricted to X satisfies<br />?Kt(x,·) − π?TV≤ GXθt−1<br />for some GX&lt; ∞. Then for all r &gt; 0 and x0∈ X,<br />r<br />√T] ≤ e<br />(3.15)<br />P[|πT,δ(f) − π(f)| &gt;<br />−(1−θ)2r2<br />2G2<br />X<br />+?1 − P[{Xt}T<br />t=1⊂ X]?.<br />We then have the following analogue to Lemma 3.6:<br />Lemma 3.7 (Error Bounds for Approximate Chains 2). Fix a countable state space Ω and<br />kernel K that satsifies Assumptions 3.2 and inequality (3.15). Also assume that for all finite<br />sets X ⊂ Ω, we have supx∈XV (x) ≡ DX&lt; ∞. Let Kδbe a kernel satisfying<br />?K(x,·) − Kδ(x,·)?TV&lt; δ.<br />Then for any function f with ?f?∞≤ 1 and q,r &gt; 0,<br />?<br />≤ e−(1−θ)2r2<br />where for all ǫ &gt; ǫ0fixed, G and θ are given by:<br />P<br />|πT,δ(f) − π(f)| &gt;<br />r<br />√T<br />+<br />δq<br />G(1 − θ)q+ (1 − G(1 − θ)q)<br />T<br />q<br />?<br />t=1⊂ X]?,<br />(3.16)<br />2G2<br />+?1 − P[{Xt}T<br />G = 2<br />?<br />1 +<br />bǫ<br />aδ,ǫ<br />?<br />+ DX<br />{x : Vǫ(x) ≤2bǫ<br />?<br />(3.17)<br />(1 − θ)2= max<br />?<br />ǫ<br />aδ,ǫ}<br />?<br />,(aδ,ǫ+ 4bǫ− 3aδ,ǫbǫ)(aδ,ǫ+ 6bǫ− 2aδ,ǫbǫ)<br />aδ,ǫ(aδ,ǫ+ 2bǫ)<br />?<br />.<br />Proof. The proof of this Lemma is identical to that of Lemma 3.6 after changing equality<br />(3.12) to equality (3.17) and propagating this change through the other computations.<br />?<br />11</p>  <p>Page 12</p> <p>3.3. Moderate-Time Concentration Bound for Walks That Almost Have Posi-<br />tive Curvature. In this section, we provide bounds on the convergence of both estimates<br />πT(f) =<br />T<br />?T<br />results generalize convergence results found in [AFEB14], in the sense that those results deal<br />with convergence of the distribution of a single point L(Xt), while the results in this section<br />deal with convergence of the entire sample Ft. We believe that these bounds are useful in<br />and of themselves, and they are also used to prove tradeoffs in the setting of [KCW13].<br />1<br />t=1f(Xt) and also empirical measures Ft ≡ U?{Xt}T<br />t=1<br />?<br />based on samples<br />{Xt}T<br />t=1drawn from a sequence of kernels {Kt}T<br />t=1approximating a desired kernel K. These<br />Theorem 4. Consider a kernel K with curvature κ &gt; 0 defined on a (possibly non-compact)<br />subset of Rdand a collection of approximating kernels {Kt}∞<br />sup<br />t=0that satisfy<br />x∈ΩWd(Kt(x,·),K(x,·)) &lt; δ.<br />Denote by Ftthe empirical measure of the sequence {Xs}t<br />that there exists a Lipschitz function S(x) ≥<br />?<br />For r &lt;<br />s=1drawn from {Ks}t−1<br />s=1. Assume<br />σ(x)2<br />ηxκ. Then<br />P<br />|Ft(f) − π(f)| ≥ r +δ<br />σ(x)2<br />ηxκ, we have instead:<br />P[|Ft(f) − π(f)| ≥ r +δ<br />Proof. Fix α &gt; 0 and let Ytbe a sequence drawn from K that satisfies<br />E[d(Xt,Yt)] ≤ α +δ<br />Such a coupling exists by inequality (3.4). Denote by Ft and Gt the empirical measures<br />associated with the points {Xs}t<br />note that<br />κ+ (1 − κ)t−1E(X0)<br />?<br />≤ 2e−κtr4max(2?S?Lip,3σ∞).<br />4<br />3σ∞supx<br />κ+ (1 − κ)t−1E(X0)] &lt; 2e−r2κt<br />16<br />infx<br />ηxκ<br />σ(x)2.<br />κ+ (1 − κ)t−1E(X0).<br />s=1and {Ys}t<br />s=1respectively. By the triangle inequality, we<br />P[|Ft(f) − π(f)| ≥ r + Wd(Gt,Ft)] ≤ P[|Gt(f) − π(f)| ≥ r].<br />Combining Inequality (3.18) with Theorem 5 of [JO10] and (3.4), we have<br />P[|Ft(f) − π(f)| ≥ r + α +δ<br />Letting α go to 0 completes the proof of the large-r bound. The proof for r small is essentially<br />the same, citing the small-r bound from Theorem 5 of [JO10] instead of the large-r version<br />cited above.<br />(3.18)<br />κ+ (1 − κ)T−1E(X0)] ≤ 2e−κtr4max(2?S?Lip,3σ∞).<br />?<br />3.4. Tradeoff Lemma. In this section, we prove a simple book-keeping lemma that will be<br />used in Section 4. We consider simulating from a kernel Kǫwith stationary distribution πǫ,<br />where simulating a step of Kǫrequires c(ǫ) units of computational time. We assume that<br />c(ǫ) is monotone decreasing in ǫ. For fixed total computational resources M, we then look<br />at the error of the estimate πTǫ,ǫ(f) ≡<br />Kǫand Tǫ= ⌊M<br />Lemma 3.8 (General Tradeoff). Let F be a class of functions. Suppose that for some<br />collection of constants Ai,ci&gt; 0, for all f ∈ F the following hold:<br />12<br />1<br />Tǫ<br />?Tǫ<br />t=1f(Xt), where Xtis a Markov chain driven by<br />c(ǫ)⌋:</p>  <p>Page 13</p> <p>(1) The bias |πǫ(f) − π(f)| ≤ A1supx∈ΩWd(K(x,·),Kǫ(x,·))c1.<br />(2) The kernel approximation error is bounded by supx∈ΩWd(K(x,·),Kǫ(x,·)) ≤ A2c(ǫ)−c2.<br />(3) For some c3&gt; 0 and some function S(·) with limr→∞S(r) = 0,<br />P<br />?<br />Then, choosing the smallest ǫ that satisfies c(ǫ) ≤ M<br />P<br />?<br />where c4=<br />(1) For some function S(·) with limr→∞S(r) = 0,<br />P<br />?<br />S(r) + A1Tc1<br />(2) The kernel approximation error is bounded by supx∈ΩWd(K(x,·),Kǫ(x,·)) ≤ A2c(ǫ)−c2.<br />Then, choosing ǫ so that c(ǫ) = M−<br />|πTǫ,ǫ(f) − πǫ(f)| &gt; T−c3<br />ǫ<br />r<br />?<br />≤ S(r).<br />c3<br />c3+c1c2, we have for all f ∈ F:<br />2+ r)<br />≤ S(r),<br />|πTǫ,ǫ(f) − π(f)| &gt; M−c4(A1Ac1<br />c3+c1c2. If instead we have<br />?<br />c1c2c3<br />|πTǫ,ǫ(f) − π(f)| &gt; T−c1<br />ǫ<br />r<br />?<br />≤<br />ǫWd(K(x,·),Kǫ(x,·))c2.<br />c1<br />c1+c2c3, we have:<br />P<br />?<br />|πTǫ,ǫ(f) − π(f)| &gt; M−c4(r + Ac1<br />1+ A2)<br />?<br />≤ S(r),<br />where c4=<br />c1c2c3<br />c1+c2c3.<br />Proof of Lemma 3.8. Applying the three initial assumptions above in each step, we compute:<br />P[?πTǫ,ǫ(f) − π(f)? &gt; M−c4(A1Ac1<br />≤ P[?πTǫ,ǫ(f) − πǫ(f)? &gt; rM−c4] + 1?πǫ(f)−π(f)?&gt;A1Ac1<br />≤ S(r) + 1M−c4&lt;T−c3<br />≤ S(r) + 1M−c4&lt;T−c3<br />= S(r),<br />2+ r)]<br />2M−c4<br />ǫ<br />+ 1Wd(K(x,·)−Kǫ(x,·))c1&gt;Ac1<br />+ 1c(ǫ)−c1c2&gt;M−c4<br />2M−c4<br />ǫ<br />where the last line is simple algebra. This completes the proof of the first version of the<br />lemma; the second is essentially the same.<br />?<br />4. Application 1: Austerity Framework<br />In [KCW13], the authors consider the problem that, as one accumulates more and more<br />data, a standard Metropolis-Hastings sampler targetting the associated posterior distribution<br />will become more and more expensive to sample from. This stems from the fact that such<br />a sampler evaluates the full posterior twice in every step, and in particular this normally<br />requires every data point to be used at every step. The authors propose several algorithms<br />that might avoid this problem. In this section, we provide one formalization of the austerity<br />framework and prove various tradeoff results with the application of Corollary 1 and Lemma<br />3.8.<br />To set notation, we consider a Metropolis-Hasting kernel K with proposal kernel L, sta-<br />tionary distribution<br />π(θ) ≡ π(θ|{xi}N<br />i=1) = p(θ)<br />N<br />?<br />i=1<br />π(θ|xi)<br />13</p>  <p>Page 14</p> <p>and acceptance ratio Q as well as an approximating kernel Kǫwith the same proposal kernel<br />L but different stationary distribution πǫand acceptance ratio Qǫ. While K is a Metropolis-<br />Hastings chain and so Q(x,y) = min<br />?<br />Metropolis-Hastings chain. Instead we view Qǫ as a random variable generated by some<br />algorithm to be specified later; we denote by its expected value E[Qǫ] the actual probability<br />of a proposal being accepted. For the approximating chain Kǫ, denote by ℓt+1the proposed<br />point at time t and by utthe U[0,1]-distributed random variable used to determine if the<br />proposal is accepted. Assume that the full data set has N points, and that at every step<br />the acceptance probability Qǫis based on a random sample of n = n(t,Xt,ℓt+1,ǫ,ut) data<br />points, a (possibly random) function of the chain’s current position and time. To formalize<br />the austerity framework, assume that we have a total computational budget of M data<br />points to view in total, over any number of steps of the Markov chain. We would like to<br />choose a function n = n(t,Xt,ℓt+1,ǫ,ut) that (approximately) minimizes the deviation of<br />our estimator<br />1,π(y)L(y,x)<br />π(x)L(x,y)<br />?<br />is a deterministic function, Kǫis not a<br />πT(f) =<br />T<br />?<br />t=1<br />f(Xt),<br />where T = sup{t :?t<br />1.<br />s=1E[n(s,Xs,ℓs+1,ǫ,ut)] ≤ M}. Without specifying the construction<br />of the approximate acceptance ratio Qǫ, our generic construction of Kǫis given in Algorithm<br />Algorithm 1 Austerity Framework<br />Initialize X1= x.<br />For t = 1 to N do<br />Generate ℓt+1from the distribution L(Xt,·).<br />Generate utfrom U[0,1].<br />Generate the (random) acceptance probability Qǫusing n = n(t,Xt,ℓt+1,ǫ,ut) indepen-<br />dent draws from the data.<br />if ut≤ Qǫ(Xt,ℓt+1) then<br />set Xt+1= ℓt+1.<br />else<br />set Xt+1= Xt.<br />end if<br />In [KCW13], they use the construction in Algorithm 2 to find Qǫat time t for data xi∈ Rd.<br />This algorithm requires the following terms:<br />s =<br />?<br />ℓ2− (ℓ)2<br />n − 1<br />Nlog<br />?<br />π(Xt)L(Xt,ℓt+1)<br />π(ℓt+1)L(ℓt+1,Xt)<br />1 −n − 1<br />N − 1,(4.1)<br />µ0=1<br />?<br />ut<br />?<br />.<br />Remark 4.1. All of our results depend on the expected number of points required to simulate<br />an approximate acceptance ratio Qǫthat satisfies ǫ ≥ supx,y|E[Qǫ(x,y)]−Q(x,y)|. We don’t<br />14</p>  <p>Page 15</p> <p>Algorithm 2 Austerity Framework II<br />Fix a constant m and initialize n = 0, S = {x1,...,xN}, X = ∅.<br />While done ?= TRUE, do:<br />Draw a mini-batch X′of size min(m,|S|) without replacement from S and then set S =<br />S\X′, X = X ∪ X′and n = |X|.<br />Compute the sample mean ℓ and sample variance ℓ2for sample X.<br />Estimate s and µ0using Equation (4.1).<br />Compute δ = 1 − φm−1<br />of freedom.<br />if δ &lt; ǫ then<br />Set done = TRUE.<br />end if<br />if If ℓ &gt; µ0then<br />Set Qǫ= 1.<br />else<br />Set Qǫ= 0.<br />end if<br />?<br />|ℓ−µ0<br />s|<br />?<br />; φkis the CDF of Student’s distribution with k degrees<br />give new algorithms for this approximation, but summarize here the growing literature on the<br />topic.<br />• For any subset S ⊂ {xi}N<br />ˆ ρS(θ) = p(θ)<br />i=1, define<br />?<br />x∈S<br />π(θ|x)<br />N<br />|S|.<br />Let S be a sample of size n; if we calculate Qǫusing<br />Qǫ= min<br />?<br />1,<br />ˆ ρS(Xt)L(ℓt+1,Xt)<br />ˆ ρS(ℓt+1)L(Xt,ℓt+1)<br />?<br />(4.2)<br />instead of Algorithm 4, we note that under sufficiently nice conditions (the target<br />distribution being uniformly bounded away from 0 on its support suffices) Hoeffeding’s<br />inequality guarantees an error of at most O(ǫ) using a computational budget of n =<br />O(−ǫ−2log(ǫ)) samples per step.<br />• As discussed in [BDH14], the specialization in [KCW13] can fail to give good approx-<br />imations under certain circumstances (obviously using equation (4.2) can also be a<br />poor choice).<br />• In [BDH14], the authors propose another choice of Qǫand give bounds both on the<br />error of the approximation and the expected computation time. These bounds are<br />quite general, and come with a minimal loss in efficiency: the average computational<br />budget per step is shown to be O(ǫ−2log(ǫ−1)). See that paper for a more thorough<br />discussion of the choice of Qǫ.<br />All of the results below are insensitive to the details of the choice of approximation, and in<br />particular apply to Qǫchosen from either algorithm 4 or equation (4.2).<br />The main theoretical result of [KCW13] is their Theorem 1 on the bias of an approximate<br />Markov chain, as follows:<br />15</p>  <p>Page 16</p> <p>Theorem. For a Metropolis-Hastings algorithm with transition kernel K satisfying the con-<br />traction condition<br />?µK − π?TV≤ (1 − α)?µ − π?TV,<br />we have<br />?π − πǫ?TV≤∆<br />α,<br />where ∆ = supx,y∈Ω|Q(x,y) − E[Qǫ(x,y)]|.<br />This result is strictly weaker than our Lemma 3.2 and is extended by Theorem 4. While<br />the bound in Theorem 4 is qualitatively useful, it doesn’t provide any finite-time bounds for<br />estimates based on the chain. In particular, it doesn’t show that there exist computational<br />budgets M for which there exists some ǫ &gt; 0 for which the kernel Kǫgives more accurate<br />estimates than the kernel K0 = K. In this section, we give a number of tradeoff results<br />showing that Kǫcan indeed give better results, and giving asymptotic results describing the<br />optimal choice of ǫ as M gets large. Our simplest result in this direction is:<br />Theorem 5 (Austerity Tradeoff). Fix a 1-Lipschitz function f, a starting point X0 with<br />finite eccentricity, and a computational budget M. Assume that the base Markov chain K<br />has curvature κ &gt; 0. Assume that there exists a Lipschitz function S(x) ≥<br />that the random estimates Qǫbased on an algorithm with an expected cost of n computational<br />units satisfy<br />Wd(K(x,·),Kǫ(x,·)) ≤ Cn−1<br />Then for<br />M−1<br />P[|π√M,ǫ(f) − π(f)| &gt; rM−1<br />for some function satisfying limr→∞A(r) = 0 that does not depend on m,M or N.<br />Remark 4.2. If we replace inequality (4.3) with the bound Cn−1<br />discussed in Remark 4.1, the same conclusion applies with only a loss of a logarithmic factor<br />in the final bound.<br />σ(x)2<br />ηxκ. Assume<br />2. (4.3)<br />C<br />4&lt; κ, an estimate of Qǫwith a mean cost of<br />1<br />√Msatisfies:<br />4] ≤ A(r),<br />2log(n), as per bounds<br />Remark 4.3. The main point is that, as one’s computational budget M goes to infinity,<br />approximate chains are more efficient than the precise chain under some conditions. It is<br />possible to obtain an error rate of O(M−1<br />4) using approximate kernels independently of the<br />amount of data N available; running the precise kernel gives an error rate of O(<br />computational resources grow sub-quadratically in the amount of data, this is a substantial<br />improvement.<br />?<br />N<br />M). If the<br />We give an example showing that, under assumptions of the form given by inequality (4.3),<br />the O<br />?<br />from πǫ. In particular, the mixing rate of the underlying Markov chain is essentially irrelevant<br />to our conclusions. We also give a simple resampling algorithm for which a much stronger<br />asymptotic rate holds. These examples serve to illustrate the sharpness of our theorem and<br />also the fact that point-wise bounds on the difference between kernels, such as those given<br />16<br />M−1<br />4<br />?<br />rate we obtain is sharp; this remains true even when Kǫgives i.i.d. samples</p>  <p>Page 17</p> <p>by inequality (4.3), are extremely unstructured assumption and give correspondingly weak<br />conclusions.<br />Example 6. We begin by looking at situations that give rise to other rates. Consider the<br />posterior π(θ|{xi}N<br />subset (possibly with repetition) S of {xi}N<br />approximation level n ≤ M,N, we approximate θ as follows. Choose n points uniformly<br />at random with replacement from {xi}N<br />decomposition of variance formula,<br />i=1) = N<br />??N<br />i=1xi<br />N<br />,1<br />N<br />?<br />with approximation πS(θ) = N<br />i=1. For any given computational budget M and<br />??<br />x∈Sx<br />|S|<br />,1<br />N<br />?<br />for any<br />i=1. We then draw θt from πS(θ). By the usual<br />Var<br />?n<br />M<br />M<br />n<br />?<br />t=0<br />θt<br />?<br />= E<br />?<br />n<br />Var?n<br />MN+1<br />M<br />M<br />n<br />?<br />t=0<br />θt<br />???S??<br />+ Var<br />??n<br />M<br />M<br />n<br />?<br />t=0<br />θt<br />???St<br />??<br />=<br />n.<br />In this setting, choosing n = min(M,√MN) is optimal, giving the usual O<br />gence rate as M becomes large much more slowly than N. Although the details change,<br />similar conclusions hold if the set S is resampled at each time t, and also if sampling is done<br />without replacement.<br />?<br />1<br />√M<br />?<br />conver-<br />Example 7. To find simple examples for which the M−1<br />putational budget M and approximation level n ≤ M,N. We define the measure µn =<br />?<br />distribution. We then have<br />4 rate is correct, fix again a com-<br />1 −<br />1<br />√n<br />?<br />U[0,1] +<br />1<br />√nδ0, and consider a sequence of i.i.d. samples θ1,...,θM<br />n<br />from this<br />E<br />??n<br />3<br />4M, giving a decay rate of O<br />M<br />M<br />n<br />?<br />t=1<br />θt−1<br />2<br />?2?<br />=<br />1<br />4n+<br />n<br />3M.<br />The optimal choice is n =<br />our approximation assumption does not allow for the sort of cancellation that occurs in the<br />previous example.<br />?<br />?<br />M−1<br />4<br />?<br />. We can see here that<br />One major difference between these two examples is that, in the first, the approximate<br />measures resulted in unbiased estimates; in the second, the approximate measures were also<br />biased. Assumptions of the form given in equation (4.3) are standard in the literature (see<br />e.g., [KCW13, AFEB14, BDH14]), but cannot detect this difference. It may be interesting<br />to try to understand which subsampling algorithms have a useful structure that inequalities<br />such as (4.3) cannot capture.<br />Example 8. As mentioned in remark 3.3, the curvature assumption used in Theorem 5 is<br />strictly weaker than the assumption made in [KCW13]. Our assumption is slightly weaker<br />than the uniform ergodicity assumption used in [AFEB14]. In particular, if a kernel K is<br />uniformly ergodic, a small power of it will have positive curvature in the Total Variation dis-<br />tance, and so we can obtain (slightly weaker) bounds in that case. In the other direction, our<br />result applies to many chains for which no finite power of the transition kernel is uniformly<br />ergodic.<br />17</p>  <p>Page 18</p> <p>Several examples that are geometrically but not uniformly ergodic, and for which our bounds<br />apply, can be found in [Oll09]. In that paper’s Example 9, the discretization of the Ornstein-<br />Uhlenbeck process dXt= −αXtdt+sdBtwith time-steps of size δ has curvature 1−e−αδand<br />eccentricity E(x) = O(|x|) under the Euclidean metric; thus, our results apply. In the other<br />direction, this kernel is clearly not uniformly ergodic.<br />We now prove Theorem 5:<br />Proof. We plug earlier estimates into Lemma 3.8, with the family F being the collection<br />of 1-Lipschitz functions. The first estimate comes from Lemma 3.2. The second estimate<br />follows from inequality (4.3). The third estimate follows from Theorem 4.<br />?<br />In the following subsections, we prove tradeoff results similar to Theorem 5, under different<br />assumptions.<br />4.1. Drift and Minorization Conditions. When the state space Ω is countable, we have<br />the following related results for chains that are uniformly ergodic:<br />Theorem 9 (Austerity Tradeoff: Uniform Ergodicity). Fix a function f satisfying ?f?∞= 1<br />and a computational budget M. Assume that the base kernel K satisfies Assumptions 3.2 and<br />that the random estimates Qǫbased on an algorithm with an expected cost of n computational<br />units satisfy<br />|E[Qǫ] − Q| ≤ Cn−1<br />Then for some M0that does not depend on N, and M &gt; M0sufficiently large,<br />P[|π√M,ǫ(f) − π(f)| &gt; rM−1<br />for some function satisfying limr→∞A(r) = 0 that does not depend on n, M or N.<br />For chains that are geometrically ergodic, we have the marginally weaker conclusion:<br />2.<br />4] ≤ A(r),<br />Theorem 10 (Austerity Tradeoff: Geometric Ergodicity). Fix a function f satisfying ||f||∞=<br />1 and a computational budget M.<br />Assume that, for all finite sets X, we have supx∈XV (x) ≡ DX &lt; ∞. Assume that the<br />random estimates Qǫbased on an algorithm with an expected cost of n computational units<br />satisfy<br />|E[Qǫ] − Q| ≤ Cn−1<br />Then for some M0that does not depend on N, and M &gt; M0sufficiently large, we have for<br />all q &gt; 0,<br />2.<br />P[|π√M,ǫ(f) − π(f)| &gt; rM−1<br />4(1−1<br />q)] ≤ A(r),<br />where A(r) is some function satisfying limr→∞A(r) = 0 that does not depend on n, M or<br />N.<br />Example 11. This Theorem applies to the Metropolis-Hastings kernel with target distribu-<br />tion π(x) ∝ e−cxon N and proposal kernel L(x,y) =1<br />We begin by proving Theorem 9 and then discussing the small modifications needed to<br />prove Theorem 10.<br />18<br />31|x−y|≤1.</p>  <p>Page 19</p> <p>Proof. We must first show that K satisfies condition (3.15) of Lemma 3.7 for all sets X of<br />the form<br />X = XC= {x ∈ Ω : V (x) &lt; C}.<br />To see this, let V be a drift function for the original kernel K with constants a,b, and let<br />ˆ Xtbe a chain run according to the kernel K restricted to XC. Let Xtbe a copy of the chain<br />run according to K, with Xt=ˆ Xt∈ XC. Then we note that<br />E[V (ˆ Xt+1)|ˆ Xt] = E[V (Xt+1)1V (Xt+1)≤C+ V (Xt)1V (Xt+1)&gt;C|Xt]<br />≤ E[V (Xt+1)|Xt]<br />≤ (1 − a)V (Xt) + b<br />= (1 − a)V (ˆ Xt) + b,<br />where the second line follows from the fact that V (ˆ Xt) ≤ C. Thus, V is also a drift function<br />for for K restricted to XC, with the same constants. In particular, condition (3.15) is satisfied<br />for all sets of the form XC.<br />To complete the proof, we plug earlier estimates into the second part of Lemma 3.8. The<br />first requirement follows from Lemma 3.7. The second estimate follows from the definition<br />of our algorithm with approximation error ǫ =<br />c4=1<br />1<br />√M. This gives c1 = c2=<br />1<br />2, c3 = 1 and<br />4.<br />?<br />We next prove Theorem 10.<br />Proof. We begin by restricting our attention to sets of the form<br />X(s) = {x : Vǫ(x) &lt; s}.<br />For these sets,<br />DX(s)≤ s.<br />Next, fix an exponent m. By inequality (3.10) above, for ǫ &gt; 2m, we have E[Vǫ(Xt+1)m|Xt] ≤<br />(1 − am,ǫ)Vǫ(Xt)m+ bm,ǫfor some am,ǫ&lt; 1 and bm,ǫ&lt; ∞. By Markov’s inequality, then, we<br />have:<br />?1 − P[{Xt}T<br />t=1⊂ X(s)]?= O<br />?T + Vǫ(X1)<br />sm<br />?<br />. (4.4)<br />Combinining this with inequality (3.16), we have for some constant C depending on the<br />initial point X0, all 1 ≤ q ≤ n and all s &gt; 0:<br />P[|πT,δ(f) − π(f)| &gt;<br />r<br />√T<br />+<br />δq<br />(C + s)(1 − θ)q+ (1 − (C + s)(1 − θ)q)<br />≤ e−(1−θ)2r2<br />T<br />q]<br />2(C+s)2+T + C<br />sm<br />.<br />Choosing s = T<br />1<br />m−1, r = uT<br />1<br />m−1and q = log(T)2, this becomes:<br />P[|πT,δ(f) − π(f)| &gt; uT−1<br />2+<br />1<br />m−1+ o<br />?<br />T<br />−1<br />2+<br />1<br />m−1<br />?<br />] ≤ e−(1−θ)2u2<br />2C2<br />+ O<br />?<br />T−<br />1<br />m−1<br />?<br />.(4.5)<br />19</p>  <p>Page 20</p> <p>We plug earlier estimates into the second part of Lemma 3.8. The first requirement follows<br />from Lemma 3.6. The second estimate follows from the definition of our algorithm with<br />approximation error δ =<br />1<br />√M. This gives c1=1<br />2+<br />1<br />m−1, c2=1<br />2, c3= 1 and c4=1<br />4<br />?1 −<br />1<br />m<br />?.<br />?<br />5. Application 2: Exponential Random Graph Models<br />While the austerity framework has so far been discussed, both above and in [KCW13], for<br />i.i.d. data, it makes sense to search for similar bias-variance tradeoffs for MCMC samplers<br />targetting more complicated posterior distributions. In this section, we briefly discuss this<br />problem in the context of the popular exponential random graph models (ERGM), finding<br />an analogue to Theorem 5. Our main result is quantitative enough to show that subsampling<br />can improve the computational efficiency of MCMC estimates in this situation, even though<br />the model is much more complicated. We emphasize that, while this is useful confirmation<br />of our intuition about subsampling, the bounds themselves are not practical. Due to other<br />computational difficulties associated with the ERGM (see e.g., [CD13]), we find it unlikely<br />that subsampling will play an important role in estimation in the near future. In addition,<br />unlike Theorem 5, we do not believe that the bounds in this section are sharp or that they<br />offer practical guidance in the choice of approximating kernel.<br />Recall that the probability of observing a given graph G in an ERGM is given by<br />p(G) = e−?k<br />i=1fi(N)βiTi(G)−f(N)φ(N,β),<br />where G is a graph on N nodes, β = (βi)k<br />of normalizing values, Tiis a collection of graph functions such as number of edges, number<br />of triangles, and φ(N,β) is a normalizing constant. We wish to sample from the posterior<br />distribution of (β1,...,βk) given an observed graph G. We focus on the common situation in<br />which |G| = N is extremely large, and specialize to the case in which Ticounts the number<br />of times the graph Hiis included as a subgraph of the dense graph G. We denote by viand<br />ei≥ 1 the number of vertices and edges of Hi. For example, we might have H1be an edge<br />between two vertices (v1= 2, e1= 1) and H2be a triangle (v2= e2= 3). We then set the<br />normalizing constants fi(n) = n−viand define V = maxiviand E = maxiei.<br />We next describe our biased kernel. Fix a reversible proposal kernel L on the parameter<br />space Rkand let K be the associated Metropolis-Hastings kernel with proposal kernel L and<br />target distribution<br />i=1is a vector of parameters, fi(N) is a collection<br />π(β) ≡ π(β|G) ∝ ρ(β)e−?k<br />i=1fi(N)βiTi(G)−f(N)φ(N,β).<br />To define our approximate kernel Kǫ, we will follow Algorithm 4 with one small modifica-<br />tion. As in Equation (4.2), we will compute Qǫvia an estimate πǫof the target distribution.<br />To do so, will fix n = n(Xt,ǫ), draw a random collection of n ≪ N vertices, and define<br />Gn⊂ G to be the induced subgraph. We then define Ti,ǫ(G) to be the number of times that<br />subgraph Hiappears in Gnand define<br />πǫ(β) ∝ ρ(β)e−?k<br />i=1fi(n)βiTi,ǫ(G)−f(n)φ(n,β).<br />Theorem 12 (Austerity Improvement for ERGM). Fix a computational budget M and a<br />function f of interest with ||f||∞= 1. Assume that the base Markov chain K satisfies<br />?µK − νK?TV≤ (1 − α)?µ − ν?TV<br />20</p>  <p>Page 21</p> <p>for some α &gt; 0 and all distributions µ,ν. Then, fixing ǫ =<br />2<br />E log2(M)<br />1<br />8<br />and choosing an<br />approximation based on n = n(ǫ) = min<br />that<br />?<br />N,2<br />3<br />(Eǫ max(1,?k<br />i=1βi))8?<br />?<br />, we have for all 0 &lt; ǫ &lt; α<br />P<br />?<br />|π<br />M<br />min?<br />N,2<br />3<br />(Eǫ)8?,ǫ(f) − π(f)| &gt; rǫ<br />≤ A(r),<br />for some function satisfying limr→∞A(r) = 0 that does not depend on N or M.<br />Remark 5.1. Before proving this result, it is important to remark on the normalizing con-<br />stant φ(N,β). This constant is necessary in order to run the usual Metropolis-Hastings chain<br />on the space of parameters, and it is generally very hard to estimate. We will ignore this<br />issue for two reasons. The first is that it is a difficult problem, outside of the scope of this<br />paper. The second is that some interesting work has been done on computing this constant<br />precisely for large N in some settings (see e.g., Theorems 3.1 and 4.1 of [CD13]), and we<br />hope that this will make estimates like those in this Theorem easier to apply in the future.<br />Remark 5.2. This convergence rate, in terms of M, is of course very slow. The argument<br />below can be tightened to give a negligibly better bound, but not one that is useful. We<br />point out only that, for N very large, this convergence bound is better than that obtained by<br />choosing n = N at every step.<br />Proof. Our proof is essentially identical to that of Theorem 5; the biggest change is that we<br />need to bound E<br />?<br />Denote by δ?the cut metric on graphs (see e.g. [BCL+06] for a definition). Recall Theorem<br />5.7 of [BCL+06]:<br />min<br />?<br />1,πǫ(x)<br />πǫ(y)<br />??<br />directly, without e.g. using the Berry-Esseen Theorem.<br />Theorem 13. Fix ǫ &gt; 0. Then for n &gt; 2<br />3<br />ǫ8,<br />P[δ?(G,Gn) &gt; ǫ] ≤ ǫ.<br />By Lemma 5.2 of [BCL+06], this implies that for n &gt; 2<br />P[|n−viTi,ǫ(G) − N−viTi(G)| &gt; eiǫ] ≤ ǫ.<br />We note that<br />3<br />ǫ8,<br />(5.1)<br />log<br />?πǫ(β)<br />π(β)<br />?<br />=<br />k<br />?<br />i=1<br />βi<br />?N−viTi(G) − n−viTi,ǫ(G)?.<br />By inequality (5.1), we have that for any ǫ &gt; 0 and n &gt; 2<br />3<br />ǫ8,<br />P[|log<br />?πǫ(β)<br />π(β)<br />?<br />| &gt; Eǫ<br />k<br />?<br />i=1<br />βi] ≤ ǫ.(5.2)<br />In particular, to obtain a uniform upper bound of Eǫ on this ratio with probability at<br />?<br />step. This provides an upper bound onπǫ<br />least 1 − ǫ, it is sufficient to sample n = min N,2<br />3<br />(Eǫmax(1,?k<br />i=1βi))8<br />?<br />points from G at each<br />π, and thus the upper bound<br />?K(x,·) − Kǫ(x,·)?TV&lt; ǫ<br />21<br />(5.3)</p>  <p>Page 22</p> <p>for n = min<br />?<br />N,2<br />3<br />(Eǫ max(1,?k<br />i=1βi))8<br />?<br />. We then follow the remainder of the proof of Theorem<br />5, with inequality (5.3) replacing the estimate of ?K(x,·)− Kǫ(x,·)?TVwherever it appears<br />(including passing it through the calculation in Lemma 3.8).<br />?<br />6. Application 3: Stochastic Gradient Langevin Dynamics<br />Fix a model with parameter vector θ, prior p(θ) and likelihood p(θ|x) for a single data<br />point x. We consider the setting of drawing N i.i.d. points xi,...,xNpoints from this model,<br />where N is extremely large. In their paper [WT11], Welling and Teh introduced the following<br />Stochastic Gradient Langevin Dynamics for sampling from such a posterior without looking<br />at all N data points at every step:<br />θt+1= θt+ǫ<br />2<br />?<br />∇log(p(θt)) +N<br />n<br />n<br />?<br />i=1<br />∇log(p(xti|θt))<br />?<br />+ ηt<br />(6.1)<br />where ǫ,n &gt; 0 are fixed constants, ηt ∼ N(0,ǫ) and xti are a subset of n &lt; N data<br />points chosen uniformly at random. In [WT11], the authors provide useful heuristics for the<br />convergence of this algorithm for fixed n. We will provide rigorous justification and error<br />bounds associated with this convergence, and show that convergence can hold even when the<br />heuristics in [WT11] don’t apply. Although we find convergence estimates, we avoid giving<br />tradeoff theorems such as our Theorem 5. Such results would require careful discussion of<br />the convergence properties of the Langevin dynamics themselves, which is beyond the scope<br />of this paper. Convergence results such as those found in [DT12, RS02, BRH13] could be<br />used to find analogues to our Theorem 5 for the Stochastic Gradient Langevin Dynamics.<br />We begin by comparing the Stochastic Gradient Langevin Dynamics to the full Langevin<br />Dynamics as introduced in [Nea10]:<br />θt+1= θt+ǫ<br />2<br />?<br />∇log(p(θt)) +<br />N<br />?<br />i=1<br />∇log(p(xi|θt))<br />?<br />+ ηt,<br />where the constants are as above. We also define the Gradient Dynamics to be:<br />θt+1= θt+ǫ<br />2<br />?<br />∇log(p(θt)) +<br />N<br />?<br />i=1<br />∇log(p(xi|θt))<br />?<br />,(6.2)<br />where again the constants are as above. We compute:<br />Lemma 6.1 (Approximation of Dynamics). Let K and˜K be the kernels associated with the<br />stochastic gradient Langevin dynamics and the Langevin dynamics respectively, and define<br />V (θ) = supi|∇log(p(xi|θ))|. Then for d the usual Euclidean distance, we have the bound:<br />Wd(K(θ,·),˜K(θ,·)) ≤ǫ2<br />Proof. Let θt evolve according to the Stochastic Gradient Langevin Dynamics, with noise<br />variable η, and let˜θtevolve according to the full Langevin Dynamics, with noise variable ˜ η.<br />We will couple θt+1,˜θt+1started at the same point θt=˜θt= Θ by first choosing the data<br />22<br />4<br />N2<br />nV (θt)2. (6.3)</p>  <p>Page 23</p> <p>points {xti}n<br />i=1and then coupling ηt, ˜ ηtconditional on the points chosen. Define<br />Et=ǫ<br />2<br />N<br />n<br />n<br />?<br />i=1<br />?<br />∇log(p(xti|θt)) −1<br />N<br />N<br />?<br />i=1<br />∇log(p(xi|θt))<br />?<br />and<br />V (θ) = sup<br />i<br />|∇log(p(xi|θ))|.<br />We note that each term in the sum defining Etis bounded by V (θt). Thus, we find:<br />E[E2<br />t] ≤ǫ2<br />4<br />N2<br />nV (θt)2<br />To find inequality (6.3) we set ηt= ˜ ηtand the proof is finished.<br />?<br />Remark 6.2. We note immediately:<br />• If V (θ) is uniformly bounded in θ, this bound together with the fact that the conver-<br />gence rate of the usual Langevin dynamics is order of ǫ can be plugged into Lemma<br />3.2 (or one of the other, similar, lemmas) to show that Stochastic Gradient Langevin<br />dynamics converges when the full Langevin dynamics do, as ǫ goes to 0 sufficiently<br />slowly. This is essentially a rigorous version of the argument in [WT11].<br />• For most familiar distributions on noncompact state spaces, V (θ) is not uniformly<br />bounded. For example, it is not bounded if the model is given by p(x|θ) ∼ N(θ,1).<br />In these situations, the above bounds cannot be used to show convergence.<br />In light of this remark, we suggest three types of convergence theorem that might be<br />useful:<br />(1) Restrict out attention to target distributions for which V (θ) is bounded. In this<br />situation, we obtain straightforward convergence estimates.<br />(2) We consider additional assumptions under which the stochastic gradient Langevin<br />dynamics converge even under the presence of stepwise error that is not uniformly<br />bounded.<br />(3) Allow the number of points n evaluated per step to vary with the location in the<br />state space. If n = n(θ,t) depends on the state space, this allows us to force the<br />appropriately-scaled error δ =<br />the same convergence result will hold, but this will come at a potentially unbounded<br />cost in number of function evaluations. This tension can be resolved by estimating<br />the the mean total number of data points?T<br />We consider these three types of results in order. For case 1,<br />Theorem 14 (Convergence of Stochastic Gradient Langevin Dynamics for Nice Targets).<br />Assume that the Langevin Dynamics associated with parameter ǫ &gt; 0 satisfies:<br />V (θ)2<br />n(θ,t)to be uniformly bounded in θ. In this setting,<br />t=0n(θ,t) used over a run of length T.<br />Wd(Kǫ(x,·),Kǫ(y,·)) ≤ (1 − aǫ)d(x,y)<br />for all x,y and for some function aǫ that satisfies inf0&lt;ǫ&lt;ǫ0<br />Also assume that supθsupi|∇log(p(xi|θ))| ≡ V0&lt; ∞. Finally, define πǫand ˜ πǫto be the<br />23<br />aǫ<br />ǫ&gt; c &gt; 0 for some ǫ0 &gt; 0.</p>  <p>Page 24</p> <p>stationary distributions of the Stochastic Gradient Langevin Dynamics and usual Langevin<br />Dynamics. We conclude that, for all 0 &lt; ǫ &lt; ǫ0,<br />Wd(πǫ, ˜ πǫ) ≤ ǫN2V0<br />Proof. This follows immediately from Lemma 3.2 and Lemma 6.1.<br />4nc.<br />?<br />Remark 6.3. This Theorem applies if π is a log-concave distribution restricted to a compact<br />and convex subset of Euclidean space.<br />Next, we consider case 2. In many natural examples, having a uniformly good approxi-<br />mation of the kernel˜K turns out to be unnecessary, just as in Lemma 3.2:<br />Theorem 15 (Fixed Sample Size Approximation). Fix ǫ &gt; 0. Assume that, for all pos-<br />sible collection of points x1,...,xm, the (deterministic) gradient dynamics associated with<br />p(θ|x1,...,xm), as defined in equation (6.2), have a Lyapunov function Lx1,...,xmwith asso-<br />ciated constants 0 &lt; ax1,...,xm≤ 1 and bx1,...,xm&lt; ∞. Furthermore, assume that<br />|θ|=r|Lx1,...,xm(θ)<br />for any collection of data points x1,...,xmand x′<br />lim<br />r→∞sup<br />Lx′<br />1,...,x′m(θ)− 1| = 0(6.4)<br />1,...,x′<br />mand that<br />sup<br />θ :L0,0,...,0(θ)&lt;cV (θ)2≡ S(c) &lt; ∞<br />(6.5)<br />for all c &gt; 0.<br />Also assume that, for the same ǫ &gt; 0 and any x1,...,xmand δ &gt; 0, there exists a compact<br />set X = X(δ,x1,...,xm) so that for θ / ∈ X,<br />N(θ,ǫ)(Lx1,...,xm) ≤ (1 + δ)Lx1,...,xm(θ)<br />We also assume that for any compact set X, supθ∈XV (θ) ≡ V (X) &lt; ∞. Assume that the<br />Langevin Dynamics kernel associated with parameter ǫ &gt; 0 satisfies:<br />(6.6)<br />Wd(Kǫ(x,·),Kǫ(y,·)) ≤ (1 − aǫ)d(x,y)<br />for all x,y and for some function aǫthat satisfies inf0&lt;ǫ&lt;ǫ0<br />for δ &lt;<br />aǫ<br />ǫ&gt; c &gt; 0 for some ǫ0&gt; 0. Then<br />1−aǫ0<br />10,<br />Wd(θT− p(θ|x1,...,xN)) &lt;δ<br />aǫ<br />+ (1 − aǫ)TE(X0) + TL0,0,...,0(X0)<br />S−1?√4δ<br />Nǫ<br />? .<br />Proof. This result will follow from Lemmas 3.2 and 6.1. Let (a,b) = (a0,0,...,0,b0,0,...,0) be the<br />constants associated with the Lyapunov function L0,...,0with n 0’s. Let δ &lt;1−a<br />10, and define<br />X1= ∪{y1,...,yn}⊂{x1,...,xN}X(δ,y1,...,yn).<br />Then define:<br />R = inf{r : sup<br />|θ|≥r<br />sup<br />{y1,...,yn}⊂{x1,...,xN}|Ly1,...,yn(θ)<br />24<br />L0,...,0(θ)<br />− 1| &lt; δ}</p>  <p>Page 25</p> <p>and set<br />X2= BR(0).<br />Then set X = X1∪ X2. We note that for the Langevin dynamics, and any θt/ ∈ X,<br />1<br />?N<br />≤ (1 − a)(1 + δ)2L0,...,0(θ) + 2b<br />≤<br />2<br />E[L0,...,0(θt+1)|θt= θ] =<br />n<br />?<br />?<br />{y1,...,yn}⊂{x1,...,xN}<br />E[L0,...,0(θt+1)|θt= θ,xti= yi]<br />?<br />1 −1 − a<br />?<br />L0,...,0(θ) + 2b.<br />For a ≥ 0, define Xa= {x : L0,0,...,0(x) ≤ a} ∪ X. By the above inequality and Markov’s<br />inequality, we have:<br />P[Xt/ ∈ Xa|X0] ≤L0,0,...,0(X0) + 2b<br />a<br />and thus<br />1 − P[{Xs}t<br />s=0∈ Xa|X0] ≥ 1 − tL0,0,...,0(X0) + 2b<br />a<br />.(6.7)<br />Define the good set G(δ) = {θ :<br />note that the stochastic gradient dynamics satisfy inequality (6.7), using the same proof as<br />given above. Then combining inequality (6.7) evaluated at a = cδwith the bound in Lemma<br />6.1 and plugging this into Lemma 3.2 with G(δ)cthe set to be avoided, we have:<br />Wd(θT− p(θ|x1,...,xN)) ≤δ<br />aǫ<br />+ 2Tsupx∈Xa∪{X0}L0,0,...,0(x) + 2b<br />ǫ2<br />4<br />N2<br />nV (θ)2≤ δ} and then cδ= sup{c : Xc⊂ G(δ)}. Also<br />+ (1 − aǫ)TE(X0) (6.8)<br />cδ<br />.<br />Expanding the definition of cδ, we see that it is given by:<br />cδ= sup{c : L(θ) ≤ c ⇒ V (θ)2≤1<br />ǫ2<br />4δn<br />N2}<br />and so in particular, for all fixed δ &gt; 0, we have by equation (6.5) that cδ = S−1?√4δ<br />Combining this with inequality (6.8) completes the proof.<br />Nǫ<br />?<br />?<br />.<br />Remark 6.4. The assumptions in Equations (6.4) and (6.6) seem strongest. We point<br />out that the assumption in equation (6.4) holds for most distributions, including e.g. the<br />Normal, Cauchy, exponential, and largely requires that individual data points don’t have too<br />much influence on the distribution. Inequality (6.6) is only slightly stronger; it will hold as<br />long as the density decays no more quickly than e−eCθ2<br />for some C &lt; ∞.<br />Example 16. We point out that Theorem 15 gives asymptotic convergence for some exam-<br />ples where the assumptions of Theorem 14 fail to hold. In particular, we consider a target<br />distribution p(θ|x1,...,xm) = N<br />25<br />??m<br />i=1xi<br />m<br />,1<br />?<br />with an (improper) flat prior. For all D &gt; 0,</p>  <p>Page 26</p> <p>the Langevin dynamics have a Lyapunov function<br />Lx1,...,xm(θ) =<br />?<br />θ −1<br />m<br />m<br />?<br />i=1<br />xi<br />?D<br />with associated constants ax1,...,xm= bx1,...,xm= 0. This Lyapunov function clearly satisfies<br />equation (6.4). The function V (θ) is given by<br />V (θ) = sup<br />i∈[N]|θ − xi|.<br />This is not bounded as a function of θ, and so the conditions of Theorem 14 don’t hold. We<br />have<br />V (θ)2≤ (Lx1,...,xm(θ))<br />2<br />D+ sup<br />i∈[N]<br />?<br />xi−1<br />N<br />N<br />?<br />j=1<br />xj<br />?2<br />uniformly in data points (x1,...,xm) and also in m. Thus, in Equation (6.5), we have<br />S(c) = c<br />2<br />D+ O(1) &lt; ∞.<br />We also note that<br />N(θ,ǫ)(Lx1,...,xm(x)) =<br />?<br />θ −1<br />m<br />m<br />?<br />i=1<br />xi<br />?2<br />+ ǫ2<br />= (Lx1,...,xm(x))(θ) + ǫ2,<br />so inequality (6.6) is satisfied by defining X(δ,x1,...,xm) =<br />The contraction estimate holds with aǫ≡ 1.<br />We conclude that, for fixed 0 &lt; D &lt;<br />decays asymptotically at least as quickly as ǫ<br />asymptotic decay of the bias at the rate of ǫcfor any c &lt; 1. We note that the Langevin<br />dynamics themselves have bias that decays at an asymptotic rate of ǫ.<br />?<br />θ : |θ −<br />1<br />m<br />?m<br />i=1xi| &lt;<br />ǫ<br />√δ<br />?<br />.<br />1<br />2and setting δ = ǫ1+<br />1<br />D+1 Letting D go to 0, we find that we have<br />1<br />D+1, we find that the error<br />Finally, we consider case 3, looking at dynamics for which V (θ) is not bounded. We apply<br />Theorem 14, but set n = n(θ,t) ≡ min<br />applies as stated for this value of V0. For many examples, such as that considered immediately<br />above, the convergence result in Theorem 14 combined with the Law of Large Numbers for<br />Markov chains give effective a.s. bounds on limT→∞<br />V (θt)2is often small outside of the tails of the target distribution, we can often achieve<br />uniform bounds on the approximation quality with minimal extra computational cost.<br />?<br />N,N2ǫ2V (θt)2<br />V2<br />0<br />?<br />for some fixed V0&gt; 0. The result then<br />1<br />T<br />?T<br />t=1n(θt,t). In particular, since<br />7. Global Bias and Mixing Properties<br />In other sections of this paper, we have discussed the situation in which it is computation-<br />ally expensive to run even a single step from some desired kernel K0, and we construct an<br />approximating kernel Kǫwhich is easier to run but gives asymptotically biased results. In<br />that setting, we are trading off bias against a purely local improvement in the MCMC algo-<br />rithm - decreasing the time it takes to calculate individual steps. Although the approximate<br />kernels are easier to run, they may not have better mixing properties than the underlying<br />kernels; indeed, the mixing properties may be significantly worse. In this section, we briefly<br />26</p>  <p>Page 27</p> <p>discuss different ways to trade off bias against a more global improvement in the MCMC<br />algorithm by constructing approximating chains K′<br />than the initial approximations Kǫ, at the cost of a small amount of additional bias. The<br />algorithms in this section are all defined through a global estimate πǫ of π, , though in<br />principle there is no reason to require this.<br />This is a large subject; indeed our recent paper [PM+13] is entirely concerned with a<br />family of approximations that falls into this framework. In this section, we discuss only two<br />very simple examples: one related to the stochastic gradient Langevin dynamics (SGLD)<br />already discussed, the other related to the well-known MCMC variant of the approximately<br />Bayesian computation (ABC) algorithm (see [MPRR12] for a survey).<br />The main observation behind the examples in this section is as follows. For many ap-<br />proximate samplers, including both ABC-MCMC and SGLD, the error d(Kǫ(θ,·),K(θ,·)) of<br />the approximations have a tendency to decay for θ in the tails of the target distributions.<br />For ABC-MCMC, this is discussed in great detail in [LL12]; for SGLD, it is discussed in<br />Section 6 above. In both of these cases, this decay makes the algorithms more difficult to<br />analyze; in the case of ABC-MCMC, this decay results in very poor mixing properties. The<br />simple solution we discuss here is to bias the target distributions towards a global estimate<br />associated with a rapidly-mixing Markov chain.<br />We begin by looking at ABC-MCMC. Recall that the ABC-MCMC algorithm requires a<br />proposal kernel L, a prior π on the parameter ω ∈ Ω of interest, a data-generating model<br />π(·|ω) for each value of the parameter ω, observed data yobs, a pseudo-metric d on the state<br />space, and a tuning parameter ǫ &gt; 0. For any ω ∈ Ω and draw y′∼ π(·|ω), we define the<br />estimate:<br />ǫthat have better convergence properties<br />ˆ πǫ(ω|yobs) = π(ω)1d(yobs,y′)&lt;ǫ. (7.1)<br />The ABC-MCMC algorithm is described in Algorithm 7. The marginal distribution of ω<br />Algorithm 3 ABCMCMC<br />Initialize (ω1,y1)<br />For t = 1 to N do:<br />Generate ω′from L(ωt,·).<br />Generate y′from π(·|ω′).<br />Set ˆ πǫ(ω|yobs) as in Equation (7.1).<br />Generate u from U[0,1].<br />if u ≤<br />Set (ωt+1,yt+1) = (ω′,y′).<br />else<br />Set (ωt+1,yt+1) = (ωt,yt).<br />end if<br />ˆ πǫ(ω′|yobs)L(ω′,ωt)<br />ˆ πǫ(ωt|yobs)L(ωt,ω′)then<br />under this chain’s stationary distribution is given by:<br />πǫ(ω|yobs) = π(ω|{y : d(y,yobs) &lt; ǫ}).<br />As discussed in in [LL12], the Markov chain described by this algorithm often fails to be<br />variance bounding (see [RR08] for definition of variance bounding) and thus also fails to be<br />27</p>  <p>Page 28</p> <p>geometrically ergodic. This problem occurs even for simple posteriors, as when estimating<br />the mean of a normal distribution with known variance.<br />The primary problem is that the acceptance probabilities of this kernel often go to 0 in the<br />tails of the posterior. There are several proposed solutions to this problem in the literature;<br />some, such as those in [LL12] and the related paper [GLS+13], are quite sophisticated.<br />We describe here a very simple solution: for a fixed distribution ρ and constant δ = δ(ǫ),<br />when running this algorithm replace the estimate ˆ πǫ in equation (7.1) with the estimate<br />ˆ π′<br />remainder of this section, is a pseudo-marginal Markov chain in the sense of [AR09], and so<br />in particular is a reversible Markov chain. We note that<br />ǫ= ˆ πǫ+ δρ. The result, which we will call Biased MCMC-ABC (B-MCMC-ABC) for the<br />E[ˆ π′<br />ǫ(ω|yobs)] = E[ˆ πǫ(ω|yobs) + δρ(ω)]<br />= Cπǫ(ω|yobs) + δρ(ω),<br />for some constant C independent of ǫ and δ. Thus, the marginal distribution of ω under this<br />chain’s stationary distribution is given by:<br />πǫ(ω|yobs)′∝ Cπ(ω|{y : d(y,yobs) &lt; ǫ}) + δρ(ω).<br />In particular, for a B-MCMC-ABC algorithm in Rn, the bias of πǫ(ω|yobs)′is O(δ + ǫn), and<br />is thus easy to control; the bias for the usual MCMC-ABC algorithm is O(ǫn).<br />We claim that, for natural target distributions π and priors ρ, this modified algorithm<br />retains variance bounding. We do this by comparing B-MCMC-ABC to a chain with kernel<br />K described by a mixture of two kernels, K1and K2. Denote by Q the kernel associated<br />with B-MCMC-ABC, and q its associated acceptance function. K1is a Metropolis-Hastings<br />algorithm that has the same proposal kernel L and stationary distribution as B-MCMC-<br />ABC; denote by k1its acceptance function. K2is the chain that doesn’t move. We write<br />K = αK1+ (1 − α)K2, where α = sup{a : supx,y<br />Proposition 7.1. If α &lt; 1 and K is variance bounding, then Q is variance bounding.<br />ak1(x,y)<br />q(x,y)≤ 1}. We have<br />Proof. By the definition of α, if α &lt; 1 then K(x,A) ≤ Q(x,A) for all x and all A satisfying<br />A ∩ {x} = ∅. Thus, Q inherits the variance bounding property from K via Theorem 8 of<br />[RR08].<br />?<br />Remark 7.2. We note that α &lt; 1 occurs in great generality. In particular, this works for the<br />prototypical example of π(·|ω) = N(ω,1) for ω ∈ R, π(ω) = N(0,10) and L(x,·) = N(x,0.1)<br />where we allow for shrinkage towards a slightly stretched version of the actual prior, so that<br />ρ(ω) = N(0,20). In this situation, we have for all δ sufficiently small relative to ǫ and all<br />sufficiently large ω that<br />k1(x,y)<br />q(x,y)= Ω(δ) .<br />We now look at notions of shrinkage for stochastic gradient Langevin dynamics. As dis-<br />cussed in Section 6, the SGLD can be arbitrarily far from the full Langevin dynamics that<br />they are approximating. This can occur even for very simple target posterior distributions,<br />such as a normal distribution with known variance. Even though this algorithm is relatively<br />new, some modifications in the literature already ameliorate this problem; see e.g., [CFG14].<br />In this section, we discuss a much simpler modification.<br />28</p>  <p>Page 29</p> <p>We follow the notation in Section 6. For constant 0 &lt; C = C(θ,δ,ǫ,n,N) &lt; 1, we modify<br />Equation (6.1) as follows:<br />θt+1= θt+ǫ<br />2<br />?<br />C∇log(p(θt)) + (1 − C)N<br />n<br />n<br />?<br />i=1<br />∇log(p(xti|θt))<br />?<br />+ ηt; (7.2)<br />we call this “shrunk-SGLD” or SSGLD. If we fix δ &gt; 0 and choose<br />C = 1 − min<br />?<br />1,<br />√4δn<br />ǫNV (θ)<br />?<br />,<br />we can guarantee that the SSGLD stay within δ of the associated shrunken Langevin dy-<br />namics (SLD) given by<br />θt+1= θt+ǫ<br />2<br />?<br />C∇log(p(θt)) + (1 − C)<br />N<br />?<br />i=1<br />∇log(p(xi|θt))<br />?<br />+ ηt,<br />as measured by Wasserstein distance. In particular, Theorem 14 applies to the comparison of<br />these two ‘shrunk’ dynamics. If the prior p is log-convex and V (θ) satisfies supθ∈X|V (θ)| &lt; ∞<br />for all compact sets X, Theorem 3.1 also implies that the shrunken Langevin dynamics<br />converge to the standard Langevin dynamics as ǫ goes to 0. Thus, as long as p is log-convex<br />and supθ∈X|V (θ)| &lt; ∞ for all compact sets X, the SSGLD converges to the SLD as δ goes<br />to 0 and the SLD converges to the LD as ǫ goes to 0. In particular, under these conditions<br />the SSGLD converges to the correct stationary distribution when the LD does.<br />Acknowledgements<br />NSP is partially supported by NSF and ONR grants.<br />References<br />[AFEB14] P. Alquier, N. Friel, R. Everitt, and A. Boland. Noisy monte carlo: Convergence<br />of markov chains with approximate transition kernels. Preprint, 2014.<br />[AR09] Christophe Andrieu and Gareth Roberts. The pseudo-marginal approach for<br />efficient monte carlo computations. Annals of Statistics, 37(2):1139–1160, 2009.<br />[BCL+06] Christian Borgs, Jennifer Chayes, L´ aszl´ o Lov´ asz, Vera Sos, Balasz Szegedy, and<br />Katalina Vesztergombi. Counting Graph Homomorphisms, volume Topics in Dis-<br />crete Mathematics. Springer, 2006.<br />[BDH14] Remi Bardenet, Arnaud Doucet, and Chris Holmes. Towards scaling up markov<br />chain monte carlo: an adapative subsampling approach. Preprint, 2014.<br />[Bea03] M.A. Beaumont. Estimation of population growth or decline in genetically mon-<br />itored populations. Genetics, (164):1139–1160, 2003.<br />[BRH13] N. Bou-Rabee and M. Hairer. Nonasymptotic mixing of the mala algorithm.<br />IMA Journal of Numerical Analysis, (33):80–110, 2013.<br />[CD13] Sourav Chatterjee and Persi Diaconis. Estimating and understanding exponential<br />random graph models. Annals of Statistics, 41(5):2428–2461, 2013.<br />[CFG14] Tianqi Chen, Emily Fox, and Carlos Guestrin. Stochastic gradient hamiltonian<br />monte carlo. Preprint, 2014.<br />[DT12] A. Dalalyan and A.B. Tsybakov. Sparse regression learning by aggregation and<br />langevin. J. Comput. System Sci., 78(5):1423–1443, 2012.<br />29</p>  <p>Page 30</p> <p>[GLS+13] Mark Girolami, Anne-Marie Lyne, Heiko Strathmann, Daniel Simpson, and Yves<br />Atchade. Playing russian roulette with intractable likelihoods. Preprint, 2013.<br />[JO10] Alderic Joulin and Yann Ollivier. Concentration, curvature and error estimates<br />for Markov chain Monte Carlo. Ann. Prob., 38:2418–2442, 2010.<br />[Jor13] Michael Jordan. On statistics, computation and scalability. Preprint, 2013.<br />[KCW13] Anoop Korattikara, Yutian Chen, and Max Welling. Austerity in mcmc land:<br />Cutting the metropolis-hastings budget. Preprint, 2013.<br />[KW13] Aryeh Kontorovitch and Roi Weiss.<br />wolfowitz-type inequalities for markov chains and related processes. Preprint,<br />2013.<br />[LL12] Anthony Lee and Krzysztof Latuszynski. Variance bounding and geometric er-<br />godicity of markov chain monte carlo kernels for approximate bayesian compu-<br />tation. Preprint, 2012.<br />[Mit05] A.Y. Mitrophanov. Sensitivity and convergence of uniformly ergodic markov<br />chains. Journal of Applied Probability, 42:1003–1014, 2005.<br />[MPRR12] Jean-Michel Marin, Pierre Pudlo, Christian Robert, and Robin Ryder. Approx-<br />imate bayesian computational methods. Statistics and Computing, 22(6):1167–<br />1180, 2012.<br />[Nea10] Radford Neal. Mcmc using hamiltonian dynamics. Handbook of Markov Chain<br />Monte Carlo, 2010.<br />[OBB+00] P.D. O’Neil, D.J. Balding, N.G. Becker, M. Eerola, and D. Mollison. Analyzes of<br />infectious disease data from houseing the expected value of ratios, hold outbreaks<br />by markov chain monte carlo methods. Appl. Statist., (49):517–542, 2000.<br />[Oll09] Yann Ollivier. Ricci curvature of markov chains on metric spaces. J. Funct.<br />Anal., 256(3):810–864, 2009.<br />[PM+13] Conrad Patrick, Youssef Marzouk, , Natesh Pillai, and Aaron Smith. Accelerating<br />mcmc with local quadratic models. Preprint, 2013.<br />[Ros95] Jeffrey Rosenthal. Minorization conditions and convergence rates for Markov<br />chain Monte Carlo. JASA, 90:558–566, 1995.<br />[RR08] Gareth O Roberts and Jeffrey S Rosenthal. Variance bounding markov chains.<br />Annals of Applied Probability, 18(3):1201–1214, 2008.<br />[RS02] G. Roberts and O. Stramer. Langevin diffusions and metropolis-hastings algo-<br />rithms. Methodology and Computing in Applied Probability, 4:337–357, 2002.<br />[RT96] Gareth O. Roberts and Richard L. Tweedie. Geometric convergence and cen-<br />tral limit theorems for multidimensional hastings and metropolis algorithms.<br />Biometrika, 83(1):95–110, 1996.<br />[Vil08] Cedric Villani. Optimal Transport: Old and New. Springer, 2008.<br />[WT11] M. Welling and Y. Teh. Bayesian learning via stochastic gradient langevin dy-<br />namics. Proceedings of the 28th International Conference on Machine Learning<br />(ICML), pages 681–688, 2011.<br />Uniform chernoff and dvoretzky-kiefer-<br />30</p>   </div> <div id="rgw20_56ab9ecea4af6" class="c-box pub-resource-container js-toggle" style=""> <h4 class="lf js-expand-list"><small><a href="javascript:" class="lf">View other sources <span class="ico-expand-list"></span></a></small></h4> <h4 class="lf js-collapse-list hidden"><small><a href="javascript:" class="lf">Hide other sources <span class="ico-collapse-list"></span></a></small></h4> <div class="clear"></div> <div class="scroll-wrapper hidden"> <ul class="files-list c-list" id="rgw21_56ab9ecea4af6">  <li class="c-list-item pub-resource-item"  data-type="fulltext" id="rgw22_56ab9ecea4af6"> <span class="ico-pub"></span> <div class="file-content"> <div class="download"> <a href="http://de.arxiv.org/pdf/1405.0182" target="_blank" rel="nofollow" class="publication-viewer" title="Ergodicity of Approximate MCMC Chains with Applications to Large Data Sets">Ergodicity of Approximate MCMC Chains with Applica...</a> </div>  <div class="details">   Available from <a href="http://de.arxiv.org/pdf/1405.0182" target="_blank" rel="nofollow">de.arxiv.org</a>  </div>    </div> </li>  </ul> </div> </div> </noscript> <div class="clearfix"> <div class="action-container">  </div> <div class="pub-legal"> Data provided are for informational purposes only. Although carefully collected, accuracy cannot be guaranteed. The impact factor represents a rough estimation of the journal's impact factor and does not reflect the actual current impact factor. Publisher conditions are provided by RoMEO. Differing provisions from the publisher's actual policy or licence agreement may be applicable. </div>   </div> </div> <div class="clearfix">     <div id="rgw24_56ab9ecea4af6" class="c-box pub-resource-container js-toggle" style="display: none;"> <h4 class="lf js-expand-list"><small><a href="javascript:" class="lf">View other sources <span class="ico-expand-list"></span></a></small></h4> <h4 class="lf js-collapse-list hidden"><small><a href="javascript:" class="lf">Hide other sources <span class="ico-collapse-list"></span></a></small></h4> <div class="clear"></div> <div class="scroll-wrapper hidden"> <ul class="files-list c-list" id="rgw25_56ab9ecea4af6">  </ul> </div> </div>   <div id="rgw16_56ab9ecea4af6" class="similar-publications"> <h2>Similar Publications</h2> <ul class="list-bordered">  <li class="c-list-item li-publication-teaser" id="rgw17_56ab9ecea4af6"> <div> <h5> <a href="publication/253767315_Confocal_scanning_beam_laser_microscopemacroscope_applications_requiring_large_data_sets" class="color-inherit ga-similar-publication-title"><span class="publication-title">Confocal scanning beam laser microscope/macroscope: applications requiring large data sets</span></a>  </h5>  <div class="authors"> <a href="researcher/6797928_Arthur_E_Dixon" class="authors ga-similar-publication-author">Arthur E. Dixon</a>, <a href="researcher/35337700_Savvas_Damaskinos" class="authors ga-similar-publication-author">Savvas Damaskinos</a>, <a href="researcher/2005555917_Alfonso_Ribes" class="authors ga-similar-publication-author">Alfonso Ribes</a>, <a href="researcher/2026403156_Eileen_Seto" class="authors ga-similar-publication-author">Eileen Seto</a>, <a href="researcher/2026249018_Marie-Claude_Beland" class="authors ga-similar-publication-author">Marie-Claude Beland</a>, <a href="researcher/2026380954_Tetsu_Uesaka" class="authors ga-similar-publication-author">Tetsu Uesaka</a>, <a href="researcher/2026377508_Brian_E_Dalrymple" class="authors ga-similar-publication-author">Brian E. Dalrymple</a>, <a href="researcher/6925260_Sid_P_Duttagupta" class="authors ga-similar-publication-author">Sid P. Duttagupta</a>, <a href="researcher/6152697_Philippe_M_Fauchet" class="authors ga-similar-publication-author">Philippe M. Fauchet</a>  </div>  </div> <div class="clear"></div> </li>  <li class="c-list-item li-publication-teaser" id="rgw18_56ab9ecea4af6"> <div> <h5> <a href="publication/272299964_1_%27%27%27%27%27%27%27_%27_Forecasting_with_Large_Data_Sets_Part_1_%27Forecasting_Methods_Using_Large_Data_Sets%27" class="color-inherit ga-similar-publication-title"><span class="publication-title">. 1 &#39;&#39;&#39;&#39;&#39;&#39;&#39; &#39; (Forecasting with Large Data Sets. Part 1 &#39;Forecasting Methods Using Large Data Sets&#39;)</span></a>  </h5>  <div class="authors"> <a href="researcher/2066719926_Ekaterina_V_Astafeva" class="authors ga-similar-publication-author">Ekaterina V. Astaf&#39;eva</a>, <a href="researcher/2066531656_Marina_Turuntseva" class="authors ga-similar-publication-author">Marina Turuntseva</a>  </div>  </div> <div class="clear"></div> </li>  <li class="c-list-item li-publication-teaser" id="rgw19_56ab9ecea4af6"> <div> <h5> <a href="publication/41885633_Large_data_sets_proceedings_of_a_symposium_on_how_to_manage_and_analyse_very_large_data_sets" class="color-inherit ga-similar-publication-title"><span class="publication-title">Large data sets proceedings of a symposium on how to manage and analyse very large data sets</span></a>  </h5>  <div class="authors"> <a href="researcher/36720210_S_Heisterkamp" class="authors ga-similar-publication-author">S. Heisterkamp</a>, <a href="researcher/20410465_Ruud_H_eds_Koning" class="authors ga-similar-publication-author">Ruud H. (eds.) Koning</a>  </div>  </div> <div class="clear"></div> </li>  </ul> </div> </div> </div> </div> </div></div></div>
<div class="clear"></div><div id="rgw30_56ab9ecea4af6" class="default-footer"> <div id="footer" class="clearfix"> <span class="footer-left"> &copy; 2008&dash;2016 researchgate.net. All rights reserved. </span> <span class="footer-right"> <a href="https://www.researchgate.net/about">About us</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="https://www.researchgate.net/contact">Contact us</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="careers">Careers</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="developers">Developers</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="blog" target="_blank">News</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="application.PrivacyPolicy.html">Privacy</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="application.TermsAndConditions.html">Terms</a> <span class="footer-link-separator" style="padding: 0 5px;">&nbsp;|&nbsp;</span> <a href="advertising?_ref=ft">Advertising</a> <span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="recruiters?_ref=ft">Recruiting</a> </span> </div>  </div></div>
<div id="rgw31_56ab9ecea4af6">  <div class="header-wrapper-logged-out"> <div id="header"> <div class="header-content"> <a href="" class="g-l-logo"> <svg width="149" height="19"> <image xlink:href="https://c5.rgstatic.net/m/235107188705592/images/template/brand-header-logo.svg" src="https://c5.rgstatic.net/m/238113351022438/images/template/brand-header-logo.png" width="149" height="19"/> </svg> </a> <a href="" class="g-l-logo-ico"> <svg width="127" height="17" viewbox="0 0 127 22"> <image xlink:href="https://c5.rgstatic.net/m/235107188705592/images/template/brand-header-logo.svg" src="https://c5.rgstatic.net/m/238113351022438/images/template/brand-header-logo.png" width="127" height="17"/> </svg> </a> <div id="rgw32_56ab9ecea4af6" class="header-login-wrapper js-header-login"> <div class="dropdown-right-align"> <div class="login-signup-container lf"> <a href="https://www.researchgate.net/signup.SignUp.html?ev=su_chnl_index&amp;hdrsu=1&amp;_sg=LfpqjHB29GhL14GLbsTJNTbAYWoYbUts2sdSL6cfjCmu1YLKAzGDcZLokcBjP2v3" class="dropdown-toggle lf">Join for free</a> </div> <div class="dropdown lf" style="height: 20px;"> <a href="https://www.researchgate.net/application.Login.html" class="js-login-url dropdown-toggle lf">Log in <span class="caret"></span></a> <div class="dropdown-menu"> <div class="header-login-form-wrapper"> <!--[if IE 6]><p class="box-warning" style="margin-bottom: 0;">Sorry, ResearchGate no longer supports the version of Internet Explorer you are using. <a href="http://whatbrowser.org/" rel="nofollow" target="_blank">Update your web browser</a> and then log in. </p><![endif]--> <form method="post" action="https://www.researchgate.net/application.Login.html" class="form-big header-login-form js-login-form" name="loginForm" id="headerLoginForm"> <input type="hidden" name="request_token" value="R8WJfn+DNZM9xOOKGsFgn4rzlwcqHOa/abvAOX0EqshCybVC5HQS+e+q8P/KfTNxWC0m7DXYsGhqzkx7oMDBQset+5Sxmn/CpUWU3e9AM7lixGVl9CYTUcbmAjEhlgCAVli2X2FZq7oeWgXHORgMHVPL6L90Q9h9c65R0wZ+RyasLwEjDQ9M+SpTOHZ9KyCRVQylGjYwiCx5keBsKBf7mgJ6sYehMg5X2gAdVkfYg3pqaq3/+64+JoZH7U0N/KSVXwxo6HBE+0t/z4m5SR7MbtM2eEwEJuqBhRluLjMVsl8="/> <input type="hidden" name="urlAfterLogin" value="publication/262030260_Ergodicity_of_Approximate_MCMC_Chains_with_Applications_to_Large_Data_Sets"/> <input type="hidden" name="invalidPasswordCount" value="0"/> <input type="hidden" name="headerLogin" value="yes"/> <label for="input-header-login">Email</label> <div class="login-input"> <div class="info-tip-wrapper"> <span class="ico-info js-info"></span> </div> <input type="email" value="" name="login" class="login js-login-input text" id="input-header-login" tabindex="1"/> </div> <div class="clear"></div> <label class="lf" for="input-header-password"> Password </label> <a class="rf forgot-password js-forgot-password" href="application.LostPassword.html">Forgot password?</a> <div class="clear"></div> <input type="password" value="" name="password" class="password js-password-input text" id="input-header-password" tabindex="2"/> <div class="clear"></div> <label class="remember-me" for="headerLoginCookie"> <input type="checkbox" checked="checked" value="yes" name="setLoginCookie" class="lf checkbox" id="headerLoginCookie" tabindex="3"/> Keep me logged in </label> <div class="clear"></div> <input value="Log in" name="loginSubmit" class="btn btn-promote btn-fullwidth btn-large allow-leave js-submit-button" type="submit" tabindex="4"/> </form> <div class="connectors"> <div class="text">or log in with</div> <div class="connector-actions"> <a href="connector/linkedin/" class="li-connect js-li-connect" data-redirect-url="cHVibGljYXRpb24vMjYyMDMwMjYwX0VyZ29kaWNpdHlfb2ZfQXBwcm94aW1hdGVfTUNNQ19DaGFpbnNfd2l0aF9BcHBsaWNhdGlvbnNfdG9fTGFyZ2VfRGF0YV9TZXRz"> <span class="icon ico-linkedin-round-grey"></span> <span class="icon ico-linkedin-round"></span> </a> <a href="connector/facebook/" class="fb-connect middle js-fb-connect" data-redirect-url="cHVibGljYXRpb24vMjYyMDMwMjYwX0VyZ29kaWNpdHlfb2ZfQXBwcm94aW1hdGVfTUNNQ19DaGFpbnNfd2l0aF9BcHBsaWNhdGlvbnNfdG9fTGFyZ2VfRGF0YV9TZXRz"> <span class="icon ico-facebook-round-grey"></span> <span class="icon ico-facebook-round"></span> </a> <a href="connector/google/" class="g-connect js-g-connect" data-redirect-url="cHVibGljYXRpb24vMjYyMDMwMjYwX0VyZ29kaWNpdHlfb2ZfQXBwcm94aW1hdGVfTUNNQ19DaGFpbnNfd2l0aF9BcHBsaWNhdGlvbnNfdG9fTGFyZ2VfRGF0YV9TZXRz"> <span class="icon ico-google-round-grey"></span> <span class="icon ico-google-round"></span> </a> </div> </div> </div> </div> </div> </div> </div> </div> </div> <script type="application/ld+json">
{ "@context" : "http://schema.org",
  "@type" : "Organization",
  "name" : "ResearchGate",
  "url" : "http://www.researchgate.net",
  "logo" : "http://www.researchgate.net/images/template/rg_logo_square_brand.png",
  "sameAs" : [ "https://www.facebook.com/ResearchGate",
    "https://twitter.com/ResearchGate",
    "https://plus.google.com/+researchgate",
    "https://www.linkedin.com/company/researchgate"] 
}
</script> </div> </div><div class="c-signup-bar" id="rgw33_56ab9ecea4af6"> <div class="banner-contents">   <span class="message">ResearchGate is the professional network for scientists and researchers.</span> <a href="signup.SignUp.html?ev=su_banner" class="btn btn-large btn-promote">Join for free</a>  </div> </div></div>
<script>
rgConfig.backendTime = 1070;
</script>
<script src="//c5.rgstatic.net/m/2277196935388619/javascript/lib/yui3/yui/yui-min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/21832295316281274/javascript/yuiLoaderConfig-min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/23178613132105398/javascript/vendor/babel-core/browser-polyfill.min.js" type="text/javascript"></script>
<script>
(function (){
if (typeof YRG === "undefined") {
var xmlHttpRequest = new XMLHttpRequest();
xmlHttpRequest.open("post", "go.Error.html");
xmlHttpRequest.setRequestHeader("Content-Type", "application/json");
xmlHttpRequest.setRequestHeader("Accept", "application/json"); var loadedScripts = "";
if (window.performance && window.performance.getEntriesByType) {
    var result = [];
    var resources = performance.getEntriesByType("resource");
    for (var i in resources) {
        if (resources.hasOwnProperty(i)) {
            result.push({
                name: resources[i].name,
                duration: resources[i].duration
            });
        }
    }
    loadedScripts += "&loadedScripts=" + encodeURIComponent(JSON.stringify(result));
}
if (typeof YUI === "undefined") {
    loadedScripts += "&yuiLoaded=false";
} else {
    loadedScripts += "&yuiLoaded=true";
}
xmlHttpRequest.send("Type=InformationException&message=" + encodeURIComponent("Error loading YUI") + loadedScripts);
}
})();
</script>
<script>if (typeof YRG !== 'undefined') { YRG.use('rg-base',function(Y){Y.applyConfig({ignore: ["css-rg","css-rg2","css-ie","css-modules-publicprofile"]});Y.use(["rg.core.pagespeed.Monitoring"],function(Y){(function(){Y.rg.createInitialWidget({"data":{"content":{"data":{"profileSmallHeader":{"data":{"profileBadge":{"data":{"profileUrl":"researcher\/15521032_Natesh_S_Pillai","fullname":"Natesh S. Pillai","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2549355721578\/images\/template\/default\/profile\/profile_default_m.png","profileStats":[{"data":{"impactPoints":"48.87","widgetId":"rgw5_56ab9ecea4af6"},"id":"rgw5_56ab9ecea4af6","partials":[],"templateName":"publicliterature\/stubs\/PublicLiteratureAuthorImpactPoints.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicLiteratureAuthorImpactPoints.html?authorUid=15521032","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"publicationCount":51,"widgetId":"rgw6_56ab9ecea4af6"},"id":"rgw6_56ab9ecea4af6","partials":[],"templateName":"publicliterature\/stubs\/PublicLiteratureAuthorPublicationCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicLiteratureAuthorPublicationCount.html?authorUid=15521032","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"followerCount":1,"widgetId":"rgw7_56ab9ecea4af6"},"id":"rgw7_56ab9ecea4af6","partials":[],"templateName":"publicliterature\/stubs\/PublicLiteratureAuthorFollowerCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicLiteratureAuthorFollowerCount.html?authorUid=15521032","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"widgetId":"rgw4_56ab9ecea4af6"},"id":"rgw4_56ab9ecea4af6","partials":[],"templateName":"publicprofile\/stubs\/ProfileBadge.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicLiteratureAuthorBadge.html?authorUid=15521032","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw3_56ab9ecea4af6"},"id":"rgw3_56ab9ecea4af6","partials":[],"templateName":"publicprofile\/stubs\/ProfileSmallHeader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicprofile.ProfileSmallHeader.html?publicationUid=262030260","viewClass":null,"yuiModules":["css-modules-publicprofile"],"stylesheets":["modules\/publicprofile.css"],"_isYUI":true},"publication":{"data":{"publicationUid":262030260,"title":"Ergodicity of Approximate MCMC Chains with Applications to Large Data Sets","journalTitle":false,"journalDetailsTooltip":false,"affiliation":false,"type":"Article","details":{"journalInfos":{"journal":"","publicationDate":"05\/2014;","publicationDateRobot":"2014-05","article":""}},"source":{"sourceUrl":"http:\/\/arxiv.org\/abs\/1405.0182","sourceName":"arXiv"},"publicationActions":null,"publicationCoins":{"data":{"tags":[{"key":"ctx_ver","value":"Z39.88-2004"},{"key":"rft_val_fmt","value":"info:ofi\/fmt:kev:mtx:journal"},{"key":"rfr_id","value":"info:sid\/researchgate.net:researchgate"},{"key":"rft.atitle","value":"Ergodicity of Approximate MCMC Chains with Applications to Large Data Sets"},{"key":"rft.date","value":"2014"},{"key":"rft.au","value":"Natesh S. Pillai,Aaron Smith"},{"key":"rft.genre","value":"article"}],"widgetId":"rgw9_56ab9ecea4af6"},"id":"rgw9_56ab9ecea4af6","partials":[],"templateName":"publicliterature\/stubs\/PublicationCoins.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationCoins.html?publicationUid=262030260","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationAuthors":{"data":{"publicationUid":262030260,"peopleItems":[{"data":{"authorUrl":"researcher\/15521032_Natesh_S_Pillai","authorNameOnPublication":"Natesh S. Pillai","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg","imageSize":"s","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Natesh S. Pillai","profile":{"professionalInstitution":{"professionalInstitutionName":false,"professionalInstitutionUrl":null}},"professionalInstitutionName":false,"professionalInstitutionUrl":null,"url":"researcher\/15521032_Natesh_S_Pillai","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":true,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":false,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"widgetId":"rgw12_56ab9ecea4af6"},"id":"rgw12_56ab9ecea4af6","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAuthorItem.html?entityId=15521032&imageSize=l&enableAuthorInviteButton=0","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"largeTooltip":false,"useRebrandedImageStyle":null,"widgetId":"rgw11_56ab9ecea4af6"},"id":"rgw11_56ab9ecea4af6","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorItem.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorItem.html?authorUid=15521032&authorNameOnPublication=Natesh%20S.%20Pillai","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true},{"data":{"authorUrl":"researcher\/2031323220_Aaron_Smith","authorNameOnPublication":"Aaron Smith","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg","imageSize":"s","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Aaron Smith","profile":{"professionalInstitution":{"professionalInstitutionName":false,"professionalInstitutionUrl":null}},"professionalInstitutionName":false,"professionalInstitutionUrl":null,"url":"researcher\/2031323220_Aaron_Smith","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":true,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":false,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"widgetId":"rgw14_56ab9ecea4af6"},"id":"rgw14_56ab9ecea4af6","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAuthorItem.html?entityId=2031323220&imageSize=l&enableAuthorInviteButton=0","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"largeTooltip":false,"useRebrandedImageStyle":null,"widgetId":"rgw13_56ab9ecea4af6"},"id":"rgw13_56ab9ecea4af6","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorItem.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorItem.html?authorUid=2031323220&authorNameOnPublication=Aaron%20Smith","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true}],"hasMore":false,"nextOffset":6,"useRebrandedImageStyle":null,"widgetId":"rgw10_56ab9ecea4af6"},"id":"rgw10_56ab9ecea4af6","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorList.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorList.html?publicationUid=262030260&context=pubdetail_authors_xflw&showContactAuthorButton=1","viewClass":"views.publicliterature.PublicationDetailAuthorListView","yuiModules":["rg.views.publicliterature.PublicationDetailAuthorListView"],"stylesheets":[],"_isYUI":true},"publicationAbstract":{"data":{"publicationUid":262030260,"abstract":"<noscript><\/noscript><div>In many modern applications, difficulty in evaluating the posterior density<br \/>\nmakes performing even a single MCMC step slow. This difficulty can be caused by<br \/>\nintractable likelihood functions, but also appears for routine problems with<br \/>\nlarge data sets. Many researchers have responded by running approximate<br \/>\nversions of MCMC algorithms. In this note, we develop quantitative bounds for<br \/>\nshowing the ergodicity of these approximate samplers. We then use these bounds<br \/>\nto study the bias-variance trade-off of approximate MCMC algorithms. We apply<br \/>\nour results to simple versions of recently proposed algorithms, including a<br \/>\nvariant of the &quot;austerity&quot; framework of Korratikara et al.<\/div>","canEdit":false,"isAdmin":false,"isArtifact":false,"showFullAbstract":false,"widgetId":"rgw15_56ab9ecea4af6"},"id":"rgw15_56ab9ecea4af6","partials":[],"templateName":"publicliterature\/stubs\/PublicationAbstract.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationAbstract.html?publicationUid=262030260","viewClass":"views.publicliterature.PublicationAbstractView","yuiModules":["rg.views.publicliterature.PublicationAbstractView"],"stylesheets":[],"_isYUI":true},"publicationKeywords":null,"publicationState":null,"isGuest":true,"isAdminEditingAllowed":false,"isArtifact":false,"figureListWidget":null,"previewImage":"https:\/\/i1.rgstatic.net\/publication\/262030260_Ergodicity_of_Approximate_MCMC_Chains_with_Applications_to_Large_Data_Sets\/links\/54c7078b0cf22d626a361153\/smallpreview.png","nativeAdDisclosure":null,"showFollowPublicationButton":false,"followPublicationPromo":"","widgetId":"rgw8_56ab9ecea4af6"},"id":"rgw8_56ab9ecea4af6","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailItem.html","templateExtensions":["generalHelpers"],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailItem.html?publicationUid=262030260&showActionBar=0&showContactAuthorButton=1&showRequestFulltextExperience=0&showNoRgAuthorsRequestFulltextExperience=0&showFollowPublicationPromo=0","viewClass":"views.publicliterature.PublicationDetailItemView","yuiModules":["rg.views.publicliterature.PublicationDetailItemView"],"stylesheets":[],"_isYUI":true},"similarPublications":{"data":{"publicationListItems":[{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":6797928,"url":"researcher\/6797928_Arthur_E_Dixon","fullname":"Arthur E. Dixon","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":35337700,"url":"researcher\/35337700_Savvas_Damaskinos","fullname":"Savvas Damaskinos","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2005555917,"url":"researcher\/2005555917_Alfonso_Ribes","fullname":"Alfonso Ribes","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":{"id":2026403156,"url":"researcher\/2026403156_Eileen_Seto","fullname":"Eileen Seto","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},"surplusAuthors":5,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Mar 1995","journal":"Proceedings of SPIE - The International Society for Optical Engineering","showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/253767315_Confocal_scanning_beam_laser_microscopemacroscope_applications_requiring_large_data_sets","usePlainButton":true,"publicationUid":253767315,"feedStubs":null,"hasFeedStubs":false,"impactPoints":"0.20","url":"publication\/253767315_Confocal_scanning_beam_laser_microscopemacroscope_applications_requiring_large_data_sets","title":"Confocal scanning beam laser microscope\/macroscope: applications requiring large data sets","displayTitleAsLink":true,"authors":[{"id":6797928,"url":"researcher\/6797928_Arthur_E_Dixon","fullname":"Arthur E. Dixon","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":35337700,"url":"researcher\/35337700_Savvas_Damaskinos","fullname":"Savvas Damaskinos","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2005555917,"url":"researcher\/2005555917_Alfonso_Ribes","fullname":"Alfonso Ribes","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2026403156,"url":"researcher\/2026403156_Eileen_Seto","fullname":"Eileen Seto","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2026249018,"url":"researcher\/2026249018_Marie-Claude_Beland","fullname":"Marie-Claude Beland","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2026380954,"url":"researcher\/2026380954_Tetsu_Uesaka","fullname":"Tetsu Uesaka","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2026377508,"url":"researcher\/2026377508_Brian_E_Dalrymple","fullname":"Brian E. Dalrymple","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":6925260,"url":"researcher\/6925260_Sid_P_Duttagupta","fullname":"Sid P. Duttagupta","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":6152697,"url":"researcher\/6152697_Philippe_M_Fauchet","fullname":"Philippe M. Fauchet","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["Proceedings of SPIE - The International Society for Optical Engineering 03\/1995;  DOI:10.1117\/12.205331"],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/253767315_Confocal_scanning_beam_laser_microscopemacroscope_applications_requiring_large_data_sets","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/253767315_Confocal_scanning_beam_laser_microscopemacroscope_applications_requiring_large_data_sets\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw17_56ab9ecea4af6"},"id":"rgw17_56ab9ecea4af6","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=253767315","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":2066719926,"url":"researcher\/2066719926_Ekaterina_V_Astafeva","fullname":"Ekaterina V. Astaf'eva","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2066531656,"url":"researcher\/2066531656_Marina_Turuntseva","fullname":"Marina Turuntseva","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Jan 2014","journal":"SSRN Electronic Journal","showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/272299964_1_'''''''_'_Forecasting_with_Large_Data_Sets_Part_1_'Forecasting_Methods_Using_Large_Data_Sets'","usePlainButton":true,"publicationUid":272299964,"feedStubs":null,"hasFeedStubs":false,"impactPoints":false,"url":"publication\/272299964_1_%27%27%27%27%27%27%27_%27_Forecasting_with_Large_Data_Sets_Part_1_%27Forecasting_Methods_Using_Large_Data_Sets%27","title":". 1 ''''''' ' (Forecasting with Large Data Sets. Part 1 'Forecasting Methods Using Large Data Sets')","displayTitleAsLink":true,"authors":[{"id":2066719926,"url":"researcher\/2066719926_Ekaterina_V_Astafeva","fullname":"Ekaterina V. Astaf'eva","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2066531656,"url":"researcher\/2066531656_Marina_Turuntseva","fullname":"Marina Turuntseva","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["SSRN Electronic Journal 01\/2014;  DOI:10.2139\/ssrn.2444143"],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/272299964_1_'''''''_'_Forecasting_with_Large_Data_Sets_Part_1_'Forecasting_Methods_Using_Large_Data_Sets'","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/272299964_1_'''''''_'_Forecasting_with_Large_Data_Sets_Part_1_'Forecasting_Methods_Using_Large_Data_Sets'\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw18_56ab9ecea4af6"},"id":"rgw18_56ab9ecea4af6","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=272299964","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":36720210,"url":"researcher\/36720210_S_Heisterkamp","fullname":"S. Heisterkamp","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":20410465,"url":"researcher\/20410465_Ruud_H_eds_Koning","fullname":"Ruud H. (eds.) Koning","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"","journal":null,"showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/41885633_Large_data_sets_proceedings_of_a_symposium_on_how_to_manage_and_analyse_very_large_data_sets","usePlainButton":true,"publicationUid":41885633,"feedStubs":null,"hasFeedStubs":false,"impactPoints":false,"url":"publication\/41885633_Large_data_sets_proceedings_of_a_symposium_on_how_to_manage_and_analyse_very_large_data_sets","title":"Large data sets proceedings of a symposium on how to manage and analyse very large data sets","displayTitleAsLink":true,"authors":[{"id":36720210,"url":"researcher\/36720210_S_Heisterkamp","fullname":"S. Heisterkamp","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":20410465,"url":"researcher\/20410465_Ruud_H_eds_Koning","fullname":"Ruud H. (eds.) Koning","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":[],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/41885633_Large_data_sets_proceedings_of_a_symposium_on_how_to_manage_and_analyse_very_large_data_sets","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/41885633_Large_data_sets_proceedings_of_a_symposium_on_how_to_manage_and_analyse_very_large_data_sets\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw19_56ab9ecea4af6"},"id":"rgw19_56ab9ecea4af6","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=41885633","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"viewClass":"sidebar","widgetId":"rgw16_56ab9ecea4af6"},"id":"rgw16_56ab9ecea4af6","partials":[],"templateName":"publicliterature\/stubs\/SimilarPublications.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.SimilarPublications.html?referencePublicationId=262030260&view=sidebar","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationFulltextPreview":null,"publicationResourcesFulltext":{"data":{"publicationUid":262030260,"publicationResourceList":{"data":{"publicationResourceItems":[{"data":{"publicationUid":262030260,"publicationType":"article","linkId":"54c7078b0cf22d626a361153","fileName":"Ergodicity of Approximate MCMC Chains with Applications to Large Data Sets","fileUrl":"http:\/\/de.arxiv.org\/pdf\/1405.0182","name":"de.arxiv.org","nameUrl":"http:\/\/de.arxiv.org\/pdf\/1405.0182","canRemove":false,"fileIcon":"ico-pub","canPreview":true,"hasPublisherLink":null,"hasMetaData":true,"hide":false,"fulltext":"ico-pub","origin":"publication_list","isLastLink":true,"isUserLink":false,"widgetId":"rgw22_56ab9ecea4af6"},"id":"rgw22_56ab9ecea4af6","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceItem.html","templateExtensions":["generalHelpers"],"attrs":{"fileRequiredPublicationTypes":["code","coverPage","experimentFindings","method","negativeResults","presentation","rawData","researchProposal","workingPaper","artifact","dataset"]},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceItem.html?publicationUid=262030260&linkId=54c7078b0cf22d626a361153&hide=0&disableJavascript=disableJavascript&useAlternativeTemplate=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"widgetId":"rgw21_56ab9ecea4af6"},"id":"rgw21_56ab9ecea4af6","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceList.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceList.html?publicationUid=262030260&limit=3&disableJavascript=disableJavascript&type=fulltextFile","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"resourceCount":1,"hidden":false,"showMore":false,"fulltext":true,"publicationDownloadCount":{"data":{"value":2,"valueFormatted":"2","widgetId":"rgw23_56ab9ecea4af6"},"id":"rgw23_56ab9ecea4af6","partials":[],"templateName":"publicliterature\/stubs\/PublicationDownloadCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDownloadCount.html?publicationUid=262030260","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw20_56ab9ecea4af6"},"id":"rgw20_56ab9ecea4af6","partials":[],"templateName":"publicliterature\/stubs\/PublicationResources.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResources.html?publicationUid=262030260&type=fulltextFile&disableJavascript=1","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationResourcesAttachments":{"data":{"publicationUid":262030260,"publicationResourceList":{"data":{"publicationResourceItems":[],"widgetId":"rgw25_56ab9ecea4af6"},"id":"rgw25_56ab9ecea4af6","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceList.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceList.html?publicationUid=262030260&limit=3&disableJavascript=disableJavascript&type=attachmentFile","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"resourceCount":0,"hidden":true,"showMore":false,"fulltext":false,"publicationDownloadCount":{"data":{"value":2,"valueFormatted":"2","widgetId":"rgw26_56ab9ecea4af6"},"id":"rgw26_56ab9ecea4af6","partials":[],"templateName":"publicliterature\/stubs\/PublicationDownloadCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDownloadCount.html?publicationUid=262030260","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw24_56ab9ecea4af6"},"id":"rgw24_56ab9ecea4af6","partials":[],"templateName":"publicliterature\/stubs\/PublicationResources.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResources.html?publicationUid=262030260&type=attachmentFile","viewClass":"views.publicliterature.PublicationResourcesView","yuiModules":["rg.views.publicliterature.PublicationResourcesView"],"stylesheets":[],"_isYUI":true},"publicationText":{"data":{"hide":false,"pages":[{"page":1,"text":"arXiv:1405.0182v1  [math.ST]  1 May 2014\nERGODICITY OF APPROXIMATE MCMC CHAINS WITH\nAPPLICATIONS TO LARGE DATA SETS\nNATESH S. PILLAI\u2021AND AARON SMITH\u266f\nAbstract. In many modern applications, difficulty in evaluating the posterior density\nmakes taking performing a single MCMC step slow; this difficulty can be caused by in-\ntractable likelihood functions, but also appears for routine problems with large data sets.\nMany researchers have responded by running approximate versions of MCMC algorithms.\nIn this note, we develop very general quantitative bounds for showing the ergodicity of these\napproximate samplers. In particular, our bounds can be used to perform a bias-variance\ntrade-off argument to give practical guidance on the quality of approximation that should\nbe used for a given total computational budget. We present a few applications of our results\nin recently proposed algorithms, including the \u201causterity\u201d framework, Stochastic Gradient\nLangevin Dynamics, exponential random graphs and ABC-MCMC algorithms.\n1. Introduction\nMarkov chain Monte Carlo (MCMC) sampling is an indispensable tool for Bayesian com-\nputation. Most of the popular Metropolis-Hastings samplers require full evaluation of the\nposterior at two points at every step, while other MCMC samplers require even more infor-\nmation, such as gradients of the likelihood function. In many modern applications involving\nintractable likelihoods, the computational cost of this full evaluation of the likelihood func-\ntion can be prohibitively expensive. For instance, a full likelihood evaluation might involve\nprocessing a massive amount data, or computing the solution of a partial differential equa-\ntion representing an underlying physical phenomenon. The result is that the inferential\nperformance of naive implementations of MCMC algorithms can deteriorate as the amount\nof data grows, unless available computational resources grow even more quickly (see [Jor13]\nfor a broader discussion of this problem outside of the context of MCMC).\nAn increasingly common approach to circumvent this difficulty is to run only approxi-\nmations of the desired MCMC dynamics. These approximations often rely on estimating,\nrather than evaluating, the posterior distribution of interest - for example, doing so based\non a subsample of the available data [Bea03, OBB+00, WT11, KCW13, BDH14]. While\nmany approximate MCMC methods seem to be very successful in practice, they do not have\nthe same convergence guarantees as standard MCMC samplers. In this paper, we present\nsome general convergence results for such \u2018approximate\u2019 MCMC algorithms and discuss their\napplications to some recently proposed algorithms. Our results give quantitative bounds on\nthe convergence in distribution of the Markov chain as well as convergence of finite samples\ndrawn from the Markov chain. These bounds allow us to provide advice on how to choose\n\u2021pillai@fas.harvard.edu, Department of Statistics Harvard University,1 Oxford Street, Cambridge MA\n02138, USA.\n\u266fsmith.aaron.matthew@gmail.com, Department of Mathematics and Statistics University of Ottawa, 585\nKing Edward Drive, Ottawa ON K1N 7N5, Canada.\n1"},{"page":2,"text":"parameters for various approximation schemes, and in particular to give modest conditions\nunder which approximation schemes are more efficient than their underlying MCMC algo-\nrithms. While our examples focus on the problems posed by large data sets, our bounds are\nalso relevant to MCMC samplers targetting intractable likelihoods; see [PM+13] for applica-\ntions of related ideas in that context.\nThroughout the paper, we are especially interested in how approximations perform outside\nof the simplest setting of uniformly good approximations of uniformly ergodic Markov chains\n(see e.g., [Mit05] for bounds in that setting; heuristic arguments presented in [KCW13]\nand [WT11] implicitly make such assumptions). It is well known that some approximation\nschemes that have been proposed in the past can fail badly even in innocuous settings when\nthe approximations are not uniformly good (see Example 17 in [PM+13] for a sampler that\nfails to converge to a two-valued density on [0,1] and Theorem 1 of [LL12] for one that\nhas difficulty sampling from a Gaussian). Similarly, even uniformly good approximations of\nchains without uniform ergodicity can fail to inherit good convergence properties. To see\nthis, fix \u01eb > 0 and consider simple random walk on N as a uniformly good approximation of\nsimple random walk on N with drift min\n?\nhas reasonable convergence properties; the former does not even have a stationary measure.\nOur paper has three main contributions. The first is providing practical advice on how\nto choose the best approximate sampler for a given computational budget. The second is\nproviding robust ergodicity results. Finally, we provide a quantitative discussion of conver-\ngence for many approximation algorithms that cannot be easily analyzed as globally-small\nperturbations. This includes non-reversible samplers, algorithms that are geometrically but\nnot uniformly ergodic, and approximations that can be arbitrarily bad outside of \u201csmall\u201d\nsets.\nAfter presenting the main results, we discuss applications.\nformalization of the austerity framework proposed in [KCW13] for discussing the problem of\nrunning approximate MCMC algorithms under computational constraints imposed by data\nvolume. In [KCW13], the authors create a family of approximate samplers K\u01ebparameterized\nby an error \u01eb \u2265 0, with K0= K being the original MCMC sampler. Heuristically, a larger\nvalue of \u01eb corresponds to an algorithm that can run more steps for any given amount of\ncomputer time, but has a larger asymptotic bias. For a fixed amount of computer time, the\ngoal is to choose the value of \u01eb that minimizes the expected L2error of the resulting sample.\nAlthough this bias-variance tradeoff is proposed in their paper, they do not provide bounds\nrelating the expected finite-time error to \u01eb or the total computing time. We use our general\nresults to relate these quantities, and provide guidance as to the optimal value of \u01eb for a\ngiven amount of computing time when the approximation K\u01ebof K0is uniformly good on\nthe parameter space. We then extend these results to several large classes of base chains K\nthat are not uniformly ergodic, obtaining similar rates. We also extend our bounds to the\nexponential random graph model, using this as a test case for non-i.i.d. data and providing\nanalogous bounds. One of the main goals of our study is to justify the fact that, for a small\ncomputational budget and large amount of data, MCMC dynamics K\u01ebwith \u01eb > 0 can be more\nefficient than the usual dynamics K0. Our approximation assumptions are stated in terms of\nfamilies of metrics on kernels that include those used in [KCW13, AFEB14, Mit05, BDH14],\nand we show that our converge bounds are sharp in this generality. In examples, we also\n0,\n\u01eb\nlog(n)\n?\ntowards 0 at point n. The latter chain\nOur first application is a\n2"},{"page":3,"text":"point out that subsampling algorithms can have additional structure under which much\nfaster convergence is possible.\nIn the following section, we apply our bounds to the Stochastic Gradient Langevin Dy-\nnamics (SGLD) of [WT11]. When these dynamics are uniformly ergodic and the SGLD\napproximation to the usual Langevin Dynamucs are uniformly good, the bounds are similar\nto those for the austerity framework. Unfortunately, as pointed out in [WT11, AFEB14],\nthese assumptions very rarely hold. We make progress by observing the fact that, for many\nnatural examples, the shape of the tails of the likelihood function depends very little on the\ndetails of a data set. When this is the case, a subsample of data may result in very poor\nkernel approximations of the tails, but even a subsample consisting of a single data point\nis often enough to obtain global properties such as drift conditions. We find quantitative\nbounds based on this idea, and apply them to examples for which the heuristic convergence\nargument in [WT11] does not apply.\nOur final section briefly discusses global properties that one might consider in trading bias\nfor variance in MCMC algorithms, with applications to SGLD and to ABC. Briefly, the work\nin [KCW13] and related papers is built on the idea that one can take more steps of an MCMC\nalgorithm if one can very cheaply approximate a transition kernel; the increased number of\nsamples will decrease the variance of the resulting estimate, at some cost in bias. This is\na local improvement, as we only improve the speed of individual steps without thought to\nthe global properties of the algorithm. Our final section discusses a very different tradeoff,\nwhere the transition kernel K is approximated by a transition kernel\u02dcK that may be just\nas expensive to sample from, but which has better convergence properties than K. In one\nof our examples,\u02dcK is geometrically ergodic while K is not. In other examples, we may\nincrease the spectral gap. In all cases, these improved convergence properties should result\nin MCMC samplers that have a smaller variance for the same number of steps. While the\napproach and algorithms discussed here are very different from those in [KCW13], the idea is\nquite similar: for a quantifiable increase in bias, we can decrease the variance of our MCMC\nsample.\nWhile we were finishing this paper, closely related work was released in the preprints\n[BDH14, AFEB14]. We feel that the preprint [BDH14] is complementary to the current\npaper: their paper focuses on providing guarantees that a given approximate algorithm is\nclose to a base chain under certain conditions, and largely ignores what this implies for the\nconvergence of the approximate algorithm. We focus on the convergence rates of approximate\nalgorithms given guarantees of the sort found in [BDH14]; besides lemmas covering very\nsimple approximation algorithms in Sections 5 and 6, we spend little time on developing\nsuch guarantees. The paper [AFEB14] is much closer to our work. Like us, the authors of\n[AFEB14] were concerned with the convergence of various approximate versions of standard\nMCMC algorithms, and are particularly interested in the problems associated with running\nMCMC algorithms when it is expensive to exactly evaluate the target distribution, even up\nto normalizing constant. Their main theoretical results are applications of the perturbation-\ntheoretic theorems found in [Mit05]. In particular, their Corollary 2.2 gives similar bounds\nto our Lemma 3.2; like us, they give a few variations on this theme.\nSince our main applications are very similar, we point out some important differences\nbetween our papers. Their theoretical results focus on the case of uniformly ergodic ap-\nproximating chains that are uniformly close to their target chains, and these results can\n3"},{"page":4,"text":"be slightly sharper than ours in that generality. In contrast, we obtain theoretical results\nthat apply to a much broader collection of chains, including approximating chains for which\nthe quality of the approximation is not uniformly bounded over the state space, as well as\ndropping the requirement for uniform ergodicity. This allows us to provide useful bounds on\nseveral algorithms, and allows us to give a partial answer to a question on the convergence\nof stochastic gradient Langevin dynamics posed in Section 2.3 of [AFEB14]. In another\ndirection, we also examine convergence in stronger metrics, such as Wasserstein distance\nof the empirical distribution of the chain to its target, and obtain sharper inequalities in\nthese situations. Finally, in addition to proving convergence results related to Corollary 2.2\nof [AFEB14], we prove a tradeoff bound that describes the optimal approximation quality\none should use with a given computational budget, and describes the asymptotic variance\nof an MCMC sample in terms of this computational budget. Their paper covers a wider\nvariety of examples than ours, and has several very useful simulated studies of different algo-\nrithms. Overall, their paper focuses more on serious empirical studies than ours, while ours\nfocuses on more broadly-applicable theoretical convergence bounds and their consequences\nfor sample properties.\nThe organization of our paper is as follows. We begin by setting up some notation in\nSection 2, and prove our main theoretical results in Section 3. In Section 4, we then study\nthe austerity framework recently proposed in [KCW13]. In Section 5, we discuss how the\nsame austerity framework extends to non-i.i.d. data by looking at exponential random graph\nmodels. We discuss a related idea, the stochastic gradient Lagevin dynamics, in Section 6.\nThese dynamics were proposed in [WT11], and they are generally very far from the parent\nalgorithm outside of a small set; overcoming this difficulty is the critical step in making\nrigorous the heuristic convergence argument presented in [WT11]. Finally, in Section 7, we\nintroduce and analyze some approximate MCMC samplers that are based on adding bias to\nimprove global mixing properties rather than local step speeds.\n2. Preliminaries\nFor a random variable X and measure \u00b5, X \u223c \u00b5 denotes that X is distributed according\nto \u00b5. Unif(A) denotes the uniform or Haar distribution on the set A as appropriate. We will\nwrite f = O(g) to mean that there exists a constant C > 0 so that f(x) \u2264 Cg(x). We also\nwrite f = o(g) if limx\u2192\u221e\nthe law of X. Throughout the paper, the letter C will denote a generic positive constant.\nBy ? \u00b7 ?TV we mean the total variation norm. We use the framework of curvature for\noperators used heavily in [JO10] and introduced in [Oll09]. Throughout, we will consider\nseveral kernels K on several Polish spaces (\u03a9,d). Associated with each kernel and Polish\nspace is a notion of curvature. Fix two measures \u00b5,\u03bd on \u03a9, and let \u03a0(\u00b5,\u03bd) be the set of all\ncouplings of \u00b5 and \u03bd. The Wasserstein distance between \u00b5 and \u03bd is defined as\nf(x)\ng(x)= 0. For a random variable X, we will write L(X) to denote\nWd(\u00b5,\u03bd) =inf\n\u03b6\u2208\u03a0(\u00b5,\u03bd)\n?\nx,y\u2208\u03a9\nd(x,y)\u03b6(dx,dy).\nIn this paper, we frequently pass between this definition of the Wasserstein distance and\nthe following version provided by the Kantorovitch-Rubinstein duality theorem (see Remark\n4"},{"page":5,"text":"6.5 of [Vil08]):\nWd(\u00b5,\u03bd) =sup\n?f?Lip=1|\u00b5(f) \u2212 \u03bd(f)|.\nThe Ricci curvature of the kernel K at the pair of points x,y is defined to be:\n\u03ba(x,y) = 1 \u2212Wd(K(x,\u00b7),K(y,\u00b7))\nand the curvature of the entire chain is defined to be\nd(x,y)\n\u03ba = inf\nx,y\u2208\u03a9\u03ba(x,y).\nIt is worth noting that in many cases of interest, it is sufficient to calculate \u03ba(x,y) for\nd(x,y) \u2018small\u2019; see, e.g., Prop 19 of [Oll09].\nIn addition to the curvature, which describes the tendency of nearby points to coallesce,\nwe also need several measures of variation from [JO10]. The eccentricity of a point x \u2208 \u03a9 is\ngiven by:\n?\nThe coarse diffusion is defined as\n\u03c3(x)2=1\n2\ny,z\u2208\u03a9\nand the local dimension is given by\n?\n?\nFinally, define the granularity to be\n\u03c3\u221e=1\nx\u2208\u03a9\nFor a running time T \u2265 11, define\n\u03c0T(f) =1\nT\nE(x) =\n\u03a9\nd(x,y)\u03c0(dy).\n?\nd(y,z)2K(x,dy)K(x,dz)\nm(x) =inf\n?f?Lip=1\ny,z\u2208\u03a9d(y,z)2K(x,dy)K(x,dz)\ny,z\u2208\u03a9|f(y) \u2212 f(z)|2K(x,dy)K(x,dz).\n2sup\ndiamSupp(K(x,\u00b7)).\nT\n?\nt=1\nf(Xt) (2.1)\nfor any f : \u03a9 ?\u2192 R. Fix a Markov chain Xtwith associated operator K and invariant measure\n\u03c0 on the Polish space (\u03a9,d), and define the quantity\nV2=\n1\n\u03baTsup\nx\u2208\u03a9\n\u03c32(x)\nm(x)\u03ba.\nTheorem 4 of [JO10] gives the following concentration inequality for any Lipschitz function\nf with \u03c0(f) = 0:\nP\n?|\u03c0T(f) \u2212 Ex[\u03c0T(f)]|\n?f?Lip\n> r\n?\n\u2264 2e\u2212r2\/(16V2)\n(2.2)\n1Without loss of generality, we assume the burn-in time of all of the MCMC algorithms studied in this\npaper to be 0; it is quite straightforward to modify our results including the burn-in time.\n5"},{"page":6,"text":"for x \u2208 \u03a9 and r < rmax=4V2\u03baT\ndenotes the initial condition of Xt.\n3\u03c3\u221e. A similar result holds for r > rmax. The subscript x in Ex\n3. Technical Results\n3.1. Convergence of Approximate Chains under Contraction Assumptions. Next\nwe consider a general non-stationary, time inhomogeneous Markov chain Xtevolving accord-\ning to some sequence of kernels Ktthat approximates a kernel of interest K with stationary\ndistribution \u03c0 on state space \u03a9. The following calculation gives quantitative bounds on the\nmixing properties of the approximate chain Xt:\nLemma 3.1 (Coupling Inequality). Assume that K satisfies\n?Kt(x,\u00b7) \u2212 \u03c0(\u00b7)?TV\u2264 Cx(1 \u2212 \u03b1)t\nfor some \u03b1 > 0 and all t > 0, and also assume that\nsup\n1\u2264t\u2264T,x\u2208X?Kt(x,\u00b7) \u2212 K(x,\u00b7)?TV< \u03b4\nfor some set X. Then, if X1= x \u2208 X, we have:\n?L(XT) \u2212 \u03c0?TV\u2264 Cx(1 \u2212 \u03b1)T\u22121+ (T \u2212 1)\u03b4 +\nT\n?\nt=1\nKt(x,Xc). (3.1)\nProof of Lemma 3.1. We will couple the process {Xt}T\nof kernels {Kt}T\u22121\nkernel K. The first chain, Yt, starts at stationarity: Y1\u223c \u03c0. The second chain, Y\u2032\nwith Xt: Y\u2032\nWe couple the Markov chains {Yt} and {Y\u2032\nP[YT?= Y\u2032\n\u2264 Cx(1 \u2212 \u03b1)T\u22121.\nNext we construct a coupling between Y\u2032\nif Xt?= Y\u2032\nXt+1from a distribution which satisfies\nt=1evolving according to the sequence\nt=1, {Y\u2032\nt=1with two Markov chains {Yt}T\nt}T\nt=1both evolving according to the\nt, starts\n1= x = X1.\nt} so that\nT] = ?L(YT) \u2212 L(Y\u2032\nT)?TV\n(3.2)\ntfrom (3.2) and Xtas follows. At every step t,\ntor Y\u2032\nt\/ \u2208 X, choose Xt+1\u223c Kt+1(Xt,\u00b7) independently of Y\u2032\nt+1. If Xt= Y\u2032\nt, choose\nP[Xt+1?= Y\u2032\nt+1] = ?Kt+1(Xt,\u00b7) \u2212 K(Y\u2032\nt}, \u03c42= inf{t \u2265 1 : Y\u2032\nt,\u00b7)?TV.\nDefine \u03c41= inf{t \u2265 1 : Xt?= Y\u2032\n?L(XT) \u2212 \u03c0?TV= ?L(XT) \u2212 L(YT)?TV\nt\/ \u2208 X} and \u03c4 = min(\u03c41,\u03c42). Then:\n\u2264 P[XT?= YT]\n\u2264 P[XT?= Y\u2032\nT\n?\nT\n?\nT] + P[Y\u2032\nT?= YT]\n\u2264\nt=1\nP[\u03c4 = t] + Cx(1 \u2212 \u03b1)T\u22121\n\u2264\nt=1\n(P[\u03c42= t] + P[\u03c42> \u03c41= t]) + Cx(1 \u2212 \u03b1)T\u22121\n6"},{"page":7,"text":"\u2264\nT\n?\nt=1\nKt\u22121(x,Xc) + (T \u2212 1)\u03b4 + Cx(1 \u2212 \u03b1)T\u22121\nand the proof is finished.\n?\nNext we give a similar argument in the Wasserstein topology.\nLemma 3.2. Fix a kernel of interest K with stationary distribution \u03c0, and let (\u03a9,d) be a\nPolish space that has eccentricity E(x) < \u221e with respect to \u03c0. Assume that K satisfies\nWd(K(x,\u00b7),K(y,\u00b7)) \u2264 (1 \u2212 \u03b1)d(x,y)\nfor all x,y \u2208 X for some \u03b1 > 0 and set X. Also assume that\nsup\n(3.3)\n1\u2264t\u2264TWd(Kt(x,\u00b7),K(x,\u00b7)) < \u03b4\nfor some \u03b4 > 0 and all x \u2208 X. Then, with X0= x \u2208 X,\nWd(L(XT),\u03c0) \u2264\u03b4\n\u03b1+ (1 \u2212 \u03b1)T\u22121E(x) +\nT\n?\nt=1\n?\nKt\u22121(x,Xc) +\nt\u22121\n?\ns=1\nKs(x,Xc)\n?\n.(3.4)\nProof of Lemma 3.2. By the triangle inequality, for any t \u2208 [1,T] and any x,y \u2208 X,\nWd(K(x,\u00b7),Kt(y,\u00b7)) \u2264 Wd(K(x,\u00b7),K(y,\u00b7)) + Wd(K(y,\u00b7),Kt(y,\u00b7))\n\u2264 (1 \u2212 \u03b1)d(x,y) + \u03b4.\nWe couple our chain Xsdriven by kernel Ksand started at X1= x with a chain Ysdriven\nby kernel K and started at Y1\u223c \u03c0 so that, at every step,\nE[d(Xs+1,Ys+1)|Xs,Ys] \u2264 \u03b3 + Wd(K(Xs,\u00b7),Ks(Ys,\u00b7)).\nThen we have\nWd(L(XT),\u03c0) \u2264 E[d(XT,YT)]\n\u2264 E[\u03b4 + \u03b3 + (1 \u2212 \u03b1)E[d(XT\u22121,YT\u22121)]] + (1 \u2212 P[XT\u22121,YT\u22121\u2208 X])\n\u2264 ...\n\u2264\u03b4 + \u03b3\n1 \u2212 \u03b1+ (1 \u2212 \u03b1)T\u22121E(x) +\nT\n?\nt=1\n?\nKt\u22121(x,Xc) +\nt\u22121\n?\ns=1\nKs(x,Xc)\n?\n.\nSince this holds for all \u03b3 > 0, the claim follows.\n?\nLemma 3.2 has the immediate corollary:\nCorollary 1. Assume that K satisfies\n?K(x,\u00b7) \u2212 K(y,\u00b7)?TV\u2264 (1 \u2212 \u03b1)\nfor some \u03b1 > 0. Also assume that\nsup\n1\u2264t\u2264T?Kt(x,\u00b7) \u2212 K(x,\u00b7)?TV< \u03b4\nfor some \u03b4 > 0. Then:\n?L(XT) \u2212 \u03c0?TV\u2264\u03b4\n\u03b1+ (1 \u2212 \u03b1)T\u22121.(3.5)\n7"},{"page":8,"text":"Remark 3.3. We mention that this corollary is also immediately implied by Corollary 3.1\nof [Mit05]; the constants are essentially the same for \u03b4 < \u03b1 small. Although our Lemma\n3.2 and the results in [Mit05] both imply the same result in this restricted setting, they have\ndifferent emphases. Their result is based on linear algebra; ours is purely probabilistic. Their\nresult gives superior results for general uniformly ergodic chains (though, by taking powers of\nthe kernel, our result also trivially implies inequalities for general uniformly ergodic chains\nthat give similar bounds for both bias and errors of MCMC estimates); our results apply to\nchains that are not uniformly ergodic. Finally, their result only applies for convergence in\nTotal Variation, while our results explicitly allow the use of many other Wasserstein metrics;\nthis flexibility can lead to bounds that are effectively much sharper if the metric is chosen\ncarefully.\nThis last difference is most easily seen in situations, such as Example 8, where the Markov\nchain satisfies inequality (3.3) for some fixed \u03b1 > 0 throughout a non-compact state space,\nand for which the eccentricity satisfies E(x) < \u221e for each x \u2208 \u03a9 but supx\u2208\u03a9E(x) = \u221e.\nThese chains are generally geometrically ergodic but not uniformly ergodic; Lemma 3.2 pro-\nvides direct bounds on their finite-time bias while Corollary 3.1 of [Mit05] does not apply.\nThe following example shows that the bound given by Corollary 1 is sharp up to constants,\nas a function of \u03b4 and \u03b1.\nExample 2. Consider the family of birth and death chains on [n] = {0,1,2,...,n} with\ntransition kernels given by\nK\u03b1,\u03b4(x,x + 1) = \u03b4\nK\u03b1,\u03b4(x,x) = 1 \u2212 \u03b1 \u2212 \u03b4\nK\u03b1,\u03b4(x,x \u2212 1) = \u03b4\nwhen x \u2212 1,x + 1 \u2208 [n], and 0 otherwise. Let \u03c0\u03b1,\u03b4be the associated stationary distribution.\nFor \u03b4 < \u03b1 and n > 2, it can be shown that\nsup\nx\u2208[n]?K\u03b1,\u03b4(x,\u00b7) \u2212 K\u03b1,0(x,\u00b7)?TV= \u03b1\n?KT\n\u03b1,0(x,\u00b7) \u2212 \u03c0\u03b1,0?TV= O?n(1 \u2212 \u03b1)T?\n?\u03c0\u03b1,\u03b4\u2212 \u03c0\u03b1,0?TV\u2265\n\u03b4\n2\u03b1+ O\n??\u03b4\n\u03b1\n2??\n.\n3.2. Convergence of Approximate Chains Under Drift and Minorization Assump-\ntions. In this subsection, we consider a Metropolis-Hastings chain K on state space \u03a9 with\nproposal kernel L and stationary distribution \u03c0, as well as an approximating chain K\u03b4on\nstate space \u03a9 with proposal kernel L and stationary distribution \u03c0\u03b4. We make the following\nassumptions throughout this subsection:\n(1) There exists a function V : \u03a9 \u2192 R+and constants 0 < a < 1, b < \u221e so that a chain\nYtevolving according to K satisfies\nE[V (Yt+1)|Yt= y] \u2264 (1 \u2212 a)V (y) + b.\n8\n(3.6)"},{"page":9,"text":"(2) Define V\u01eb(x) = V (x)\nwe have:\n1\n1+\u01eb. Assume that there exists some \u01eb0\u2265 0 so that, for all \u01eb > \u01eb0,\n|?\nz(V\u01eb(x) \u2212 V\u01eb(z))L(x,dz)|\nV\u01eb(x)\n< C\u01eb< \u221e\n(3.7)\n(3) For all compact sets X \u2282 \u03a9, there exists some \u01eb(X) > 0 and measure \u00b5Xwith support\nequal to X so that, for all x \u2208 X and some measure rxassociated with each point x,\nwe have:\nK(x,\u00b7) = \u01eb(X)\u00b5X(\u00b7) + (1 \u2212 \u01eb(X))rx(\u00b7). (3.8)\nRemark 3.4. We briefly discuss the strength of these assumptions.\n(1) This assumption is fairly standard; see e.g. [RT96] for useful sufficient conditions.\n(2) This holds for most reasonable chains. In particular, this inequality holds if our target\nand proposal distributions are both Gaussian; it holds with \u01eb0 = 0 if the proposal\ndistribution has smaller variance.\n(3) This holds if L(x,\u00b7) has density bounded away from 0 on all compact sets, and in\nparticular it is easy to force any chain to satisfy this for small values of \u01eb.\nUnder these assumptions, the drift condition is transferred to the approximate chain K\u03b4:\nLemma 3.5 (Drift and Minorization of Approximate Chains). Let K be a kernel satisfying\nassumptions 3.2, and let K\u03b4be a kernel satisfying\n||K(x,\u00b7) \u2212 K\u03b4(x,\u00b7)||TV < \u03b4.\nThen a chain Xtevolving according to K\u03b4satisfies a drift condition of the form\nE[V\u01eb(Xt+1)|Xt= x] \u2264 (1 \u2212 a\u03b4,\u01eb)V\u01eb(x) + b\u01eb,\nfor any \u01eb > \u01eb0, where\na\u03b4,\u01eb= 1 \u2212\n??\n?\n1 \u2212a\n2\n?\n1\n1+\u01eb+ C\u01eb\u03b4\n?\n(3.9)\nb\u01eb= b\n1\n1+\u01eb\n1 +2(1 \u2212 a)\na\n?\n1\n1+\u01eb\nand we note that for any \u01eb > 0, a\u03b4,\u01ebis strictly greater than 0 for \u03b4 sufficiently small.\nProof. By Jensen\u2019s inequality and inequality (3.6),\nE[V\u01eb(Yt+1)|Yt= y] \u2264 E[V (Yt+1)|Yt= y]\n\u2264 ((1 \u2212 a)V (y) + b)\n1\n1+\u01eb\n1\n1+\u01eb\nIfa\n?\n2V (y) > b, we have (1\u2212a)V (y)+b \u2264?1 \u2212a\na\n. Thus, continuing the above calculation,\n2\n?V (y). Ifa\n2V (y) \u2264 b, we have (1\u2212a)V (y)+b \u2264\nb 1 +2(1\u2212a)\n?\nE[V\u01eb(Yt+1)|Yt= y] \u2264\n?\n1 \u2212a\n2\n?\n1\n1+\u01ebV\u01eb(y) + b\n1\n1+\u01eb\n?\n1 +2(1 \u2212 a)\na\n?\n1\n1+\u01eb\n. (3.10)\n9"},{"page":10,"text":"Define a\u01eb= 1 \u2212?1 \u2212a\nE[V\u01eb(Xt+1)|Xt= x] = E[V\u01eb(Yt+1)|Yt= x] + E[V\u01eb(Xt+1) \u2212 V\u01eb(Yt+1)|Yt= Xt= x]\n\u2264 (1 \u2212 a\u01eb)V\u01eb(x) + b\u01eb+ E[V\u01eb(Xt+1) \u2212 V\u01eb(Yt+1)|Yt= Xt= x].\nDenote by \u03b1(x,y) the acceptance probability associated with K and \u03b1\u03b4(x,y) the acceptance\nprobability associated with K\u03b4. By Assumption 3.7, we have for \u01eb > \u01eb0:\n2\n?\n1\n1+\u01eband b\u01eb= b\n1\n1+\u01eb\n?\n1 +2(1\u2212a)\na\n?\n1\n1+\u01eb. We then calculate\n|E[V\u01eb(Xt+1) \u2212 V\u01eb(Yt+1)]| = |\n?\n?\nz:\u03b1(x,z)>\u03b1\u03b4(x,z)\n(\u03b1(x,z) \u2212 \u03b1\u03b4(x,z))(V (x) \u2212 V (z))\u2113(x,dz)\n+ |\nz:\u03b1(x,z)<\u03b1\u03b4(x,z)\n(\u2212\u03b1(x,z) + \u03b1\u03b4(x,z))(V (z) \u2212 V (x))\u2113(x,dz)\n?\n\u2264 ||K(x,\u00b7) \u2212 K\u03b4(x,\u00b7)||TV|\n\u2264 C\u01eb\u03b4V\u01eb(x).\nz\n(V (x) \u2212 V (z))\u2113(x,dz)|\n(3.11)\nPutting together inequalities (3.10) and (3.11), we have:\nE[V\u01eb(Xt+1)|Xt= x] \u2264 (1 \u2212 a\u01eb)V\u01eb(x) + b\u01eb+ C\u01eb\u03b4V\u01eb(x).\n=\n??\n1 \u2212a\n2\n?\n1\n1+\u01eb+ C\u01eb\u03b4\n?\nV\u01eb(x) + b\u01eb\nand the proof is finished.\n?\nFor a Markov chain Xtevolving according to an approximate chain K\u03b4, define\n\u03c0T,\u03b4(f) =1\nT\nT\n?\nt=1\nf(Xt).\nThen this Lemma allows us to prove the following concentration result when K is uniformly\nergodic and \u03a9 is countable:\nLemma 3.6 (Error Bounds for Approximate Chains). Let K satsify Assumptions 3.2, and\nalso assume that supxV (x) \u2261 D < \u221e and \u03a9 is countable. Let K\u03b4be a kernel satisfying\n?K(x,\u00b7) \u2212 K\u03b4(x,\u00b7)?TV< \u03b4.\nThen for any function f with ?f?\u221e\u2264 1 and q,r > 0,\nP[|\u03c0T,\u03b4(f) \u2212 \u03c0(f)| >\nr\n\u221aT\n+\n\u03b4q\nG(1 \u2212 \u03b8)q+ (1 \u2212 G(1 \u2212 \u03b8)q)\nT\nq] \u2264 e\u2212(1\u2212\u03b8)2r2\n2G2\n,\nwhere G,\u03b8 are as defined in Equation (3.12) below.\nProof. Applying Theorem 5 of [Ros95], with bounds given by Lemma 3.5 and assumptions\n3.2, for any \u01eb > \u01eb0the kernel K\u03b4is (G,\u03b8)-uniformly ergodic with\n?\n(1 \u2212 \u03b8)2= max\nG = 2 1 +\nb\u01eb\na\u03b4,\u01eb\n?\n+ D\nsup{x : V\u01eb(x) \u22642b\u01eb\n?\n(3.12)\n?\n\u01eb\na\u03b4,\u01eb}\n?\n10\n,(a\u03b4,\u01eb+ 4b\u01eb\u2212 3a\u03b4,\u01ebb\u01eb)(a\u03b4,\u01eb+ 6b\u01eb\u2212 2a\u03b4,\u01ebb\u01eb)\na\u03b4,\u01eb(a\u03b4,\u01eb+ 2b\u01eb)\n?"},{"page":11,"text":"where a\u03b4,\u01eb,b\u01ebare given by Equation (3.9). Combining this bound with Theorem 1 of [KW13],\nwe have for these values of (G,\u03b8) that:\nP[|\u03c0T,\u03b4(f) \u2212 \u03c0\u03b4(f)| >\nr\n\u221aT] \u2264 2e\u2212(1\u2212\u03b8)2r2\n2G2\n. (3.13)\nFinally, combining Corollary 1 with Lemma 3.5, we have for all 1 \u2264 q \u2264 T:\n|\u03c0(f) \u2212 \u03c0\u03b4(f)| \u2264\n\u03b4q\nG(1 \u2212 \u03b8)q+ (1 \u2212 G(1 \u2212 \u03b8)q)\nT\nq. (3.14)\nCombining inequalities (3.12), (3.13) and (3.14) gives the result.\n?\nWe then prove similar, weaker, bounds for geometrically ergodic but not uniformly ergodic\nchains. We begin by noting that the following follows immediately from Theorem 1 of\n[KCW13]:\nTheorem 3 (Concentration for Geometrically Ergodic Chains). Fix a subset X of a count-\nable space \u03a9 and assume that the kernel K restricted to X satisfies\n?Kt(x,\u00b7) \u2212 \u03c0?TV\u2264 GX\u03b8t\u22121\nfor some GX< \u221e. Then for all r > 0 and x0\u2208 X,\nr\n\u221aT] \u2264 e\n(3.15)\nP[|\u03c0T,\u03b4(f) \u2212 \u03c0(f)| >\n\u2212(1\u2212\u03b8)2r2\n2G2\nX\n+?1 \u2212 P[{Xt}T\nt=1\u2282 X]?.\nWe then have the following analogue to Lemma 3.6:\nLemma 3.7 (Error Bounds for Approximate Chains 2). Fix a countable state space \u03a9 and\nkernel K that satsifies Assumptions 3.2 and inequality (3.15). Also assume that for all finite\nsets X \u2282 \u03a9, we have supx\u2208XV (x) \u2261 DX< \u221e. Let K\u03b4be a kernel satisfying\n?K(x,\u00b7) \u2212 K\u03b4(x,\u00b7)?TV< \u03b4.\nThen for any function f with ?f?\u221e\u2264 1 and q,r > 0,\n?\n\u2264 e\u2212(1\u2212\u03b8)2r2\nwhere for all \u01eb > \u01eb0fixed, G and \u03b8 are given by:\nP\n|\u03c0T,\u03b4(f) \u2212 \u03c0(f)| >\nr\n\u221aT\n+\n\u03b4q\nG(1 \u2212 \u03b8)q+ (1 \u2212 G(1 \u2212 \u03b8)q)\nT\nq\n?\nt=1\u2282 X]?,\n(3.16)\n2G2\n+?1 \u2212 P[{Xt}T\nG = 2\n?\n1 +\nb\u01eb\na\u03b4,\u01eb\n?\n+ DX\n{x : V\u01eb(x) \u22642b\u01eb\n?\n(3.17)\n(1 \u2212 \u03b8)2= max\n?\n\u01eb\na\u03b4,\u01eb}\n?\n,(a\u03b4,\u01eb+ 4b\u01eb\u2212 3a\u03b4,\u01ebb\u01eb)(a\u03b4,\u01eb+ 6b\u01eb\u2212 2a\u03b4,\u01ebb\u01eb)\na\u03b4,\u01eb(a\u03b4,\u01eb+ 2b\u01eb)\n?\n.\nProof. The proof of this Lemma is identical to that of Lemma 3.6 after changing equality\n(3.12) to equality (3.17) and propagating this change through the other computations.\n?\n11"},{"page":12,"text":"3.3. Moderate-Time Concentration Bound for Walks That Almost Have Posi-\ntive Curvature. In this section, we provide bounds on the convergence of both estimates\n\u03c0T(f) =\nT\n?T\nresults generalize convergence results found in [AFEB14], in the sense that those results deal\nwith convergence of the distribution of a single point L(Xt), while the results in this section\ndeal with convergence of the entire sample Ft. We believe that these bounds are useful in\nand of themselves, and they are also used to prove tradeoffs in the setting of [KCW13].\n1\nt=1f(Xt) and also empirical measures Ft \u2261 U?{Xt}T\nt=1\n?\nbased on samples\n{Xt}T\nt=1drawn from a sequence of kernels {Kt}T\nt=1approximating a desired kernel K. These\nTheorem 4. Consider a kernel K with curvature \u03ba > 0 defined on a (possibly non-compact)\nsubset of Rdand a collection of approximating kernels {Kt}\u221e\nsup\nt=0that satisfy\nx\u2208\u03a9Wd(Kt(x,\u00b7),K(x,\u00b7)) < \u03b4.\nDenote by Ftthe empirical measure of the sequence {Xs}t\nthat there exists a Lipschitz function S(x) \u2265\n?\nFor r <\ns=1drawn from {Ks}t\u22121\ns=1. Assume\n\u03c3(x)2\n\u03b7x\u03ba. Then\nP\n|Ft(f) \u2212 \u03c0(f)| \u2265 r +\u03b4\n\u03c3(x)2\n\u03b7x\u03ba, we have instead:\nP[|Ft(f) \u2212 \u03c0(f)| \u2265 r +\u03b4\nProof. Fix \u03b1 > 0 and let Ytbe a sequence drawn from K that satisfies\nE[d(Xt,Yt)] \u2264 \u03b1 +\u03b4\nSuch a coupling exists by inequality (3.4). Denote by Ft and Gt the empirical measures\nassociated with the points {Xs}t\nnote that\n\u03ba+ (1 \u2212 \u03ba)t\u22121E(X0)\n?\n\u2264 2e\u2212\u03batr4max(2?S?Lip,3\u03c3\u221e).\n4\n3\u03c3\u221esupx\n\u03ba+ (1 \u2212 \u03ba)t\u22121E(X0)] < 2e\u2212r2\u03bat\n16\ninfx\n\u03b7x\u03ba\n\u03c3(x)2.\n\u03ba+ (1 \u2212 \u03ba)t\u22121E(X0).\ns=1and {Ys}t\ns=1respectively. By the triangle inequality, we\nP[|Ft(f) \u2212 \u03c0(f)| \u2265 r + Wd(Gt,Ft)] \u2264 P[|Gt(f) \u2212 \u03c0(f)| \u2265 r].\nCombining Inequality (3.18) with Theorem 5 of [JO10] and (3.4), we have\nP[|Ft(f) \u2212 \u03c0(f)| \u2265 r + \u03b1 +\u03b4\nLetting \u03b1 go to 0 completes the proof of the large-r bound. The proof for r small is essentially\nthe same, citing the small-r bound from Theorem 5 of [JO10] instead of the large-r version\ncited above.\n(3.18)\n\u03ba+ (1 \u2212 \u03ba)T\u22121E(X0)] \u2264 2e\u2212\u03batr4max(2?S?Lip,3\u03c3\u221e).\n?\n3.4. Tradeoff Lemma. In this section, we prove a simple book-keeping lemma that will be\nused in Section 4. We consider simulating from a kernel K\u01ebwith stationary distribution \u03c0\u01eb,\nwhere simulating a step of K\u01ebrequires c(\u01eb) units of computational time. We assume that\nc(\u01eb) is monotone decreasing in \u01eb. For fixed total computational resources M, we then look\nat the error of the estimate \u03c0T\u01eb,\u01eb(f) \u2261\nK\u01eband T\u01eb= \u230aM\nLemma 3.8 (General Tradeoff). Let F be a class of functions. Suppose that for some\ncollection of constants Ai,ci> 0, for all f \u2208 F the following hold:\n12\n1\nT\u01eb\n?T\u01eb\nt=1f(Xt), where Xtis a Markov chain driven by\nc(\u01eb)\u230b:"},{"page":13,"text":"(1) The bias |\u03c0\u01eb(f) \u2212 \u03c0(f)| \u2264 A1supx\u2208\u03a9Wd(K(x,\u00b7),K\u01eb(x,\u00b7))c1.\n(2) The kernel approximation error is bounded by supx\u2208\u03a9Wd(K(x,\u00b7),K\u01eb(x,\u00b7)) \u2264 A2c(\u01eb)\u2212c2.\n(3) For some c3> 0 and some function S(\u00b7) with limr\u2192\u221eS(r) = 0,\nP\n?\nThen, choosing the smallest \u01eb that satisfies c(\u01eb) \u2264 M\nP\n?\nwhere c4=\n(1) For some function S(\u00b7) with limr\u2192\u221eS(r) = 0,\nP\n?\nS(r) + A1Tc1\n(2) The kernel approximation error is bounded by supx\u2208\u03a9Wd(K(x,\u00b7),K\u01eb(x,\u00b7)) \u2264 A2c(\u01eb)\u2212c2.\nThen, choosing \u01eb so that c(\u01eb) = M\u2212\n|\u03c0T\u01eb,\u01eb(f) \u2212 \u03c0\u01eb(f)| > T\u2212c3\n\u01eb\nr\n?\n\u2264 S(r).\nc3\nc3+c1c2, we have for all f \u2208 F:\n2+ r)\n\u2264 S(r),\n|\u03c0T\u01eb,\u01eb(f) \u2212 \u03c0(f)| > M\u2212c4(A1Ac1\nc3+c1c2. If instead we have\n?\nc1c2c3\n|\u03c0T\u01eb,\u01eb(f) \u2212 \u03c0(f)| > T\u2212c1\n\u01eb\nr\n?\n\u2264\n\u01ebWd(K(x,\u00b7),K\u01eb(x,\u00b7))c2.\nc1\nc1+c2c3, we have:\nP\n?\n|\u03c0T\u01eb,\u01eb(f) \u2212 \u03c0(f)| > M\u2212c4(r + Ac1\n1+ A2)\n?\n\u2264 S(r),\nwhere c4=\nc1c2c3\nc1+c2c3.\nProof of Lemma 3.8. Applying the three initial assumptions above in each step, we compute:\nP[?\u03c0T\u01eb,\u01eb(f) \u2212 \u03c0(f)? > M\u2212c4(A1Ac1\n\u2264 P[?\u03c0T\u01eb,\u01eb(f) \u2212 \u03c0\u01eb(f)? > rM\u2212c4] + 1?\u03c0\u01eb(f)\u2212\u03c0(f)?>A1Ac1\n\u2264 S(r) + 1M\u2212c4<T\u2212c3\n\u2264 S(r) + 1M\u2212c4<T\u2212c3\n= S(r),\n2+ r)]\n2M\u2212c4\n\u01eb\n+ 1Wd(K(x,\u00b7)\u2212K\u01eb(x,\u00b7))c1>Ac1\n+ 1c(\u01eb)\u2212c1c2>M\u2212c4\n2M\u2212c4\n\u01eb\nwhere the last line is simple algebra. This completes the proof of the first version of the\nlemma; the second is essentially the same.\n?\n4. Application 1: Austerity Framework\nIn [KCW13], the authors consider the problem that, as one accumulates more and more\ndata, a standard Metropolis-Hastings sampler targetting the associated posterior distribution\nwill become more and more expensive to sample from. This stems from the fact that such\na sampler evaluates the full posterior twice in every step, and in particular this normally\nrequires every data point to be used at every step. The authors propose several algorithms\nthat might avoid this problem. In this section, we provide one formalization of the austerity\nframework and prove various tradeoff results with the application of Corollary 1 and Lemma\n3.8.\nTo set notation, we consider a Metropolis-Hasting kernel K with proposal kernel L, sta-\ntionary distribution\n\u03c0(\u03b8) \u2261 \u03c0(\u03b8|{xi}N\ni=1) = p(\u03b8)\nN\n?\ni=1\n\u03c0(\u03b8|xi)\n13"},{"page":14,"text":"and acceptance ratio Q as well as an approximating kernel K\u01ebwith the same proposal kernel\nL but different stationary distribution \u03c0\u01eband acceptance ratio Q\u01eb. While K is a Metropolis-\nHastings chain and so Q(x,y) = min\n?\nMetropolis-Hastings chain. Instead we view Q\u01eb as a random variable generated by some\nalgorithm to be specified later; we denote by its expected value E[Q\u01eb] the actual probability\nof a proposal being accepted. For the approximating chain K\u01eb, denote by \u2113t+1the proposed\npoint at time t and by utthe U[0,1]-distributed random variable used to determine if the\nproposal is accepted. Assume that the full data set has N points, and that at every step\nthe acceptance probability Q\u01ebis based on a random sample of n = n(t,Xt,\u2113t+1,\u01eb,ut) data\npoints, a (possibly random) function of the chain\u2019s current position and time. To formalize\nthe austerity framework, assume that we have a total computational budget of M data\npoints to view in total, over any number of steps of the Markov chain. We would like to\nchoose a function n = n(t,Xt,\u2113t+1,\u01eb,ut) that (approximately) minimizes the deviation of\nour estimator\n1,\u03c0(y)L(y,x)\n\u03c0(x)L(x,y)\n?\nis a deterministic function, K\u01ebis not a\n\u03c0T(f) =\nT\n?\nt=1\nf(Xt),\nwhere T = sup{t :?t\n1.\ns=1E[n(s,Xs,\u2113s+1,\u01eb,ut)] \u2264 M}. Without specifying the construction\nof the approximate acceptance ratio Q\u01eb, our generic construction of K\u01ebis given in Algorithm\nAlgorithm 1 Austerity Framework\nInitialize X1= x.\nFor t = 1 to N do\nGenerate \u2113t+1from the distribution L(Xt,\u00b7).\nGenerate utfrom U[0,1].\nGenerate the (random) acceptance probability Q\u01ebusing n = n(t,Xt,\u2113t+1,\u01eb,ut) indepen-\ndent draws from the data.\nif ut\u2264 Q\u01eb(Xt,\u2113t+1) then\nset Xt+1= \u2113t+1.\nelse\nset Xt+1= Xt.\nend if\nIn [KCW13], they use the construction in Algorithm 2 to find Q\u01ebat time t for data xi\u2208 Rd.\nThis algorithm requires the following terms:\ns =\n?\n\u21132\u2212 (\u2113)2\nn \u2212 1\nNlog\n?\n\u03c0(Xt)L(Xt,\u2113t+1)\n\u03c0(\u2113t+1)L(\u2113t+1,Xt)\n1 \u2212n \u2212 1\nN \u2212 1,(4.1)\n\u00b50=1\n?\nut\n?\n.\nRemark 4.1. All of our results depend on the expected number of points required to simulate\nan approximate acceptance ratio Q\u01ebthat satisfies \u01eb \u2265 supx,y|E[Q\u01eb(x,y)]\u2212Q(x,y)|. We don\u2019t\n14"},{"page":15,"text":"Algorithm 2 Austerity Framework II\nFix a constant m and initialize n = 0, S = {x1,...,xN}, X = \u2205.\nWhile done ?= TRUE, do:\nDraw a mini-batch X\u2032of size min(m,|S|) without replacement from S and then set S =\nS\\X\u2032, X = X \u222a X\u2032and n = |X|.\nCompute the sample mean \u2113 and sample variance \u21132for sample X.\nEstimate s and \u00b50using Equation (4.1).\nCompute \u03b4 = 1 \u2212 \u03c6m\u22121\nof freedom.\nif \u03b4 < \u01eb then\nSet done = TRUE.\nend if\nif If \u2113 > \u00b50then\nSet Q\u01eb= 1.\nelse\nSet Q\u01eb= 0.\nend if\n?\n|\u2113\u2212\u00b50\ns|\n?\n; \u03c6kis the CDF of Student\u2019s distribution with k degrees\ngive new algorithms for this approximation, but summarize here the growing literature on the\ntopic.\n\u2022 For any subset S \u2282 {xi}N\n\u02c6 \u03c1S(\u03b8) = p(\u03b8)\ni=1, define\n?\nx\u2208S\n\u03c0(\u03b8|x)\nN\n|S|.\nLet S be a sample of size n; if we calculate Q\u01ebusing\nQ\u01eb= min\n?\n1,\n\u02c6 \u03c1S(Xt)L(\u2113t+1,Xt)\n\u02c6 \u03c1S(\u2113t+1)L(Xt,\u2113t+1)\n?\n(4.2)\ninstead of Algorithm 4, we note that under sufficiently nice conditions (the target\ndistribution being uniformly bounded away from 0 on its support suffices) Hoeffeding\u2019s\ninequality guarantees an error of at most O(\u01eb) using a computational budget of n =\nO(\u2212\u01eb\u22122log(\u01eb)) samples per step.\n\u2022 As discussed in [BDH14], the specialization in [KCW13] can fail to give good approx-\nimations under certain circumstances (obviously using equation (4.2) can also be a\npoor choice).\n\u2022 In [BDH14], the authors propose another choice of Q\u01eband give bounds both on the\nerror of the approximation and the expected computation time. These bounds are\nquite general, and come with a minimal loss in efficiency: the average computational\nbudget per step is shown to be O(\u01eb\u22122log(\u01eb\u22121)). See that paper for a more thorough\ndiscussion of the choice of Q\u01eb.\nAll of the results below are insensitive to the details of the choice of approximation, and in\nparticular apply to Q\u01ebchosen from either algorithm 4 or equation (4.2).\nThe main theoretical result of [KCW13] is their Theorem 1 on the bias of an approximate\nMarkov chain, as follows:\n15"},{"page":16,"text":"Theorem. For a Metropolis-Hastings algorithm with transition kernel K satisfying the con-\ntraction condition\n?\u00b5K \u2212 \u03c0?TV\u2264 (1 \u2212 \u03b1)?\u00b5 \u2212 \u03c0?TV,\nwe have\n?\u03c0 \u2212 \u03c0\u01eb?TV\u2264\u2206\n\u03b1,\nwhere \u2206 = supx,y\u2208\u03a9|Q(x,y) \u2212 E[Q\u01eb(x,y)]|.\nThis result is strictly weaker than our Lemma 3.2 and is extended by Theorem 4. While\nthe bound in Theorem 4 is qualitatively useful, it doesn\u2019t provide any finite-time bounds for\nestimates based on the chain. In particular, it doesn\u2019t show that there exist computational\nbudgets M for which there exists some \u01eb > 0 for which the kernel K\u01ebgives more accurate\nestimates than the kernel K0 = K. In this section, we give a number of tradeoff results\nshowing that K\u01ebcan indeed give better results, and giving asymptotic results describing the\noptimal choice of \u01eb as M gets large. Our simplest result in this direction is:\nTheorem 5 (Austerity Tradeoff). Fix a 1-Lipschitz function f, a starting point X0 with\nfinite eccentricity, and a computational budget M. Assume that the base Markov chain K\nhas curvature \u03ba > 0. Assume that there exists a Lipschitz function S(x) \u2265\nthat the random estimates Q\u01ebbased on an algorithm with an expected cost of n computational\nunits satisfy\nWd(K(x,\u00b7),K\u01eb(x,\u00b7)) \u2264 Cn\u22121\nThen for\nM\u22121\nP[|\u03c0\u221aM,\u01eb(f) \u2212 \u03c0(f)| > rM\u22121\nfor some function satisfying limr\u2192\u221eA(r) = 0 that does not depend on m,M or N.\nRemark 4.2. If we replace inequality (4.3) with the bound Cn\u22121\ndiscussed in Remark 4.1, the same conclusion applies with only a loss of a logarithmic factor\nin the final bound.\n\u03c3(x)2\n\u03b7x\u03ba. Assume\n2. (4.3)\nC\n4< \u03ba, an estimate of Q\u01ebwith a mean cost of\n1\n\u221aMsatisfies:\n4] \u2264 A(r),\n2log(n), as per bounds\nRemark 4.3. The main point is that, as one\u2019s computational budget M goes to infinity,\napproximate chains are more efficient than the precise chain under some conditions. It is\npossible to obtain an error rate of O(M\u22121\n4) using approximate kernels independently of the\namount of data N available; running the precise kernel gives an error rate of O(\ncomputational resources grow sub-quadratically in the amount of data, this is a substantial\nimprovement.\n?\nN\nM). If the\nWe give an example showing that, under assumptions of the form given by inequality (4.3),\nthe O\n?\nfrom \u03c0\u01eb. In particular, the mixing rate of the underlying Markov chain is essentially irrelevant\nto our conclusions. We also give a simple resampling algorithm for which a much stronger\nasymptotic rate holds. These examples serve to illustrate the sharpness of our theorem and\nalso the fact that point-wise bounds on the difference between kernels, such as those given\n16\nM\u22121\n4\n?\nrate we obtain is sharp; this remains true even when K\u01ebgives i.i.d. samples"},{"page":17,"text":"by inequality (4.3), are extremely unstructured assumption and give correspondingly weak\nconclusions.\nExample 6. We begin by looking at situations that give rise to other rates. Consider the\nposterior \u03c0(\u03b8|{xi}N\nsubset (possibly with repetition) S of {xi}N\napproximation level n \u2264 M,N, we approximate \u03b8 as follows. Choose n points uniformly\nat random with replacement from {xi}N\ndecomposition of variance formula,\ni=1) = N\n??N\ni=1xi\nN\n,1\nN\n?\nwith approximation \u03c0S(\u03b8) = N\ni=1. For any given computational budget M and\n??\nx\u2208Sx\n|S|\n,1\nN\n?\nfor any\ni=1. We then draw \u03b8t from \u03c0S(\u03b8). By the usual\nVar\n?n\nM\nM\nn\n?\nt=0\n\u03b8t\n?\n= E\n?\nn\nVar?n\nMN+1\nM\nM\nn\n?\nt=0\n\u03b8t\n???S??\n+ Var\n??n\nM\nM\nn\n?\nt=0\n\u03b8t\n???St\n??\n=\nn.\nIn this setting, choosing n = min(M,\u221aMN) is optimal, giving the usual O\ngence rate as M becomes large much more slowly than N. Although the details change,\nsimilar conclusions hold if the set S is resampled at each time t, and also if sampling is done\nwithout replacement.\n?\n1\n\u221aM\n?\nconver-\nExample 7. To find simple examples for which the M\u22121\nputational budget M and approximation level n \u2264 M,N. We define the measure \u00b5n =\n?\ndistribution. We then have\n4 rate is correct, fix again a com-\n1 \u2212\n1\n\u221an\n?\nU[0,1] +\n1\n\u221an\u03b40, and consider a sequence of i.i.d. samples \u03b81,...,\u03b8M\nn\nfrom this\nE\n??n\n3\n4M, giving a decay rate of O\nM\nM\nn\n?\nt=1\n\u03b8t\u22121\n2\n?2?\n=\n1\n4n+\nn\n3M.\nThe optimal choice is n =\nour approximation assumption does not allow for the sort of cancellation that occurs in the\nprevious example.\n?\n?\nM\u22121\n4\n?\n. We can see here that\nOne major difference between these two examples is that, in the first, the approximate\nmeasures resulted in unbiased estimates; in the second, the approximate measures were also\nbiased. Assumptions of the form given in equation (4.3) are standard in the literature (see\ne.g., [KCW13, AFEB14, BDH14]), but cannot detect this difference. It may be interesting\nto try to understand which subsampling algorithms have a useful structure that inequalities\nsuch as (4.3) cannot capture.\nExample 8. As mentioned in remark 3.3, the curvature assumption used in Theorem 5 is\nstrictly weaker than the assumption made in [KCW13]. Our assumption is slightly weaker\nthan the uniform ergodicity assumption used in [AFEB14]. In particular, if a kernel K is\nuniformly ergodic, a small power of it will have positive curvature in the Total Variation dis-\ntance, and so we can obtain (slightly weaker) bounds in that case. In the other direction, our\nresult applies to many chains for which no finite power of the transition kernel is uniformly\nergodic.\n17"},{"page":18,"text":"Several examples that are geometrically but not uniformly ergodic, and for which our bounds\napply, can be found in [Oll09]. In that paper\u2019s Example 9, the discretization of the Ornstein-\nUhlenbeck process dXt= \u2212\u03b1Xtdt+sdBtwith time-steps of size \u03b4 has curvature 1\u2212e\u2212\u03b1\u03b4and\neccentricity E(x) = O(|x|) under the Euclidean metric; thus, our results apply. In the other\ndirection, this kernel is clearly not uniformly ergodic.\nWe now prove Theorem 5:\nProof. We plug earlier estimates into Lemma 3.8, with the family F being the collection\nof 1-Lipschitz functions. The first estimate comes from Lemma 3.2. The second estimate\nfollows from inequality (4.3). The third estimate follows from Theorem 4.\n?\nIn the following subsections, we prove tradeoff results similar to Theorem 5, under different\nassumptions.\n4.1. Drift and Minorization Conditions. When the state space \u03a9 is countable, we have\nthe following related results for chains that are uniformly ergodic:\nTheorem 9 (Austerity Tradeoff: Uniform Ergodicity). Fix a function f satisfying ?f?\u221e= 1\nand a computational budget M. Assume that the base kernel K satisfies Assumptions 3.2 and\nthat the random estimates Q\u01ebbased on an algorithm with an expected cost of n computational\nunits satisfy\n|E[Q\u01eb] \u2212 Q| \u2264 Cn\u22121\nThen for some M0that does not depend on N, and M > M0sufficiently large,\nP[|\u03c0\u221aM,\u01eb(f) \u2212 \u03c0(f)| > rM\u22121\nfor some function satisfying limr\u2192\u221eA(r) = 0 that does not depend on n, M or N.\nFor chains that are geometrically ergodic, we have the marginally weaker conclusion:\n2.\n4] \u2264 A(r),\nTheorem 10 (Austerity Tradeoff: Geometric Ergodicity). Fix a function f satisfying ||f||\u221e=\n1 and a computational budget M.\nAssume that, for all finite sets X, we have supx\u2208XV (x) \u2261 DX < \u221e. Assume that the\nrandom estimates Q\u01ebbased on an algorithm with an expected cost of n computational units\nsatisfy\n|E[Q\u01eb] \u2212 Q| \u2264 Cn\u22121\nThen for some M0that does not depend on N, and M > M0sufficiently large, we have for\nall q > 0,\n2.\nP[|\u03c0\u221aM,\u01eb(f) \u2212 \u03c0(f)| > rM\u22121\n4(1\u22121\nq)] \u2264 A(r),\nwhere A(r) is some function satisfying limr\u2192\u221eA(r) = 0 that does not depend on n, M or\nN.\nExample 11. This Theorem applies to the Metropolis-Hastings kernel with target distribu-\ntion \u03c0(x) \u221d e\u2212cxon N and proposal kernel L(x,y) =1\nWe begin by proving Theorem 9 and then discussing the small modifications needed to\nprove Theorem 10.\n18\n31|x\u2212y|\u22641."},{"page":19,"text":"Proof. We must first show that K satisfies condition (3.15) of Lemma 3.7 for all sets X of\nthe form\nX = XC= {x \u2208 \u03a9 : V (x) < C}.\nTo see this, let V be a drift function for the original kernel K with constants a,b, and let\n\u02c6 Xtbe a chain run according to the kernel K restricted to XC. Let Xtbe a copy of the chain\nrun according to K, with Xt=\u02c6 Xt\u2208 XC. Then we note that\nE[V (\u02c6 Xt+1)|\u02c6 Xt] = E[V (Xt+1)1V (Xt+1)\u2264C+ V (Xt)1V (Xt+1)>C|Xt]\n\u2264 E[V (Xt+1)|Xt]\n\u2264 (1 \u2212 a)V (Xt) + b\n= (1 \u2212 a)V (\u02c6 Xt) + b,\nwhere the second line follows from the fact that V (\u02c6 Xt) \u2264 C. Thus, V is also a drift function\nfor for K restricted to XC, with the same constants. In particular, condition (3.15) is satisfied\nfor all sets of the form XC.\nTo complete the proof, we plug earlier estimates into the second part of Lemma 3.8. The\nfirst requirement follows from Lemma 3.7. The second estimate follows from the definition\nof our algorithm with approximation error \u01eb =\nc4=1\n1\n\u221aM. This gives c1 = c2=\n1\n2, c3 = 1 and\n4.\n?\nWe next prove Theorem 10.\nProof. We begin by restricting our attention to sets of the form\nX(s) = {x : V\u01eb(x) < s}.\nFor these sets,\nDX(s)\u2264 s.\nNext, fix an exponent m. By inequality (3.10) above, for \u01eb > 2m, we have E[V\u01eb(Xt+1)m|Xt] \u2264\n(1 \u2212 am,\u01eb)V\u01eb(Xt)m+ bm,\u01ebfor some am,\u01eb< 1 and bm,\u01eb< \u221e. By Markov\u2019s inequality, then, we\nhave:\n?1 \u2212 P[{Xt}T\nt=1\u2282 X(s)]?= O\n?T + V\u01eb(X1)\nsm\n?\n. (4.4)\nCombinining this with inequality (3.16), we have for some constant C depending on the\ninitial point X0, all 1 \u2264 q \u2264 n and all s > 0:\nP[|\u03c0T,\u03b4(f) \u2212 \u03c0(f)| >\nr\n\u221aT\n+\n\u03b4q\n(C + s)(1 \u2212 \u03b8)q+ (1 \u2212 (C + s)(1 \u2212 \u03b8)q)\n\u2264 e\u2212(1\u2212\u03b8)2r2\nT\nq]\n2(C+s)2+T + C\nsm\n.\nChoosing s = T\n1\nm\u22121, r = uT\n1\nm\u22121and q = log(T)2, this becomes:\nP[|\u03c0T,\u03b4(f) \u2212 \u03c0(f)| > uT\u22121\n2+\n1\nm\u22121+ o\n?\nT\n\u22121\n2+\n1\nm\u22121\n?\n] \u2264 e\u2212(1\u2212\u03b8)2u2\n2C2\n+ O\n?\nT\u2212\n1\nm\u22121\n?\n.(4.5)\n19"},{"page":20,"text":"We plug earlier estimates into the second part of Lemma 3.8. The first requirement follows\nfrom Lemma 3.6. The second estimate follows from the definition of our algorithm with\napproximation error \u03b4 =\n1\n\u221aM. This gives c1=1\n2+\n1\nm\u22121, c2=1\n2, c3= 1 and c4=1\n4\n?1 \u2212\n1\nm\n?.\n?\n5. Application 2: Exponential Random Graph Models\nWhile the austerity framework has so far been discussed, both above and in [KCW13], for\ni.i.d. data, it makes sense to search for similar bias-variance tradeoffs for MCMC samplers\ntargetting more complicated posterior distributions. In this section, we briefly discuss this\nproblem in the context of the popular exponential random graph models (ERGM), finding\nan analogue to Theorem 5. Our main result is quantitative enough to show that subsampling\ncan improve the computational efficiency of MCMC estimates in this situation, even though\nthe model is much more complicated. We emphasize that, while this is useful confirmation\nof our intuition about subsampling, the bounds themselves are not practical. Due to other\ncomputational difficulties associated with the ERGM (see e.g., [CD13]), we find it unlikely\nthat subsampling will play an important role in estimation in the near future. In addition,\nunlike Theorem 5, we do not believe that the bounds in this section are sharp or that they\noffer practical guidance in the choice of approximating kernel.\nRecall that the probability of observing a given graph G in an ERGM is given by\np(G) = e\u2212?k\ni=1fi(N)\u03b2iTi(G)\u2212f(N)\u03c6(N,\u03b2),\nwhere G is a graph on N nodes, \u03b2 = (\u03b2i)k\nof normalizing values, Tiis a collection of graph functions such as number of edges, number\nof triangles, and \u03c6(N,\u03b2) is a normalizing constant. We wish to sample from the posterior\ndistribution of (\u03b21,...,\u03b2k) given an observed graph G. We focus on the common situation in\nwhich |G| = N is extremely large, and specialize to the case in which Ticounts the number\nof times the graph Hiis included as a subgraph of the dense graph G. We denote by viand\nei\u2265 1 the number of vertices and edges of Hi. For example, we might have H1be an edge\nbetween two vertices (v1= 2, e1= 1) and H2be a triangle (v2= e2= 3). We then set the\nnormalizing constants fi(n) = n\u2212viand define V = maxiviand E = maxiei.\nWe next describe our biased kernel. Fix a reversible proposal kernel L on the parameter\nspace Rkand let K be the associated Metropolis-Hastings kernel with proposal kernel L and\ntarget distribution\ni=1is a vector of parameters, fi(N) is a collection\n\u03c0(\u03b2) \u2261 \u03c0(\u03b2|G) \u221d \u03c1(\u03b2)e\u2212?k\ni=1fi(N)\u03b2iTi(G)\u2212f(N)\u03c6(N,\u03b2).\nTo define our approximate kernel K\u01eb, we will follow Algorithm 4 with one small modifica-\ntion. As in Equation (4.2), we will compute Q\u01ebvia an estimate \u03c0\u01ebof the target distribution.\nTo do so, will fix n = n(Xt,\u01eb), draw a random collection of n \u226a N vertices, and define\nGn\u2282 G to be the induced subgraph. We then define Ti,\u01eb(G) to be the number of times that\nsubgraph Hiappears in Gnand define\n\u03c0\u01eb(\u03b2) \u221d \u03c1(\u03b2)e\u2212?k\ni=1fi(n)\u03b2iTi,\u01eb(G)\u2212f(n)\u03c6(n,\u03b2).\nTheorem 12 (Austerity Improvement for ERGM). Fix a computational budget M and a\nfunction f of interest with ||f||\u221e= 1. Assume that the base Markov chain K satisfies\n?\u00b5K \u2212 \u03bdK?TV\u2264 (1 \u2212 \u03b1)?\u00b5 \u2212 \u03bd?TV\n20"},{"page":21,"text":"for some \u03b1 > 0 and all distributions \u00b5,\u03bd. Then, fixing \u01eb =\n2\nE log2(M)\n1\n8\nand choosing an\napproximation based on n = n(\u01eb) = min\nthat\n?\nN,2\n3\n(E\u01eb max(1,?k\ni=1\u03b2i))8?\n?\n, we have for all 0 < \u01eb < \u03b1\nP\n?\n|\u03c0\nM\nmin?\nN,2\n3\n(E\u01eb)8?,\u01eb(f) \u2212 \u03c0(f)| > r\u01eb\n\u2264 A(r),\nfor some function satisfying limr\u2192\u221eA(r) = 0 that does not depend on N or M.\nRemark 5.1. Before proving this result, it is important to remark on the normalizing con-\nstant \u03c6(N,\u03b2). This constant is necessary in order to run the usual Metropolis-Hastings chain\non the space of parameters, and it is generally very hard to estimate. We will ignore this\nissue for two reasons. The first is that it is a difficult problem, outside of the scope of this\npaper. The second is that some interesting work has been done on computing this constant\nprecisely for large N in some settings (see e.g., Theorems 3.1 and 4.1 of [CD13]), and we\nhope that this will make estimates like those in this Theorem easier to apply in the future.\nRemark 5.2. This convergence rate, in terms of M, is of course very slow. The argument\nbelow can be tightened to give a negligibly better bound, but not one that is useful. We\npoint out only that, for N very large, this convergence bound is better than that obtained by\nchoosing n = N at every step.\nProof. Our proof is essentially identical to that of Theorem 5; the biggest change is that we\nneed to bound E\n?\nDenote by \u03b4?the cut metric on graphs (see e.g. [BCL+06] for a definition). Recall Theorem\n5.7 of [BCL+06]:\nmin\n?\n1,\u03c0\u01eb(x)\n\u03c0\u01eb(y)\n??\ndirectly, without e.g. using the Berry-Esseen Theorem.\nTheorem 13. Fix \u01eb > 0. Then for n > 2\n3\n\u01eb8,\nP[\u03b4?(G,Gn) > \u01eb] \u2264 \u01eb.\nBy Lemma 5.2 of [BCL+06], this implies that for n > 2\nP[|n\u2212viTi,\u01eb(G) \u2212 N\u2212viTi(G)| > ei\u01eb] \u2264 \u01eb.\nWe note that\n3\n\u01eb8,\n(5.1)\nlog\n?\u03c0\u01eb(\u03b2)\n\u03c0(\u03b2)\n?\n=\nk\n?\ni=1\n\u03b2i\n?N\u2212viTi(G) \u2212 n\u2212viTi,\u01eb(G)?.\nBy inequality (5.1), we have that for any \u01eb > 0 and n > 2\n3\n\u01eb8,\nP[|log\n?\u03c0\u01eb(\u03b2)\n\u03c0(\u03b2)\n?\n| > E\u01eb\nk\n?\ni=1\n\u03b2i] \u2264 \u01eb.(5.2)\nIn particular, to obtain a uniform upper bound of E\u01eb on this ratio with probability at\n?\nstep. This provides an upper bound on\u03c0\u01eb\nleast 1 \u2212 \u01eb, it is sufficient to sample n = min N,2\n3\n(E\u01ebmax(1,?k\ni=1\u03b2i))8\n?\npoints from G at each\n\u03c0, and thus the upper bound\n?K(x,\u00b7) \u2212 K\u01eb(x,\u00b7)?TV< \u01eb\n21\n(5.3)"},{"page":22,"text":"for n = min\n?\nN,2\n3\n(E\u01eb max(1,?k\ni=1\u03b2i))8\n?\n. We then follow the remainder of the proof of Theorem\n5, with inequality (5.3) replacing the estimate of ?K(x,\u00b7)\u2212 K\u01eb(x,\u00b7)?TVwherever it appears\n(including passing it through the calculation in Lemma 3.8).\n?\n6. Application 3: Stochastic Gradient Langevin Dynamics\nFix a model with parameter vector \u03b8, prior p(\u03b8) and likelihood p(\u03b8|x) for a single data\npoint x. We consider the setting of drawing N i.i.d. points xi,...,xNpoints from this model,\nwhere N is extremely large. In their paper [WT11], Welling and Teh introduced the following\nStochastic Gradient Langevin Dynamics for sampling from such a posterior without looking\nat all N data points at every step:\n\u03b8t+1= \u03b8t+\u01eb\n2\n?\n\u2207log(p(\u03b8t)) +N\nn\nn\n?\ni=1\n\u2207log(p(xti|\u03b8t))\n?\n+ \u03b7t\n(6.1)\nwhere \u01eb,n > 0 are fixed constants, \u03b7t \u223c N(0,\u01eb) and xti are a subset of n < N data\npoints chosen uniformly at random. In [WT11], the authors provide useful heuristics for the\nconvergence of this algorithm for fixed n. We will provide rigorous justification and error\nbounds associated with this convergence, and show that convergence can hold even when the\nheuristics in [WT11] don\u2019t apply. Although we find convergence estimates, we avoid giving\ntradeoff theorems such as our Theorem 5. Such results would require careful discussion of\nthe convergence properties of the Langevin dynamics themselves, which is beyond the scope\nof this paper. Convergence results such as those found in [DT12, RS02, BRH13] could be\nused to find analogues to our Theorem 5 for the Stochastic Gradient Langevin Dynamics.\nWe begin by comparing the Stochastic Gradient Langevin Dynamics to the full Langevin\nDynamics as introduced in [Nea10]:\n\u03b8t+1= \u03b8t+\u01eb\n2\n?\n\u2207log(p(\u03b8t)) +\nN\n?\ni=1\n\u2207log(p(xi|\u03b8t))\n?\n+ \u03b7t,\nwhere the constants are as above. We also define the Gradient Dynamics to be:\n\u03b8t+1= \u03b8t+\u01eb\n2\n?\n\u2207log(p(\u03b8t)) +\nN\n?\ni=1\n\u2207log(p(xi|\u03b8t))\n?\n,(6.2)\nwhere again the constants are as above. We compute:\nLemma 6.1 (Approximation of Dynamics). Let K and\u02dcK be the kernels associated with the\nstochastic gradient Langevin dynamics and the Langevin dynamics respectively, and define\nV (\u03b8) = supi|\u2207log(p(xi|\u03b8))|. Then for d the usual Euclidean distance, we have the bound:\nWd(K(\u03b8,\u00b7),\u02dcK(\u03b8,\u00b7)) \u2264\u01eb2\nProof. Let \u03b8t evolve according to the Stochastic Gradient Langevin Dynamics, with noise\nvariable \u03b7, and let\u02dc\u03b8tevolve according to the full Langevin Dynamics, with noise variable \u02dc \u03b7.\nWe will couple \u03b8t+1,\u02dc\u03b8t+1started at the same point \u03b8t=\u02dc\u03b8t= \u0398 by first choosing the data\n22\n4\nN2\nnV (\u03b8t)2. (6.3)"},{"page":23,"text":"points {xti}n\ni=1and then coupling \u03b7t, \u02dc \u03b7tconditional on the points chosen. Define\nEt=\u01eb\n2\nN\nn\nn\n?\ni=1\n?\n\u2207log(p(xti|\u03b8t)) \u22121\nN\nN\n?\ni=1\n\u2207log(p(xi|\u03b8t))\n?\nand\nV (\u03b8) = sup\ni\n|\u2207log(p(xi|\u03b8))|.\nWe note that each term in the sum defining Etis bounded by V (\u03b8t). Thus, we find:\nE[E2\nt] \u2264\u01eb2\n4\nN2\nnV (\u03b8t)2\nTo find inequality (6.3) we set \u03b7t= \u02dc \u03b7tand the proof is finished.\n?\nRemark 6.2. We note immediately:\n\u2022 If V (\u03b8) is uniformly bounded in \u03b8, this bound together with the fact that the conver-\ngence rate of the usual Langevin dynamics is order of \u01eb can be plugged into Lemma\n3.2 (or one of the other, similar, lemmas) to show that Stochastic Gradient Langevin\ndynamics converges when the full Langevin dynamics do, as \u01eb goes to 0 sufficiently\nslowly. This is essentially a rigorous version of the argument in [WT11].\n\u2022 For most familiar distributions on noncompact state spaces, V (\u03b8) is not uniformly\nbounded. For example, it is not bounded if the model is given by p(x|\u03b8) \u223c N(\u03b8,1).\nIn these situations, the above bounds cannot be used to show convergence.\nIn light of this remark, we suggest three types of convergence theorem that might be\nuseful:\n(1) Restrict out attention to target distributions for which V (\u03b8) is bounded. In this\nsituation, we obtain straightforward convergence estimates.\n(2) We consider additional assumptions under which the stochastic gradient Langevin\ndynamics converge even under the presence of stepwise error that is not uniformly\nbounded.\n(3) Allow the number of points n evaluated per step to vary with the location in the\nstate space. If n = n(\u03b8,t) depends on the state space, this allows us to force the\nappropriately-scaled error \u03b4 =\nthe same convergence result will hold, but this will come at a potentially unbounded\ncost in number of function evaluations. This tension can be resolved by estimating\nthe the mean total number of data points?T\nWe consider these three types of results in order. For case 1,\nTheorem 14 (Convergence of Stochastic Gradient Langevin Dynamics for Nice Targets).\nAssume that the Langevin Dynamics associated with parameter \u01eb > 0 satisfies:\nV (\u03b8)2\nn(\u03b8,t)to be uniformly bounded in \u03b8. In this setting,\nt=0n(\u03b8,t) used over a run of length T.\nWd(K\u01eb(x,\u00b7),K\u01eb(y,\u00b7)) \u2264 (1 \u2212 a\u01eb)d(x,y)\nfor all x,y and for some function a\u01eb that satisfies inf0<\u01eb<\u01eb0\nAlso assume that sup\u03b8supi|\u2207log(p(xi|\u03b8))| \u2261 V0< \u221e. Finally, define \u03c0\u01eband \u02dc \u03c0\u01ebto be the\n23\na\u01eb\n\u01eb> c > 0 for some \u01eb0 > 0."},{"page":24,"text":"stationary distributions of the Stochastic Gradient Langevin Dynamics and usual Langevin\nDynamics. We conclude that, for all 0 < \u01eb < \u01eb0,\nWd(\u03c0\u01eb, \u02dc \u03c0\u01eb) \u2264 \u01ebN2V0\nProof. This follows immediately from Lemma 3.2 and Lemma 6.1.\n4nc.\n?\nRemark 6.3. This Theorem applies if \u03c0 is a log-concave distribution restricted to a compact\nand convex subset of Euclidean space.\nNext, we consider case 2. In many natural examples, having a uniformly good approxi-\nmation of the kernel\u02dcK turns out to be unnecessary, just as in Lemma 3.2:\nTheorem 15 (Fixed Sample Size Approximation). Fix \u01eb > 0. Assume that, for all pos-\nsible collection of points x1,...,xm, the (deterministic) gradient dynamics associated with\np(\u03b8|x1,...,xm), as defined in equation (6.2), have a Lyapunov function Lx1,...,xmwith asso-\nciated constants 0 < ax1,...,xm\u2264 1 and bx1,...,xm< \u221e. Furthermore, assume that\n|\u03b8|=r|Lx1,...,xm(\u03b8)\nfor any collection of data points x1,...,xmand x\u2032\nlim\nr\u2192\u221esup\nLx\u2032\n1,...,x\u2032m(\u03b8)\u2212 1| = 0(6.4)\n1,...,x\u2032\nmand that\nsup\n\u03b8 :L0,0,...,0(\u03b8)<cV (\u03b8)2\u2261 S(c) < \u221e\n(6.5)\nfor all c > 0.\nAlso assume that, for the same \u01eb > 0 and any x1,...,xmand \u03b4 > 0, there exists a compact\nset X = X(\u03b4,x1,...,xm) so that for \u03b8 \/ \u2208 X,\nN(\u03b8,\u01eb)(Lx1,...,xm) \u2264 (1 + \u03b4)Lx1,...,xm(\u03b8)\nWe also assume that for any compact set X, sup\u03b8\u2208XV (\u03b8) \u2261 V (X) < \u221e. Assume that the\nLangevin Dynamics kernel associated with parameter \u01eb > 0 satisfies:\n(6.6)\nWd(K\u01eb(x,\u00b7),K\u01eb(y,\u00b7)) \u2264 (1 \u2212 a\u01eb)d(x,y)\nfor all x,y and for some function a\u01ebthat satisfies inf0<\u01eb<\u01eb0\nfor \u03b4 <\na\u01eb\n\u01eb> c > 0 for some \u01eb0> 0. Then\n1\u2212a\u01eb0\n10,\nWd(\u03b8T\u2212 p(\u03b8|x1,...,xN)) <\u03b4\na\u01eb\n+ (1 \u2212 a\u01eb)TE(X0) + TL0,0,...,0(X0)\nS\u22121?\u221a4\u03b4\nN\u01eb\n? .\nProof. This result will follow from Lemmas 3.2 and 6.1. Let (a,b) = (a0,0,...,0,b0,0,...,0) be the\nconstants associated with the Lyapunov function L0,...,0with n 0\u2019s. Let \u03b4 <1\u2212a\n10, and define\nX1= \u222a{y1,...,yn}\u2282{x1,...,xN}X(\u03b4,y1,...,yn).\nThen define:\nR = inf{r : sup\n|\u03b8|\u2265r\nsup\n{y1,...,yn}\u2282{x1,...,xN}|Ly1,...,yn(\u03b8)\n24\nL0,...,0(\u03b8)\n\u2212 1| < \u03b4}"},{"page":25,"text":"and set\nX2= BR(0).\nThen set X = X1\u222a X2. We note that for the Langevin dynamics, and any \u03b8t\/ \u2208 X,\n1\n?N\n\u2264 (1 \u2212 a)(1 + \u03b4)2L0,...,0(\u03b8) + 2b\n\u2264\n2\nE[L0,...,0(\u03b8t+1)|\u03b8t= \u03b8] =\nn\n?\n?\n{y1,...,yn}\u2282{x1,...,xN}\nE[L0,...,0(\u03b8t+1)|\u03b8t= \u03b8,xti= yi]\n?\n1 \u22121 \u2212 a\n?\nL0,...,0(\u03b8) + 2b.\nFor a \u2265 0, define Xa= {x : L0,0,...,0(x) \u2264 a} \u222a X. By the above inequality and Markov\u2019s\ninequality, we have:\nP[Xt\/ \u2208 Xa|X0] \u2264L0,0,...,0(X0) + 2b\na\nand thus\n1 \u2212 P[{Xs}t\ns=0\u2208 Xa|X0] \u2265 1 \u2212 tL0,0,...,0(X0) + 2b\na\n.(6.7)\nDefine the good set G(\u03b4) = {\u03b8 :\nnote that the stochastic gradient dynamics satisfy inequality (6.7), using the same proof as\ngiven above. Then combining inequality (6.7) evaluated at a = c\u03b4with the bound in Lemma\n6.1 and plugging this into Lemma 3.2 with G(\u03b4)cthe set to be avoided, we have:\nWd(\u03b8T\u2212 p(\u03b8|x1,...,xN)) \u2264\u03b4\na\u01eb\n+ 2Tsupx\u2208Xa\u222a{X0}L0,0,...,0(x) + 2b\n\u01eb2\n4\nN2\nnV (\u03b8)2\u2264 \u03b4} and then c\u03b4= sup{c : Xc\u2282 G(\u03b4)}. Also\n+ (1 \u2212 a\u01eb)TE(X0) (6.8)\nc\u03b4\n.\nExpanding the definition of c\u03b4, we see that it is given by:\nc\u03b4= sup{c : L(\u03b8) \u2264 c \u21d2 V (\u03b8)2\u22641\n\u01eb2\n4\u03b4n\nN2}\nand so in particular, for all fixed \u03b4 > 0, we have by equation (6.5) that c\u03b4 = S\u22121?\u221a4\u03b4\nCombining this with inequality (6.8) completes the proof.\nN\u01eb\n?\n?\n.\nRemark 6.4. The assumptions in Equations (6.4) and (6.6) seem strongest. We point\nout that the assumption in equation (6.4) holds for most distributions, including e.g. the\nNormal, Cauchy, exponential, and largely requires that individual data points don\u2019t have too\nmuch influence on the distribution. Inequality (6.6) is only slightly stronger; it will hold as\nlong as the density decays no more quickly than e\u2212eC\u03b82\nfor some C < \u221e.\nExample 16. We point out that Theorem 15 gives asymptotic convergence for some exam-\nples where the assumptions of Theorem 14 fail to hold. In particular, we consider a target\ndistribution p(\u03b8|x1,...,xm) = N\n25\n??m\ni=1xi\nm\n,1\n?\nwith an (improper) flat prior. For all D > 0,"},{"page":26,"text":"the Langevin dynamics have a Lyapunov function\nLx1,...,xm(\u03b8) =\n?\n\u03b8 \u22121\nm\nm\n?\ni=1\nxi\n?D\nwith associated constants ax1,...,xm= bx1,...,xm= 0. This Lyapunov function clearly satisfies\nequation (6.4). The function V (\u03b8) is given by\nV (\u03b8) = sup\ni\u2208[N]|\u03b8 \u2212 xi|.\nThis is not bounded as a function of \u03b8, and so the conditions of Theorem 14 don\u2019t hold. We\nhave\nV (\u03b8)2\u2264 (Lx1,...,xm(\u03b8))\n2\nD+ sup\ni\u2208[N]\n?\nxi\u22121\nN\nN\n?\nj=1\nxj\n?2\nuniformly in data points (x1,...,xm) and also in m. Thus, in Equation (6.5), we have\nS(c) = c\n2\nD+ O(1) < \u221e.\nWe also note that\nN(\u03b8,\u01eb)(Lx1,...,xm(x)) =\n?\n\u03b8 \u22121\nm\nm\n?\ni=1\nxi\n?2\n+ \u01eb2\n= (Lx1,...,xm(x))(\u03b8) + \u01eb2,\nso inequality (6.6) is satisfied by defining X(\u03b4,x1,...,xm) =\nThe contraction estimate holds with a\u01eb\u2261 1.\nWe conclude that, for fixed 0 < D <\ndecays asymptotically at least as quickly as \u01eb\nasymptotic decay of the bias at the rate of \u01ebcfor any c < 1. We note that the Langevin\ndynamics themselves have bias that decays at an asymptotic rate of \u01eb.\n?\n\u03b8 : |\u03b8 \u2212\n1\nm\n?m\ni=1xi| <\n\u01eb\n\u221a\u03b4\n?\n.\n1\n2and setting \u03b4 = \u01eb1+\n1\nD+1 Letting D go to 0, we find that we have\n1\nD+1, we find that the error\nFinally, we consider case 3, looking at dynamics for which V (\u03b8) is not bounded. We apply\nTheorem 14, but set n = n(\u03b8,t) \u2261 min\napplies as stated for this value of V0. For many examples, such as that considered immediately\nabove, the convergence result in Theorem 14 combined with the Law of Large Numbers for\nMarkov chains give effective a.s. bounds on limT\u2192\u221e\nV (\u03b8t)2is often small outside of the tails of the target distribution, we can often achieve\nuniform bounds on the approximation quality with minimal extra computational cost.\n?\nN,N2\u01eb2V (\u03b8t)2\nV2\n0\n?\nfor some fixed V0> 0. The result then\n1\nT\n?T\nt=1n(\u03b8t,t). In particular, since\n7. Global Bias and Mixing Properties\nIn other sections of this paper, we have discussed the situation in which it is computation-\nally expensive to run even a single step from some desired kernel K0, and we construct an\napproximating kernel K\u01ebwhich is easier to run but gives asymptotically biased results. In\nthat setting, we are trading off bias against a purely local improvement in the MCMC algo-\nrithm - decreasing the time it takes to calculate individual steps. Although the approximate\nkernels are easier to run, they may not have better mixing properties than the underlying\nkernels; indeed, the mixing properties may be significantly worse. In this section, we briefly\n26"},{"page":27,"text":"discuss different ways to trade off bias against a more global improvement in the MCMC\nalgorithm by constructing approximating chains K\u2032\nthan the initial approximations K\u01eb, at the cost of a small amount of additional bias. The\nalgorithms in this section are all defined through a global estimate \u03c0\u01eb of \u03c0, , though in\nprinciple there is no reason to require this.\nThis is a large subject; indeed our recent paper [PM+13] is entirely concerned with a\nfamily of approximations that falls into this framework. In this section, we discuss only two\nvery simple examples: one related to the stochastic gradient Langevin dynamics (SGLD)\nalready discussed, the other related to the well-known MCMC variant of the approximately\nBayesian computation (ABC) algorithm (see [MPRR12] for a survey).\nThe main observation behind the examples in this section is as follows. For many ap-\nproximate samplers, including both ABC-MCMC and SGLD, the error d(K\u01eb(\u03b8,\u00b7),K(\u03b8,\u00b7)) of\nthe approximations have a tendency to decay for \u03b8 in the tails of the target distributions.\nFor ABC-MCMC, this is discussed in great detail in [LL12]; for SGLD, it is discussed in\nSection 6 above. In both of these cases, this decay makes the algorithms more difficult to\nanalyze; in the case of ABC-MCMC, this decay results in very poor mixing properties. The\nsimple solution we discuss here is to bias the target distributions towards a global estimate\nassociated with a rapidly-mixing Markov chain.\nWe begin by looking at ABC-MCMC. Recall that the ABC-MCMC algorithm requires a\nproposal kernel L, a prior \u03c0 on the parameter \u03c9 \u2208 \u03a9 of interest, a data-generating model\n\u03c0(\u00b7|\u03c9) for each value of the parameter \u03c9, observed data yobs, a pseudo-metric d on the state\nspace, and a tuning parameter \u01eb > 0. For any \u03c9 \u2208 \u03a9 and draw y\u2032\u223c \u03c0(\u00b7|\u03c9), we define the\nestimate:\n\u01ebthat have better convergence properties\n\u02c6 \u03c0\u01eb(\u03c9|yobs) = \u03c0(\u03c9)1d(yobs,y\u2032)<\u01eb. (7.1)\nThe ABC-MCMC algorithm is described in Algorithm 7. The marginal distribution of \u03c9\nAlgorithm 3 ABCMCMC\nInitialize (\u03c91,y1)\nFor t = 1 to N do:\nGenerate \u03c9\u2032from L(\u03c9t,\u00b7).\nGenerate y\u2032from \u03c0(\u00b7|\u03c9\u2032).\nSet \u02c6 \u03c0\u01eb(\u03c9|yobs) as in Equation (7.1).\nGenerate u from U[0,1].\nif u \u2264\nSet (\u03c9t+1,yt+1) = (\u03c9\u2032,y\u2032).\nelse\nSet (\u03c9t+1,yt+1) = (\u03c9t,yt).\nend if\n\u02c6 \u03c0\u01eb(\u03c9\u2032|yobs)L(\u03c9\u2032,\u03c9t)\n\u02c6 \u03c0\u01eb(\u03c9t|yobs)L(\u03c9t,\u03c9\u2032)then\nunder this chain\u2019s stationary distribution is given by:\n\u03c0\u01eb(\u03c9|yobs) = \u03c0(\u03c9|{y : d(y,yobs) < \u01eb}).\nAs discussed in in [LL12], the Markov chain described by this algorithm often fails to be\nvariance bounding (see [RR08] for definition of variance bounding) and thus also fails to be\n27"},{"page":28,"text":"geometrically ergodic. This problem occurs even for simple posteriors, as when estimating\nthe mean of a normal distribution with known variance.\nThe primary problem is that the acceptance probabilities of this kernel often go to 0 in the\ntails of the posterior. There are several proposed solutions to this problem in the literature;\nsome, such as those in [LL12] and the related paper [GLS+13], are quite sophisticated.\nWe describe here a very simple solution: for a fixed distribution \u03c1 and constant \u03b4 = \u03b4(\u01eb),\nwhen running this algorithm replace the estimate \u02c6 \u03c0\u01eb in equation (7.1) with the estimate\n\u02c6 \u03c0\u2032\nremainder of this section, is a pseudo-marginal Markov chain in the sense of [AR09], and so\nin particular is a reversible Markov chain. We note that\n\u01eb= \u02c6 \u03c0\u01eb+ \u03b4\u03c1. The result, which we will call Biased MCMC-ABC (B-MCMC-ABC) for the\nE[\u02c6 \u03c0\u2032\n\u01eb(\u03c9|yobs)] = E[\u02c6 \u03c0\u01eb(\u03c9|yobs) + \u03b4\u03c1(\u03c9)]\n= C\u03c0\u01eb(\u03c9|yobs) + \u03b4\u03c1(\u03c9),\nfor some constant C independent of \u01eb and \u03b4. Thus, the marginal distribution of \u03c9 under this\nchain\u2019s stationary distribution is given by:\n\u03c0\u01eb(\u03c9|yobs)\u2032\u221d C\u03c0(\u03c9|{y : d(y,yobs) < \u01eb}) + \u03b4\u03c1(\u03c9).\nIn particular, for a B-MCMC-ABC algorithm in Rn, the bias of \u03c0\u01eb(\u03c9|yobs)\u2032is O(\u03b4 + \u01ebn), and\nis thus easy to control; the bias for the usual MCMC-ABC algorithm is O(\u01ebn).\nWe claim that, for natural target distributions \u03c0 and priors \u03c1, this modified algorithm\nretains variance bounding. We do this by comparing B-MCMC-ABC to a chain with kernel\nK described by a mixture of two kernels, K1and K2. Denote by Q the kernel associated\nwith B-MCMC-ABC, and q its associated acceptance function. K1is a Metropolis-Hastings\nalgorithm that has the same proposal kernel L and stationary distribution as B-MCMC-\nABC; denote by k1its acceptance function. K2is the chain that doesn\u2019t move. We write\nK = \u03b1K1+ (1 \u2212 \u03b1)K2, where \u03b1 = sup{a : supx,y\nProposition 7.1. If \u03b1 < 1 and K is variance bounding, then Q is variance bounding.\nak1(x,y)\nq(x,y)\u2264 1}. We have\nProof. By the definition of \u03b1, if \u03b1 < 1 then K(x,A) \u2264 Q(x,A) for all x and all A satisfying\nA \u2229 {x} = \u2205. Thus, Q inherits the variance bounding property from K via Theorem 8 of\n[RR08].\n?\nRemark 7.2. We note that \u03b1 < 1 occurs in great generality. In particular, this works for the\nprototypical example of \u03c0(\u00b7|\u03c9) = N(\u03c9,1) for \u03c9 \u2208 R, \u03c0(\u03c9) = N(0,10) and L(x,\u00b7) = N(x,0.1)\nwhere we allow for shrinkage towards a slightly stretched version of the actual prior, so that\n\u03c1(\u03c9) = N(0,20). In this situation, we have for all \u03b4 sufficiently small relative to \u01eb and all\nsufficiently large \u03c9 that\nk1(x,y)\nq(x,y)= \u03a9(\u03b4) .\nWe now look at notions of shrinkage for stochastic gradient Langevin dynamics. As dis-\ncussed in Section 6, the SGLD can be arbitrarily far from the full Langevin dynamics that\nthey are approximating. This can occur even for very simple target posterior distributions,\nsuch as a normal distribution with known variance. Even though this algorithm is relatively\nnew, some modifications in the literature already ameliorate this problem; see e.g., [CFG14].\nIn this section, we discuss a much simpler modification.\n28"},{"page":29,"text":"We follow the notation in Section 6. For constant 0 < C = C(\u03b8,\u03b4,\u01eb,n,N) < 1, we modify\nEquation (6.1) as follows:\n\u03b8t+1= \u03b8t+\u01eb\n2\n?\nC\u2207log(p(\u03b8t)) + (1 \u2212 C)N\nn\nn\n?\ni=1\n\u2207log(p(xti|\u03b8t))\n?\n+ \u03b7t; (7.2)\nwe call this \u201cshrunk-SGLD\u201d or SSGLD. If we fix \u03b4 > 0 and choose\nC = 1 \u2212 min\n?\n1,\n\u221a4\u03b4n\n\u01ebNV (\u03b8)\n?\n,\nwe can guarantee that the SSGLD stay within \u03b4 of the associated shrunken Langevin dy-\nnamics (SLD) given by\n\u03b8t+1= \u03b8t+\u01eb\n2\n?\nC\u2207log(p(\u03b8t)) + (1 \u2212 C)\nN\n?\ni=1\n\u2207log(p(xi|\u03b8t))\n?\n+ \u03b7t,\nas measured by Wasserstein distance. In particular, Theorem 14 applies to the comparison of\nthese two \u2018shrunk\u2019 dynamics. If the prior p is log-convex and V (\u03b8) satisfies sup\u03b8\u2208X|V (\u03b8)| < \u221e\nfor all compact sets X, Theorem 3.1 also implies that the shrunken Langevin dynamics\nconverge to the standard Langevin dynamics as \u01eb goes to 0. Thus, as long as p is log-convex\nand sup\u03b8\u2208X|V (\u03b8)| < \u221e for all compact sets X, the SSGLD converges to the SLD as \u03b4 goes\nto 0 and the SLD converges to the LD as \u01eb goes to 0. In particular, under these conditions\nthe SSGLD converges to the correct stationary distribution when the LD does.\nAcknowledgements\nNSP is partially supported by NSF and ONR grants.\nReferences\n[AFEB14] P. Alquier, N. Friel, R. Everitt, and A. Boland. Noisy monte carlo: Convergence\nof markov chains with approximate transition kernels. Preprint, 2014.\n[AR09] Christophe Andrieu and Gareth Roberts. The pseudo-marginal approach for\nefficient monte carlo computations. Annals of Statistics, 37(2):1139\u20131160, 2009.\n[BCL+06] Christian Borgs, Jennifer Chayes, L\u00b4 aszl\u00b4 o Lov\u00b4 asz, Vera Sos, Balasz Szegedy, and\nKatalina Vesztergombi. Counting Graph Homomorphisms, volume Topics in Dis-\ncrete Mathematics. Springer, 2006.\n[BDH14] Remi Bardenet, Arnaud Doucet, and Chris Holmes. Towards scaling up markov\nchain monte carlo: an adapative subsampling approach. Preprint, 2014.\n[Bea03] M.A. Beaumont. Estimation of population growth or decline in genetically mon-\nitored populations. Genetics, (164):1139\u20131160, 2003.\n[BRH13] N. Bou-Rabee and M. Hairer. Nonasymptotic mixing of the mala algorithm.\nIMA Journal of Numerical Analysis, (33):80\u2013110, 2013.\n[CD13] Sourav Chatterjee and Persi Diaconis. Estimating and understanding exponential\nrandom graph models. Annals of Statistics, 41(5):2428\u20132461, 2013.\n[CFG14] Tianqi Chen, Emily Fox, and Carlos Guestrin. Stochastic gradient hamiltonian\nmonte carlo. Preprint, 2014.\n[DT12] A. Dalalyan and A.B. Tsybakov. Sparse regression learning by aggregation and\nlangevin. J. Comput. System Sci., 78(5):1423\u20131443, 2012.\n29"},{"page":30,"text":"[GLS+13] Mark Girolami, Anne-Marie Lyne, Heiko Strathmann, Daniel Simpson, and Yves\nAtchade. Playing russian roulette with intractable likelihoods. Preprint, 2013.\n[JO10] Alderic Joulin and Yann Ollivier. Concentration, curvature and error estimates\nfor Markov chain Monte Carlo. Ann. Prob., 38:2418\u20132442, 2010.\n[Jor13] Michael Jordan. On statistics, computation and scalability. Preprint, 2013.\n[KCW13] Anoop Korattikara, Yutian Chen, and Max Welling. Austerity in mcmc land:\nCutting the metropolis-hastings budget. Preprint, 2013.\n[KW13] Aryeh Kontorovitch and Roi Weiss.\nwolfowitz-type inequalities for markov chains and related processes. Preprint,\n2013.\n[LL12] Anthony Lee and Krzysztof Latuszynski. Variance bounding and geometric er-\ngodicity of markov chain monte carlo kernels for approximate bayesian compu-\ntation. Preprint, 2012.\n[Mit05] A.Y. Mitrophanov. Sensitivity and convergence of uniformly ergodic markov\nchains. Journal of Applied Probability, 42:1003\u20131014, 2005.\n[MPRR12] Jean-Michel Marin, Pierre Pudlo, Christian Robert, and Robin Ryder. Approx-\nimate bayesian computational methods. Statistics and Computing, 22(6):1167\u2013\n1180, 2012.\n[Nea10] Radford Neal. Mcmc using hamiltonian dynamics. Handbook of Markov Chain\nMonte Carlo, 2010.\n[OBB+00] P.D. O\u2019Neil, D.J. Balding, N.G. Becker, M. Eerola, and D. Mollison. Analyzes of\ninfectious disease data from houseing the expected value of ratios, hold outbreaks\nby markov chain monte carlo methods. Appl. Statist., (49):517\u2013542, 2000.\n[Oll09] Yann Ollivier. Ricci curvature of markov chains on metric spaces. J. Funct.\nAnal., 256(3):810\u2013864, 2009.\n[PM+13] Conrad Patrick, Youssef Marzouk, , Natesh Pillai, and Aaron Smith. Accelerating\nmcmc with local quadratic models. Preprint, 2013.\n[Ros95] Jeffrey Rosenthal. Minorization conditions and convergence rates for Markov\nchain Monte Carlo. JASA, 90:558\u2013566, 1995.\n[RR08] Gareth O Roberts and Jeffrey S Rosenthal. Variance bounding markov chains.\nAnnals of Applied Probability, 18(3):1201\u20131214, 2008.\n[RS02] G. Roberts and O. Stramer. Langevin diffusions and metropolis-hastings algo-\nrithms. Methodology and Computing in Applied Probability, 4:337\u2013357, 2002.\n[RT96] Gareth O. Roberts and Richard L. Tweedie. Geometric convergence and cen-\ntral limit theorems for multidimensional hastings and metropolis algorithms.\nBiometrika, 83(1):95\u2013110, 1996.\n[Vil08] Cedric Villani. Optimal Transport: Old and New. Springer, 2008.\n[WT11] M. Welling and Y. Teh. Bayesian learning via stochastic gradient langevin dy-\nnamics. Proceedings of the 28th International Conference on Machine Learning\n(ICML), pages 681\u2013688, 2011.\nUniform chernoff and dvoretzky-kiefer-\n30"}],"widgetId":"rgw27_56ab9ecea4af6"},"id":"rgw27_56ab9ecea4af6","partials":[],"templateName":"publicliterature\/stubs\/PublicationText.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationText.html?publicationUid=262030260&hide=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationDetailAd":{"data":{"googleDfpSlot":null,"widgetId":"rgw28_56ab9ecea4af6"},"id":"rgw28_56ab9ecea4af6","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAd.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAd.html?publicationUid=262030260&slotId=336x280_Publications_ATF_Right&collapseSlotMode=never&fallbackContainerEnabled=1","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationRelations":null,"publicationRelationsReverse":null,"publicationUid":262030260,"showSignUpDialog":false,"selectNewSignUpDialog":false,"publicationQuestions":null,"publicationCitations":null,"publicationReviewPromo":null,"publicationUsedInReviews":null,"publicationPdfJsReader":null,"useFulltextOptimizedLayout":false,"publicationActions":null,"requestFulltextPromo":null,"currentUrl":"publication\/262030260_Ergodicity_of_Approximate_MCMC_Chains_with_Applications_to_Large_Data_Sets","isLeaderboardAd":false,"enableStickyBox":null,"googleDfpSlotMobileBottom":null,"fullTextExitPopup":null,"showExitPopupDialog":false,"widgetId":"rgw2_56ab9ecea4af6"},"id":"rgw2_56ab9ecea4af6","partials":{"romeo_legal_notice":"publicliterature\/stubs\/partials\/romeo_legal_notice.html"},"templateName":"publicliterature\/stubs\/PublicPublicationDetails_NewLayout.html","templateExtensions":["generalHelpers"],"attrs":{"publicationUid":262030260},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicPublicationDetailsOld.html?publicationUid=262030260&isTestOldDesign=0","viewClass":"views.publicliterature.PublicPublicationDetailsOldView","yuiModules":["rg.views.publicliterature.PublicPublicationDetailsOldView"],"stylesheets":[],"_isYUI":true},"widgetId":"rgw1_56ab9ecea4af6"},"id":"rgw1_56ab9ecea4af6","partials":[],"templateName":"publicliterature\/stubs\/PublicPublicationDetails.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicPublicationDetails.html","viewClass":"views.publicliterature.PublicPublicationDetailsView","yuiModules":["rg.views.publicliterature.PublicPublicationDetailsView"],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"uaClass":"","headPrefix":[],"rootUrl":"https:\/\/www.researchgate.net\/","requestToken":"BknqRXCvsqohKnk3awiDyHogarIq\/S8+vI6zvKR\/WsBCz2gv\/aMrZvDYBlQbpGVGVj3tNtm6Mmdpc7KEQOKIyWl4+hPriHOM6c\/b\/TDnt70J8m3XRnF++RdCc2Iza2RLZh2Ppyi5JxxHZpYRdAsyIzvGTFtcppryOEV2o5v8O+o11IXLJVjmSUtQPNph0A13cGEHrO0onGe4zTGkt8gx1PL7EhWXORPZWGi6MfVC3emCvp9RWTEVLqokM2HHo+vZP\/tyNlkPTwOiqjNXLTf3+1Mu1eGDkAQwvnrJlPgfA3E=","faviconCdnUrl":"https:\/\/c5.rgstatic.net\/m\/2390829798215018\/images\/favicon.ico","headerOutput":"<noscript><\/noscript><link rel=\"canonical\" href=\"https:\/\/www.researchgate.net\/publication\/262030260_Ergodicity_of_Approximate_MCMC_Chains_with_Applications_to_Large_Data_Sets\" \/>\n<link rel=\"dns-prefetch\" href=\"\/\/c5.rgstatic.net\" \/>\n<link rel=\"dns-prefetch\" href=\"\/\/i1.rgstatic.net\" \/>\n<meta property=\"twitter:card\" content=\"summary\" \/>\n<meta property=\"twitter:site\" content=\"@ResearchGate\" \/>\n<meta property=\"og:title\" content=\"Ergodicity of Approximate MCMC Chains with Applications to Large Data Sets\" \/>\n<meta property=\"og:description\" content=\"In many modern applications, difficulty in evaluating the posterior density\nmakes performing even a single MCMC step slow. This difficulty can be caused by\nintractable likelihood functions, but...\" \/>\n<meta property=\"og:site_name\" content=\"ResearchGate\" \/>\n<meta property=\"og:image\" content=\"https:\/\/i1.rgstatic.net\/publication\/262030260_Ergodicity_of_Approximate_MCMC_Chains_with_Applications_to_Large_Data_Sets\/links\/54c7078b0cf22d626a361153\/smallpreview.png\" \/>\n<meta property=\"og:url\" content=\"https:\/\/www.researchgate.net\/publication\/262030260_Ergodicity_of_Approximate_MCMC_Chains_with_Applications_to_Large_Data_Sets\" \/>\n<meta property=\"rg:id\" content=\"PB:262030260\" \/>\n<meta name=\"DC.identifier\" scheme=\"DCTERMS.URI\" content=\"http:\/\/dx.doi.org\/\" \/>\n<meta name=\"gs_meta_revision\" content=\"1.1\" \/>\n<meta name=\"citation_title\" content=\"Ergodicity of Approximate MCMC Chains with Applications to Large Data Sets\" \/>\n<meta name=\"citation_author\" content=\"Natesh S. Pillai\" \/>\n<meta name=\"citation_author\" content=\"Aaron Smith\" \/>\n<meta name=\"citation_publication_date\" content=\"2014\/05\/01\" \/>\n<meta name=\"citation_abstract_html_url\" content=\"https:\/\/www.researchgate.net\/publication\/262030260_Ergodicity_of_Approximate_MCMC_Chains_with_Applications_to_Large_Data_Sets\" \/>\n<meta name=\"citation_fulltext_html_url\" content=\"https:\/\/www.researchgate.net\/publication\/262030260_Ergodicity_of_Approximate_MCMC_Chains_with_Applications_to_Large_Data_Sets\" \/>\n<meta name=\"viewport\" content=\"width=device-width,initial-scale=1\" \/>\n<link href=\"\/\/c5.rgstatic.net\/m\/22664197317151888\/styles\/rg.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/21004998181197492\/styles\/rg2.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<!--[if lt IE 9]><link href=\"\/\/c5.rgstatic.net\/m\/238176252723686\/styles\/ie.css\" type=\"text\/css\" rel=\"stylesheet\"\/><![endif]-->\n<link href=\"\/\/c5.rgstatic.net\/m\/217752362214895\/styles\/modules\/publicprofile.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<script src=\"\/\/c5.rgstatic.net\/m\/2321000301012716\/javascript\/vendor\/webfontloader\/webfontloader.js\" type=\"text\/javascript\"><\/script>\n <script>(function(i,s,o,g,r,a,m){i[\"GoogleAnalyticsObject\"]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,\"script\",\"\/\/www.google-analytics.com\/analytics.js\",\"ga\");\n ga(\"create\",\"UA-58591210-1\");ga(\"set\",\"anonymizeIp\",true);ga('set', 'dimension1', 'publication slurped');ga('set', 'dimension2', 'Article');ga('set', 'dimension3', 'Logged out');ga('set', 'dimension4', 'https');ga(\"send\",\"pageview\");<\/script>\n","webfont":"<noscript><\/noscript><script> WebFontConfig = { custom: { families: ['source_sans_pro_italic', 'source_sans_pro_bold', 'source_sans_pro', 'martel'], urls : ['\/\/c5.rgstatic.net\/m\/231392577336386\/styles\/fonts.css'] } }; WebFont.load(WebFontConfig); <\/script>\n","correlationId":"rgreq-3f590742-325f-49df-9846-ed3ce0163df0","accountId":null,"module":"publicliterature","action":"publicliterature.PublicPublicationDetails","page":"publicationDetail","product":"publications","backendTime":1046,"continent":"Asia","stylesHome":"\/\/c5.rgstatic.net\/m\/","staticHost":"c5.rgstatic.net","useEarlyFlush":false,"longRunningRequestIdentifier":"LongRunningRequest.publicliterature.PublicPublicationDetails","longRunningRequestFp":"e9e5bbe1366c7ee8c8e41d02f793c884ac9be19b","widgetId":"rgw29_56ab9ecea4af6"},"id":"rgw29_56ab9ecea4af6","partials":[],"templateName":"application\/stubs\/StaticHeader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.StaticHeader.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){
            Y.rg.core.pagespeed.Monitoring.monitorPage("\/\/glassmoni.researchgate.net", "publicliterature.PublicPublicationDetails.run.html.loggedOut.get", "59de9668d07aeb77ab4de5f24d382b5d199d2437", "rgreq-3f590742-325f-49df-9846-ed3ce0163df0", "05bd732ff48b25b54dede6f4afa0b94a970789c0");
        
            Y.rg.core.pagespeed.Monitoring.monitorPage("\/\/glassmoni.researchgate.net", "publicationDetail.loggedOut", "ed1993d9e20f6cefa83edacaa24401a18c071aea", "rgreq-3f590742-325f-49df-9846-ed3ce0163df0", "05bd732ff48b25b54dede6f4afa0b94a970789c0");
        })();
(function(){Y.rg.createInitialWidget({"data":{"year":"2016","inlinePromo":null,"isAdmin":false,"contactUrl":"https:\/\/www.researchgate.net\/contact","aboutUsUrl":"https:\/\/www.researchgate.net\/about","widgetId":"rgw30_56ab9ecea4af6"},"id":"rgw30_56ab9ecea4af6","partials":[],"templateName":"application\/stubs\/DefaultFooter.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.DefaultFooter.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"headerLogin":{"data":{"urlAfterLogin":"publication\/262030260_Ergodicity_of_Approximate_MCMC_Chains_with_Applications_to_Large_Data_Sets","requestToken":"R8WJfn+DNZM9xOOKGsFgn4rzlwcqHOa\/abvAOX0EqshCybVC5HQS+e+q8P\/KfTNxWC0m7DXYsGhqzkx7oMDBQset+5Sxmn\/CpUWU3e9AM7lixGVl9CYTUcbmAjEhlgCAVli2X2FZq7oeWgXHORgMHVPL6L90Q9h9c65R0wZ+RyasLwEjDQ9M+SpTOHZ9KyCRVQylGjYwiCx5keBsKBf7mgJ6sYehMg5X2gAdVkfYg3pqaq3\/+64+JoZH7U0N\/KSVXwxo6HBE+0t\/z4m5SR7MbtM2eEwEJuqBhRluLjMVsl8=","loginUrl":"https:\/\/www.researchgate.net\/application.Login.html","signupUrl":"https:\/\/www.researchgate.net\/signup.SignUp.html?ev=su_chnl_index&hdrsu=1&_sg=LfpqjHB29GhL14GLbsTJNTbAYWoYbUts2sdSL6cfjCmu1YLKAzGDcZLokcBjP2v3","encodedUrlAfterLogin":"cHVibGljYXRpb24vMjYyMDMwMjYwX0VyZ29kaWNpdHlfb2ZfQXBwcm94aW1hdGVfTUNNQ19DaGFpbnNfd2l0aF9BcHBsaWNhdGlvbnNfdG9fTGFyZ2VfRGF0YV9TZXRz","signupCallToAction":"Join for free","widgetId":"rgw32_56ab9ecea4af6"},"id":"rgw32_56ab9ecea4af6","partials":{"partial":"application\/stubs\/partials\/headerLoginDefault.html"},"templateName":"application\/stubs\/HeaderLogin.html","templateExtensions":[],"attrs":{"goal":"milestoneHeaderLoginSeen"},"widgetUrl":"https:\/\/www.researchgate.net\/application.HeaderLogin.html","viewClass":"views.application.HeaderLoginView","yuiModules":["rg.views.application.HeaderLoginView"],"stylesheets":[],"_isYUI":true},"cookieConsent":null,"logoSvgSrc":"https:\/\/c5.rgstatic.net\/m\/235107188705592\/images\/template\/brand-header-logo.svg","logoFallbackSrc":"https:\/\/c5.rgstatic.net\/m\/238113351022438\/images\/template\/brand-header-logo.png","widgetId":"rgw31_56ab9ecea4af6"},"id":"rgw31_56ab9ecea4af6","partials":{"schemaSocialProfiles":"application\/stubs\/partials\/schemaSocialProfiles.html"},"templateName":"application\/stubs\/HeaderLoggedOut.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.HeaderLoggedOut.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"logEvent":"su_banner","specialCopy":false,"widgetId":"rgw33_56ab9ecea4af6"},"id":"rgw33_56ab9ecea4af6","partials":[],"templateName":"application\/stubs\/LoggedOutBanner.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.LoggedOutBanner.html","viewClass":"views.application.LoggedOutBannerView","yuiModules":["rg.views.application.LoggedOutBannerView"],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.core.util.ParameterFilter.filter(["ev","cp","ch","ref","dbw","pli","loginT","uid","claimChannel","enrichId","enrichSource","utm_source","utm_medium","utm_campaign","el","ci"]);})();
});}); } else { throw 'YRG was not loaded when attaching widgets'; }</script><script> dataLayer = [{"pageCategory":"publication slurped","publicationType":"Article","eventCategory":"Publication page"}]; </script> <noscript><iframe src="//www.googletagmanager.com/ns.html?id=GTM-MKVKH7" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-MKVKH7');</script><script>(function(e){function n(n,t,o,a){"use strict";var i=e.document.createElement("link"),r=t||e.document.getElementsByTagName("script")[0],d=e.document.styleSheets;return i.rel="stylesheet",i.href=n,i.media="only x",a&&(i.onload=a),r.parentNode.insertBefore(i,r),i.onloadcssdefined=function(e){for(var t,o=0;d.length>o;o++)d[o].href&&d[o].href.indexOf(n)>-1&&(t=!0);t?e():setTimeout(function(){i.onloadcssdefined(e)})},i.onloadcssdefined(function(){i.media=o||"all"}),i}function t(e,n){e.onload=function(){e.onload=null,n&&n.call(e)},"isApplicationInstalled"in navigator&&"onloadcssdefined"in e&&e.onloadcssdefined(n)}var o=function(a,i){"use strict";if(a&&3===a.length){var r=e.Image,d=!(!document.createElementNS||!document.createElementNS("http://www.w3.org/2000/svg","svg").createSVGRect||!document.implementation.hasFeature("http://www.w3.org/TR/SVG11/feature#Image","1.1")||e.opera&&-1===navigator.userAgent.indexOf("Chrome")||-1!==navigator.userAgent.indexOf("Series40")),c=new r;c.onerror=function(){o.method="png",o.href=a[2],n(a[2])},c.onload=function(){var e=1===c.width&&1===c.height,r=a[e&&d?0:e?1:2];o.method=e&&d?"svg":e?"datapng":"png",o.href=r,t(n(r),i)},c.src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///ywAAAAAAQABAAACAUwAOw==",document.documentElement.className+=" grunticon"}};o.loadCSS=n,o.onloadCSS=t,e.grunticon=o})(this);grunticon(["https://c5.rgstatic.net/c/o1q2er/styles/icons/_header-ico.svg.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_header-ico.png.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_header-ico.fallback.scss"]);grunticon(["https://c5.rgstatic.net/c/o1q2er/styles/icons/_admin-ico.svg.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_admin-ico.png.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_admin-ico.fallback.scss"]);grunticon(["https://c5.rgstatic.net/c/o1q2er/styles/icons/_ico.svg.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_ico.png.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_ico.fallback.scss"]);</script></body>
</html>
