<!DOCTYPE html> <html lang="en" class="" id="rgw51_56ab19b4883a8"> <head > <meta charset="utf-8"/> <meta http-equiv="content-type" content="text/html; charset=UTF-8"/> <meta name="Rg-Request-Token" id="Rg-Request-Token" content="bH7P6hnMG7lavlgiSXl5+8c476zRlAYrQJmR13GzIICdys7MRKri3rrZiZZFQ1dbrBZzzzCpMlGy+LfaY8kN4yUDgZ2QEPvI5ReK0feJSQrBgv/Eg15nAfOVWcolxHxdKppa6JNKEeprdXu63M9jep7fRQCzsPKfB6LdAFj2fIbTeRHwHbT2A5Q+/lal4Gj2N2kzVxxY0qARl4BlkfdJ9mjiximyTRD50d1rkEuHpG4sNTEzsPvx+d/LwguZIMPK0rRnyw8TcUIoKyk7QMA89JSYTDi8zEDTMEs68KH5jC8="/> <meta http-equiv="expires" content="0"/> <link rel="apple-touch-icon" sizes="57x57" href="https://www.researchgate.net/apple-touch-icon-57x57.png"> <link rel="apple-touch-icon" sizes="60x60" href="https://www.researchgate.net/apple-touch-icon-60x60.png"> <link rel="apple-touch-icon" sizes="72x72" href="https://www.researchgate.net/apple-touch-icon-72x72.png"> <link rel="apple-touch-icon" sizes="76x76" href="https://www.researchgate.net/apple-touch-icon-76x76.png"> <link rel="apple-touch-icon" sizes="114x114" href="https://www.researchgate.net/apple-touch-icon-114x114.png"> <link rel="apple-touch-icon" sizes="120x120" href="https://www.researchgate.net/apple-touch-icon-120x120.png"> <link rel="apple-touch-icon" sizes="144x144" href="https://www.researchgate.net/apple-touch-icon-144x144.png"> <link rel="apple-touch-icon" sizes="152x152" href="https://www.researchgate.net/apple-touch-icon-152x152.png"> <link rel="apple-touch-icon" sizes="180x180" href="https://www.researchgate.net/apple-touch-icon-180x180.png"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-32x32.png" sizes="32x32"> <link rel="icon" type="image/png" href="https://www.researchgate.net/android-chrome-192x192.png" sizes="192x192"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-96x96.png" sizes="96x96"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-16x16.png" sizes="16x16"> <link rel="shortcut icon" type="image/x-icon" href="https://c5.rgstatic.net/m/2390829798215018/images/favicon.ico"/> <link rel="manifest" href="https://www.researchgate.net/manifest.json"> <meta name="msapplication-TileColor" content="#da532c"> <meta name="msapplication-TileImage" content="https://www.researchgate.net/mstile-144x144.png"> <meta name="theme-color" content="#444444"> <link rel="search" type="application/opensearchdescription+xml" title="ResearchGate search" href="https://www.researchgate.net/application.DownloadOpenSearchPlugin.html"/> <link rel="meta" type="application/rdf+xml" title="ICRA labels" href="https://www.researchgate.net/application.DownloadLabels.html"/> <link rel="http://oexchange.org/spec/0.8/rel/related-target" type="application/xrd+xml" href="https://www.researchgate.net/application.DownloadOExchange.html"/> <base href="https://www.researchgate.net/"/> <script>
    var rgConfig = {
        correlationId: "rgreq-d6cd385c-0a39-49ac-af9d-da4ceb76aa42",
        accountId: "",
        module: "publicliterature",
        action: "publicliterature.PublicPublicationDetails",
        page: "publicationDetail",
        product: "publications",
        continent: "Asia",
        stylesHome: "//c5.rgstatic.net/m/",
        staticHost: "c5.rgstatic.net",
        longRunningRequestIdentifier: "LongRunningRequest.publicliterature.PublicPublicationDetails",
        longRunningRequestFp: "e9e5bbe1366c7ee8c8e41d02f793c884ac9be19b"
    };
    window.rootUrl = "https://www.researchgate.net/";
</script> <link rel="canonical" href="https://www.researchgate.net/publication/221344933_An_HDP-HMM_for_systems_with_state_persistence" />
<link rel="dns-prefetch" href="//c5.rgstatic.net" />
<link rel="dns-prefetch" href="//i1.rgstatic.net" />
<meta property="twitter:card" content="summary" />
<meta property="twitter:site" content="@ResearchGate" />
<meta property="og:title" content="An HDP-HMM for systems with state persistence" />
<meta property="og:description" content="The hierarchical Dirichlet process hidden Markov model (HDP-HMM) is a flexible, nonparametric model which allows state spaces of unknown size to be learned from data. We demonstrate some..." />
<meta property="og:site_name" content="ResearchGate" />
<meta property="og:image" content="https://i1.rgstatic.net/publication/221344933_An_HDP-HMM_for_systems_with_state_persistence/links/53fe28a60cf283c3583bcdd5/smallpreview.png" />
<meta property="og:url" content="https://www.researchgate.net/publication/221344933_An_HDP-HMM_for_systems_with_state_persistence" />
<meta property="rg:id" content="PB:221344933" />
<meta name="DC.identifier" scheme="DCTERMS.URI" content="http://dx.doi.org/10.1145/1390156.1390196" />
<meta name="gs_meta_revision" content="1.1" />
<meta name="citation_title" content="An HDP-HMM for systems with state persistence" />
<meta name="citation_author" content="Emily B. Fox" />
<meta name="citation_author" content="Erik B. Sudderth" />
<meta name="citation_author" content="Michael I. Jordan" />
<meta name="citation_author" content="Alan S. Willsky" />
<meta name="citation_conference_title" content="Machine Learning, Proceedings of the Twenty-Fifth International Conference (ICML 2008), Helsinki, Finland, June 5-9, 2008" />
<meta name="citation_publication_date" content="2008/01/01" />
<meta name="citation_firstpage" content="312" />
<meta name="citation_lastpage" content="319" />
<meta name="citation_doi" content="10.1145/1390156.1390196" />
<meta name="citation_pdf_url" content="https://www.researchgate.net/profile/Michael_Jordan13/publication/221344933_An_HDP-HMM_for_systems_with_state_persistence/links/53fe28a60cf283c3583bcdd5.pdf" />
<meta name="citation_abstract_html_url" content="https://www.researchgate.net/publication/221344933_An_HDP-HMM_for_systems_with_state_persistence" />
<meta name="citation_fulltext_html_url" content="https://www.researchgate.net/publication/221344933_An_HDP-HMM_for_systems_with_state_persistence" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<link href="//c5.rgstatic.net/m/22664197317151888/styles/rg.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/21004998181197492/styles/rg2.css" type="text/css" rel="stylesheet"/>
<!--[if lt IE 9]><link href="//c5.rgstatic.net/m/238176252723686/styles/ie.css" type="text/css" rel="stylesheet"/><![endif]-->
<link href="//c5.rgstatic.net/m/217752362214895/styles/modules/publicprofile.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/21993347442549/styles/pow/publicliterature/FollowPublicationPromo.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/282514599719602/styles/pow/application/PdfJsReader.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/23819663151220/styles/pow/publicliterature/PublicationInlineReader.css" type="text/css" rel="stylesheet"/>
<script src="//c5.rgstatic.net/m/2321000301012716/javascript/vendor/webfontloader/webfontloader.js" type="text/javascript"></script>
 <script>(function(i,s,o,g,r,a,m){i["GoogleAnalyticsObject"]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,"script","//www.google-analytics.com/analytics.js","ga");
 ga("create","UA-58591210-1");ga("set","anonymizeIp",true);ga('set', 'dimension1', 'publication full-text');ga('set', 'dimension2', 'Conference Paper');ga('set', 'dimension3', 'Logged out');ga('set', 'dimension4', 'https');ga("send","pageview");</script>
  <script> WebFontConfig = { custom: { families: ['source_sans_pro_italic', 'source_sans_pro_bold', 'source_sans_pro', 'martel'], urls : ['//c5.rgstatic.net/m/231392577336386/styles/fonts.css'] } }; WebFont.load(WebFontConfig); </script><noscript></noscript>

<title>An HDP-HMM for systems with state persistence (PDF Download Available)</title>
<meta name="description" content="Official Full-Text Publication: An HDP-HMM for systems with state persistence on ResearchGate, the professional network for scientists."/>
<meta name="keywords" content="scientific network, scientific platform, scientific community, research partner, research collaboration, journal articles, international collaboration, find researcher, lifescience researcher, interdisciplinary research, research collaboration"/>
</head>
<body class="use-svg-icons logged-out">
<div id="page-container">
<script type="text/javascript">var googletag = googletag || {}; googletag.cmd = googletag.cmd || [];
(function() { var gads = document.createElement("script"); gads.async = true; gads.type = "text/javascript"; var useSSL = "https:" == document.location.protocol; gads.src = (useSSL ? "https:" : "http:") + "//www.googletagservices.com/tag/js/gpt.js"; var node =document.getElementsByTagName("script")[0]; node.parentNode.insertBefore(gads, node); })();</script><div id="main" class="logged-out-header-support">
<div id="content" class="">

<noscript>
<div class="c-box-warning full-width-element" style="text-align: center; ">
    <div style="margin: auto; padding:10px;" class="container">
        <b>For full functionality of ResearchGate it is necessary to enable JavaScript.
            Here are the <a href="http://www.enable-javascript.com/" rel="nofollow" target="_blank">
                instructions how to enable JavaScript in your web browser</a>.</b>
    </div>
</div>
</noscript>

<div id="rgw1_56ab19b4883a8" itemscope itemtype="http://schema.org/ScholarlyArticle"><div class="publication-wrapper publication-wrapper-onecol" id="rgw2_56ab19b4883a8" itemscope itemtype="http://schema.org/ScholarlyArticle"> <div class="c-col-content"> <div class="c-content"> <div class="clearfix">  <div class="publication-header"> <div id="rgw5_56ab19b4883a8">  <div class="type-label"> Conference Paper   </div> <span class="Z3988" title="ctx_ver=Z39.88-2004&rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&rfr_id=info%3Asid%2Fresearchgate.net%3Aresearchgate&rft_id=info%3Adoi%2F10.1145%2F1390156.1390196&rft.atitle=An%20HDP-HMM%20for%20systems%20with%20state%20persistence&rft.title=Proceedings%20of%20the%2025th%20International%20Conference%20on%20Machine%20Learning&rft.jtitle=Proceedings%20of%20the%2025th%20International%20Conference%20on%20Machine%20Learning&rft.date=2008&rft.pages=312-319&rft.au=Emily%20B.%20Fox%2CErik%20B.%20Sudderth%2CMichael%20I.%20Jordan%2CAlan%20S.%20Willsky&rft.genre=inProceedings"></span> <h1 class="pub-title" itemprop="name">An HDP-HMM for systems with state persistence</h1> <meta itemprop="headline" content="An HDP-HMM for systems with state persistence">  <meta itemprop="image" content="https://i1.rgstatic.net/publication/221344933_An_HDP-HMM_for_systems_with_state_persistence/links/53fe28a60cf283c3583bcdd5/smallpreview.png">  <div id="rgw7_56ab19b4883a8" class="publication-detail-author-list"> <div> <ul class="clearfix js-people-list">  <li id="rgw8_56ab19b4883a8"> <a href="researcher/44211050_Emily_B_Fox" class="pub-detail-item author-item" itemprop="author" itemscope itemtype="http://schema.org/Person"> <div class="indent-left"> <div class="people-img">  <img src="https://c5.rgstatic.net/m/2951093203564/images/template/default/profile/profile_default_s.jpg" title="Emily B. Fox" alt="Emily B. Fox" height="20px" width="20px" style="height: 20px;"/>  </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Emily B. Fox</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item   not-claimed " id="rgw9_56ab19b4883a8">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="researcher/44211050_Emily_B_Fox"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="Emily B. Fox" alt="Emily B. Fox" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">       </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="researcher/44211050_Emily_B_Fox" class="display-name">Emily B. Fox</a>    </h5> <div class="truncate-single-line meta">   </div>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>  <li id="rgw10_56ab19b4883a8"> <a href="researcher/8993785_Erik_B_Sudderth" class="pub-detail-item author-item" itemprop="author" itemscope itemtype="http://schema.org/Person"> <div class="indent-left"> <div class="people-img">  <img src="https://c5.rgstatic.net/m/2951093203564/images/template/default/profile/profile_default_s.jpg" title="Erik B. Sudderth" alt="Erik B. Sudderth" height="20px" width="20px" style="height: 20px;"/>  </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Erik B. Sudderth</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item   not-claimed " id="rgw11_56ab19b4883a8">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="researcher/8993785_Erik_B_Sudderth"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="Erik B. Sudderth" alt="Erik B. Sudderth" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">       </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="researcher/8993785_Erik_B_Sudderth" class="display-name">Erik B. Sudderth</a>    </h5> <div class="truncate-single-line meta">   </div>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>  <li id="rgw12_56ab19b4883a8" itemprop="author" itemscope itemtype="http://schema.org/Person"> <a itemprop="sameAs" href="profile/Michael_Jordan13" class="pub-detail-item account-item"> <div class="indent-left"> <div class="people-img"> <img  src="https://i1.rgstatic.net/ii/profile.image/AS%3A278648436346888%401443446372379_m" title="Michael Jordan" alt="Michael Jordan" height="20px" width="20px" style="height: 20px;"/> </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Michael Jordan</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item  remove-action-indent   " id="rgw13_56ab19b4883a8" data-account-key="Michael_Jordan13">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="profile/Michael_Jordan13"> <img class="lazyload" data-src="https://i1.rgstatic.net/ii/profile.image/AS%3A278648436346888%401443446372379_l" title="Michael Jordan" alt="Michael Jordan" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">     </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="profile/Michael_Jordan13" class="display-name">Michael Jordan</a>    </h5> <div class="truncate-single-line meta">   <a class="meta ga-top-coauthor-institution" href="institution/University_of_California_Berkeley" title="University of California, Berkeley">University of California, Berkeley</a>     </div>  <a href="javascript:" class="btn btn-promote btn-large people-item-contact-author js-contact-author">Message author</a>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>  <li id="rgw14_56ab19b4883a8"> <a href="researcher/5936615_Alan_S_Willsky" class="pub-detail-item author-item" itemprop="author" itemscope itemtype="http://schema.org/Person"> <div class="indent-left"> <div class="people-img">  <img src="https://c5.rgstatic.net/m/2951093203564/images/template/default/profile/profile_default_s.jpg" title="Alan S. Willsky" alt="Alan S. Willsky" height="20px" width="20px" style="height: 20px;"/>  </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Alan S. Willsky</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item   not-claimed " id="rgw15_56ab19b4883a8">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="researcher/5936615_Alan_S_Willsky"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="Alan S. Willsky" alt="Alan S. Willsky" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">       </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="researcher/5936615_Alan_S_Willsky" class="display-name">Alan S. Willsky</a>    </h5> <div class="truncate-single-line meta">   </div>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>   </ul> <div class="js-loading"></div>  </div> </div> <div class="pub-details js-pub-details">  <div> Massachusetts Institute of Technology Stochastic Systems Group </div>      DOI:&nbsp;10.1145/1390156.1390196     Conference: Machine Learning, Proceedings of the Twenty-Fifth International Conference (ICML 2008), Helsinki, Finland, June 5-9, 2008      <div class="pub-source"> Source: <a href="http://dblp.uni-trier.de/db/conf/icml/icml2008.html#FoxSJW08" rel="nofollow">DBLP</a> </div>  </div> <div id="rgw16_56ab19b4883a8" class="pub-abstract">  <div class="clearfix">   <p itemprop="description"> <strong>ABSTRACT</strong> <div>The hierarchical Dirichlet process hidden Markov model (HDP-HMM) is a flexible, nonparametric model which allows state spaces of unknown size to be learned from data. We demonstrate some limitations of the original HDP-HMM formulation (Teh et al., 2006), and propose a sticky exten- sion which allows more robust learning of smoothly varying dynamics. Using DP mix- tures, this formulation also allows learning of more complex, multimodal emission dis- tributions. We further develop a sampling algorithm that employs a truncated approx- imation of the DP to jointly resample the full state sequence, greatly improving mixing rates. Via extensive experiments with syn- thetic data and the NIST speaker diarization database, we demonstrate the advantages of our sticky extension, and the utility of the HDP-HMM in real-world applications.</div> </p>  </div>   </div>      <div class="action-container"> <div id="rgw17_56ab19b4883a8" class="follow-publication-promo"> <table> <tr> <td class="follow-publication-promo-text-cell"> <p>Get notified about updates to this publication</p> <a class="btn btn-large btn-promote js-follow-publication ga-follow-publication-new-promo">Follow publication</a> </td> <td> <div class="follow-publication-publication-image"></div> </td> </tr> </table> </div>  <div class="clear"></div> <div class="share-dialog-container" style="display: none;">  </div> </div> </div> <div style="margin-left: -20px; margin-right: -20px;">  </div> </div>  <div class="publication-detail-dfp-container rf"> <div id="rgw31_56ab19b4883a8">  </div> </div>  </div>  <div class="clearfix"> <div class="pdf-js-container clearfix " id="rgw43_56ab19b4883a8">  <div class="pdf-js-header js-sticky-header clear">  <a class="blue-link js-download rf btn btn-promote" href="https://www.researchgate.net/profile/Michael_Jordan13/publication/221344933_An_HDP-HMM_for_systems_with_state_persistence/links/53fe28a60cf283c3583bcdd5.pdf?inViewer=0&amp;pdfJsDownload=0&amp;origin=publication_detail">Download full-text</a>  <h3>Full-text</h3> <span class="publication-info">  <span class="js-doi-container" style="display: none;"> DOI: <span class="js-doi"></span> &middot; </span> Available from: <a class="js-name" href="profile/Michael_Jordan13">Michael Jordan</a>, <span class="js-publication-date"> Aug 27, 2014 </span>   </span>  </div>  <div class="social-share-container"><div id="rgw45_56ab19b4883a8" class="social-share js-social-share"> <div class="social-share-heading">Share</div>  <a id="rgw46_56ab19b4883a8" href="javascript:" title="Share on Facebook" class="link-nostyle js-share-item share-icon "  data-url="http://www.facebook.com/share.php?u={{url}}{{#title}}&amp;t={{title}}{{/title}}" data-width="600" data-height="350" data-name="Facebook"> <span class="share-icon ico-share-facebook-round reset-background ga-share-blog-facebook"></span> </a>  <a id="rgw47_56ab19b4883a8" href="javascript:" title="Share on Twitter" class="link-nostyle js-share-item share-icon "  data-url="http://twitter.com/intent/tweet?text={{#title}}{{title}}: {{/title}}{{url}}&amp;via=researchgate" data-width="600" data-height="350" data-name="Twitter"> <span class="share-icon ico-share-twitter-round reset-background ga-share-blog-twitter"></span> </a>  <a id="rgw48_56ab19b4883a8" href="javascript:" title="Share on Google+" class="link-nostyle js-share-item share-icon "  data-url="https://plus.google.com/share?url={{url}}" data-width="600" data-height="600" data-name="Google+"> <span class="share-icon ico-share-gplus-round reset-background ga-share-blog-gplus"></span> </a>  <a id="rgw49_56ab19b4883a8" href="javascript:" title="Share on LinkedIn" class="link-nostyle js-share-item share-icon "  data-url="http://www.linkedin.com/shareArticle?mini=true&amp;url={{url}}{{#title}}&amp;title={{title}}{{/title}}&amp;source=ResearchGate" data-width="520" data-height="570" data-name="LinkedIn"> <span class="share-icon ico-share-linkedin-round reset-background ga-share-blog-linkedin"></span> </a>  <a id="rgw50_56ab19b4883a8" href="javascript:" title="Share on Reddit" class="link-nostyle js-share-item share-icon "  data-url="https://www.reddit.com/submit?url={{url}}{{#title}}&amp;title={{title}}{{/title}}" data-width="600" data-height="600" data-name="Reddit"> <span class="share-icon ico-share-reddit reset-background ga-share-blog-reddit"></span> </a>  </div></div>    <iframe id="rgw44_56ab19b4883a8" src="https://www.researchgate.net/c/o1o9o3/javascript/lib/pdfjs/web/viewer.html?file=https%3A%2F%2Fwww.researchgate.net%2Fprofile%2FMichael_Jordan13%2Fpublication%2F221344933_An_HDP-HMM_for_systems_with_state_persistence%2Flinks%2F53fe28a60cf283c3583bcdd5.pdf%3FinViewer%3D1%26pdfJsDownload%3D1%26origin%3Dpublication_detail" allowfullscreen frameborder="0" style="width: 100%; height: 100%; box-sizing: border-box;"></iframe>    </div> <noscript> <div id="rgw30_56ab19b4883a8"  itemprop="articleBody">  <p>Page 1</p> <p>An HDP-HMM for Systems with State Persistence<br />Emily B. Fox<br />Department of EECS, Massachusetts Institute of Technology, Cambridge, MA 02139<br />ebfox@mit.edu<br />Erik B. Sudderth<br />Department of EECS, University of California, Berkeley, CA 94720<br />sudderth@eecs.berkeley.edu<br />Michael I. Jordan<br />Department of EECS and Department of Statistics, University of California, Berkeley, CA 94720<br />jordan@eecs.berkeley.edu<br />Alan S. Willsky<br />Department of EECS, Massachusetts Institute of Technology, Cambridge, MA 02139<br />willsky@mit.edu<br />Abstract<br />The hierarchical Dirichlet process hidden<br />Markov model (HDP-HMM) is a flexible,<br />nonparametric model which allows state<br />spaces of unknown size to be learned from<br />data. We demonstrate some limitations of<br />the original HDP-HMM formulation (Teh<br />et al., 2006), and propose a sticky exten-<br />sion which allows more robust learning of<br />smoothly varying dynamics. Using DP mix-<br />tures, this formulation also allows learning<br />of more complex, multimodal emission dis-<br />tributions. We further develop a sampling<br />algorithm that employs a truncated approx-<br />imation of the DP to jointly resample the<br />full state sequence, greatly improving mixing<br />rates. Via extensive experiments with syn-<br />thetic data and the NIST speaker diarization<br />database, we demonstrate the advantages of<br />our sticky extension, and the utility of the<br />HDP-HMM in real-world applications.<br />1. Introduction<br />Hidden Markov models (HMMs) have been a major<br />success story in many applied fields; they provide core<br />statistical inference procedures in areas as diverse as<br />speech recognition, genomics, structural biology, ma-<br />chine translation, cryptanalysis and finance. Even af-<br />ter four decades of work on HMMs, however, signifi-<br />cant problems remain. One lingering issue is the choice<br />of the hidden state space’s cardinality. While standard<br />parametric model selection methods can be adapted to<br />the HMM, there is little understanding of the strengths<br />and weaknesses of such methods in this setting.<br />Appearing in Proceedings of the 25thInternational Confer-<br />ence on Machine Learning, Helsinki, Finland, 2008. Copy-<br />right 2008 by the author(s)/owner(s).<br />Recently, Teh et al. (2006) presented a nonparamet-<br />ric Bayesian approach to HMMs in which a stochastic<br />process, the hierarchical Dirichlet process (HDP), de-<br />fines a prior distribution on transition matrices over<br />countably infinite state spaces. The resulting HDP-<br />HMM leads to data–driven learning algorithms which<br />infer posterior distributions over the number of states.<br />This posterior uncertainty can be integrated out when<br />making predictions, effectively averaging over models<br />of varying complexity.The HDP-HMM has shown<br />promise in a variety of applications, including visual<br />scene recognition (Kivinen et al., 2007) and the mod-<br />eling of genetic recombination (Xing &amp; Sohn, 2007).<br />One serious limitation of the standard HDP-HMM<br />is that it inadequately models the temporal persis-<br />tence of states. This problem arises in classical finite<br />HMMs as well, where semi-Markovian models are of-<br />ten proposed as solutions. However, the problem is<br />exacerbated in the nonparametric setting, where the<br />Bayesian bias towards simpler models is insufficient to<br />prevent the HDP-HMM from learning models with un-<br />realistically rapid dynamics, as demonstrated in Fig. 1.<br />To illustrate the seriousness of this issue, let us con-<br />sider a challenging application that we revisit in Sec. 5.<br />The problem of speaker diarization involves segment-<br />ing an audio recording into time intervals associated<br />with individual speakers. This application seems like<br />a natural fit for the HDP-HMM, as the number of true<br />speakers is typically unknown, and may grow as more<br />data is observed. However, this is not a setting in<br />which model averaging is the goal; rather, it is critical<br />to infer the number of speakers as well as the transi-<br />tions among speakers. As we show in Sec. 5, the HDP-<br />HMM’s tendency to rapidly switch among redundant<br />states leads to poor speaker diarization performance.<br />In contrast, the methods that we develop in this paper<br />yield a state-of-the-art speaker diarization method, as</p>  <p>Page 2</p> <p>An HDP-HMM for Systems with State Persistence<br />0 50 100150 200 250300 350400<br />−80<br />−60<br />−40<br />−20<br />0<br />20<br />40<br />60<br />80<br />Observation Sequence<br />Time<br />(a)<br />0 50 100 150200 250300 350400<br />0<br />2<br />4<br />6<br />8<br />10<br />12<br />14<br />Time<br />True Mode Sequence<br />0 50 100150 200250 300350 400<br />0<br />2<br />4<br />6<br />8<br />10<br />12<br />14<br />Time<br />(c)<br />Estimated Mode Sequence<br />0 50100150200 250300 350 400<br />0<br />2<br />4<br />6<br />8<br />10<br />12<br />14<br />Time<br />Estimated Mode Sequence<br />(b)(d)<br />Figure 1. Sensitivity of the HDP-HMM to within-state variations in the observations. (a) Observation sequence; (b) true<br />state sequence; estimated state sequence after 100 Gibbs iterations for the (c) original and (d) sticky HDP-HMM, with<br />errors indicated in red. Without an extra self–transition bias, the HDP-HMM rapidly transitions among redundant states.<br />well as a general solution to the problem of state persis-<br />tence in HDP-HMMs. The approach is easily stated—<br />we simply augment the HDP-HMM to include a pa-<br />rameter for self-transition bias, and place a separate<br />prior on this parameter. The challenge is to consis-<br />tently execute this idea in a nonparametric Bayesian<br />framework. Earlier papers have also proposed self-<br />transition parameters for HMMs with infinite state<br />spaces (Beal et al., 2002; Xing &amp; Sohn, 2007), but<br />did not formulate general solutions that integrate fully<br />with nonparametric Bayesian inference.<br />While the HDP-HMM treats the state transition dis-<br />tribution nonparametrically, it is also desirable to al-<br />low more flexible, nonparametric emission distribu-<br />tions. In classical applications of HMMs, finite Gaus-<br />sian mixtures are often used to model multimodal ob-<br />servations. Dirichlet process (DP) mixtures provide<br />an appealing alternative which avoids fixing the num-<br />ber of observation modes.<br />tions are not identifiable for the standard HDP-HMM,<br />due to the tendency to rapidly switch between redun-<br />dant states. With an additional self-transition bias,<br />however, we show that a fully nonparametric HMM<br />leads to effective learning algorithms. In particular,<br />we develop a blocked Gibbs sampler which leverages<br />forward–backward recursions to jointly resample the<br />state and emission assignments for all observations.<br />Such emission distribu-<br />In Sec. 2, we begin by presenting background material<br />on the HDP. Sec. 3 then links these nonparametric<br />methods with HMMs, and extends them to account<br />for state persistence. We further augment the model<br />with multimodal emission distributions in Sec. 4, and<br />present results using synthetic data and the NIST<br />speaker diarization database in Sec. 5.<br />2. Background: Dirichlet Processes<br />A Dirichlet process (DP), denoted by DP(γ,H), is a<br />distribution over countably infinite random measures<br />G0(θ) =<br />∞<br />?<br />k=1<br />βkδ(θ − θk)θk∼ H(1)<br />on a parameter space Θ. The weights are sampled via<br />a stick-breaking construction (Sethuraman, 1994):<br />βk= β′<br />k<br />k−1<br />?<br />ℓ=1<br />(1 − β′<br />ℓ)β′<br />k∼ Beta(1,γ) (2)<br />We denote this distribution by β ∼ GEM(γ).<br />The DP is commonly used as a prior on the parameters<br />of a mixture model of unknown complexity, resulting<br />in a DPMM (see Fig. 2(a)). To generate observations,<br />we choose¯θi ∼ G0 and yi ∼ F(¯θi). This sampling<br />process is often described via a discrete variable zi∼ β<br />indicating which component generates yi∼ F(θzi).<br />The hierarchical Dirichlet process (HDP) (Teh et al.,<br />2006) extends the DP to cases in which groups of data<br />are produced by related, yet unique, generative pro-<br />cesses. Taking a hierarchical Bayesian approach, the<br />HDP places a global Dirichlet process prior DP(α,G0)<br />on Θ, and then draws group specific distributions<br />Gj∼ DP(α,G0). Here, the base measure G0 acts as<br />an “average” distribution (E[Gj] = G0) encoding the<br />frequency of each shared, global parameter:<br />∞<br />?<br />∞<br />?<br />Because G0 is discrete, multiple˜θjt ∼ G0 may take<br />identical values θk. Eq. (4) aggregates these probabil-<br />ities, allowing an observation yjito be directly associ-<br />ated with the unique global parameters via an indica-<br />tor random variable zji∼ πj. See Fig. 2(b).<br />Gj(θ) =<br />t=1<br />˜ πjtδ(θ −˜θjt)˜ πj∼ GEM(α) (3)<br />=<br />k=1<br />πjkδ(θ − θk)πj∼ DP(α,β) (4)<br />We can alternatively represent this generative process<br />via indicator variables tji ∼ ˜ πj and kjt ∼ β, as in<br />Fig. 2(c).The stick-breaking priors on these mix-<br />ture weights can be analytically marginalized, yield-<br />ing simple forms for the predictive distributions of as-<br />signments. The resulting distribution on partitions is<br />sometimes described using the metaphor of a Chinese<br />restaurant franchise (CRF). There are J restaurants<br />(groups), each with infinitely many tables (clusters) at</p>  <p>Page 3</p> <p>An HDP-HMM for Systems with State Persistence<br />(a)(b)(c)<br />Figure 2. (a) DPMM in which β ∼ GEM(γ), θk ∼ H(λ),<br />zi ∼ β, and yi ∼ f(y | θzi). (b) HDP mixture model<br />with β ∼ GEM(γ), πj ∼ DP(α,β), θk ∼ H(λ), zji ∼<br />πj, and yji ∼ f(y | θzji). (c) CRF with loyal customers.<br />Customers yji sit at table tji ∼ ˜ πj which considers dish<br />¯kjt ∼ β, but override variables wjt ∼ Ber(κ/α + κ) can<br />force the served dish kjt to be j. The original CRF, as<br />described in Sec. 2, has κ = 0 so that kjt =¯kjt.<br />which customers (observations) sit. Upon entering the<br />jthrestaurant, customer yjisits at currently occupied<br />tables tjiwith probability proportional to the number<br />of currently seated customers, or starts a new table˜t<br />with probability proportional to α. Each table chooses<br />a dish (parameter)˜θjt= θkjtwith probability propor-<br />tional to the number of other tables in the franchise<br />that ordered that dish, or orders a new dish θ˜kwith<br />probability proportional to γ. Observation yjiis then<br />generated by global parameter θzji=˜θjtji= θkjtji.<br />An alternative, non–constructive characterization of<br />samples G0∼ DP(γ,H) from a Dirichlet process states<br />that for every finite partition {A1,...,AK} of Θ,<br />(G0(A1),...,G0(AK))<br />∼ Dir(γH(A1),...,γH(AK)).(5)<br />Using this expression, it can be shown that the fol-<br />lowing finite, hierarchical mixture model converges in<br />distribution to the HDP as L → ∞ (Ishwaran &amp; Zare-<br />pour, 2002; Teh et al., 2006):<br />β ∼ Dir(γ/L,...,γ/L)<br />πj∼ Dir(αβ1,...,αβL).<br />(6)<br />Later sections use this weak limit approximation to<br />develop efficient, blocked sampling algorithms.<br />3. The Sticky HDP-HMM<br />The HDP can be used to develop an HMM with an<br />unknown, potentially infinite state space (Teh et al.,<br />2006). For this HDP-HMM, each HDP group-specific<br />distribution, πj, is a state-specific transition distribu-<br />tion and, due to the infinite state space, there are in-<br />finitely many groups. Let zt denote the state of the<br />Markov chain at time t. For Markov chains zt∼ πzt−1,<br />so that zt−1indexes the group to which ytis assigned.<br />The current HMM state ztthen indexes the parameter<br />θztused to generate observation yt(see Fig. 3).<br />Figure 3. Graph of the sticky HDP-HMM. The state<br />evolves as zt+1 ∼ πzt, where πk ∼ DP(α + κ,(αβ +<br />κδk)/(α+κ)) and β ∼ GEM(γ), and observations are gen-<br />erated as yt ∼ F(θzt). The original HDP-HMM has κ = 0.<br />By sampling πj ∼ DP(α,β), the HDP prior encour-<br />ages states to have similar transition distributions<br />(E[πjk] = βk). However, it does not differentiate self–<br />transitions from moves between states. When model-<br />ing systems with state persistence, the flexible nature<br />of the HDP-HMM prior allows for state sequences with<br />unrealistically fast dynamics to have large posterior<br />probability. For example, with Gaussian emissions, as<br />in Fig. 1, a good explanation of the data is to divide an<br />observation block into two small–variance states with<br />slightly different means, and then rapidly switch be-<br />tween them (see Fig. 1). In such cases, many models<br />with redundant states may have large posterior prob-<br />ability, thus impeding our ability to identify a single<br />dynamical model which best explains the observations.<br />The problem is compounded by the fact that once this<br />alternating pattern has been instantiated by the sam-<br />pler, its persistence is then reinforced by the prop-<br />erties of the Chinese restaurant franchise, thus slow-<br />ing mixing rates. Furthermore, when observations are<br />high-dimensional, this fragmentation of data into re-<br />dundant states may reduce predictive performance. In<br />many applications, one would thus like to be able to<br />incorporate prior knowledge that slow, smoothly vary-<br />ing dynamics are more likely.<br />To address these issues, we propose to instead sample<br />transition distributions πjas follows:<br />πj∼ DP<br />?<br />α + κ,αβ + κδj<br />α + κ<br />?<br />.(7)<br />Here, (αβ + κδj) indicates that an amount κ &gt; 0 is<br />added to the jthcomponent of αβ. The measure of πj<br />over a finite partition (Z1,...,ZK) of the positive in-<br />tegers Z+, as described by Eq. (5), adds an amount κ<br />only to the arbitrarily small partition containing j, cor-<br />responding to a self-transition. When κ = 0 the origi-<br />nal HDP-HMM is recovered. Because positive κ values<br />increase the prior probability E[πjj] of self–transitions,<br />we refer to this extension as the sticky HDP-HMM.<br />In some ways, this κ parameter is reminiscent of the<br />infinite HMM’s self-transition bias (Beal et al., 2002).</p>  <p>Page 4</p> <p>An HDP-HMM for Systems with State Persistence<br />However, that paper relied on a heuristic, approximate<br />Gibbs sampler. The full connection between the infi-<br />nite HMM and an underlying nonparametric Bayesian<br />prior, as well as the development of a globally con-<br />sistent inference algorithm, was made in Teh et al.<br />(2006), but without a treatment of a self-transition<br />parameter.<br />3.1. A CRF with Loyal Customers<br />We further abuse the Chinese restaurant metaphor by<br />extending it to the sticky HDP-HMM, where our fran-<br />chise now has restaurants with loyal customers. Each<br />restaurant has a specialty dish with the same index as<br />that of the restaurant. Although this dish is served<br />elsewhere, it is more popular in the dish’s namesake<br />restaurant. We see this increased popularity from the<br />fact that a table’s dish is now drawn as<br />kjt∼αβ + κδj<br />α + κ<br />.(8)<br />We will refer to ztas the parent and zt+1as the child.<br />The parent enters a restaurant j determined by its<br />parent (the grandparent), zt−1= j. We assume there<br />is a bijective mapping of indices f : t → ji. The parent<br />then chooses a table tji∼ ˜ πj and that table is served<br />a dish indexed by kjtji. Noting that zt= zji= kjtji,<br />the increased popularity of the house specialty dish<br />implies that children are more likely to eat in the same<br />restaurant as their parent and, in turn, more likely<br />to eat the restaurant’s specialty dish. This develops<br />family loyalty to a given restaurant in the franchise.<br />However, if the parent chooses a dish other than the<br />house specialty, the child will then go to the restaurant<br />where this dish is the specialty and will in turn be more<br />likely to eat this dish, too. One might say that for the<br />sticky HDP-HMM, children have similar tastebuds to<br />their parents and will always go the restaurant that<br />prepares their parent’s dish best. Often, this keeps<br />many generations eating in the same restaurant.<br />The inference algorithm is simplified if we introduce a<br />set of auxiliary random variables¯kjtand wjtas follows:<br />¯kjt∼ β,<br />wjt∼ Ber<br />?<br />κ<br />α + κ<br />?<br />,<br />kjt=<br />?¯kjt,wjt= 0;<br />wjt= 1,j,<br />(9)<br />where Ber(p) represents the Bernoulli distribution.<br />The table first chooses a dish¯kjt without taking the<br />restaurant’s specialty into consideration (i.e., the origi-<br />nal CRF.) With some probability, this considered dish<br />is overridden (perhaps by a waiter’s suggestion) and<br />the table is served the specialty dish j. Thus, kjtrep-<br />resents the served dish. We refer to wjtas the override<br />variable. For the original HDP-HMM, when κ = 0, the<br />considered dish is always the served dish since wjt= 0<br />for all tables. See Fig. 2(c).<br />3.2. Sampling via Direct Assignments<br />In this section we describe a modified version of the<br />direct assignment Rao-Blackwellized Gibbs sampler of<br />Teh et al. (2006) which circumvents the complicated<br />bookkeeping of the CRF by sampling indicator random<br />variables directly. Throughout this section, we refer to<br />the variables in the graph of Fig. 3. For this sampler,<br />a set of auxiliary variables mjk, ¯ mjk, and wjtmust be<br />added (as illustrated in Fig. 2(c)).<br />Sampling zt<br />The posterior distribution factors as:<br />p(zt= k | z\t,y1:T,β,α,κ,λ) ∝<br />p(zt= k | z\t,β,α,κ)p(yt| y\t,zt= k,z\t,λ).<br />The properties of the Dirichlet process dictate that on<br />the finite partition {1,...,K,˜k} we have the following<br />form for the group-specific transition distributions:<br />(10)<br />πj∼ Dir(αβ1,...,αβj+ κ,...,αβK,αβ˜k).<br />We use the above definition of πjand the Dirichlet dis-<br />tribution’s conjugacy to the multinomial observations<br />zt to marginalize πj and derive the following condi-<br />tional distribution over the states assignments:<br />(11)<br />p(zt= k | z\t,β,α,κ) ∝ (αβk+n−t<br />?αβzt+1+ n−t<br />α + n−t<br />zt−1k+κδ(zt−1,k))<br />kzt+1+ κδ(k,zt+1) + δ(zt−1,k)δ(k,zt+1)<br />k.+ κ + δ(zt−1,k)<br />?<br />.<br />(12)<br />This formula is more complex than that of the stan-<br />dard HDP sampler due to potential dependencies in<br />the marginalization of πzt−1and πzt. For a detailed<br />derivation, see Fox et al. (2007). The notation njkrep-<br />resents the number of Markov chain transitions from<br />state j to k, nj. =?<br />tion zt−1to ztor ztto zt+1. Intuitively, this expression<br />chooses a state k with probability depending on how<br />many times we have seen other zt−1 to k and k to<br />zt+1transitions. Note that there is a dependency on<br />whether either or both of these transitions correspond<br />to a self-transition, which is strongest when κ &gt; 0.<br />knjk, and n−t<br />jkthe number of<br />transitions from state j to k not counting the transi-<br />As in Teh et al. (2006), by placing a conjugate prior<br />on the parameter space, there is a closed analytic form<br />for the likelihood component p(yt| y\t,zt= k,z\t,λ).<br />Assume there are currently¯K unique<br />dishes being considered and take a finite partition<br />{θ1,θ2,...,θ ¯ K,θ˜k} of Θ, where θ˜k= Θ\? ¯ K<br />θk, the properties of the Dirichlet distribution dictate:<br />p((β1,...,β ¯ K,β˜k) |¯k,γ) ∝ Dir(¯ m.1,..., ¯ m.¯ K,γ). (13)<br />From the above, we see that {¯ m.k}¯ K<br />ficient statistics for resampling β on this partition.<br />Sampling β<br />k=1{θk}.<br />Since˜θjt ∼ G0 and ¯ m.k tables are considering dish<br />k=1is a set of suf-</p>  <p>Page 5</p> <p>An HDP-HMM for Systems with State Persistence<br />However, this requires sampling two additional vari-<br />ables, mjk and wjt, corresponding to the number of<br />tables in restaurant j served dish k and the corre-<br />sponding overwrite variables. We jointly sample from<br />p(m,w, ¯ m | z1:T,β,α,κ) = p( ¯ m | m,w,z1:T,β,α,κ)<br />p(w | m,z1:T,β,α,κ)p(m | z1:T,β,α,κ). (14)<br />We start by examining p(m | z1:T,β,α,κ). Having<br />the state index assignments z1:T effectively partitions<br />the data (customers) into both restaurants and dishes,<br />though the table assignments are unknown since mul-<br />tiple tables can be served the same dish. Thus, sam-<br />pling mjkis in effect equivalent to sampling table as-<br />signments for each customer after knowing the dish<br />assignment. This conditional distribution is given by:<br />p(tji= t | kjt= k,t−ji,k−jt,y1:T,β,α,κ)<br />˜ n−ji<br />jt,<br />αβk+ κδ(k,j),<br />∝<br />?<br />is the number of customers at table t in<br />restaurant j, not counting yji. The form of Eq. (15)<br />implies that a customer’s table assignment conditioned<br />on a dish assignment k follows a DP with concentra-<br />tion parameter αβk+κδ(k,j) and may be sampled by<br />simulating the associated Chinese restaurant process.<br />t ∈ {1,...,Tj};<br />t =˜tj,<br />(15)<br />where ˜ n−ji<br />jt<br />We now derive the conditional distribution for the<br />override variables wjt. The table counts provide that<br />mjktables are serving dish k in restaurant j. If k ?= j,<br />we automatically have mjk tables with wjt= 0 since<br />the served dish is not the house specialty. Otherwise,<br />p(wjt| kjt= j,β,ρ) ∝<br />?<br />βj(1 − ρ),<br />ρ,<br />wjt= 0;<br />wjt= 1,<br />(16)<br />where ρ =<br />Observing served dish kjt= j makes it more likely that<br />the considered dish¯kjtwas overridden than the prior<br />suggests. We draw mjjsamples of wjtfrom Eq. (16).<br />κ<br />α+κis the prior probability that wjt= 1.<br />Given mjk for all j and k and wjt for each of these<br />instantiated tables, we can now deterministically com-<br />pute ¯ mjk. Any table that was overridden is an unin-<br />formative observation for the posterior of ¯ mjkso that<br />¯ mjk=<br />?<br />mjk,<br />mjj− wj.,<br />j ?= k;<br />j = k.<br />(17)<br />Sampling Hyperparameters<br />the sticky HDP-HMM’s hyperparameters, we place<br />vague gamma priors on γ and (α + κ), and a beta<br />prior on κ/(α+κ). As detailed in Fox et al. (2007), the<br />auxiliary variables introduced in the preceding section<br />then allow tractable resampling of these hyperparam-<br />eters. This allows the number of occupied states, and<br />the degree of self–transition bias, to be strongly influ-<br />enced by the statistics of observed data, as desired.<br />Rather than fixing<br />3.3. Blocked Sampling of State Sequences<br />The HDP-HMM direct assignment sampler can exhibit<br />slow mixing rates since global state sequence changes<br />are forced to occur coordinate by coordinate. This is<br />explored in Scott (2002) for the finite HMM. Although<br />the sticky HDP-HMM reduces the posterior uncer-<br />tainty caused by fast state-switching explanations of<br />the data, the self-transition bias can cause two con-<br />tinuous and temporally separated sets of observations<br />of a given state to be grouped into two states. If this<br />occurs, the high probability of self-transition makes it<br />challenging for the sequential sampler to group those<br />two examples into a single state.<br />A variant of the HMM forward-backward procedure<br />(Rabiner, 1989) allows us to harness the Markov struc-<br />ture and jointly sample the state sequence z1:T given<br />the observations y1:T, transitions probabilities πj, and<br />model parameters θk. To take advantage of this pro-<br />cedure, we now must sample the previously marginal-<br />ized transition distributions and model parameters. In<br />practice, this requires approximating the theoretically<br />countably infinite transition distributions.<br />proach is the degree L weak limit approximation to<br />the DP (Ishwaran &amp; Zarepour, 2002),<br />One ap-<br />GEML(α) ? Dir(α/L,...,α/L),(18)<br />where L is a number that exceeds the total number<br />of expected HMM states. This approximation encour-<br />ages the learning of models with fewer than L com-<br />ponents while allowing the generation of new compo-<br />nents, upper bounded by L, as new data are observed.<br />The posterior distributions of β and πjare given by:<br />β ∼ Dir(γ/L + ¯ m.1,...,γ/L + ¯ m.L)<br />πj∼ Dir(αβ1+ nj1,...,αβj+ κ + njj,...,αβL+ njL).<br />(19)<br />Depending on the form of the emission distribution<br />and base measure on the parameter space Θ, we sam-<br />ple parameters for each of the currently instantiated<br />states from the updated posterior distribution:<br />θj∼ p(θ | {yt| zt= j},λ).(20)<br />Now that we are sampling θj directly, we can use a<br />non-conjugate base measure.<br />We block sample z1:T by first computing backward<br />messages mt,t−1(zt−1) ∝ p(yt:T|zt−1,π,θ) and then<br />recursively sampling each ztconditioned on zt−1from<br />p(zt| zt−1,y1:T,π,θ) ∝<br />p(zt| πzt−1)p(yt| θzt)mt+1,t(zt). (21)<br />A similar sampler has been used for learning HDP hid-<br />den Markov trees (Kivinen et al., 2007). However, this<br />work did not consider the complications introduced by<br />multimodal emissions, as we explore next.</p>  <p>Page 6</p> <p>An HDP-HMM for Systems with State Persistence<br />Figure 4. Sticky HDP-HMM with DP emissions, where st<br />indexes the state-specific mixture component generating<br />observation yt. The DP prior dictates that st ∼ ψztfor<br />ψk ∼ GEM(σ). The jthGaussian component of the kth<br />mixture density is parameterized by θk,j so yt ∼ F(θzt,st).<br />4. Multimodal Emission Distributions<br />For many application domains, the data associated<br />with each hidden state may have a complex, multi-<br />modal distribution. We propose to approximate such<br />emission distributions nonparametrically, using an in-<br />finite DP mixture of Gaussians. This formulation is<br />related to the nested DP (Rodriguez et al., 2006).<br />The bias towards self-transitions allow us to distin-<br />guish between the underlying HDP-HMM states. If<br />the model were free to both rapidly switch between<br />HDP-HMM states and associate multiple Gaussians<br />per state, there would be considerable posterior un-<br />certainty. Thus, it is only with the sticky HDP-HMM<br />that we can effectively learn such models.<br />We augment the HDP-HMM state zt with a term st<br />indexing the mixture component of the zth<br />density. For each HDP-HMM state, there is a unique<br />stick-breaking distribution ψk∼ GEM(σ) defining the<br />mixture weights of the kthemission density so that<br />st∼ ψzt. The observation ytis generated by the Gaus-<br />sian component with parameter θzt,st. See Fig. 4.<br />t<br />emission<br />To implement blocked resampling of (z1:T,s1:T), we<br />use weak limit approximations to both the HDP-HMM<br />and Dirichlet process emissions, approximated to lev-<br />els L and L′, respectively. The posterior distributions<br />of β and πkremain unchanged; that of ψkis given by:<br />ψk∼ Dir(σ/L′+ n′<br />where n′<br />klare the number of observations assigned to<br />the lthmixture component of the kthHMM state. The<br />posterior distribution for each Gaussian’s mean and<br />covariance, θk,j, is determined by the observations as-<br />signed to this component, namely,<br />k1,...,σ/L′+ n′<br />kL′),(22)<br />θk,j∼ p(θ | {yt| (zt= k,st= j)},λ).(23)<br />The augmented state (zt,st) is sampled from<br />p(zt,st| zt−1,y1:T,π,ψ,θ) ∝<br />p(zt| πzt−1)p(st| ψzt)p(yt| θzt,st)mt+1,t(zt).<br />Since the Markov structure is only on the zt compo-<br />(24)<br />nent of the augmented state, the backward message<br />mt,t−1(zt−1) from (zt,st) to (zt−1,st−1) is solely a<br />function of zt−1. These messages are given by:<br />mt,t−1(zt−1) ∝<br />?<br />zt<br />?<br />st<br />p(zt| πzt−1)p(st| ψzt)<br />p(yt| θzt,st)mt+1,t(zt).(25)<br />5. Results<br />Synthetic Data<br />three-state Gaussian emission HMM with: 0.97 proba-<br />bility of self-transition; means 50, 0, and -50; and vari-<br />ances 50, 10, and 50 (see Fig. 1(a).) For the blocked<br />sampler, we used a truncation level of L = 15.<br />We generated test data from a<br />Fig. 5 shows the clear advantage of considering a sticky<br />HDP-HMM with blocked sampling.<br />distance error is calculated by greedily mapping the<br />indices of the estimated state sequence to those max-<br />imizing overlap with the true sequence. The appar-<br />ent slow convergence of the sticky HDP-HMM direct<br />assignment sampler (Fig. 5(b)) can be attributed to<br />the sampler splitting temporally separated segments<br />of a true state into multiple, redundant states. Al-<br />though not depicted due to space constraints, both<br />sticky HDP-HMM samplers result in estimated mod-<br />els with significantly larger likelihoods of the true state<br />sequence than those of the original HDP-HMM.<br />The Hamming<br />To test the model of Sec. 4, we generated data from a<br />two-state HMM, where each state had a two-Gaussian<br />mixture emission distribution with equally weighted<br />components defined by means (0,10) and (−7,7), and<br />variances of 10. The probability of self-transition was<br />set to 0.98. The resulting observation and true state<br />sequences are shown in Fig. 6(a) and (b).<br />Fig. 6(e)-(h) compares the performance of the sticky<br />and original HDP-HMM with single and infinite Gaus-<br />sian mixture emissions. All results are for the blocked<br />sampler with truncation levels L = L′= 15.<br />tuitively, when constrained to single Gaussian emis-<br />sions, the best explanation of the data is to associate<br />each true mixture component with a separate state<br />and then quickly switch between these states, result-<br />ing in the large Hamming distances of Fig. 6(g)-(h).<br />Although not the desired effect in this scenario, this<br />behavior, as depicted in Fig. 6(c), demonstrates the<br />flexibility of the sticky HDP-HMM: if the best ex-<br />planation of the data according to the model is fast<br />state-switching, the sticky HDP-HMM still allows for<br />this by learning a small bias towards self-transitions.<br />The sticky HDP-HMM occasionally has more accu-<br />rate state sequence estimates by grouping a true state’s<br />Gaussian mixture components into a single Gaussian<br />with large variance. By far the best performance is<br />In-</p>  <p>Page 7</p> <p>An HDP-HMM for Systems with State Persistence<br />0 2040 60 80100120140160 180200<br />0<br />0.1<br />0.2<br />0.3<br />0.4<br />0.5<br />0.6<br />Iteration<br />(a)<br />Normalized Hamming Distance<br />0 2040 6080 100120140160180200<br />0<br />0.1<br />0.2<br />0.3<br />0.4<br />0.5<br />0.6<br />Iteration<br />(b)<br />Normalized Hamming Distance<br />02040 6080100120140160 180200<br />0<br />0.1<br />0.2<br />0.3<br />0.4<br />0.5<br />0.6<br />Iteration<br />(c)<br />Normalized Hamming Distance<br />0 2040 6080 100120140160180200<br />0<br />0.1<br />0.2<br />0.3<br />0.4<br />0.5<br />0.6<br />Iteration<br />(d)<br />Normalized Hamming Distance<br />Figure 5. Hamming distance between true and estimated state sequences over 100 iterations for the sticky HDP-HMM (a)<br />blocked and (b) direct assignment samplers and the original HDP-HMM (c) blocked and (d) direct assignment samplers.<br />These plots show the median (solid blue) and 10thand 90thquantiles (dashed red) from 200 initializations.<br />0 100 200300 400 500 600700800900 1000<br />−20<br />−15<br />−10<br />−5<br />0<br />5<br />10<br />15<br />20<br />25<br />Time<br />(a)<br />Observations<br />0100 200300400500 6007008009001000<br />1<br />2<br />Time<br />True Mode Sequence<br />0 100200300400500 600700800 900 1000<br />−1<br />0<br />1<br />2<br />3<br />4<br />5<br />6<br />7<br />8<br />Time<br />(c)<br />Estimated Mode Sequence<br />0100200 300400500600700 8009001000<br />1<br />2<br />Time<br />Estimated Mode Sequence<br />(b)(d)<br />01020304050607080 90 100<br />0<br />0.1<br />0.2<br />0.3<br />0.4<br />0.5<br />0.6<br />0.7<br />0.8<br />Iteration<br />(e)<br />Normalized Hamming Distance<br />0102030405060708090100<br />0<br />0.1<br />0.2<br />0.3<br />0.4<br />0.5<br />0.6<br />0.7<br />0.8<br />Iteration<br />(f)<br />Normalized Hamming Distance<br />0102030405060708090100<br />0<br />0.1<br />0.2<br />0.3<br />0.4<br />0.5<br />0.6<br />0.7<br />0.8<br />Iteration<br />(g)<br />Normalized Hamming Distance<br />01020 30 40 5060 708090100<br />0<br />0.1<br />0.2<br />0.3<br />0.4<br />0.5<br />0.6<br />0.7<br />0.8<br />Iteration<br />(h)<br />Normalized Hamming Distance<br />Figure 6. Performance of inference on data generated by an HMM with Gaussian mixture emissions. (a) Observation<br />sequence; (b) true HMM state sequence; estimated HMM state sequence using the sticky HDP-HMM model with (c)<br />single and (d) infinite Gaussian mixture emissions. Errors are indicated by red markers. The bottom row contains<br />Hamming distance plots, as in Fig. 5, for infinite Gaussian mixture emissions and the (e) sticky HDP-HMM and (f)<br />original HDP-HMM, and single Gaussian emissions for the (g) sticky HDP-HMM and (h) original HDP-HMM.<br />achieved by the sticky HDP-HMM with infinite Gaus-<br />sian mixture emissions (see Fig. 6(e) and (d)); compar-<br />ing to Fig. 6(f), we see that the gain can be attributed<br />to modeling rather than just improved mixing rates.<br />Speaker Diarization Data<br />tion task involves segmenting an audio recording into<br />speaker-homogeneous regions, while simultaneously<br />identifying the number of speakers. We tested the util-<br />ity of the sticky HDP-HMM for this task on the data<br />distributed by NIST as part of the Rich Transcrip-<br />tion 2004-2007 meeting recognition evaluations (NIST,<br />2007). We use the first 19 Mel Frequency Cepstral<br />Coefficients (MFCCs), computed over a 30ms window<br />every 10ms, as our feature vector.<br />with this dataset, we discovered that: (1) the high<br />frequency content of these features contained little<br />discriminative information, and (2) without a mini-<br />mum speaker duration, the sticky HDP-HMM learned<br />within speaker dynamics in addition to global speaker<br />changes. To jointly address these issues, we instead<br />The speaker diariza-<br />When working<br />model feature averages computed over 250ms, non–<br />overlapping blocks. A minimum speaker duration of<br />500ms is set by associating two average features with<br />each hidden state. We also tie the covariances of<br />within–state mixture components. We found single–<br />Gaussian emission distributions to be less effective.<br />For each of 21 meetings, we compare 10 initializations<br />of the original and sticky HDP-HMM blocked sam-<br />plers. In Fig. 8(a), we report the official NIST di-<br />arization error rate (DER) of the run with the largest<br />observation sequence likelihood, given parameters esti-<br />mated at the 1000th Gibbs iteration. The sticky HDP-<br />HMM’s temporal smoothing provides substantial per-<br />formance gains. Fig 8(b) plots the estimated versus<br />true number of speakers who talk for more than 10%<br />of the meeting time, and shows our model’s ability<br />to adapt to a varying number of speakers. As a fur-<br />ther comparison, the ICSI team’s algorithm (Wooters<br />&amp; Huijbregts, 2007), by far the best performer at the<br />2007 competition, has an overall DER of 18.37%, simi-</p>  <p>Page 8</p> <p>An HDP-HMM for Systems with State Persistence<br />0123456<br />4<br />x 10<br />1<br />2<br />3<br />4<br />True speaker label<br />Time<br />(a)<br />0123456<br />4<br />x 10<br />1<br />2<br />3<br />4<br />Estimated speaker label<br />Time<br />0123456<br />4<br />x 10<br />0<br />1<br />2<br />3<br />4<br />5<br />6<br />7<br />8<br />True speaker label<br />Time<br />(c)<br />0123456<br />4<br />x 10<br />1<br />2<br />3<br />4<br />5<br />6<br />7<br />Estimated speaker label<br />Time<br />(b)(d)<br />Figure 7. True state sequences for meetings (a) AMI 20041210-1052 and (c) VT 20050304-1300, with the corresponding<br />most likely state estimates shown in (b) and (d), respectively, with incorrect labels shown in red.<br />0 10<br />Sticky HDP−HMM DER (%)<br />(a)<br />20304050<br />0<br />5<br />10<br />15<br />20<br />25<br />30<br />35<br />40<br />45<br />50<br />HDP−HMM DER (%)<br />12345<br />1<br />2<br />3<br />4<br />5<br />Estimated number of speakers<br />(b)<br />True number of speakers<br />Figure 8. For the 21 meeting database: (a) plot of sticky<br />vs. original HDP-HMM most likely sequence DER; and<br />(b) plot of true vs. estimated number of speakers for sam-<br />ples drawn from 10 random initializations of each meeting<br />(larger circles have higher likelihood).<br />lar to our 19.04%. Our best and worst DER are 1.26%<br />and 31.42%, respectively, compared to their 4.39% and<br />32.23%. We use the same non-speech pre-processing,<br />so that the differences are due to changes in the iden-<br />tified speakers. As depicted in Fig. 7, a significant<br />proportion of our errors can be attributed to split-<br />ting or merging speakers. The ICSI team’s algorithm<br />uses agglomerative clustering, and requires significant<br />tuning of parameters on representative training data.<br />In contrast, our hyperparameters are automatically<br />set meeting-by-meeting, so that each component’s ex-<br />pected mean and covariance are that of the entire fea-<br />ture sequence.Note that the selected runs plotted<br />in Fig. 8 are not necessarily those with the smallest<br />DER. For example, the run depicted in Fig. 7(d) had<br />24.06% DER, while another run on the same meeting<br />had 4.37% (versus ICSI’s 22.00%.) There is inherent<br />posterior uncertainty in this task, and our sampler has<br />the advantage of giving several interpretations. When<br />considering the best per-meeting DER for the five most<br />likely samples, our overall DER drops to 15.14%; we<br />hope to explore automated ways of combining multiple<br />samples in future work. Regardless, our results demon-<br />strate that the sticky HDP-HMM provides an elegant<br />and empirically effective speaker diarization method.<br />6. Discussion<br />We have demonstrated the considerable benefits of an<br />extended HDP-HMM in which a separate parameter<br />captures state persistence. We have also shown that<br />this sticky HDP-HMM allows a fully nonparametric<br />treatment of multimodal emissions, disambiguated by<br />its bias towards self-transitions, and presented efficient<br />sampling techniques with mixing rates that improve<br />on the state-of-the-art. Results on synthetic data, and<br />a challenging speaker diarization task, clearly demon-<br />strate the practical importance of our extensions.<br />Acknowledgments<br />We thank O. Vinyals, G. Friedland, and N. Morgan for<br />helpful discussions about the NIST dataset. This research<br />was supported in part by DARPA contract NBCHD030010,<br />and MURIs funded through ARO Grant W911NF-06-1-<br />0076 and AFOSR Grant FA9550-06-1-0324.<br />partially funded by an NDSEG fellowship.<br />E.B.F. was<br />References<br />Beal, M. J., Ghahramani, Z., &amp; Rasmussen, C. E. (2002).<br />The infinite hidden Markov model. NIPS (pp. 577–584).<br />Fox, E., Sudderth, E., Jordan, M., &amp; Willsky, A. (2007).<br />A tempered HDP-HMM for systems with state persis-<br />tence. MIT LIDS, TR #2777.<br />Ishwaran, H., &amp; Zarepour, M. (2002). Exact and approxi-<br />mate sum–representations for the Dirichlet process. Can.<br />J. Stat., 30, 269–283.<br />Kivinen, J. J., Sudderth, E. B., &amp; Jordan, M. I. (2007).<br />Learning multiscale representations of natural scenes us-<br />ing Dirichlet processes. ICCV (pp. 1–8).<br />NIST (2007).Rich<br />http://www.nist.gov/speech/tests/rt/.<br />Rabiner, L. (1989). A tutorial on hidden Markov mod-<br />els and selected applications in speech recognition. Proc.<br />IEEE, 77, 257–286.<br />Rodriguez, A., Dunson, D., &amp; Gelfand, A. (2006). The<br />nested Dirichlet process. Duke ISDS, TR #06-19.<br />Scott, S. (2002). Bayesian methods for hidden Markov<br />models: Recursive computing in the 21st century.<br />Amer. Stat. Assoc., 97, 337–351.<br />Sethuraman, J. (1994).A constructive definition of<br />Dirichlet priors. Stat. Sinica, 4, 639–650.<br />Teh, Y. W., Jordan, M. I., Beal, M. J., &amp; Blei, D. M.<br />(2006). Hierarchical Dirichlet processes. J. Amer. Stat.<br />Assoc., 101, 1566–1581.<br />Wooters, C., &amp; Huijbregts, M. (2007). The ICSI RT07s<br />speaker diarization system. To appear in LNCS.<br />Xing, E., &amp; Sohn, K.-A. (2007). Hidden Markov Dirich-<br />let process: Modeling genetic inference in open ancestral<br />space. Bayes. Analysis, 2, 501–528.<br />transcriptionsdatabase.<br />J.</p>  <a href="https://www.researchgate.net/profile/Michael_Jordan13/publication/221344933_An_HDP-HMM_for_systems_with_state_persistence/links/53fe28a60cf283c3583bcdd5.pdf">Download full-text</a> </div> <div id="rgw22_56ab19b4883a8" class="c-box pub-resource-container js-toggle" style=""> <h4 class="lf js-expand-list"><small><a href="javascript:" class="lf">View other sources <span class="ico-expand-list"></span></a></small></h4> <h4 class="lf js-collapse-list hidden"><small><a href="javascript:" class="lf">Hide other sources <span class="ico-collapse-list"></span></a></small></h4> <div class="clear"></div> <div class="scroll-wrapper hidden"> <ul class="files-list c-list" id="rgw23_56ab19b4883a8">  <li class="c-list-item pub-resource-item"  data-type="fulltext" id="rgw24_56ab19b4883a8"> <span class="ico-pub"></span> <div class="file-content"> <div class="download"> <a href="profile/Michael_Jordan13/publication/221344933_An_HDP-HMM_for_systems_with_state_persistence/links/53fe28a60cf283c3583bcdd5.pdf" class="publication-viewer" title="53fe28a60cf283c3583bcdd5.pdf">53fe28a60cf283c3583bcdd5.pdf</a> </div>  <div class="details">  <span> Available from <a href="profile/Michael_Jordan13">Michael Jordan</a> &middot; Aug 27, 2014 </span>   </div>    </div> </li>  <li class="c-list-item pub-resource-item"  data-type="fulltext" id="rgw25_56ab19b4883a8"> <span class="ico-pub"></span> <div class="file-content"> <div class="download"> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.149.5741&amp;amp;rep=rep1&amp;amp;type=pdf" target="_blank" rel="nofollow" class="publication-viewer" title="An HDP-HMM for systems with state persistence">An HDP-HMM for systems with state persistence</a> </div>  <div class="details">   Available from <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.149.5741&amp;amp;rep=rep1&amp;amp;type=pdf" target="_blank" rel="nofollow">psu.edu</a>  </div>    </div> </li>  </ul> </div> </div> </noscript> <div class="clearfix"> <div class="action-container">  </div> <div class="pub-legal"> Data provided are for informational purposes only. Although carefully collected, accuracy cannot be guaranteed. The impact factor represents a rough estimation of the journal's impact factor and does not reflect the actual current impact factor. Publisher conditions are provided by RoMEO. Differing provisions from the publisher's actual policy or licence agreement may be applicable. </div>  <div id="rgw32_56ab19b4883a8" class="citations-container"> <div class="tab-container"> <ul class="tab-list"> <li class="lf tab-item  js-citations"> <a href="javascript:void(0);" class="tab-link"> References  </small> </a> </li>  <li class="lf tab-item tab-item-active js-cited-in js-cited-in-tooltip"> <a href="javascript:void(0);" class="tab-link"> Cited In <small> (97) </small> </a> </li>    <li class="rf"> <div class="dropdown js-citations-sorter dropdown-right-align" style="position: relative; bottom: -1px;display:none;"> <a href="javascript:void(0);" class="dropdown-toggle"> Sorted by: <strong class="js-current-sorting"> Order of availability  </strong> <span class="caret"></span> </a> <ul class="dropdown-menu"> <li><a href="javascript:void(0);" data-sort="normal">Order of availability</a></li> <li><a href="javascript:void(0);" data-sort="original">Appearance in publication</a></li> </ul> </div> </li>  </ul> <div class="tab-section tab-section-active js-citations-list-container"> <div id="rgw33_56ab19b4883a8" class="pub-citations-list">  <ul class="c-list">  <li class="c-list-item li-publication   includes-citation-list"  id="rgw34_56ab19b4883a8" >  <div class="indent-left">  <div id="rgw35_56ab19b4883a8" class="js-publication-item-fulltext fulltext-thumb">    <a class="publication-preview ga-publication-viewer js-publication-item-fulltext-content" href="publication/283043558_Accelerometer_based_Activity_Classification_with_Variational_Inference_on_Sticky_HDP-SLDS">       </a>   <div class="preview-source-info"> <a class="details js-show-source ga-source-url" href="deref/http%3A%2F%2Fde.arxiv.org%2Fpdf%2F1510.05477" target="_blank" >Source</a>  <div class="tooltip-content" style="display: none"> Available from: de.arxiv.org </div> </div>   </div>  </div>  <div class="indent-right">      </div>  <ul class="citation-contexts" id="rgw36_56ab19b4883a8">  <li class="citation-context-item"> "The initial attempts resulted in oscillatory behavior in practice. [16] modified the generative process to ensure the mode persistence. Later this concept is extended to SLDS in [17] where the new model is named sticky HDP- SLDS. " </li>  </ul>   <div  style="margin-top: -2px">  <h5 class="pub-type-and-title">  <span class="publication-type">Article:</span>    <a class="js-publication-title-link js-go-to-publication ga-publication-item" href="publication/283043558_Accelerometer_based_Activity_Classification_with_Variational_Inference_on_Sticky_HDP-SLDS"> <span class="publication-title js-publication-title">Accelerometer based Activity Classification with Variational Inference on Sticky HDP-SLDS</span> </a>     </h5>  </div>    <div class="authors">     <a href="researcher/2083158713_Mehmet_Emin_Basbug" class="authors js-author-name ga-publications-authors">Mehmet Emin Basbug</a> &middot;     <a href="researcher/2006576155_Koray_Ozcan" class="authors js-author-name ga-publications-authors">Koray Ozcan</a> &middot;     <a href="researcher/74635859_Senem_Velipasalar" class="authors js-author-name ga-publications-authors">Senem Velipasalar</a>      </div>        <div class="abstract"> <span class="shorten"> <a href="javascript:" class="js-toggle-abstract">[Show abstract]</a> </span> <span class="full"> <a href="javascript:" class="js-toggle-abstract">[Hide abstract]</a><br/>  <strong>ABSTRACT:</strong> As part of daily monitoring of human activities, wearable sensors and devices
are becoming increasingly popular sources of data. With the advent of
smartphones equipped with acceloremeter, gyroscope and camera; it is now
possible to develop activity classification platforms everyone can use
conveniently. In this paper, we propose a fast inference method for an
unsupervised non-parametric time series model namely variational inference for
sticky HDP-SLDS(Hierarchical Dirichlet Process Switching Linear Dynamical
System). We show that the proposed algorithm can differentiate various indoor
activities such as sitting, walking, turning, going up/down the stairs and
taking the elevator using only the acceloremeter of an Android smartphone
Samsung Galaxy S4. We used the front camera of the smartphone to annotate
activity types precisely. We compared the proposed method with Hidden Markov
Models with Gaussian emission probabilities on a dataset of 10 subjects. We
showed that the efficacy of the stickiness property. We further compared the
variational inference to the Gibbs sampler on the same model and show that
variational inference is faster in one order of magnitude. </span> </div>    <div class="publication-meta publication-meta">  <span class="ico-publication-preview reset-background"></span> Preview    &middot; Article &middot; Oct 2015  </div>        <div class="publication-actions"> <div class="btn-group">  <a class="btn btn-plain action-request-external  " href="javascript:;" data-context="pubCit">  <span class="js-btn-label">Request full-text</span> </a>    </div> </div>      </li>  <li class="c-list-item li-publication   includes-citation-list"  id="rgw37_56ab19b4883a8" >  <div class="indent-left">  <div id="rgw38_56ab19b4883a8" class="js-publication-item-fulltext fulltext-thumb">    <a class="publication-preview ga-publication-viewer js-publication-item-fulltext-content" href="publication/276923083_Sequential_Bayesian_inference_for_implicit_hidden_Markov_models_and_current_limitations">       </a>   <div class="preview-source-info"> <a class="details js-show-source ga-source-url" href="profile/Pierre_Jacob2" >Source</a>  <div class="tooltip-content" style="display: none"> Available from: Pierre E Jacob </div> </div>   </div>  </div>  <div class="indent-right">      </div>  <ul class="citation-contexts" id="rgw39_56ab19b4883a8">  <li class="citation-context-item"> "Note that combining non-parametric models for the function f and for the noise v t is not obvious because of identifiability issues. Other instances of non-parametric hidden Markov models consider the case where the hidden process lives on an infinite but discrete state space [44] [84]. Particle Markov chain Monte Carlo methods have recently been used in this context [86]. " </li>  </ul>   <div  style="margin-top: -2px">  <h5 class="pub-type-and-title">  <span class="publication-type">Article:</span>    <a class="js-publication-title-link js-go-to-publication ga-publication-item" href="publication/276923083_Sequential_Bayesian_inference_for_implicit_hidden_Markov_models_and_current_limitations"> <span class="publication-title js-publication-title">Sequential Bayesian inference for implicit hidden Markov models and current limitations</span> </a>     </h5>  </div>    <div class="authors">     <a href="researcher/48987261_Pierre_E_Jacob" class="authors js-author-name ga-publications-authors">Pierre E. Jacob</a>      </div>        <div class="abstract"> <span class="shorten"> <a href="javascript:" class="js-toggle-abstract">[Show abstract]</a> </span> <span class="full"> <a href="javascript:" class="js-toggle-abstract">[Hide abstract]</a><br/>  <strong>ABSTRACT:</strong> Hidden Markov models can describe time series arising in various fields of
science, by treating the data as noisy measurements of an arbitrarily complex
Markov process. Sequential Monte Carlo (SMC) methods have become standard tools
to estimate the hidden Markov process given the observations and a fixed
parameter value. We review some of the recent developments allowing the
inclusion of parameter uncertainty as well as model uncertainty. The
shortcomings of the currently available methodology are emphasised from an
algorithmic complexity perspective. The statistical objects of interest for
time series analysis are illustrated on a toy &quot;Lotka-Volterra&quot; model used in
population ecology. Some open challenges are discussed regarding the
scalability of the reviewed methodology to longer time series,
higher-dimensional state spaces and more flexible models. </span> </div>    <div class="publication-meta publication-meta">   <span class="ico-publication-fulltext reset-background"></span> Full-text   &middot; Article &middot; May 2015  </div>        <div class="publication-actions"> <div class="btn-group">  <a class="btn btn-plain action-download primary  open-viewer" href="profile/Pierre_Jacob2/publication/276923083_Sequential_Bayesian_inference_for_implicit_hidden_Markov_models_and_current_limitations/links/560410d808aea25fce30b296.pdf?origin=publication_list">  <span class="js-btn-label">Download</span> </a>    </div> </div>      </li>  <li class="c-list-item li-publication   includes-citation-list"  id="rgw40_56ab19b4883a8" >  <div class="indent-left">  <div id="rgw41_56ab19b4883a8" class="js-publication-item-fulltext fulltext-thumb">    <a class="publication-preview ga-publication-viewer js-publication-item-fulltext-content" href="publication/273472293_An_Adaptive_Online_HDP-HMM_for_Segmentation_and_Classification_of_Sequential_Data">       </a>   <div class="preview-source-info"> <a class="details js-show-source ga-source-url" href="deref/http%3A%2F%2Fde.arxiv.org%2Fpdf%2F1503.02761" target="_blank" >Source</a>  <div class="tooltip-content" style="display: none"> Available from: de.arxiv.org </div> </div>   </div>  </div>  <div class="indent-right">      </div>  <ul class="citation-contexts" id="rgw42_56ab19b4883a8">  <li class="citation-context-item"> "It is worth adding that a reported limitation of HDP-HMM is the tendency to over-segment due to its unbounded number of classes [26]. Fox et al. have proposed adding a &#39;sticky&#39; prior (κ) to the transition matrix to emulate an inertia towards changing states, illustrated in Figure 2 [27]. We utilise the sticky prior in this study, yet denoting it as HDP-HMM for brevity. " </li>  </ul>   <div  style="margin-top: -2px">  <h5 class="pub-type-and-title">  <span class="publication-type">Article:</span>    <a class="js-publication-title-link js-go-to-publication ga-publication-item" href="publication/273472293_An_Adaptive_Online_HDP-HMM_for_Segmentation_and_Classification_of_Sequential_Data"> <span class="publication-title js-publication-title">An Adaptive Online HDP-HMM for Segmentation and Classification of Sequential Data</span> </a>     </h5>  </div>    <div class="authors">     <a href="researcher/2017394071_Ava_Bargi" class="authors js-author-name ga-publications-authors">Ava Bargi</a> &middot;     <a href="researcher/69866501_Richard_Yi_Da_Xu" class="authors js-author-name ga-publications-authors">Richard Yi Da Xu</a> &middot;     <a href="researcher/6373073_Massimo_Piccardi" class="authors js-author-name ga-publications-authors">Massimo Piccardi</a>      </div>        <div class="abstract"> <span class="shorten"> <a href="javascript:" class="js-toggle-abstract">[Show abstract]</a> </span> <span class="full"> <a href="javascript:" class="js-toggle-abstract">[Hide abstract]</a><br/>  <strong>ABSTRACT:</strong> In the recent years, the desire and need to understand sequential data has
been increasing, with particular interest in sequential contexts such as
patient monitoring, understanding daily activities, video surveillance, stock
market and the like. Along with the constant flow of data, it is critical to
classify and segment the observations on-the-fly, without being limited to a
rigid number of classes. In addition, the model needs to be capable of updating
its parameters to comply with possible evolutions. This interesting problem,
however, is not adequately addressed in the literature since many studies focus
on offline classification over a pre-defined class set. In this paper, we
propose a principled solution to this gap by introducing an adaptive online
system based on Markov switching models with hierarchical Dirichlet process
priors. This infinite adaptive online approach is capable of segmenting and
classifying the sequential data over unlimited number of classes, while meeting
the memory and delay constraints of streaming contexts. The model is further
enhanced by introducing a learning rate, responsible for balancing the extent
to which the model sustains its previous learning (parameters) or adapts to the
new streaming observations. Experimental results on several variants of
stationary and evolving synthetic data and two video datasets, TUM Assistive
Kitchen and collatedWeizmann, show remarkable performance in segmentation and
classification, particularly for evolutionary sequences with changing
distributions and/or containing new, unseen classes. </span> </div>    <div class="publication-meta publication-meta">  <span class="ico-publication-preview reset-background"></span> Preview    &middot; Article &middot; Mar 2015  </div>        <div class="publication-actions"> <div class="btn-group">  <a class="btn btn-plain action-request-external  " href="javascript:;" data-context="pubCit">  <span class="js-btn-label">Request full-text</span> </a>    </div> </div>      </li>  </ul>    <a class="show-more-rebranded js-show-more rf text-gray-lighter">Show more</a> <span class="ajax-loading-small list-loading" style="display: none"></span>  <div class="clearfix"></div>  <div class="publication-detail-sidebar-legal">Note: This list is based on the publications in our database and might not be exhaustive.</div> <div class="clearfix"></div>  </div> </div> </div> </div> </div> </div> <div class="clearfix">     <div id="rgw27_56ab19b4883a8" class="c-box pub-resource-container js-toggle" style="display: none;"> <h4 class="lf js-expand-list"><small><a href="javascript:" class="lf">View other sources <span class="ico-expand-list"></span></a></small></h4> <h4 class="lf js-collapse-list hidden"><small><a href="javascript:" class="lf">Hide other sources <span class="ico-collapse-list"></span></a></small></h4> <div class="clear"></div> <div class="scroll-wrapper hidden"> <ul class="files-list c-list" id="rgw28_56ab19b4883a8">  </ul> </div> </div>   <div id="rgw18_56ab19b4883a8" class="similar-publications"> <h2>Similar Publications</h2> <ul class="list-bordered">  <li class="c-list-item li-publication-teaser" id="rgw19_56ab19b4883a8"> <div> <h5> <a href="publication/291436958_Efficient_parameter_inference_in_general_hidden_Markov_models_using_the_filter_derivatives" class="color-inherit ga-similar-publication-title"><span class="publication-title">Efficient parameter inference in general hidden Markov models using the filter derivatives</span></a>  </h5>  <div class="authors"> <a href="researcher/12967165_Jimmy_Olsson" class="authors ga-similar-publication-author">Jimmy Olsson</a>, <a href="researcher/2056557047_Johan_Westerborn" class="authors ga-similar-publication-author">Johan Westerborn</a>  </div>  </div> <div class="clear"></div> </li>  <li class="c-list-item li-publication-teaser" id="rgw20_56ab19b4883a8"> <div> <h5> <a href="publication/290523253_State-Space_Model_with_Deep_Learning_for_Functional_Dynamics_Estimation_in_Resting-State_fMRI" class="color-inherit ga-similar-publication-title"><span class="publication-title">State-Space Model with Deep Learning for Functional Dynamics Estimation in Resting-State fMRI</span></a>  </h5>  <div class="authors"> <a href="researcher/70109621_Heung-Il_Suk" class="authors ga-similar-publication-author">Heung-Il Suk</a>, <a href="researcher/9596576_Chong-Yaw_Wee" class="authors ga-similar-publication-author">Chong-Yaw Wee</a>, <a href="researcher/2046696996_Seong-Whan_Lee" class="authors ga-similar-publication-author">Seong-Whan Lee</a>, <a href="researcher/2036723170_Dinggang_Shen" class="authors ga-similar-publication-author">Dinggang Shen</a>  </div>  </div> <div class="clear"></div> </li>  <li class="c-list-item li-publication-teaser" id="rgw21_56ab19b4883a8"> <div> <h5> <a href="publication/285270766_Non_Parametric_Hidden_Markov_Models_with_Finite_State_Space_Posterior_Concentration_Rates" class="color-inherit ga-similar-publication-title"><span class="publication-title">Non Parametric Hidden Markov Models with Finite State Space: Posterior Concentration Rates</span></a>  </h5>  <div class="authors"> <a href="researcher/2086594424_Elodie_Vernet" class="authors ga-similar-publication-author">Elodie Vernet</a>  </div>  </div> <div class="clear"></div> </li>  </ul> </div> </div> </div> </div> </div></div></div>
<div class="clear"></div><div id="rgw52_56ab19b4883a8" class="default-footer"> <div id="footer" class="clearfix"> <span class="footer-left"> &copy; 2008&dash;2016 researchgate.net. All rights reserved. </span> <span class="footer-right"> <a href="https://www.researchgate.net/about">About us</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="https://www.researchgate.net/contact">Contact us</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="careers">Careers</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="developers">Developers</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="blog" target="_blank">News</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="application.PrivacyPolicy.html">Privacy</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="application.TermsAndConditions.html">Terms</a> <span class="footer-link-separator" style="padding: 0 5px;">&nbsp;|&nbsp;</span> <a href="advertising?_ref=ft">Advertising</a> <span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="recruiters?_ref=ft">Recruiting</a> </span> </div>  </div></div>
<div id="rgw53_56ab19b4883a8">  <div class="header-wrapper-logged-out"> <div id="header"> <div class="header-content"> <a href="" class="g-l-logo"> <svg width="149" height="19"> <image xlink:href="https://c5.rgstatic.net/m/235107188705592/images/template/brand-header-logo.svg" src="https://c5.rgstatic.net/m/238113351022438/images/template/brand-header-logo.png" width="149" height="19"/> </svg> </a> <a href="" class="g-l-logo-ico"> <svg width="127" height="17" viewbox="0 0 127 22"> <image xlink:href="https://c5.rgstatic.net/m/235107188705592/images/template/brand-header-logo.svg" src="https://c5.rgstatic.net/m/238113351022438/images/template/brand-header-logo.png" width="127" height="17"/> </svg> </a> <div id="rgw54_56ab19b4883a8" class="header-login-wrapper js-header-login"> <div class="dropdown-right-align"> <div class="login-signup-container lf"> <a href="https://www.researchgate.net/signup.SignUp.html?ev=su_chnl_index&amp;hdrsu=1&amp;_sg=cDkNAcKADMfw3wRSYBNI55u64OhbMwee99M8JtLStkVcopyLr7cegHY0mbHtEID6" class="dropdown-toggle lf">Join for free</a> </div> <div class="dropdown lf" style="height: 20px;"> <a href="https://www.researchgate.net/application.Login.html" class="js-login-url dropdown-toggle lf">Log in <span class="caret"></span></a> <div class="dropdown-menu"> <div class="header-login-form-wrapper"> <!--[if IE 6]><p class="box-warning" style="margin-bottom: 0;">Sorry, ResearchGate no longer supports the version of Internet Explorer you are using. <a href="http://whatbrowser.org/" rel="nofollow" target="_blank">Update your web browser</a> and then log in. </p><![endif]--> <form method="post" action="https://www.researchgate.net/application.Login.html" class="form-big header-login-form js-login-form" name="loginForm" id="headerLoginForm"> <input type="hidden" name="request_token" value="ToAJG4+bm7+wgvKUx5fVb3WL9PqPLMKefvAJeMTH3TOmxwHZaf2glhS73sBCohd3lvY64+mwvbZtc/39HxP06WYaBSjQkfKLtpeN0wArPYvxzgLnf3oufPhUf0C72/lxl7EzlLUznqfxzUyIDjFtm63SxB1Zkm2j1Qxo+GU1hmEO9zw0oKYOn3COOKzworNEeref+Rpc+xVIXHTjAvRocgI5XNt13HQTIBa90pIFAcJVAlBKXquasftdj1HCAe8VqmbEvYVXh7yqpHww2VyN/FzmsLegNWHa8+WJdNAqgDw="/> <input type="hidden" name="urlAfterLogin" value="publication/221344933_An_HDP-HMM_for_systems_with_state_persistence"/> <input type="hidden" name="invalidPasswordCount" value="0"/> <input type="hidden" name="headerLogin" value="yes"/> <label for="input-header-login">Email</label> <div class="login-input"> <div class="info-tip-wrapper"> <span class="ico-info js-info"></span> </div> <input type="email" value="" name="login" class="login js-login-input text" id="input-header-login" tabindex="1"/> </div> <div class="clear"></div> <label class="lf" for="input-header-password"> Password </label> <a class="rf forgot-password js-forgot-password" href="application.LostPassword.html">Forgot password?</a> <div class="clear"></div> <input type="password" value="" name="password" class="password js-password-input text" id="input-header-password" tabindex="2"/> <div class="clear"></div> <label class="remember-me" for="headerLoginCookie"> <input type="checkbox" checked="checked" value="yes" name="setLoginCookie" class="lf checkbox" id="headerLoginCookie" tabindex="3"/> Keep me logged in </label> <div class="clear"></div> <input value="Log in" name="loginSubmit" class="btn btn-promote btn-fullwidth btn-large allow-leave js-submit-button" type="submit" tabindex="4"/> </form> <div class="connectors"> <div class="text">or log in with</div> <div class="connector-actions"> <a href="connector/linkedin/" class="li-connect js-li-connect" data-redirect-url="cHVibGljYXRpb24vMjIxMzQ0OTMzX0FuX0hEUC1ITU1fZm9yX3N5c3RlbXNfd2l0aF9zdGF0ZV9wZXJzaXN0ZW5jZQ%3D%3D"> <span class="icon ico-linkedin-round-grey"></span> <span class="icon ico-linkedin-round"></span> </a> <a href="connector/facebook/" class="fb-connect middle js-fb-connect" data-redirect-url="cHVibGljYXRpb24vMjIxMzQ0OTMzX0FuX0hEUC1ITU1fZm9yX3N5c3RlbXNfd2l0aF9zdGF0ZV9wZXJzaXN0ZW5jZQ%3D%3D"> <span class="icon ico-facebook-round-grey"></span> <span class="icon ico-facebook-round"></span> </a> <a href="connector/google/" class="g-connect js-g-connect" data-redirect-url="cHVibGljYXRpb24vMjIxMzQ0OTMzX0FuX0hEUC1ITU1fZm9yX3N5c3RlbXNfd2l0aF9zdGF0ZV9wZXJzaXN0ZW5jZQ%3D%3D"> <span class="icon ico-google-round-grey"></span> <span class="icon ico-google-round"></span> </a> </div> </div> </div> </div> </div> </div> </div> </div> </div> <script type="application/ld+json">
{ "@context" : "http://schema.org",
  "@type" : "Organization",
  "name" : "ResearchGate",
  "url" : "http://www.researchgate.net",
  "logo" : "http://www.researchgate.net/images/template/rg_logo_square_brand.png",
  "sameAs" : [ "https://www.facebook.com/ResearchGate",
    "https://twitter.com/ResearchGate",
    "https://plus.google.com/+researchgate",
    "https://www.linkedin.com/company/researchgate"] 
}
</script> </div> </div><div class="c-signup-bar" id="rgw55_56ab19b4883a8"> <div class="banner-contents">   <span class="message">ResearchGate is the professional network for scientists and researchers.</span> <a href="signup.SignUp.html?ev=su_banner" class="btn btn-large btn-promote">Join for free</a>  </div> </div></div>
<script>
rgConfig.backendTime = 510;
</script>
<script src="//c5.rgstatic.net/m/2277196935388619/javascript/lib/yui3/yui/yui-min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/2448732603281275/javascript/yuiLoaderConfig-min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/23178613132105398/javascript/vendor/babel-core/browser-polyfill.min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/2198378204065/javascript/min/lib/error_logging.js" type="text/javascript"></script>
<script>
(function (){
if (typeof YRG === "undefined") {
var xmlHttpRequest = new XMLHttpRequest();
xmlHttpRequest.open("post", "go.Error.html");
xmlHttpRequest.setRequestHeader("Content-Type", "application/json");
xmlHttpRequest.setRequestHeader("Accept", "application/json"); var loadedScripts = "";
if (window.performance && window.performance.getEntriesByType) {
    var result = [];
    var resources = performance.getEntriesByType("resource");
    for (var i in resources) {
        if (resources.hasOwnProperty(i)) {
            result.push({
                name: resources[i].name,
                duration: resources[i].duration
            });
        }
    }
    loadedScripts += "&loadedScripts=" + encodeURIComponent(JSON.stringify(result));
}
if (typeof YUI === "undefined") {
    loadedScripts += "&yuiLoaded=false";
} else {
    loadedScripts += "&yuiLoaded=true";
}
xmlHttpRequest.send("Type=InformationException&message=" + encodeURIComponent("Error loading YUI") + loadedScripts);
}
})();
</script>
<script>if (typeof YRG !== 'undefined') { YRG.use('rg-base',function(Y){Y.applyConfig({ignore: ["css-rg","css-rg2","css-ie","css-modules-publicprofile","css-pow-publicliterature-FollowPublicationPromo","css-pow-application-PdfJsReader","css-pow-publicliterature-PublicationInlineReader"]});Y.use(["rg.core.pagespeed.Monitoring"],function(Y){(function(){Y.rg.createInitialWidget({"data":{"content":{"data":{"profileSmallHeader":{"data":{"profileBadge":{"data":{"fullname":"Michael Jordan","imageUrl":"https:\/\/i1.rgstatic.net\/ii\/profile.image\/AS%3A278648436346888%401443446372379_m","profileStats":[],"profileFollowButton":null,"profileReputationScoreNumber":null,"profileUrl":"profile\/Michael_Jordan13","institution":"University of California, Berkeley","institutionUrl":false,"widgetId":"rgw4_56ab19b4883a8"},"id":"rgw4_56ab19b4883a8","partials":[],"templateName":"publicprofile\/stubs\/ProfileBadge.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicprofile.ProfileBadge.html?accountId=5451072","viewClass":null,"yuiModules":["css-modules-publicprofile"],"stylesheets":["modules\/publicprofile.css"],"_isYUI":true},"widgetId":"rgw3_56ab19b4883a8"},"id":"rgw3_56ab19b4883a8","partials":[],"templateName":"publicprofile\/stubs\/ProfileSmallHeader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicprofile.ProfileSmallHeader.html?publicationUid=221344933","viewClass":null,"yuiModules":["css-modules-publicprofile"],"stylesheets":["modules\/publicprofile.css"],"_isYUI":true},"publication":{"data":{"publicationUid":221344933,"title":"An HDP-HMM for systems with state persistence","journalTitle":false,"journalDetailsTooltip":false,"affiliation":"Massachusetts Institute of Technology Stochastic Systems Group","type":"Conference Paper","details":{"doi":"10.1145\/1390156.1390196","conferenceInfos":"Conference: Machine Learning, Proceedings of the Twenty-Fifth International Conference (ICML 2008), Helsinki, Finland, June 5-9, 2008"},"source":{"sourceUrl":"http:\/\/dblp.uni-trier.de\/db\/conf\/icml\/icml2008.html#FoxSJW08","sourceName":"DBLP"},"publicationActions":null,"publicationCoins":{"data":{"tags":[{"key":"ctx_ver","value":"Z39.88-2004"},{"key":"rft_val_fmt","value":"info:ofi\/fmt:kev:mtx:journal"},{"key":"rfr_id","value":"info:sid\/researchgate.net:researchgate"},{"key":"rft_id","value":"info:doi\/10.1145\/1390156.1390196"},{"key":"rft.atitle","value":"An HDP-HMM for systems with state persistence"},{"key":"rft.title","value":"Proceedings of the 25th International Conference on Machine Learning"},{"key":"rft.jtitle","value":"Proceedings of the 25th International Conference on Machine Learning"},{"key":"rft.date","value":"2008"},{"key":"rft.pages","value":"312-319"},{"key":"rft.au","value":"Emily B. Fox,Erik B. Sudderth,Michael I. Jordan,Alan S. Willsky"},{"key":"rft.genre","value":"inProceedings"}],"widgetId":"rgw6_56ab19b4883a8"},"id":"rgw6_56ab19b4883a8","partials":[],"templateName":"publicliterature\/stubs\/PublicationCoins.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationCoins.html?publicationUid=221344933","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationAuthors":{"data":{"publicationUid":221344933,"peopleItems":[{"data":{"authorUrl":"researcher\/44211050_Emily_B_Fox","authorNameOnPublication":"Emily B. Fox","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg","imageSize":"s","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Emily B. Fox","profile":{"professionalInstitution":{"professionalInstitutionName":false,"professionalInstitutionUrl":null}},"professionalInstitutionName":false,"professionalInstitutionUrl":null,"url":"researcher\/44211050_Emily_B_Fox","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":true,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":false,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"widgetId":"rgw9_56ab19b4883a8"},"id":"rgw9_56ab19b4883a8","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAuthorItem.html?entityId=44211050&imageSize=l&enableAuthorInviteButton=0","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"largeTooltip":false,"useRebrandedImageStyle":null,"widgetId":"rgw8_56ab19b4883a8"},"id":"rgw8_56ab19b4883a8","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorItem.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorItem.html?authorUid=44211050&authorNameOnPublication=Emily%20B.%20Fox","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true},{"data":{"authorUrl":"researcher\/8993785_Erik_B_Sudderth","authorNameOnPublication":"Erik B. Sudderth","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg","imageSize":"s","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Erik B. Sudderth","profile":{"professionalInstitution":{"professionalInstitutionName":false,"professionalInstitutionUrl":null}},"professionalInstitutionName":false,"professionalInstitutionUrl":null,"url":"researcher\/8993785_Erik_B_Sudderth","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":true,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":false,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"widgetId":"rgw11_56ab19b4883a8"},"id":"rgw11_56ab19b4883a8","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAuthorItem.html?entityId=8993785&imageSize=l&enableAuthorInviteButton=0","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"largeTooltip":false,"useRebrandedImageStyle":null,"widgetId":"rgw10_56ab19b4883a8"},"id":"rgw10_56ab19b4883a8","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorItem.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorItem.html?authorUid=8993785&authorNameOnPublication=Erik%20B.%20Sudderth","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true},{"data":{"authorNameOnPublication":"Michael Jordan","accountUrl":"profile\/Michael_Jordan13","accountKey":"Michael_Jordan13","imageUrl":"https:\/\/i1.rgstatic.net\/ii\/profile.image\/AS%3A278648436346888%401443446372379_m","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Michael Jordan","profile":{"professionalInstitution":{"professionalInstitutionName":"University of California, Berkeley","professionalInstitutionUrl":"institution\/University_of_California_Berkeley"}},"professionalInstitutionName":"University of California, Berkeley","professionalInstitutionUrl":"institution\/University_of_California_Berkeley","url":"profile\/Michael_Jordan13","imageUrl":"https:\/\/i1.rgstatic.net\/ii\/profile.image\/AS%3A278648436346888%401443446372379_l","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":false,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":true,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"accountKey":"Michael_Jordan13","hasInfoPopup":false,"hasTeaserPopup":true,"showContactAuthorButton":true,"widgetId":"rgw13_56ab19b4883a8"},"id":"rgw13_56ab19b4883a8","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAccountItem.html?entityId=5451072&enableUnfollow=0&imageSize=l&enableFollowButton=0&showContactAuthorButton=1","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"accountInstitution":"University of California, Berkeley","score":null,"largeTooltip":false,"useRebrandedImageStyle":null,"authorCount":4,"accountCount":1,"publicationUid":221344933,"widgetId":"rgw12_56ab19b4883a8"},"id":"rgw12_56ab19b4883a8","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAccountItem.html","templateExtensions":[],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAccountItem.html?accountId=5451072&context=pubdetail_authors_xflw&showContactAuthorButton=1&authorCount=4&accountCount=1&publicationUid=221344933","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true},{"data":{"authorUrl":"researcher\/5936615_Alan_S_Willsky","authorNameOnPublication":"Alan S. Willsky","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg","imageSize":"s","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Alan S. Willsky","profile":{"professionalInstitution":{"professionalInstitutionName":false,"professionalInstitutionUrl":null}},"professionalInstitutionName":false,"professionalInstitutionUrl":null,"url":"researcher\/5936615_Alan_S_Willsky","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":true,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":false,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"widgetId":"rgw15_56ab19b4883a8"},"id":"rgw15_56ab19b4883a8","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAuthorItem.html?entityId=5936615&imageSize=l&enableAuthorInviteButton=0","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"largeTooltip":false,"useRebrandedImageStyle":null,"widgetId":"rgw14_56ab19b4883a8"},"id":"rgw14_56ab19b4883a8","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorItem.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorItem.html?authorUid=5936615&authorNameOnPublication=Alan%20S.%20Willsky","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true}],"hasMore":false,"nextOffset":6,"useRebrandedImageStyle":null,"widgetId":"rgw7_56ab19b4883a8"},"id":"rgw7_56ab19b4883a8","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorList.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorList.html?publicationUid=221344933&context=pubdetail_authors_xflw&showContactAuthorButton=1","viewClass":"views.publicliterature.PublicationDetailAuthorListView","yuiModules":["rg.views.publicliterature.PublicationDetailAuthorListView"],"stylesheets":[],"_isYUI":true},"publicationAbstract":{"data":{"publicationUid":221344933,"abstract":"<noscript><\/noscript><div>The hierarchical Dirichlet process hidden Markov model (HDP-HMM) is a flexible, nonparametric model which allows state spaces of unknown size to be learned from data. We demonstrate some limitations of the original HDP-HMM formulation (Teh et al., 2006), and propose a sticky exten- sion which allows more robust learning of smoothly varying dynamics. Using DP mix- tures, this formulation also allows learning of more complex, multimodal emission dis- tributions. We further develop a sampling algorithm that employs a truncated approx- imation of the DP to jointly resample the full state sequence, greatly improving mixing rates. Via extensive experiments with syn- thetic data and the NIST speaker diarization database, we demonstrate the advantages of our sticky extension, and the utility of the HDP-HMM in real-world applications.<\/div>","canEdit":false,"isAdmin":false,"isArtifact":false,"showFullAbstract":true,"widgetId":"rgw16_56ab19b4883a8"},"id":"rgw16_56ab19b4883a8","partials":[],"templateName":"publicliterature\/stubs\/PublicationAbstract.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationAbstract.html?publicationUid=221344933","viewClass":"views.publicliterature.PublicationAbstractView","yuiModules":["rg.views.publicliterature.PublicationAbstractView"],"stylesheets":[],"_isYUI":true},"publicationKeywords":null,"publicationState":null,"isGuest":true,"isAdminEditingAllowed":false,"isArtifact":false,"figureListWidget":null,"previewImage":"https:\/\/i1.rgstatic.net\/publication\/221344933_An_HDP-HMM_for_systems_with_state_persistence\/links\/53fe28a60cf283c3583bcdd5\/smallpreview.png","nativeAdDisclosure":null,"showFollowPublicationButton":false,"followPublicationPromo":{"data":{"widgetId":"rgw17_56ab19b4883a8"},"id":"rgw17_56ab19b4883a8","partials":[],"templateName":"publicliterature\/stubs\/FollowPublicationPromo.html","templateExtensions":[],"attrs":{"context":null,"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.FollowPublicationPromo.html","viewClass":null,"yuiModules":["css-pow-publicliterature-FollowPublicationPromo"],"stylesheets":["pow\/publicliterature\/FollowPublicationPromo.css"],"_isYUI":true},"widgetId":"rgw5_56ab19b4883a8"},"id":"rgw5_56ab19b4883a8","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailItem.html","templateExtensions":["generalHelpers"],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailItem.html?publicationUid=221344933&showActionBar=0&showContactAuthorButton=1&showRequestFulltextExperience=0&showNoRgAuthorsRequestFulltextExperience=0&showFollowPublicationPromo=1","viewClass":"views.publicliterature.PublicationDetailItemView","yuiModules":["rg.views.publicliterature.PublicationDetailItemView"],"stylesheets":[],"_isYUI":true},"similarPublications":{"data":{"publicationListItems":[{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore","clickThrough":"experimentMilestoneClickedToPublicationFromReferenceWithNoFulltext","clickThroughWithContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":12967165,"url":"researcher\/12967165_Jimmy_Olsson","fullname":"Jimmy Olsson","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2056557047,"url":"researcher\/2056557047_Johan_Westerborn","fullname":"Johan Westerborn","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Jan 2016","journal":null,"showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/291436958_Efficient_parameter_inference_in_general_hidden_Markov_models_using_the_filter_derivatives","usePlainButton":true,"publicationUid":291436958,"feedStubs":null,"hasFeedStubs":false,"impactPoints":false,"url":"publication\/291436958_Efficient_parameter_inference_in_general_hidden_Markov_models_using_the_filter_derivatives","title":"Efficient parameter inference in general hidden Markov models using the filter derivatives","displayTitleAsLink":true,"authors":[{"id":12967165,"url":"researcher\/12967165_Jimmy_Olsson","fullname":"Jimmy Olsson","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2056557047,"url":"researcher\/2056557047_Johan_Westerborn","fullname":"Johan Westerborn","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":[],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/291436958_Efficient_parameter_inference_in_general_hidden_Markov_models_using_the_filter_derivatives","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/291436958_Efficient_parameter_inference_in_general_hidden_Markov_models_using_the_filter_derivatives\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw19_56ab19b4883a8"},"id":"rgw19_56ab19b4883a8","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=291436958","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore","clickThrough":"experimentMilestoneClickedToPublicationFromReferenceWithNoFulltext","clickThroughWithContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":70109621,"url":"researcher\/70109621_Heung-Il_Suk","fullname":"Heung-Il Suk","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":9596576,"url":"researcher\/9596576_Chong-Yaw_Wee","fullname":"Chong-Yaw Wee","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2046696996,"url":"researcher\/2046696996_Seong-Whan_Lee","fullname":"Seong-Whan Lee","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2036723170,"url":"researcher\/2036723170_Dinggang_Shen","fullname":"Dinggang Shen","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Jan 2016","journal":"NeuroImage","showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/290523253_State-Space_Model_with_Deep_Learning_for_Functional_Dynamics_Estimation_in_Resting-State_fMRI","usePlainButton":true,"publicationUid":290523253,"feedStubs":null,"hasFeedStubs":false,"impactPoints":"6.36","url":"publication\/290523253_State-Space_Model_with_Deep_Learning_for_Functional_Dynamics_Estimation_in_Resting-State_fMRI","title":"State-Space Model with Deep Learning for Functional Dynamics Estimation in Resting-State fMRI","displayTitleAsLink":true,"authors":[{"id":70109621,"url":"researcher\/70109621_Heung-Il_Suk","fullname":"Heung-Il Suk","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":9596576,"url":"researcher\/9596576_Chong-Yaw_Wee","fullname":"Chong-Yaw Wee","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2046696996,"url":"researcher\/2046696996_Seong-Whan_Lee","fullname":"Seong-Whan Lee","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2036723170,"url":"researcher\/2036723170_Dinggang_Shen","fullname":"Dinggang Shen","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["NeuroImage 01\/2016;  DOI:10.1016\/j.neuroimage.2016.01.005"],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/290523253_State-Space_Model_with_Deep_Learning_for_Functional_Dynamics_Estimation_in_Resting-State_fMRI","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/290523253_State-Space_Model_with_Deep_Learning_for_Functional_Dynamics_Estimation_in_Resting-State_fMRI\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw20_56ab19b4883a8"},"id":"rgw20_56ab19b4883a8","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=290523253","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore","clickThrough":"experimentMilestoneClickedToPublicationFromReferenceWithNoFulltext","clickThroughWithContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":2086594424,"url":"researcher\/2086594424_Elodie_Vernet","fullname":"Elodie Vernet","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Nov 2015","journal":null,"showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/285270766_Non_Parametric_Hidden_Markov_Models_with_Finite_State_Space_Posterior_Concentration_Rates","usePlainButton":true,"publicationUid":285270766,"feedStubs":null,"hasFeedStubs":false,"impactPoints":false,"url":"publication\/285270766_Non_Parametric_Hidden_Markov_Models_with_Finite_State_Space_Posterior_Concentration_Rates","title":"Non Parametric Hidden Markov Models with Finite State Space: Posterior Concentration Rates","displayTitleAsLink":true,"authors":[{"id":2086594424,"url":"researcher\/2086594424_Elodie_Vernet","fullname":"Elodie Vernet","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":[],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/285270766_Non_Parametric_Hidden_Markov_Models_with_Finite_State_Space_Posterior_Concentration_Rates","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/285270766_Non_Parametric_Hidden_Markov_Models_with_Finite_State_Space_Posterior_Concentration_Rates\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw21_56ab19b4883a8"},"id":"rgw21_56ab19b4883a8","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=285270766","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"viewClass":"sidebar","widgetId":"rgw18_56ab19b4883a8"},"id":"rgw18_56ab19b4883a8","partials":[],"templateName":"publicliterature\/stubs\/SimilarPublications.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.SimilarPublications.html?referencePublicationId=221344933&view=sidebar","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationFulltextPreview":null,"publicationResourcesFulltext":{"data":{"publicationUid":221344933,"publicationResourceList":{"data":{"publicationResourceItems":[{"data":{"publicationUid":221344933,"publicationType":"inProceedings","linkId":"53fe28a60cf283c3583bcdd5","fileName":"53fe28a60cf283c3583bcdd5.pdf","fileUrl":"profile\/Michael_Jordan13\/publication\/221344933_An_HDP-HMM_for_systems_with_state_persistence\/links\/53fe28a60cf283c3583bcdd5.pdf","name":"Michael Jordan","nameUrl":"profile\/Michael_Jordan13","canRemove":false,"fileIcon":"ico-pub","canPreview":true,"hasPublisherLink":null,"hasMetaData":true,"hide":false,"fulltext":"ico-pub","origin":"publication_list","isLastLink":false,"isUserLink":true,"uploadDate":"Aug 27, 2014","fileSize":"494.63 KB","widgetId":"rgw24_56ab19b4883a8"},"id":"rgw24_56ab19b4883a8","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceItem.html","templateExtensions":["generalHelpers"],"attrs":{"fileRequiredPublicationTypes":["code","coverPage","experimentFindings","method","negativeResults","presentation","rawData","researchProposal","workingPaper","artifact","dataset"]},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceItem.html?publicationUid=221344933&linkId=53fe28a60cf283c3583bcdd5&hide=0&disableJavascript=disableJavascript&useAlternativeTemplate=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"publicationUid":221344933,"publicationType":"inProceedings","linkId":"0ffc635a0cf255165fc8324f","fileName":"An HDP-HMM for systems with state persistence","fileUrl":"http:\/\/citeseerx.ist.psu.edu\/viewdoc\/download?doi=10.1.1.149.5741&amp;rep=rep1&amp;type=pdf","name":"psu.edu","nameUrl":"http:\/\/citeseerx.ist.psu.edu\/viewdoc\/download?doi=10.1.1.149.5741&amp;rep=rep1&amp;type=pdf","canRemove":false,"fileIcon":"ico-pub","canPreview":true,"hasPublisherLink":null,"hasMetaData":true,"hide":false,"fulltext":"ico-pub","origin":"publication_list","isLastLink":false,"isUserLink":false,"widgetId":"rgw25_56ab19b4883a8"},"id":"rgw25_56ab19b4883a8","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceItem.html","templateExtensions":["generalHelpers"],"attrs":{"fileRequiredPublicationTypes":["code","coverPage","experimentFindings","method","negativeResults","presentation","rawData","researchProposal","workingPaper","artifact","dataset"]},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceItem.html?publicationUid=221344933&linkId=0ffc635a0cf255165fc8324f&hide=0&disableJavascript=disableJavascript&useAlternativeTemplate=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"widgetId":"rgw23_56ab19b4883a8"},"id":"rgw23_56ab19b4883a8","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceList.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceList.html?publicationUid=221344933&limit=3&disableJavascript=disableJavascript&type=fulltextFile","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"resourceCount":2,"hidden":false,"showMore":false,"fulltext":true,"publicationDownloadCount":{"data":{"value":154,"valueFormatted":"154","widgetId":"rgw26_56ab19b4883a8"},"id":"rgw26_56ab19b4883a8","partials":[],"templateName":"publicliterature\/stubs\/PublicationDownloadCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDownloadCount.html?publicationUid=221344933","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw22_56ab19b4883a8"},"id":"rgw22_56ab19b4883a8","partials":[],"templateName":"publicliterature\/stubs\/PublicationResources.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResources.html?publicationUid=221344933&type=fulltextFile&disableJavascript=1","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationResourcesAttachments":{"data":{"publicationUid":221344933,"publicationResourceList":{"data":{"publicationResourceItems":[],"widgetId":"rgw28_56ab19b4883a8"},"id":"rgw28_56ab19b4883a8","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceList.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceList.html?publicationUid=221344933&limit=3&disableJavascript=disableJavascript&type=attachmentFile","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"resourceCount":0,"hidden":true,"showMore":false,"fulltext":false,"publicationDownloadCount":{"data":{"value":154,"valueFormatted":"154","widgetId":"rgw29_56ab19b4883a8"},"id":"rgw29_56ab19b4883a8","partials":[],"templateName":"publicliterature\/stubs\/PublicationDownloadCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDownloadCount.html?publicationUid=221344933","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw27_56ab19b4883a8"},"id":"rgw27_56ab19b4883a8","partials":[],"templateName":"publicliterature\/stubs\/PublicationResources.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResources.html?publicationUid=221344933&type=attachmentFile","viewClass":"views.publicliterature.PublicationResourcesView","yuiModules":["rg.views.publicliterature.PublicationResourcesView"],"stylesheets":[],"_isYUI":true},"publicationText":{"data":{"hide":false,"pages":[{"page":1,"text":"An HDP-HMM for Systems with State Persistence\nEmily B. Fox\nDepartment of EECS, Massachusetts Institute of Technology, Cambridge, MA 02139\nebfox@mit.edu\nErik B. Sudderth\nDepartment of EECS, University of California, Berkeley, CA 94720\nsudderth@eecs.berkeley.edu\nMichael I. Jordan\nDepartment of EECS and Department of Statistics, University of California, Berkeley, CA 94720\njordan@eecs.berkeley.edu\nAlan S. Willsky\nDepartment of EECS, Massachusetts Institute of Technology, Cambridge, MA 02139\nwillsky@mit.edu\nAbstract\nThe hierarchical Dirichlet process hidden\nMarkov model (HDP-HMM) is a flexible,\nnonparametric model which allows state\nspaces of unknown size to be learned from\ndata. We demonstrate some limitations of\nthe original HDP-HMM formulation (Teh\net al., 2006), and propose a sticky exten-\nsion which allows more robust learning of\nsmoothly varying dynamics. Using DP mix-\ntures, this formulation also allows learning\nof more complex, multimodal emission dis-\ntributions. We further develop a sampling\nalgorithm that employs a truncated approx-\nimation of the DP to jointly resample the\nfull state sequence, greatly improving mixing\nrates. Via extensive experiments with syn-\nthetic data and the NIST speaker diarization\ndatabase, we demonstrate the advantages of\nour sticky extension, and the utility of the\nHDP-HMM in real-world applications.\n1. Introduction\nHidden Markov models (HMMs) have been a major\nsuccess story in many applied fields; they provide core\nstatistical inference procedures in areas as diverse as\nspeech recognition, genomics, structural biology, ma-\nchine translation, cryptanalysis and finance. Even af-\nter four decades of work on HMMs, however, signifi-\ncant problems remain. One lingering issue is the choice\nof the hidden state space\u2019s cardinality. While standard\nparametric model selection methods can be adapted to\nthe HMM, there is little understanding of the strengths\nand weaknesses of such methods in this setting.\nAppearing in Proceedings of the 25thInternational Confer-\nence on Machine Learning, Helsinki, Finland, 2008. Copy-\nright 2008 by the author(s)\/owner(s).\nRecently, Teh et al. (2006) presented a nonparamet-\nric Bayesian approach to HMMs in which a stochastic\nprocess, the hierarchical Dirichlet process (HDP), de-\nfines a prior distribution on transition matrices over\ncountably infinite state spaces. The resulting HDP-\nHMM leads to data\u2013driven learning algorithms which\ninfer posterior distributions over the number of states.\nThis posterior uncertainty can be integrated out when\nmaking predictions, effectively averaging over models\nof varying complexity.The HDP-HMM has shown\npromise in a variety of applications, including visual\nscene recognition (Kivinen et al., 2007) and the mod-\neling of genetic recombination (Xing & Sohn, 2007).\nOne serious limitation of the standard HDP-HMM\nis that it inadequately models the temporal persis-\ntence of states. This problem arises in classical finite\nHMMs as well, where semi-Markovian models are of-\nten proposed as solutions. However, the problem is\nexacerbated in the nonparametric setting, where the\nBayesian bias towards simpler models is insufficient to\nprevent the HDP-HMM from learning models with un-\nrealistically rapid dynamics, as demonstrated in Fig. 1.\nTo illustrate the seriousness of this issue, let us con-\nsider a challenging application that we revisit in Sec. 5.\nThe problem of speaker diarization involves segment-\ning an audio recording into time intervals associated\nwith individual speakers. This application seems like\na natural fit for the HDP-HMM, as the number of true\nspeakers is typically unknown, and may grow as more\ndata is observed. However, this is not a setting in\nwhich model averaging is the goal; rather, it is critical\nto infer the number of speakers as well as the transi-\ntions among speakers. As we show in Sec. 5, the HDP-\nHMM\u2019s tendency to rapidly switch among redundant\nstates leads to poor speaker diarization performance.\nIn contrast, the methods that we develop in this paper\nyield a state-of-the-art speaker diarization method, as"},{"page":2,"text":"An HDP-HMM for Systems with State Persistence\n0 50 100150 200 250300 350400\n\u221280\n\u221260\n\u221240\n\u221220\n0\n20\n40\n60\n80\nObservation Sequence\nTime\n(a)\n0 50 100 150200 250300 350400\n0\n2\n4\n6\n8\n10\n12\n14\nTime\nTrue Mode Sequence\n0 50 100150 200250 300350 400\n0\n2\n4\n6\n8\n10\n12\n14\nTime\n(c)\nEstimated Mode Sequence\n0 50100150200 250300 350 400\n0\n2\n4\n6\n8\n10\n12\n14\nTime\nEstimated Mode Sequence\n(b)(d)\nFigure 1. Sensitivity of the HDP-HMM to within-state variations in the observations. (a) Observation sequence; (b) true\nstate sequence; estimated state sequence after 100 Gibbs iterations for the (c) original and (d) sticky HDP-HMM, with\nerrors indicated in red. Without an extra self\u2013transition bias, the HDP-HMM rapidly transitions among redundant states.\nwell as a general solution to the problem of state persis-\ntence in HDP-HMMs. The approach is easily stated\u2014\nwe simply augment the HDP-HMM to include a pa-\nrameter for self-transition bias, and place a separate\nprior on this parameter. The challenge is to consis-\ntently execute this idea in a nonparametric Bayesian\nframework. Earlier papers have also proposed self-\ntransition parameters for HMMs with infinite state\nspaces (Beal et al., 2002; Xing & Sohn, 2007), but\ndid not formulate general solutions that integrate fully\nwith nonparametric Bayesian inference.\nWhile the HDP-HMM treats the state transition dis-\ntribution nonparametrically, it is also desirable to al-\nlow more flexible, nonparametric emission distribu-\ntions. In classical applications of HMMs, finite Gaus-\nsian mixtures are often used to model multimodal ob-\nservations. Dirichlet process (DP) mixtures provide\nan appealing alternative which avoids fixing the num-\nber of observation modes.\ntions are not identifiable for the standard HDP-HMM,\ndue to the tendency to rapidly switch between redun-\ndant states. With an additional self-transition bias,\nhowever, we show that a fully nonparametric HMM\nleads to effective learning algorithms. In particular,\nwe develop a blocked Gibbs sampler which leverages\nforward\u2013backward recursions to jointly resample the\nstate and emission assignments for all observations.\nSuch emission distribu-\nIn Sec. 2, we begin by presenting background material\non the HDP. Sec. 3 then links these nonparametric\nmethods with HMMs, and extends them to account\nfor state persistence. We further augment the model\nwith multimodal emission distributions in Sec. 4, and\npresent results using synthetic data and the NIST\nspeaker diarization database in Sec. 5.\n2. Background: Dirichlet Processes\nA Dirichlet process (DP), denoted by DP(\u03b3,H), is a\ndistribution over countably infinite random measures\nG0(\u03b8) =\n\u221e\n?\nk=1\n\u03b2k\u03b4(\u03b8 \u2212 \u03b8k)\u03b8k\u223c H(1)\non a parameter space \u0398. The weights are sampled via\na stick-breaking construction (Sethuraman, 1994):\n\u03b2k= \u03b2\u2032\nk\nk\u22121\n?\n\u2113=1\n(1 \u2212 \u03b2\u2032\n\u2113)\u03b2\u2032\nk\u223c Beta(1,\u03b3) (2)\nWe denote this distribution by \u03b2 \u223c GEM(\u03b3).\nThe DP is commonly used as a prior on the parameters\nof a mixture model of unknown complexity, resulting\nin a DPMM (see Fig. 2(a)). To generate observations,\nwe choose\u00af\u03b8i \u223c G0 and yi \u223c F(\u00af\u03b8i). This sampling\nprocess is often described via a discrete variable zi\u223c \u03b2\nindicating which component generates yi\u223c F(\u03b8zi).\nThe hierarchical Dirichlet process (HDP) (Teh et al.,\n2006) extends the DP to cases in which groups of data\nare produced by related, yet unique, generative pro-\ncesses. Taking a hierarchical Bayesian approach, the\nHDP places a global Dirichlet process prior DP(\u03b1,G0)\non \u0398, and then draws group specific distributions\nGj\u223c DP(\u03b1,G0). Here, the base measure G0 acts as\nan \u201caverage\u201d distribution (E[Gj] = G0) encoding the\nfrequency of each shared, global parameter:\n\u221e\n?\n\u221e\n?\nBecause G0 is discrete, multiple\u02dc\u03b8jt \u223c G0 may take\nidentical values \u03b8k. Eq. (4) aggregates these probabil-\nities, allowing an observation yjito be directly associ-\nated with the unique global parameters via an indica-\ntor random variable zji\u223c \u03c0j. See Fig. 2(b).\nGj(\u03b8) =\nt=1\n\u02dc \u03c0jt\u03b4(\u03b8 \u2212\u02dc\u03b8jt)\u02dc \u03c0j\u223c GEM(\u03b1) (3)\n=\nk=1\n\u03c0jk\u03b4(\u03b8 \u2212 \u03b8k)\u03c0j\u223c DP(\u03b1,\u03b2) (4)\nWe can alternatively represent this generative process\nvia indicator variables tji \u223c \u02dc \u03c0j and kjt \u223c \u03b2, as in\nFig. 2(c).The stick-breaking priors on these mix-\nture weights can be analytically marginalized, yield-\ning simple forms for the predictive distributions of as-\nsignments. The resulting distribution on partitions is\nsometimes described using the metaphor of a Chinese\nrestaurant franchise (CRF). There are J restaurants\n(groups), each with infinitely many tables (clusters) at"},{"page":3,"text":"An HDP-HMM for Systems with State Persistence\n(a)(b)(c)\nFigure 2. (a) DPMM in which \u03b2 \u223c GEM(\u03b3), \u03b8k \u223c H(\u03bb),\nzi \u223c \u03b2, and yi \u223c f(y | \u03b8zi). (b) HDP mixture model\nwith \u03b2 \u223c GEM(\u03b3), \u03c0j \u223c DP(\u03b1,\u03b2), \u03b8k \u223c H(\u03bb), zji \u223c\n\u03c0j, and yji \u223c f(y | \u03b8zji). (c) CRF with loyal customers.\nCustomers yji sit at table tji \u223c \u02dc \u03c0j which considers dish\n\u00afkjt \u223c \u03b2, but override variables wjt \u223c Ber(\u03ba\/\u03b1 + \u03ba) can\nforce the served dish kjt to be j. The original CRF, as\ndescribed in Sec. 2, has \u03ba = 0 so that kjt =\u00afkjt.\nwhich customers (observations) sit. Upon entering the\njthrestaurant, customer yjisits at currently occupied\ntables tjiwith probability proportional to the number\nof currently seated customers, or starts a new table\u02dct\nwith probability proportional to \u03b1. Each table chooses\na dish (parameter)\u02dc\u03b8jt= \u03b8kjtwith probability propor-\ntional to the number of other tables in the franchise\nthat ordered that dish, or orders a new dish \u03b8\u02dckwith\nprobability proportional to \u03b3. Observation yjiis then\ngenerated by global parameter \u03b8zji=\u02dc\u03b8jtji= \u03b8kjtji.\nAn alternative, non\u2013constructive characterization of\nsamples G0\u223c DP(\u03b3,H) from a Dirichlet process states\nthat for every finite partition {A1,...,AK} of \u0398,\n(G0(A1),...,G0(AK))\n\u223c Dir(\u03b3H(A1),...,\u03b3H(AK)).(5)\nUsing this expression, it can be shown that the fol-\nlowing finite, hierarchical mixture model converges in\ndistribution to the HDP as L \u2192 \u221e (Ishwaran & Zare-\npour, 2002; Teh et al., 2006):\n\u03b2 \u223c Dir(\u03b3\/L,...,\u03b3\/L)\n\u03c0j\u223c Dir(\u03b1\u03b21,...,\u03b1\u03b2L).\n(6)\nLater sections use this weak limit approximation to\ndevelop efficient, blocked sampling algorithms.\n3. The Sticky HDP-HMM\nThe HDP can be used to develop an HMM with an\nunknown, potentially infinite state space (Teh et al.,\n2006). For this HDP-HMM, each HDP group-specific\ndistribution, \u03c0j, is a state-specific transition distribu-\ntion and, due to the infinite state space, there are in-\nfinitely many groups. Let zt denote the state of the\nMarkov chain at time t. For Markov chains zt\u223c \u03c0zt\u22121,\nso that zt\u22121indexes the group to which ytis assigned.\nThe current HMM state ztthen indexes the parameter\n\u03b8ztused to generate observation yt(see Fig. 3).\nFigure 3. Graph of the sticky HDP-HMM. The state\nevolves as zt+1 \u223c \u03c0zt, where \u03c0k \u223c DP(\u03b1 + \u03ba,(\u03b1\u03b2 +\n\u03ba\u03b4k)\/(\u03b1+\u03ba)) and \u03b2 \u223c GEM(\u03b3), and observations are gen-\nerated as yt \u223c F(\u03b8zt). The original HDP-HMM has \u03ba = 0.\nBy sampling \u03c0j \u223c DP(\u03b1,\u03b2), the HDP prior encour-\nages states to have similar transition distributions\n(E[\u03c0jk] = \u03b2k). However, it does not differentiate self\u2013\ntransitions from moves between states. When model-\ning systems with state persistence, the flexible nature\nof the HDP-HMM prior allows for state sequences with\nunrealistically fast dynamics to have large posterior\nprobability. For example, with Gaussian emissions, as\nin Fig. 1, a good explanation of the data is to divide an\nobservation block into two small\u2013variance states with\nslightly different means, and then rapidly switch be-\ntween them (see Fig. 1). In such cases, many models\nwith redundant states may have large posterior prob-\nability, thus impeding our ability to identify a single\ndynamical model which best explains the observations.\nThe problem is compounded by the fact that once this\nalternating pattern has been instantiated by the sam-\npler, its persistence is then reinforced by the prop-\nerties of the Chinese restaurant franchise, thus slow-\ning mixing rates. Furthermore, when observations are\nhigh-dimensional, this fragmentation of data into re-\ndundant states may reduce predictive performance. In\nmany applications, one would thus like to be able to\nincorporate prior knowledge that slow, smoothly vary-\ning dynamics are more likely.\nTo address these issues, we propose to instead sample\ntransition distributions \u03c0jas follows:\n\u03c0j\u223c DP\n?\n\u03b1 + \u03ba,\u03b1\u03b2 + \u03ba\u03b4j\n\u03b1 + \u03ba\n?\n.(7)\nHere, (\u03b1\u03b2 + \u03ba\u03b4j) indicates that an amount \u03ba > 0 is\nadded to the jthcomponent of \u03b1\u03b2. The measure of \u03c0j\nover a finite partition (Z1,...,ZK) of the positive in-\ntegers Z+, as described by Eq. (5), adds an amount \u03ba\nonly to the arbitrarily small partition containing j, cor-\nresponding to a self-transition. When \u03ba = 0 the origi-\nnal HDP-HMM is recovered. Because positive \u03ba values\nincrease the prior probability E[\u03c0jj] of self\u2013transitions,\nwe refer to this extension as the sticky HDP-HMM.\nIn some ways, this \u03ba parameter is reminiscent of the\ninfinite HMM\u2019s self-transition bias (Beal et al., 2002)."},{"page":4,"text":"An HDP-HMM for Systems with State Persistence\nHowever, that paper relied on a heuristic, approximate\nGibbs sampler. The full connection between the infi-\nnite HMM and an underlying nonparametric Bayesian\nprior, as well as the development of a globally con-\nsistent inference algorithm, was made in Teh et al.\n(2006), but without a treatment of a self-transition\nparameter.\n3.1. A CRF with Loyal Customers\nWe further abuse the Chinese restaurant metaphor by\nextending it to the sticky HDP-HMM, where our fran-\nchise now has restaurants with loyal customers. Each\nrestaurant has a specialty dish with the same index as\nthat of the restaurant. Although this dish is served\nelsewhere, it is more popular in the dish\u2019s namesake\nrestaurant. We see this increased popularity from the\nfact that a table\u2019s dish is now drawn as\nkjt\u223c\u03b1\u03b2 + \u03ba\u03b4j\n\u03b1 + \u03ba\n.(8)\nWe will refer to ztas the parent and zt+1as the child.\nThe parent enters a restaurant j determined by its\nparent (the grandparent), zt\u22121= j. We assume there\nis a bijective mapping of indices f : t \u2192 ji. The parent\nthen chooses a table tji\u223c \u02dc \u03c0j and that table is served\na dish indexed by kjtji. Noting that zt= zji= kjtji,\nthe increased popularity of the house specialty dish\nimplies that children are more likely to eat in the same\nrestaurant as their parent and, in turn, more likely\nto eat the restaurant\u2019s specialty dish. This develops\nfamily loyalty to a given restaurant in the franchise.\nHowever, if the parent chooses a dish other than the\nhouse specialty, the child will then go to the restaurant\nwhere this dish is the specialty and will in turn be more\nlikely to eat this dish, too. One might say that for the\nsticky HDP-HMM, children have similar tastebuds to\ntheir parents and will always go the restaurant that\nprepares their parent\u2019s dish best. Often, this keeps\nmany generations eating in the same restaurant.\nThe inference algorithm is simplified if we introduce a\nset of auxiliary random variables\u00afkjtand wjtas follows:\n\u00afkjt\u223c \u03b2,\nwjt\u223c Ber\n?\n\u03ba\n\u03b1 + \u03ba\n?\n,\nkjt=\n?\u00afkjt,wjt= 0;\nwjt= 1,j,\n(9)\nwhere Ber(p) represents the Bernoulli distribution.\nThe table first chooses a dish\u00afkjt without taking the\nrestaurant\u2019s specialty into consideration (i.e., the origi-\nnal CRF.) With some probability, this considered dish\nis overridden (perhaps by a waiter\u2019s suggestion) and\nthe table is served the specialty dish j. Thus, kjtrep-\nresents the served dish. We refer to wjtas the override\nvariable. For the original HDP-HMM, when \u03ba = 0, the\nconsidered dish is always the served dish since wjt= 0\nfor all tables. See Fig. 2(c).\n3.2. Sampling via Direct Assignments\nIn this section we describe a modified version of the\ndirect assignment Rao-Blackwellized Gibbs sampler of\nTeh et al. (2006) which circumvents the complicated\nbookkeeping of the CRF by sampling indicator random\nvariables directly. Throughout this section, we refer to\nthe variables in the graph of Fig. 3. For this sampler,\na set of auxiliary variables mjk, \u00af mjk, and wjtmust be\nadded (as illustrated in Fig. 2(c)).\nSampling zt\nThe posterior distribution factors as:\np(zt= k | z\\t,y1:T,\u03b2,\u03b1,\u03ba,\u03bb) \u221d\np(zt= k | z\\t,\u03b2,\u03b1,\u03ba)p(yt| y\\t,zt= k,z\\t,\u03bb).\nThe properties of the Dirichlet process dictate that on\nthe finite partition {1,...,K,\u02dck} we have the following\nform for the group-specific transition distributions:\n(10)\n\u03c0j\u223c Dir(\u03b1\u03b21,...,\u03b1\u03b2j+ \u03ba,...,\u03b1\u03b2K,\u03b1\u03b2\u02dck).\nWe use the above definition of \u03c0jand the Dirichlet dis-\ntribution\u2019s conjugacy to the multinomial observations\nzt to marginalize \u03c0j and derive the following condi-\ntional distribution over the states assignments:\n(11)\np(zt= k | z\\t,\u03b2,\u03b1,\u03ba) \u221d (\u03b1\u03b2k+n\u2212t\n?\u03b1\u03b2zt+1+ n\u2212t\n\u03b1 + n\u2212t\nzt\u22121k+\u03ba\u03b4(zt\u22121,k))\nkzt+1+ \u03ba\u03b4(k,zt+1) + \u03b4(zt\u22121,k)\u03b4(k,zt+1)\nk.+ \u03ba + \u03b4(zt\u22121,k)\n?\n.\n(12)\nThis formula is more complex than that of the stan-\ndard HDP sampler due to potential dependencies in\nthe marginalization of \u03c0zt\u22121and \u03c0zt. For a detailed\nderivation, see Fox et al. (2007). The notation njkrep-\nresents the number of Markov chain transitions from\nstate j to k, nj. =?\ntion zt\u22121to ztor ztto zt+1. Intuitively, this expression\nchooses a state k with probability depending on how\nmany times we have seen other zt\u22121 to k and k to\nzt+1transitions. Note that there is a dependency on\nwhether either or both of these transitions correspond\nto a self-transition, which is strongest when \u03ba > 0.\nknjk, and n\u2212t\njkthe number of\ntransitions from state j to k not counting the transi-\nAs in Teh et al. (2006), by placing a conjugate prior\non the parameter space, there is a closed analytic form\nfor the likelihood component p(yt| y\\t,zt= k,z\\t,\u03bb).\nAssume there are currently\u00afK unique\ndishes being considered and take a finite partition\n{\u03b81,\u03b82,...,\u03b8 \u00af K,\u03b8\u02dck} of \u0398, where \u03b8\u02dck= \u0398\\? \u00af K\n\u03b8k, the properties of the Dirichlet distribution dictate:\np((\u03b21,...,\u03b2 \u00af K,\u03b2\u02dck) |\u00afk,\u03b3) \u221d Dir(\u00af m.1,..., \u00af m.\u00af K,\u03b3). (13)\nFrom the above, we see that {\u00af m.k}\u00af K\nficient statistics for resampling \u03b2 on this partition.\nSampling \u03b2\nk=1{\u03b8k}.\nSince\u02dc\u03b8jt \u223c G0 and \u00af m.k tables are considering dish\nk=1is a set of suf-"},{"page":5,"text":"An HDP-HMM for Systems with State Persistence\nHowever, this requires sampling two additional vari-\nables, mjk and wjt, corresponding to the number of\ntables in restaurant j served dish k and the corre-\nsponding overwrite variables. We jointly sample from\np(m,w, \u00af m | z1:T,\u03b2,\u03b1,\u03ba) = p( \u00af m | m,w,z1:T,\u03b2,\u03b1,\u03ba)\np(w | m,z1:T,\u03b2,\u03b1,\u03ba)p(m | z1:T,\u03b2,\u03b1,\u03ba). (14)\nWe start by examining p(m | z1:T,\u03b2,\u03b1,\u03ba). Having\nthe state index assignments z1:T effectively partitions\nthe data (customers) into both restaurants and dishes,\nthough the table assignments are unknown since mul-\ntiple tables can be served the same dish. Thus, sam-\npling mjkis in effect equivalent to sampling table as-\nsignments for each customer after knowing the dish\nassignment. This conditional distribution is given by:\np(tji= t | kjt= k,t\u2212ji,k\u2212jt,y1:T,\u03b2,\u03b1,\u03ba)\n\u02dc n\u2212ji\njt,\n\u03b1\u03b2k+ \u03ba\u03b4(k,j),\n\u221d\n?\nis the number of customers at table t in\nrestaurant j, not counting yji. The form of Eq. (15)\nimplies that a customer\u2019s table assignment conditioned\non a dish assignment k follows a DP with concentra-\ntion parameter \u03b1\u03b2k+\u03ba\u03b4(k,j) and may be sampled by\nsimulating the associated Chinese restaurant process.\nt \u2208 {1,...,Tj};\nt =\u02dctj,\n(15)\nwhere \u02dc n\u2212ji\njt\nWe now derive the conditional distribution for the\noverride variables wjt. The table counts provide that\nmjktables are serving dish k in restaurant j. If k ?= j,\nwe automatically have mjk tables with wjt= 0 since\nthe served dish is not the house specialty. Otherwise,\np(wjt| kjt= j,\u03b2,\u03c1) \u221d\n?\n\u03b2j(1 \u2212 \u03c1),\n\u03c1,\nwjt= 0;\nwjt= 1,\n(16)\nwhere \u03c1 =\nObserving served dish kjt= j makes it more likely that\nthe considered dish\u00afkjtwas overridden than the prior\nsuggests. We draw mjjsamples of wjtfrom Eq. (16).\n\u03ba\n\u03b1+\u03bais the prior probability that wjt= 1.\nGiven mjk for all j and k and wjt for each of these\ninstantiated tables, we can now deterministically com-\npute \u00af mjk. Any table that was overridden is an unin-\nformative observation for the posterior of \u00af mjkso that\n\u00af mjk=\n?\nmjk,\nmjj\u2212 wj.,\nj ?= k;\nj = k.\n(17)\nSampling Hyperparameters\nthe sticky HDP-HMM\u2019s hyperparameters, we place\nvague gamma priors on \u03b3 and (\u03b1 + \u03ba), and a beta\nprior on \u03ba\/(\u03b1+\u03ba). As detailed in Fox et al. (2007), the\nauxiliary variables introduced in the preceding section\nthen allow tractable resampling of these hyperparam-\neters. This allows the number of occupied states, and\nthe degree of self\u2013transition bias, to be strongly influ-\nenced by the statistics of observed data, as desired.\nRather than fixing\n3.3. Blocked Sampling of State Sequences\nThe HDP-HMM direct assignment sampler can exhibit\nslow mixing rates since global state sequence changes\nare forced to occur coordinate by coordinate. This is\nexplored in Scott (2002) for the finite HMM. Although\nthe sticky HDP-HMM reduces the posterior uncer-\ntainty caused by fast state-switching explanations of\nthe data, the self-transition bias can cause two con-\ntinuous and temporally separated sets of observations\nof a given state to be grouped into two states. If this\noccurs, the high probability of self-transition makes it\nchallenging for the sequential sampler to group those\ntwo examples into a single state.\nA variant of the HMM forward-backward procedure\n(Rabiner, 1989) allows us to harness the Markov struc-\nture and jointly sample the state sequence z1:T given\nthe observations y1:T, transitions probabilities \u03c0j, and\nmodel parameters \u03b8k. To take advantage of this pro-\ncedure, we now must sample the previously marginal-\nized transition distributions and model parameters. In\npractice, this requires approximating the theoretically\ncountably infinite transition distributions.\nproach is the degree L weak limit approximation to\nthe DP (Ishwaran & Zarepour, 2002),\nOne ap-\nGEML(\u03b1) ? Dir(\u03b1\/L,...,\u03b1\/L),(18)\nwhere L is a number that exceeds the total number\nof expected HMM states. This approximation encour-\nages the learning of models with fewer than L com-\nponents while allowing the generation of new compo-\nnents, upper bounded by L, as new data are observed.\nThe posterior distributions of \u03b2 and \u03c0jare given by:\n\u03b2 \u223c Dir(\u03b3\/L + \u00af m.1,...,\u03b3\/L + \u00af m.L)\n\u03c0j\u223c Dir(\u03b1\u03b21+ nj1,...,\u03b1\u03b2j+ \u03ba + njj,...,\u03b1\u03b2L+ njL).\n(19)\nDepending on the form of the emission distribution\nand base measure on the parameter space \u0398, we sam-\nple parameters for each of the currently instantiated\nstates from the updated posterior distribution:\n\u03b8j\u223c p(\u03b8 | {yt| zt= j},\u03bb).(20)\nNow that we are sampling \u03b8j directly, we can use a\nnon-conjugate base measure.\nWe block sample z1:T by first computing backward\nmessages mt,t\u22121(zt\u22121) \u221d p(yt:T|zt\u22121,\u03c0,\u03b8) and then\nrecursively sampling each ztconditioned on zt\u22121from\np(zt| zt\u22121,y1:T,\u03c0,\u03b8) \u221d\np(zt| \u03c0zt\u22121)p(yt| \u03b8zt)mt+1,t(zt). (21)\nA similar sampler has been used for learning HDP hid-\nden Markov trees (Kivinen et al., 2007). However, this\nwork did not consider the complications introduced by\nmultimodal emissions, as we explore next."},{"page":6,"text":"An HDP-HMM for Systems with State Persistence\nFigure 4. Sticky HDP-HMM with DP emissions, where st\nindexes the state-specific mixture component generating\nobservation yt. The DP prior dictates that st \u223c \u03c8ztfor\n\u03c8k \u223c GEM(\u03c3). The jthGaussian component of the kth\nmixture density is parameterized by \u03b8k,j so yt \u223c F(\u03b8zt,st).\n4. Multimodal Emission Distributions\nFor many application domains, the data associated\nwith each hidden state may have a complex, multi-\nmodal distribution. We propose to approximate such\nemission distributions nonparametrically, using an in-\nfinite DP mixture of Gaussians. This formulation is\nrelated to the nested DP (Rodriguez et al., 2006).\nThe bias towards self-transitions allow us to distin-\nguish between the underlying HDP-HMM states. If\nthe model were free to both rapidly switch between\nHDP-HMM states and associate multiple Gaussians\nper state, there would be considerable posterior un-\ncertainty. Thus, it is only with the sticky HDP-HMM\nthat we can effectively learn such models.\nWe augment the HDP-HMM state zt with a term st\nindexing the mixture component of the zth\ndensity. For each HDP-HMM state, there is a unique\nstick-breaking distribution \u03c8k\u223c GEM(\u03c3) defining the\nmixture weights of the kthemission density so that\nst\u223c \u03c8zt. The observation ytis generated by the Gaus-\nsian component with parameter \u03b8zt,st. See Fig. 4.\nt\nemission\nTo implement blocked resampling of (z1:T,s1:T), we\nuse weak limit approximations to both the HDP-HMM\nand Dirichlet process emissions, approximated to lev-\nels L and L\u2032, respectively. The posterior distributions\nof \u03b2 and \u03c0kremain unchanged; that of \u03c8kis given by:\n\u03c8k\u223c Dir(\u03c3\/L\u2032+ n\u2032\nwhere n\u2032\nklare the number of observations assigned to\nthe lthmixture component of the kthHMM state. The\nposterior distribution for each Gaussian\u2019s mean and\ncovariance, \u03b8k,j, is determined by the observations as-\nsigned to this component, namely,\nk1,...,\u03c3\/L\u2032+ n\u2032\nkL\u2032),(22)\n\u03b8k,j\u223c p(\u03b8 | {yt| (zt= k,st= j)},\u03bb).(23)\nThe augmented state (zt,st) is sampled from\np(zt,st| zt\u22121,y1:T,\u03c0,\u03c8,\u03b8) \u221d\np(zt| \u03c0zt\u22121)p(st| \u03c8zt)p(yt| \u03b8zt,st)mt+1,t(zt).\nSince the Markov structure is only on the zt compo-\n(24)\nnent of the augmented state, the backward message\nmt,t\u22121(zt\u22121) from (zt,st) to (zt\u22121,st\u22121) is solely a\nfunction of zt\u22121. These messages are given by:\nmt,t\u22121(zt\u22121) \u221d\n?\nzt\n?\nst\np(zt| \u03c0zt\u22121)p(st| \u03c8zt)\np(yt| \u03b8zt,st)mt+1,t(zt).(25)\n5. Results\nSynthetic Data\nthree-state Gaussian emission HMM with: 0.97 proba-\nbility of self-transition; means 50, 0, and -50; and vari-\nances 50, 10, and 50 (see Fig. 1(a).) For the blocked\nsampler, we used a truncation level of L = 15.\nWe generated test data from a\nFig. 5 shows the clear advantage of considering a sticky\nHDP-HMM with blocked sampling.\ndistance error is calculated by greedily mapping the\nindices of the estimated state sequence to those max-\nimizing overlap with the true sequence. The appar-\nent slow convergence of the sticky HDP-HMM direct\nassignment sampler (Fig. 5(b)) can be attributed to\nthe sampler splitting temporally separated segments\nof a true state into multiple, redundant states. Al-\nthough not depicted due to space constraints, both\nsticky HDP-HMM samplers result in estimated mod-\nels with significantly larger likelihoods of the true state\nsequence than those of the original HDP-HMM.\nThe Hamming\nTo test the model of Sec. 4, we generated data from a\ntwo-state HMM, where each state had a two-Gaussian\nmixture emission distribution with equally weighted\ncomponents defined by means (0,10) and (\u22127,7), and\nvariances of 10. The probability of self-transition was\nset to 0.98. The resulting observation and true state\nsequences are shown in Fig. 6(a) and (b).\nFig. 6(e)-(h) compares the performance of the sticky\nand original HDP-HMM with single and infinite Gaus-\nsian mixture emissions. All results are for the blocked\nsampler with truncation levels L = L\u2032= 15.\ntuitively, when constrained to single Gaussian emis-\nsions, the best explanation of the data is to associate\neach true mixture component with a separate state\nand then quickly switch between these states, result-\ning in the large Hamming distances of Fig. 6(g)-(h).\nAlthough not the desired effect in this scenario, this\nbehavior, as depicted in Fig. 6(c), demonstrates the\nflexibility of the sticky HDP-HMM: if the best ex-\nplanation of the data according to the model is fast\nstate-switching, the sticky HDP-HMM still allows for\nthis by learning a small bias towards self-transitions.\nThe sticky HDP-HMM occasionally has more accu-\nrate state sequence estimates by grouping a true state\u2019s\nGaussian mixture components into a single Gaussian\nwith large variance. By far the best performance is\nIn-"},{"page":7,"text":"An HDP-HMM for Systems with State Persistence\n0 2040 60 80100120140160 180200\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\nIteration\n(a)\nNormalized Hamming Distance\n0 2040 6080 100120140160180200\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\nIteration\n(b)\nNormalized Hamming Distance\n02040 6080100120140160 180200\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\nIteration\n(c)\nNormalized Hamming Distance\n0 2040 6080 100120140160180200\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\nIteration\n(d)\nNormalized Hamming Distance\nFigure 5. Hamming distance between true and estimated state sequences over 100 iterations for the sticky HDP-HMM (a)\nblocked and (b) direct assignment samplers and the original HDP-HMM (c) blocked and (d) direct assignment samplers.\nThese plots show the median (solid blue) and 10thand 90thquantiles (dashed red) from 200 initializations.\n0 100 200300 400 500 600700800900 1000\n\u221220\n\u221215\n\u221210\n\u22125\n0\n5\n10\n15\n20\n25\nTime\n(a)\nObservations\n0100 200300400500 6007008009001000\n1\n2\nTime\nTrue Mode Sequence\n0 100200300400500 600700800 900 1000\n\u22121\n0\n1\n2\n3\n4\n5\n6\n7\n8\nTime\n(c)\nEstimated Mode Sequence\n0100200 300400500600700 8009001000\n1\n2\nTime\nEstimated Mode Sequence\n(b)(d)\n01020304050607080 90 100\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\nIteration\n(e)\nNormalized Hamming Distance\n0102030405060708090100\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\nIteration\n(f)\nNormalized Hamming Distance\n0102030405060708090100\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\nIteration\n(g)\nNormalized Hamming Distance\n01020 30 40 5060 708090100\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\nIteration\n(h)\nNormalized Hamming Distance\nFigure 6. Performance of inference on data generated by an HMM with Gaussian mixture emissions. (a) Observation\nsequence; (b) true HMM state sequence; estimated HMM state sequence using the sticky HDP-HMM model with (c)\nsingle and (d) infinite Gaussian mixture emissions. Errors are indicated by red markers. The bottom row contains\nHamming distance plots, as in Fig. 5, for infinite Gaussian mixture emissions and the (e) sticky HDP-HMM and (f)\noriginal HDP-HMM, and single Gaussian emissions for the (g) sticky HDP-HMM and (h) original HDP-HMM.\nachieved by the sticky HDP-HMM with infinite Gaus-\nsian mixture emissions (see Fig. 6(e) and (d)); compar-\ning to Fig. 6(f), we see that the gain can be attributed\nto modeling rather than just improved mixing rates.\nSpeaker Diarization Data\ntion task involves segmenting an audio recording into\nspeaker-homogeneous regions, while simultaneously\nidentifying the number of speakers. We tested the util-\nity of the sticky HDP-HMM for this task on the data\ndistributed by NIST as part of the Rich Transcrip-\ntion 2004-2007 meeting recognition evaluations (NIST,\n2007). We use the first 19 Mel Frequency Cepstral\nCoefficients (MFCCs), computed over a 30ms window\nevery 10ms, as our feature vector.\nwith this dataset, we discovered that: (1) the high\nfrequency content of these features contained little\ndiscriminative information, and (2) without a mini-\nmum speaker duration, the sticky HDP-HMM learned\nwithin speaker dynamics in addition to global speaker\nchanges. To jointly address these issues, we instead\nThe speaker diariza-\nWhen working\nmodel feature averages computed over 250ms, non\u2013\noverlapping blocks. A minimum speaker duration of\n500ms is set by associating two average features with\neach hidden state. We also tie the covariances of\nwithin\u2013state mixture components. We found single\u2013\nGaussian emission distributions to be less effective.\nFor each of 21 meetings, we compare 10 initializations\nof the original and sticky HDP-HMM blocked sam-\nplers. In Fig. 8(a), we report the official NIST di-\narization error rate (DER) of the run with the largest\nobservation sequence likelihood, given parameters esti-\nmated at the 1000th Gibbs iteration. The sticky HDP-\nHMM\u2019s temporal smoothing provides substantial per-\nformance gains. Fig 8(b) plots the estimated versus\ntrue number of speakers who talk for more than 10%\nof the meeting time, and shows our model\u2019s ability\nto adapt to a varying number of speakers. As a fur-\nther comparison, the ICSI team\u2019s algorithm (Wooters\n& Huijbregts, 2007), by far the best performer at the\n2007 competition, has an overall DER of 18.37%, simi-"},{"page":8,"text":"An HDP-HMM for Systems with State Persistence\n0123456\n4\nx 10\n1\n2\n3\n4\nTrue speaker label\nTime\n(a)\n0123456\n4\nx 10\n1\n2\n3\n4\nEstimated speaker label\nTime\n0123456\n4\nx 10\n0\n1\n2\n3\n4\n5\n6\n7\n8\nTrue speaker label\nTime\n(c)\n0123456\n4\nx 10\n1\n2\n3\n4\n5\n6\n7\nEstimated speaker label\nTime\n(b)(d)\nFigure 7. True state sequences for meetings (a) AMI 20041210-1052 and (c) VT 20050304-1300, with the corresponding\nmost likely state estimates shown in (b) and (d), respectively, with incorrect labels shown in red.\n0 10\nSticky HDP\u2212HMM DER (%)\n(a)\n20304050\n0\n5\n10\n15\n20\n25\n30\n35\n40\n45\n50\nHDP\u2212HMM DER (%)\n12345\n1\n2\n3\n4\n5\nEstimated number of speakers\n(b)\nTrue number of speakers\nFigure 8. For the 21 meeting database: (a) plot of sticky\nvs. original HDP-HMM most likely sequence DER; and\n(b) plot of true vs. estimated number of speakers for sam-\nples drawn from 10 random initializations of each meeting\n(larger circles have higher likelihood).\nlar to our 19.04%. Our best and worst DER are 1.26%\nand 31.42%, respectively, compared to their 4.39% and\n32.23%. We use the same non-speech pre-processing,\nso that the differences are due to changes in the iden-\ntified speakers. As depicted in Fig. 7, a significant\nproportion of our errors can be attributed to split-\nting or merging speakers. The ICSI team\u2019s algorithm\nuses agglomerative clustering, and requires significant\ntuning of parameters on representative training data.\nIn contrast, our hyperparameters are automatically\nset meeting-by-meeting, so that each component\u2019s ex-\npected mean and covariance are that of the entire fea-\nture sequence.Note that the selected runs plotted\nin Fig. 8 are not necessarily those with the smallest\nDER. For example, the run depicted in Fig. 7(d) had\n24.06% DER, while another run on the same meeting\nhad 4.37% (versus ICSI\u2019s 22.00%.) There is inherent\nposterior uncertainty in this task, and our sampler has\nthe advantage of giving several interpretations. When\nconsidering the best per-meeting DER for the five most\nlikely samples, our overall DER drops to 15.14%; we\nhope to explore automated ways of combining multiple\nsamples in future work. Regardless, our results demon-\nstrate that the sticky HDP-HMM provides an elegant\nand empirically effective speaker diarization method.\n6. Discussion\nWe have demonstrated the considerable benefits of an\nextended HDP-HMM in which a separate parameter\ncaptures state persistence. We have also shown that\nthis sticky HDP-HMM allows a fully nonparametric\ntreatment of multimodal emissions, disambiguated by\nits bias towards self-transitions, and presented efficient\nsampling techniques with mixing rates that improve\non the state-of-the-art. Results on synthetic data, and\na challenging speaker diarization task, clearly demon-\nstrate the practical importance of our extensions.\nAcknowledgments\nWe thank O. Vinyals, G. Friedland, and N. Morgan for\nhelpful discussions about the NIST dataset. This research\nwas supported in part by DARPA contract NBCHD030010,\nand MURIs funded through ARO Grant W911NF-06-1-\n0076 and AFOSR Grant FA9550-06-1-0324.\npartially funded by an NDSEG fellowship.\nE.B.F. was\nReferences\nBeal, M. J., Ghahramani, Z., & Rasmussen, C. E. (2002).\nThe infinite hidden Markov model. NIPS (pp. 577\u2013584).\nFox, E., Sudderth, E., Jordan, M., & Willsky, A. (2007).\nA tempered HDP-HMM for systems with state persis-\ntence. MIT LIDS, TR #2777.\nIshwaran, H., & Zarepour, M. (2002). Exact and approxi-\nmate sum\u2013representations for the Dirichlet process. Can.\nJ. Stat., 30, 269\u2013283.\nKivinen, J. J., Sudderth, E. B., & Jordan, M. I. (2007).\nLearning multiscale representations of natural scenes us-\ning Dirichlet processes. ICCV (pp. 1\u20138).\nNIST (2007).Rich\nhttp:\/\/www.nist.gov\/speech\/tests\/rt\/.\nRabiner, L. (1989). A tutorial on hidden Markov mod-\nels and selected applications in speech recognition. Proc.\nIEEE, 77, 257\u2013286.\nRodriguez, A., Dunson, D., & Gelfand, A. (2006). The\nnested Dirichlet process. Duke ISDS, TR #06-19.\nScott, S. (2002). Bayesian methods for hidden Markov\nmodels: Recursive computing in the 21st century.\nAmer. Stat. Assoc., 97, 337\u2013351.\nSethuraman, J. (1994).A constructive definition of\nDirichlet priors. Stat. Sinica, 4, 639\u2013650.\nTeh, Y. W., Jordan, M. I., Beal, M. J., & Blei, D. M.\n(2006). Hierarchical Dirichlet processes. J. Amer. Stat.\nAssoc., 101, 1566\u20131581.\nWooters, C., & Huijbregts, M. (2007). The ICSI RT07s\nspeaker diarization system. To appear in LNCS.\nXing, E., & Sohn, K.-A. (2007). Hidden Markov Dirich-\nlet process: Modeling genetic inference in open ancestral\nspace. Bayes. Analysis, 2, 501\u2013528.\ntranscriptionsdatabase.\nJ."}],"fullTextUrl":"https:\/\/www.researchgate.net\/profile\/Michael_Jordan13\/publication\/221344933_An_HDP-HMM_for_systems_with_state_persistence\/links\/53fe28a60cf283c3583bcdd5.pdf","widgetId":"rgw30_56ab19b4883a8"},"id":"rgw30_56ab19b4883a8","partials":[],"templateName":"publicliterature\/stubs\/PublicationText.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationText.html?publicationUid=221344933&hide=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationDetailAd":{"data":{"googleDfpSlot":null,"widgetId":"rgw31_56ab19b4883a8"},"id":"rgw31_56ab19b4883a8","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAd.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAd.html?publicationUid=221344933&slotId=336x280_Publications_ATF_Right&collapseSlotMode=never&fallbackContainerEnabled=1","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationRelations":null,"publicationRelationsReverse":null,"publicationUid":221344933,"showSignUpDialog":false,"selectNewSignUpDialog":false,"publicationQuestions":null,"publicationCitations":{"data":{"publicationUid":221344933,"publicationCitationsList":{"data":{"citationItems":[{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore","clickThrough":"experimentMilestoneClickedToPublicationFromCitationWithSlurp","clickThroughWithContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextSlurp","nextPublicationViewId":null,"authorsPartOne":[{"id":2083158713,"url":"researcher\/2083158713_Mehmet_Emin_Basbug","fullname":"Mehmet Emin Basbug","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2006576155,"url":"researcher\/2006576155_Koray_Ozcan","fullname":"Koray Ozcan","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":74635859,"url":"researcher\/74635859_Senem_Velipasalar","fullname":"Senem Velipasalar","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":[["includes-citation-list"]],"isFulltext":false,"isSlurp":true,"isNoText":false,"publicationType":"Article","publicationDate":"Oct 2015","journal":null,"showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/283043558_Accelerometer_based_Activity_Classification_with_Variational_Inference_on_Sticky_HDP-SLDS","usePlainButton":true,"publicationUid":283043558,"feedStubs":null,"hasFeedStubs":false,"impactPoints":false,"url":"publication\/283043558_Accelerometer_based_Activity_Classification_with_Variational_Inference_on_Sticky_HDP-SLDS","title":"Accelerometer based Activity Classification with Variational Inference on Sticky HDP-SLDS","displayTitleAsLink":true,"authors":[{"id":2083158713,"url":"researcher\/2083158713_Mehmet_Emin_Basbug","fullname":"Mehmet Emin Basbug","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2006576155,"url":"researcher\/2006576155_Koray_Ozcan","fullname":"Koray Ozcan","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":74635859,"url":"researcher\/74635859_Senem_Velipasalar","fullname":"Senem Velipasalar","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":[],"abstract":"As part of daily monitoring of human activities, wearable sensors and devices\nare becoming increasingly popular sources of data. With the advent of\nsmartphones equipped with acceloremeter, gyroscope and camera; it is now\npossible to develop activity classification platforms everyone can use\nconveniently. In this paper, we propose a fast inference method for an\nunsupervised non-parametric time series model namely variational inference for\nsticky HDP-SLDS(Hierarchical Dirichlet Process Switching Linear Dynamical\nSystem). We show that the proposed algorithm can differentiate various indoor\nactivities such as sitting, walking, turning, going up\/down the stairs and\ntaking the elevator using only the acceloremeter of an Android smartphone\nSamsung Galaxy S4. We used the front camera of the smartphone to annotate\nactivity types precisely. We compared the proposed method with Hidden Markov\nModels with Gaussian emission probabilities on a dataset of 10 subjects. We\nshowed that the efficacy of the stickiness property. We further compared the\nvariational inference to the Gibbs sampler on the same model and show that\nvariational inference is faster in one order of magnitude.","description":false,"swapJournalAndAuthorPositions":false,"showAbstract":true,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/283043558_Accelerometer_based_Activity_Classification_with_Variational_Inference_on_Sticky_HDP-SLDS","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":false,"actions":[{"type":"request-external","text":"Request full-text","url":"javascript:;","active":false,"primary":false,"extraClass":null,"icon":null,"data":[{"key":"context","value":"pubCit"}]}],"actionWidgets":[],"publicationItemFulltext":{"data":{"isDataset":false,"isResearch":false,"isFulltext":true,"source":{"isPreview":true,"sourceUrl":"deref\/http%3A%2F%2Fde.arxiv.org%2Fpdf%2F1510.05477","sourceName":"de.arxiv.org","hasSourceUrl":true},"publicationUid":283043558,"publicationUrl":"publication\/283043558_Accelerometer_based_Activity_Classification_with_Variational_Inference_on_Sticky_HDP-SLDS","eventCode":"","citationCount":0,"additionalContentWidgets":[],"disableViewer":true,"showLoggedOutRequestButton":false,"context":null,"previewUrl":"https:\/\/i1.rgstatic.net\/publication\/283043558_Accelerometer_based_Activity_Classification_with_Variational_Inference_on_Sticky_HDP-SLDS\/links\/562ec62508ae04c2aeb5e29a\/smallpreview.png","linkId":"562ec62508ae04c2aeb5e29a","origin":"publication_list","showRequestCount":false,"publish":false,"request":false,"showAction":false,"displayAsLink":true,"documentViewerUrl":"publicliterature.PublicLiteratureDocumentViewer.html?publicationId=283043558&reference=562ec62508ae04c2aeb5e29a&eventCode=&origin=publication_list","widgetId":"rgw35_56ab19b4883a8"},"id":"rgw35_56ab19b4883a8","partials":[],"templateName":"publicliterature\/stubs\/PublicationItemFulltext.html","templateExtensions":["generalHelpers"],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItemFulltext.html?publicationUid=283043558&showAction=1&eventCode=&hideSource=0&displayAsLink=1&showPublishAsSelectFile=0","viewClass":"views.publicliterature.PublicationItemFulltextView","yuiModules":["rg.views.publicliterature.PublicationItemFulltextView"],"stylesheets":[],"_isYUI":true},"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":true,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":221344933,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/283043558_Accelerometer_based_Activity_Classification_with_Variational_Inference_on_Sticky_HDP-SLDS\/review","additionalRightSideTopWidgets":[{"data":{"citationContexts":["The initial attempts resulted in oscillatory behavior in practice. [16] modified the generative process to ensure the mode persistence. Later this concept is extended to SLDS in [17] where the new model is named sticky HDP- SLDS. "],"widgetId":"rgw36_56ab19b4883a8"},"id":"rgw36_56ab19b4883a8","partials":[],"templateName":"publicliterature\/stubs\/PublicationItemCitationContexts.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItemCitationContexts.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":true,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw34_56ab19b4883a8"},"id":"rgw34_56ab19b4883a8","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":true,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItem.html?showEnrichedPublicationItem=0&showRequestButton=1&publicationUid=283043558&additionalCssClasses%5B0%5D=includes-citation-list&citationContextItemVersion=old&isIncomingCitation=1","viewClass":"views.publicliterature.PublicationItemView","yuiModules":["rg.views.publicliterature.PublicationItemView"],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore","clickThrough":"experimentMilestoneClickedToPublicationFromCitationWithFulltext","clickThroughWithContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":48987261,"url":"researcher\/48987261_Pierre_E_Jacob","fullname":"Pierre E. Jacob","last":true,"imageUrl":"https:\/\/i1.rgstatic.net\/ii\/profile.image\/AS%3A272385618214939%401441953200622_m\/Pierre_Jacob2.png"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":[["includes-citation-list"]],"isFulltext":true,"isSlurp":false,"isNoText":false,"publicationType":"Article","publicationDate":"May 2015","journal":null,"showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/276923083_Sequential_Bayesian_inference_for_implicit_hidden_Markov_models_and_current_limitations","usePlainButton":true,"publicationUid":276923083,"feedStubs":null,"hasFeedStubs":false,"impactPoints":false,"url":"publication\/276923083_Sequential_Bayesian_inference_for_implicit_hidden_Markov_models_and_current_limitations","title":"Sequential Bayesian inference for implicit hidden Markov models and current limitations","displayTitleAsLink":true,"authors":[{"id":48987261,"url":"researcher\/48987261_Pierre_E_Jacob","fullname":"Pierre E. Jacob","last":true,"imageUrl":"https:\/\/i1.rgstatic.net\/ii\/profile.image\/AS%3A272385618214939%401441953200622_m\/Pierre_Jacob2.png"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["05\/2015; 51. DOI:10.1051\/proc\/201551002"],"abstract":"Hidden Markov models can describe time series arising in various fields of\nscience, by treating the data as noisy measurements of an arbitrarily complex\nMarkov process. Sequential Monte Carlo (SMC) methods have become standard tools\nto estimate the hidden Markov process given the observations and a fixed\nparameter value. We review some of the recent developments allowing the\ninclusion of parameter uncertainty as well as model uncertainty. The\nshortcomings of the currently available methodology are emphasised from an\nalgorithmic complexity perspective. The statistical objects of interest for\ntime series analysis are illustrated on a toy \"Lotka-Volterra\" model used in\npopulation ecology. Some open challenges are discussed regarding the\nscalability of the reviewed methodology to longer time series,\nhigher-dimensional state spaces and more flexible models.","description":false,"swapJournalAndAuthorPositions":false,"showAbstract":true,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/276923083_Sequential_Bayesian_inference_for_implicit_hidden_Markov_models_and_current_limitations","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":true,"actions":[{"type":"download","text":"Download","url":"profile\/Pierre_Jacob2\/publication\/276923083_Sequential_Bayesian_inference_for_implicit_hidden_Markov_models_and_current_limitations\/links\/560410d808aea25fce30b296.pdf?origin=publication_list","active":false,"primary":true,"extraClass":"open-viewer","icon":null,"data":[]}],"actionWidgets":[],"publicationItemFulltext":{"data":{"isDataset":false,"isResearch":false,"isFulltext":true,"source":{"isPreview":false,"sourceUrl":"profile\/Pierre_Jacob2","sourceName":"Pierre E Jacob","hasSourceUrl":true},"publicationUid":276923083,"publicationUrl":"publication\/276923083_Sequential_Bayesian_inference_for_implicit_hidden_Markov_models_and_current_limitations","eventCode":"","citationCount":0,"additionalContentWidgets":[],"disableViewer":true,"showLoggedOutRequestButton":false,"context":null,"previewUrl":"https:\/\/i1.rgstatic.net\/publication\/276923083_Sequential_Bayesian_inference_for_implicit_hidden_Markov_models_and_current_limitations\/links\/560410d808aea25fce30b296\/smallpreview.png","linkId":"560410d808aea25fce30b296","origin":"publication_list","showRequestCount":false,"publish":false,"request":false,"showAction":false,"displayAsLink":true,"documentViewerUrl":"publicliterature.PublicLiteratureDocumentViewer.html?publicationId=276923083&reference=560410d808aea25fce30b296&eventCode=&origin=publication_list","widgetId":"rgw38_56ab19b4883a8"},"id":"rgw38_56ab19b4883a8","partials":[],"templateName":"publicliterature\/stubs\/PublicationItemFulltext.html","templateExtensions":["generalHelpers"],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItemFulltext.html?publicationUid=276923083&showAction=1&eventCode=&hideSource=0&displayAsLink=1&showPublishAsSelectFile=0","viewClass":"views.publicliterature.PublicationItemFulltextView","yuiModules":["rg.views.publicliterature.PublicationItemFulltextView"],"stylesheets":[],"_isYUI":true},"linkId":"560410d808aea25fce30b296","context":null,"contextId":null,"eventCode":"","isCitation":true,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":221344933,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/276923083_Sequential_Bayesian_inference_for_implicit_hidden_Markov_models_and_current_limitations\/review","additionalRightSideTopWidgets":[{"data":{"citationContexts":["Note that combining non-parametric models for the function f and for the noise v t is not obvious because of identifiability issues. Other instances of non-parametric hidden Markov models consider the case where the hidden process lives on an infinite but discrete state space [44] [84]. Particle Markov chain Monte Carlo methods have recently been used in this context [86]. "],"widgetId":"rgw39_56ab19b4883a8"},"id":"rgw39_56ab19b4883a8","partials":[],"templateName":"publicliterature\/stubs\/PublicationItemCitationContexts.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItemCitationContexts.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":true,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read full-text","widgetId":"rgw37_56ab19b4883a8"},"id":"rgw37_56ab19b4883a8","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":true,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItem.html?showEnrichedPublicationItem=0&showRequestButton=1&publicationUid=276923083&additionalCssClasses%5B0%5D=includes-citation-list&citationContextItemVersion=old&isIncomingCitation=1","viewClass":"views.publicliterature.PublicationItemView","yuiModules":["rg.views.publicliterature.PublicationItemView"],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore","clickThrough":"experimentMilestoneClickedToPublicationFromCitationWithSlurp","clickThroughWithContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextSlurp","nextPublicationViewId":null,"authorsPartOne":[{"id":2017394071,"url":"researcher\/2017394071_Ava_Bargi","fullname":"Ava Bargi","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":69866501,"url":"researcher\/69866501_Richard_Yi_Da_Xu","fullname":"Richard Yi Da Xu","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":6373073,"url":"researcher\/6373073_Massimo_Piccardi","fullname":"Massimo Piccardi","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":[["includes-citation-list"]],"isFulltext":false,"isSlurp":true,"isNoText":false,"publicationType":"Article","publicationDate":"Mar 2015","journal":null,"showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/273472293_An_Adaptive_Online_HDP-HMM_for_Segmentation_and_Classification_of_Sequential_Data","usePlainButton":true,"publicationUid":273472293,"feedStubs":null,"hasFeedStubs":false,"impactPoints":false,"url":"publication\/273472293_An_Adaptive_Online_HDP-HMM_for_Segmentation_and_Classification_of_Sequential_Data","title":"An Adaptive Online HDP-HMM for Segmentation and Classification of Sequential Data","displayTitleAsLink":true,"authors":[{"id":2017394071,"url":"researcher\/2017394071_Ava_Bargi","fullname":"Ava Bargi","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":69866501,"url":"researcher\/69866501_Richard_Yi_Da_Xu","fullname":"Richard Yi Da Xu","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":6373073,"url":"researcher\/6373073_Massimo_Piccardi","fullname":"Massimo Piccardi","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":[],"abstract":"In the recent years, the desire and need to understand sequential data has\nbeen increasing, with particular interest in sequential contexts such as\npatient monitoring, understanding daily activities, video surveillance, stock\nmarket and the like. Along with the constant flow of data, it is critical to\nclassify and segment the observations on-the-fly, without being limited to a\nrigid number of classes. In addition, the model needs to be capable of updating\nits parameters to comply with possible evolutions. This interesting problem,\nhowever, is not adequately addressed in the literature since many studies focus\non offline classification over a pre-defined class set. In this paper, we\npropose a principled solution to this gap by introducing an adaptive online\nsystem based on Markov switching models with hierarchical Dirichlet process\npriors. This infinite adaptive online approach is capable of segmenting and\nclassifying the sequential data over unlimited number of classes, while meeting\nthe memory and delay constraints of streaming contexts. The model is further\nenhanced by introducing a learning rate, responsible for balancing the extent\nto which the model sustains its previous learning (parameters) or adapts to the\nnew streaming observations. Experimental results on several variants of\nstationary and evolving synthetic data and two video datasets, TUM Assistive\nKitchen and collatedWeizmann, show remarkable performance in segmentation and\nclassification, particularly for evolutionary sequences with changing\ndistributions and\/or containing new, unseen classes.","description":false,"swapJournalAndAuthorPositions":false,"showAbstract":true,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/273472293_An_Adaptive_Online_HDP-HMM_for_Segmentation_and_Classification_of_Sequential_Data","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":false,"actions":[{"type":"request-external","text":"Request full-text","url":"javascript:;","active":false,"primary":false,"extraClass":null,"icon":null,"data":[{"key":"context","value":"pubCit"}]}],"actionWidgets":[],"publicationItemFulltext":{"data":{"isDataset":false,"isResearch":false,"isFulltext":true,"source":{"isPreview":true,"sourceUrl":"deref\/http%3A%2F%2Fde.arxiv.org%2Fpdf%2F1503.02761","sourceName":"de.arxiv.org","hasSourceUrl":true},"publicationUid":273472293,"publicationUrl":"publication\/273472293_An_Adaptive_Online_HDP-HMM_for_Segmentation_and_Classification_of_Sequential_Data","eventCode":"","citationCount":0,"additionalContentWidgets":[],"disableViewer":true,"showLoggedOutRequestButton":false,"context":null,"previewUrl":"https:\/\/i1.rgstatic.net\/publication\/273472293_An_Adaptive_Online_HDP-HMM_for_Segmentation_and_Classification_of_Sequential_Data\/links\/5507a95b0cf2d7a28126033d\/smallpreview.png","linkId":"5507a95b0cf2d7a28126033d","origin":"publication_list","showRequestCount":false,"publish":false,"request":false,"showAction":false,"displayAsLink":true,"documentViewerUrl":"publicliterature.PublicLiteratureDocumentViewer.html?publicationId=273472293&reference=5507a95b0cf2d7a28126033d&eventCode=&origin=publication_list","widgetId":"rgw41_56ab19b4883a8"},"id":"rgw41_56ab19b4883a8","partials":[],"templateName":"publicliterature\/stubs\/PublicationItemFulltext.html","templateExtensions":["generalHelpers"],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItemFulltext.html?publicationUid=273472293&showAction=1&eventCode=&hideSource=0&displayAsLink=1&showPublishAsSelectFile=0","viewClass":"views.publicliterature.PublicationItemFulltextView","yuiModules":["rg.views.publicliterature.PublicationItemFulltextView"],"stylesheets":[],"_isYUI":true},"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":true,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":221344933,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/273472293_An_Adaptive_Online_HDP-HMM_for_Segmentation_and_Classification_of_Sequential_Data\/review","additionalRightSideTopWidgets":[{"data":{"citationContexts":["It is worth adding that a reported limitation of HDP-HMM is the tendency to over-segment due to its unbounded number of classes [26]. Fox et al. have proposed adding a 'sticky' prior (\u03ba) to the transition matrix to emulate an inertia towards changing states, illustrated in Figure 2 [27]. We utilise the sticky prior in this study, yet denoting it as HDP-HMM for brevity. "],"widgetId":"rgw42_56ab19b4883a8"},"id":"rgw42_56ab19b4883a8","partials":[],"templateName":"publicliterature\/stubs\/PublicationItemCitationContexts.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItemCitationContexts.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":true,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw40_56ab19b4883a8"},"id":"rgw40_56ab19b4883a8","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":true,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationItem.html?showEnrichedPublicationItem=0&showRequestButton=1&publicationUid=273472293&additionalCssClasses%5B0%5D=includes-citation-list&citationContextItemVersion=old&isIncomingCitation=1","viewClass":"views.publicliterature.PublicationItemView","yuiModules":["rg.views.publicliterature.PublicationItemView"],"stylesheets":[],"_isYUI":true}],"hasCitations":true,"isPublicationAuthor":false,"isPublicationVisitor":false,"publicationUid":221344933,"publicationLink":"publication\/221344933_An_HDP-HMM_for_systems_with_state_persistence","hasShowMore":true,"newOffset":3,"pageSize":10,"widgetId":"rgw33_56ab19b4883a8"},"id":"rgw33_56ab19b4883a8","partials":[],"templateName":"publicliterature\/stubs\/PublicationIncomingCitationsList.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationIncomingCitationsList.html?publicationUid=221344933&citedInPage=1&swapJournalAndAuthorPositions=0&showAbstract=1&showType=1&showPublicationPreview=1&totalCount=97","viewClass":"views.publicliterature.PublicationIncomingCitationsListView","yuiModules":["rg.views.publicliterature.PublicationIncomingCitationsListView"],"stylesheets":[],"_isYUI":true},"hasCitations":false,"citationsCount":0,"hasIncomingCitations":true,"incomingCitationsCount":97,"showCitationsSorter":true,"showAbstract":true,"showType":true,"showPublicationPreview":true,"swapJournalAndAuthorPositions":false,"sort":"","sortOriginal":false,"citationList":"incoming","showsIncoming":true,"showSorting":false,"usePlainButton":null,"useEnrichedContext":null,"widgetId":"rgw32_56ab19b4883a8"},"id":"rgw32_56ab19b4883a8","partials":[],"templateName":"publicliterature\/stubs\/PublicationCitations.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationCitations.html?publicationUid=221344933&citationList=&citedInPage=1&sort=","viewClass":"views.publicliterature.PublicationCitationsView","yuiModules":["rg.views.publicliterature.PublicationCitationsView"],"stylesheets":[],"_isYUI":true},"publicationReviewPromo":null,"publicationUsedInReviews":null,"publicationPdfJsReader":{"data":{"isPreview":false,"licenseUrl":null,"licenseInfo":null,"defaultLinkData":{"linkId":"53fe28a60cf283c3583bcdd5","name":"Michael Jordan","date":"Aug 27, 2014 ","nameLink":"profile\/Michael_Jordan13","filename":"","downloadLink":"https:\/\/www.researchgate.net\/profile\/Michael_Jordan13\/publication\/221344933_An_HDP-HMM_for_systems_with_state_persistence\/links\/53fe28a60cf283c3583bcdd5.pdf?inViewer=0&pdfJsDownload=0&origin=publication_detail","viewerUrl":"https:\/\/www.researchgate.net\/profile\/Michael_Jordan13\/publication\/221344933_An_HDP-HMM_for_systems_with_state_persistence\/links\/53fe28a60cf283c3583bcdd5.pdf?inViewer=1&pdfJsDownload=1&origin=publication_detail","downloadHash":"3dec20ad4d457ef71fc65a302888a2d5","showFileSizeNote":false,"fileSize":"494.63 KB","noFollow":false,"isDefault":true,"doi":null},"displayableLinks":[{"linkId":"53fe28a60cf283c3583bcdd5","name":"Michael Jordan","date":"Aug 27, 2014 ","nameLink":"profile\/Michael_Jordan13","filename":"","downloadLink":"https:\/\/www.researchgate.net\/profile\/Michael_Jordan13\/publication\/221344933_An_HDP-HMM_for_systems_with_state_persistence\/links\/53fe28a60cf283c3583bcdd5.pdf?inViewer=0&pdfJsDownload=0&origin=publication_detail","viewerUrl":"https:\/\/www.researchgate.net\/profile\/Michael_Jordan13\/publication\/221344933_An_HDP-HMM_for_systems_with_state_persistence\/links\/53fe28a60cf283c3583bcdd5.pdf?inViewer=1&pdfJsDownload=1&origin=publication_detail","downloadHash":"3dec20ad4d457ef71fc65a302888a2d5","showFileSizeNote":false,"fileSize":"494.63 KB","noFollow":false,"isDefault":true,"doi":null}],"hasDisplayableLinks":false,"reader":{"data":{"pdfCommentsActive":false,"publicationType":"Conference Paper","onlyRenderFirstPage":false,"readMoreExperimentGoal":"goalPublicationPdfClicksReadMore","readMoreExperimentViewId":null,"comments":null,"figures":[],"figureAssetIds":[],"figureOverlayUrls":{"clickOnOverlay":"publication.PublicationFigures.html?_sg=8k45Dy0W9EQOBEEzrYuuzTEv8YDzhdIkGIoWny7IbwdoxTVPXVq8lOkHyjfqkGX6Vvw1FSNcoB4m3PeeFBh7aQ.jXqovlUp5ZaKkCEaqDuzHF8fSUS3DkENGK3FvfvUHfdmkHCgARqnFSKkdTLttPJfKduBMucGCnAYtGYnqIqtaw","clickOnPill":"publication.PublicationFigures.html?_sg=ISIZ6AjvAtpWtYTeZi_0ZjvRFHGwPbStpZizuCxwcStL6qY737lUT42-pCxPCK3rJkZ8RNUiBrjBWhOXMHyDqw.JX_Xvp1VdXDm5GWLR2Ti45aq4igB82bL91CNmWcFGX_nHvR1rDH6Wl3hNABMemWlg2Jul9O5a-paO_Ny1711tw"},"canSelect":false,"javascriptPath":"https:\/\/www.researchgate.net\/c\/o1o9o3\/","downloadUrl":"https%3A%2F%2Fwww.researchgate.net%2Fprofile%2FMichael_Jordan13%2Fpublication%2F221344933_An_HDP-HMM_for_systems_with_state_persistence%2Flinks%2F53fe28a60cf283c3583bcdd5.pdf%3FinViewer%3D1%26pdfJsDownload%3D1%26origin%3Dpublication_detail","viewerUrl":"https:\/\/www.researchgate.net\/c\/o1o9o3\/javascript\/lib\/pdfjs\/web\/viewer.html","commentEndpoint":"https:\/\/www.researchgate.net\/rgformat\/api\/comment","experimentEndpoint":"https:\/\/www.researchgate.net\/rgformat\/api\/experiment?key=BzgL6UW7sDaNmUBJizsHV3tMYZDbTLNp92bHPaLNn-SHMy-MHc51tjCYBnfD9hEHHvSNV4Q_d2or_9OaWphU1g","urlHash":"3ebb3c6d4fd9e9eaced2c7cfb09705bd","downloadTrackUrl":"application.PdfJsReader.ajaxTrackDownload.html?msrp=kHT9OeaCjycsZkCV2q90v4zjSPy9lt-2CPHadM1vp_I-ewHUtXNq8uloDXkNT40ZzgERr7ORPMzpEFRkedZt7dTp8bPfNcSH37xvB-Wt_so.ZlulpVNsmWgn3LbwTh2vBRVbnOrUlz1-PCS-SF_oC_zNJqNGicMUtZ4SJQlBUEH0X3WLaJuYo705AmCbFtFe_g.ZAPPX3FbYTh03adMsEELG12Wn9XcMmbUqsl7tPaWJtu2i5vLAIvUQHOiPpwBXrtl75buLC0o8-ZUCXwrTYNgQg","viewportMilestoneTrackUrl":"application.PdfJsReader.ajaxTrackViewportMilestone.html","linkId":"53fe28a60cf283c3583bcdd5","trackedDownloads":{"53fe28a60cf283c3583bcdd5":{"v":false,"d":false}},"assetId":"AS:134863944425472@1409165478348","readerDocId":null,"assetType":"fulltext","interactionType":{"comment":"comment","highlight":"highlight"},"publicationUid":221344933,"commentCursorPromo":null,"widgetId":"rgw44_56ab19b4883a8"},"id":"rgw44_56ab19b4883a8","partials":[],"templateName":"application\/stubs\/PdfJsReader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PdfJsReader.html?fileHref=https%3A%2F%2Fwww.researchgate.net%2Fprofile%2FMichael_Jordan13%2Fpublication%2F221344933_An_HDP-HMM_for_systems_with_state_persistence%2Flinks%2F53fe28a60cf283c3583bcdd5.pdf%3FinViewer%3D1%26pdfJsDownload%3D1%26origin%3Dpublication_detail&assetId=AS%3A134863944425472%401409165478348&publicationUid=221344933&linkId=53fe28a60cf283c3583bcdd5&onlyShowFirstPage=0","viewClass":null,"yuiModules":["css-pow-application-PdfJsReader"],"stylesheets":["pow\/application\/PdfJsReader.css"],"_isYUI":true},"showHeader":true,"title":"An HDP-HMM for systems with state persistence","publicationType":"Conference Paper","downloadTrackUrl":"publicliterature.PublicationInlineReader.ajaxTrackDownload.html?msrp=FLgjE_EJsTm755gMpaFR7Ia3kvNy2OnZo1CUw8DQTgOvlhueHazAxufm7sq5qa7G5hVd-B1JHjEg3pF8g5Swf6F0dHtZ9HLbHj89E1HRRsw.GijlLJlMVnZOVOgATXIcsrHDt2M1_Qf5TtsV7XVjipN_j80ybY2SoLJq56klWdwXPTU7yF1PP7N9IWed3nwvuQ.4IJJLW2PClqcAKhjQ8DKN0vr4fvBiipQY_L1GR68uj1ka2fyqsjWdwLN-udQv2ufhivLWZ2IkjSQrlzr0KyMSA","publicationUid":221344933,"trackedDownloads":{"53fe28a60cf283c3583bcdd5":{"v":false,"d":false}},"inlinePdf":false,"publicationComments":null,"showDownloadButton":true,"socialShare":{"data":{"shareItems":[{"data":{"name":"Facebook","url":"http:\/\/www.facebook.com\/share.php?u={{url}}{{#title}}&t={{title}}{{\/title}}","width":600,"height":350,"useUtmTags":true,"utmSource":"facebook","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareFacebook.ajaxTrackSocialShare.html","widgetId":"rgw46_56ab19b4883a8"},"id":"rgw46_56ab19b4883a8","partials":{"shareIcon":"application\/stubs\/partials\/shareFacebookBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareFacebook.html?provider=Facebook&shareIcon=shareIconBlog&utmSource=facebook&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"Twitter","url":"http:\/\/twitter.com\/intent\/tweet?text={{#title}}{{title}}: {{\/title}}{{url}}&via=researchgate","width":600,"height":350,"useUtmTags":true,"utmSource":"twitter","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareTwitter.ajaxTrackSocialShare.html","widgetId":"rgw47_56ab19b4883a8"},"id":"rgw47_56ab19b4883a8","partials":{"shareIcon":"application\/stubs\/partials\/shareTwitterBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareTwitter.html?provider=Twitter&shareIcon=shareIconBlog&utmSource=twitter&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"Google+","url":"https:\/\/plus.google.com\/share?url={{url}}","width":600,"height":600,"useUtmTags":true,"utmSource":"googleplus","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareGooglePlus.ajaxTrackSocialShare.html","widgetId":"rgw48_56ab19b4883a8"},"id":"rgw48_56ab19b4883a8","partials":{"shareIcon":"application\/stubs\/partials\/shareGooglePlusBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareGooglePlus.html?provider=Google%2B&shareIcon=shareIconBlog&utmSource=googleplus&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"LinkedIn","url":"http:\/\/www.linkedin.com\/shareArticle?mini=true&url={{url}}{{#title}}&title={{title}}{{\/title}}&source=ResearchGate","width":520,"height":570,"useUtmTags":true,"utmSource":"linkedin","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareLinkedIn.ajaxTrackSocialShare.html","widgetId":"rgw49_56ab19b4883a8"},"id":"rgw49_56ab19b4883a8","partials":{"shareIcon":"application\/stubs\/partials\/shareLinkedInBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareLinkedIn.html?provider=LinkedIn&shareIcon=shareIconBlog&utmSource=linkedin&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true},{"data":{"name":"Reddit","url":"https:\/\/www.reddit.com\/submit?url={{url}}{{#title}}&title={{title}}{{\/title}}","width":600,"height":600,"useUtmTags":true,"utmSource":"reddit","utmMedium":"rgShare","utmCampaign":"shareFullTextPublication","cssClass":"","trackClick":true,"trackUrl":"https:\/\/www.researchgate.net\/application.ShareReddit.ajaxTrackSocialShare.html","widgetId":"rgw50_56ab19b4883a8"},"id":"rgw50_56ab19b4883a8","partials":{"shareIcon":"application\/stubs\/partials\/shareRedditBlogIcon.html"},"templateName":"application\/stubs\/BaseShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.ShareReddit.html?provider=Reddit&shareIcon=shareIconBlog&utmSource=reddit&utmMedium=rgShare&utmCampaign=shareFullTextPublication&trackClick=1","viewClass":"views.application.BaseShareView","yuiModules":["rg.views.application.BaseShareView"],"stylesheets":[],"_isYUI":true}],"widgetId":"rgw45_56ab19b4883a8"},"id":"rgw45_56ab19b4883a8","partials":[],"templateName":"application\/stubs\/SocialShare.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.SocialShare.html?campaign=shareFullTextPublication&trackClick=1&shareIcon=shareIconBlog","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw43_56ab19b4883a8"},"id":"rgw43_56ab19b4883a8","partials":[],"templateName":"publicliterature\/stubs\/PublicationInlineReader.html","templateExtensions":["generalHelpers"],"attrs":{"showFulltextDownloadedSignupDialog":true,"preSignUpDialogContext":null,"requestFulltext":false},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationInlineReader.html","viewClass":"views.publicliterature.PublicationInlineReaderView","yuiModules":["rg.views.publicliterature.PublicationInlineReaderView","css-pow-publicliterature-PublicationInlineReader"],"stylesheets":["pow\/publicliterature\/PublicationInlineReader.css"],"_isYUI":true},"useFulltextOptimizedLayout":false,"publicationActions":null,"requestFulltextPromo":null,"currentUrl":"publication\/221344933_An_HDP-HMM_for_systems_with_state_persistence","isLeaderboardAd":false,"enableStickyBox":null,"googleDfpSlotMobileBottom":null,"fullTextExitPopup":null,"showExitPopupDialog":false,"widgetId":"rgw2_56ab19b4883a8"},"id":"rgw2_56ab19b4883a8","partials":{"romeo_legal_notice":"publicliterature\/stubs\/partials\/romeo_legal_notice.html"},"templateName":"publicliterature\/stubs\/PublicPublicationDetails_NewLayout.html","templateExtensions":["generalHelpers"],"attrs":{"publicationUid":221344933},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicPublicationDetailsOld.html?publicationUid=221344933&isTestOldDesign=0","viewClass":"views.publicliterature.PublicPublicationDetailsOldView","yuiModules":["rg.views.publicliterature.PublicPublicationDetailsOldView"],"stylesheets":[],"_isYUI":true},"widgetId":"rgw1_56ab19b4883a8"},"id":"rgw1_56ab19b4883a8","partials":[],"templateName":"publicliterature\/stubs\/PublicPublicationDetails.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicPublicationDetails.html","viewClass":"views.publicliterature.PublicPublicationDetailsView","yuiModules":["rg.views.publicliterature.PublicPublicationDetailsView"],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"uaClass":"","headPrefix":[],"rootUrl":"https:\/\/www.researchgate.net\/","requestToken":"bH7P6hnMG7lavlgiSXl5+8c476zRlAYrQJmR13GzIICdys7MRKri3rrZiZZFQ1dbrBZzzzCpMlGy+LfaY8kN4yUDgZ2QEPvI5ReK0feJSQrBgv\/Eg15nAfOVWcolxHxdKppa6JNKEeprdXu63M9jep7fRQCzsPKfB6LdAFj2fIbTeRHwHbT2A5Q+\/lal4Gj2N2kzVxxY0qARl4BlkfdJ9mjiximyTRD50d1rkEuHpG4sNTEzsPvx+d\/LwguZIMPK0rRnyw8TcUIoKyk7QMA89JSYTDi8zEDTMEs68KH5jC8=","faviconCdnUrl":"https:\/\/c5.rgstatic.net\/m\/2390829798215018\/images\/favicon.ico","headerOutput":"<noscript><\/noscript><link rel=\"canonical\" href=\"https:\/\/www.researchgate.net\/publication\/221344933_An_HDP-HMM_for_systems_with_state_persistence\" \/>\n<link rel=\"dns-prefetch\" href=\"\/\/c5.rgstatic.net\" \/>\n<link rel=\"dns-prefetch\" href=\"\/\/i1.rgstatic.net\" \/>\n<meta property=\"twitter:card\" content=\"summary\" \/>\n<meta property=\"twitter:site\" content=\"@ResearchGate\" \/>\n<meta property=\"og:title\" content=\"An HDP-HMM for systems with state persistence\" \/>\n<meta property=\"og:description\" content=\"The hierarchical Dirichlet process hidden Markov model (HDP-HMM) is a flexible, nonparametric model which allows state spaces of unknown size to be learned from data. We demonstrate some...\" \/>\n<meta property=\"og:site_name\" content=\"ResearchGate\" \/>\n<meta property=\"og:image\" content=\"https:\/\/i1.rgstatic.net\/publication\/221344933_An_HDP-HMM_for_systems_with_state_persistence\/links\/53fe28a60cf283c3583bcdd5\/smallpreview.png\" \/>\n<meta property=\"og:url\" content=\"https:\/\/www.researchgate.net\/publication\/221344933_An_HDP-HMM_for_systems_with_state_persistence\" \/>\n<meta property=\"rg:id\" content=\"PB:221344933\" \/>\n<meta name=\"DC.identifier\" scheme=\"DCTERMS.URI\" content=\"http:\/\/dx.doi.org\/10.1145\/1390156.1390196\" \/>\n<meta name=\"gs_meta_revision\" content=\"1.1\" \/>\n<meta name=\"citation_title\" content=\"An HDP-HMM for systems with state persistence\" \/>\n<meta name=\"citation_author\" content=\"Emily B. Fox\" \/>\n<meta name=\"citation_author\" content=\"Erik B. Sudderth\" \/>\n<meta name=\"citation_author\" content=\"Michael I. Jordan\" \/>\n<meta name=\"citation_author\" content=\"Alan S. Willsky\" \/>\n<meta name=\"citation_conference_title\" content=\"Machine Learning, Proceedings of the Twenty-Fifth International Conference (ICML 2008), Helsinki, Finland, June 5-9, 2008\" \/>\n<meta name=\"citation_publication_date\" content=\"2008\/01\/01\" \/>\n<meta name=\"citation_firstpage\" content=\"312\" \/>\n<meta name=\"citation_lastpage\" content=\"319\" \/>\n<meta name=\"citation_doi\" content=\"10.1145\/1390156.1390196\" \/>\n<meta name=\"citation_pdf_url\" content=\"https:\/\/www.researchgate.net\/profile\/Michael_Jordan13\/publication\/221344933_An_HDP-HMM_for_systems_with_state_persistence\/links\/53fe28a60cf283c3583bcdd5.pdf\" \/>\n<meta name=\"citation_abstract_html_url\" content=\"https:\/\/www.researchgate.net\/publication\/221344933_An_HDP-HMM_for_systems_with_state_persistence\" \/>\n<meta name=\"citation_fulltext_html_url\" content=\"https:\/\/www.researchgate.net\/publication\/221344933_An_HDP-HMM_for_systems_with_state_persistence\" \/>\n<meta name=\"viewport\" content=\"width=device-width,initial-scale=1\" \/>\n<link href=\"\/\/c5.rgstatic.net\/m\/22664197317151888\/styles\/rg.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/21004998181197492\/styles\/rg2.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<!--[if lt IE 9]><link href=\"\/\/c5.rgstatic.net\/m\/238176252723686\/styles\/ie.css\" type=\"text\/css\" rel=\"stylesheet\"\/><![endif]-->\n<link href=\"\/\/c5.rgstatic.net\/m\/217752362214895\/styles\/modules\/publicprofile.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/21993347442549\/styles\/pow\/publicliterature\/FollowPublicationPromo.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/282514599719602\/styles\/pow\/application\/PdfJsReader.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/23819663151220\/styles\/pow\/publicliterature\/PublicationInlineReader.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<script src=\"\/\/c5.rgstatic.net\/m\/2321000301012716\/javascript\/vendor\/webfontloader\/webfontloader.js\" type=\"text\/javascript\"><\/script>\n <script>(function(i,s,o,g,r,a,m){i[\"GoogleAnalyticsObject\"]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,\"script\",\"\/\/www.google-analytics.com\/analytics.js\",\"ga\");\n ga(\"create\",\"UA-58591210-1\");ga(\"set\",\"anonymizeIp\",true);ga('set', 'dimension1', 'publication full-text');ga('set', 'dimension2', 'Conference Paper');ga('set', 'dimension3', 'Logged out');ga('set', 'dimension4', 'https');ga(\"send\",\"pageview\");<\/script>\n","webfont":"<noscript><\/noscript><script> WebFontConfig = { custom: { families: ['source_sans_pro_italic', 'source_sans_pro_bold', 'source_sans_pro', 'martel'], urls : ['\/\/c5.rgstatic.net\/m\/231392577336386\/styles\/fonts.css'] } }; WebFont.load(WebFontConfig); <\/script>\n","correlationId":"rgreq-d6cd385c-0a39-49ac-af9d-da4ceb76aa42","accountId":null,"module":"publicliterature","action":"publicliterature.PublicPublicationDetails","page":"publicationDetail","product":"publications","backendTime":495,"continent":"Asia","stylesHome":"\/\/c5.rgstatic.net\/m\/","staticHost":"c5.rgstatic.net","useEarlyFlush":false,"longRunningRequestIdentifier":"LongRunningRequest.publicliterature.PublicPublicationDetails","longRunningRequestFp":"e9e5bbe1366c7ee8c8e41d02f793c884ac9be19b","widgetId":"rgw51_56ab19b4883a8"},"id":"rgw51_56ab19b4883a8","partials":[],"templateName":"application\/stubs\/StaticHeader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.StaticHeader.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){
            Y.rg.core.pagespeed.Monitoring.monitorPage("\/\/glassmoni.researchgate.net", "publicliterature.PublicPublicationDetails.run.html.loggedOut.get", "59de9668d07aeb77ab4de5f24d382b5d199d2437", "rgreq-d6cd385c-0a39-49ac-af9d-da4ceb76aa42", "302d2e0b76ebe85887aad3ee5f2df9aa6118e47e");
        
            Y.rg.core.pagespeed.Monitoring.monitorPage("\/\/glassmoni.researchgate.net", "publicationDetail.loggedOut", "ed1993d9e20f6cefa83edacaa24401a18c071aea", "rgreq-d6cd385c-0a39-49ac-af9d-da4ceb76aa42", "302d2e0b76ebe85887aad3ee5f2df9aa6118e47e");
        })();
(function(){Y.rg.createInitialWidget({"data":{"year":"2016","inlinePromo":null,"isAdmin":false,"contactUrl":"https:\/\/www.researchgate.net\/contact","aboutUsUrl":"https:\/\/www.researchgate.net\/about","widgetId":"rgw52_56ab19b4883a8"},"id":"rgw52_56ab19b4883a8","partials":[],"templateName":"application\/stubs\/DefaultFooter.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.DefaultFooter.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"headerLogin":{"data":{"urlAfterLogin":"publication\/221344933_An_HDP-HMM_for_systems_with_state_persistence","requestToken":"ToAJG4+bm7+wgvKUx5fVb3WL9PqPLMKefvAJeMTH3TOmxwHZaf2glhS73sBCohd3lvY64+mwvbZtc\/39HxP06WYaBSjQkfKLtpeN0wArPYvxzgLnf3oufPhUf0C72\/lxl7EzlLUznqfxzUyIDjFtm63SxB1Zkm2j1Qxo+GU1hmEO9zw0oKYOn3COOKzworNEeref+Rpc+xVIXHTjAvRocgI5XNt13HQTIBa90pIFAcJVAlBKXquasftdj1HCAe8VqmbEvYVXh7yqpHww2VyN\/FzmsLegNWHa8+WJdNAqgDw=","loginUrl":"https:\/\/www.researchgate.net\/application.Login.html","signupUrl":"https:\/\/www.researchgate.net\/signup.SignUp.html?ev=su_chnl_index&hdrsu=1&_sg=cDkNAcKADMfw3wRSYBNI55u64OhbMwee99M8JtLStkVcopyLr7cegHY0mbHtEID6","encodedUrlAfterLogin":"cHVibGljYXRpb24vMjIxMzQ0OTMzX0FuX0hEUC1ITU1fZm9yX3N5c3RlbXNfd2l0aF9zdGF0ZV9wZXJzaXN0ZW5jZQ%3D%3D","signupCallToAction":"Join for free","widgetId":"rgw54_56ab19b4883a8"},"id":"rgw54_56ab19b4883a8","partials":{"partial":"application\/stubs\/partials\/headerLoginDefault.html"},"templateName":"application\/stubs\/HeaderLogin.html","templateExtensions":[],"attrs":{"goal":"milestoneHeaderLoginSeen"},"widgetUrl":"https:\/\/www.researchgate.net\/application.HeaderLogin.html","viewClass":"views.application.HeaderLoginView","yuiModules":["rg.views.application.HeaderLoginView"],"stylesheets":[],"_isYUI":true},"cookieConsent":null,"logoSvgSrc":"https:\/\/c5.rgstatic.net\/m\/235107188705592\/images\/template\/brand-header-logo.svg","logoFallbackSrc":"https:\/\/c5.rgstatic.net\/m\/238113351022438\/images\/template\/brand-header-logo.png","widgetId":"rgw53_56ab19b4883a8"},"id":"rgw53_56ab19b4883a8","partials":{"schemaSocialProfiles":"application\/stubs\/partials\/schemaSocialProfiles.html"},"templateName":"application\/stubs\/HeaderLoggedOut.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.HeaderLoggedOut.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"logEvent":"su_banner","specialCopy":false,"widgetId":"rgw55_56ab19b4883a8"},"id":"rgw55_56ab19b4883a8","partials":[],"templateName":"application\/stubs\/LoggedOutBanner.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.LoggedOutBanner.html","viewClass":"views.application.LoggedOutBannerView","yuiModules":["rg.views.application.LoggedOutBannerView"],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.core.util.ParameterFilter.filter(["ev","cp","ch","ref","dbw","pli","loginT","uid","claimChannel","enrichId","enrichSource","utm_source","utm_medium","utm_campaign","el","ci"]);})();
});}); } else { throw 'YRG was not loaded when attaching widgets'; }</script><script> dataLayer = [{"pageCategory":"publication full-text","publicationType":"Conference Paper","eventCategory":"Publication page"}]; </script> <noscript><iframe src="//www.googletagmanager.com/ns.html?id=GTM-MKVKH7" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-MKVKH7');</script><script>(function(e){function n(n,t,o,a){"use strict";var i=e.document.createElement("link"),r=t||e.document.getElementsByTagName("script")[0],d=e.document.styleSheets;return i.rel="stylesheet",i.href=n,i.media="only x",a&&(i.onload=a),r.parentNode.insertBefore(i,r),i.onloadcssdefined=function(e){for(var t,o=0;d.length>o;o++)d[o].href&&d[o].href.indexOf(n)>-1&&(t=!0);t?e():setTimeout(function(){i.onloadcssdefined(e)})},i.onloadcssdefined(function(){i.media=o||"all"}),i}function t(e,n){e.onload=function(){e.onload=null,n&&n.call(e)},"isApplicationInstalled"in navigator&&"onloadcssdefined"in e&&e.onloadcssdefined(n)}var o=function(a,i){"use strict";if(a&&3===a.length){var r=e.Image,d=!(!document.createElementNS||!document.createElementNS("http://www.w3.org/2000/svg","svg").createSVGRect||!document.implementation.hasFeature("http://www.w3.org/TR/SVG11/feature#Image","1.1")||e.opera&&-1===navigator.userAgent.indexOf("Chrome")||-1!==navigator.userAgent.indexOf("Series40")),c=new r;c.onerror=function(){o.method="png",o.href=a[2],n(a[2])},c.onload=function(){var e=1===c.width&&1===c.height,r=a[e&&d?0:e?1:2];o.method=e&&d?"svg":e?"datapng":"png",o.href=r,t(n(r),i)},c.src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///ywAAAAAAQABAAACAUwAOw==",document.documentElement.className+=" grunticon"}};o.loadCSS=n,o.onloadCSS=t,e.grunticon=o})(this);grunticon(["https://c5.rgstatic.net/c/o1o9o3/styles/icons/_header-ico.svg.css", "https://c5.rgstatic.net/c/o1o9o3/styles/icons/_header-ico.png.css", "https://c5.rgstatic.net/c/o1o9o3/styles/icons/_header-ico.fallback.scss"]);grunticon(["https://c5.rgstatic.net/c/o1o9o3/styles/icons/_admin-ico.svg.css", "https://c5.rgstatic.net/c/o1o9o3/styles/icons/_admin-ico.png.css", "https://c5.rgstatic.net/c/o1o9o3/styles/icons/_admin-ico.fallback.scss"]);grunticon(["https://c5.rgstatic.net/c/o1o9o3/styles/icons/_ico.svg.css", "https://c5.rgstatic.net/c/o1o9o3/styles/icons/_ico.png.css", "https://c5.rgstatic.net/c/o1o9o3/styles/icons/_ico.fallback.scss"]);</script></body>
</html>
