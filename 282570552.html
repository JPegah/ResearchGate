<!DOCTYPE html> <html lang="en" class="" id="rgw31_56ab9d61e091d"> <head > <meta charset="utf-8"/> <meta http-equiv="content-type" content="text/html; charset=UTF-8"/> <meta name="Rg-Request-Token" id="Rg-Request-Token" content="FDaeDgwwuzLTK04T3FaxXhmCLPcViawTbupqWYY8hAXMg7gYL57tt4zcq4wVJkl5gpGjqeWT7+g+hxJJD72n5aDhWhIRSuDEPXmiIsguC5sKQp4O9/hOPJWFV4gX4KpLZq2ozp+wTrfZFSsFdnx/vxL2/BJ19JU/taSOxE2WgIRsAkrJhXiqRY78faA/vkiZTRe/0bcUg6LyNvbkjifL05vCQA6kE/vCBG8NhEtmd8AFcj+61DSpzly3xTaG3qof/O2Gosrw3iHw6AYvUlndkx3KVoxs6suAVdZ9i60AzbM="/> <meta http-equiv="expires" content="0"/> <link rel="apple-touch-icon" sizes="57x57" href="https://www.researchgate.net/apple-touch-icon-57x57.png"> <link rel="apple-touch-icon" sizes="60x60" href="https://www.researchgate.net/apple-touch-icon-60x60.png"> <link rel="apple-touch-icon" sizes="72x72" href="https://www.researchgate.net/apple-touch-icon-72x72.png"> <link rel="apple-touch-icon" sizes="76x76" href="https://www.researchgate.net/apple-touch-icon-76x76.png"> <link rel="apple-touch-icon" sizes="114x114" href="https://www.researchgate.net/apple-touch-icon-114x114.png"> <link rel="apple-touch-icon" sizes="120x120" href="https://www.researchgate.net/apple-touch-icon-120x120.png"> <link rel="apple-touch-icon" sizes="144x144" href="https://www.researchgate.net/apple-touch-icon-144x144.png"> <link rel="apple-touch-icon" sizes="152x152" href="https://www.researchgate.net/apple-touch-icon-152x152.png"> <link rel="apple-touch-icon" sizes="180x180" href="https://www.researchgate.net/apple-touch-icon-180x180.png"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-32x32.png" sizes="32x32"> <link rel="icon" type="image/png" href="https://www.researchgate.net/android-chrome-192x192.png" sizes="192x192"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-96x96.png" sizes="96x96"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-16x16.png" sizes="16x16"> <link rel="shortcut icon" type="image/x-icon" href="https://c5.rgstatic.net/m/2390829798215018/images/favicon.ico"/> <link rel="manifest" href="https://www.researchgate.net/manifest.json"> <meta name="msapplication-TileColor" content="#da532c"> <meta name="msapplication-TileImage" content="https://www.researchgate.net/mstile-144x144.png"> <meta name="theme-color" content="#444444"> <link rel="search" type="application/opensearchdescription+xml" title="ResearchGate search" href="https://www.researchgate.net/application.DownloadOpenSearchPlugin.html"/> <link rel="meta" type="application/rdf+xml" title="ICRA labels" href="https://www.researchgate.net/application.DownloadLabels.html"/> <link rel="http://oexchange.org/spec/0.8/rel/related-target" type="application/xrd+xml" href="https://www.researchgate.net/application.DownloadOExchange.html"/> <base href="https://www.researchgate.net/"/> <script>
    var rgConfig = {
        correlationId: "rgreq-a6ca9f68-5341-4338-aea2-09e76e7365d0",
        accountId: "",
        module: "publicliterature",
        action: "publicliterature.PublicPublicationDetails",
        page: "publicationDetail",
        product: "publications",
        continent: "Asia",
        stylesHome: "//c5.rgstatic.net/m/",
        staticHost: "c5.rgstatic.net",
        longRunningRequestIdentifier: "LongRunningRequest.publicliterature.PublicPublicationDetails",
        longRunningRequestFp: "e9e5bbe1366c7ee8c8e41d02f793c884ac9be19b"
    };
    window.rootUrl = "https://www.researchgate.net/";
</script> <link rel="canonical" href="https://www.researchgate.net/publication/282570552_A_Bayesian_approach_to_constrained_single-_and_multi-objective_optimization" />
<link rel="dns-prefetch" href="//c5.rgstatic.net" />
<link rel="dns-prefetch" href="//i1.rgstatic.net" />
<meta property="twitter:card" content="summary" />
<meta property="twitter:site" content="@ResearchGate" />
<meta property="og:title" content="A Bayesian approach to constrained single- and multi-objective optimization" />
<meta property="og:description" content="This article addresses the problem of derivative-free (single- or multi-objective) optimization subject to multiple inequality constraints. Both the objective and constraint functions are assumed..." />
<meta property="og:site_name" content="ResearchGate" />
<meta property="og:image" content="https://i1.rgstatic.net/publication/282570552_A_Bayesian_approach_to_constrained_single-_and_multi-objective_optimization/links/569e3d4308ae16fdf07c454f/smallpreview.png" />
<meta property="og:url" content="https://www.researchgate.net/publication/282570552_A_Bayesian_approach_to_constrained_single-_and_multi-objective_optimization" />
<meta property="rg:id" content="PB:282570552" />
<meta name="DC.identifier" scheme="DCTERMS.URI" content="http://dx.doi.org/" />
<meta name="gs_meta_revision" content="1.1" />
<meta name="citation_title" content="A Bayesian approach to constrained single- and multi-objective optimization" />
<meta name="citation_author" content="Paul Féliot" />
<meta name="citation_author" content="Julien Bect" />
<meta name="citation_author" content="Emmanuel Vazquez" />
<meta name="citation_publication_date" content="2015/09/23" />
<meta name="citation_abstract_html_url" content="https://www.researchgate.net/publication/282570552_A_Bayesian_approach_to_constrained_single-_and_multi-objective_optimization" />
<meta name="citation_fulltext_html_url" content="https://www.researchgate.net/publication/282570552_A_Bayesian_approach_to_constrained_single-_and_multi-objective_optimization" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<link href="//c5.rgstatic.net/m/22664197317151888/styles/rg.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/21004998181197492/styles/rg2.css" type="text/css" rel="stylesheet"/>
<!--[if lt IE 9]><link href="//c5.rgstatic.net/m/238176252723686/styles/ie.css" type="text/css" rel="stylesheet"/><![endif]-->
<link href="//c5.rgstatic.net/m/217752362214895/styles/modules/publicprofile.css" type="text/css" rel="stylesheet"/>
<script src="//c5.rgstatic.net/m/2321000301012716/javascript/vendor/webfontloader/webfontloader.js" type="text/javascript"></script>
 <script>(function(i,s,o,g,r,a,m){i["GoogleAnalyticsObject"]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,"script","//www.google-analytics.com/analytics.js","ga");
 ga("create","UA-58591210-1");ga("set","anonymizeIp",true);ga('set', 'dimension1', 'publication slurped');ga('set', 'dimension2', 'Article');ga('set', 'dimension3', 'Logged out');ga('set', 'dimension4', 'https');ga("send","pageview");</script>
  <script> WebFontConfig = { custom: { families: ['source_sans_pro_italic', 'source_sans_pro_bold', 'source_sans_pro', 'martel'], urls : ['//c5.rgstatic.net/m/231392577336386/styles/fonts.css'] } }; WebFont.load(WebFontConfig); </script><noscript></noscript>

<title>A Bayesian approach to constrained single- and multi-objective optimization</title>
<meta name="description" content="A Bayesian approach to constrained single- and multi-objective optimization on ResearchGate, the professional network for scientists."/>
<meta name="keywords" content="scientific network, scientific platform, scientific community, research partner, research collaboration, journal articles, international collaboration, find researcher, lifescience researcher, interdisciplinary research, research collaboration"/>
</head>
<body class="use-svg-icons logged-out">
<div id="page-container">
<script type="text/javascript">var googletag = googletag || {}; googletag.cmd = googletag.cmd || [];
(function() { var gads = document.createElement("script"); gads.async = true; gads.type = "text/javascript"; var useSSL = "https:" == document.location.protocol; gads.src = (useSSL ? "https:" : "http:") + "//www.googletagservices.com/tag/js/gpt.js"; var node =document.getElementsByTagName("script")[0]; node.parentNode.insertBefore(gads, node); })();</script><div id="main" class="logged-out-header-support">
<div id="content" class="">

<noscript>
<div class="c-box-warning full-width-element" style="text-align: center; ">
    <div style="margin: auto; padding:10px;" class="container">
        <b>For full functionality of ResearchGate it is necessary to enable JavaScript.
            Here are the <a href="http://www.enable-javascript.com/" rel="nofollow" target="_blank">
                instructions how to enable JavaScript in your web browser</a>.</b>
    </div>
</div>
</noscript>

<div id="rgw1_56ab9d61e091d" itemscope itemtype="http://schema.org/ScholarlyArticle"><div class="publication-wrapper publication-wrapper-onecol" id="rgw2_56ab9d61e091d" itemscope itemtype="http://schema.org/ScholarlyArticle"> <div class="c-col-content"> <div class="c-content"> <div class="clearfix">  <div class="publication-header"> <div id="rgw6_56ab9d61e091d">  <div class="type-label"> Article   </div> <span class="Z3988" title="ctx_ver=Z39.88-2004&rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&rfr_id=info%3Asid%2Fresearchgate.net%3Aresearchgate&rft.atitle=A%20Bayesian%20approach%20to%20constrained%20single-%20and%20multi-objective%20optimization&rft.date=2015&rft.au=Paul%20F%C3%A9liot%2CJulien%20Bect%2CEmmanuel%20Vazquez&rft.genre=article"></span> <h1 class="pub-title" itemprop="name">A Bayesian approach to constrained single- and multi-objective optimization</h1> <meta itemprop="headline" content="A Bayesian approach to constrained single- and multi-objective optimization">  <meta itemprop="image" content="https://i1.rgstatic.net/publication/282570552_A_Bayesian_approach_to_constrained_single-_and_multi-objective_optimization/links/569e3d4308ae16fdf07c454f/smallpreview.png">  <div id="rgw8_56ab9d61e091d" class="publication-detail-author-list"> <div> <ul class="clearfix js-people-list">  <li id="rgw9_56ab9d61e091d"> <a href="researcher/2077554322_Paul_Feliot" class="pub-detail-item author-item" itemprop="author" itemscope itemtype="http://schema.org/Person"> <div class="indent-left"> <div class="people-img">  <img src="https://c5.rgstatic.net/m/2951093203564/images/template/default/profile/profile_default_s.jpg" title="Paul Féliot" alt="Paul Féliot" height="20px" width="20px" style="height: 20px;"/>  </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Paul Féliot</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item   not-claimed " id="rgw10_56ab9d61e091d">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="researcher/2077554322_Paul_Feliot"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="Paul Féliot" alt="Paul Féliot" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">       </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="researcher/2077554322_Paul_Feliot" class="display-name">Paul Féliot</a>    </h5> <div class="truncate-single-line meta">   </div>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>  <li id="rgw11_56ab9d61e091d"> <a href="researcher/14088780_Julien_Bect" class="pub-detail-item author-item" itemprop="author" itemscope itemtype="http://schema.org/Person"> <div class="indent-left"> <div class="people-img">  <img src="https://c5.rgstatic.net/m/2951093203564/images/template/default/profile/profile_default_s.jpg" title="Julien Bect" alt="Julien Bect" height="20px" width="20px" style="height: 20px;"/>  </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Julien Bect</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item   not-claimed " id="rgw12_56ab9d61e091d">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="researcher/14088780_Julien_Bect"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="Julien Bect" alt="Julien Bect" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">       </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="researcher/14088780_Julien_Bect" class="display-name">Julien Bect</a>    </h5> <div class="truncate-single-line meta">   </div>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>  <li id="rgw13_56ab9d61e091d"> <a href="researcher/26760014_Emmanuel_Vazquez" class="pub-detail-item author-item" itemprop="author" itemscope itemtype="http://schema.org/Person"> <div class="indent-left"> <div class="people-img">  <img src="https://c5.rgstatic.net/m/2951093203564/images/template/default/profile/profile_default_s.jpg" title="Emmanuel Vazquez" alt="Emmanuel Vazquez" height="20px" width="20px" style="height: 20px;"/>  </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Emmanuel Vazquez</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item   not-claimed " id="rgw14_56ab9d61e091d">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="researcher/26760014_Emmanuel_Vazquez"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="Emmanuel Vazquez" alt="Emmanuel Vazquez" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">       </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="researcher/26760014_Emmanuel_Vazquez" class="display-name">Emmanuel Vazquez</a>    </h5> <div class="truncate-single-line meta">   </div>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>   </ul> <div class="js-loading"></div>  </div> </div> <div class="pub-details js-pub-details">        <meta itemprop="datePublished" content="2015-09">  09/2015;               </div> <div id="rgw15_56ab9d61e091d" class="pub-abstract">  <div class="clearfix">   <div style="max-height: 54px;" class="js-expander-container js-expander-collapsed">  <p itemprop="description"> <strong>ABSTRACT</strong> <div>This article addresses the problem of derivative-free (single- or multi-objective) optimization subject to multiple inequality constraints. Both the objective and constraint functions are assumed to be smooth, non-linear and expensive to evaluate. As a consequence, the number of evaluations that can be used to carry out the optimization is very limited, as in complex industrial design optimization problems. The method we propose to overcome this difficulty has its roots in the Bayesian and the multiobjective optimization literatures. More specifically, an extended domination rule is used to handle the constraints and a corresponding Bayesian expected hyper-volume improvement sampling criterion is proposed. This new criterion extends existing Bayesian sampling criteria to the multi-objective constrained case, and makes it possible to start the algorithm without an initial feasible point. The calculation and optimization of the criterion are performed using Sequential Monte Carlo techniques. In particular, an algorithm similar to the subset simulation method, which is well known in the field of structural reliability, is used to estimate the expected hyper-volume improvement criterion. The method, which we call BMOO (for Bayesian Multi-Objective Optimization), is compared to state-of-the-art algorithms for single-objective and multi-objective constrained optimization problems.</div> </p>  </div>  </div>   </div>      <div class="action-container">   <div class="clear"></div> <div class="share-dialog-container" style="display: none;">  </div> </div> </div> <div style="margin-left: -20px; margin-right: -20px;">  </div> </div>  <div class="publication-detail-dfp-container rf"> <div id="rgw28_56ab9d61e091d">  </div> </div>  </div>  <div class="clearfix">  <noscript> <div id="rgw27_56ab9d61e091d"  itemprop="articleBody">  <p>Page 1</p> <p>A Bayesian approach to constrained single- and<br />multi-objective optimization<br />Paul F´ eliot, Julien Bect, Emmanuel Vazquez<br />To cite this version:<br />Paul F´ eliot, Julien Bect, Emmanuel Vazquez. A Bayesian approach to constrained single- and<br />multi-objective optimization. 2016. &lt;hal-01207679v2&gt;<br />HAL Id: hal-01207679<br />https://hal.archives-ouvertes.fr/hal-01207679v2<br />Submitted on 5 Jan 2016<br />HAL is a multi-disciplinary open access<br />archive for the deposit and dissemination of sci-<br />entific research documents, whether they are pub-<br />lished or not.The documents may come from<br />teaching and research institutions in France or<br />abroad, or from public or private research centers.<br />L’archive ouverte pluridisciplinaire HAL, est<br />destin´ ee au d´ epˆ ot et ` a la diffusion de documents<br />scientifiques de niveau recherche, publi´ es ou non,<br />´ emanant des ´ etablissements d’enseignement et de<br />recherche fran¸ cais ou ´ etrangers, des laboratoires<br />publics ou priv´ es.<br />Copyright</p>  <p>Page 2</p> <p>A Bayesian approach to constrained single- and multi-objective optimization<br />Paul FELIOT · Julien BECT · Emmanuel VAZQUEZ<br />Abstract This article addresses the problem of derivative-free (single- or multi-objective) optimization<br />subject to multiple inequality constraints. Both the objective and constraint functions are assumed to<br />be smooth, non-linear and expensive to evaluate. As a consequence, the number of evaluations that<br />can be used to carry out the optimization is very limited, as in complex industrial design optimization<br />problems. The method we propose to overcome this difficulty has its roots in both the Bayesian and<br />the multi-objective optimization literatures. More specifically, we construct a loss function based on an<br />extended domination rule to handle the objectives and the constraints simultaneously. Then, we derive<br />a corresponding (Bayesian) expected hyper-volume improvement sampling criterion. This new sampling<br />criterion makes it possible to build an optimization algorithm that can start without any feasible point.<br />The new sampling criterion reduces to existing Bayesian sampling criteria—the classical Expected Im-<br />provement (EI) criterion and some of its constrained/multi-objective extensions—as soon as at least one<br />feasible point is available. The calculation and optimization of the criterion are performed using Sequen-<br />tial Monte Carlo techniques. In particular, an algorithm similar to the subset simulation method, which<br />is well known in the field of structural reliability, is used to estimate the expected hyper-volume im-<br />provement criterion. The method, which we call BMOO (for Bayesian Multi-Objective Optimization), is<br />compared to state-of-the-art algorithms for single-objective and multi-objective constrained optimization<br />problems.<br />Keywords Bayesian optimization · Expected improvement · Kriging · Gaussian process · Multi-<br />Objective · Sequential Monte Carlo · Subset simulation<br />1 Introduction<br />This article addresses the problem of derivative-free multi-objective optimization of real-valued functions<br />subject to multiple inequality constraints. The problem consists in finding an approximation of the set<br />Γ = {x ∈ X : c(x) ≤ 0 and ?x?∈ X such that f(x?) ≺ f(x)}<br />where X ⊂ Rdis the search domain, c = (ci)1≤i≤q is a vector of constraint functions (ci : X → R),<br />c(x) ≤ 0 means that ci(x) ≤ 0 for all 1 ≤ i ≤ q, f = (fj)1≤j≤p is a vector of objective functions<br />to be minimized (fj : X → R), and ≺ denotes the Pareto domination rule (see, e.g., Fonseca and<br />Fleming, 1998). Both the objective functions fj and the constraint functions ci are assumed to be<br />(1)<br />Paul Feliot (Ph.D. student) – E-mail: paul.feliot@irt-systemx.fr<br />Institut de Recherche Technologique SystemX, Palaiseau, France.<br />Julien Bect &amp; Emmanuel Vazquez – E-mail: firstname.lastname@centralesupelec.fr<br />Laboratoire des Signaux et Systèmes, Gif-sur-Yvette, France</p>  <p>Page 3</p> <p>2<br />continuous. The search domain X is assumed to be compact—typically, X is a hyper-rectangle defined<br />by bound constraints. Moreover, the objective and constraint functions are regarded as black boxes<br />and, in particular, we assume that no gradient information is available. Finally, the objective and the<br />constraint functions are assumed to be expensive to evaluate, which arises for instance when the values<br />f(x) and c(x), for a given x ∈ X, correspond to the outputs of a computationally expensive computer<br />program. In this setting, the emphasis is on building optimization algorithms that perform well under a<br />very limited budget of evaluations (e.g., a few hundred evaluations).<br />We adopt a Bayesian approach to this optimization problem. The essence of Bayesian optimization is to<br />choose a prior model for the expensive-to-evaluate function(s) involved in the optimization problem—<br />usually a Gaussian process model (Santner et al., 2003; Williams and Rasmussen, 2006) for tractability—<br />and then to select the evaluation points sequentially in order to obtain a small average error between the<br />approximation obtained by the optimization algorithm and the optimal solution, under the selected prior.<br />See, e.g., Kushner (1964); Mockus (1975); Mockus et al. (1978); Archetti and Betrò (1979) and Mockus<br />(1989) for some of the earliest references in the field. Bayesian optimization research was first focused<br />on the case of single-objective bound-constrained optimization: the Expected Improvement (EI) crite-<br />rion (Mockus et al., 1978; Jones et al., 1998) has emerged in this case as one of the most popular criteria<br />for selecting evaluation points. Later, the EI criterion has been extended to handle constraints (Schonlau<br />et al., 1998; Sasena et al., 2002; Gramacy and Lee, 2011; Gelbart et al., 2014; Gramacy et al., to appear)<br />and to address bound-constrained multi-objective problems (Emmerich et al., 2006; Jeong et al., 2006;<br />Wagner et al., 2010; Svenson and Santner, 2010).<br />The contribution of this article is twofold. The first part of the contribution is the proposition of a<br />new sampling criterion that handles multiple objectives and non-linear constraints simultaneously. This<br />criterion corresponds to a one-step look-ahead Bayesian strategy, using the dominated hyper-volume as a<br />utility function (following in this respect Emmerich et al., 2006). More specifically, the dominated hyper-<br />volume is defined using an extended domination rule, which handles both the objectives and constraints<br />jointly (in the spirit of Fonseca and Fleming, 1998; Ray et al., 2001; Oyama et al., 2007). Our new criterion<br />is naturally adapted to the search of a feasible point when none is available, and several criteria from<br />the literature—the EI criterion and some of its constrained/multi-objective extensions—are recovered<br />as special cases when at least one feasible point is known. The second part of the contribution lies in the<br />numerical methods employed to compute and optimize the sampling criterion. Indeed, this criterion takes<br />the form of an integral over the space of constraints and objectives, for which no analytical expression is<br />available in the general case. Besides, it must be optimized at each iteration of the algorithm to determine<br />the next evaluation point. In order to compute the integral, we use an algorithm similar to the subset<br />simulation method (Au and Beck, 2001; Cérou et al., 2012), which is a well known Sequential Monte<br />Carlo (SMC) technique (see Del Moral et al., 2006; Liu, 2008, and references therein) from the field of<br />structural reliability and rare event estimation. For the optimization of the criterion, we resort to an SMC<br />method as well, following earlier work by Benassi et al. (2012) for single-objective bound-constrained<br />problems. The resulting algorithm is called BMOO (for Bayesian multi-objective optimization).<br />The structure of the article is as follows. In Section 2, we recall the framework of Bayesian optimization<br />based on the expected improvement sampling criterion, starting with the unconstrained single-objective<br />setting. Section 3 presents our new sampling criterion for constrained multi-objective optimization. The<br />calculation and the optimization of the criterion are discussed in Section 4. Section 5 presents experimen-<br />tal results. An illustration on a two-dimensional toy problem is proposed for visualization purpose. Then,<br />the performances of the method are compared to those of reference methods on both single-objective and<br />multi-objective constrained optimization problems from the literature. Finally, future work is discussed<br />in Section 6.</p>  <p>Page 4</p> <p>3<br />2 Background literature<br />2.1 Expected Improvement<br />Consider the single-objective unconstrained optimization problem<br />x?= argminx∈Xf(x),<br />where f is a continuous real-valued function defined over X ⊂ Rd. Our objective is to find an approxima-<br />tion of x?using a sequence of evaluation points X1, X2, ... ∈ X. Because the choice of a new evaluation<br />point Xn+1at iteration n depends on the evaluation results of f at X1, ..., Xn, the construction of an<br />optimization strategy X : f ?→ (X1, X2, X3...) is a sequential decision problem.<br />The Bayesian approach to this decision problem originates from the early work of Kushner (1964)<br />and Mockus et al. (1978). Assume that a loss function εn(X,f) has been chosen to measure the perfor-<br />mance of the strategy X on f after n evaluations, for instance the classical loss function<br />εn(X,f) = mn− m,<br />(2)<br />with mn= f(X1) ∧ ··· ∧ f(Xn) and m = minx∈Xf(x). Then, a good strategy in the Bayesian sense<br />is a strategy that achieves, on average, a small value of εn(X,f) when n increases, where the average<br />is taken with respect to a stochastic process model ξ (defined on a probability space (Ω,A,P0), with<br />parameter in X) for the function f. In other words, the Bayesian approach assumes that f = ξ(ω,·) for<br />some ω ∈ Ω. The probability distribution of ξ represents prior knowledge about the function f—before<br />actual evaluations are performed. The reader is referred to Vazquez and Bect (2014) for a discussion of<br />other possible loss functions in the context of Bayesian optimization.<br />Observing that the Bayes-optimal strategy for a budget of N evaluations is intractable for N greater<br />than a few units, Mockus et al. (1978) proposed to use a one-step look-ahead strategy (also known as a<br />myopic strategy). Given n &lt; N evaluation results, the next evaluation point Xn+1is chosen in order to<br />minimize the conditional expectation of the future loss εn+1(X,ξ) given available evaluation results:<br />?εn+1(X,ξ) | Xn+1= x?,<br />where Enstands for the conditional expectation with respect to X1, ξ(X1), ..., Xn, ξ(Xn). Most of the<br />work produced in the field of Bayesian optimization since then has been focusing, as the present paper<br />will, on one-step look-ahead (or similar) strategies1; the reader is referred to Ginsbouger and Le Riche<br />(2009) and Benassi (2013) for discussions about two-step look-ahead strategies.<br />Xn+1= argminx∈XEn<br />(3)<br />When (2) is used as a loss function, the right-hand side of (3) can be rewritten as<br />?εn+1(X,ξ) | Xn+1= x?= argminEn<br />argminEn<br />?mn+1<br />??Xn+1= x?<br />= argmaxEn<br />?(mn− ξ(x))+<br />?,<br />(4)<br />with z+= max(z, 0). The function<br />ρn(x) : x ?→ En<br />?(mn− ξ(x))+<br />?<br />(5)<br />is called the Expected Improvement (EI) criterion (Schonlau et al., 1998; Jones et al., 1998). When ξ is<br />a Gaussian process with known mean and covariance functions, ρn(x) has a closed-form expression:<br />?<br />1Mockus (1989, Section 2.5) heuristically introduces a modification of (3) to compensate for the fact that subsequent<br />evaluation results are not taken into account in the myopic strategy. In this work, we consider a purely myopic strategy as<br />in Jones et al. (1998).<br />ρn(x) = γmn−?ξn(x), σ2<br />n(x)<br />?<br />,<br />(6)</p>  <p>Page 5</p> <p>4<br />where<br />γ(z,s) =<br />?√sϕ<br />max(z,0)<br />?<br />z<br />√s<br />?<br />+ z Φ<br />?<br />z<br />√s<br />?<br />if s &gt; 0,<br />if s = 0,<br />with Φ standing for the normal cumulative distribution function, ϕ = Φ?for the normal probability<br />density function,?ξn(x) = En(ξ(x)) for the kriging predictor at x (the posterior mean of ξ(x) after<br />See, e.g., the books of Stein (1999), Santner et al. (2003), and Williams and Rasmussen (2006) for more<br />information on Gaussian process models and kriging (also known as Gaussian process interpolation).<br />n evaluations) and σ2<br />n(x) for the kriging variance at x (the posterior variance of ξ(x) after n evaluations).<br />Finally, observe that the one-step look-ahead strategy (3) requires to solve an auxiliary global optimiza-<br />tion problem on X for each new evaluation point to be selected. The objective function ρn is rather<br />inexpensive to evaluate when ξ is a Gaussian process, using (6), but it is typically severely multi-modal.<br />A simple method to optimize ρnconsists in choosing a fixed finite set of points that covers X reasonably<br />well and then performing a discrete search. Recently, sequential Monte Carlo techniques (see Del Moral<br />et al., 2006; Liu, 2008, and references therein) have been shown to be a valuable tool for this task (Benassi<br />et al., 2012). A review of other approaches is provided in the PhD thesis of Benassi (2013, Section 4.2).<br />2.2 EI-based multi-objective optimization without constraints<br />We now turn to the case of unconstrained multi-objective optimization. Under this framework, we con-<br />sider a set of objective functions fj : X → R, j = 1, ..., p, to be minimized, and the objective is to<br />build an approximation of the Pareto front and of the set of corresponding solutions<br />Γ = {x ∈ X : ?x?∈ X such that f(x?) ≺ f(x)},<br />(7)<br />where ≺ stands for the Pareto domination rule defined by<br />y = (y1, ..., yp) ≺ z = (z1, ..., zp) ⇐⇒<br />?∀i ≤ p, yi≤ zi,<br />∃j ≤ p, yj&lt; zj.<br />(8)<br />Given evaluation results f(X1) = (f1(X1), ..., fp(X1)), ..., f(Xn) = (f1(Xn), ..., fp(Xn)), define<br />Hn= {y ∈ B;∃i ≤ n, f(Xi) ≺ y},<br />(9)<br />where B ⊂ Rpis a set of the form B = {y ∈ Rp; y ≤ yupp} for some yupp∈ Rp, which is introduced<br />to ensure that the volume of Hn is finite. Hn is the subset of B whose points are dominated by the<br />evaluations.<br />A natural idea, to extend the EI sampling criterion (5) to the multi-objective case, is to use the volume<br />of the non-dominated region as loss function:<br />εn(X,f) = |H \ Hn| ,<br />where H = {y ∈ B;∃x ∈ X,f(x) ≺ y} and |·| denotes the usual (Lebesgue) volume in Rp. The im-<br />provement yielded by a new evaluation result f(Xn+1) = (f1(Xn+1),...,fp(Xn+1)) is then the increase<br />of the volume of the dominated region (see Figure 1):<br />In(Xn+1) = |H \ Hn| − |H \ Hn+1| = |Hn+1\ Hn| = |Hn+1| − |Hn|,<br />since Hn ⊂ Hn+1 ⊂ H. Given a vector-valued Gaussian random process model ξ = (ξ1,...,ξp) of<br />f = (f1,...,fp), defined on a probability space (Ω,A,P0), a multi-objective EI criterion can then be<br />(10)</p>  <p>Page 6</p> <p>5<br />y1<br />y2<br />y3<br />f1<br />f2<br />B \ H3<br />Fig. 1: Example of an improvement of the dominated region. The regions dominated by y1 and y2 are represented in<br />shaded areas, with darker shades indicating overlapping regions. The hatched area corresponds to the improvement of the<br />dominated region resulting from the observation of y3.<br />derived as<br />ρn(x) = En(In(x))<br />= En<br />??<br />B\Hn<br />1ξ(x)≺ydy<br />?<br />=<br />?<br />?<br />B\Hn<br />En<br />?1ξ(x)≺y<br />Pn(ξ(x) ≺ y) dy ,<br />?dy<br />=<br />B\Hn<br />(11)<br />where Pnstands for the probability P0conditioned on X1, ξ(X1), ..., Xn, ξ(Xn). The multi-objective<br />sampling criterion (11), also called Expected Hyper-Volume Improvement (EHVI), has been proposed by<br />Emmerich and coworkers (Emmerich, 2005; Emmerich et al., 2006; Emmerich and Klinkenberg, 2008).<br />Remark 1 A variety of alternative approaches have been proposed to extend the EI criterion to the<br />multi-objective case, which can be roughly classified into aggregation-based techniques (Knowles, 2006;<br />Knowles and Hughes, 2005; Zhang et al., 2010) and domination-based techniques (Jeong and Obayashi,<br />2005; Keane, 2006; Ponweiser et al., 2008; Bautista, 2009; Svenson and Santner, 2010; Wagner et al.,<br />2010). We consider these approaches are heuristic extensions of the EI criterion, in the sense that none<br />of them emerges from a proper Bayesian formulation (i.e., a myopic strategy associated to some well-<br />identified loss function). A detailed description of these approaches is out of the scope of this paper.<br />The reader is referred to Wagner et al. (2010), Couckuyt et al. (2014) and Horn et al. (2015) for some<br />comparisons and discussions. See also Picheny (2014b) and Hernández-Lobato et al. (2015a) for other<br />approaches not directly related to the concept of expected improvement.<br />Remark 2 The multi-objective sampling criterion (11) reduces to the usual EI criterion (5) in the single-<br />objective case (assuming that f(Xi) ≤ yuppfor at least one i ≤ n).</p>  <p>Page 7</p> <p>6<br />Under the assumption that the components ξi of ξ are mutually independent2, Pn(ξ(x) ≺ y) can be<br />expressed in closed form: for all x ∈ X and y ∈ B \ Hn,<br />Pn(ξ(x) ≺ y) =<br />p<br />?<br />i=1<br />Φ<br />?<br />yi−?ξi,n(x)<br />σi,n(x)<br />?<br />,<br />(12)<br />where?ξi,n(x) and σ2<br />The integration of (12) over B \ Hn, in the expression (11) of the multi-objective EI criterion, is a non-<br />trivial problem. Several authors (Emmerich and Klinkenberg, 2008; Bader and Zitzler, 2011; Hupkens<br />et al., 2014; Couckuyt et al., 2014) have proposed decomposition methods to carry out this computation,<br />where the integration domain B\Hnis partitioned into hyper-rectangles, over which the integral can be<br />computed analytically. The computational complexity of these methods, however, increases exponentially<br />with the number of objectives3, which makes the approach impractical in problems with more than a few<br />objective functions. The method proposed in this work also encounters this type of integration problem,<br />but takes a different route to solve it (using SMC techniques; see Section 4). Our approach will make it<br />possible to deal with more objective functions.<br />i,n(x) denote respectively the kriging predictor and the kriging variance at x for<br />the ithcomponent of ξ.<br />Remark 3 Exact and approximate implementations of the EHVI criterion are available, together with<br />other Gaussian-process-based criteria for bound-constrained multi-objective optimization, in the Mat-<br />lab/Octave toolbox STK (Bect et al., 2016) and in the R packages GPareto (Binois and Picheny, 2015)<br />and mlrMBO (Horn et al., 2015). Note that several approaches discussed in Remark 1 maintain an<br />affordable computational cost when the number of objectives grows, and therefore constitute possible<br />alternatives to the SMC technique proposed in this paper for many-objective box-constrained problems.<br />2.3 EI-based optimization with constraints<br />In this section, we discuss extensions of the expected improvement criterion for single- and multi-objective<br />constrained optimization.<br />Consider first the case of problems with a single objective and several constraints:<br />?minx∈Xf(x),<br />c(x) ≤ 0,<br />(13)<br />where c = (c1, ..., cq) is a vector of continuous constraints. The set C = {x ∈ X; c(x) ≤ 0} is called the<br />feasible domain. If it is assumed that at least one evaluation has been made in C, it is natural to define a<br />notion of improvement with respect to the best objective value mn= min{f(x); x ∈ {X1, ...,Xn} ∩ C}:<br />In(Xn+1) = mn− mn+1<br />= 1c(Xn+1)≤0·?mn− f(Xn+1)?<br />=<br />0<br />+<br />?mn− f(Xn+1) if Xn+1∈ C and f(Xn+1) &lt; mn,<br />otherwise.<br />(14)<br />2This is the most common modeling assumption in the Bayesian optimization literature, when several objective functions,<br />and possibly also several constraint functions, have to be dealt with. See the VIPER algorithm of Williams et al. (2010)<br />for an example of an algorithm based on correlated Gaussian processes.<br />3See, e.g., Beume (2009), Hupkens et al. (2014), Couckuyt et al. (2014) and references therein for decomposition<br />algorithms and complexity results.</p>  <p>Page 8</p> <p>7<br />In other words, a new observation makes an improvement if it is feasible and improves upon the best past<br />value (Schonlau et al., 1998). The corresponding expected improvement criterion follows from taking the<br />expectation:<br />ρn(x) = En<br />?<br />1ξc(x)≤0·?mn− ξo(x)?<br />+<br />?<br />.<br />(15)<br />If f is modeled by a random process ξo and c is modeled by a vector-valued random process ξc =<br />(ξc,1, ..., ξc,q) independent of ξo, then the sampling criterion (15) simplifies to Schonlau et al.’s criterion:<br />ρn(x) = Pn(ξc(x) ≤ 0) En<br />?(mn− ξo(x))+<br />?.<br />(16)<br />In other words, the expected improvement is equal in this case to the product of the unconstrained ex-<br />pected improvement, with respect to mn, with the probability of feasibility. The sampling criterion (16)<br />is extensively discussed, and compared with other Gaussian-process-based constraint handling meth-<br />ods, in the PhD thesis of Sasena (2002). More generally, sampling criteria for constrained optimization<br />problems have been reviewed by Parr et al. (2012) and Gelbart (2015).<br />In the general case of constrained multi-objective problems, the aim is to build an approximation of Γ<br />defined by (1). If it is assumed that an observation has been made in the feasible set C, a reasoning<br />similar to that used in the single-objective case can be made to formulate an extension of the EI (11):<br />ρn(x) = En(|Hn+1| − |Hn|),<br />(17)<br />where<br />Hn= {y ∈ B;∃i ≤ n, Xi∈ C and f(Xi) ≺ y}<br />(18)<br />is the subset of B, defined as in Section 2.2, whose points are dominated by feasible evaluations. When ξo<br />and ξcare assumed independent, (17) boils down to the product of a modified EHVI criterion, where<br />only feasible points are considered4, and the probability of feasibility, as suggested by Emmerich et al.<br />(2006) and Shimoyama et al. (2013):<br />?<br />ρn(x) = Pn(ξc(x) ≤ 0)<br />B\Hn<br />Pn(ξo(x) ≺ y) dy.<br />(19)<br />Observe that the sampling criterion (17) is the one-step look-ahead criterion associated to the loss<br />function εn(X,f) = −|Hn|, where Hnis defined by (18). This loss function remains constant as long<br />as no feasible point has been found and, therefore, is not an appropriate measure of loss for heavily<br />constrained problems where finding feasible points is sometimes the main difficulty5. From a practical<br />point of view, not all unfeasible points should be considered equivalent: a point that does not satisfy<br />a constraint by a small amount has probably more value than one that does not satisfy the constraint<br />by a large amount, and should therefore make the loss smaller. Section 3 will present a generalization<br />of the expected improvement for constrained problems, relying on a new loss function that encodes this<br />preference among unfeasible solutions.<br />Remark 4 Other Gaussian-process-based approaches that can be used to handle constraints include the<br />method by Gramacy et al. (to appear), based on the augmented Lagrangian approach of Conn et al.<br />(1991), and several recent methods (Picheny, 2014a; Gelbart, 2015; Hernández-Lobato et al., 2015b, to<br />appear) based on stepwise uncertainty reduction strategies (see, e.g., Villemonteix et al., 2009; Bect<br />et al., 2012; Chevalier et al., 2014, for more information on this topic).<br />4Note that this modified EHVI criterion remains well defined even when Hn= ∅, owing to the introduction of an upper<br />bound yuppin the definition of B. Its single-objective counterpart introduced earlier (see Equation (15)), however, was<br />only well defined under the assumption that at least one feasible point is known. Introducing an upper bound yuppis of<br />course also possible in the single-objective case.<br />5The same remark holds for the variant (see, e.g., Gelbart et al., 2014) which consists in using the probability of<br />feasibility as a sampling criterion when no feasible point is available. This is indeed equivalent to using the loss function<br />εn(X,f) = −1∃i≤n,Xi∈Cin the search for feasible points.</p>  <p>Page 9</p> <p>8<br />Remark 5 The term En<br />computation of the integral in (19) has been discussed in Section 2.2. If it is further assumed that the<br />components of ξcare Gaussian and independent, then the probability of feasibility can be written as<br />?(mn−ξo(x))+<br />?in (16) can be computed analytically as in Section 2.1, and the<br />?<br />σc,j,n(x)<br />Pn(ξc(x) ≤ 0) =<br />q?<br />j=1<br />Φ<br />−<br />?ξc,j,n(x)<br />?<br />(20)<br />where?ξc,j,n(x) and σ2<br />c,j,n(x) stand respectively for the kriging predictor and the kriging variance of ξc,j<br />at x.<br />3 An EI criterion for constrained multi-objective optimization<br />3.1 Extended domination rule<br />In a constrained multi-objective optimization setting, we propose to handle the constraints using an<br />extended Pareto domination rule that takes both objectives and constraints into account, in the spirit of<br />Fonseca and Fleming (1998), Ray et al. (2001) and Oyama et al. (2007). For ease of presentation, denote<br />by Yo= Rpand Yc= Rqthe objective and constraint spaces respectively, and let Y = Yo× Yc.<br />We shall say that y1∈ Y dominates y2∈ Y, which will be written as y1?y2, if ψ(y1) ≺ ψ(y2), where ≺<br />is the usual Pareto domination rule recalled in Section 2.2 and, denoting by R the extended real line,<br />p× Rq<br /><br /><br />The extended domination rule (21) has the following properties:<br />ψ : Yo× Yc → R<br />(yo, yc) ?→<br /><br />(yo, 0)<br />?+∞, max(yc,0)?<br />if yc≤ 0,<br />otherwise.<br />(21)<br />(i) For unconstrained problems (q = 0, Yc = ∅), the extended domination rule boils down to the<br />Pareto domination rule on Y = Yo.<br />(ii) Feasible solutions (corresponding to yc≤ 0) are compared using the Pareto domination rule applied<br />in the objective space (in other words, using the Pareto domination rule with respect to the objective<br />values yo).<br />(iii) Non-feasible solutions (corresponding to yc?≤ 0) are compared using the Pareto domination rule<br />applied to the vector of constraint violations.<br />(iv) Feasible solutions always dominate non-feasible solutions.<br />These properties are illustrated on Figure 2.<br />3.2 A new EI criterion<br />The extended domination rule presented above makes it possible to define a notion of expected hyper-<br />volume improvement as in Section 2.2 for the constrained multi-objective setting. Given evaluation<br />results (f(X1),c(X1)), ..., (f(Xn),c(Xn)), define<br />Hn= {y ∈ B; ∃i ≤ n, (f(Xi), c(Xi)) ? y}<br />with B = Bo× Bc, where Bo⊂ Yoand Bc⊂ Ycare two bounded hyper-rectangles that are introduced<br />to ensure, as in Section 2.2, that |Hn| &lt; +∞ (see Appendix A). Then, define the improvement yielded<br />by a new evaluation (f(Xn+1), c(Xn+1)) by<br />In(Xn+1) = |Hn+1\ Hn| = |Hn+1| − |Hn|</p>  <p>Page 10</p> <p>9<br />y1<br />y2<br />y3<br />Yo<br />fi<br />fj<br />(a)<br />y3<br />y4<br />y5<br />Yc<br />ci<br />cj<br />(b)<br />y7<br />y8<br />Yc× Yo<br />ci<br />fj<br />(c)<br />y6<br />y3<br />y4<br />y5<br />Yc<br />ci<br />cj<br />(d)<br />y9<br />y7<br />y8<br />Yc× Yo<br />ci<br />fj<br />(e)<br />Fig. 2: Illustration of the extended domination rule in different cases. The region dominated by each point is represented<br />by a shaded area. Darker regions indicate overlapping regions. (a) Feasible solutions are compared with respect to their<br />objective values using the usual domination rule in the objective space—see properties (i) and (ii). (b–c) Non-feasible<br />solutions are compared using the Pareto domination rule applied to the vectors of constraint violations according to<br />property (iii). Note that y4 dominates points having a higher value of cj regardless of the corresponding value of ci, and,<br />likewise, y5 dominates points with higher values of ci. (d–e) Feasible solutions always dominate non-feasible solutions: y6<br />is feasible and hence dominates y3, y4and y5; y9is feasible and dominates both y7and y8as stated in (iv).<br />as in Section 2.2. In order to get a meaningful concept of improvement both before and after the first<br />feasible point has been found, we assume without loss of generality that (0, ..., 0) ∈ Rqis in the interior<br />of Bc.<br />If (f,c) is modeled by a vector-valued random process ξ = (ξo, ξc), with ξo = (ξo,1, ...,ξo,p) and<br />ξc = (ξc,1, ,...ξc,q), then the expected improvement for the constrained multi-objective optimization<br />problem may be written as<br />ρn(x) = En<br />?(In(x)?= En<br />??<br />Gn<br />1ξ(x)?ydy<br />?<br />=<br />?<br />Gn<br />Pn(ξ(x) ? y)dy ,<br />(22)<br />where Gn= B \ Hnis the set of all non-dominated points in B.</p>  <p>Page 11</p> <p>10<br />As in Section 2.2, under the assumption that the components of ξ are mutually independent and Gaus-<br />sian, Pn(ξ(x) ? y) can be expressed in closed form: for all x ∈ X and y = (yo, yc) ∈ Gn,<br /><br /><br /><br /><br />The EI-based constrained multi-objective optimization procedure may be written as (3). In practice, the<br />computation of each new evaluation point requires to solve two numerical problems: a) the computation<br />of the integral in (22); b) the optimization of ρnin the procedure (3). These problems will be addressed<br />in Section 4.<br />Pn(ξ(x) ? y) =<br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br />?p<br />i=1<br />?<br />Φ<br />?yo,i−?ξo,i,n(x)<br />σo,i,n(x)<br />??<br /><br />q?<br />j=1<br />Φ<br />?<br />−<br />?ξc,j,n(x)<br />σc,j,n(x)<br />?<br /><br />if yc≤ 0,<br />q?<br />j=1<br />Φ<br />?max(yc,j, 0) −?ξc,j,n(x)<br />σc,j,n(x)<br />?<br />otherwise.<br />(23)<br />Remark 6 When there are no constraints (q = 0, Yc= ∅), the extended domination rule ? corresponds<br />to the usual Pareto domination rule ≺. In this case, the sampling criterion (22) simplifies to<br />?<br />with<br />Hn,o= {yo∈ Bo; ∃i ≤ n, f(Xi) ≺ yo}.<br />Denote by ylow<br />o<br />∈ Yothe lower and upper corners of the hyper-rectangle Bo. Then, the sampling<br />criterion (24) is equivalent to the multi-objective EI criterion presented in Section 2.2 in the limit ylow<br />−∞. If, moreover, the problem has only one objective function, then the criterion (22) boils down to the<br />original Expected Improvement criterion as soon as the best evaluation dominates yupp<br />ρn(x) =<br />Bo\Hn,o<br />Pn(ξo(x) ≺ yo) dyo,<br />(24)<br />o , yupp<br />o<br />→<br />o<br />(see Remark 2).<br />3.3 Decomposition of the expected improvement: feasible and unfeasible components<br />Assume that there is at least one constraint (q ≥ 1). Then, the expected improvement ρn(x) can be<br />decomposed as<br />ρn(x) = ρfeas<br />n<br />(x) + ρunf<br />by splitting the integration domain in the right-hand side of (22) in two parts: ρfeas<br />the integral on (Gn) ∩ {yc≤ 0}, while ρunf<br />More explicit expressions will now be given for both terms. First,<br />?<br />= |Bo| ·<br />Bc\Hn,c<br />where y+<br />Hn,c=?yc∈ Bc| ∃i ≤ n, ξ+<br />Let B−<br />?<br />=<br />c<br />n(x),<br />(25)<br />n<br />(x) corresponds to<br />n(x) corresponds to the integral on (Gn) ∩ {yc?≤ 0}.<br />ρunf<br />n(x) =<br />Gn∩{yc?≤0}<br />?<br />Pn((ξo(x),ξc(x)) ? (yo,yc)) d(yo,yc)<br />?ξ+<br />Pn<br />c(x) ≺ y+<br />c<br />?1yc?≤0dyc<br />(26)<br />c= max(yc,0) and<br />c(Xi) ≺ y+<br />c<br />?.<br />c= Bc∩]−∞, 0]qdenote the feasible subset of Bc. Then, assuming that ξcand ξoare independent,<br />ρfeas<br />n<br />(x) =<br />Gn∩{yc≤0}<br />??B−<br />Pn((ξo(x),ξc(x)) ? (yo,yc)) d(yo,yc)<br />??· Pn(ξc(x) ≤ 0) ·<br />?<br />Bo\Hn,o<br />Pn(ξo(x) ≺ yo) dyo,<br />(27)</p>  <p>Page 12</p> <p>11<br />where<br />Hn,o= {yo∈ Bo| ∃i ≤ n, ξc(Xi) ≤ 0 and ξo(Xi) ≺ yo} .<br />Remark 7 The set Bc\ Hn,cis empty as soon as a feasible point has been evaluated. As a consequence,<br />the component ρunfof the expected improvement vanishes and therefore, according to (27),<br />?<br />In other words, up to a multiplicative constant, the expected improvement is equal, in this case, to the<br />product of the probability of feasibility with a modified EHVI criterion in the objective space, where<br />only feasible points are used to define the dominated region. In particular, in constrained single-objective<br />problems, the criterion of Schonlau et al. (see Section 2.3) is recovered as the limit case ylow<br />soon as the best evaluation dominates yupp<br />o<br />.<br />ρn(x) ∝ Pn(ξc(x) ≤ 0) ·<br />Bo\Hn,o<br />Pn(ξo(x) ≺ yo) dyo.<br />o<br />→ −∞, as<br />Remark 8 In our numerical experiments, Bo and Bc are defined using estimates of the range of the<br />objective and constraint functions (see Appendix B). Another natural choice for the Bowould have been<br />to use (an estimate of) the range of the objective functions restricted to the feasible subset C ⊂ X for Bo.<br />Further investigation of this idea is left for future work.<br />4 Sequential Monte Carlo techniques to compute and optimize the expected improvement<br />4.1 Computation of the expected improvement<br />Since the dimension of Y is likely to be high in practical problems (say, p + q ≥ 5), the integration<br />of y ?→ Pn(ξ(x) ? y) over Gn cannot be carried out using decomposition methods (Emmerich and<br />Klinkenberg, 2008; Bader and Zitzler, 2011; Hupkens et al., 2014) because, as mentioned in Section 2.2,<br />the computational complexity of these methods increases exponentially with the dimension of Y.<br />To address this difficulty, we propose to use a Monte Carlo approximation of the integral (22):<br />ρn(x) ≈1<br />m<br />m<br />?<br />k=1<br />Pn(ξ(x) ? yn,k),<br />(28)<br />where Yn= (yn,k)1≤k≤mis a set of particles distributed according to the uniform density πY<br />on Gn. In principle, sampling uniformly over Gncould be achieved using an accept-reject method (see,<br />e.g., Robert and Casella, 2013), by sampling uniformly over B and discarding points in Hn(Bader and<br />Zitzler, 2011). However, when the dimension of Y is high, Gnwill probably have a small volume with<br />respect to that of B. Then, the acceptance rate becomes small and the cost of generating a uniform<br />sample on Gn becomes prohibitive. (As an example, consider an optimization problem with q = 20<br />constraints. If Bc= [−v/2, +v/2]q, then the volume of the feasible region is 220≈ 106times smaller<br />than that of Bc.)<br />n∝ 1Gn<br />In this work, we use a variant of the technique called subset simulation (Au and Beck, 2001; Cérou et al.,<br />2012) to achieve uniform sampling over Gn. The subset simulation method is a well-known method in<br />the field of structural reliability and rare event estimation, which is used to estimate the volume of small<br />sets by Monte Carlo sampling.<br />Denote by ΠY<br />when n increases, so that sampling Gnusing an accept-reject method is impractical. Observe that the<br />sets Gn, n = 1, 2, ... form a nested sequence of subsets of B (hence the name subset simulation):<br />0the uniform distribution over B and assume that the probability ΠY<br />0(Gn) becomes small<br />B ⊃ G1⊃ G2⊃ ··· .<br />(29)</p>  <p>Page 13</p> <p>12<br />Algorithm 1: Remove-Resample-Move procedure to construct Yn<br />1 if n = 0 then<br />2<br />Generate m independent and uniformly distributed particles over G0= B.<br />3 else<br />4<br />Remove: Set Y0<br />5<br />Resample: Set Y1<br />distributed on Y0<br />6<br />Move: Move the particles using a Metropolis-Hastings algorithm (see, e.g, Robert and Casella, 2013)<br />which targets the uniform distribution over Gn+1. The resulting set of particles is Yn+1.<br />n= Yn−1∩ Gn and m0=??Y0<br />n. (Each ˜ yn,kis a replicate of a particle from Y0<br />n<br />??.<br />n= Y0<br />n∪ {˜ yn,1,..., ˜ yn,m−m0}, where ˜ yn,1,..., ˜ yn,m−m0are independent and uniformly<br />n.)<br />Algorithm 2: Modified procedure to construct Yn<br />Notation: Given a set A in Y, denote by Pareto(A) the set of points of A that are not dominated by any<br />other point of A<br />1 if n = 0 then<br />2<br />Generate m independent and uniformly distributed particles over G0= B.<br />3 else<br />4<br />Set Pn−1= Pareto({ξ(X1), ...,ξ(Xn−1)}).<br />5<br />Set Pn= Pareto({ξ(X1), ...,ξ(Xn)}) = Pareto(Pn−1∪ {ξ(Xn)}).<br />6<br />Construct Yn using the adaptive multi-level splitting procedure described in Algorithm 3, with Yn−1,<br />Pn−1, Pn and B as inputs.<br />Denote by ΠY<br />above. Since the addition of a single new evaluation, at iteration n + 1, is likely to yield only a small<br />modification of the set Gn, the probability<br />?<br />is likely to be high. Then, supposing that a set of particles Yn = (yn,k)1≤k≤muniformly distributed<br />on Gnis already available, one obtains a sample Yn+1uniformly distributed over Gn+1using the Remove-<br />Resample-Move procedure described in Algorithm 1. (All the random variables generated in Algorithm 1<br />are independent of ξ conditionally on X1, ξ(Xi), ..., Xn+1, ξ(Xn+1).)<br />nthe uniform distribution on Gn, which has the probability density function πY<br />ndefined<br />ΠY<br />n(Gn+1) =<br />Gn+1<br />πY<br />n(y)dy =ΠY<br />0(Gn+1)<br />ΠY<br />0(Gn)<br />Algorithm 1 obviously requires that at least one particle from Yn, which belongs by construction to Gn,<br />also belongs to Gn+1; otherwise, the set of surviving particles, referred to in the second step of the<br />algorithm, will be empty. More generally, Algorithm 1 will typically fail to produce a good sample<br />from ΠY<br />is small—indeed, the expected number of particles of Ynin a given6set A ⊂ B is<br />?<br />where N(A; Y) denotes the number of particles of Y in A. This situation occurs, for instance, when a<br />new evaluation point brings a large improvement Gn\ Gn+1= Hn+1\ Hn.<br />When the number of surviving particles is smaller than a prescribed fraction ν of the population size,<br />that is, when N(Gn+1; Yn) &lt; mν, intermediate subsets are inserted in the decreasing sequence (29) to<br />ensure that the volume of the subsets does not decrease too fast. The corrected version of Algorithm 1 is<br />described in Algorithms 2 and 3. The method used in Algorithm 3 to construct the intermediate subsets<br />is illustrated on Figures 3 and 4.<br />n+1if the number of surviving particles is small, which happens with high probability if ΠY<br />n(Gn+1)<br />En<br />N(A; Yn)<br />?<br />= En<br />?m<br />k=1<br />?<br />1A(yn,k)<br />?<br />= m · ΠY<br />n(A),<br />(30)<br />6Equation (30) does not hold exactly for A = Gn+1since, conditionally on X1, ξ(Xi), ..., Xn, ξ(Xn), the set Gn+1is<br />a random set and is not independent of Yn. Indeed, Gn+1 depends on ξ(Xn+1) and Xn+1 is chosen by minimization of<br />the approximate expected improvement, which in turn is computed using Yn.</p>  <p>Page 14</p> <p>13<br />y3<br />y1<br />y2<br />Bc<br />ci<br />cj<br />(a)<br />y3<br />y1<br />y2<br />Bc<br />ci<br />cj<br />yanchor<br />˜ yu<br />(b)<br />Fig. 3: Illustration of the steps 10 → 12 and 13 → 15 of Algorithm 3. The objective is to build a uniform sample Y3on G3<br />from Y2. The initial Pareto front P0 is determined by evaluations results y1 = (f(X1),c(X1)) and y2 = (f(X2),c(X2)).<br />PT corresponds to the Pareto front determined by P0∪ {y3}, with y3 = (f(X3),c(X3)). At the end of steps 1–9, y3 is<br />not in P because the number of surviving particles in Y2 is too small: in (a), there is only one particle (black dot) in G3<br />(white region). Thus, intermediate subsets are needed. The main idea here is to build a continuous path between P0and<br />PT, which is illustrated in (b). Here, we pick y?= y3 and since y3 is not feasible, q?&lt; q. Then, we set an anchor point<br />yanchoron the edge of B, as described in step 14, and we build an intermediate Pareto front? Pu determined by y1, y2and<br />of killed particles (grey dots) is not too large.<br />˜ yu, where ˜ yu lies on the segment (yanchor–y3). The intermediate Pareto front? Pu is chosen in such a way that the number<br />y2<br />y1<br />Bc× Bo<br />ci<br />fj<br />(a)<br />y2<br />y1<br />˜ yu<br />Bc× Bo<br />ci<br />fj<br />y0<br />anchor<br />yi<br />anchor<br />(b)<br />Fig. 4: Illustration of the steps 10 → 12 and 16 → 20 of Algorithm 3. The setting is the same as that described in Figure 3,<br />except that the new observation (y2 in this case) is feasible. Hence, q?= q. As above, the main idea is to construct a<br />continuous path between P0and PT, represented by the broken red line.</p>  <p>Page 15</p> <p>14<br />Algorithm 3: Adaptive multi-level splitting in the Y-domain<br />Notations: Given a set A in Y, denote by<br />– Pareto(A) the set of points of A that are not dominated by any other point of A,<br />– G(A) := B \ {y ∈ B; ∃y?∈ A such that y?? y} the region of B not dominated by A.<br />Inputs: Y0, P0, P?and B such that<br />– P0= Pareto(P0), i.e., no point in P0is dominated by another point in P0, and similarly P?= Pareto(P?),<br />– G(P?) ⊂ G(P0),<br />– Y0=?y0,k<br />o<br />o<br />c<br />c<br />B = Bo× Bc contains P0and P?.<br />Output: A set of particles YT=?yT,k<br />2 while Pt?= P?do<br />3<br />Initialize: P ← Pt.<br />4<br />P is the front that we will build upon. First we try to add the points of P?into P:<br />5<br />for y ∈ P?do<br />6<br />Ptry← Pareto(P ∪ {y})<br />7<br />Compute the number N(G(Ptry);Yt) of particles of Yt in G(Ptry)<br />8<br />if N(G(Ptry);Yt) ≥ νm then<br />9<br />P ← Ptry<br />At the end of this first step, either P = P?or P?\ P contains points that cannot be added without killing<br />a large number of particles, in which case we insert intermediate fronts.<br />10<br />if (P?\ P) ?= ∅ then<br />11<br />Randomly choose a point y?= (y?<br />12<br />Count the number q?of constraints satisfied by y?.<br />13<br />if q?&lt; q then<br />14<br />yanchor← (yupp<br />15<br />Find? Pu such that N(G(? Pu);Yt) ≈ νm using a dichotomy on u ∈ [0,1], where<br />16<br />else<br />17<br />y0<br />o<br />,0) ∈ Bo× Bc<br />18<br />yk<br />o<br />,yk<br />and 1 ≤ k ≤ q.<br />19<br />if N(G({y0<br />20<br />Find? Pu such that N(G(? Pu);Yt) ≈ νm using a dichotomy on u ∈ [0,1], where<br />else<br />Find? Pu such that N(G(? Pu);Yt) ≈ νm using a dichotomy on u ∈ [0,1], where<br />?<br />1≤k≤m∈ Ymis uniformly distributed on G(P0). Note that Y0may contain replicated values.<br />,ylow<br />and yupp<br />o<br />– ylow<br />,yupp<br />such that Bo=?y ∈ Yo; ylow<br />?<br />≤ y ≤ yupp<br />o<br />?, Bc=?y ∈ Yc; ylow<br />c<br />≤ y ≤ yupp<br />c<br />?, and<br />1≤k≤m∈ Ymuniformly distributed on G(PT).<br />1 t ← 0<br />o,y?<br />c) ∈ (P?\ P) toward which we will try to augment the front P.<br />o<br />,yc) ∈ Bo× Bc, where yc,j= yupp<br />c,j<br />if y?<br />c,j&gt; 0 and zero otherwise, 1 ≤ j ≤ q.<br />? Pu= Pareto(P ∪ {yanchor+ u(y?− yanchor)}).<br />anchor← (yupp<br />anchor← (yupp<br />c) ∈ Bo× Bc, where yk<br />c,j= yupp<br />c,j<br />if j = k and zero otherwise, for 1 ≤ j ≤ q<br />anchor});Yt) ≥ νm then<br />? Pu= Pareto(P ∪ {y0<br />anchor+ u(y?− y0<br />anchor)}).<br />21<br />22<br />? Pu= Pareto(P ∪ {y1<br />anchor+ u(y0<br />anchor− y1<br />anchor)} ∪ ··· ∪ {yq<br />anchor+ u(y0<br />anchor− yq<br />anchor)}).<br />23<br />P ←? Pu<br />24<br />Pt+1← P<br />Generate Yt+1=?yt+1,k<br />t ← t + 1<br />25<br />?<br />1≤k≤muniformly distributed on G(Pt+1) using the “Remove-Resample-Move”<br />steps described in Algorithm 1.<br />26<br />Remark 9 The algorithms presented in this section provide a general numerical method for the approx-<br />imate computation of the expected improvement criterion, that can be used with multiple objectives,<br />multiples constraints and possibly correlated Gaussian process models. When the objectives and con-<br />straints are independent, the decomposition introduced in Section 3.3 makes it possible to compute two<br />integrals over spaces of lower dimension (over Bc\ Hn,c and Bo\ Hn,o, respectively) instead of one<br />integral over Gn = B \ Hn. In fact, only one of the two integrals actually needs to be approximated<br />numerically: indeed, the term ρfeasof the decomposition can be calculated in closed form prior to finding</p>  <p>Page 16</p> <p>15<br />feasible solutions, and the term ρunfvanishes once a feasible observation has been made. We have taken<br />advantage of this observation for all the numerical results presented in Section 5.<br />4.2 Maximization of the sampling criterion<br />The optimization of the sampling criterion (22) is a difficult problem in itself because, even under the<br />unconstrained single-objective setting, the EI criterion is very often highly multi-modal. Our proposal is<br />to conduct a discrete search on a small set of good candidates provided at each iteration by a Sequential<br />Monte Carlo algorithm, in the spirit of Benassi et al. (2012), Li et al. (2012), Li (2012) and Benassi<br />(2013).<br />The key of such an algorithm is the choice of a suitable sequence?πX<br />sequence of densities are stability—πX<br />the probability mass in regions corresponding to high values of the expected improvement. We propose,<br />following Benassi et al. (2012), to consider the sequence defined by<br />?πX<br />πX<br />In other words, we start from the uniform distribution on X and then we use the probability of improve-<br />ment x ?→ Pn(ξ(x) ∈ Gn) as an un-normalized probability density function.<br />A procedure similar to that described in Algorithms 1 is used to generate particles distributed from<br />the target densities πX<br />particles<br />Xn= (xn,k,wn,k)m<br />such that the empirical distribution?<br />with respect to Section 4.1 is the introduction of weighted particles, which makes it possible to deal with<br />non-uniform target distributions. When a new sample is observed at step n, the weights of the particles<br />are updated to fit the new density πX<br />n<br />?<br />n≥0of probability density functions<br />on X, which will be the targets of the SMC algorithm. Desirable but antagonistic properties for this<br />n+1should not differ too much from πX<br />n—and concentration of<br />n(x) ∝ 1<br />n(x) ∝ Pn(ξ(x) ∈ Gn) for n = 1,2,...<br />if n = 0,<br />n. At each step n of the algorithm, our objective is to construct a set of weighted<br />k=1∈ (X × R)m<br />(31)<br />kwn,kδxn,k(where δxdenotes the Dirac measure at x ∈ X) is a<br />good approximation, for m large enough, of the target distribution with density πX<br />n. The main difference<br />n+1:<br />w0<br />n+1,k∝πX<br />n+1(xn,k)<br />πX<br />n(xn,k)<br />wn,k.<br />(32)<br />The weighted sample X0<br />π0,π1,... become more and more concentrated as more information is obtained about the functions f<br />and c, the regions of high values for πX<br />sequently, the weights of some particles degenerate to zero, indicating that those particles are no longer<br />good candidates for the optimization. Then, the corresponding particles are killed, and the particles with<br />non-degenerated weights are replicated to keep the size of the population constant. All particles are then<br />moved randomly using an MCMC transition kernel targeting πX<br />The corresponding procedure, which is very similar to that described in Algorithm 1, is summarized in<br />Algorithm 4.<br />n+1= (xn,k,w0<br />n+1,k)1≤k≤m is then distributed from πX<br />n+1. Since the densities<br />n+1become different from the regions of high values for πX<br />n. Con-<br />n+1, in order to restore some diversity.<br />When the densities πX<br />non-degenerated weights is very small and that the empirical distribution?<br />of non uniform target densities, we use the Effective Sample Size (ESS) to detect degeneracy (see, e.g.,<br />Del Moral et al., 2006), instead of simply counting the surviving particles. When the ESS falls below<br />a prescribed fraction of the population size, we insert intermediate densities, in a similar way to what<br />was described in Section 4.1. The intermediate densities are of the form ˜ πu(x) ∝ Pn(ξ(x) ∈˜Gu), with<br />Gn+1⊂˜Gu⊂ Gn. The corresponding modification of Algorithm 4 is straightforward. It is very similar<br />to the procedure described in Algorithms 2 and 3 and is not repeated here for the sake of brevity.<br />nand πX<br />n+1are too far apart, it may happen that the number of particles with<br />kwn,kδxn+1,kis not a good<br />approximation of πX<br />n+1. This is similar to the problem explained in Section 4.1, except that in the case</p>  <p>Page 17</p> <p>16<br />Algorithm 4: Reweight-Resample-Move procedure to construct Xn<br />1 if n = 0 then<br />2<br />m<br />3 else<br />4<br />Reweight Xn−1according to Equation (32) to obtain X0<br />5<br />Resample with a residual resampling scheme (see, e.g., Douc and Cappé, 2005) to obtain a set of particles<br />X1<br />Move the particles with an MCMC transition kernel to obtain Xn=?xn,k,1<br />Set X0=?x0,k,1<br />?<br />1≤k≤mwith x0,1,...,x0,mindependent and uniformly distributed on X.<br />n.<br />n=<br />?<br />x1<br />n,k,1<br />m<br />?<br />1≤k≤m.<br />6<br />m<br />?<br />1≤k≤m.<br />Remark 10 A closed form expression of the probability of improvement is available in the single-objective<br />case, as soon as one feasible point has been found. When no closed form expression is available, we<br />estimate the probability of improvement using a Monte Carlo approximation: 1/N?N<br />for the use of such an unbiased estimator inside a Metropolis-Hastings transition kernel (see the Move<br />step of Algorithm 4) is provided by Andrieu and Roberts (2009).<br />k=11Gn(Zk), where<br />(Zk)1≤k≤N is an N-sample of Gaussian vectors, distributed as ξ(x) under Pn. A rigorous justification<br />Remark 11 It sometimes happens that a new evaluation result—say, the n-th evaluation result—changes<br />the posterior so dramatically that the ESS falls below the threshold νm (see Algorithm 3) for the current<br />region Gn−1. When that happens, we simply restart the Sequential Monte Carlo procedure using a<br />sequence of transitions from P0= ∅ to the target front P?(notation introduced in Algorithm 3).<br />Remark 12 For the sake of clarity, the number of particles used in the SMC approximation has been<br />denoted by m both in Section 4.1 and in Section 4.2. Note that the two sample size are, actually, not<br />tied to each other. We will denote them respectively by mX and mYin Section 5.<br />5 Experiments<br />5.1 Settings<br />The BMOO algorithm has been written in the Matlab/Octave programming language, using the Small<br />Toolbox for Kriging (STK) (Bect et al., 2016) for the Gaussian process modeling part. All simulation<br />results have been obtained using Matlab R2014b.<br />In all our experiments, the algorithm is initialized with a maximin Latin hypercube design consisting of<br />Ninit= 3d evaluations. This is an arbitrary rule of thumb. A dedicated discussion about the size of initial<br />designs can be found in Loeppky et al. (2009). The objective and constraint functions are modeled using<br />independent Gaussian processes, with a constant but unknown mean function, and a Matérn covariance<br />function with regularity parameter ν = 5/2 (these settings are described, for instance, in Bect et al.,<br />2012). The variance parameter σ2and the range parameters θi, 1 ≤ i ≤ d, of the covariance functions<br />are (re-)estimated at each iteration using a maximum a posteriori (MAP) estimator. Besides, we assume<br />that the observations are slightly noisy to improve the conditioning of the covariance matrices, as is<br />usually done in kriging implementations.<br />In Sections 5.3 and 5.4, the computation of the expected improvement is carried out using the SMC<br />method described in Section 4.1. Taking advantage of Remark 9, the integration is performed only on<br />the constraint space (prior to finding a feasible point) or the objective space (once a feasible point is<br />found). In the case of single-objective problems (Section 5.3), we perform exact calculation using (16)<br />once a feasible point has been observed. The parameter ν of Algorithm 3 is set to 0.2 and we take<br />m = mY= 1000 particles. The bounding hyper-rectangles Boand Bcare determined using the adaptive<br />procedure described in Appendix B with λo= λc= 5.</p>  <p>Page 18</p> <p>17<br />x1<br />x2<br />-5<br />0<br />0<br />510<br />5<br />10<br />15<br />(a) Constraint function<br />x1<br />x2<br />-5<br />0<br />0<br />510<br />5<br />10<br />15<br />(b) Objective functions<br />f1<br />f2<br />-300<br />-200-100<br />0<br />-250<br />-200<br />-150<br />-100<br />-50<br />(c) Objective space<br />Fig. 5: Figure (a) represents contour lines of the constraint function, and Figure (b) corresponds to contour lines of the<br />two objective functions. The three gray areas correspond to the feasible region on Figures (a) and (b), and the image<br />of the feasible region by the objective functions on Figure (c). Thick dark curves correspond to the set of feasible and<br />non-dominated solutions on Figures (a) and (b). On Figure (c), thick dark curves correspond to the Pareto front.<br />For the optimization of the sampling criterion, we use the SMC method of Section 4.2, with m = mX=<br />1000 particles, residual resampling (Douc and Cappé, 2005), and an adaptive anisotropic Gaussian<br />random walk Metropolis-Hastings algorithm to move the particles (Andrieu and Thoms, 2008; Roberts<br />and Rosenthal, 2009). When the probability of improvement cannot be written under closed-form, a<br />Monte Carlo approximation (see Remark 10) with N = 100 simulations is used.<br />5.2 Illustration on a constrained multi-objective problem<br />In this section, the proposed method is illustrated on a two-dimensional two-objective toy problem,<br />which allows for easy visualization. The optimization problem is as follows:<br />minimize<br />subject to<br />f1and f2,<br />c(x) ≤ 0 and x = (x1,x2) ∈ [−5,10] × [0,15],<br />where<br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br />f1: (x1,x2) ?→ −(x1− 10)2− (x2− 15)2,<br />f2: (x1,x2) ?→ −(x1+ 5)2− x2<br />?<br />2,<br />c : (x1,x2) ?→<br />x2−5.1<br />4π2x2<br />1+5<br />πx1− 6<br />?2<br />+ 10<br />?<br />1 −<br />1<br />8π<br />?<br />cos(x1) + 9.<br />The set of solutions to that problem is represented on Figure 5. The feasible subset consists of three<br />disconnected regions of relatively small size compared to that of the search space. The solution Pareto<br />front consists of three corresponding disconnected fronts in the space of objectives. (The visualization is<br />achieved by evaluating the objectives and constraints on a fine grid, which would not be affordable in<br />the case of truly expensive-to-evaluate functions.)<br />The behavior of BMOO is presented in Figure 6. The algorithm is initialized with 5d = 10 function<br />evaluations. Figure 6 shows that the algorithm correctly samples the three feasible regions, and achieves<br />good covering of the solution Pareto front after only a few iterations. Note that no feasible solution is<br />given at the beginning of the procedure and that the algorithm finds one after 10 iterations.</p>  <p>Page 19</p> <p>18<br />x1<br />x2<br />Input space (n = 10)<br />-5<br />0<br />05<br />10<br />5<br />10<br />15<br />f1<br />f2<br />Objective space (n = 10)<br />-300<br />-200<br />-1000<br />-400<br />-300<br />-200<br />-100<br />x1<br />x2<br />Input space (n = 20)<br />-5<br />0<br />05<br />10<br />5<br />10<br />15<br />f1<br />f2<br />Objective space (n = 20)<br />-300<br />-200-100<br />-250<br />-200<br />-150<br />-100<br />-50<br />x1<br />x2<br />Input space (n = 40)<br />-5<br />0<br />05<br />10<br />5<br />10<br />15<br />f1<br />f2<br />Objective space (n = 40)<br />-300<br />-200-100<br />-250<br />-200<br />-150<br />-100<br />-50<br />x1<br />x2<br />Input space (n = 60)<br />-5<br />0<br />05<br />10<br />5<br />10<br />15<br />f1<br />f2<br />Objective space (n = 60)<br />-300<br />-200-100<br />-250<br />-200<br />-150<br />-100<br />-50<br />Fig. 6: Convergence of the algorithm after n = 10,20,40 and 60 evaluations. The left column shows the input space X,<br />whereas the right one shows the objective space Bo. Dominated observations are represented by triangles (filled or empty),<br />and non-dominated ones by circles (or disks). The symbols are filled for feasible points and empty otherwise. On the left<br />column, the small dots represent the particles used for the optimization of the expected improvement (see Section 4.2).<br />On the right column, the small dots represent the particles used for the computation of the expected improvement (see<br />Section 4.1). Note in particular that they appear only when a feasible point has been observed: before that, the term ρfeas<br />(see Section 3.3) can be computed analytically.<br />n</p>  <p>Page 20</p> <p>19<br />Pbm<br />g1<br />g3mod<br />g5mod<br />g6<br />g7<br />g8<br />g9<br />g10<br />g13mod<br />g16<br />g18<br />g19<br />g24<br />SR7<br />PVD4<br />WB4<br />d<br />13<br />20<br />4<br />2<br />10<br />2<br />7<br />8<br />5<br />5<br />9<br />15<br />2<br />7<br />4<br />4<br />q<br />9<br />1<br />5<br />2<br />8<br />2<br />4<br />6<br />3<br />Γ(%)<br />4 · 10−4<br />10−4<br />8.7 · 10−2<br />6.6 · 10−3<br />10−4<br />0.86<br />0.52<br />7 · 10−4<br />4.5<br />1.3 · 10−2<br />2 · 10−10<br />3.4 · 10−3<br />44.3<br />9.3 · 10−2<br />5.6 · 10−1<br />5.6 · 10−2<br />Best<br />-15<br />-0.693<br />5126.2<br />-6961.8<br />24.3<br />-0.0958<br />680.6<br />7049.4<br />0.0035<br />-1.916<br />-0.866<br />32.66<br />-5.5080<br />2994.4<br />5804.3<br />2.3813<br />Target<br />-14.85<br />-0.33<br />5150<br />-6800<br />25<br />-0.09<br />1000<br />8000<br />0.005<br />-1.8<br />-0.8<br />40<br />-5<br />2995<br />6000<br />2.5<br />38<br />13<br />5<br />2<br />11<br />3<br />6<br />Table 1: Main features of the mono-objective problems of our first benchmark.<br />5.3 Mono-objective optimization benchmark<br />The first benchmark that we use to assess the performance of BMOO consists of a set of sixteen con-<br />strained single-objective test problems proposed by Regis (2014). Table 1 summarizes the main features<br />of these problems. The input dimension d varies from 2 to 20, and the number q of constraints from 1<br />to 38. The problems may have linear or non-linear constraints but this information is not used by the<br />algorithms that we use in our comparisons (all functions are regarded as black boxes). Column Γ(%)<br />gives the ratio in percents of the volume of feasible region C to the volume of the search space X. This<br />ratio has been estimated using Monte Carlo sampling and gives an indication on the difficulty of the<br />problem for finding a feasible point. Note that problems g1, g3mod, g6, g7, g10, g19 and in particular<br />problem g18 have very small feasible regions. The last two columns correspond respectively to the best<br />known feasible objective value and to target values for the optimization. The target values are the ones<br />used in the work of Regis (2014).<br />BMOO is compared to two classes of algorithms. The first class consists of four local optimization<br />algorithms: the COBYLA algorithm of Powell (1994), using the implementation proposed by Johnson<br />(2012), and three algorithms implemented in the Matlab function fmincon7, namely, an interior-point<br />algorithm, an active-set algorithm and an SQP algorithm. Local optimization methods are known to<br />perform well on a limited budget provided that good starting points are chosen. We think that they are<br />relevant competitors in our context. The second class of algorithms are those proposed by Regis (2014),<br />which are state-of-the-art—to the best of our knowledge—algorithms for constrained optimization under<br />a limited budget of evaluations.<br />Each algorithm is run 30 times on each problem of the benchmark. Note that we use a random starting<br />point uniformly distributed inside the search domain for local search algorithms, and a random initial<br />design for BMOO, as described in Section 5.1. For the local search algorithms the maximum number<br />of evaluations is set to two hundred times the dimension d of the problem. Concerning the algorithms<br />proposed by Regis (2014), we simply reproduce the results presented by the author; the reader is referred<br />to the original article for more details about the settings. Results are presented in Tables 2 and 3. In<br />both tables, a solution is considered as feasible when there is no constraint violation larger than 10−5.<br />In Table 2, we measure the performance for finding feasible solutions. For local algorithms and Regis’<br />algorithms, only the results of the best scoring algorithm are reported in the table. Full results are<br />presented in Appendix C. For local algorithms, the first column indicates the best scoring algorithm:<br />Cob for the COBYLA algorithm, IP for the interior-point algorithm, AS for the active-set algorithm<br />and SQP for the SQP algorithm. Similarly, for the algorithms proposed by Regis (2014), the first col-<br />7Optimization toolbox v7.1, MATLAB R2014b</p>  <p>Page 21</p> <p>20<br />umn indicates the best scoring algorithm: CG for COBRA-Global, CL for COBRA-Local and Ext for<br />Extended-ConstrLMSRBF. The second column gives the number of successful runs—a run being success-<br />ful when at least one feasible solution has been found. The third column gives the number of function<br />evaluations that were required to find the first feasible point, averaged over the successful runs. The<br />corresponding standard deviation is given in parentheses.<br />Table 3 presents convergence results. Again, for local algorithms and for those proposed by Regis (2014),<br />the first column indicates the best scoring algorithm. The next columns give successively the number of<br />successful runs (a run being considered successful when a feasible solution with objective value below<br />the target value of Table 1 has been found), the average number—over successful runs—of evaluations<br />that were required to reach the target value, and the corresponding standard deviation (in parentheses).<br />The reader is referred to Appendix C for the full results.<br />BMOO achieves very good results on most test problems. It very often comes close to the best algorithm<br />in each of the two classes of competitors, and sometimes significantly outperforms both of them—see,<br />in particular, the results for g1, g6, g7, g9, g16 and WB4 in Table 3. However, BMOO stalls on test<br />problems g3mod, g10, g18 and PVD4. We were able to identify the causes of theses problems and to<br />propose remedies, which are presented in the following paragraphs. It can also be observed that BMOO<br />is sometimes slower than the best algorithm of Regis (2014) to find a first feasible point. In almost all<br />cases (except for g10, g18 and PVD4, which are discussed separately below), this is easily explained by<br />the size of the initial design which is Ninit= 3d in our experiments (see Section 5.1). Further work on<br />this issue is required to make it possible to start BMOO with a much smaller set of evaluations.<br />Regarding g3mod, g10 and PVD4, the difficulty lies in the presence of functions, among the objective or<br />the constraints, which are not adequately modeled using a Gaussian process with a stationary covariance<br />function. However, as we can see in Table 4, the performances of BMOO are greatly improved in all<br />three cases if a transformation of the form f → fλ(for λ &gt; 0) is applied to the functions that cause the<br />problem (see Appendix D for more details). Thus, we think that the theoretical foundations of BMOO<br />are not being questioned by these tests problems, but further work is needed on the Gaussian process<br />models for a proper treatment of these cases. In light of the results of our experiments, one promising<br />direction would be to consider models of the form ξλ, where ξ is a Gaussian process and λ is a parameter<br />to be estimated from the evaluation results (see, e.g., Box and Cox, 1964; Snelson et al., 2004).<br />Regarding the g18 test problem, the difficulty stems from our choice of a sampling density derived<br />from the probability of improvement for optimizing the expected improvement. When the number of<br />constraints is high (q = 13 for the g18 test problem) and no feasible point has yet been found, the<br />expected number of particles in the feasible regions C is typically very small with this choice of density.<br />Consequently, there is a high probability that none of the particles produced by the SMC algorithm<br />are good candidates for the optimization of the expected improvement. To illustrate this phenomenon,<br />consider the following idealized setting. Suppose that q = d, X = [−1/2,1/2]qand cj: x = (x1,...,xq) ?→<br />|xj| −ε<br />of the subset of X where exactly k constraints are satisfied is<br />2, j = 1,...,q, for some ε ∈ (0;1]. Thus, the feasible domain is C = [−ε/2,ε/2]qand the volume<br />Vk≈ (q<br />k) εk(1 − ε)q−k.<br />Assume moreover that the Gaussian process models are almost perfect, i.e.,<br />Pn(ξc,j(x) ≤ 0) ≈<br />?<br />1,<br />0,<br />if cj(x) ≤ 0,<br />otherwise,<br />(33)<br />for j = 1,...,q. Further assume n = 1 with X1 =<br />by ξ(x) for any x ∈ X (except at the corners) so that the probability of improvement Pn(ξ(x) ∈ G1) is<br />close to one everywhere on X. As a consequence, the sampling density πX<br />expected improvement is (approximately) uniform on X and the expected number of particles satisfying<br />exactly k constraints is mVk. In particular, if q is large, the particles thus tend to concentrate in regions<br />?1<br />2,...,1<br />2<br />?<br />and observe that ξ(X1) is dominated<br />1that we use to optimize the</p>  <p>Page 22</p> <p>21<br />Pbm<br />g1<br />g3mod<br />g5mod<br />g6<br />g7<br />g8<br />g9<br />g10<br />g13mod<br />g16<br />g18<br />g19<br />g24<br />SR7<br />WB4<br />PVD4<br />Local (best among 4)<br />IP30<br />IP30<br />AS 30<br />AS 30<br />SQP 30<br />IP 30<br />IP 30<br />SQP25<br />IP30<br />Cob27<br />SQP30<br />SQP30<br />IP30<br />SQP30<br />SQP30<br />SQP26<br />Regis (best among 3)<br />CG30<br />Ext 30<br />CL30<br />CL30<br />CG 30<br />CL 30<br />CG 30<br />CG30<br />Ext 30<br />Ext 30<br />CL30<br />CL30<br />CG30<br />CG30<br />CL30<br />CG30<br />BMOO<br />44.2 (1.9)<br />63.1 (0.6)<br />13.0 (1.2)<br />9.7 (0.7)<br />38.8 (3.3)<br />7.0 (0.2)<br />21.8 (5.1)<br />71.5 (28.1)<br />10.5 (5.6)<br />21.7 (7.3)<br />- (-)<br />46.4 (3.0)<br />2.6 (1.6)<br />22.0 (0.2)<br />19.1 (5.8)<br />15.7 (5.7)<br />128.4 (27.8)<br />342.3 (66.3)<br />35.0 (5.5)<br />29.7 (5.0)<br />107.6 (9.3)<br />12.1 (7.7)<br />170.9 (42.9)<br />144.6 (132.3)<br />21.4 (17.1)<br />31.5 (20.4)<br />101.9 (19.8)<br />19.7 (6.1)<br />4.0 (3.5)<br />27.1 (3.6)<br />76.6 (21.9)<br />7.6 (4.8)<br />15.0 (0)<br />31.2 (0.3)<br />6.4 (0.1)<br />10.9 (0.3)<br />47.5 (4.6)<br />6.5 (0.2)<br />21.5 (1.9)<br />22.8 (1.5)<br />8.6 (0.7)<br />19.6 (1.8)<br />108.6 (6.5)<br />16.5 (0.5)<br />1.3 (0.1)<br />9.5 (0.1)<br />37.4 (5.9)<br />7.9 (0.4)<br />30<br />30<br />30<br />30<br />30<br />30<br />30<br />30<br />30<br />30<br />0<br />30<br />30<br />30<br />30<br />30<br />Table 2: Number of evaluations to find a first feasible point. In bold, the good results in terms of average number of<br />evaluations. We consider the results to be good if more than 20 runs where successful and the average number of evaluations<br />is at most 20% above the best result. See Tables 11 and 13 in Appendix C for more detailed results. Dash symbols are<br />used when a value cannot be calculated.<br />Pbm<br />g1<br />g3mod<br />g5mod<br />g6<br />g7<br />g8<br />g9<br />g10<br />g13mod<br />g16<br />g18<br />g19<br />g24<br />SR7<br />WB4<br />PVD4<br />Local (best among 4)<br />IP20<br />IP30<br />AS30<br />AS30<br />SQP30<br />IP18<br />IP30<br />SQP18<br />IP25<br />Cob 27<br />SQP 21<br />SQP 30<br />IP16<br />SQP 30<br />SQP30<br />SQP23<br />Regis (best among 3)<br />CG30<br />Ext30<br />CL30<br />CL30<br />CG30<br />CL 30<br />CG 30<br />CG 29<br />Ext 30<br />Ext30<br />CL24<br />CL30<br />CG30<br />CG30<br />CL30<br />CG 30<br />BMOO<br />57.7 (2.6)<br />- (-)<br />16.3 (0.6)<br />13.3 (0.8)<br />55.8 (2.8)<br />26.3 (10.4)<br />61.6 (14.3)<br />- (-)<br />180.3 (84.6)<br />30.3 (12.3)<br />- (-)<br />133.3 (6.2)<br />9.9 (1.0)<br />29.3 (0.7)<br />44.5 (13.3)<br />151.0 (21.2)<br />349.7 (57.0)<br />356.9 (65.1)<br />35.8 (4.3)<br />29.7 (5.0)<br />107.6 (9.3)<br />59.3 (87.0)<br />179.3 (42.0)<br />658.3 (316.7)<br />122.5 (70.3)<br />60.0 (65.2)<br />97.5 (23.8)<br />61.3 (12.4)<br />10.4 (5.3)<br />27.1 (3.6)<br />78.3 (18.0)<br />54.7 (27.5)<br />125.2 (15.3)<br />141.7 (8.6)<br />12.9 (0.5)<br />53.6 (14.0)<br />99.8 (5.7)<br />30.3 (2.8)<br />176.4 (26.3)<br />193.7 (-)<br />146.4 (29.2)<br />38.4 (3.6)<br />195.9 (-)<br />698.5 (75.3)<br />9.0 (0)<br />33.5 (1.6)<br />164.6 (12.2)<br />155.4 (38.2)<br />30<br />0<br />30<br />30<br />30<br />30<br />30<br />0<br />30<br />30<br />0<br />30<br />30<br />30<br />30<br />2<br />Table 3: Number of evaluations to reach specified target. See Table 2 for conventions. See Tables 12 and 14 in Appendix C<br />for more detailed results.<br />where k ≈ qε, and the expected number mVqof particles in C is small. To compensate for the decrease<br />of Vk, when k is close to q, we suggest using the following modified sampling density:<br />πX<br />n∝ En<br />?K(x)!1ξ(x)∈Gn<br />?,<br />where K(x) is the number of constraints satisfied by ξ at x. Table 5 shows the promising results obtained<br />with this modified density on g18. Further investigations on this particular issue are left for future work.</p>  <p>Page 23</p> <p>22<br />Pbm<br />modified-g3mod<br />modified-g10<br />modified-PVD4<br />Feasible<br />63.3 (0.8)<br />48.4 (8.0)<br />12.9 (1.6)<br />Target<br />151.8 (12.2)<br />63.1 (10.4)<br />32.9 (13.2)<br />30<br />30<br />30<br />30<br />30<br />30<br />Table 4: Number of evaluations to find a first feasible point and to reach the target on transformed versions of the g3mod,<br />g10 and PDV4 problems, using the BMOO algorithm.<br />Pbm<br />g18<br />Feasible<br />75.5 (11.5)<br />Target<br />83.6 (9.1)3030<br />Table 5: Number of evaluations to find a first feasible point and to reach the target using a modified probability density<br />function for the criterion optimization.<br />Pbm<br />BNH<br />SRN<br />TNK<br />OSY<br />TwoBarTruss<br />WeldedBeam<br />CONSTR<br />WATER<br />d<br />2<br />2<br />2<br />6<br />3<br />4<br />2<br />3<br />q<br />2<br />2<br />2<br />6<br />1<br />4<br />2<br />7<br />p<br />2<br />2<br />2<br />2<br />2<br />2<br />2<br />5<br />Γ(%)<br />93,6<br />16,1<br />5,1<br />3,2<br />86,3<br />45,5<br />52,5<br />92<br />Vyref<br />o<br />5249<br />31820<br />0,6466<br />16169<br />4495<br />0,4228<br />3,8152<br />0,5138<br />[140; 50]<br />[200; 50]<br />[1,2; 1,2]<br />[0; 80]<br />[0,06; 105]<br />[50; 0,01]<br />[1; 9]<br />[1; 1; 1; 1,6; 3,2]<br />Table 6: Main features of the multi-objective problems in our benchmark.<br />5.4 Multi-objective optimization benchmark<br />The second benchmark consists of a set of eight constrained multi-objective test problems from Chafekar<br />et al. (2003) and Deb et al. (2002). The main features of these problems are given in Table 6. The input<br />dimension d varies from two to six, and the number q of constraints from one to seven. All problems<br />have two objective functions, except the WATER test problem, which has five. As in Table 1, column<br />Γ(%) gives an estimate of the ratio (in percents) of the volume of the feasible region to that of the search<br />space. Column V gives the volume of the region<br />dominated by the Pareto front8, measured using a reference point yref<br />in the last column. As an illustration, the result of one run of BMOO is shown on Figure 7, for each test<br />problem.<br />o, whose coordinates are specified<br />To the best of our knowledge, published state-of-the-art methods to solve multi-objective optimization<br />problems in the presence of nonlinear constraints are based on genetic or evolutionary approaches. The<br />most popular algorithms are probably NSGA2 (Deb et al., 2002) and SPEA2 (Zitzler et al., 2001). Such<br />algorithms, however, are not primarily designed to work on a limited budget of function<br />evaluations. Some methods that combine genetic/evolutionary approaches and surrogate modeling tech-<br />niques have been proposed in the literature (see, e.g., Emmerich et al., 2006; Jin, 2011, and references<br />therein), but a quantitative comparison with these methods would necessitate to develop proper imple-<br />mentations, which is out of the scope of this paper. In this section, we shall limit ourselves to emphasizing<br />advantages and limitations of the proposed approach. Since the ability of the BMOO algorithm to find<br />feasible solutions has already been demonstrated in Section 5.3, we will focus here on the other contribu-<br />8This volume has been obtained using massive runs of the gamultiobj algorithm of Matlab. It might be slightly under-<br />estimated.</p>  <p>Page 24</p> <p>23<br />f1<br />f2<br />040<br />80<br />120<br />0<br />15<br />30<br />45<br />(a) BNH<br />f1<br />f2<br />0<br />100<br />200300<br />0<br />1000<br />2000<br />(b) SRN<br />f1<br />f2<br />0 0.4<br />0.8<br />1.2<br />0<br />0.4<br />0.8<br />1.2<br />(c) TNK<br />f1<br />f2<br />-300-200<br />-100<br />0<br />0<br />50<br />100<br />150<br />(d) OSY<br />f1<br />f2<br />0<br />0.03 0.06<br />0.09<br />0<br />30k<br />60k<br />90k<br />(f) TwoBarTruss<br />f1<br />f2<br />0<br />15<br />3045<br />0<br />0.004<br />0.008<br />0.012<br />(g) WeldedBeam<br />f1<br />f2<br />0.3<br />0.5<br />0.70.9<br />1<br />3<br />5<br />7<br />(h) CONSTR<br />✵✷✹✵✶✷✵✵?✁ ✶✵✵?✁ ✶✵?✂✵?✄ ✶<br />✵<br />✷<br />✹<br />✵<br />✶<br />✷<br />✵<br />✵?✁<br />✶<br />✵<br />✵?✁<br />✶<br />✵?✂<br />✵?✄<br />✶<br />(i) WATER<br />Fig. 7: Result of one run of the BMOO algorithm on the problems of Table 6, with n = 100 evaluations on the bi-objective<br />problems and n = 200 evaluations on the WATER problem. Black dots represent non-dominated solutions. For bi-objective<br />problems, the set of feasible objective values is shown in gray. On the subfigure corresponding to the WeldedBeam problem,<br />a zoom has been made to improve visualization.</p>  <p>Page 25</p> <p>24<br />tions of the paper: the SMC methods for the computation and optimization of the expected improvement<br />sampling criterion.<br />First, we demonstrate the effectiveness of the proposed SMC algorithm for optimizing expected im-<br />provement based criteria. We compare our SMC approach (see Section 4.2) with the approach used by<br />Couckuyt et al. (2014), that we shall call MCSQP (for Monte-Carlo Sequential Quadratic Programming).<br />This approach consists in selecting the best point out of a population of candidates uniformly distributed<br />on the search space X, and then running an SQP algorithm starting from this point. In our experiments,<br />the number of candidates is chosen equal to the population size mX= 1000 of the SMC method.<br />Table 7 presents experimental results obtained with the extended EHVI criterion proposed in Section 3<br />as a sampling criterion. As a preliminary remark, observe that the finest target precision is systematically<br />reached by our SMC method in all but three test cases (OSY, TwoBarTruss and WeldedBeam). The<br />OSY case will be discussed below. On the TwoBarTruss and WeldedBeam problems, we found out that<br />the poor performances are due to Gaussian process modeling issues, similar to those encountered earlier<br />on the g3mod, g10 and PVD4 test problems (see Section 5.3). The results on these problems are thus<br />left out of the analyses in the following, but will motivate future work on the models, as concluded<br />in Section 5.3. Regarding the optimization of the criteria, the results show that our SMC approach<br />compares very favorably with MCSQP. More specifically, we note a drop of performance of the MCSQP<br />method compared with the SMC approach as we try to converge more finely toward the Pareto front<br />(see, in particular, column “Target 99%” of Table 7, but this is also visible in the other columns as well<br />for most of the test cases). Because of its sequential nature, the SMC approach is able to track much<br />more efficiently the concentration of the sampling criterion in the search domain, and thus makes it<br />possible to reach higher accuracy.<br />Tables 8 and 9 provide additional results obtained when performing the same study with respectively the<br />EMMI and WCPI criteria9(see Svenson and Santner, 2010; Keane, 2006, respectively). These criteria<br />are not primarily designed to address constrained problems, but they can easily be extended to handle<br />constraints by calculating them using only feasible values of the objectives, and then multiplying them<br />by the probability of satisfying the constraints (as explained in Section 2.3). When no feasible solution<br />is available at the start of the optimization procedure, we use the probability of feasibility as a sampling<br />criterion, as advised by Gelbart et al. (2014). The conclusions drawn from Table 7 for the extended EHVI<br />criterion carry through to the results presented in Tables 8–9. It shows that the SMC algorithm proposed<br />in Section 4.2 can be viewed as a contribution of independent interest for optimizing improvement-based<br />sampling criteria.<br />Next we study the influence on the convergence of the algorithm of the number m = mYof particles used<br />in Algorithm 1 for approximating the expected improvement value. In Table 10 we compare the number<br />of evaluations required to dominate successively 90%, 95% and 99% of the volume V of Table 6 when<br />using different numbers of particles. As expected, the overall performances of the algorithm deteriorate<br />when the number mY of particles used to approximate the expected improvement decreases. However,<br />the algorithm maintains satisfactory convergence properties even with a small number of particles. For<br />reference, we have also included results obtained by choosing the evaluation point randomly in the set<br />of candidate points. Notice that these results are always much worse than those obtained using the<br />sampling criterion with mY= 200. This shows that not all candidate points are equally good, and thus<br />confirms that the sampling criterion, even with a rather small value of mY, is effectively discriminating<br />between good and bad candidate points.<br />We observe poor performances of the BMOO algorithm on the OSY test problem, regardless of the<br />number of particles that are used to estimate the expected improvement. Figure 8 reveals that this is<br />due to the choice of a uniform sampling density on Bo\Hnas the target density of the SMC algorithm<br />used for the approximate computation of the criterion. Indeed, most of the particles do not effectively<br />participate to the approximation of the integral, since they lie outside the set of feasible objective values<br />(see Figure 7(d)). Further work is required on this topic to propose a better sampling density, that would<br />9An implementation of the EMMI criterion is available in the STK. An implementation of the WCPI sampling crtiterion<br />for bi-objective problems is distributed alongside with Forrester et al.’s book (Forrester et al., 2008).</p>  <p>Page 26</p> <p>25<br />Problemoptimizer<br />SMC<br />MCSQP<br />SMC<br />MCSQP<br />SMC<br />MCSQP<br />SMC<br />MCSQP<br />SMC<br />MCSQP<br />SMC<br />MCSQP<br />SMC<br />MCSQP<br />SMC<br />MCSQP<br />Target 90%<br />8.5 (0.6)<br />8.4 (0.6)<br />16.7 (0.9)<br />20.5 (2.4)<br />35.5 (2.6)<br />43.5 (4.6)<br />29.0 (1.7)<br />&gt; 250 (-)<br />90.9 (62.0)<br />88.7 (68.4)<br />146.5 (41.1)<br />171.3 (46.9)<br />12.4 (1.0)<br />13.8 (1.4)<br />48.3 (3.6)<br />53.5 (4.8)<br />Target 95%<br />12.7 (0.7)<br />12.8 (0.7)<br />22.4 (1.0)<br />35.6 (5.9)<br />44.1 (2.5)<br />71.6 (11.3)<br />38.2 (3.4)<br />&gt; 250 (-)<br />234 (-)<br />162.0 (29.7)<br />212 (33.9)<br />229.0 (-)<br />19.2 (1.4)<br />26.3 (3.3)<br />80.7 (5.6)<br />88.7 (7.5)<br />Target 99%<br />34.6 (1.3)<br />38.9 (2.2)<br />52.6 (4.1)<br />&gt; 250 (-)<br />71.1 (4.0)<br />&gt; 250 (-)<br />119.8 (53.0)<br />&gt; 250 (-)<br />&gt; 250 (-)<br />&gt; 250 (-)<br />&gt; 250 (-)<br />&gt; 250 (-)<br />83.5 (5.9)<br />&gt; 250 (-)<br />139.1 (8.0)<br />164.3 (9.6)<br />BNH<br />30<br />30<br />30<br />30<br />30<br />30<br />30<br />0<br />22<br />26<br />28<br />26<br />30<br />30<br />30<br />30<br />30<br />30<br />30<br />30<br />30<br />30<br />30<br />0<br />1<br />2<br />2<br />1<br />30<br />30<br />30<br />30<br />30<br />30<br />30<br />0<br />30<br />0<br />13<br />0<br />0<br />0<br />0<br />0<br />30<br />0<br />30<br />30<br />SRN<br />TNK<br />OSY<br />TwoBarTruss<br />WeldedBeam<br />CONSTR<br />WATER<br />Table 7: Results achieved when using either SMC or MCSQP for the optimization of the extended EHVI, on the problems of<br />Table 6. We measure the number of function evaluations for dominating successively 90%, 95% and 99% of the volume V . For<br />each target, the first column contains the number of successful runs over 30 runs. The second column contains the number<br />of function evaluations, averaged over the successful runs, with the corresponding standard deviation (in parentheses).<br />Dash symbols are used when a value cannot be calculated.<br />f1<br />f2<br />Bo<br />-1600 -1200<br />-800<br />-4000<br />0<br />50<br />100<br />150<br />200<br />250<br />Fig. 8: An illustration, in the objective domain Yo, of BMOO running on the OSY test problem. The small dots are the<br />particles used for the computation of the expected improvement. They are uniformly distributed on the non-dominated<br />subset of Bo. Dark disks indicate the non-dominated solutions found so far, light gray disks indicate the dominated ones.<br />concentrate on objective values that are likely to be feasible (instead of covering uniformly the entire<br />non-dominated region Bo\ Hn).<br />In practice, for problems with a small number of objectives, and especially for bi-objective problems,<br />we do not recommend the use of our SMC algorithm for the (approximate) computation of the EHVI<br />criterion since exact and efficient domain-decomposition-based algorithms are available (see Hupkens<br />et al., 2014; Couckuyt et al., 2014, and references therein). An in-depth study of the quality of the<br />approximation provided by our SMC method, and a comparison with exact methods, is therefore needed<br />before more precise recommandations can be made.</p>  <p>Page 27</p> <p>26<br />Problemoptimizer<br />SMC<br />MCSQP<br />SMC<br />MCSQP<br />SMC<br />MCSQP<br />SMC<br />MCSQP<br />SMC<br />MCSQP<br />SMC<br />MCSQP<br />SMC<br />MCSQP<br />SMC<br />MCSQP<br />Target 90%<br />9.8 (1.1)<br />9.5 (0.7)<br />15.5 (1.2)<br />18.6 (1.8)<br />47.7 (3.5)<br />60.6 (8.2)<br />32.3 (2.9)<br />&gt; 250 (-)<br />116.5 (48.5)<br />130.9 (63.9)<br />156.6 (50.5)<br />161.9 (60.1)<br />22.1 (2.5)<br />18.4 (2.1)<br />60.4 (6.5)<br />68.2 (8.1)<br />Target 95%<br />15.9 (1.5)<br />15.4 (1.4)<br />21.0 (1.4)<br />29.1 (2.7)<br />61.8 (4.4)<br />94.3 (13.2)<br />41.9 (3.9)<br />&gt; 250 (-)<br />199.0 (24.1)<br />174.0 (-)<br />177.0 (40.5)<br />156.0 (35.8)<br />33.8 (3.0)<br />30.9 (3.1)<br />93.4 (8.8)<br />103.9 (11.3)<br />Target 99%<br />41.2 (2.8)<br />42.6 (2.4)<br />48.3 (2.8)<br />90.9 (9.0)<br />100.2 (5.4)<br />224.2 (15.0)<br />73.6 (20.8)<br />&gt; 250 (-)<br />&gt; 250 (-)<br />&gt; 250 (-)<br />&gt; 250 (-)<br />&gt; 250 (-)<br />100.9 (8.6)<br />154.8 (9.0)<br />153.9 (9.0)<br />172.7 (13.7)<br />BNH<br />30<br />30<br />30<br />30<br />30<br />30<br />30<br />0<br />28<br />26<br />16<br />9<br />30<br />30<br />30<br />30<br />30<br />30<br />30<br />30<br />30<br />30<br />30<br />0<br />3<br />1<br />4<br />3<br />30<br />30<br />30<br />30<br />30<br />30<br />30<br />30<br />30<br />5<br />25<br />0<br />0<br />0<br />0<br />0<br />30<br />30<br />30<br />30<br />SRN<br />TNK<br />OSY<br />TwoBarTruss<br />WeldedBeam<br />CONSTR<br />WATER<br />Table 8: Results achieved when using the EMMI criterion. See Table 7 for more information.<br />Problemoptimizer<br />SMC<br />MCSQP<br />SMC<br />MCSQP<br />SMC<br />MCSQP<br />SMC<br />MCSQP<br />SMC<br />MCSQP<br />SMC<br />MCSQP<br />SMC<br />MCSQP<br />Target 90%<br />20.9 (8.9)<br />18.7 (8.2)<br />39.1 (6.0)<br />154.5 (62.1)<br />53.3 (6.8)<br />&gt; 250 (-)<br />39.7 (5.7)<br />&gt; 250 (-)<br />70.1 (40.3)<br />69.6 (47.3)<br />&gt; 250 (-)<br />&gt; 250 (-)<br />40.0 (5.6)<br />42.2 (16.0)<br />Target 95%<br />43.4 (7.6)<br />49.0 (14.2)<br />57.53 (7.5)<br />248.0 (-)<br />68.3 (6.9)<br />&gt; 250 (-)<br />61.5 (22.0)<br />&gt; 250 (-)<br />180.4 (40.0)<br />185.2 (53.0)<br />&gt; 250 (-)<br />&gt; 250 (-)<br />60.4 (7.8)<br />150.7 (42.8)<br />Target 99%<br />132.4 (15.4)<br />176.1 (29.1)<br />154.9 (12.8)<br />&gt; 250 (-)<br />120.8 (13.7)<br />&gt; 250 (-)<br />123.0 (41.9)<br />&gt; 250 (-)<br />&gt; 250 (-)<br />&gt; 250 (-)<br />&gt; 250 (-)<br />&gt; 250 (-)<br />212.1 (15.6)<br />&gt; 250 (-)<br />BNH<br />30<br />30<br />30<br />20<br />30<br />0<br />30<br />0<br />29<br />29<br />0<br />0<br />30<br />30<br />30<br />30<br />30<br />1<br />30<br />0<br />29<br />0<br />8<br />11<br />0<br />0<br />30<br />26<br />30<br />30<br />30<br />0<br />30<br />0<br />14<br />0<br />0<br />0<br />0<br />0<br />30<br />0<br />SRN<br />TNK<br />OSY<br />TwoBarTruss<br />WeldedBeam<br />CONSTR<br />Table 9: Results achieved when using the WCPI criterion. See Table 7 for more information.<br />6 Conclusions and future work<br />In this article, a new Bayesian optimization approach is proposed to solve multi-objective optimization<br />problems with non-linear constraints. The constraints are handled using an extended domination rule<br />and a new expected improvement formulation is proposed. In particular, the new formulation makes it<br />possible to deal with problems where no feasible solution is available from the start. Several criteria from<br />the literature are recovered as special cases.<br />The computation and optimization of the new expected improvement criterion are carried out using<br />sequential Monte Carlo sampling techniques. Indeed, the criterion takes the form of an integral over the<br />space of objectives and constraints, for which no closed-form expression is known. Besides, the sampling</p>  <p>Page 28</p> <p>27<br />ProblemEHVI<br />SMC (mY= 5000)<br />SMC (mY= 1000)<br />SMC (mY= 200)<br />random<br />SMC (mY= 5000)<br />SMC (mY= 1000)<br />SMC (mY= 200)<br />random<br />SMC (mY= 5000)<br />SMC (mY= 1000)<br />SMC (mY= 200)<br />random<br />SMC (mY= 5000)<br />SMC (mY= 1000)<br />SMC (mY= 200)<br />random<br />SMC (mY= 5000)<br />SMC (mY= 1000)<br />SMC (mY= 200)<br />random<br />SMC (mY= 5000)<br />SMC (mY= 1000)<br />SMC (mY= 200)<br />random<br />Target 90%<br />8.3 (0.7)<br />8.5 (0.6)<br />8.8 (0.6)<br />12.8 (2.7)<br />16.3 (1.0)<br />16.7 (0.9)<br />16.6 (1.3)<br />30.6 (5.2)<br />36.2 (4.4)<br />35.5 (2.6)<br />37.7 (4.1)<br />64.0 (10.3)<br />28.6 (2.0)<br />29.0 (1.7)<br />32.4 (3.1)<br />140.2 (21.0)<br />12.2 (0.7)<br />12.4 (1.0)<br />12.9 (1.2)<br />31.1 (6.6)<br />45.8 (4.0)<br />48.3 (3.6)<br />52.5 (4.5)<br />223.2 (15.4)<br />Target 95%<br />12.5 (0.5)<br />12.7 (0.7)<br />13.1 (0.7)<br />29.6 (6.0)<br />21.6 (1.1)<br />22.4 (1.0)<br />23.0 (1.9)<br />51.1 (8.2)<br />43.4 (3.6)<br />44.1 (2.5)<br />48.4 (5.0)<br />94.2 (12.4)<br />36.0 (2.8)<br />38.2 (3.4)<br />49 (16.0)<br />203.4 (21.4)<br />18.0 (1.0)<br />19.2 (1.4)<br />21.0 (1.6)<br />58.1 (8.5)<br />75.3 (6.2)<br />80.7 (5.6)<br />88.6 (6.0)<br />&gt; 250 (-)<br />Target 99%<br />32.8 (1.0)<br />34.6 (1.3)<br />39.2 (2.0)<br />106.8 (13.2)<br />47.3 (2.1)<br />52.6 (4.1)<br />60.9 (6.9)<br />146.2 (13.2)<br />65.1 (3.1)<br />71.1 (4.0)<br />87.3 (5.9)<br />193.3 (27.4)<br />82.5 (33.5)<br />119.8 (53.0)<br />164.8 (54.6)<br />&gt; 250 (-)<br />68.8 (4.7)<br />83.5 (5.9)<br />109.2 (10.7)<br />235.1 (11.0)<br />127 (8.2)<br />139.1 (8.0)<br />154.8 (8.8)<br />&gt; 250 (-)<br />BNH<br />30<br />30<br />30<br />30<br />30<br />30<br />30<br />30<br />30<br />30<br />30<br />30<br />30<br />30<br />30<br />30<br />30<br />30<br />30<br />30<br />30<br />30<br />30<br />14<br />30<br />30<br />30<br />30<br />30<br />30<br />30<br />30<br />30<br />30<br />30<br />30<br />30<br />30<br />29<br />25<br />30<br />30<br />30<br />30<br />30<br />30<br />30<br />0<br />30<br />30<br />30<br />30<br />30<br />30<br />30<br />30<br />30<br />30<br />30<br />29<br />22<br />13<br />5<br />0<br />30<br />30<br />30<br />18<br />30<br />30<br />30<br />0<br />SRN<br />TNK<br />OSY<br />CONSTR<br />WATER<br />Table 10: Results achieved on the problems of Table 6 when using successively mY = 200,1000 and 5000 particles for<br />the approximate computation of the extended EHVI criterion. For reference, results obtained by selecting the evaluation<br />point randomly in the pool of candidates points are provided (“random” rows). See Table 7 for more information.<br />criterion may be highly multi-modal, as is well known in the special case of unconstrained single-objective<br />optimization, which makes it difficult to optimize. The proposed sampling techniques borrow ideas from<br />the literature of structural reliability for estimating the probability of rare events, and can be viewed as<br />a contribution in itself.<br />We show that the resulting algorithm, which we call BMOO, achieves good results on a set of single-<br />objective constrained test problems, with respect to state-of-the-art algorithms. In particular, BMOO<br />is able to effectively find feasible solutions, even when the feasible region is very small compared to<br />the size of the search space and when the number of constraints is high. In the case of multi-objective<br />optimization with non-linear constraints, we show that BMOO is able to yield good approximations of<br />the Pareto front on small budgets of evaluations.<br />Several questions are left open for future work. First, our numerical studies reveal that the choice<br />of sampling densities in the input domain (as demonstrated by unsatisfactory results on the g18 test<br />problem) and in the output domain (as shown on the OSY case) could be improved. Suggestions for<br />improvement are proposed in the article and will be the object of future investigations. Second, an in-<br />depth study of the quality of the approximation provided by our SMC method, and a comparison with<br />exact methods, is needed before recommandations can be made on when to switch between exact and<br />approximate calculation of the expected improvement, and how to select the sample size—possibly in<br />an adaptive manner—used for the SMC approximation. Last, the choice of the random processes used<br />for modeling objective and constraint functions deserves more attention. Stationary Gaussian process</p>  <p>Page 29</p> <p>28<br />models have been found to lack flexibility on some single- and multi-objective cases (g3mod, g10, PVD4,<br />TwoBarTruss and WeldedBeam). Several types of models proposed in the literature—warped Gaussian<br />processes (Snelson et al., 2004), non-stationary Gaussian processes (see Toal and Keane, 2012, and<br />references therein), deep Gaussian processes (Damianou and Lawrence, 2013), etc.—provide interesting<br />directions regarding this issue.<br />Acknowledgements This research work has been carried out within the Technological Research Institute SystemX, using<br />public funds from the French Programme Investissements d’Avenir.<br />References<br />C. Andrieu and G. O. Roberts. The pseudo-marginal approach for efficient monte carlo computations.<br />The Annals of Statistics, pages 697–725, 2009.<br />Christophe Andrieu and Johannes Thoms. A tutorial on adaptive mcmc. Statistics and Computing, 18<br />(4):343–373, 2008.<br />F. Archetti and B. Betrò. A probabilistic algorithm for global optimization. CALCOLO, 16(3):335–343,<br />1979.<br />S.-K. Au and J. L Beck. Estimation of small failure probabilities in high dimensions by subset simulation.<br />Probabilistic Engineering Mechanics, 16(4):263–277, 2001.<br />J. Bader and E. Zitzler. Hype: An algorithm for fast hypervolume-based many-objective optimization.<br />Evolutionary Computation, 19(1):45–76, 2011.<br />D. C. Bautista. A sequential design for approximating the pareto front using the expected pareto im-<br />provement function. PhD thesis, The Ohio State University, 2009.<br />J. Bect, D. Ginsbourger, L. Li, V. Picheny, and E. Vazquez. Sequential design of computer experiments<br />for the estimation of a probability of failure. Statistics and Computing, 22(3):773–793, 2012.<br />J. Bect, E. Vazquez, et al. STK: a Small (Matlab/Octave) Toolbox for Kriging. Release 2.4 (to appear),<br />2016. URL http://kriging.sourceforge.net.<br />R. Benassi. Nouvel algorithme d’optimisation bayésien utilisant une approche Monte-Carlo séquentielle.<br />PhD thesis, Supélec, 2013.<br />R. Benassi, J. Bect, and E. Vazquez. Bayesian optimization using sequential Monte Carlo. In Learning<br />and Intelligent Optimization. 6th International Conference, LION 6, Paris, France, January 16-20,<br />2012, Revised Selected Papers, volume 7219 of Lecture Notes in Computer Science, pages 339–342.<br />Springer, 2012.<br />N. Beume. S-metric calculation by considering dominated hypervolume as klee’s measure problem.<br />Evolutionary Computation, 17(4):477–492, 2009.<br />M. Binois and V. Picheny. GPareto: Gaussian Processes for Pareto Front Estimation and Optimization,<br />2015. URL http://CRAN.R-project.org/package=GPareto. R package version 1.0.1.<br />G. E. P. Box and D. R. Cox. An analysis of transformations. Journal of the Royal Statistical Society.<br />Series B (Methodological), pages 211–252, 1964.<br />F. Cérou, P. Del Moral, T. Furon, and A. Guyader. Sequential Monte Carlo for rare event estimation.<br />Statistics and Computing, 22(3):795–808, 2012.<br />D. Chafekar, J. Xuan, and K. Rasheed. Constrained multi-objective optimization using steady state<br />genetic algorithms. In Genetic and Evolutionary Computation-GECCO 2003, pages 813–824. Springer,<br />2003.<br />C. Chevalier, J. Bect, D. Ginsbourger, E. Vazquez, V. Picheny, and Y. Richet. Fast parallel kriging-based<br />stepwise uncertainty reduction with application to the identification of an excursion set. Technometrics,<br />56(4), 2014.<br />A. R. Conn, N. I. M. Gould, and P. Toint. A globally convergent augmented lagrangian algorithm for<br />optimization with general constraints and simple bounds. SIAM Journal on Numerical Analysis, 28<br />(2):545–572, 1991.<br />I. Couckuyt, D. Deschrijver, and T. Dhaene. Fast calculation of multiobjective probability of improve-<br />ment and expected improvement criteria for pareto optimization. Journal of Global Optimization, 60<br />(3):575–594, 2014.</p>  <p>Page 30</p> <p>29<br />A. Damianou and N. Lawrence. Deep gaussian processes. In Proceedings of the Sixteenth International<br />Conference on Artificial Intelligence and Statistics, pages 207–215, 2013.<br />K. Deb, A. Pratap, S. Agarwal, and T. Meyarivan. A fast and elitist multiobjective genetic algorithm:<br />NSGA-II. Evolutionary Computation, IEEE Transactions on, 6(2):182–197, 2002.<br />P. Del Moral, A. Doucet, and A. Jasra. Sequential monte carlo samplers. Journal of the Royal Statistical<br />Society: Series B (Statistical Methodology), 68(3):411–436, 2006.<br />R. Douc and O. Cappé. Comparison of resampling schemes for particle filtering. In Image and Signal<br />Processing and Analysis, 2005. ISPA 2005. Proceedings of the 4th International Symposium on, pages<br />64–69. IEEE, 2005.<br />M. Emmerich. Single- and multiobjective evolutionary design optimization assisted by Gaussian random<br />field metamodels. PhD thesis, Technical University Dortmund, 2005.<br />M. Emmerich and J. W. Klinkenberg. The computation of the expected improvement in dominated<br />hypervolume of Pareto front approximations. Rapport technique, Leiden University, 2008.<br />M. Emmerich, K. C. Giannakoglou, and B. Naujoks. Single- and multi-objective evolutionary optimiza-<br />tion assisted by Gaussian random field metamodels. IEEE Transactions on Evolutionary Computation,<br />10(4):421–439, 2006.<br />C. M. Fonseca and P. J. Fleming. Multiobjective optimization and multiple constraint handling with evo-<br />lutionary algorithms. I. A unified formulation. IEEE Transactions on Systems, Man and Cybernetics.<br />Part A: Systems and Humans, 28(1):26–37, 1998.<br />A. I. J. Forrester, A. Sobester, and A. J. Keane. Engineering design via surrogate modelling: a practical<br />guide. John Wiley &amp; Sons, 2008.<br />M. A. Gelbart. Constrained Bayesian Optimization and Applications. PhD thesis, Harvard University,<br />Graduate School of Arts and Sciences, 2015.<br />M. A. Gelbart, J. Snoek, and R. P. Adams. Bayesian optimization with unknown constraints. arXiv<br />preprint arXiv:1403.5607, 2014.<br />D. Ginsbouger and R. Le Riche. Towards Gaussian process-based optimization with finite time horizon.<br />In Invited talk at the 6th Autumn Symposium of the &quot;Statistical Modelling&quot; Research Training Group,<br />November 21st 2009.<br />R. B. Gramacy and H. Lee. Optimization under unknown constraints. In Bayesian Statistics 9. Pro-<br />ceedings of the Ninth Valencia International Meeting, pages 229–256. Oxford University Press, 2011.<br />R. B. Gramacy, G. A. Gray, S. Le Digabel, H. K. H. Lee, P. Ranjan, G. Wells, and S. M. Wild. Modeling<br />an augmented lagrangian for blackbox constrained optimization. Technometrics, to appear.<br />D. Hernández-Lobato, J. M. Hernández-Lobato, A. Shah, and R. P. Adams. Predictive entropy search<br />for multi-objective bayesian optimization. arXiv preprint arXiv:1511.05467, 2015a.<br />J. M. Hernández-Lobato, M. A. Gelbart, M. W. Hoffman, R. P. Adams, and Z. Ghahramani. Predic-<br />tive entropy search for bayesian optimization with unknown constraints. In Proceedings of the 32nd<br />International Conference on Machine Learning, Lille, France, 2015. JMLR: W&amp;CP volume 37, 2015b.<br />J. M. Hernández-Lobato, M. A. Gelbart, R. P. Adams, M. W. Hoffman, and Z. Ghahramani. A general<br />framework for constrained bayesian optimization using information-based search. TBD, to appear.<br />D. Horn, T. Wagner, D. Biermann, C. Weihs, and B. Bischl. Model-based multi-objective optimization:<br />Taxonomy, multi-point proposal, toolbox and benchmark. In Evolutionary Multi-Criterion Optimiza-<br />tion, pages 64–78. Springer, 2015.<br />I. Hupkens, M. Emmerich, and A. Deutz. Faster computation of expected hypervolume improvement.<br />arXiv preprint arXiv:1408.7114, 2014.<br />S. Jeong and S. Obayashi. Efficient global optimization (ego) for multi-objective problem and data<br />mining. In Evolutionary Computation, 2005. The 2005 IEEE Congress on, volume 3, pages 2138–<br />2145, 2005.<br />S. Jeong, Y. Minemura, and S. Obayashi. Optimization of combustion chamber for diesel engine using<br />kriging model. Journal of Fluid Science and Technology, 1(2):138–146, 2006.<br />Y. Jin. Surrogate-assisted evolutionary computation: Recent advances and future challenges. Swarm<br />and Evolutionary Computation, 1(2):61–70, 2011.<br />S. G. Johnson. The nlopt nonlinear-optimization package (version 2.3). URL http://ab-initio. mit.<br />edu/nlopt, 2012.</p>  <p>Page 31</p> <p>30<br />D. R. Jones, M. Schonlau, and W. J. Welch. Efficient global optimization of expensive black-box func-<br />tions. Journal of Global Optimization, 13(4):455–492, 1998.<br />A. J. Keane. Statistical improvement criteria for use in multiobjective design optimization. AIAA<br />journal, 44(4):879–891, 2006.<br />J. Knowles. Parego: a hybrid algorithm with on-line landscape approximation for expensive multiobjec-<br />tive optimization problems. Evolutionary Computation, IEEE Transactions on, 10(1):50–66, 2006.<br />J. Knowles and E. J. Hughes. Multiobjective optimization on a budget of 250 evaluations. In Evolutionary<br />Multi-Criterion Optimization, pages 176–190. Springer, 2005.<br />H. J Kushner. A new method of locating the maximum point of an arbitrary multipeak curve in the<br />presence of noise. Journal of Fluids Engineering, 86(1):97–106, 1964.<br />L. Li. Sequential Design of Experiments to Estimate a Probability of Failure. PhD thesis, Supélec, 2012.<br />L. Li, J. Bect, and E. Vazquez. Bayesian Subset Simulation: a kriging-based subset simulation algorithm<br />for the estimation of small probabilities of failure. In Proceedings of PSAM 11 &amp; ESREL 2012, 25-29<br />June 2012, Helsinki, Finland. IAPSAM, 2012.<br />J. S. Liu. Monte Carlo strategies in scientific computing. Springer, 2008.<br />J. L. Loeppky, J. Sacks, and W. J. Welch. Choosing the sample size of a computer experiment: A<br />practical guide. Technometrics, 51(4), 2009.<br />J. Mockus. On Bayesian methods of optimization. In Towards Global Optimization, pages 166–181.<br />North-Holland, 1975.<br />J. Mockus.<br />Bayesian approach to global optimization: theory and applications, volume 37.<br />Academic Publishers, 1989.<br />J. Mockus, V. Tiesis, and A. Žilinskas. The application of Bayesian methods for seeking the extremum. In<br />L. C. W. Dixon and Gábor. P. Szegö, editors, Towards Global Optimization, volume 2, pages 117–129,<br />North Holland, New York, 1978.<br />A. Oyama, K. Shimoyama, and K. Fujii. New constraint-handling method for multi-objective and multi-<br />constraint evolutionary optimization. Transactions of the Japan Society for Aeronautical and Space<br />Sciences, 50(167):56–62, 2007.<br />J. M. Parr, A. J. Keane, A. I. J. Forrester, and C. M. E. Holden. Infill sampling criteria for surrogate-<br />based optimization with constraint handling. Engineering Optimization, 44(10):1147–1166, 2012.<br />V. Picheny. A stepwise uncertainty reduction approach to constrained global optimization. In Proceed-<br />ings of the 17th International Conference on Artificial Intelligence and Statistics (AISTATS), 2014,<br />Reykjavik, Iceland., volume 33, pages 787–795. JMLR: W&amp;CP, 2014a.<br />V. Picheny. Multiobjective optimization using Gaussian process emulators via stepwise uncertainty<br />reduction. Statistics and Computing, DOI:10.1007/s11222-014-9477-x:1–16, 2014b.<br />W. Ponweiser, T. Wagner, D. Biermann, and M. Vincze. Multiobjective optimization on a limited budget<br />of evaluations using model-assisted S-metric selection. In Parallel Problem Solving from Nature (PPSN<br />X), volume 5199 of Lecture Notes in Computer Science, pages 784–794. Springer, 2008.<br />M. J. D. Powell. A direct search optimization method that models the objective and constraint functions<br />by linear interpolation. In Advances in optimization and numerical analysis, pages 51–67. Springer,<br />1994.<br />T. Ray, K. Tai, and K. C. Seow. Multiobjective design optimization by an evolutionary algorithm.<br />Engineering Optimization, 33(4):399–424, 2001.<br />R. G. Regis. Constrained optimization by radial basis function interpolation for high-dimensional ex-<br />pensive black-box problems with infeasible initial points. Engineering Optimization, 46(2):218–243,<br />2014.<br />C. Robert and G. Casella. Monte Carlo statistical methods. Springer, 2013.<br />Gareth O Roberts and Jeffrey S Rosenthal. Examples of adaptive mcmc. Journal of Computational and<br />Graphical Statistics, 18(2):349–367, 2009.<br />T. J. Santner, B. J. Williams, and W. Notz. The design and analysis of computer experiments. Springer<br />Science &amp; Business Media, 2003.<br />M. J. Sasena. Flexibility and efficiency enhancements for constrained global design optimization with<br />kriging approximations. PhD thesis, University of Michigan, 2002.<br />M. J. Sasena, P. Papalambros, and P. Goovaerts. Exploration of metamodeling sampling criteria for<br />constrained global optimization. Engineering Optimization, 34(3):263–278, 2002.<br />Kluwer</p>  <p>Page 32</p> <p>31<br />M. Schonlau, W. J. Welch, and D. R. Jones. Global versus local search in constrained optimization of<br />computer models. In New Developments and Applications in Experimental Design: Selected Proceedings<br />of a 1997 Joint AMS-IMS-SIAM Summer Conference, volume 34 of IMS Lecture Notes-Monographs<br />Series, pages 11–25. Institute of Mathematical Statistics, 1998.<br />K. Shimoyama, K. Sato, S. Jeong, and S. Obayashi. Updating kriging surrogate models based on the<br />hypervolume indicator in multi-objective optimization. Journal of Mechanical Design, 135(9):094503,<br />2013.<br />E. Snelson, C. E. Rasmussen, and Z. Ghahramani. Warped gaussian processes. Advances in neural<br />information processing systems, 16:337–344, 2004.<br />M. L. Stein. Interpolation of Spatial Data: Some Theory for Kriging. Springer, 1999.<br />J. D. Svenson and T. J. Santner. Multiobjective optimization of expensive black-box functions via<br />expected maximin improvement. Technical report, Tech. rep., 43210, Ohio University, Columbus,<br />Ohio, 2010.<br />D. J. J. Toal and A. J. Keane. Non-stationary kriging for design optimization. Engineering Optimization,<br />44(6):741–765, 2012.<br />E. Vazquez and J. Bect.A new integral loss function for Bayesian optimization.<br />arXiv:1408.4622, 2014. URL http://arxiv.org/abs/1408.4622.<br />J. Villemonteix, E. Vazquez, and E. Walter. An informational approach to the global optimization of<br />expensive-to-evaluate functions. Journal of Global Optimization, 44(4):509–534, 2009.<br />T. Wagner, M. Emmerich, A. Deutz, and W. Ponweiser. On expected-improvement criteria for model-<br />based multi-objective optimization. In Parallel Problem Solving from Nature, PPSN XI. 11th Inter-<br />national Conference, Krakov, Poland, September 11-15, 2010, Proceedings, Part I, volume 6238 of<br />Lecture Notes in Computer Science, pages 718–727. Springer, 2010.<br />B. J. Williams, T. J. Santner, W. I. Notz, and J. S. Lehman. Sequential design of computer experiments<br />for constrained optimization. In T. Kneib and G. Tutz, editors, Statistical Modelling and Regression<br />Structures, pages 449–472. Physica-Verlag HD, 2010.<br />C. K. I. Williams and C. Rasmussen. Gaussian processes for machine learning. the MIT Press, 2(3):4,<br />2006.<br />Q. Zhang, W. Liu, E. Tsang, and B. Virginas. Expensive multiobjective optimization by moea/d with<br />gaussian process model. Evolutionary Computation, IEEE Transactions on, 14(3):456–474, 2010.<br />E. Zitzler, M. Laumanns, and L. Thiele. SPEA2: Improving Strength Pareto Evolutionary Algorithm,<br />2001.<br />arXiv preprint<br />A On the bounded hyper-rectangles Boand Bc<br />We have assumed in Section 3 that Bo and Bc are bounded hyper-rectangles; that is, sets of the form<br />Bo=?y ∈ Yo; ylow<br />o<br />≤ y ≤ yupp<br />≤ y ≤ yupp<br />o<br />?,<br />Bc=?y ∈ Yc; ylow<br />∈ Yc, with the additional assumption that ylow<br />cc<br />?,<br />for some ylow<br />Remember that upper bounds only where required in the unconstrained case discussed in Section 2.2. To shed some light<br />on the role of these lower and upper bounds, let us now compute the improvement I1(X1) = |H1| brought by a single<br />evaluation.<br />o<br />,yupp<br />o<br />∈ Yo and ylow<br />c<br />, yupp<br />c<br />c,j<br />&lt; 0 &lt; yupp<br />c,j<br />for all j ≤ q.<br />If X1is not feasible, then<br />|H1| = |Bo| ·<br />q<br />?<br />j=1<br />?<br />yupp<br />c,j− ylow<br />c,j<br />?γj?<br />yupp<br />c,j− ξc,j(X1)<br />?1−γj<br />(34)<br />where γj= 1ξc,j(X1)≤0. It is clear from the right-hand side of (34) that both Bo and Bc have to be bounded if we want<br />|H1| &lt; +∞ for any γ = (γ1,,..., γq) ∈ {0,1}q. Note, however, that only the volume of Bo actually matters in this<br />expression, not the actual values of ylow<br />o<br />o<br />. Equation (34) also reveals that the improvement is a discontinuous<br />function of the observations: indeed, the jthterm in the product jumps from yupp<br />goes from 0+to 0. The increment −ylow<br />respect to the jthconstraint.<br />and yupp<br />c,j<br />to yupp<br />c,j− ylow<br />c,j&gt; yupp<br />c,j<br />when ξc,j(X1)<br />c,jcan be thought of as a reward associated to finding a point which is feasible with</p>  <p>Page 33</p> <p>32<br />The value of |H1| when X1is feasible is<br />|H1| = |Bo| ·<br />?|Bc| −??B−<br />??? is the volume of the feasible subset of Bc, B−<br />c<br />???<br />+<br />?<br />j≤p<br />?<br />min<br />?<br />ξo,j(X1),yupp<br />o,j<br />?<br />− max<br />?<br />ξo,j(X1),ylow<br />o,j<br />??<br />·<br />??B−<br />c<br />??,<br />(35)<br />where<br />side of (35) is the improvement associated to the domination of the entire unfeasible subset of B = Bo× Bc; the second<br />term measures the improvement in the space of objective values.<br />???B−<br />c<br />??? =?q<br />j=1<br />???ylow<br />c,j<br />c = Bc∩]−∞;0]q. The first term in the right-hand<br />B An adaptive procedure to set Boand Bc<br />This section describes the adaptive numerical procedure that is used, in our numerical experiments, to define the hyper-<br />rectangles Boand Bc. As said in Section 3.3, these hyper-rectangles are defined using estimates of the range of the objective<br />and constraint functions, respectively. To this end, we will use the available evaluations results, together with posterior<br />quantiles provided by our Gaussian process models on the set of candidate points Xn (defined in Section 4.2).<br />More precisely, assume that n evaluation results ξ(Xi), 1 ≤ i ≤ n, are available. Then, we define the corners of Bo by<br /><br /><br />for 1 ≤ i ≤ p, and the corners of Bc by<br /><br /><br />for 1 ≤ j ≤ q, where λo and λc are positive numbers.<br /><br />ylow<br />o,i,n= min<br />yupp<br />o,i,n= max<br />?<br />mini≤nξo,i(Xi), minx∈Xn?ξo, i, n(x) − λoσo, i, n(x)<br />?<br />,<br />?<br />maxi≤nξo,i(Xi), maxx∈Xn?ξo, i, n(x) + λoσo, i, n(x)<br />?<br />,<br />(36)<br /><br />ylow<br />c,j,n= min<br />yupp<br />c,j,n= max<br />?<br />0, mini≤nξc,j(Xi), minx∈Xn?ξc, j, n(x) − λcσc, j, n(x)<br />?<br />,<br />?<br />0, maxi≤nξc,j(Xi), maxx∈Xn?ξc, j, n(x) + λcσc, j, n(x)<br />?<br />,<br />(37)<br />C Mono-objective benchmark result tables<br />In Section 5.3, only the best results for both the “Local” and the “Regis” groups of algorithms were shown. In this Appendix,<br />we present the full results. Tables 11 and 12, and Tables 13 and 14 present respectively the results obtained with the local<br />optimization algorithms and the results obtained by Regis (2014) on the single-objective benchmark test problems (see<br />Table 1). Table 11 and Table 12 show the performances for finding feasible solutions and for reaching the targets specified<br />in Table 1 for the COBYLA, Active-Set, Interior-Point and SQP algorithms. Similarly, Table 13 and Table 14 show<br />the performances for finding feasible solutions and for reaching the targets for the COBRA-Local, COBRA-Global and<br />Extended-ConstrLMSRBF algorithms of Regis (2014).<br />D Modified g3mod, g10 and PVD4 test problems<br />We detail here the modified formulations of the g3mod, g10 and PVD4 problems that were used in Section 5.3 to overcome<br />the modeling problems with BMOO. Our modifications are shown in boldface. The rationale of the modifications is to<br />smooth local jumps.<br />– modified-g3mod problem<br />?f(x) = −plog((√d)d?d<br />i=1xi)0.1<br />c(x) = (?d<br />i=1x2<br />i) − 1<br />– modified-g10 problem<br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br />f(x) = x1+ x2+ x3<br />c1(x) = 0.0025(x4+ x6) − 1<br />c2(x) = 0.0025(x5+ x7− x4) − 1<br />c3(x) = 0.01(x8− x5) − 1<br />c4(x) = plog(100x1− x1x6+ 833.33252x4− 83333.333)7<br />c5(x) = plog(x2x4− x2x7− 1250x4+ 1250x5)7<br />c6(x) = plog(x3x5− x3x8− 2500x5+ 1250000)7</p>  <p>Page 34</p> <p>33<br />Pbm<br />g1<br />g3mod<br />g5mod<br />g6<br />g7<br />g8<br />g9<br />g10<br />g13mod<br />g16<br />g18<br />g19<br />g24<br />SR7<br />WB4<br />PVD4<br />COBYLA<br />52.3 (102.3)<br />386.1 (645.8)<br />30.7 (23.0)<br />39.7 (12.7)<br />162.4 (175.7)<br />53.3 (77.1)<br />95.2 (104.7)<br />14.5 (3.5)<br />53.9 (68.8)<br />31.5 (20.4)<br />345.0 (275.7)<br />31.4 (19.5)<br />7.7 (10.2)<br />30.0 (50.1)<br />71.8 (82.5)<br />50.8 (70.2)<br />active-set<br />15.0 (0.0)<br />643.2 (248.9)<br />35.0 (5.5)<br />29.7 (5.0)<br />109.4 (11.2)<br />17.6 (5.0)<br />313.7 (84.4)<br />53.6 (41.9)<br />74.0 (59.5)<br />38.0 (15.0)<br />114.5 (41.5)<br />21.8 (7.5)<br />5.2 (5.3)<br />27.5 (3.9)<br />125.7 (71.0)<br />51.3 (27.7)<br />interior-point<br />128.4 (27.8)<br />342.3 (66.3)<br />41.3 (16.9)<br />99.7 (14.3)<br />146.0 (18.1)<br />12.1 (7.7)<br />170.9 (42.9)<br />469.8 (393.8)<br />21.4 (17.1)<br />100.9 (160.3)<br />70.3 (22.2)<br />291.3 (57.9)<br />4.0 (3.5)<br />78.6 (23.1)<br />93.5 (48.9)<br />59.1 (43.5)<br />sqp<br />15.0 (0.0)<br />794.3 (53.7)<br />38.5 (10.5)<br />32.6 (5.4)<br />107.6 (9.3)<br />19.6 (8.5)<br />194.5 (60.2)<br />144.6 (132.3)<br />69.4 (62.4)<br />40.7 (17.1)<br />101.9 (19.8)<br />19.7 (6.1)<br />5.1 (5.2)<br />27.1 (3.6)<br />76.6 (21.9)<br />7.6 (4.8)<br />30<br />28<br />22<br />26<br />28<br />28<br />25<br />2<br />30<br />27<br />26<br />19<br />30<br />29<br />27<br />12<br />30<br />30<br />30<br />30<br />30<br />28<br />30<br />9<br />30<br />30<br />30<br />30<br />30<br />30<br />30<br />3<br />30<br />30<br />30<br />30<br />30<br />30<br />30<br />12<br />30<br />22<br />30<br />30<br />30<br />30<br />30<br />30<br />30<br />30<br />30<br />30<br />30<br />30<br />30<br />25<br />30<br />30<br />30<br />30<br />30<br />30<br />30<br />26<br />Table 11: Number of evaluations to find a first feasible point for the COBYLA, Active-Set, Interior-Point and SQP local<br />optimization algorithms. See Table 2 for conventions.<br />Pbm<br />g1<br />g3mod<br />g5mod<br />g6<br />g7<br />g8<br />g9<br />g10<br />g13mod<br />g16<br />g18<br />g19<br />g24<br />SR7<br />WB4<br />PVD4<br />COBYLA<br />212.9 (225.8)<br />1312.3 (1123.6)<br />53.4 (20.3)<br />41.0 (11.1)<br />495.5 (461.3)<br />79.5 (84.6)<br />144.9 (143.7)<br />- (-)<br />191.9 (209.7)<br />60.0 (65.2)<br />383.0 (389.3)<br />912.1 (685.8)<br />17.5 (8.9)<br />62.5 (52.1)<br />247.1 (176.2)<br />58.0 (35.4)<br />active-set<br />22.0 (7.7)<br />760.5 (79.8)<br />35.8 (4.3)<br />29.7 (5.0)<br />109.4 (11.2)<br />30.5 (2.1)<br />334.5 (84.0)<br />- (-)<br />153.9 (46.6)<br />85.1 (41.1)<br />101.0 (30.2)<br />61.3 (12.4)<br />14.7 (3.9)<br />27.5 (3.9)<br />162.0 (73.1)<br />54.0 (25.1)<br />interior-point<br />349.7 (57.0)<br />356.9 (65.1)<br />54.8 (11.7)<br />99.7 (14.3)<br />147.2 (18.2)<br />59.3 (87.0)<br />179.3 (42.0)<br />- (-)<br />122.5 (70.3)<br />400.0 (242.1)<br />149.1 (39.4)<br />335.5 (65.4)<br />10.4 (5.3)<br />80.2 (22.1)<br />168.2 (94.4)<br />146.7 (115.2)<br />sqp<br />22.0 (7.7)<br />794.3 (53.7)<br />41.8 (7.5)<br />32.6 (5.4)<br />107.6 (9.3)<br />55.8 (27.0)<br />194.5 (60.2)<br />658.3 (316.7)<br />147.6 (75.1)<br />152.2 (53.2)<br />97.5 (23.8)<br />61.3 (12.4)<br />16.4 (5.3)<br />27.1 (3.6)<br />78.3 (18.0)<br />54.7 (27.5)<br />76 20<br />30<br />30<br />30<br />30<br />18<br />30<br />0<br />25<br />13<br />21<br />30<br />16<br />30<br />30<br />26<br />6<br />16<br />22<br />26<br />20<br />4<br />22<br />0<br />23<br />27<br />14<br />16<br />18<br />28<br />24<br />2<br />24<br />30<br />30<br />30<br />2<br />30<br />0<br />24<br />14<br />21<br />30<br />17<br />30<br />29<br />3<br />30<br />30<br />30<br />30<br />4<br />30<br />18<br />22<br />30<br />21<br />30<br />17<br />30<br />30<br />23<br />Table 12: Number of evaluations to reach the target for the COBYLA, Active-Set, Interior-Point and SQP local opti-<br />mization algorithms. See Table 2 for conventions.<br />– modified-PVD4 problem<br /><br /><br /><br /><br /><br /><br /><br />f(x) = 0.6224x1x3x4+ 1.7781x2x2<br />c1(x) = −x1+ 0.0193x3<br />c2(x) = −x2+ 0.00954x3<br />c3(x) = plog(−πx2<br />3+ 3.1661x2<br />1x4+ 19.84x2<br />1x3<br />3x4− 4/3πx3<br />3+ 1296000)7<br />Note that the above defined problems make use of the plog function defined below (see Regis (2014)).<br />plog(x) =<br />?log(1 + x)<br />if x ≥ 0<br />−log(1 − x) otherwise</p>  <p>Page 35</p> <p>34<br />Pbm<br />g1<br />g3mod<br />g5mod<br />g6<br />g7<br />g8<br />g9<br />g10<br />g13mod<br />g16<br />g18<br />g19<br />g24<br />SR7<br />WB4<br />PVD4<br />COBRA-Local<br />3015.0 (0.0)<br />3023.5 (0.2)<br />306.4 (0.1)<br />3010.9 (0.3)<br />3047.5 (4.6)<br />306.5 (0.2)<br />3021.5 (1.9)<br />3022.8 (1.5)<br />30 9.4 (0.8)<br />3014.7 (2.4)<br />30 108.6 (6.5)<br />3016.5 (0.5)<br />301.3 (0.1)<br />309.5 (0.1)<br />3037.4 (5.9)<br />30 7.9 (0.4)<br />COBRA-Global<br />30 15.0 (0.0)<br />3023.5 (0.2)<br />30 6.4 (0.1)<br />3010.9 (0.3)<br />3047.5 (4.7)<br />306.5 (0.2)<br />3021.5 (1.9)<br />3022.8 (1.5)<br />30 9.4 (0.8)<br />3014.7 (2.4)<br />30108.6 (6.5)<br />30 16.5 (0.5)<br />301.3 (0.1)<br />30 9.5 (0.1)<br />30 37.4 (5.9)<br />307.9 (0.4)<br />Extended-ConstrLMSRBF<br />3019.1 (0.4)<br />30 31.2 (0.3)<br />309.6 (0.3)<br />30 11.9 (0.2)<br />3039.8 (2.9)<br />305.2 (0.2)<br />3023.1 (2.3)<br />3051.1 (6.5)<br />308.6 (0.7)<br />3019.6 (1.8)<br />30 122.0 (5.6)<br />30 20.8 (0.8)<br />301.3 (0.1)<br />30 12.4 (0.4)<br />30 25.0 (4.1)<br />30 10.4 (0.7)<br />Table 13: Number of evaluations to find a first feasible point for the COBRA-Local, COBRA-Global and Extended-<br />ConstrLMSRBF optimization algorithms. These results are taken from (Regis, 2014).<br />Pbm<br />g1<br />g3mod<br />g5mod<br />g6<br />g7<br />g8<br />g9<br />g10<br />g13mod<br />g16<br />g18<br />g19<br />g24<br />SR7<br />WB4<br />PVD4<br />COBRA-Local<br />7 387.8 (-)<br />6451.1 (-)<br />30 12.9 (0.5)<br />30 53.6 (14.0)<br />30 199.5 (20.7)<br />30 30.3 (2.8)<br />28275.5 (-)<br />30 276.4 (43.6)<br />30221.7 (35.6)<br />30 38.8 (9.3)<br />24 195.9 (-)<br />30698.5 (75.3)<br />309.0 (0.0)<br />30 35.0 (2.7)<br />30164.6 (12.2)<br />28 212.2 (-)<br />COBRA-Global<br />30125.2 (15.3)<br />6440.0 (-)<br />3016.6 (1.8)<br />30 62.5 (10.5)<br />3099.8 (5.7)<br />30 31.2 (2.5)<br />30176.4 (26.3)<br />29 193.7 (-)<br />30169.0 (19.1)<br />30 46.3 (13.5)<br />23 212.8 (-)<br />30850.9 (70.6)<br />309.0 (0.0)<br />3033.5 (1.6)<br />30202.0 (13.0)<br />30155.4 (38.2)<br />Extended-ConstrLMSRBF<br />0 &gt; 500 (-)<br />30 141.7 (8.6)<br />3040.3 (1.4)<br />26 101.2 (-)<br />30264.5 (34.2)<br />3046.2 (6.2)<br />29 294.0 (-)<br />24394.3 (-)<br />30146.4 (29.2)<br />3038.4 (3.6)<br />21 276.0 (-)<br />0&gt; 1000 (-)<br />3091.9 (6.0)<br />0 &gt; 500 (-)<br />30238.6 (20.0)<br />29263.5 (-)<br />Table 14: Number of evaluations to reach the target for the COBRA-Local, COBRA-Global and Extended-<br />ConstrLMSRBF optimization algorithms. These results are taken from (Regis, 2014). See Table 2 for conventions.</p>   </div> <div id="rgw20_56ab9d61e091d" class="c-box pub-resource-container js-toggle" style=""> <h4 class="lf js-expand-list"><small><a href="javascript:" class="lf">View other sources <span class="ico-expand-list"></span></a></small></h4> <h4 class="lf js-collapse-list hidden"><small><a href="javascript:" class="lf">Hide other sources <span class="ico-collapse-list"></span></a></small></h4> <div class="clear"></div> <div class="scroll-wrapper hidden"> <ul class="files-list c-list" id="rgw21_56ab9d61e091d">  <li class="c-list-item pub-resource-item"  data-type="fulltext" id="rgw22_56ab9d61e091d"> <span class="ico-pub"></span> <div class="file-content"> <div class="download"> <a href="https://hal.archives-ouvertes.fr/hal-01207679/file/paper_bmoo.pdf" target="_blank" rel="nofollow" class="publication-viewer" title="A Bayesian approach to constrained single- and multi-objective optimization">A Bayesian approach to constrained single- and mul...</a> </div>  <div class="details">   Available from <a href="https://hal.archives-ouvertes.fr/hal-01207679/file/paper_bmoo.pdf" target="_blank" rel="nofollow">hal.archives-ouvertes.fr</a>  </div>    </div> </li>  </ul> </div> </div> </noscript> <div class="clearfix"> <div class="action-container">  </div> <div class="pub-legal"> Data provided are for informational purposes only. Although carefully collected, accuracy cannot be guaranteed. The impact factor represents a rough estimation of the journal's impact factor and does not reflect the actual current impact factor. Publisher conditions are provided by RoMEO. Differing provisions from the publisher's actual policy or licence agreement may be applicable. </div>  <div id="rgw29_56ab9d61e091d" class="citations-container"> <div class="tab-container"> <ul class="tab-list"> <li class="lf tab-item tab-item-active js-citations"> <a href="javascript:void(0);" class="tab-link"> References  <small> (70)  </small> </a> </li>   <li class="lf tab-item"> <div class="tab-link tab-link-disabled js-cited-in-tooltip"> Cited In <small>(0)</small></div> </li>   <li class="rf"> <div class="dropdown js-citations-sorter dropdown-right-align" style="position: relative; bottom: -1px;"> <a href="javascript:void(0);" class="dropdown-toggle"> Sorted by: <strong class="js-current-sorting"> Order of availability  </strong> <span class="caret"></span> </a> <ul class="dropdown-menu"> <li><a href="javascript:void(0);" data-sort="normal">Order of availability</a></li> <li><a href="javascript:void(0);" data-sort="original">Appearance in publication</a></li> </ul> </div> </li>  </ul> <div class="tab-section tab-section-active js-citations-list-container"> <div id="rgw30_56ab9d61e091d" class="pub-citations-list">   <div class="publication-detail-sidebar-empty">This research doesn't cite any other publications.</div>   <a class="show-more-rebranded js-show-more rf text-gray-lighter">Show more</a> <div class="ajax-loading-small list-loading" style="display: none;"></div>  <div class="clearfix"></div> </div> </div> </div> </div> </div> </div> <div class="clearfix">     <div id="rgw24_56ab9d61e091d" class="c-box pub-resource-container js-toggle" style="display: none;"> <h4 class="lf js-expand-list"><small><a href="javascript:" class="lf">View other sources <span class="ico-expand-list"></span></a></small></h4> <h4 class="lf js-collapse-list hidden"><small><a href="javascript:" class="lf">Hide other sources <span class="ico-collapse-list"></span></a></small></h4> <div class="clear"></div> <div class="scroll-wrapper hidden"> <ul class="files-list c-list" id="rgw25_56ab9d61e091d">  </ul> </div> </div>   <div id="rgw16_56ab9d61e091d" class="similar-publications"> <h2>Similar Publications</h2> <ul class="list-bordered">  <li class="c-list-item li-publication-teaser" id="rgw17_56ab9d61e091d"> <div> <h5> <a href="publication/291422735_Multiobjective_Optimization_Model_for_Maximizing_Sustainability_of_Existing_Buildings" class="color-inherit ga-similar-publication-title"><span class="publication-title">Multiobjective Optimization Model for Maximizing Sustainability of Existing Buildings</span></a>  </h5>  <div class="authors"> <a href="researcher/2059020655_Moatassem_Abdallah" class="authors ga-similar-publication-author">Moatassem Abdallah</a>, <a href="researcher/9619124_Khaled_El-Rayes" class="authors ga-similar-publication-author">Khaled El-Rayes</a>  </div>  </div> <div class="clear"></div> </li>  <li class="c-list-item li-publication-teaser" id="rgw18_56ab9d61e091d"> <div> <h5> <a href="publication/291386111_On_Benson%27s_scalarization_in_multiobjective_optimization" class="color-inherit ga-similar-publication-title"><span class="publication-title">On Benson’s scalarization in multiobjective optimization</span></a>  </h5>  <div class="authors"> <a href="researcher/2095267012_Majid_Soleimani-damaneh" class="authors ga-similar-publication-author">Majid Soleimani-damaneh</a>, <a href="researcher/2080468840_Moslem_Zamani" class="authors ga-similar-publication-author">Moslem Zamani</a>  </div>  </div> <div class="clear"></div> </li>  <li class="c-list-item li-publication-teaser" id="rgw19_56ab9d61e091d"> <div> <h5> <a href="publication/283474033_A_two-stage_multiobjective_optimization_algorithm_for_porous_air_bearing_design" class="color-inherit ga-similar-publication-title"><span class="publication-title">A two-stage multiobjective optimization algorithm for porous air bearing design</span></a>  </h5>  <div class="authors"> <a href="researcher/79095497_Nenzi_Wang" class="authors ga-similar-publication-author">Nenzi Wang</a>, <a href="researcher/2083969832_H-Y_Chen" class="authors ga-similar-publication-author">H.-Y. Chen</a>  </div>  </div> <div class="clear"></div> </li>  </ul> </div> </div> </div> </div> </div></div></div>
<div class="clear"></div><div id="rgw32_56ab9d61e091d" class="default-footer"> <div id="footer" class="clearfix"> <span class="footer-left"> &copy; 2008&dash;2016 researchgate.net. All rights reserved. </span> <span class="footer-right"> <a href="https://www.researchgate.net/about">About us</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="https://www.researchgate.net/contact">Contact us</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="careers">Careers</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="developers">Developers</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="blog" target="_blank">News</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="application.PrivacyPolicy.html">Privacy</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="application.TermsAndConditions.html">Terms</a> <span class="footer-link-separator" style="padding: 0 5px;">&nbsp;|&nbsp;</span> <a href="advertising?_ref=ft">Advertising</a> <span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="recruiters?_ref=ft">Recruiting</a> </span> </div>  </div></div>
<div id="rgw33_56ab9d61e091d">  <div class="header-wrapper-logged-out"> <div id="header"> <div class="header-content"> <a href="" class="g-l-logo"> <svg width="149" height="19"> <image xlink:href="https://c5.rgstatic.net/m/235107188705592/images/template/brand-header-logo.svg" src="https://c5.rgstatic.net/m/238113351022438/images/template/brand-header-logo.png" width="149" height="19"/> </svg> </a> <a href="" class="g-l-logo-ico"> <svg width="127" height="17" viewbox="0 0 127 22"> <image xlink:href="https://c5.rgstatic.net/m/235107188705592/images/template/brand-header-logo.svg" src="https://c5.rgstatic.net/m/238113351022438/images/template/brand-header-logo.png" width="127" height="17"/> </svg> </a> <div id="rgw34_56ab9d61e091d" class="header-login-wrapper js-header-login"> <div class="dropdown-right-align"> <div class="login-signup-container lf"> <a href="https://www.researchgate.net/signup.SignUp.html?ev=su_chnl_index&amp;hdrsu=1&amp;_sg=TXSisDefaqz6P6SDC7KWhRlR_x4Fp8Aaqw9ADbfcm8QMzfu5sBolGKa0W1KgqcpK" class="dropdown-toggle lf">Join for free</a> </div> <div class="dropdown lf" style="height: 20px;"> <a href="https://www.researchgate.net/application.Login.html" class="js-login-url dropdown-toggle lf">Log in <span class="caret"></span></a> <div class="dropdown-menu"> <div class="header-login-form-wrapper"> <!--[if IE 6]><p class="box-warning" style="margin-bottom: 0;">Sorry, ResearchGate no longer supports the version of Internet Explorer you are using. <a href="http://whatbrowser.org/" rel="nofollow" target="_blank">Update your web browser</a> and then log in. </p><![endif]--> <form method="post" action="https://www.researchgate.net/application.Login.html" class="form-big header-login-form js-login-form" name="loginForm" id="headerLoginForm"> <input type="hidden" name="request_token" value="0xjqYPPWKVXIHSQM6lDfnD0CRYqjKwd3M/Hshd19mnPq5v9bfNEMIA50eaAiTX9tPktx2jUTpLry+lbkEwUCpbBSfEfB9IU65QP61ajPg2dkUSuwlxKs3kDBxLfloCTRUkm4Wv0XBn95MCh4zKq3oakVr72aBqQJdfhdYEBUEif/ft8MH4YgMiFPBBPKmroUDEJm7AqcjxBiQSbBgJr8DrVLdp1rEPXa+1jldd1ECguy+XM8KmgwrFerbHk8ci8svuzol2zCtis1ky3Kwh7sMu2/jmTEpq3m9FIRSVi0Nho="/> <input type="hidden" name="urlAfterLogin" value="publication/282570552_A_Bayesian_approach_to_constrained_single-_and_multi-objective_optimization"/> <input type="hidden" name="invalidPasswordCount" value="0"/> <input type="hidden" name="headerLogin" value="yes"/> <label for="input-header-login">Email</label> <div class="login-input"> <div class="info-tip-wrapper"> <span class="ico-info js-info"></span> </div> <input type="email" value="" name="login" class="login js-login-input text" id="input-header-login" tabindex="1"/> </div> <div class="clear"></div> <label class="lf" for="input-header-password"> Password </label> <a class="rf forgot-password js-forgot-password" href="application.LostPassword.html">Forgot password?</a> <div class="clear"></div> <input type="password" value="" name="password" class="password js-password-input text" id="input-header-password" tabindex="2"/> <div class="clear"></div> <label class="remember-me" for="headerLoginCookie"> <input type="checkbox" checked="checked" value="yes" name="setLoginCookie" class="lf checkbox" id="headerLoginCookie" tabindex="3"/> Keep me logged in </label> <div class="clear"></div> <input value="Log in" name="loginSubmit" class="btn btn-promote btn-fullwidth btn-large allow-leave js-submit-button" type="submit" tabindex="4"/> </form> <div class="connectors"> <div class="text">or log in with</div> <div class="connector-actions"> <a href="connector/linkedin/" class="li-connect js-li-connect" data-redirect-url="cHVibGljYXRpb24vMjgyNTcwNTUyX0FfQmF5ZXNpYW5fYXBwcm9hY2hfdG9fY29uc3RyYWluZWRfc2luZ2xlLV9hbmRfbXVsdGktb2JqZWN0aXZlX29wdGltaXphdGlvbg%3D%3D"> <span class="icon ico-linkedin-round-grey"></span> <span class="icon ico-linkedin-round"></span> </a> <a href="connector/facebook/" class="fb-connect middle js-fb-connect" data-redirect-url="cHVibGljYXRpb24vMjgyNTcwNTUyX0FfQmF5ZXNpYW5fYXBwcm9hY2hfdG9fY29uc3RyYWluZWRfc2luZ2xlLV9hbmRfbXVsdGktb2JqZWN0aXZlX29wdGltaXphdGlvbg%3D%3D"> <span class="icon ico-facebook-round-grey"></span> <span class="icon ico-facebook-round"></span> </a> <a href="connector/google/" class="g-connect js-g-connect" data-redirect-url="cHVibGljYXRpb24vMjgyNTcwNTUyX0FfQmF5ZXNpYW5fYXBwcm9hY2hfdG9fY29uc3RyYWluZWRfc2luZ2xlLV9hbmRfbXVsdGktb2JqZWN0aXZlX29wdGltaXphdGlvbg%3D%3D"> <span class="icon ico-google-round-grey"></span> <span class="icon ico-google-round"></span> </a> </div> </div> </div> </div> </div> </div> </div> </div> </div> <script type="application/ld+json">
{ "@context" : "http://schema.org",
  "@type" : "Organization",
  "name" : "ResearchGate",
  "url" : "http://www.researchgate.net",
  "logo" : "http://www.researchgate.net/images/template/rg_logo_square_brand.png",
  "sameAs" : [ "https://www.facebook.com/ResearchGate",
    "https://twitter.com/ResearchGate",
    "https://plus.google.com/+researchgate",
    "https://www.linkedin.com/company/researchgate"] 
}
</script> </div> </div><div class="c-signup-bar" id="rgw35_56ab9d61e091d"> <div class="banner-contents">   <span class="message">ResearchGate is the professional network for scientists and researchers.</span> <a href="signup.SignUp.html?ev=su_banner" class="btn btn-large btn-promote">Join for free</a>  </div> </div></div>
<script>
rgConfig.backendTime = 393;
</script>
<script src="//c5.rgstatic.net/m/2277196935388619/javascript/lib/yui3/yui/yui-min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/21832295316281274/javascript/yuiLoaderConfig-min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/23178613132105398/javascript/vendor/babel-core/browser-polyfill.min.js" type="text/javascript"></script>
<script>
(function (){
if (typeof YRG === "undefined") {
var xmlHttpRequest = new XMLHttpRequest();
xmlHttpRequest.open("post", "go.Error.html");
xmlHttpRequest.setRequestHeader("Content-Type", "application/json");
xmlHttpRequest.setRequestHeader("Accept", "application/json"); var loadedScripts = "";
if (window.performance && window.performance.getEntriesByType) {
    var result = [];
    var resources = performance.getEntriesByType("resource");
    for (var i in resources) {
        if (resources.hasOwnProperty(i)) {
            result.push({
                name: resources[i].name,
                duration: resources[i].duration
            });
        }
    }
    loadedScripts += "&loadedScripts=" + encodeURIComponent(JSON.stringify(result));
}
if (typeof YUI === "undefined") {
    loadedScripts += "&yuiLoaded=false";
} else {
    loadedScripts += "&yuiLoaded=true";
}
xmlHttpRequest.send("Type=InformationException&message=" + encodeURIComponent("Error loading YUI") + loadedScripts);
}
})();
</script>
<script>if (typeof YRG !== 'undefined') { YRG.use('rg-base',function(Y){Y.applyConfig({ignore: ["css-rg","css-rg2","css-ie","css-modules-publicprofile"]});Y.use(["rg.core.pagespeed.Monitoring"],function(Y){(function(){Y.rg.createInitialWidget({"data":{"content":{"data":{"profileSmallHeader":{"data":{"profileBadge":{"data":{"profileUrl":"researcher\/2077554322_Paul_Feliot","fullname":"Paul Feliot","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2549355721578\/images\/template\/default\/profile\/profile_default_m.png","profileStats":[null,{"data":{"publicationCount":3,"widgetId":"rgw5_56ab9d61e091d"},"id":"rgw5_56ab9d61e091d","partials":[],"templateName":"publicliterature\/stubs\/PublicLiteratureAuthorPublicationCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicLiteratureAuthorPublicationCount.html?authorUid=2077554322","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},null],"widgetId":"rgw4_56ab9d61e091d"},"id":"rgw4_56ab9d61e091d","partials":[],"templateName":"publicprofile\/stubs\/ProfileBadge.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicLiteratureAuthorBadge.html?authorUid=2077554322","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw3_56ab9d61e091d"},"id":"rgw3_56ab9d61e091d","partials":[],"templateName":"publicprofile\/stubs\/ProfileSmallHeader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicprofile.ProfileSmallHeader.html?publicationUid=282570552","viewClass":null,"yuiModules":["css-modules-publicprofile"],"stylesheets":["modules\/publicprofile.css"],"_isYUI":true},"publication":{"data":{"publicationUid":282570552,"title":"A Bayesian approach to constrained single- and multi-objective optimization","journalTitle":false,"journalDetailsTooltip":false,"affiliation":false,"type":"Article","details":{"journalInfos":{"journal":"","publicationDate":"09\/2015;","publicationDateRobot":"2015-09","article":""}},"source":false,"publicationActions":null,"publicationCoins":{"data":{"tags":[{"key":"ctx_ver","value":"Z39.88-2004"},{"key":"rft_val_fmt","value":"info:ofi\/fmt:kev:mtx:journal"},{"key":"rfr_id","value":"info:sid\/researchgate.net:researchgate"},{"key":"rft.atitle","value":"A Bayesian approach to constrained single- and multi-objective optimization"},{"key":"rft.date","value":"2015"},{"key":"rft.au","value":"Paul F\u00e9liot,Julien Bect,Emmanuel Vazquez"},{"key":"rft.genre","value":"article"}],"widgetId":"rgw7_56ab9d61e091d"},"id":"rgw7_56ab9d61e091d","partials":[],"templateName":"publicliterature\/stubs\/PublicationCoins.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationCoins.html?publicationUid=282570552","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationAuthors":{"data":{"publicationUid":282570552,"peopleItems":[{"data":{"authorUrl":"researcher\/2077554322_Paul_Feliot","authorNameOnPublication":"Paul F\u00e9liot","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg","imageSize":"s","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Paul F\u00e9liot","profile":{"professionalInstitution":{"professionalInstitutionName":false,"professionalInstitutionUrl":null}},"professionalInstitutionName":false,"professionalInstitutionUrl":null,"url":"researcher\/2077554322_Paul_Feliot","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":true,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":false,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"widgetId":"rgw10_56ab9d61e091d"},"id":"rgw10_56ab9d61e091d","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAuthorItem.html?entityId=2077554322&imageSize=l&enableAuthorInviteButton=0","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"largeTooltip":false,"useRebrandedImageStyle":null,"widgetId":"rgw9_56ab9d61e091d"},"id":"rgw9_56ab9d61e091d","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorItem.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorItem.html?authorUid=2077554322&authorNameOnPublication=Paul%20F%C3%A9liot","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true},{"data":{"authorUrl":"researcher\/14088780_Julien_Bect","authorNameOnPublication":"Julien Bect","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg","imageSize":"s","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Julien Bect","profile":{"professionalInstitution":{"professionalInstitutionName":false,"professionalInstitutionUrl":null}},"professionalInstitutionName":false,"professionalInstitutionUrl":null,"url":"researcher\/14088780_Julien_Bect","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":true,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":false,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"widgetId":"rgw12_56ab9d61e091d"},"id":"rgw12_56ab9d61e091d","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAuthorItem.html?entityId=14088780&imageSize=l&enableAuthorInviteButton=0","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"largeTooltip":false,"useRebrandedImageStyle":null,"widgetId":"rgw11_56ab9d61e091d"},"id":"rgw11_56ab9d61e091d","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorItem.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorItem.html?authorUid=14088780&authorNameOnPublication=Julien%20Bect","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true},{"data":{"authorUrl":"researcher\/26760014_Emmanuel_Vazquez","authorNameOnPublication":"Emmanuel Vazquez","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg","imageSize":"s","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Emmanuel Vazquez","profile":{"professionalInstitution":{"professionalInstitutionName":false,"professionalInstitutionUrl":null}},"professionalInstitutionName":false,"professionalInstitutionUrl":null,"url":"researcher\/26760014_Emmanuel_Vazquez","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":true,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":false,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"widgetId":"rgw14_56ab9d61e091d"},"id":"rgw14_56ab9d61e091d","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAuthorItem.html?entityId=26760014&imageSize=l&enableAuthorInviteButton=0","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"largeTooltip":false,"useRebrandedImageStyle":null,"widgetId":"rgw13_56ab9d61e091d"},"id":"rgw13_56ab9d61e091d","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorItem.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorItem.html?authorUid=26760014&authorNameOnPublication=Emmanuel%20Vazquez","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true}],"hasMore":false,"nextOffset":6,"useRebrandedImageStyle":null,"widgetId":"rgw8_56ab9d61e091d"},"id":"rgw8_56ab9d61e091d","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorList.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorList.html?publicationUid=282570552&context=pubdetail_authors_xflw&showContactAuthorButton=1","viewClass":"views.publicliterature.PublicationDetailAuthorListView","yuiModules":["rg.views.publicliterature.PublicationDetailAuthorListView"],"stylesheets":[],"_isYUI":true},"publicationAbstract":{"data":{"publicationUid":282570552,"abstract":"<noscript><\/noscript><div>This article addresses the problem of derivative-free (single- or multi-objective) optimization subject to multiple inequality constraints. Both the objective and constraint functions are assumed to be smooth, non-linear and expensive to evaluate. As a consequence, the number of evaluations that can be used to carry out the optimization is very limited, as in complex industrial design optimization problems. The method we propose to overcome this difficulty has its roots in the Bayesian and the multiobjective optimization literatures. More specifically, an extended domination rule is used to handle the constraints and a corresponding Bayesian expected hyper-volume improvement sampling criterion is proposed. This new criterion extends existing Bayesian sampling criteria to the multi-objective constrained case, and makes it possible to start the algorithm without an initial feasible point. The calculation and optimization of the criterion are performed using Sequential Monte Carlo techniques. In particular, an algorithm similar to the subset simulation method, which is well known in the field of structural reliability, is used to estimate the expected hyper-volume improvement criterion. The method, which we call BMOO (for Bayesian Multi-Objective Optimization), is compared to state-of-the-art algorithms for single-objective and multi-objective constrained optimization problems.<\/div>","canEdit":false,"isAdmin":false,"isArtifact":false,"showFullAbstract":false,"widgetId":"rgw15_56ab9d61e091d"},"id":"rgw15_56ab9d61e091d","partials":[],"templateName":"publicliterature\/stubs\/PublicationAbstract.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationAbstract.html?publicationUid=282570552","viewClass":"views.publicliterature.PublicationAbstractView","yuiModules":["rg.views.publicliterature.PublicationAbstractView"],"stylesheets":[],"_isYUI":true},"publicationKeywords":null,"publicationState":null,"isGuest":true,"isAdminEditingAllowed":false,"isArtifact":false,"figureListWidget":null,"previewImage":"https:\/\/i1.rgstatic.net\/publication\/282570552_A_Bayesian_approach_to_constrained_single-_and_multi-objective_optimization\/links\/569e3d4308ae16fdf07c454f\/smallpreview.png","nativeAdDisclosure":null,"showFollowPublicationButton":false,"followPublicationPromo":"","widgetId":"rgw6_56ab9d61e091d"},"id":"rgw6_56ab9d61e091d","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailItem.html","templateExtensions":["generalHelpers"],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailItem.html?publicationUid=282570552&showActionBar=0&showContactAuthorButton=1&showRequestFulltextExperience=0&showNoRgAuthorsRequestFulltextExperience=0&showFollowPublicationPromo=0","viewClass":"views.publicliterature.PublicationDetailItemView","yuiModules":["rg.views.publicliterature.PublicationDetailItemView"],"stylesheets":[],"_isYUI":true},"similarPublications":{"data":{"publicationListItems":[{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":2059020655,"url":"researcher\/2059020655_Moatassem_Abdallah","fullname":"Moatassem Abdallah","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":9619124,"url":"researcher\/9619124_Khaled_El-Rayes","fullname":"Khaled El-Rayes","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Jan 2016","journal":"Journal of Management in Engineering","showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/291422735_Multiobjective_Optimization_Model_for_Maximizing_Sustainability_of_Existing_Buildings","usePlainButton":true,"publicationUid":291422735,"feedStubs":null,"hasFeedStubs":false,"impactPoints":"0.93","url":"publication\/291422735_Multiobjective_Optimization_Model_for_Maximizing_Sustainability_of_Existing_Buildings","title":"Multiobjective Optimization Model for Maximizing Sustainability of Existing Buildings","displayTitleAsLink":true,"authors":[{"id":2059020655,"url":"researcher\/2059020655_Moatassem_Abdallah","fullname":"Moatassem Abdallah","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":9619124,"url":"researcher\/9619124_Khaled_El-Rayes","fullname":"Khaled El-Rayes","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["Journal of Management in Engineering 01\/2016;  DOI:10.1061\/(ASCE)ME.1943-5479.0000425"],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/291422735_Multiobjective_Optimization_Model_for_Maximizing_Sustainability_of_Existing_Buildings","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/291422735_Multiobjective_Optimization_Model_for_Maximizing_Sustainability_of_Existing_Buildings\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw17_56ab9d61e091d"},"id":"rgw17_56ab9d61e091d","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=291422735","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":2095267012,"url":"researcher\/2095267012_Majid_Soleimani-damaneh","fullname":"Majid Soleimani-damaneh","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2080468840,"url":"researcher\/2080468840_Moslem_Zamani","fullname":"Moslem Zamani","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Jan 2016","journal":"Optimization Letters","showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/291386111_On_Benson's_scalarization_in_multiobjective_optimization","usePlainButton":true,"publicationUid":291386111,"feedStubs":null,"hasFeedStubs":false,"impactPoints":"0.93","url":"publication\/291386111_On_Benson%27s_scalarization_in_multiobjective_optimization","title":"On Benson\u2019s scalarization in multiobjective optimization","displayTitleAsLink":true,"authors":[{"id":2095267012,"url":"researcher\/2095267012_Majid_Soleimani-damaneh","fullname":"Majid Soleimani-damaneh","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2080468840,"url":"researcher\/2080468840_Moslem_Zamani","fullname":"Moslem Zamani","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["Optimization Letters 01\/2016;  DOI:10.1007\/s11590-016-0999-3"],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/291386111_On_Benson's_scalarization_in_multiobjective_optimization","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/291386111_On_Benson's_scalarization_in_multiobjective_optimization\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw18_56ab9d61e091d"},"id":"rgw18_56ab9d61e091d","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=291386111","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":79095497,"url":"researcher\/79095497_Nenzi_Wang","fullname":"Nenzi Wang","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2083969832,"url":"researcher\/2083969832_H-Y_Chen","fullname":"H.-Y. Chen","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Jan 2016","journal":"Tribology International","showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/283474033_A_two-stage_multiobjective_optimization_algorithm_for_porous_air_bearing_design","usePlainButton":true,"publicationUid":283474033,"feedStubs":null,"hasFeedStubs":false,"impactPoints":"1.94","url":"publication\/283474033_A_two-stage_multiobjective_optimization_algorithm_for_porous_air_bearing_design","title":"A two-stage multiobjective optimization algorithm for porous air bearing design","displayTitleAsLink":true,"authors":[{"id":79095497,"url":"researcher\/79095497_Nenzi_Wang","fullname":"Nenzi Wang","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":2083969832,"url":"researcher\/2083969832_H-Y_Chen","fullname":"H.-Y. Chen","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["Tribology International 01\/2016; 93:355-363. DOI:10.1016\/j.triboint.2015.09.045"],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/283474033_A_two-stage_multiobjective_optimization_algorithm_for_porous_air_bearing_design","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/283474033_A_two-stage_multiobjective_optimization_algorithm_for_porous_air_bearing_design\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw19_56ab9d61e091d"},"id":"rgw19_56ab9d61e091d","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=283474033","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"viewClass":"sidebar","widgetId":"rgw16_56ab9d61e091d"},"id":"rgw16_56ab9d61e091d","partials":[],"templateName":"publicliterature\/stubs\/SimilarPublications.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.SimilarPublications.html?referencePublicationId=282570552&view=sidebar","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationFulltextPreview":null,"publicationResourcesFulltext":{"data":{"publicationUid":282570552,"publicationResourceList":{"data":{"publicationResourceItems":[{"data":{"publicationUid":282570552,"publicationType":"article","linkId":"569e3d4308ae16fdf07c454f","fileName":"A Bayesian approach to constrained single- and multi-objective optimization","fileUrl":"https:\/\/hal.archives-ouvertes.fr\/hal-01207679\/file\/paper_bmoo.pdf","name":"hal.archives-ouvertes.fr","nameUrl":"https:\/\/hal.archives-ouvertes.fr\/hal-01207679\/file\/paper_bmoo.pdf","canRemove":false,"fileIcon":"ico-pub","canPreview":true,"hasPublisherLink":null,"hasMetaData":true,"hide":false,"fulltext":"ico-pub","origin":"publication_list","isLastLink":true,"isUserLink":false,"widgetId":"rgw22_56ab9d61e091d"},"id":"rgw22_56ab9d61e091d","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceItem.html","templateExtensions":["generalHelpers"],"attrs":{"fileRequiredPublicationTypes":["code","coverPage","experimentFindings","method","negativeResults","presentation","rawData","researchProposal","workingPaper","artifact","dataset"]},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceItem.html?publicationUid=282570552&linkId=569e3d4308ae16fdf07c454f&hide=0&disableJavascript=disableJavascript&useAlternativeTemplate=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"widgetId":"rgw21_56ab9d61e091d"},"id":"rgw21_56ab9d61e091d","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceList.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceList.html?publicationUid=282570552&limit=3&disableJavascript=disableJavascript&type=fulltextFile","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"resourceCount":1,"hidden":false,"showMore":false,"fulltext":true,"publicationDownloadCount":{"data":{"value":6,"valueFormatted":"6","widgetId":"rgw23_56ab9d61e091d"},"id":"rgw23_56ab9d61e091d","partials":[],"templateName":"publicliterature\/stubs\/PublicationDownloadCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDownloadCount.html?publicationUid=282570552","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw20_56ab9d61e091d"},"id":"rgw20_56ab9d61e091d","partials":[],"templateName":"publicliterature\/stubs\/PublicationResources.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResources.html?publicationUid=282570552&type=fulltextFile&disableJavascript=1","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationResourcesAttachments":{"data":{"publicationUid":282570552,"publicationResourceList":{"data":{"publicationResourceItems":[],"widgetId":"rgw25_56ab9d61e091d"},"id":"rgw25_56ab9d61e091d","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceList.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceList.html?publicationUid=282570552&limit=3&disableJavascript=disableJavascript&type=attachmentFile","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"resourceCount":0,"hidden":true,"showMore":false,"fulltext":false,"publicationDownloadCount":{"data":{"value":6,"valueFormatted":"6","widgetId":"rgw26_56ab9d61e091d"},"id":"rgw26_56ab9d61e091d","partials":[],"templateName":"publicliterature\/stubs\/PublicationDownloadCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDownloadCount.html?publicationUid=282570552","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw24_56ab9d61e091d"},"id":"rgw24_56ab9d61e091d","partials":[],"templateName":"publicliterature\/stubs\/PublicationResources.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResources.html?publicationUid=282570552&type=attachmentFile","viewClass":"views.publicliterature.PublicationResourcesView","yuiModules":["rg.views.publicliterature.PublicationResourcesView"],"stylesheets":[],"_isYUI":true},"publicationText":{"data":{"hide":false,"pages":[{"page":1,"text":"A Bayesian approach to constrained single- and\nmulti-objective optimization\nPaul F\u00b4 eliot, Julien Bect, Emmanuel Vazquez\nTo cite this version:\nPaul F\u00b4 eliot, Julien Bect, Emmanuel Vazquez. A Bayesian approach to constrained single- and\nmulti-objective optimization. 2016. <hal-01207679v2>\nHAL Id: hal-01207679\nhttps:\/\/hal.archives-ouvertes.fr\/hal-01207679v2\nSubmitted on 5 Jan 2016\nHAL is a multi-disciplinary open access\narchive for the deposit and dissemination of sci-\nentific research documents, whether they are pub-\nlished or not.The documents may come from\nteaching and research institutions in France or\nabroad, or from public or private research centers.\nL\u2019archive ouverte pluridisciplinaire HAL, est\ndestin\u00b4 ee au d\u00b4 ep\u02c6 ot et ` a la diffusion de documents\nscientifiques de niveau recherche, publi\u00b4 es ou non,\n\u00b4 emanant des \u00b4 etablissements d\u2019enseignement et de\nrecherche fran\u00b8 cais ou \u00b4 etrangers, des laboratoires\npublics ou priv\u00b4 es.\nCopyright"},{"page":2,"text":"A Bayesian approach to constrained single- and multi-objective optimization\nPaul FELIOT \u00b7 Julien BECT \u00b7 Emmanuel VAZQUEZ\nAbstract This article addresses the problem of derivative-free (single- or multi-objective) optimization\nsubject to multiple inequality constraints. Both the objective and constraint functions are assumed to\nbe smooth, non-linear and expensive to evaluate. As a consequence, the number of evaluations that\ncan be used to carry out the optimization is very limited, as in complex industrial design optimization\nproblems. The method we propose to overcome this difficulty has its roots in both the Bayesian and\nthe multi-objective optimization literatures. More specifically, we construct a loss function based on an\nextended domination rule to handle the objectives and the constraints simultaneously. Then, we derive\na corresponding (Bayesian) expected hyper-volume improvement sampling criterion. This new sampling\ncriterion makes it possible to build an optimization algorithm that can start without any feasible point.\nThe new sampling criterion reduces to existing Bayesian sampling criteria\u2014the classical Expected Im-\nprovement (EI) criterion and some of its constrained\/multi-objective extensions\u2014as soon as at least one\nfeasible point is available. The calculation and optimization of the criterion are performed using Sequen-\ntial Monte Carlo techniques. In particular, an algorithm similar to the subset simulation method, which\nis well known in the field of structural reliability, is used to estimate the expected hyper-volume im-\nprovement criterion. The method, which we call BMOO (for Bayesian Multi-Objective Optimization), is\ncompared to state-of-the-art algorithms for single-objective and multi-objective constrained optimization\nproblems.\nKeywords Bayesian optimization \u00b7 Expected improvement \u00b7 Kriging \u00b7 Gaussian process \u00b7 Multi-\nObjective \u00b7 Sequential Monte Carlo \u00b7 Subset simulation\n1 Introduction\nThis article addresses the problem of derivative-free multi-objective optimization of real-valued functions\nsubject to multiple inequality constraints. The problem consists in finding an approximation of the set\n\u0393 = {x \u2208 X : c(x) \u2264 0 and ?x?\u2208 X such that f(x?) \u227a f(x)}\nwhere X \u2282 Rdis the search domain, c = (ci)1\u2264i\u2264q is a vector of constraint functions (ci : X \u2192 R),\nc(x) \u2264 0 means that ci(x) \u2264 0 for all 1 \u2264 i \u2264 q, f = (fj)1\u2264j\u2264p is a vector of objective functions\nto be minimized (fj : X \u2192 R), and \u227a denotes the Pareto domination rule (see, e.g., Fonseca and\nFleming, 1998). Both the objective functions fj and the constraint functions ci are assumed to be\n(1)\nPaul Feliot (Ph.D. student) \u2013 E-mail: paul.feliot@irt-systemx.fr\nInstitut de Recherche Technologique SystemX, Palaiseau, France.\nJulien Bect & Emmanuel Vazquez \u2013 E-mail: firstname.lastname@centralesupelec.fr\nLaboratoire des Signaux et Syst\u00e8mes, Gif-sur-Yvette, France"},{"page":3,"text":"2\ncontinuous. The search domain X is assumed to be compact\u2014typically, X is a hyper-rectangle defined\nby bound constraints. Moreover, the objective and constraint functions are regarded as black boxes\nand, in particular, we assume that no gradient information is available. Finally, the objective and the\nconstraint functions are assumed to be expensive to evaluate, which arises for instance when the values\nf(x) and c(x), for a given x \u2208 X, correspond to the outputs of a computationally expensive computer\nprogram. In this setting, the emphasis is on building optimization algorithms that perform well under a\nvery limited budget of evaluations (e.g., a few hundred evaluations).\nWe adopt a Bayesian approach to this optimization problem. The essence of Bayesian optimization is to\nchoose a prior model for the expensive-to-evaluate function(s) involved in the optimization problem\u2014\nusually a Gaussian process model (Santner et al., 2003; Williams and Rasmussen, 2006) for tractability\u2014\nand then to select the evaluation points sequentially in order to obtain a small average error between the\napproximation obtained by the optimization algorithm and the optimal solution, under the selected prior.\nSee, e.g., Kushner (1964); Mockus (1975); Mockus et al. (1978); Archetti and Betr\u00f2 (1979) and Mockus\n(1989) for some of the earliest references in the field. Bayesian optimization research was first focused\non the case of single-objective bound-constrained optimization: the Expected Improvement (EI) crite-\nrion (Mockus et al., 1978; Jones et al., 1998) has emerged in this case as one of the most popular criteria\nfor selecting evaluation points. Later, the EI criterion has been extended to handle constraints (Schonlau\net al., 1998; Sasena et al., 2002; Gramacy and Lee, 2011; Gelbart et al., 2014; Gramacy et al., to appear)\nand to address bound-constrained multi-objective problems (Emmerich et al., 2006; Jeong et al., 2006;\nWagner et al., 2010; Svenson and Santner, 2010).\nThe contribution of this article is twofold. The first part of the contribution is the proposition of a\nnew sampling criterion that handles multiple objectives and non-linear constraints simultaneously. This\ncriterion corresponds to a one-step look-ahead Bayesian strategy, using the dominated hyper-volume as a\nutility function (following in this respect Emmerich et al., 2006). More specifically, the dominated hyper-\nvolume is defined using an extended domination rule, which handles both the objectives and constraints\njointly (in the spirit of Fonseca and Fleming, 1998; Ray et al., 2001; Oyama et al., 2007). Our new criterion\nis naturally adapted to the search of a feasible point when none is available, and several criteria from\nthe literature\u2014the EI criterion and some of its constrained\/multi-objective extensions\u2014are recovered\nas special cases when at least one feasible point is known. The second part of the contribution lies in the\nnumerical methods employed to compute and optimize the sampling criterion. Indeed, this criterion takes\nthe form of an integral over the space of constraints and objectives, for which no analytical expression is\navailable in the general case. Besides, it must be optimized at each iteration of the algorithm to determine\nthe next evaluation point. In order to compute the integral, we use an algorithm similar to the subset\nsimulation method (Au and Beck, 2001; C\u00e9rou et al., 2012), which is a well known Sequential Monte\nCarlo (SMC) technique (see Del Moral et al., 2006; Liu, 2008, and references therein) from the field of\nstructural reliability and rare event estimation. For the optimization of the criterion, we resort to an SMC\nmethod as well, following earlier work by Benassi et al. (2012) for single-objective bound-constrained\nproblems. The resulting algorithm is called BMOO (for Bayesian multi-objective optimization).\nThe structure of the article is as follows. In Section 2, we recall the framework of Bayesian optimization\nbased on the expected improvement sampling criterion, starting with the unconstrained single-objective\nsetting. Section 3 presents our new sampling criterion for constrained multi-objective optimization. The\ncalculation and the optimization of the criterion are discussed in Section 4. Section 5 presents experimen-\ntal results. An illustration on a two-dimensional toy problem is proposed for visualization purpose. Then,\nthe performances of the method are compared to those of reference methods on both single-objective and\nmulti-objective constrained optimization problems from the literature. Finally, future work is discussed\nin Section 6."},{"page":4,"text":"3\n2 Background literature\n2.1 Expected Improvement\nConsider the single-objective unconstrained optimization problem\nx?= argminx\u2208Xf(x),\nwhere f is a continuous real-valued function defined over X \u2282 Rd. Our objective is to find an approxima-\ntion of x?using a sequence of evaluation points X1, X2, ... \u2208 X. Because the choice of a new evaluation\npoint Xn+1at iteration n depends on the evaluation results of f at X1, ..., Xn, the construction of an\noptimization strategy X : f ?\u2192 (X1, X2, X3...) is a sequential decision problem.\nThe Bayesian approach to this decision problem originates from the early work of Kushner (1964)\nand Mockus et al. (1978). Assume that a loss function \u03b5n(X,f) has been chosen to measure the perfor-\nmance of the strategy X on f after n evaluations, for instance the classical loss function\n\u03b5n(X,f) = mn\u2212 m,\n(2)\nwith mn= f(X1) \u2227 \u00b7\u00b7\u00b7 \u2227 f(Xn) and m = minx\u2208Xf(x). Then, a good strategy in the Bayesian sense\nis a strategy that achieves, on average, a small value of \u03b5n(X,f) when n increases, where the average\nis taken with respect to a stochastic process model \u03be (defined on a probability space (\u03a9,A,P0), with\nparameter in X) for the function f. In other words, the Bayesian approach assumes that f = \u03be(\u03c9,\u00b7) for\nsome \u03c9 \u2208 \u03a9. The probability distribution of \u03be represents prior knowledge about the function f\u2014before\nactual evaluations are performed. The reader is referred to Vazquez and Bect (2014) for a discussion of\nother possible loss functions in the context of Bayesian optimization.\nObserving that the Bayes-optimal strategy for a budget of N evaluations is intractable for N greater\nthan a few units, Mockus et al. (1978) proposed to use a one-step look-ahead strategy (also known as a\nmyopic strategy). Given n < N evaluation results, the next evaluation point Xn+1is chosen in order to\nminimize the conditional expectation of the future loss \u03b5n+1(X,\u03be) given available evaluation results:\n?\u03b5n+1(X,\u03be) | Xn+1= x?,\nwhere Enstands for the conditional expectation with respect to X1, \u03be(X1), ..., Xn, \u03be(Xn). Most of the\nwork produced in the field of Bayesian optimization since then has been focusing, as the present paper\nwill, on one-step look-ahead (or similar) strategies1; the reader is referred to Ginsbouger and Le Riche\n(2009) and Benassi (2013) for discussions about two-step look-ahead strategies.\nXn+1= argminx\u2208XEn\n(3)\nWhen (2) is used as a loss function, the right-hand side of (3) can be rewritten as\n?\u03b5n+1(X,\u03be) | Xn+1= x?= argminEn\nargminEn\n?mn+1\n??Xn+1= x?\n= argmaxEn\n?(mn\u2212 \u03be(x))+\n?,\n(4)\nwith z+= max(z, 0). The function\n\u03c1n(x) : x ?\u2192 En\n?(mn\u2212 \u03be(x))+\n?\n(5)\nis called the Expected Improvement (EI) criterion (Schonlau et al., 1998; Jones et al., 1998). When \u03be is\na Gaussian process with known mean and covariance functions, \u03c1n(x) has a closed-form expression:\n?\n1Mockus (1989, Section 2.5) heuristically introduces a modification of (3) to compensate for the fact that subsequent\nevaluation results are not taken into account in the myopic strategy. In this work, we consider a purely myopic strategy as\nin Jones et al. (1998).\n\u03c1n(x) = \u03b3mn\u2212?\u03ben(x), \u03c32\nn(x)\n?\n,\n(6)"},{"page":5,"text":"4\nwhere\n\u03b3(z,s) =\n?\u221as\u03d5\nmax(z,0)\n?\nz\n\u221as\n?\n+ z \u03a6\n?\nz\n\u221as\n?\nif s > 0,\nif s = 0,\nwith \u03a6 standing for the normal cumulative distribution function, \u03d5 = \u03a6?for the normal probability\ndensity function,?\u03ben(x) = En(\u03be(x)) for the kriging predictor at x (the posterior mean of \u03be(x) after\nSee, e.g., the books of Stein (1999), Santner et al. (2003), and Williams and Rasmussen (2006) for more\ninformation on Gaussian process models and kriging (also known as Gaussian process interpolation).\nn evaluations) and \u03c32\nn(x) for the kriging variance at x (the posterior variance of \u03be(x) after n evaluations).\nFinally, observe that the one-step look-ahead strategy (3) requires to solve an auxiliary global optimiza-\ntion problem on X for each new evaluation point to be selected. The objective function \u03c1n is rather\ninexpensive to evaluate when \u03be is a Gaussian process, using (6), but it is typically severely multi-modal.\nA simple method to optimize \u03c1nconsists in choosing a fixed finite set of points that covers X reasonably\nwell and then performing a discrete search. Recently, sequential Monte Carlo techniques (see Del Moral\net al., 2006; Liu, 2008, and references therein) have been shown to be a valuable tool for this task (Benassi\net al., 2012). A review of other approaches is provided in the PhD thesis of Benassi (2013, Section 4.2).\n2.2 EI-based multi-objective optimization without constraints\nWe now turn to the case of unconstrained multi-objective optimization. Under this framework, we con-\nsider a set of objective functions fj : X \u2192 R, j = 1, ..., p, to be minimized, and the objective is to\nbuild an approximation of the Pareto front and of the set of corresponding solutions\n\u0393 = {x \u2208 X : ?x?\u2208 X such that f(x?) \u227a f(x)},\n(7)\nwhere \u227a stands for the Pareto domination rule defined by\ny = (y1, ..., yp) \u227a z = (z1, ..., zp) \u21d0\u21d2\n?\u2200i \u2264 p, yi\u2264 zi,\n\u2203j \u2264 p, yj< zj.\n(8)\nGiven evaluation results f(X1) = (f1(X1), ..., fp(X1)), ..., f(Xn) = (f1(Xn), ..., fp(Xn)), define\nHn= {y \u2208 B;\u2203i \u2264 n, f(Xi) \u227a y},\n(9)\nwhere B \u2282 Rpis a set of the form B = {y \u2208 Rp; y \u2264 yupp} for some yupp\u2208 Rp, which is introduced\nto ensure that the volume of Hn is finite. Hn is the subset of B whose points are dominated by the\nevaluations.\nA natural idea, to extend the EI sampling criterion (5) to the multi-objective case, is to use the volume\nof the non-dominated region as loss function:\n\u03b5n(X,f) = |H \\ Hn| ,\nwhere H = {y \u2208 B;\u2203x \u2208 X,f(x) \u227a y} and |\u00b7| denotes the usual (Lebesgue) volume in Rp. The im-\nprovement yielded by a new evaluation result f(Xn+1) = (f1(Xn+1),...,fp(Xn+1)) is then the increase\nof the volume of the dominated region (see Figure 1):\nIn(Xn+1) = |H \\ Hn| \u2212 |H \\ Hn+1| = |Hn+1\\ Hn| = |Hn+1| \u2212 |Hn|,\nsince Hn \u2282 Hn+1 \u2282 H. Given a vector-valued Gaussian random process model \u03be = (\u03be1,...,\u03bep) of\nf = (f1,...,fp), defined on a probability space (\u03a9,A,P0), a multi-objective EI criterion can then be\n(10)"},{"page":6,"text":"5\ny1\ny2\ny3\nf1\nf2\nB \\ H3\nFig. 1: Example of an improvement of the dominated region. The regions dominated by y1 and y2 are represented in\nshaded areas, with darker shades indicating overlapping regions. The hatched area corresponds to the improvement of the\ndominated region resulting from the observation of y3.\nderived as\n\u03c1n(x) = En(In(x))\n= En\n??\nB\\Hn\n1\u03be(x)\u227aydy\n?\n=\n?\n?\nB\\Hn\nEn\n?1\u03be(x)\u227ay\nPn(\u03be(x) \u227a y) dy ,\n?dy\n=\nB\\Hn\n(11)\nwhere Pnstands for the probability P0conditioned on X1, \u03be(X1), ..., Xn, \u03be(Xn). The multi-objective\nsampling criterion (11), also called Expected Hyper-Volume Improvement (EHVI), has been proposed by\nEmmerich and coworkers (Emmerich, 2005; Emmerich et al., 2006; Emmerich and Klinkenberg, 2008).\nRemark 1 A variety of alternative approaches have been proposed to extend the EI criterion to the\nmulti-objective case, which can be roughly classified into aggregation-based techniques (Knowles, 2006;\nKnowles and Hughes, 2005; Zhang et al., 2010) and domination-based techniques (Jeong and Obayashi,\n2005; Keane, 2006; Ponweiser et al., 2008; Bautista, 2009; Svenson and Santner, 2010; Wagner et al.,\n2010). We consider these approaches are heuristic extensions of the EI criterion, in the sense that none\nof them emerges from a proper Bayesian formulation (i.e., a myopic strategy associated to some well-\nidentified loss function). A detailed description of these approaches is out of the scope of this paper.\nThe reader is referred to Wagner et al. (2010), Couckuyt et al. (2014) and Horn et al. (2015) for some\ncomparisons and discussions. See also Picheny (2014b) and Hern\u00e1ndez-Lobato et al. (2015a) for other\napproaches not directly related to the concept of expected improvement.\nRemark 2 The multi-objective sampling criterion (11) reduces to the usual EI criterion (5) in the single-\nobjective case (assuming that f(Xi) \u2264 yuppfor at least one i \u2264 n)."},{"page":7,"text":"6\nUnder the assumption that the components \u03bei of \u03be are mutually independent2, Pn(\u03be(x) \u227a y) can be\nexpressed in closed form: for all x \u2208 X and y \u2208 B \\ Hn,\nPn(\u03be(x) \u227a y) =\np\n?\ni=1\n\u03a6\n?\nyi\u2212?\u03bei,n(x)\n\u03c3i,n(x)\n?\n,\n(12)\nwhere?\u03bei,n(x) and \u03c32\nThe integration of (12) over B \\ Hn, in the expression (11) of the multi-objective EI criterion, is a non-\ntrivial problem. Several authors (Emmerich and Klinkenberg, 2008; Bader and Zitzler, 2011; Hupkens\net al., 2014; Couckuyt et al., 2014) have proposed decomposition methods to carry out this computation,\nwhere the integration domain B\\Hnis partitioned into hyper-rectangles, over which the integral can be\ncomputed analytically. The computational complexity of these methods, however, increases exponentially\nwith the number of objectives3, which makes the approach impractical in problems with more than a few\nobjective functions. The method proposed in this work also encounters this type of integration problem,\nbut takes a different route to solve it (using SMC techniques; see Section 4). Our approach will make it\npossible to deal with more objective functions.\ni,n(x) denote respectively the kriging predictor and the kriging variance at x for\nthe ithcomponent of \u03be.\nRemark 3 Exact and approximate implementations of the EHVI criterion are available, together with\nother Gaussian-process-based criteria for bound-constrained multi-objective optimization, in the Mat-\nlab\/Octave toolbox STK (Bect et al., 2016) and in the R packages GPareto (Binois and Picheny, 2015)\nand mlrMBO (Horn et al., 2015). Note that several approaches discussed in Remark 1 maintain an\naffordable computational cost when the number of objectives grows, and therefore constitute possible\nalternatives to the SMC technique proposed in this paper for many-objective box-constrained problems.\n2.3 EI-based optimization with constraints\nIn this section, we discuss extensions of the expected improvement criterion for single- and multi-objective\nconstrained optimization.\nConsider first the case of problems with a single objective and several constraints:\n?minx\u2208Xf(x),\nc(x) \u2264 0,\n(13)\nwhere c = (c1, ..., cq) is a vector of continuous constraints. The set C = {x \u2208 X; c(x) \u2264 0} is called the\nfeasible domain. If it is assumed that at least one evaluation has been made in C, it is natural to define a\nnotion of improvement with respect to the best objective value mn= min{f(x); x \u2208 {X1, ...,Xn} \u2229 C}:\nIn(Xn+1) = mn\u2212 mn+1\n= 1c(Xn+1)\u22640\u00b7?mn\u2212 f(Xn+1)?\n=\n0\n+\n?mn\u2212 f(Xn+1) if Xn+1\u2208 C and f(Xn+1) < mn,\notherwise.\n(14)\n2This is the most common modeling assumption in the Bayesian optimization literature, when several objective functions,\nand possibly also several constraint functions, have to be dealt with. See the VIPER algorithm of Williams et al. (2010)\nfor an example of an algorithm based on correlated Gaussian processes.\n3See, e.g., Beume (2009), Hupkens et al. (2014), Couckuyt et al. (2014) and references therein for decomposition\nalgorithms and complexity results."},{"page":8,"text":"7\nIn other words, a new observation makes an improvement if it is feasible and improves upon the best past\nvalue (Schonlau et al., 1998). The corresponding expected improvement criterion follows from taking the\nexpectation:\n\u03c1n(x) = En\n?\n1\u03bec(x)\u22640\u00b7?mn\u2212 \u03beo(x)?\n+\n?\n.\n(15)\nIf f is modeled by a random process \u03beo and c is modeled by a vector-valued random process \u03bec =\n(\u03bec,1, ..., \u03bec,q) independent of \u03beo, then the sampling criterion (15) simplifies to Schonlau et al.\u2019s criterion:\n\u03c1n(x) = Pn(\u03bec(x) \u2264 0) En\n?(mn\u2212 \u03beo(x))+\n?.\n(16)\nIn other words, the expected improvement is equal in this case to the product of the unconstrained ex-\npected improvement, with respect to mn, with the probability of feasibility. The sampling criterion (16)\nis extensively discussed, and compared with other Gaussian-process-based constraint handling meth-\nods, in the PhD thesis of Sasena (2002). More generally, sampling criteria for constrained optimization\nproblems have been reviewed by Parr et al. (2012) and Gelbart (2015).\nIn the general case of constrained multi-objective problems, the aim is to build an approximation of \u0393\ndefined by (1). If it is assumed that an observation has been made in the feasible set C, a reasoning\nsimilar to that used in the single-objective case can be made to formulate an extension of the EI (11):\n\u03c1n(x) = En(|Hn+1| \u2212 |Hn|),\n(17)\nwhere\nHn= {y \u2208 B;\u2203i \u2264 n, Xi\u2208 C and f(Xi) \u227a y}\n(18)\nis the subset of B, defined as in Section 2.2, whose points are dominated by feasible evaluations. When \u03beo\nand \u03becare assumed independent, (17) boils down to the product of a modified EHVI criterion, where\nonly feasible points are considered4, and the probability of feasibility, as suggested by Emmerich et al.\n(2006) and Shimoyama et al. (2013):\n?\n\u03c1n(x) = Pn(\u03bec(x) \u2264 0)\nB\\Hn\nPn(\u03beo(x) \u227a y) dy.\n(19)\nObserve that the sampling criterion (17) is the one-step look-ahead criterion associated to the loss\nfunction \u03b5n(X,f) = \u2212|Hn|, where Hnis defined by (18). This loss function remains constant as long\nas no feasible point has been found and, therefore, is not an appropriate measure of loss for heavily\nconstrained problems where finding feasible points is sometimes the main difficulty5. From a practical\npoint of view, not all unfeasible points should be considered equivalent: a point that does not satisfy\na constraint by a small amount has probably more value than one that does not satisfy the constraint\nby a large amount, and should therefore make the loss smaller. Section 3 will present a generalization\nof the expected improvement for constrained problems, relying on a new loss function that encodes this\npreference among unfeasible solutions.\nRemark 4 Other Gaussian-process-based approaches that can be used to handle constraints include the\nmethod by Gramacy et al. (to appear), based on the augmented Lagrangian approach of Conn et al.\n(1991), and several recent methods (Picheny, 2014a; Gelbart, 2015; Hern\u00e1ndez-Lobato et al., 2015b, to\nappear) based on stepwise uncertainty reduction strategies (see, e.g., Villemonteix et al., 2009; Bect\net al., 2012; Chevalier et al., 2014, for more information on this topic).\n4Note that this modified EHVI criterion remains well defined even when Hn= \u2205, owing to the introduction of an upper\nbound yuppin the definition of B. Its single-objective counterpart introduced earlier (see Equation (15)), however, was\nonly well defined under the assumption that at least one feasible point is known. Introducing an upper bound yuppis of\ncourse also possible in the single-objective case.\n5The same remark holds for the variant (see, e.g., Gelbart et al., 2014) which consists in using the probability of\nfeasibility as a sampling criterion when no feasible point is available. This is indeed equivalent to using the loss function\n\u03b5n(X,f) = \u22121\u2203i\u2264n,Xi\u2208Cin the search for feasible points."},{"page":9,"text":"8\nRemark 5 The term En\ncomputation of the integral in (19) has been discussed in Section 2.2. If it is further assumed that the\ncomponents of \u03becare Gaussian and independent, then the probability of feasibility can be written as\n?(mn\u2212\u03beo(x))+\n?in (16) can be computed analytically as in Section 2.1, and the\n?\n\u03c3c,j,n(x)\nPn(\u03bec(x) \u2264 0) =\nq?\nj=1\n\u03a6\n\u2212\n?\u03bec,j,n(x)\n?\n(20)\nwhere?\u03bec,j,n(x) and \u03c32\nc,j,n(x) stand respectively for the kriging predictor and the kriging variance of \u03bec,j\nat x.\n3 An EI criterion for constrained multi-objective optimization\n3.1 Extended domination rule\nIn a constrained multi-objective optimization setting, we propose to handle the constraints using an\nextended Pareto domination rule that takes both objectives and constraints into account, in the spirit of\nFonseca and Fleming (1998), Ray et al. (2001) and Oyama et al. (2007). For ease of presentation, denote\nby Yo= Rpand Yc= Rqthe objective and constraint spaces respectively, and let Y = Yo\u00d7 Yc.\nWe shall say that y1\u2208 Y dominates y2\u2208 Y, which will be written as y1?y2, if \u03c8(y1) \u227a \u03c8(y2), where \u227a\nis the usual Pareto domination rule recalled in Section 2.2 and, denoting by R the extended real line,\np\u00d7 Rq\n\uf8f1\n\uf8f3\nThe extended domination rule (21) has the following properties:\n\u03c8 : Yo\u00d7 Yc \u2192 R\n(yo, yc) ?\u2192\n\uf8f2\n(yo, 0)\n?+\u221e, max(yc,0)?\nif yc\u2264 0,\notherwise.\n(21)\n(i) For unconstrained problems (q = 0, Yc = \u2205), the extended domination rule boils down to the\nPareto domination rule on Y = Yo.\n(ii) Feasible solutions (corresponding to yc\u2264 0) are compared using the Pareto domination rule applied\nin the objective space (in other words, using the Pareto domination rule with respect to the objective\nvalues yo).\n(iii) Non-feasible solutions (corresponding to yc?\u2264 0) are compared using the Pareto domination rule\napplied to the vector of constraint violations.\n(iv) Feasible solutions always dominate non-feasible solutions.\nThese properties are illustrated on Figure 2.\n3.2 A new EI criterion\nThe extended domination rule presented above makes it possible to define a notion of expected hyper-\nvolume improvement as in Section 2.2 for the constrained multi-objective setting. Given evaluation\nresults (f(X1),c(X1)), ..., (f(Xn),c(Xn)), define\nHn= {y \u2208 B; \u2203i \u2264 n, (f(Xi), c(Xi)) ? y}\nwith B = Bo\u00d7 Bc, where Bo\u2282 Yoand Bc\u2282 Ycare two bounded hyper-rectangles that are introduced\nto ensure, as in Section 2.2, that |Hn| < +\u221e (see Appendix A). Then, define the improvement yielded\nby a new evaluation (f(Xn+1), c(Xn+1)) by\nIn(Xn+1) = |Hn+1\\ Hn| = |Hn+1| \u2212 |Hn|"},{"page":10,"text":"9\ny1\ny2\ny3\nYo\nfi\nfj\n(a)\ny3\ny4\ny5\nYc\nci\ncj\n(b)\ny7\ny8\nYc\u00d7 Yo\nci\nfj\n(c)\ny6\ny3\ny4\ny5\nYc\nci\ncj\n(d)\ny9\ny7\ny8\nYc\u00d7 Yo\nci\nfj\n(e)\nFig. 2: Illustration of the extended domination rule in different cases. The region dominated by each point is represented\nby a shaded area. Darker regions indicate overlapping regions. (a) Feasible solutions are compared with respect to their\nobjective values using the usual domination rule in the objective space\u2014see properties (i) and (ii). (b\u2013c) Non-feasible\nsolutions are compared using the Pareto domination rule applied to the vectors of constraint violations according to\nproperty (iii). Note that y4 dominates points having a higher value of cj regardless of the corresponding value of ci, and,\nlikewise, y5 dominates points with higher values of ci. (d\u2013e) Feasible solutions always dominate non-feasible solutions: y6\nis feasible and hence dominates y3, y4and y5; y9is feasible and dominates both y7and y8as stated in (iv).\nas in Section 2.2. In order to get a meaningful concept of improvement both before and after the first\nfeasible point has been found, we assume without loss of generality that (0, ..., 0) \u2208 Rqis in the interior\nof Bc.\nIf (f,c) is modeled by a vector-valued random process \u03be = (\u03beo, \u03bec), with \u03beo = (\u03beo,1, ...,\u03beo,p) and\n\u03bec = (\u03bec,1, ,...\u03bec,q), then the expected improvement for the constrained multi-objective optimization\nproblem may be written as\n\u03c1n(x) = En\n?(In(x)?= En\n??\nGn\n1\u03be(x)?ydy\n?\n=\n?\nGn\nPn(\u03be(x) ? y)dy ,\n(22)\nwhere Gn= B \\ Hnis the set of all non-dominated points in B."},{"page":11,"text":"10\nAs in Section 2.2, under the assumption that the components of \u03be are mutually independent and Gaus-\nsian, Pn(\u03be(x) ? y) can be expressed in closed form: for all x \u2208 X and y = (yo, yc) \u2208 Gn,\n\uf8f1\n\uf8f4\n\uf8f4\n\uf8f3\nThe EI-based constrained multi-objective optimization procedure may be written as (3). In practice, the\ncomputation of each new evaluation point requires to solve two numerical problems: a) the computation\nof the integral in (22); b) the optimization of \u03c1nin the procedure (3). These problems will be addressed\nin Section 4.\nPn(\u03be(x) ? y) =\n\uf8f4\n\uf8f2\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n?p\ni=1\n?\n\u03a6\n?yo,i\u2212?\u03beo,i,n(x)\n\u03c3o,i,n(x)\n??\uf8eb\n\uf8ed\nq?\nj=1\n\u03a6\n?\n\u2212\n?\u03bec,j,n(x)\n\u03c3c,j,n(x)\n?\uf8f6\n\uf8f8\nif yc\u2264 0,\nq?\nj=1\n\u03a6\n?max(yc,j, 0) \u2212?\u03bec,j,n(x)\n\u03c3c,j,n(x)\n?\notherwise.\n(23)\nRemark 6 When there are no constraints (q = 0, Yc= \u2205), the extended domination rule ? corresponds\nto the usual Pareto domination rule \u227a. In this case, the sampling criterion (22) simplifies to\n?\nwith\nHn,o= {yo\u2208 Bo; \u2203i \u2264 n, f(Xi) \u227a yo}.\nDenote by ylow\no\n\u2208 Yothe lower and upper corners of the hyper-rectangle Bo. Then, the sampling\ncriterion (24) is equivalent to the multi-objective EI criterion presented in Section 2.2 in the limit ylow\n\u2212\u221e. If, moreover, the problem has only one objective function, then the criterion (22) boils down to the\noriginal Expected Improvement criterion as soon as the best evaluation dominates yupp\n\u03c1n(x) =\nBo\\Hn,o\nPn(\u03beo(x) \u227a yo) dyo,\n(24)\no , yupp\no\n\u2192\no\n(see Remark 2).\n3.3 Decomposition of the expected improvement: feasible and unfeasible components\nAssume that there is at least one constraint (q \u2265 1). Then, the expected improvement \u03c1n(x) can be\ndecomposed as\n\u03c1n(x) = \u03c1feas\nn\n(x) + \u03c1unf\nby splitting the integration domain in the right-hand side of (22) in two parts: \u03c1feas\nthe integral on (Gn) \u2229 {yc\u2264 0}, while \u03c1unf\nMore explicit expressions will now be given for both terms. First,\n?\n= |Bo| \u00b7\nBc\\Hn,c\nwhere y+\nHn,c=?yc\u2208 Bc| \u2203i \u2264 n, \u03be+\nLet B\u2212\n?\n=\nc\nn(x),\n(25)\nn\n(x) corresponds to\nn(x) corresponds to the integral on (Gn) \u2229 {yc?\u2264 0}.\n\u03c1unf\nn(x) =\nGn\u2229{yc?\u22640}\n?\nPn((\u03beo(x),\u03bec(x)) ? (yo,yc)) d(yo,yc)\n?\u03be+\nPn\nc(x) \u227a y+\nc\n?1yc?\u22640dyc\n(26)\nc= max(yc,0) and\nc(Xi) \u227a y+\nc\n?.\nc= Bc\u2229]\u2212\u221e, 0]qdenote the feasible subset of Bc. Then, assuming that \u03becand \u03beoare independent,\n\u03c1feas\nn\n(x) =\nGn\u2229{yc\u22640}\n??B\u2212\nPn((\u03beo(x),\u03bec(x)) ? (yo,yc)) d(yo,yc)\n??\u00b7 Pn(\u03bec(x) \u2264 0) \u00b7\n?\nBo\\Hn,o\nPn(\u03beo(x) \u227a yo) dyo,\n(27)"},{"page":12,"text":"11\nwhere\nHn,o= {yo\u2208 Bo| \u2203i \u2264 n, \u03bec(Xi) \u2264 0 and \u03beo(Xi) \u227a yo} .\nRemark 7 The set Bc\\ Hn,cis empty as soon as a feasible point has been evaluated. As a consequence,\nthe component \u03c1unfof the expected improvement vanishes and therefore, according to (27),\n?\nIn other words, up to a multiplicative constant, the expected improvement is equal, in this case, to the\nproduct of the probability of feasibility with a modified EHVI criterion in the objective space, where\nonly feasible points are used to define the dominated region. In particular, in constrained single-objective\nproblems, the criterion of Schonlau et al. (see Section 2.3) is recovered as the limit case ylow\nsoon as the best evaluation dominates yupp\no\n.\n\u03c1n(x) \u221d Pn(\u03bec(x) \u2264 0) \u00b7\nBo\\Hn,o\nPn(\u03beo(x) \u227a yo) dyo.\no\n\u2192 \u2212\u221e, as\nRemark 8 In our numerical experiments, Bo and Bc are defined using estimates of the range of the\nobjective and constraint functions (see Appendix B). Another natural choice for the Bowould have been\nto use (an estimate of) the range of the objective functions restricted to the feasible subset C \u2282 X for Bo.\nFurther investigation of this idea is left for future work.\n4 Sequential Monte Carlo techniques to compute and optimize the expected improvement\n4.1 Computation of the expected improvement\nSince the dimension of Y is likely to be high in practical problems (say, p + q \u2265 5), the integration\nof y ?\u2192 Pn(\u03be(x) ? y) over Gn cannot be carried out using decomposition methods (Emmerich and\nKlinkenberg, 2008; Bader and Zitzler, 2011; Hupkens et al., 2014) because, as mentioned in Section 2.2,\nthe computational complexity of these methods increases exponentially with the dimension of Y.\nTo address this difficulty, we propose to use a Monte Carlo approximation of the integral (22):\n\u03c1n(x) \u22481\nm\nm\n?\nk=1\nPn(\u03be(x) ? yn,k),\n(28)\nwhere Yn= (yn,k)1\u2264k\u2264mis a set of particles distributed according to the uniform density \u03c0Y\non Gn. In principle, sampling uniformly over Gncould be achieved using an accept-reject method (see,\ne.g., Robert and Casella, 2013), by sampling uniformly over B and discarding points in Hn(Bader and\nZitzler, 2011). However, when the dimension of Y is high, Gnwill probably have a small volume with\nrespect to that of B. Then, the acceptance rate becomes small and the cost of generating a uniform\nsample on Gn becomes prohibitive. (As an example, consider an optimization problem with q = 20\nconstraints. If Bc= [\u2212v\/2, +v\/2]q, then the volume of the feasible region is 220\u2248 106times smaller\nthan that of Bc.)\nn\u221d 1Gn\nIn this work, we use a variant of the technique called subset simulation (Au and Beck, 2001; C\u00e9rou et al.,\n2012) to achieve uniform sampling over Gn. The subset simulation method is a well-known method in\nthe field of structural reliability and rare event estimation, which is used to estimate the volume of small\nsets by Monte Carlo sampling.\nDenote by \u03a0Y\nwhen n increases, so that sampling Gnusing an accept-reject method is impractical. Observe that the\nsets Gn, n = 1, 2, ... form a nested sequence of subsets of B (hence the name subset simulation):\n0the uniform distribution over B and assume that the probability \u03a0Y\n0(Gn) becomes small\nB \u2283 G1\u2283 G2\u2283 \u00b7\u00b7\u00b7 .\n(29)"},{"page":13,"text":"12\nAlgorithm 1: Remove-Resample-Move procedure to construct Yn\n1 if n = 0 then\n2\nGenerate m independent and uniformly distributed particles over G0= B.\n3 else\n4\nRemove: Set Y0\n5\nResample: Set Y1\ndistributed on Y0\n6\nMove: Move the particles using a Metropolis-Hastings algorithm (see, e.g, Robert and Casella, 2013)\nwhich targets the uniform distribution over Gn+1. The resulting set of particles is Yn+1.\nn= Yn\u22121\u2229 Gn and m0=??Y0\nn. (Each \u02dc yn,kis a replicate of a particle from Y0\nn\n??.\nn= Y0\nn\u222a {\u02dc yn,1,..., \u02dc yn,m\u2212m0}, where \u02dc yn,1,..., \u02dc yn,m\u2212m0are independent and uniformly\nn.)\nAlgorithm 2: Modified procedure to construct Yn\nNotation: Given a set A in Y, denote by Pareto(A) the set of points of A that are not dominated by any\nother point of A\n1 if n = 0 then\n2\nGenerate m independent and uniformly distributed particles over G0= B.\n3 else\n4\nSet Pn\u22121= Pareto({\u03be(X1), ...,\u03be(Xn\u22121)}).\n5\nSet Pn= Pareto({\u03be(X1), ...,\u03be(Xn)}) = Pareto(Pn\u22121\u222a {\u03be(Xn)}).\n6\nConstruct Yn using the adaptive multi-level splitting procedure described in Algorithm 3, with Yn\u22121,\nPn\u22121, Pn and B as inputs.\nDenote by \u03a0Y\nabove. Since the addition of a single new evaluation, at iteration n + 1, is likely to yield only a small\nmodification of the set Gn, the probability\n?\nis likely to be high. Then, supposing that a set of particles Yn = (yn,k)1\u2264k\u2264muniformly distributed\non Gnis already available, one obtains a sample Yn+1uniformly distributed over Gn+1using the Remove-\nResample-Move procedure described in Algorithm 1. (All the random variables generated in Algorithm 1\nare independent of \u03be conditionally on X1, \u03be(Xi), ..., Xn+1, \u03be(Xn+1).)\nnthe uniform distribution on Gn, which has the probability density function \u03c0Y\nndefined\n\u03a0Y\nn(Gn+1) =\nGn+1\n\u03c0Y\nn(y)dy =\u03a0Y\n0(Gn+1)\n\u03a0Y\n0(Gn)\nAlgorithm 1 obviously requires that at least one particle from Yn, which belongs by construction to Gn,\nalso belongs to Gn+1; otherwise, the set of surviving particles, referred to in the second step of the\nalgorithm, will be empty. More generally, Algorithm 1 will typically fail to produce a good sample\nfrom \u03a0Y\nis small\u2014indeed, the expected number of particles of Ynin a given6set A \u2282 B is\n?\nwhere N(A; Y) denotes the number of particles of Y in A. This situation occurs, for instance, when a\nnew evaluation point brings a large improvement Gn\\ Gn+1= Hn+1\\ Hn.\nWhen the number of surviving particles is smaller than a prescribed fraction \u03bd of the population size,\nthat is, when N(Gn+1; Yn) < m\u03bd, intermediate subsets are inserted in the decreasing sequence (29) to\nensure that the volume of the subsets does not decrease too fast. The corrected version of Algorithm 1 is\ndescribed in Algorithms 2 and 3. The method used in Algorithm 3 to construct the intermediate subsets\nis illustrated on Figures 3 and 4.\nn+1if the number of surviving particles is small, which happens with high probability if \u03a0Y\nn(Gn+1)\nEn\nN(A; Yn)\n?\n= En\n?m\nk=1\n?\n1A(yn,k)\n?\n= m \u00b7 \u03a0Y\nn(A),\n(30)\n6Equation (30) does not hold exactly for A = Gn+1since, conditionally on X1, \u03be(Xi), ..., Xn, \u03be(Xn), the set Gn+1is\na random set and is not independent of Yn. Indeed, Gn+1 depends on \u03be(Xn+1) and Xn+1 is chosen by minimization of\nthe approximate expected improvement, which in turn is computed using Yn."},{"page":14,"text":"13\ny3\ny1\ny2\nBc\nci\ncj\n(a)\ny3\ny1\ny2\nBc\nci\ncj\nyanchor\n\u02dc yu\n(b)\nFig. 3: Illustration of the steps 10 \u2192 12 and 13 \u2192 15 of Algorithm 3. The objective is to build a uniform sample Y3on G3\nfrom Y2. The initial Pareto front P0 is determined by evaluations results y1 = (f(X1),c(X1)) and y2 = (f(X2),c(X2)).\nPT corresponds to the Pareto front determined by P0\u222a {y3}, with y3 = (f(X3),c(X3)). At the end of steps 1\u20139, y3 is\nnot in P because the number of surviving particles in Y2 is too small: in (a), there is only one particle (black dot) in G3\n(white region). Thus, intermediate subsets are needed. The main idea here is to build a continuous path between P0and\nPT, which is illustrated in (b). Here, we pick y?= y3 and since y3 is not feasible, q?< q. Then, we set an anchor point\nyanchoron the edge of B, as described in step 14, and we build an intermediate Pareto front? Pu determined by y1, y2and\nof killed particles (grey dots) is not too large.\n\u02dc yu, where \u02dc yu lies on the segment (yanchor\u2013y3). The intermediate Pareto front? Pu is chosen in such a way that the number\ny2\ny1\nBc\u00d7 Bo\nci\nfj\n(a)\ny2\ny1\n\u02dc yu\nBc\u00d7 Bo\nci\nfj\ny0\nanchor\nyi\nanchor\n(b)\nFig. 4: Illustration of the steps 10 \u2192 12 and 16 \u2192 20 of Algorithm 3. The setting is the same as that described in Figure 3,\nexcept that the new observation (y2 in this case) is feasible. Hence, q?= q. As above, the main idea is to construct a\ncontinuous path between P0and PT, represented by the broken red line."},{"page":15,"text":"14\nAlgorithm 3: Adaptive multi-level splitting in the Y-domain\nNotations: Given a set A in Y, denote by\n\u2013 Pareto(A) the set of points of A that are not dominated by any other point of A,\n\u2013 G(A) := B \\ {y \u2208 B; \u2203y?\u2208 A such that y?? y} the region of B not dominated by A.\nInputs: Y0, P0, P?and B such that\n\u2013 P0= Pareto(P0), i.e., no point in P0is dominated by another point in P0, and similarly P?= Pareto(P?),\n\u2013 G(P?) \u2282 G(P0),\n\u2013 Y0=?y0,k\no\no\nc\nc\nB = Bo\u00d7 Bc contains P0and P?.\nOutput: A set of particles YT=?yT,k\n2 while Pt?= P?do\n3\nInitialize: P \u2190 Pt.\n4\nP is the front that we will build upon. First we try to add the points of P?into P:\n5\nfor y \u2208 P?do\n6\nPtry\u2190 Pareto(P \u222a {y})\n7\nCompute the number N(G(Ptry);Yt) of particles of Yt in G(Ptry)\n8\nif N(G(Ptry);Yt) \u2265 \u03bdm then\n9\nP \u2190 Ptry\nAt the end of this first step, either P = P?or P?\\ P contains points that cannot be added without killing\na large number of particles, in which case we insert intermediate fronts.\n10\nif (P?\\ P) ?= \u2205 then\n11\nRandomly choose a point y?= (y?\n12\nCount the number q?of constraints satisfied by y?.\n13\nif q?< q then\n14\nyanchor\u2190 (yupp\n15\nFind? Pu such that N(G(? Pu);Yt) \u2248 \u03bdm using a dichotomy on u \u2208 [0,1], where\n16\nelse\n17\ny0\no\n,0) \u2208 Bo\u00d7 Bc\n18\nyk\no\n,yk\nand 1 \u2264 k \u2264 q.\n19\nif N(G({y0\n20\nFind? Pu such that N(G(? Pu);Yt) \u2248 \u03bdm using a dichotomy on u \u2208 [0,1], where\nelse\nFind? Pu such that N(G(? Pu);Yt) \u2248 \u03bdm using a dichotomy on u \u2208 [0,1], where\n?\n1\u2264k\u2264m\u2208 Ymis uniformly distributed on G(P0). Note that Y0may contain replicated values.\n,ylow\nand yupp\no\n\u2013 ylow\n,yupp\nsuch that Bo=?y \u2208 Yo; ylow\n?\n\u2264 y \u2264 yupp\no\n?, Bc=?y \u2208 Yc; ylow\nc\n\u2264 y \u2264 yupp\nc\n?, and\n1\u2264k\u2264m\u2208 Ymuniformly distributed on G(PT).\n1 t \u2190 0\no,y?\nc) \u2208 (P?\\ P) toward which we will try to augment the front P.\no\n,yc) \u2208 Bo\u00d7 Bc, where yc,j= yupp\nc,j\nif y?\nc,j> 0 and zero otherwise, 1 \u2264 j \u2264 q.\n? Pu= Pareto(P \u222a {yanchor+ u(y?\u2212 yanchor)}).\nanchor\u2190 (yupp\nanchor\u2190 (yupp\nc) \u2208 Bo\u00d7 Bc, where yk\nc,j= yupp\nc,j\nif j = k and zero otherwise, for 1 \u2264 j \u2264 q\nanchor});Yt) \u2265 \u03bdm then\n? Pu= Pareto(P \u222a {y0\nanchor+ u(y?\u2212 y0\nanchor)}).\n21\n22\n? Pu= Pareto(P \u222a {y1\nanchor+ u(y0\nanchor\u2212 y1\nanchor)} \u222a \u00b7\u00b7\u00b7 \u222a {yq\nanchor+ u(y0\nanchor\u2212 yq\nanchor)}).\n23\nP \u2190? Pu\n24\nPt+1\u2190 P\nGenerate Yt+1=?yt+1,k\nt \u2190 t + 1\n25\n?\n1\u2264k\u2264muniformly distributed on G(Pt+1) using the \u201cRemove-Resample-Move\u201d\nsteps described in Algorithm 1.\n26\nRemark 9 The algorithms presented in this section provide a general numerical method for the approx-\nimate computation of the expected improvement criterion, that can be used with multiple objectives,\nmultiples constraints and possibly correlated Gaussian process models. When the objectives and con-\nstraints are independent, the decomposition introduced in Section 3.3 makes it possible to compute two\nintegrals over spaces of lower dimension (over Bc\\ Hn,c and Bo\\ Hn,o, respectively) instead of one\nintegral over Gn = B \\ Hn. In fact, only one of the two integrals actually needs to be approximated\nnumerically: indeed, the term \u03c1feasof the decomposition can be calculated in closed form prior to finding"},{"page":16,"text":"15\nfeasible solutions, and the term \u03c1unfvanishes once a feasible observation has been made. We have taken\nadvantage of this observation for all the numerical results presented in Section 5.\n4.2 Maximization of the sampling criterion\nThe optimization of the sampling criterion (22) is a difficult problem in itself because, even under the\nunconstrained single-objective setting, the EI criterion is very often highly multi-modal. Our proposal is\nto conduct a discrete search on a small set of good candidates provided at each iteration by a Sequential\nMonte Carlo algorithm, in the spirit of Benassi et al. (2012), Li et al. (2012), Li (2012) and Benassi\n(2013).\nThe key of such an algorithm is the choice of a suitable sequence?\u03c0X\nsequence of densities are stability\u2014\u03c0X\nthe probability mass in regions corresponding to high values of the expected improvement. We propose,\nfollowing Benassi et al. (2012), to consider the sequence defined by\n?\u03c0X\n\u03c0X\nIn other words, we start from the uniform distribution on X and then we use the probability of improve-\nment x ?\u2192 Pn(\u03be(x) \u2208 Gn) as an un-normalized probability density function.\nA procedure similar to that described in Algorithms 1 is used to generate particles distributed from\nthe target densities \u03c0X\nparticles\nXn= (xn,k,wn,k)m\nsuch that the empirical distribution?\nwith respect to Section 4.1 is the introduction of weighted particles, which makes it possible to deal with\nnon-uniform target distributions. When a new sample is observed at step n, the weights of the particles\nare updated to fit the new density \u03c0X\nn\n?\nn\u22650of probability density functions\non X, which will be the targets of the SMC algorithm. Desirable but antagonistic properties for this\nn+1should not differ too much from \u03c0X\nn\u2014and concentration of\nn(x) \u221d 1\nn(x) \u221d Pn(\u03be(x) \u2208 Gn) for n = 1,2,...\nif n = 0,\nn. At each step n of the algorithm, our objective is to construct a set of weighted\nk=1\u2208 (X \u00d7 R)m\n(31)\nkwn,k\u03b4xn,k(where \u03b4xdenotes the Dirac measure at x \u2208 X) is a\ngood approximation, for m large enough, of the target distribution with density \u03c0X\nn. The main difference\nn+1:\nw0\nn+1,k\u221d\u03c0X\nn+1(xn,k)\n\u03c0X\nn(xn,k)\nwn,k.\n(32)\nThe weighted sample X0\n\u03c00,\u03c01,... become more and more concentrated as more information is obtained about the functions f\nand c, the regions of high values for \u03c0X\nsequently, the weights of some particles degenerate to zero, indicating that those particles are no longer\ngood candidates for the optimization. Then, the corresponding particles are killed, and the particles with\nnon-degenerated weights are replicated to keep the size of the population constant. All particles are then\nmoved randomly using an MCMC transition kernel targeting \u03c0X\nThe corresponding procedure, which is very similar to that described in Algorithm 1, is summarized in\nAlgorithm 4.\nn+1= (xn,k,w0\nn+1,k)1\u2264k\u2264m is then distributed from \u03c0X\nn+1. Since the densities\nn+1become different from the regions of high values for \u03c0X\nn. Con-\nn+1, in order to restore some diversity.\nWhen the densities \u03c0X\nnon-degenerated weights is very small and that the empirical distribution?\nof non uniform target densities, we use the Effective Sample Size (ESS) to detect degeneracy (see, e.g.,\nDel Moral et al., 2006), instead of simply counting the surviving particles. When the ESS falls below\na prescribed fraction of the population size, we insert intermediate densities, in a similar way to what\nwas described in Section 4.1. The intermediate densities are of the form \u02dc \u03c0u(x) \u221d Pn(\u03be(x) \u2208\u02dcGu), with\nGn+1\u2282\u02dcGu\u2282 Gn. The corresponding modification of Algorithm 4 is straightforward. It is very similar\nto the procedure described in Algorithms 2 and 3 and is not repeated here for the sake of brevity.\nnand \u03c0X\nn+1are too far apart, it may happen that the number of particles with\nkwn,k\u03b4xn+1,kis not a good\napproximation of \u03c0X\nn+1. This is similar to the problem explained in Section 4.1, except that in the case"},{"page":17,"text":"16\nAlgorithm 4: Reweight-Resample-Move procedure to construct Xn\n1 if n = 0 then\n2\nm\n3 else\n4\nReweight Xn\u22121according to Equation (32) to obtain X0\n5\nResample with a residual resampling scheme (see, e.g., Douc and Capp\u00e9, 2005) to obtain a set of particles\nX1\nMove the particles with an MCMC transition kernel to obtain Xn=?xn,k,1\nSet X0=?x0,k,1\n?\n1\u2264k\u2264mwith x0,1,...,x0,mindependent and uniformly distributed on X.\nn.\nn=\n?\nx1\nn,k,1\nm\n?\n1\u2264k\u2264m.\n6\nm\n?\n1\u2264k\u2264m.\nRemark 10 A closed form expression of the probability of improvement is available in the single-objective\ncase, as soon as one feasible point has been found. When no closed form expression is available, we\nestimate the probability of improvement using a Monte Carlo approximation: 1\/N?N\nfor the use of such an unbiased estimator inside a Metropolis-Hastings transition kernel (see the Move\nstep of Algorithm 4) is provided by Andrieu and Roberts (2009).\nk=11Gn(Zk), where\n(Zk)1\u2264k\u2264N is an N-sample of Gaussian vectors, distributed as \u03be(x) under Pn. A rigorous justification\nRemark 11 It sometimes happens that a new evaluation result\u2014say, the n-th evaluation result\u2014changes\nthe posterior so dramatically that the ESS falls below the threshold \u03bdm (see Algorithm 3) for the current\nregion Gn\u22121. When that happens, we simply restart the Sequential Monte Carlo procedure using a\nsequence of transitions from P0= \u2205 to the target front P?(notation introduced in Algorithm 3).\nRemark 12 For the sake of clarity, the number of particles used in the SMC approximation has been\ndenoted by m both in Section 4.1 and in Section 4.2. Note that the two sample size are, actually, not\ntied to each other. We will denote them respectively by mX and mYin Section 5.\n5 Experiments\n5.1 Settings\nThe BMOO algorithm has been written in the Matlab\/Octave programming language, using the Small\nToolbox for Kriging (STK) (Bect et al., 2016) for the Gaussian process modeling part. All simulation\nresults have been obtained using Matlab R2014b.\nIn all our experiments, the algorithm is initialized with a maximin Latin hypercube design consisting of\nNinit= 3d evaluations. This is an arbitrary rule of thumb. A dedicated discussion about the size of initial\ndesigns can be found in Loeppky et al. (2009). The objective and constraint functions are modeled using\nindependent Gaussian processes, with a constant but unknown mean function, and a Mat\u00e9rn covariance\nfunction with regularity parameter \u03bd = 5\/2 (these settings are described, for instance, in Bect et al.,\n2012). The variance parameter \u03c32and the range parameters \u03b8i, 1 \u2264 i \u2264 d, of the covariance functions\nare (re-)estimated at each iteration using a maximum a posteriori (MAP) estimator. Besides, we assume\nthat the observations are slightly noisy to improve the conditioning of the covariance matrices, as is\nusually done in kriging implementations.\nIn Sections 5.3 and 5.4, the computation of the expected improvement is carried out using the SMC\nmethod described in Section 4.1. Taking advantage of Remark 9, the integration is performed only on\nthe constraint space (prior to finding a feasible point) or the objective space (once a feasible point is\nfound). In the case of single-objective problems (Section 5.3), we perform exact calculation using (16)\nonce a feasible point has been observed. The parameter \u03bd of Algorithm 3 is set to 0.2 and we take\nm = mY= 1000 particles. The bounding hyper-rectangles Boand Bcare determined using the adaptive\nprocedure described in Appendix B with \u03bbo= \u03bbc= 5."},{"page":18,"text":"17\nx1\nx2\n-5\n0\n0\n510\n5\n10\n15\n(a) Constraint function\nx1\nx2\n-5\n0\n0\n510\n5\n10\n15\n(b) Objective functions\nf1\nf2\n-300\n-200-100\n0\n-250\n-200\n-150\n-100\n-50\n(c) Objective space\nFig. 5: Figure (a) represents contour lines of the constraint function, and Figure (b) corresponds to contour lines of the\ntwo objective functions. The three gray areas correspond to the feasible region on Figures (a) and (b), and the image\nof the feasible region by the objective functions on Figure (c). Thick dark curves correspond to the set of feasible and\nnon-dominated solutions on Figures (a) and (b). On Figure (c), thick dark curves correspond to the Pareto front.\nFor the optimization of the sampling criterion, we use the SMC method of Section 4.2, with m = mX=\n1000 particles, residual resampling (Douc and Capp\u00e9, 2005), and an adaptive anisotropic Gaussian\nrandom walk Metropolis-Hastings algorithm to move the particles (Andrieu and Thoms, 2008; Roberts\nand Rosenthal, 2009). When the probability of improvement cannot be written under closed-form, a\nMonte Carlo approximation (see Remark 10) with N = 100 simulations is used.\n5.2 Illustration on a constrained multi-objective problem\nIn this section, the proposed method is illustrated on a two-dimensional two-objective toy problem,\nwhich allows for easy visualization. The optimization problem is as follows:\nminimize\nsubject to\nf1and f2,\nc(x) \u2264 0 and x = (x1,x2) \u2208 [\u22125,10] \u00d7 [0,15],\nwhere\n\uf8f1\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f2\n\uf8f3\nf1: (x1,x2) ?\u2192 \u2212(x1\u2212 10)2\u2212 (x2\u2212 15)2,\nf2: (x1,x2) ?\u2192 \u2212(x1+ 5)2\u2212 x2\n?\n2,\nc : (x1,x2) ?\u2192\nx2\u22125.1\n4\u03c02x2\n1+5\n\u03c0x1\u2212 6\n?2\n+ 10\n?\n1 \u2212\n1\n8\u03c0\n?\ncos(x1) + 9.\nThe set of solutions to that problem is represented on Figure 5. The feasible subset consists of three\ndisconnected regions of relatively small size compared to that of the search space. The solution Pareto\nfront consists of three corresponding disconnected fronts in the space of objectives. (The visualization is\nachieved by evaluating the objectives and constraints on a fine grid, which would not be affordable in\nthe case of truly expensive-to-evaluate functions.)\nThe behavior of BMOO is presented in Figure 6. The algorithm is initialized with 5d = 10 function\nevaluations. Figure 6 shows that the algorithm correctly samples the three feasible regions, and achieves\ngood covering of the solution Pareto front after only a few iterations. Note that no feasible solution is\ngiven at the beginning of the procedure and that the algorithm finds one after 10 iterations."},{"page":19,"text":"18\nx1\nx2\nInput space (n = 10)\n-5\n0\n05\n10\n5\n10\n15\nf1\nf2\nObjective space (n = 10)\n-300\n-200\n-1000\n-400\n-300\n-200\n-100\nx1\nx2\nInput space (n = 20)\n-5\n0\n05\n10\n5\n10\n15\nf1\nf2\nObjective space (n = 20)\n-300\n-200-100\n-250\n-200\n-150\n-100\n-50\nx1\nx2\nInput space (n = 40)\n-5\n0\n05\n10\n5\n10\n15\nf1\nf2\nObjective space (n = 40)\n-300\n-200-100\n-250\n-200\n-150\n-100\n-50\nx1\nx2\nInput space (n = 60)\n-5\n0\n05\n10\n5\n10\n15\nf1\nf2\nObjective space (n = 60)\n-300\n-200-100\n-250\n-200\n-150\n-100\n-50\nFig. 6: Convergence of the algorithm after n = 10,20,40 and 60 evaluations. The left column shows the input space X,\nwhereas the right one shows the objective space Bo. Dominated observations are represented by triangles (filled or empty),\nand non-dominated ones by circles (or disks). The symbols are filled for feasible points and empty otherwise. On the left\ncolumn, the small dots represent the particles used for the optimization of the expected improvement (see Section 4.2).\nOn the right column, the small dots represent the particles used for the computation of the expected improvement (see\nSection 4.1). Note in particular that they appear only when a feasible point has been observed: before that, the term \u03c1feas\n(see Section 3.3) can be computed analytically.\nn"},{"page":20,"text":"19\nPbm\ng1\ng3mod\ng5mod\ng6\ng7\ng8\ng9\ng10\ng13mod\ng16\ng18\ng19\ng24\nSR7\nPVD4\nWB4\nd\n13\n20\n4\n2\n10\n2\n7\n8\n5\n5\n9\n15\n2\n7\n4\n4\nq\n9\n1\n5\n2\n8\n2\n4\n6\n3\n\u0393(%)\n4 \u00b7 10\u22124\n10\u22124\n8.7 \u00b7 10\u22122\n6.6 \u00b7 10\u22123\n10\u22124\n0.86\n0.52\n7 \u00b7 10\u22124\n4.5\n1.3 \u00b7 10\u22122\n2 \u00b7 10\u221210\n3.4 \u00b7 10\u22123\n44.3\n9.3 \u00b7 10\u22122\n5.6 \u00b7 10\u22121\n5.6 \u00b7 10\u22122\nBest\n-15\n-0.693\n5126.2\n-6961.8\n24.3\n-0.0958\n680.6\n7049.4\n0.0035\n-1.916\n-0.866\n32.66\n-5.5080\n2994.4\n5804.3\n2.3813\nTarget\n-14.85\n-0.33\n5150\n-6800\n25\n-0.09\n1000\n8000\n0.005\n-1.8\n-0.8\n40\n-5\n2995\n6000\n2.5\n38\n13\n5\n2\n11\n3\n6\nTable 1: Main features of the mono-objective problems of our first benchmark.\n5.3 Mono-objective optimization benchmark\nThe first benchmark that we use to assess the performance of BMOO consists of a set of sixteen con-\nstrained single-objective test problems proposed by Regis (2014). Table 1 summarizes the main features\nof these problems. The input dimension d varies from 2 to 20, and the number q of constraints from 1\nto 38. The problems may have linear or non-linear constraints but this information is not used by the\nalgorithms that we use in our comparisons (all functions are regarded as black boxes). Column \u0393(%)\ngives the ratio in percents of the volume of feasible region C to the volume of the search space X. This\nratio has been estimated using Monte Carlo sampling and gives an indication on the difficulty of the\nproblem for finding a feasible point. Note that problems g1, g3mod, g6, g7, g10, g19 and in particular\nproblem g18 have very small feasible regions. The last two columns correspond respectively to the best\nknown feasible objective value and to target values for the optimization. The target values are the ones\nused in the work of Regis (2014).\nBMOO is compared to two classes of algorithms. The first class consists of four local optimization\nalgorithms: the COBYLA algorithm of Powell (1994), using the implementation proposed by Johnson\n(2012), and three algorithms implemented in the Matlab function fmincon7, namely, an interior-point\nalgorithm, an active-set algorithm and an SQP algorithm. Local optimization methods are known to\nperform well on a limited budget provided that good starting points are chosen. We think that they are\nrelevant competitors in our context. The second class of algorithms are those proposed by Regis (2014),\nwhich are state-of-the-art\u2014to the best of our knowledge\u2014algorithms for constrained optimization under\na limited budget of evaluations.\nEach algorithm is run 30 times on each problem of the benchmark. Note that we use a random starting\npoint uniformly distributed inside the search domain for local search algorithms, and a random initial\ndesign for BMOO, as described in Section 5.1. For the local search algorithms the maximum number\nof evaluations is set to two hundred times the dimension d of the problem. Concerning the algorithms\nproposed by Regis (2014), we simply reproduce the results presented by the author; the reader is referred\nto the original article for more details about the settings. Results are presented in Tables 2 and 3. In\nboth tables, a solution is considered as feasible when there is no constraint violation larger than 10\u22125.\nIn Table 2, we measure the performance for finding feasible solutions. For local algorithms and Regis\u2019\nalgorithms, only the results of the best scoring algorithm are reported in the table. Full results are\npresented in Appendix C. For local algorithms, the first column indicates the best scoring algorithm:\nCob for the COBYLA algorithm, IP for the interior-point algorithm, AS for the active-set algorithm\nand SQP for the SQP algorithm. Similarly, for the algorithms proposed by Regis (2014), the first col-\n7Optimization toolbox v7.1, MATLAB R2014b"},{"page":21,"text":"20\numn indicates the best scoring algorithm: CG for COBRA-Global, CL for COBRA-Local and Ext for\nExtended-ConstrLMSRBF. The second column gives the number of successful runs\u2014a run being success-\nful when at least one feasible solution has been found. The third column gives the number of function\nevaluations that were required to find the first feasible point, averaged over the successful runs. The\ncorresponding standard deviation is given in parentheses.\nTable 3 presents convergence results. Again, for local algorithms and for those proposed by Regis (2014),\nthe first column indicates the best scoring algorithm. The next columns give successively the number of\nsuccessful runs (a run being considered successful when a feasible solution with objective value below\nthe target value of Table 1 has been found), the average number\u2014over successful runs\u2014of evaluations\nthat were required to reach the target value, and the corresponding standard deviation (in parentheses).\nThe reader is referred to Appendix C for the full results.\nBMOO achieves very good results on most test problems. It very often comes close to the best algorithm\nin each of the two classes of competitors, and sometimes significantly outperforms both of them\u2014see,\nin particular, the results for g1, g6, g7, g9, g16 and WB4 in Table 3. However, BMOO stalls on test\nproblems g3mod, g10, g18 and PVD4. We were able to identify the causes of theses problems and to\npropose remedies, which are presented in the following paragraphs. It can also be observed that BMOO\nis sometimes slower than the best algorithm of Regis (2014) to find a first feasible point. In almost all\ncases (except for g10, g18 and PVD4, which are discussed separately below), this is easily explained by\nthe size of the initial design which is Ninit= 3d in our experiments (see Section 5.1). Further work on\nthis issue is required to make it possible to start BMOO with a much smaller set of evaluations.\nRegarding g3mod, g10 and PVD4, the difficulty lies in the presence of functions, among the objective or\nthe constraints, which are not adequately modeled using a Gaussian process with a stationary covariance\nfunction. However, as we can see in Table 4, the performances of BMOO are greatly improved in all\nthree cases if a transformation of the form f \u2192 f\u03bb(for \u03bb > 0) is applied to the functions that cause the\nproblem (see Appendix D for more details). Thus, we think that the theoretical foundations of BMOO\nare not being questioned by these tests problems, but further work is needed on the Gaussian process\nmodels for a proper treatment of these cases. In light of the results of our experiments, one promising\ndirection would be to consider models of the form \u03be\u03bb, where \u03be is a Gaussian process and \u03bb is a parameter\nto be estimated from the evaluation results (see, e.g., Box and Cox, 1964; Snelson et al., 2004).\nRegarding the g18 test problem, the difficulty stems from our choice of a sampling density derived\nfrom the probability of improvement for optimizing the expected improvement. When the number of\nconstraints is high (q = 13 for the g18 test problem) and no feasible point has yet been found, the\nexpected number of particles in the feasible regions C is typically very small with this choice of density.\nConsequently, there is a high probability that none of the particles produced by the SMC algorithm\nare good candidates for the optimization of the expected improvement. To illustrate this phenomenon,\nconsider the following idealized setting. Suppose that q = d, X = [\u22121\/2,1\/2]qand cj: x = (x1,...,xq) ?\u2192\n|xj| \u2212\u03b5\nof the subset of X where exactly k constraints are satisfied is\n2, j = 1,...,q, for some \u03b5 \u2208 (0;1]. Thus, the feasible domain is C = [\u2212\u03b5\/2,\u03b5\/2]qand the volume\nVk\u2248 (q\nk) \u03b5k(1 \u2212 \u03b5)q\u2212k.\nAssume moreover that the Gaussian process models are almost perfect, i.e.,\nPn(\u03bec,j(x) \u2264 0) \u2248\n?\n1,\n0,\nif cj(x) \u2264 0,\notherwise,\n(33)\nfor j = 1,...,q. Further assume n = 1 with X1 =\nby \u03be(x) for any x \u2208 X (except at the corners) so that the probability of improvement Pn(\u03be(x) \u2208 G1) is\nclose to one everywhere on X. As a consequence, the sampling density \u03c0X\nexpected improvement is (approximately) uniform on X and the expected number of particles satisfying\nexactly k constraints is mVk. In particular, if q is large, the particles thus tend to concentrate in regions\n?1\n2,...,1\n2\n?\nand observe that \u03be(X1) is dominated\n1that we use to optimize the"},{"page":22,"text":"21\nPbm\ng1\ng3mod\ng5mod\ng6\ng7\ng8\ng9\ng10\ng13mod\ng16\ng18\ng19\ng24\nSR7\nWB4\nPVD4\nLocal (best among 4)\nIP30\nIP30\nAS 30\nAS 30\nSQP 30\nIP 30\nIP 30\nSQP25\nIP30\nCob27\nSQP30\nSQP30\nIP30\nSQP30\nSQP30\nSQP26\nRegis (best among 3)\nCG30\nExt 30\nCL30\nCL30\nCG 30\nCL 30\nCG 30\nCG30\nExt 30\nExt 30\nCL30\nCL30\nCG30\nCG30\nCL30\nCG30\nBMOO\n44.2 (1.9)\n63.1 (0.6)\n13.0 (1.2)\n9.7 (0.7)\n38.8 (3.3)\n7.0 (0.2)\n21.8 (5.1)\n71.5 (28.1)\n10.5 (5.6)\n21.7 (7.3)\n- (-)\n46.4 (3.0)\n2.6 (1.6)\n22.0 (0.2)\n19.1 (5.8)\n15.7 (5.7)\n128.4 (27.8)\n342.3 (66.3)\n35.0 (5.5)\n29.7 (5.0)\n107.6 (9.3)\n12.1 (7.7)\n170.9 (42.9)\n144.6 (132.3)\n21.4 (17.1)\n31.5 (20.4)\n101.9 (19.8)\n19.7 (6.1)\n4.0 (3.5)\n27.1 (3.6)\n76.6 (21.9)\n7.6 (4.8)\n15.0 (0)\n31.2 (0.3)\n6.4 (0.1)\n10.9 (0.3)\n47.5 (4.6)\n6.5 (0.2)\n21.5 (1.9)\n22.8 (1.5)\n8.6 (0.7)\n19.6 (1.8)\n108.6 (6.5)\n16.5 (0.5)\n1.3 (0.1)\n9.5 (0.1)\n37.4 (5.9)\n7.9 (0.4)\n30\n30\n30\n30\n30\n30\n30\n30\n30\n30\n0\n30\n30\n30\n30\n30\nTable 2: Number of evaluations to find a first feasible point. In bold, the good results in terms of average number of\nevaluations. We consider the results to be good if more than 20 runs where successful and the average number of evaluations\nis at most 20% above the best result. See Tables 11 and 13 in Appendix C for more detailed results. Dash symbols are\nused when a value cannot be calculated.\nPbm\ng1\ng3mod\ng5mod\ng6\ng7\ng8\ng9\ng10\ng13mod\ng16\ng18\ng19\ng24\nSR7\nWB4\nPVD4\nLocal (best among 4)\nIP20\nIP30\nAS30\nAS30\nSQP30\nIP18\nIP30\nSQP18\nIP25\nCob 27\nSQP 21\nSQP 30\nIP16\nSQP 30\nSQP30\nSQP23\nRegis (best among 3)\nCG30\nExt30\nCL30\nCL30\nCG30\nCL 30\nCG 30\nCG 29\nExt 30\nExt30\nCL24\nCL30\nCG30\nCG30\nCL30\nCG 30\nBMOO\n57.7 (2.6)\n- (-)\n16.3 (0.6)\n13.3 (0.8)\n55.8 (2.8)\n26.3 (10.4)\n61.6 (14.3)\n- (-)\n180.3 (84.6)\n30.3 (12.3)\n- (-)\n133.3 (6.2)\n9.9 (1.0)\n29.3 (0.7)\n44.5 (13.3)\n151.0 (21.2)\n349.7 (57.0)\n356.9 (65.1)\n35.8 (4.3)\n29.7 (5.0)\n107.6 (9.3)\n59.3 (87.0)\n179.3 (42.0)\n658.3 (316.7)\n122.5 (70.3)\n60.0 (65.2)\n97.5 (23.8)\n61.3 (12.4)\n10.4 (5.3)\n27.1 (3.6)\n78.3 (18.0)\n54.7 (27.5)\n125.2 (15.3)\n141.7 (8.6)\n12.9 (0.5)\n53.6 (14.0)\n99.8 (5.7)\n30.3 (2.8)\n176.4 (26.3)\n193.7 (-)\n146.4 (29.2)\n38.4 (3.6)\n195.9 (-)\n698.5 (75.3)\n9.0 (0)\n33.5 (1.6)\n164.6 (12.2)\n155.4 (38.2)\n30\n0\n30\n30\n30\n30\n30\n0\n30\n30\n0\n30\n30\n30\n30\n2\nTable 3: Number of evaluations to reach specified target. See Table 2 for conventions. See Tables 12 and 14 in Appendix C\nfor more detailed results.\nwhere k \u2248 q\u03b5, and the expected number mVqof particles in C is small. To compensate for the decrease\nof Vk, when k is close to q, we suggest using the following modified sampling density:\n\u03c0X\nn\u221d En\n?K(x)!1\u03be(x)\u2208Gn\n?,\nwhere K(x) is the number of constraints satisfied by \u03be at x. Table 5 shows the promising results obtained\nwith this modified density on g18. Further investigations on this particular issue are left for future work."},{"page":23,"text":"22\nPbm\nmodified-g3mod\nmodified-g10\nmodified-PVD4\nFeasible\n63.3 (0.8)\n48.4 (8.0)\n12.9 (1.6)\nTarget\n151.8 (12.2)\n63.1 (10.4)\n32.9 (13.2)\n30\n30\n30\n30\n30\n30\nTable 4: Number of evaluations to find a first feasible point and to reach the target on transformed versions of the g3mod,\ng10 and PDV4 problems, using the BMOO algorithm.\nPbm\ng18\nFeasible\n75.5 (11.5)\nTarget\n83.6 (9.1)3030\nTable 5: Number of evaluations to find a first feasible point and to reach the target using a modified probability density\nfunction for the criterion optimization.\nPbm\nBNH\nSRN\nTNK\nOSY\nTwoBarTruss\nWeldedBeam\nCONSTR\nWATER\nd\n2\n2\n2\n6\n3\n4\n2\n3\nq\n2\n2\n2\n6\n1\n4\n2\n7\np\n2\n2\n2\n2\n2\n2\n2\n5\n\u0393(%)\n93,6\n16,1\n5,1\n3,2\n86,3\n45,5\n52,5\n92\nVyref\no\n5249\n31820\n0,6466\n16169\n4495\n0,4228\n3,8152\n0,5138\n[140; 50]\n[200; 50]\n[1,2; 1,2]\n[0; 80]\n[0,06; 105]\n[50; 0,01]\n[1; 9]\n[1; 1; 1; 1,6; 3,2]\nTable 6: Main features of the multi-objective problems in our benchmark.\n5.4 Multi-objective optimization benchmark\nThe second benchmark consists of a set of eight constrained multi-objective test problems from Chafekar\net al. (2003) and Deb et al. (2002). The main features of these problems are given in Table 6. The input\ndimension d varies from two to six, and the number q of constraints from one to seven. All problems\nhave two objective functions, except the WATER test problem, which has five. As in Table 1, column\n\u0393(%) gives an estimate of the ratio (in percents) of the volume of the feasible region to that of the search\nspace. Column V gives the volume of the region\ndominated by the Pareto front8, measured using a reference point yref\nin the last column. As an illustration, the result of one run of BMOO is shown on Figure 7, for each test\nproblem.\no, whose coordinates are specified\nTo the best of our knowledge, published state-of-the-art methods to solve multi-objective optimization\nproblems in the presence of nonlinear constraints are based on genetic or evolutionary approaches. The\nmost popular algorithms are probably NSGA2 (Deb et al., 2002) and SPEA2 (Zitzler et al., 2001). Such\nalgorithms, however, are not primarily designed to work on a limited budget of function\nevaluations. Some methods that combine genetic\/evolutionary approaches and surrogate modeling tech-\nniques have been proposed in the literature (see, e.g., Emmerich et al., 2006; Jin, 2011, and references\ntherein), but a quantitative comparison with these methods would necessitate to develop proper imple-\nmentations, which is out of the scope of this paper. In this section, we shall limit ourselves to emphasizing\nadvantages and limitations of the proposed approach. Since the ability of the BMOO algorithm to find\nfeasible solutions has already been demonstrated in Section 5.3, we will focus here on the other contribu-\n8This volume has been obtained using massive runs of the gamultiobj algorithm of Matlab. It might be slightly under-\nestimated."},{"page":24,"text":"23\nf1\nf2\n040\n80\n120\n0\n15\n30\n45\n(a) BNH\nf1\nf2\n0\n100\n200300\n0\n1000\n2000\n(b) SRN\nf1\nf2\n0 0.4\n0.8\n1.2\n0\n0.4\n0.8\n1.2\n(c) TNK\nf1\nf2\n-300-200\n-100\n0\n0\n50\n100\n150\n(d) OSY\nf1\nf2\n0\n0.03 0.06\n0.09\n0\n30k\n60k\n90k\n(f) TwoBarTruss\nf1\nf2\n0\n15\n3045\n0\n0.004\n0.008\n0.012\n(g) WeldedBeam\nf1\nf2\n0.3\n0.5\n0.70.9\n1\n3\n5\n7\n(h) CONSTR\n\u2735\u2737\u2739\u2735\u2736\u2737\u2735\u2735?\u2701 \u2736\u2735\u2735?\u2701 \u2736\u2735?\u2702\u2735?\u2704 \u2736\n\u2735\n\u2737\n\u2739\n\u2735\n\u2736\n\u2737\n\u2735\n\u2735?\u2701\n\u2736\n\u2735\n\u2735?\u2701\n\u2736\n\u2735?\u2702\n\u2735?\u2704\n\u2736\n(i) WATER\nFig. 7: Result of one run of the BMOO algorithm on the problems of Table 6, with n = 100 evaluations on the bi-objective\nproblems and n = 200 evaluations on the WATER problem. Black dots represent non-dominated solutions. For bi-objective\nproblems, the set of feasible objective values is shown in gray. On the subfigure corresponding to the WeldedBeam problem,\na zoom has been made to improve visualization."},{"page":25,"text":"24\ntions of the paper: the SMC methods for the computation and optimization of the expected improvement\nsampling criterion.\nFirst, we demonstrate the effectiveness of the proposed SMC algorithm for optimizing expected im-\nprovement based criteria. We compare our SMC approach (see Section 4.2) with the approach used by\nCouckuyt et al. (2014), that we shall call MCSQP (for Monte-Carlo Sequential Quadratic Programming).\nThis approach consists in selecting the best point out of a population of candidates uniformly distributed\non the search space X, and then running an SQP algorithm starting from this point. In our experiments,\nthe number of candidates is chosen equal to the population size mX= 1000 of the SMC method.\nTable 7 presents experimental results obtained with the extended EHVI criterion proposed in Section 3\nas a sampling criterion. As a preliminary remark, observe that the finest target precision is systematically\nreached by our SMC method in all but three test cases (OSY, TwoBarTruss and WeldedBeam). The\nOSY case will be discussed below. On the TwoBarTruss and WeldedBeam problems, we found out that\nthe poor performances are due to Gaussian process modeling issues, similar to those encountered earlier\non the g3mod, g10 and PVD4 test problems (see Section 5.3). The results on these problems are thus\nleft out of the analyses in the following, but will motivate future work on the models, as concluded\nin Section 5.3. Regarding the optimization of the criteria, the results show that our SMC approach\ncompares very favorably with MCSQP. More specifically, we note a drop of performance of the MCSQP\nmethod compared with the SMC approach as we try to converge more finely toward the Pareto front\n(see, in particular, column \u201cTarget 99%\u201d of Table 7, but this is also visible in the other columns as well\nfor most of the test cases). Because of its sequential nature, the SMC approach is able to track much\nmore efficiently the concentration of the sampling criterion in the search domain, and thus makes it\npossible to reach higher accuracy.\nTables 8 and 9 provide additional results obtained when performing the same study with respectively the\nEMMI and WCPI criteria9(see Svenson and Santner, 2010; Keane, 2006, respectively). These criteria\nare not primarily designed to address constrained problems, but they can easily be extended to handle\nconstraints by calculating them using only feasible values of the objectives, and then multiplying them\nby the probability of satisfying the constraints (as explained in Section 2.3). When no feasible solution\nis available at the start of the optimization procedure, we use the probability of feasibility as a sampling\ncriterion, as advised by Gelbart et al. (2014). The conclusions drawn from Table 7 for the extended EHVI\ncriterion carry through to the results presented in Tables 8\u20139. It shows that the SMC algorithm proposed\nin Section 4.2 can be viewed as a contribution of independent interest for optimizing improvement-based\nsampling criteria.\nNext we study the influence on the convergence of the algorithm of the number m = mYof particles used\nin Algorithm 1 for approximating the expected improvement value. In Table 10 we compare the number\nof evaluations required to dominate successively 90%, 95% and 99% of the volume V of Table 6 when\nusing different numbers of particles. As expected, the overall performances of the algorithm deteriorate\nwhen the number mY of particles used to approximate the expected improvement decreases. However,\nthe algorithm maintains satisfactory convergence properties even with a small number of particles. For\nreference, we have also included results obtained by choosing the evaluation point randomly in the set\nof candidate points. Notice that these results are always much worse than those obtained using the\nsampling criterion with mY= 200. This shows that not all candidate points are equally good, and thus\nconfirms that the sampling criterion, even with a rather small value of mY, is effectively discriminating\nbetween good and bad candidate points.\nWe observe poor performances of the BMOO algorithm on the OSY test problem, regardless of the\nnumber of particles that are used to estimate the expected improvement. Figure 8 reveals that this is\ndue to the choice of a uniform sampling density on Bo\\Hnas the target density of the SMC algorithm\nused for the approximate computation of the criterion. Indeed, most of the particles do not effectively\nparticipate to the approximation of the integral, since they lie outside the set of feasible objective values\n(see Figure 7(d)). Further work is required on this topic to propose a better sampling density, that would\n9An implementation of the EMMI criterion is available in the STK. An implementation of the WCPI sampling crtiterion\nfor bi-objective problems is distributed alongside with Forrester et al.\u2019s book (Forrester et al., 2008)."},{"page":26,"text":"25\nProblemoptimizer\nSMC\nMCSQP\nSMC\nMCSQP\nSMC\nMCSQP\nSMC\nMCSQP\nSMC\nMCSQP\nSMC\nMCSQP\nSMC\nMCSQP\nSMC\nMCSQP\nTarget 90%\n8.5 (0.6)\n8.4 (0.6)\n16.7 (0.9)\n20.5 (2.4)\n35.5 (2.6)\n43.5 (4.6)\n29.0 (1.7)\n> 250 (-)\n90.9 (62.0)\n88.7 (68.4)\n146.5 (41.1)\n171.3 (46.9)\n12.4 (1.0)\n13.8 (1.4)\n48.3 (3.6)\n53.5 (4.8)\nTarget 95%\n12.7 (0.7)\n12.8 (0.7)\n22.4 (1.0)\n35.6 (5.9)\n44.1 (2.5)\n71.6 (11.3)\n38.2 (3.4)\n> 250 (-)\n234 (-)\n162.0 (29.7)\n212 (33.9)\n229.0 (-)\n19.2 (1.4)\n26.3 (3.3)\n80.7 (5.6)\n88.7 (7.5)\nTarget 99%\n34.6 (1.3)\n38.9 (2.2)\n52.6 (4.1)\n> 250 (-)\n71.1 (4.0)\n> 250 (-)\n119.8 (53.0)\n> 250 (-)\n> 250 (-)\n> 250 (-)\n> 250 (-)\n> 250 (-)\n83.5 (5.9)\n> 250 (-)\n139.1 (8.0)\n164.3 (9.6)\nBNH\n30\n30\n30\n30\n30\n30\n30\n0\n22\n26\n28\n26\n30\n30\n30\n30\n30\n30\n30\n30\n30\n30\n30\n0\n1\n2\n2\n1\n30\n30\n30\n30\n30\n30\n30\n0\n30\n0\n13\n0\n0\n0\n0\n0\n30\n0\n30\n30\nSRN\nTNK\nOSY\nTwoBarTruss\nWeldedBeam\nCONSTR\nWATER\nTable 7: Results achieved when using either SMC or MCSQP for the optimization of the extended EHVI, on the problems of\nTable 6. We measure the number of function evaluations for dominating successively 90%, 95% and 99% of the volume V . For\neach target, the first column contains the number of successful runs over 30 runs. The second column contains the number\nof function evaluations, averaged over the successful runs, with the corresponding standard deviation (in parentheses).\nDash symbols are used when a value cannot be calculated.\nf1\nf2\nBo\n-1600 -1200\n-800\n-4000\n0\n50\n100\n150\n200\n250\nFig. 8: An illustration, in the objective domain Yo, of BMOO running on the OSY test problem. The small dots are the\nparticles used for the computation of the expected improvement. They are uniformly distributed on the non-dominated\nsubset of Bo. Dark disks indicate the non-dominated solutions found so far, light gray disks indicate the dominated ones.\nconcentrate on objective values that are likely to be feasible (instead of covering uniformly the entire\nnon-dominated region Bo\\ Hn).\nIn practice, for problems with a small number of objectives, and especially for bi-objective problems,\nwe do not recommend the use of our SMC algorithm for the (approximate) computation of the EHVI\ncriterion since exact and efficient domain-decomposition-based algorithms are available (see Hupkens\net al., 2014; Couckuyt et al., 2014, and references therein). An in-depth study of the quality of the\napproximation provided by our SMC method, and a comparison with exact methods, is therefore needed\nbefore more precise recommandations can be made."},{"page":27,"text":"26\nProblemoptimizer\nSMC\nMCSQP\nSMC\nMCSQP\nSMC\nMCSQP\nSMC\nMCSQP\nSMC\nMCSQP\nSMC\nMCSQP\nSMC\nMCSQP\nSMC\nMCSQP\nTarget 90%\n9.8 (1.1)\n9.5 (0.7)\n15.5 (1.2)\n18.6 (1.8)\n47.7 (3.5)\n60.6 (8.2)\n32.3 (2.9)\n> 250 (-)\n116.5 (48.5)\n130.9 (63.9)\n156.6 (50.5)\n161.9 (60.1)\n22.1 (2.5)\n18.4 (2.1)\n60.4 (6.5)\n68.2 (8.1)\nTarget 95%\n15.9 (1.5)\n15.4 (1.4)\n21.0 (1.4)\n29.1 (2.7)\n61.8 (4.4)\n94.3 (13.2)\n41.9 (3.9)\n> 250 (-)\n199.0 (24.1)\n174.0 (-)\n177.0 (40.5)\n156.0 (35.8)\n33.8 (3.0)\n30.9 (3.1)\n93.4 (8.8)\n103.9 (11.3)\nTarget 99%\n41.2 (2.8)\n42.6 (2.4)\n48.3 (2.8)\n90.9 (9.0)\n100.2 (5.4)\n224.2 (15.0)\n73.6 (20.8)\n> 250 (-)\n> 250 (-)\n> 250 (-)\n> 250 (-)\n> 250 (-)\n100.9 (8.6)\n154.8 (9.0)\n153.9 (9.0)\n172.7 (13.7)\nBNH\n30\n30\n30\n30\n30\n30\n30\n0\n28\n26\n16\n9\n30\n30\n30\n30\n30\n30\n30\n30\n30\n30\n30\n0\n3\n1\n4\n3\n30\n30\n30\n30\n30\n30\n30\n30\n30\n5\n25\n0\n0\n0\n0\n0\n30\n30\n30\n30\nSRN\nTNK\nOSY\nTwoBarTruss\nWeldedBeam\nCONSTR\nWATER\nTable 8: Results achieved when using the EMMI criterion. See Table 7 for more information.\nProblemoptimizer\nSMC\nMCSQP\nSMC\nMCSQP\nSMC\nMCSQP\nSMC\nMCSQP\nSMC\nMCSQP\nSMC\nMCSQP\nSMC\nMCSQP\nTarget 90%\n20.9 (8.9)\n18.7 (8.2)\n39.1 (6.0)\n154.5 (62.1)\n53.3 (6.8)\n> 250 (-)\n39.7 (5.7)\n> 250 (-)\n70.1 (40.3)\n69.6 (47.3)\n> 250 (-)\n> 250 (-)\n40.0 (5.6)\n42.2 (16.0)\nTarget 95%\n43.4 (7.6)\n49.0 (14.2)\n57.53 (7.5)\n248.0 (-)\n68.3 (6.9)\n> 250 (-)\n61.5 (22.0)\n> 250 (-)\n180.4 (40.0)\n185.2 (53.0)\n> 250 (-)\n> 250 (-)\n60.4 (7.8)\n150.7 (42.8)\nTarget 99%\n132.4 (15.4)\n176.1 (29.1)\n154.9 (12.8)\n> 250 (-)\n120.8 (13.7)\n> 250 (-)\n123.0 (41.9)\n> 250 (-)\n> 250 (-)\n> 250 (-)\n> 250 (-)\n> 250 (-)\n212.1 (15.6)\n> 250 (-)\nBNH\n30\n30\n30\n20\n30\n0\n30\n0\n29\n29\n0\n0\n30\n30\n30\n30\n30\n1\n30\n0\n29\n0\n8\n11\n0\n0\n30\n26\n30\n30\n30\n0\n30\n0\n14\n0\n0\n0\n0\n0\n30\n0\nSRN\nTNK\nOSY\nTwoBarTruss\nWeldedBeam\nCONSTR\nTable 9: Results achieved when using the WCPI criterion. See Table 7 for more information.\n6 Conclusions and future work\nIn this article, a new Bayesian optimization approach is proposed to solve multi-objective optimization\nproblems with non-linear constraints. The constraints are handled using an extended domination rule\nand a new expected improvement formulation is proposed. In particular, the new formulation makes it\npossible to deal with problems where no feasible solution is available from the start. Several criteria from\nthe literature are recovered as special cases.\nThe computation and optimization of the new expected improvement criterion are carried out using\nsequential Monte Carlo sampling techniques. Indeed, the criterion takes the form of an integral over the\nspace of objectives and constraints, for which no closed-form expression is known. Besides, the sampling"},{"page":28,"text":"27\nProblemEHVI\nSMC (mY= 5000)\nSMC (mY= 1000)\nSMC (mY= 200)\nrandom\nSMC (mY= 5000)\nSMC (mY= 1000)\nSMC (mY= 200)\nrandom\nSMC (mY= 5000)\nSMC (mY= 1000)\nSMC (mY= 200)\nrandom\nSMC (mY= 5000)\nSMC (mY= 1000)\nSMC (mY= 200)\nrandom\nSMC (mY= 5000)\nSMC (mY= 1000)\nSMC (mY= 200)\nrandom\nSMC (mY= 5000)\nSMC (mY= 1000)\nSMC (mY= 200)\nrandom\nTarget 90%\n8.3 (0.7)\n8.5 (0.6)\n8.8 (0.6)\n12.8 (2.7)\n16.3 (1.0)\n16.7 (0.9)\n16.6 (1.3)\n30.6 (5.2)\n36.2 (4.4)\n35.5 (2.6)\n37.7 (4.1)\n64.0 (10.3)\n28.6 (2.0)\n29.0 (1.7)\n32.4 (3.1)\n140.2 (21.0)\n12.2 (0.7)\n12.4 (1.0)\n12.9 (1.2)\n31.1 (6.6)\n45.8 (4.0)\n48.3 (3.6)\n52.5 (4.5)\n223.2 (15.4)\nTarget 95%\n12.5 (0.5)\n12.7 (0.7)\n13.1 (0.7)\n29.6 (6.0)\n21.6 (1.1)\n22.4 (1.0)\n23.0 (1.9)\n51.1 (8.2)\n43.4 (3.6)\n44.1 (2.5)\n48.4 (5.0)\n94.2 (12.4)\n36.0 (2.8)\n38.2 (3.4)\n49 (16.0)\n203.4 (21.4)\n18.0 (1.0)\n19.2 (1.4)\n21.0 (1.6)\n58.1 (8.5)\n75.3 (6.2)\n80.7 (5.6)\n88.6 (6.0)\n> 250 (-)\nTarget 99%\n32.8 (1.0)\n34.6 (1.3)\n39.2 (2.0)\n106.8 (13.2)\n47.3 (2.1)\n52.6 (4.1)\n60.9 (6.9)\n146.2 (13.2)\n65.1 (3.1)\n71.1 (4.0)\n87.3 (5.9)\n193.3 (27.4)\n82.5 (33.5)\n119.8 (53.0)\n164.8 (54.6)\n> 250 (-)\n68.8 (4.7)\n83.5 (5.9)\n109.2 (10.7)\n235.1 (11.0)\n127 (8.2)\n139.1 (8.0)\n154.8 (8.8)\n> 250 (-)\nBNH\n30\n30\n30\n30\n30\n30\n30\n30\n30\n30\n30\n30\n30\n30\n30\n30\n30\n30\n30\n30\n30\n30\n30\n14\n30\n30\n30\n30\n30\n30\n30\n30\n30\n30\n30\n30\n30\n30\n29\n25\n30\n30\n30\n30\n30\n30\n30\n0\n30\n30\n30\n30\n30\n30\n30\n30\n30\n30\n30\n29\n22\n13\n5\n0\n30\n30\n30\n18\n30\n30\n30\n0\nSRN\nTNK\nOSY\nCONSTR\nWATER\nTable 10: Results achieved on the problems of Table 6 when using successively mY = 200,1000 and 5000 particles for\nthe approximate computation of the extended EHVI criterion. For reference, results obtained by selecting the evaluation\npoint randomly in the pool of candidates points are provided (\u201crandom\u201d rows). See Table 7 for more information.\ncriterion may be highly multi-modal, as is well known in the special case of unconstrained single-objective\noptimization, which makes it difficult to optimize. The proposed sampling techniques borrow ideas from\nthe literature of structural reliability for estimating the probability of rare events, and can be viewed as\na contribution in itself.\nWe show that the resulting algorithm, which we call BMOO, achieves good results on a set of single-\nobjective constrained test problems, with respect to state-of-the-art algorithms. In particular, BMOO\nis able to effectively find feasible solutions, even when the feasible region is very small compared to\nthe size of the search space and when the number of constraints is high. In the case of multi-objective\noptimization with non-linear constraints, we show that BMOO is able to yield good approximations of\nthe Pareto front on small budgets of evaluations.\nSeveral questions are left open for future work. First, our numerical studies reveal that the choice\nof sampling densities in the input domain (as demonstrated by unsatisfactory results on the g18 test\nproblem) and in the output domain (as shown on the OSY case) could be improved. Suggestions for\nimprovement are proposed in the article and will be the object of future investigations. Second, an in-\ndepth study of the quality of the approximation provided by our SMC method, and a comparison with\nexact methods, is needed before recommandations can be made on when to switch between exact and\napproximate calculation of the expected improvement, and how to select the sample size\u2014possibly in\nan adaptive manner\u2014used for the SMC approximation. Last, the choice of the random processes used\nfor modeling objective and constraint functions deserves more attention. Stationary Gaussian process"},{"page":29,"text":"28\nmodels have been found to lack flexibility on some single- and multi-objective cases (g3mod, g10, PVD4,\nTwoBarTruss and WeldedBeam). Several types of models proposed in the literature\u2014warped Gaussian\nprocesses (Snelson et al., 2004), non-stationary Gaussian processes (see Toal and Keane, 2012, and\nreferences therein), deep Gaussian processes (Damianou and Lawrence, 2013), etc.\u2014provide interesting\ndirections regarding this issue.\nAcknowledgements This research work has been carried out within the Technological Research Institute SystemX, using\npublic funds from the French Programme Investissements d\u2019Avenir.\nReferences\nC. Andrieu and G. O. Roberts. The pseudo-marginal approach for efficient monte carlo computations.\nThe Annals of Statistics, pages 697\u2013725, 2009.\nChristophe Andrieu and Johannes Thoms. A tutorial on adaptive mcmc. Statistics and Computing, 18\n(4):343\u2013373, 2008.\nF. Archetti and B. Betr\u00f2. A probabilistic algorithm for global optimization. CALCOLO, 16(3):335\u2013343,\n1979.\nS.-K. Au and J. L Beck. Estimation of small failure probabilities in high dimensions by subset simulation.\nProbabilistic Engineering Mechanics, 16(4):263\u2013277, 2001.\nJ. Bader and E. Zitzler. Hype: An algorithm for fast hypervolume-based many-objective optimization.\nEvolutionary Computation, 19(1):45\u201376, 2011.\nD. C. Bautista. A sequential design for approximating the pareto front using the expected pareto im-\nprovement function. PhD thesis, The Ohio State University, 2009.\nJ. Bect, D. Ginsbourger, L. Li, V. Picheny, and E. Vazquez. Sequential design of computer experiments\nfor the estimation of a probability of failure. Statistics and Computing, 22(3):773\u2013793, 2012.\nJ. Bect, E. Vazquez, et al. STK: a Small (Matlab\/Octave) Toolbox for Kriging. Release 2.4 (to appear),\n2016. URL http:\/\/kriging.sourceforge.net.\nR. Benassi. Nouvel algorithme d\u2019optimisation bay\u00e9sien utilisant une approche Monte-Carlo s\u00e9quentielle.\nPhD thesis, Sup\u00e9lec, 2013.\nR. Benassi, J. Bect, and E. Vazquez. Bayesian optimization using sequential Monte Carlo. In Learning\nand Intelligent Optimization. 6th International Conference, LION 6, Paris, France, January 16-20,\n2012, Revised Selected Papers, volume 7219 of Lecture Notes in Computer Science, pages 339\u2013342.\nSpringer, 2012.\nN. Beume. S-metric calculation by considering dominated hypervolume as klee\u2019s measure problem.\nEvolutionary Computation, 17(4):477\u2013492, 2009.\nM. Binois and V. Picheny. GPareto: Gaussian Processes for Pareto Front Estimation and Optimization,\n2015. URL http:\/\/CRAN.R-project.org\/package=GPareto. R package version 1.0.1.\nG. E. P. Box and D. R. Cox. An analysis of transformations. Journal of the Royal Statistical Society.\nSeries B (Methodological), pages 211\u2013252, 1964.\nF. C\u00e9rou, P. Del Moral, T. Furon, and A. Guyader. Sequential Monte Carlo for rare event estimation.\nStatistics and Computing, 22(3):795\u2013808, 2012.\nD. Chafekar, J. Xuan, and K. Rasheed. Constrained multi-objective optimization using steady state\ngenetic algorithms. In Genetic and Evolutionary Computation-GECCO 2003, pages 813\u2013824. Springer,\n2003.\nC. Chevalier, J. Bect, D. Ginsbourger, E. Vazquez, V. Picheny, and Y. Richet. Fast parallel kriging-based\nstepwise uncertainty reduction with application to the identification of an excursion set. Technometrics,\n56(4), 2014.\nA. R. Conn, N. I. M. Gould, and P. Toint. A globally convergent augmented lagrangian algorithm for\noptimization with general constraints and simple bounds. SIAM Journal on Numerical Analysis, 28\n(2):545\u2013572, 1991.\nI. Couckuyt, D. Deschrijver, and T. Dhaene. Fast calculation of multiobjective probability of improve-\nment and expected improvement criteria for pareto optimization. Journal of Global Optimization, 60\n(3):575\u2013594, 2014."},{"page":30,"text":"29\nA. Damianou and N. Lawrence. Deep gaussian processes. In Proceedings of the Sixteenth International\nConference on Artificial Intelligence and Statistics, pages 207\u2013215, 2013.\nK. Deb, A. Pratap, S. Agarwal, and T. Meyarivan. A fast and elitist multiobjective genetic algorithm:\nNSGA-II. Evolutionary Computation, IEEE Transactions on, 6(2):182\u2013197, 2002.\nP. Del Moral, A. Doucet, and A. Jasra. Sequential monte carlo samplers. Journal of the Royal Statistical\nSociety: Series B (Statistical Methodology), 68(3):411\u2013436, 2006.\nR. Douc and O. Capp\u00e9. Comparison of resampling schemes for particle filtering. In Image and Signal\nProcessing and Analysis, 2005. ISPA 2005. Proceedings of the 4th International Symposium on, pages\n64\u201369. IEEE, 2005.\nM. Emmerich. Single- and multiobjective evolutionary design optimization assisted by Gaussian random\nfield metamodels. PhD thesis, Technical University Dortmund, 2005.\nM. Emmerich and J. W. Klinkenberg. The computation of the expected improvement in dominated\nhypervolume of Pareto front approximations. Rapport technique, Leiden University, 2008.\nM. Emmerich, K. C. Giannakoglou, and B. Naujoks. Single- and multi-objective evolutionary optimiza-\ntion assisted by Gaussian random field metamodels. IEEE Transactions on Evolutionary Computation,\n10(4):421\u2013439, 2006.\nC. M. Fonseca and P. J. Fleming. Multiobjective optimization and multiple constraint handling with evo-\nlutionary algorithms. I. A unified formulation. IEEE Transactions on Systems, Man and Cybernetics.\nPart A: Systems and Humans, 28(1):26\u201337, 1998.\nA. I. J. Forrester, A. Sobester, and A. J. Keane. Engineering design via surrogate modelling: a practical\nguide. John Wiley & Sons, 2008.\nM. A. Gelbart. Constrained Bayesian Optimization and Applications. PhD thesis, Harvard University,\nGraduate School of Arts and Sciences, 2015.\nM. A. Gelbart, J. Snoek, and R. P. Adams. Bayesian optimization with unknown constraints. arXiv\npreprint arXiv:1403.5607, 2014.\nD. Ginsbouger and R. Le Riche. Towards Gaussian process-based optimization with finite time horizon.\nIn Invited talk at the 6th Autumn Symposium of the \"Statistical Modelling\" Research Training Group,\nNovember 21st 2009.\nR. B. Gramacy and H. Lee. Optimization under unknown constraints. In Bayesian Statistics 9. Pro-\nceedings of the Ninth Valencia International Meeting, pages 229\u2013256. Oxford University Press, 2011.\nR. B. Gramacy, G. A. Gray, S. Le Digabel, H. K. H. Lee, P. Ranjan, G. Wells, and S. M. Wild. Modeling\nan augmented lagrangian for blackbox constrained optimization. Technometrics, to appear.\nD. Hern\u00e1ndez-Lobato, J. M. Hern\u00e1ndez-Lobato, A. Shah, and R. P. Adams. Predictive entropy search\nfor multi-objective bayesian optimization. arXiv preprint arXiv:1511.05467, 2015a.\nJ. M. Hern\u00e1ndez-Lobato, M. A. Gelbart, M. W. Hoffman, R. P. Adams, and Z. Ghahramani. Predic-\ntive entropy search for bayesian optimization with unknown constraints. In Proceedings of the 32nd\nInternational Conference on Machine Learning, Lille, France, 2015. JMLR: W&CP volume 37, 2015b.\nJ. M. Hern\u00e1ndez-Lobato, M. A. Gelbart, R. P. Adams, M. W. Hoffman, and Z. Ghahramani. A general\nframework for constrained bayesian optimization using information-based search. TBD, to appear.\nD. Horn, T. Wagner, D. Biermann, C. Weihs, and B. Bischl. Model-based multi-objective optimization:\nTaxonomy, multi-point proposal, toolbox and benchmark. In Evolutionary Multi-Criterion Optimiza-\ntion, pages 64\u201378. Springer, 2015.\nI. Hupkens, M. Emmerich, and A. Deutz. Faster computation of expected hypervolume improvement.\narXiv preprint arXiv:1408.7114, 2014.\nS. Jeong and S. Obayashi. Efficient global optimization (ego) for multi-objective problem and data\nmining. In Evolutionary Computation, 2005. The 2005 IEEE Congress on, volume 3, pages 2138\u2013\n2145, 2005.\nS. Jeong, Y. Minemura, and S. Obayashi. Optimization of combustion chamber for diesel engine using\nkriging model. Journal of Fluid Science and Technology, 1(2):138\u2013146, 2006.\nY. Jin. Surrogate-assisted evolutionary computation: Recent advances and future challenges. Swarm\nand Evolutionary Computation, 1(2):61\u201370, 2011.\nS. G. Johnson. The nlopt nonlinear-optimization package (version 2.3). URL http:\/\/ab-initio. mit.\nedu\/nlopt, 2012."},{"page":31,"text":"30\nD. R. Jones, M. Schonlau, and W. J. Welch. Efficient global optimization of expensive black-box func-\ntions. Journal of Global Optimization, 13(4):455\u2013492, 1998.\nA. J. Keane. Statistical improvement criteria for use in multiobjective design optimization. AIAA\njournal, 44(4):879\u2013891, 2006.\nJ. Knowles. Parego: a hybrid algorithm with on-line landscape approximation for expensive multiobjec-\ntive optimization problems. Evolutionary Computation, IEEE Transactions on, 10(1):50\u201366, 2006.\nJ. Knowles and E. J. Hughes. Multiobjective optimization on a budget of 250 evaluations. In Evolutionary\nMulti-Criterion Optimization, pages 176\u2013190. Springer, 2005.\nH. J Kushner. A new method of locating the maximum point of an arbitrary multipeak curve in the\npresence of noise. Journal of Fluids Engineering, 86(1):97\u2013106, 1964.\nL. Li. Sequential Design of Experiments to Estimate a Probability of Failure. PhD thesis, Sup\u00e9lec, 2012.\nL. Li, J. Bect, and E. Vazquez. Bayesian Subset Simulation: a kriging-based subset simulation algorithm\nfor the estimation of small probabilities of failure. In Proceedings of PSAM 11 & ESREL 2012, 25-29\nJune 2012, Helsinki, Finland. IAPSAM, 2012.\nJ. S. Liu. Monte Carlo strategies in scientific computing. Springer, 2008.\nJ. L. Loeppky, J. Sacks, and W. J. Welch. Choosing the sample size of a computer experiment: A\npractical guide. Technometrics, 51(4), 2009.\nJ. Mockus. On Bayesian methods of optimization. In Towards Global Optimization, pages 166\u2013181.\nNorth-Holland, 1975.\nJ. Mockus.\nBayesian approach to global optimization: theory and applications, volume 37.\nAcademic Publishers, 1989.\nJ. Mockus, V. Tiesis, and A. \u017dilinskas. The application of Bayesian methods for seeking the extremum. In\nL. C. W. Dixon and G\u00e1bor. P. Szeg\u00f6, editors, Towards Global Optimization, volume 2, pages 117\u2013129,\nNorth Holland, New York, 1978.\nA. Oyama, K. Shimoyama, and K. Fujii. New constraint-handling method for multi-objective and multi-\nconstraint evolutionary optimization. Transactions of the Japan Society for Aeronautical and Space\nSciences, 50(167):56\u201362, 2007.\nJ. M. Parr, A. J. Keane, A. I. J. Forrester, and C. M. E. Holden. Infill sampling criteria for surrogate-\nbased optimization with constraint handling. Engineering Optimization, 44(10):1147\u20131166, 2012.\nV. Picheny. A stepwise uncertainty reduction approach to constrained global optimization. In Proceed-\nings of the 17th International Conference on Artificial Intelligence and Statistics (AISTATS), 2014,\nReykjavik, Iceland., volume 33, pages 787\u2013795. JMLR: W&CP, 2014a.\nV. Picheny. Multiobjective optimization using Gaussian process emulators via stepwise uncertainty\nreduction. Statistics and Computing, DOI:10.1007\/s11222-014-9477-x:1\u201316, 2014b.\nW. Ponweiser, T. Wagner, D. Biermann, and M. Vincze. Multiobjective optimization on a limited budget\nof evaluations using model-assisted S-metric selection. In Parallel Problem Solving from Nature (PPSN\nX), volume 5199 of Lecture Notes in Computer Science, pages 784\u2013794. Springer, 2008.\nM. J. D. Powell. A direct search optimization method that models the objective and constraint functions\nby linear interpolation. In Advances in optimization and numerical analysis, pages 51\u201367. Springer,\n1994.\nT. Ray, K. Tai, and K. C. Seow. Multiobjective design optimization by an evolutionary algorithm.\nEngineering Optimization, 33(4):399\u2013424, 2001.\nR. G. Regis. Constrained optimization by radial basis function interpolation for high-dimensional ex-\npensive black-box problems with infeasible initial points. Engineering Optimization, 46(2):218\u2013243,\n2014.\nC. Robert and G. Casella. Monte Carlo statistical methods. Springer, 2013.\nGareth O Roberts and Jeffrey S Rosenthal. Examples of adaptive mcmc. Journal of Computational and\nGraphical Statistics, 18(2):349\u2013367, 2009.\nT. J. Santner, B. J. Williams, and W. Notz. The design and analysis of computer experiments. Springer\nScience & Business Media, 2003.\nM. J. Sasena. Flexibility and efficiency enhancements for constrained global design optimization with\nkriging approximations. PhD thesis, University of Michigan, 2002.\nM. J. Sasena, P. Papalambros, and P. Goovaerts. Exploration of metamodeling sampling criteria for\nconstrained global optimization. Engineering Optimization, 34(3):263\u2013278, 2002.\nKluwer"},{"page":32,"text":"31\nM. Schonlau, W. J. Welch, and D. R. Jones. Global versus local search in constrained optimization of\ncomputer models. In New Developments and Applications in Experimental Design: Selected Proceedings\nof a 1997 Joint AMS-IMS-SIAM Summer Conference, volume 34 of IMS Lecture Notes-Monographs\nSeries, pages 11\u201325. Institute of Mathematical Statistics, 1998.\nK. Shimoyama, K. Sato, S. Jeong, and S. Obayashi. Updating kriging surrogate models based on the\nhypervolume indicator in multi-objective optimization. Journal of Mechanical Design, 135(9):094503,\n2013.\nE. Snelson, C. E. Rasmussen, and Z. Ghahramani. Warped gaussian processes. Advances in neural\ninformation processing systems, 16:337\u2013344, 2004.\nM. L. Stein. Interpolation of Spatial Data: Some Theory for Kriging. Springer, 1999.\nJ. D. Svenson and T. J. Santner. Multiobjective optimization of expensive black-box functions via\nexpected maximin improvement. Technical report, Tech. rep., 43210, Ohio University, Columbus,\nOhio, 2010.\nD. J. J. Toal and A. J. Keane. Non-stationary kriging for design optimization. Engineering Optimization,\n44(6):741\u2013765, 2012.\nE. Vazquez and J. Bect.A new integral loss function for Bayesian optimization.\narXiv:1408.4622, 2014. URL http:\/\/arxiv.org\/abs\/1408.4622.\nJ. Villemonteix, E. Vazquez, and E. Walter. An informational approach to the global optimization of\nexpensive-to-evaluate functions. Journal of Global Optimization, 44(4):509\u2013534, 2009.\nT. Wagner, M. Emmerich, A. Deutz, and W. Ponweiser. On expected-improvement criteria for model-\nbased multi-objective optimization. In Parallel Problem Solving from Nature, PPSN XI. 11th Inter-\nnational Conference, Krakov, Poland, September 11-15, 2010, Proceedings, Part I, volume 6238 of\nLecture Notes in Computer Science, pages 718\u2013727. Springer, 2010.\nB. J. Williams, T. J. Santner, W. I. Notz, and J. S. Lehman. Sequential design of computer experiments\nfor constrained optimization. In T. Kneib and G. Tutz, editors, Statistical Modelling and Regression\nStructures, pages 449\u2013472. Physica-Verlag HD, 2010.\nC. K. I. Williams and C. Rasmussen. Gaussian processes for machine learning. the MIT Press, 2(3):4,\n2006.\nQ. Zhang, W. Liu, E. Tsang, and B. Virginas. Expensive multiobjective optimization by moea\/d with\ngaussian process model. Evolutionary Computation, IEEE Transactions on, 14(3):456\u2013474, 2010.\nE. Zitzler, M. Laumanns, and L. Thiele. SPEA2: Improving Strength Pareto Evolutionary Algorithm,\n2001.\narXiv preprint\nA On the bounded hyper-rectangles Boand Bc\nWe have assumed in Section 3 that Bo and Bc are bounded hyper-rectangles; that is, sets of the form\nBo=?y \u2208 Yo; ylow\no\n\u2264 y \u2264 yupp\n\u2264 y \u2264 yupp\no\n?,\nBc=?y \u2208 Yc; ylow\n\u2208 Yc, with the additional assumption that ylow\ncc\n?,\nfor some ylow\nRemember that upper bounds only where required in the unconstrained case discussed in Section 2.2. To shed some light\non the role of these lower and upper bounds, let us now compute the improvement I1(X1) = |H1| brought by a single\nevaluation.\no\n,yupp\no\n\u2208 Yo and ylow\nc\n, yupp\nc\nc,j\n< 0 < yupp\nc,j\nfor all j \u2264 q.\nIf X1is not feasible, then\n|H1| = |Bo| \u00b7\nq\n?\nj=1\n?\nyupp\nc,j\u2212 ylow\nc,j\n?\u03b3j?\nyupp\nc,j\u2212 \u03bec,j(X1)\n?1\u2212\u03b3j\n(34)\nwhere \u03b3j= 1\u03bec,j(X1)\u22640. It is clear from the right-hand side of (34) that both Bo and Bc have to be bounded if we want\n|H1| < +\u221e for any \u03b3 = (\u03b31,,..., \u03b3q) \u2208 {0,1}q. Note, however, that only the volume of Bo actually matters in this\nexpression, not the actual values of ylow\no\no\n. Equation (34) also reveals that the improvement is a discontinuous\nfunction of the observations: indeed, the jthterm in the product jumps from yupp\ngoes from 0+to 0. The increment \u2212ylow\nrespect to the jthconstraint.\nand yupp\nc,j\nto yupp\nc,j\u2212 ylow\nc,j> yupp\nc,j\nwhen \u03bec,j(X1)\nc,jcan be thought of as a reward associated to finding a point which is feasible with"},{"page":33,"text":"32\nThe value of |H1| when X1is feasible is\n|H1| = |Bo| \u00b7\n?|Bc| \u2212??B\u2212\n??? is the volume of the feasible subset of Bc, B\u2212\nc\n???\n+\n?\nj\u2264p\n?\nmin\n?\n\u03beo,j(X1),yupp\no,j\n?\n\u2212 max\n?\n\u03beo,j(X1),ylow\no,j\n??\n\u00b7\n??B\u2212\nc\n??,\n(35)\nwhere\nside of (35) is the improvement associated to the domination of the entire unfeasible subset of B = Bo\u00d7 Bc; the second\nterm measures the improvement in the space of objective values.\n???B\u2212\nc\n??? =?q\nj=1\n???ylow\nc,j\nc = Bc\u2229]\u2212\u221e;0]q. The first term in the right-hand\nB An adaptive procedure to set Boand Bc\nThis section describes the adaptive numerical procedure that is used, in our numerical experiments, to define the hyper-\nrectangles Boand Bc. As said in Section 3.3, these hyper-rectangles are defined using estimates of the range of the objective\nand constraint functions, respectively. To this end, we will use the available evaluations results, together with posterior\nquantiles provided by our Gaussian process models on the set of candidate points Xn (defined in Section 4.2).\nMore precisely, assume that n evaluation results \u03be(Xi), 1 \u2264 i \u2264 n, are available. Then, we define the corners of Bo by\n\uf8f1\n\uf8f3\nfor 1 \u2264 i \u2264 p, and the corners of Bc by\n\uf8f1\n\uf8f3\nfor 1 \u2264 j \u2264 q, where \u03bbo and \u03bbc are positive numbers.\n\uf8f2\nylow\no,i,n= min\nyupp\no,i,n= max\n?\nmini\u2264n\u03beo,i(Xi), minx\u2208Xn?\u03beo, i, n(x) \u2212 \u03bbo\u03c3o, i, n(x)\n?\n,\n?\nmaxi\u2264n\u03beo,i(Xi), maxx\u2208Xn?\u03beo, i, n(x) + \u03bbo\u03c3o, i, n(x)\n?\n,\n(36)\n\uf8f2\nylow\nc,j,n= min\nyupp\nc,j,n= max\n?\n0, mini\u2264n\u03bec,j(Xi), minx\u2208Xn?\u03bec, j, n(x) \u2212 \u03bbc\u03c3c, j, n(x)\n?\n,\n?\n0, maxi\u2264n\u03bec,j(Xi), maxx\u2208Xn?\u03bec, j, n(x) + \u03bbc\u03c3c, j, n(x)\n?\n,\n(37)\nC Mono-objective benchmark result tables\nIn Section 5.3, only the best results for both the \u201cLocal\u201d and the \u201cRegis\u201d groups of algorithms were shown. In this Appendix,\nwe present the full results. Tables 11 and 12, and Tables 13 and 14 present respectively the results obtained with the local\noptimization algorithms and the results obtained by Regis (2014) on the single-objective benchmark test problems (see\nTable 1). Table 11 and Table 12 show the performances for finding feasible solutions and for reaching the targets specified\nin Table 1 for the COBYLA, Active-Set, Interior-Point and SQP algorithms. Similarly, Table 13 and Table 14 show\nthe performances for finding feasible solutions and for reaching the targets for the COBRA-Local, COBRA-Global and\nExtended-ConstrLMSRBF algorithms of Regis (2014).\nD Modified g3mod, g10 and PVD4 test problems\nWe detail here the modified formulations of the g3mod, g10 and PVD4 problems that were used in Section 5.3 to overcome\nthe modeling problems with BMOO. Our modifications are shown in boldface. The rationale of the modifications is to\nsmooth local jumps.\n\u2013 modified-g3mod problem\n?f(x) = \u2212plog((\u221ad)d?d\ni=1xi)0.1\nc(x) = (?d\ni=1x2\ni) \u2212 1\n\u2013 modified-g10 problem\n\uf8f1\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f2\n\uf8f3\nf(x) = x1+ x2+ x3\nc1(x) = 0.0025(x4+ x6) \u2212 1\nc2(x) = 0.0025(x5+ x7\u2212 x4) \u2212 1\nc3(x) = 0.01(x8\u2212 x5) \u2212 1\nc4(x) = plog(100x1\u2212 x1x6+ 833.33252x4\u2212 83333.333)7\nc5(x) = plog(x2x4\u2212 x2x7\u2212 1250x4+ 1250x5)7\nc6(x) = plog(x3x5\u2212 x3x8\u2212 2500x5+ 1250000)7"},{"page":34,"text":"33\nPbm\ng1\ng3mod\ng5mod\ng6\ng7\ng8\ng9\ng10\ng13mod\ng16\ng18\ng19\ng24\nSR7\nWB4\nPVD4\nCOBYLA\n52.3 (102.3)\n386.1 (645.8)\n30.7 (23.0)\n39.7 (12.7)\n162.4 (175.7)\n53.3 (77.1)\n95.2 (104.7)\n14.5 (3.5)\n53.9 (68.8)\n31.5 (20.4)\n345.0 (275.7)\n31.4 (19.5)\n7.7 (10.2)\n30.0 (50.1)\n71.8 (82.5)\n50.8 (70.2)\nactive-set\n15.0 (0.0)\n643.2 (248.9)\n35.0 (5.5)\n29.7 (5.0)\n109.4 (11.2)\n17.6 (5.0)\n313.7 (84.4)\n53.6 (41.9)\n74.0 (59.5)\n38.0 (15.0)\n114.5 (41.5)\n21.8 (7.5)\n5.2 (5.3)\n27.5 (3.9)\n125.7 (71.0)\n51.3 (27.7)\ninterior-point\n128.4 (27.8)\n342.3 (66.3)\n41.3 (16.9)\n99.7 (14.3)\n146.0 (18.1)\n12.1 (7.7)\n170.9 (42.9)\n469.8 (393.8)\n21.4 (17.1)\n100.9 (160.3)\n70.3 (22.2)\n291.3 (57.9)\n4.0 (3.5)\n78.6 (23.1)\n93.5 (48.9)\n59.1 (43.5)\nsqp\n15.0 (0.0)\n794.3 (53.7)\n38.5 (10.5)\n32.6 (5.4)\n107.6 (9.3)\n19.6 (8.5)\n194.5 (60.2)\n144.6 (132.3)\n69.4 (62.4)\n40.7 (17.1)\n101.9 (19.8)\n19.7 (6.1)\n5.1 (5.2)\n27.1 (3.6)\n76.6 (21.9)\n7.6 (4.8)\n30\n28\n22\n26\n28\n28\n25\n2\n30\n27\n26\n19\n30\n29\n27\n12\n30\n30\n30\n30\n30\n28\n30\n9\n30\n30\n30\n30\n30\n30\n30\n3\n30\n30\n30\n30\n30\n30\n30\n12\n30\n22\n30\n30\n30\n30\n30\n30\n30\n30\n30\n30\n30\n30\n30\n25\n30\n30\n30\n30\n30\n30\n30\n26\nTable 11: Number of evaluations to find a first feasible point for the COBYLA, Active-Set, Interior-Point and SQP local\noptimization algorithms. See Table 2 for conventions.\nPbm\ng1\ng3mod\ng5mod\ng6\ng7\ng8\ng9\ng10\ng13mod\ng16\ng18\ng19\ng24\nSR7\nWB4\nPVD4\nCOBYLA\n212.9 (225.8)\n1312.3 (1123.6)\n53.4 (20.3)\n41.0 (11.1)\n495.5 (461.3)\n79.5 (84.6)\n144.9 (143.7)\n- (-)\n191.9 (209.7)\n60.0 (65.2)\n383.0 (389.3)\n912.1 (685.8)\n17.5 (8.9)\n62.5 (52.1)\n247.1 (176.2)\n58.0 (35.4)\nactive-set\n22.0 (7.7)\n760.5 (79.8)\n35.8 (4.3)\n29.7 (5.0)\n109.4 (11.2)\n30.5 (2.1)\n334.5 (84.0)\n- (-)\n153.9 (46.6)\n85.1 (41.1)\n101.0 (30.2)\n61.3 (12.4)\n14.7 (3.9)\n27.5 (3.9)\n162.0 (73.1)\n54.0 (25.1)\ninterior-point\n349.7 (57.0)\n356.9 (65.1)\n54.8 (11.7)\n99.7 (14.3)\n147.2 (18.2)\n59.3 (87.0)\n179.3 (42.0)\n- (-)\n122.5 (70.3)\n400.0 (242.1)\n149.1 (39.4)\n335.5 (65.4)\n10.4 (5.3)\n80.2 (22.1)\n168.2 (94.4)\n146.7 (115.2)\nsqp\n22.0 (7.7)\n794.3 (53.7)\n41.8 (7.5)\n32.6 (5.4)\n107.6 (9.3)\n55.8 (27.0)\n194.5 (60.2)\n658.3 (316.7)\n147.6 (75.1)\n152.2 (53.2)\n97.5 (23.8)\n61.3 (12.4)\n16.4 (5.3)\n27.1 (3.6)\n78.3 (18.0)\n54.7 (27.5)\n76 20\n30\n30\n30\n30\n18\n30\n0\n25\n13\n21\n30\n16\n30\n30\n26\n6\n16\n22\n26\n20\n4\n22\n0\n23\n27\n14\n16\n18\n28\n24\n2\n24\n30\n30\n30\n2\n30\n0\n24\n14\n21\n30\n17\n30\n29\n3\n30\n30\n30\n30\n4\n30\n18\n22\n30\n21\n30\n17\n30\n30\n23\nTable 12: Number of evaluations to reach the target for the COBYLA, Active-Set, Interior-Point and SQP local opti-\nmization algorithms. See Table 2 for conventions.\n\u2013 modified-PVD4 problem\n\uf8f1\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f3\n\uf8f2\nf(x) = 0.6224x1x3x4+ 1.7781x2x2\nc1(x) = \u2212x1+ 0.0193x3\nc2(x) = \u2212x2+ 0.00954x3\nc3(x) = plog(\u2212\u03c0x2\n3+ 3.1661x2\n1x4+ 19.84x2\n1x3\n3x4\u2212 4\/3\u03c0x3\n3+ 1296000)7\nNote that the above defined problems make use of the plog function defined below (see Regis (2014)).\nplog(x) =\n?log(1 + x)\nif x \u2265 0\n\u2212log(1 \u2212 x) otherwise"},{"page":35,"text":"34\nPbm\ng1\ng3mod\ng5mod\ng6\ng7\ng8\ng9\ng10\ng13mod\ng16\ng18\ng19\ng24\nSR7\nWB4\nPVD4\nCOBRA-Local\n3015.0 (0.0)\n3023.5 (0.2)\n306.4 (0.1)\n3010.9 (0.3)\n3047.5 (4.6)\n306.5 (0.2)\n3021.5 (1.9)\n3022.8 (1.5)\n30 9.4 (0.8)\n3014.7 (2.4)\n30 108.6 (6.5)\n3016.5 (0.5)\n301.3 (0.1)\n309.5 (0.1)\n3037.4 (5.9)\n30 7.9 (0.4)\nCOBRA-Global\n30 15.0 (0.0)\n3023.5 (0.2)\n30 6.4 (0.1)\n3010.9 (0.3)\n3047.5 (4.7)\n306.5 (0.2)\n3021.5 (1.9)\n3022.8 (1.5)\n30 9.4 (0.8)\n3014.7 (2.4)\n30108.6 (6.5)\n30 16.5 (0.5)\n301.3 (0.1)\n30 9.5 (0.1)\n30 37.4 (5.9)\n307.9 (0.4)\nExtended-ConstrLMSRBF\n3019.1 (0.4)\n30 31.2 (0.3)\n309.6 (0.3)\n30 11.9 (0.2)\n3039.8 (2.9)\n305.2 (0.2)\n3023.1 (2.3)\n3051.1 (6.5)\n308.6 (0.7)\n3019.6 (1.8)\n30 122.0 (5.6)\n30 20.8 (0.8)\n301.3 (0.1)\n30 12.4 (0.4)\n30 25.0 (4.1)\n30 10.4 (0.7)\nTable 13: Number of evaluations to find a first feasible point for the COBRA-Local, COBRA-Global and Extended-\nConstrLMSRBF optimization algorithms. These results are taken from (Regis, 2014).\nPbm\ng1\ng3mod\ng5mod\ng6\ng7\ng8\ng9\ng10\ng13mod\ng16\ng18\ng19\ng24\nSR7\nWB4\nPVD4\nCOBRA-Local\n7 387.8 (-)\n6451.1 (-)\n30 12.9 (0.5)\n30 53.6 (14.0)\n30 199.5 (20.7)\n30 30.3 (2.8)\n28275.5 (-)\n30 276.4 (43.6)\n30221.7 (35.6)\n30 38.8 (9.3)\n24 195.9 (-)\n30698.5 (75.3)\n309.0 (0.0)\n30 35.0 (2.7)\n30164.6 (12.2)\n28 212.2 (-)\nCOBRA-Global\n30125.2 (15.3)\n6440.0 (-)\n3016.6 (1.8)\n30 62.5 (10.5)\n3099.8 (5.7)\n30 31.2 (2.5)\n30176.4 (26.3)\n29 193.7 (-)\n30169.0 (19.1)\n30 46.3 (13.5)\n23 212.8 (-)\n30850.9 (70.6)\n309.0 (0.0)\n3033.5 (1.6)\n30202.0 (13.0)\n30155.4 (38.2)\nExtended-ConstrLMSRBF\n0 > 500 (-)\n30 141.7 (8.6)\n3040.3 (1.4)\n26 101.2 (-)\n30264.5 (34.2)\n3046.2 (6.2)\n29 294.0 (-)\n24394.3 (-)\n30146.4 (29.2)\n3038.4 (3.6)\n21 276.0 (-)\n0> 1000 (-)\n3091.9 (6.0)\n0 > 500 (-)\n30238.6 (20.0)\n29263.5 (-)\nTable 14: Number of evaluations to reach the target for the COBRA-Local, COBRA-Global and Extended-\nConstrLMSRBF optimization algorithms. These results are taken from (Regis, 2014). See Table 2 for conventions."}],"widgetId":"rgw27_56ab9d61e091d"},"id":"rgw27_56ab9d61e091d","partials":[],"templateName":"publicliterature\/stubs\/PublicationText.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationText.html?publicationUid=282570552&hide=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationDetailAd":{"data":{"googleDfpSlot":null,"widgetId":"rgw28_56ab9d61e091d"},"id":"rgw28_56ab9d61e091d","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAd.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAd.html?publicationUid=282570552&slotId=336x280_Publications_ATF_Right&collapseSlotMode=never&fallbackContainerEnabled=1","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationRelations":null,"publicationRelationsReverse":null,"publicationUid":282570552,"showSignUpDialog":false,"selectNewSignUpDialog":false,"publicationQuestions":null,"publicationCitations":{"data":{"publicationUid":282570552,"publicationCitationsList":{"data":{"citationItems":[],"hasCitations":false,"sort":"normal","sortNormal":true,"sortOriginal":false,"publicationUid":282570552,"publicationLink":"publication\/282570552_A_Bayesian_approach_to_constrained_single-_and_multi-objective_optimization","showOriginalOrderSortingOption":true,"hasShowMore":true,"newOffset":10,"pageSize":10,"widgetId":"rgw30_56ab9d61e091d"},"id":"rgw30_56ab9d61e091d","partials":[],"templateName":"publicliterature\/stubs\/PublicationCitationsList.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationCitationsList.html?publicationUid=282570552&sort=&totalCount=70&swapJournalAndAuthorPositions=0&showAbstract=1&showType=1&showPublicationPreview=1","viewClass":"views.publicliterature.PublicationCitationsListView","yuiModules":["rg.views.publicliterature.PublicationCitationsListView"],"stylesheets":[],"_isYUI":true},"hasCitations":true,"citationsCount":70,"hasIncomingCitations":false,"incomingCitationsCount":0,"showCitationsSorter":true,"showAbstract":true,"showType":true,"showPublicationPreview":true,"swapJournalAndAuthorPositions":false,"sort":"","sortOriginal":false,"citationList":"outgoing","showsIncoming":false,"showSorting":true,"usePlainButton":null,"useEnrichedContext":null,"widgetId":"rgw29_56ab9d61e091d"},"id":"rgw29_56ab9d61e091d","partials":[],"templateName":"publicliterature\/stubs\/PublicationCitations.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationCitations.html?publicationUid=282570552&citationList=&citedInPage=1&sort=","viewClass":"views.publicliterature.PublicationCitationsView","yuiModules":["rg.views.publicliterature.PublicationCitationsView"],"stylesheets":[],"_isYUI":true},"publicationReviewPromo":null,"publicationUsedInReviews":null,"publicationPdfJsReader":null,"useFulltextOptimizedLayout":false,"publicationActions":null,"requestFulltextPromo":null,"currentUrl":"publication\/282570552_A_Bayesian_approach_to_constrained_single-_and_multi-objective_optimization","isLeaderboardAd":false,"enableStickyBox":null,"googleDfpSlotMobileBottom":null,"fullTextExitPopup":null,"showExitPopupDialog":false,"widgetId":"rgw2_56ab9d61e091d"},"id":"rgw2_56ab9d61e091d","partials":{"romeo_legal_notice":"publicliterature\/stubs\/partials\/romeo_legal_notice.html"},"templateName":"publicliterature\/stubs\/PublicPublicationDetails_NewLayout.html","templateExtensions":["generalHelpers"],"attrs":{"publicationUid":282570552},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicPublicationDetailsOld.html?publicationUid=282570552&isTestOldDesign=0","viewClass":"views.publicliterature.PublicPublicationDetailsOldView","yuiModules":["rg.views.publicliterature.PublicPublicationDetailsOldView"],"stylesheets":[],"_isYUI":true},"widgetId":"rgw1_56ab9d61e091d"},"id":"rgw1_56ab9d61e091d","partials":[],"templateName":"publicliterature\/stubs\/PublicPublicationDetails.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicPublicationDetails.html","viewClass":"views.publicliterature.PublicPublicationDetailsView","yuiModules":["rg.views.publicliterature.PublicPublicationDetailsView"],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"uaClass":"","headPrefix":[],"rootUrl":"https:\/\/www.researchgate.net\/","requestToken":"FDaeDgwwuzLTK04T3FaxXhmCLPcViawTbupqWYY8hAXMg7gYL57tt4zcq4wVJkl5gpGjqeWT7+g+hxJJD72n5aDhWhIRSuDEPXmiIsguC5sKQp4O9\/hOPJWFV4gX4KpLZq2ozp+wTrfZFSsFdnx\/vxL2\/BJ19JU\/taSOxE2WgIRsAkrJhXiqRY78faA\/vkiZTRe\/0bcUg6LyNvbkjifL05vCQA6kE\/vCBG8NhEtmd8AFcj+61DSpzly3xTaG3qof\/O2Gosrw3iHw6AYvUlndkx3KVoxs6suAVdZ9i60AzbM=","faviconCdnUrl":"https:\/\/c5.rgstatic.net\/m\/2390829798215018\/images\/favicon.ico","headerOutput":"<noscript><\/noscript><link rel=\"canonical\" href=\"https:\/\/www.researchgate.net\/publication\/282570552_A_Bayesian_approach_to_constrained_single-_and_multi-objective_optimization\" \/>\n<link rel=\"dns-prefetch\" href=\"\/\/c5.rgstatic.net\" \/>\n<link rel=\"dns-prefetch\" href=\"\/\/i1.rgstatic.net\" \/>\n<meta property=\"twitter:card\" content=\"summary\" \/>\n<meta property=\"twitter:site\" content=\"@ResearchGate\" \/>\n<meta property=\"og:title\" content=\"A Bayesian approach to constrained single- and multi-objective optimization\" \/>\n<meta property=\"og:description\" content=\"This article addresses the problem of derivative-free (single- or multi-objective) optimization subject to multiple inequality constraints. Both the objective and constraint functions are assumed...\" \/>\n<meta property=\"og:site_name\" content=\"ResearchGate\" \/>\n<meta property=\"og:image\" content=\"https:\/\/i1.rgstatic.net\/publication\/282570552_A_Bayesian_approach_to_constrained_single-_and_multi-objective_optimization\/links\/569e3d4308ae16fdf07c454f\/smallpreview.png\" \/>\n<meta property=\"og:url\" content=\"https:\/\/www.researchgate.net\/publication\/282570552_A_Bayesian_approach_to_constrained_single-_and_multi-objective_optimization\" \/>\n<meta property=\"rg:id\" content=\"PB:282570552\" \/>\n<meta name=\"DC.identifier\" scheme=\"DCTERMS.URI\" content=\"http:\/\/dx.doi.org\/\" \/>\n<meta name=\"gs_meta_revision\" content=\"1.1\" \/>\n<meta name=\"citation_title\" content=\"A Bayesian approach to constrained single- and multi-objective optimization\" \/>\n<meta name=\"citation_author\" content=\"Paul F\u00e9liot\" \/>\n<meta name=\"citation_author\" content=\"Julien Bect\" \/>\n<meta name=\"citation_author\" content=\"Emmanuel Vazquez\" \/>\n<meta name=\"citation_publication_date\" content=\"2015\/09\/23\" \/>\n<meta name=\"citation_abstract_html_url\" content=\"https:\/\/www.researchgate.net\/publication\/282570552_A_Bayesian_approach_to_constrained_single-_and_multi-objective_optimization\" \/>\n<meta name=\"citation_fulltext_html_url\" content=\"https:\/\/www.researchgate.net\/publication\/282570552_A_Bayesian_approach_to_constrained_single-_and_multi-objective_optimization\" \/>\n<meta name=\"viewport\" content=\"width=device-width,initial-scale=1\" \/>\n<link href=\"\/\/c5.rgstatic.net\/m\/22664197317151888\/styles\/rg.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/21004998181197492\/styles\/rg2.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<!--[if lt IE 9]><link href=\"\/\/c5.rgstatic.net\/m\/238176252723686\/styles\/ie.css\" type=\"text\/css\" rel=\"stylesheet\"\/><![endif]-->\n<link href=\"\/\/c5.rgstatic.net\/m\/217752362214895\/styles\/modules\/publicprofile.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<script src=\"\/\/c5.rgstatic.net\/m\/2321000301012716\/javascript\/vendor\/webfontloader\/webfontloader.js\" type=\"text\/javascript\"><\/script>\n <script>(function(i,s,o,g,r,a,m){i[\"GoogleAnalyticsObject\"]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,\"script\",\"\/\/www.google-analytics.com\/analytics.js\",\"ga\");\n ga(\"create\",\"UA-58591210-1\");ga(\"set\",\"anonymizeIp\",true);ga('set', 'dimension1', 'publication slurped');ga('set', 'dimension2', 'Article');ga('set', 'dimension3', 'Logged out');ga('set', 'dimension4', 'https');ga(\"send\",\"pageview\");<\/script>\n","webfont":"<noscript><\/noscript><script> WebFontConfig = { custom: { families: ['source_sans_pro_italic', 'source_sans_pro_bold', 'source_sans_pro', 'martel'], urls : ['\/\/c5.rgstatic.net\/m\/231392577336386\/styles\/fonts.css'] } }; WebFont.load(WebFontConfig); <\/script>\n","correlationId":"rgreq-a6ca9f68-5341-4338-aea2-09e76e7365d0","accountId":null,"module":"publicliterature","action":"publicliterature.PublicPublicationDetails","page":"publicationDetail","product":"publications","backendTime":375,"continent":"Asia","stylesHome":"\/\/c5.rgstatic.net\/m\/","staticHost":"c5.rgstatic.net","useEarlyFlush":false,"longRunningRequestIdentifier":"LongRunningRequest.publicliterature.PublicPublicationDetails","longRunningRequestFp":"e9e5bbe1366c7ee8c8e41d02f793c884ac9be19b","widgetId":"rgw31_56ab9d61e091d"},"id":"rgw31_56ab9d61e091d","partials":[],"templateName":"application\/stubs\/StaticHeader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.StaticHeader.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){
            Y.rg.core.pagespeed.Monitoring.monitorPage("\/\/glassmoni.researchgate.net", "publicliterature.PublicPublicationDetails.run.html.loggedOut.get", "59de9668d07aeb77ab4de5f24d382b5d199d2437", "rgreq-a6ca9f68-5341-4338-aea2-09e76e7365d0", "d52c7442689f067c7a7fc3c91d7dffef23c85153");
        
            Y.rg.core.pagespeed.Monitoring.monitorPage("\/\/glassmoni.researchgate.net", "publicationDetail.loggedOut", "ed1993d9e20f6cefa83edacaa24401a18c071aea", "rgreq-a6ca9f68-5341-4338-aea2-09e76e7365d0", "d52c7442689f067c7a7fc3c91d7dffef23c85153");
        })();
(function(){Y.rg.createInitialWidget({"data":{"year":"2016","inlinePromo":null,"isAdmin":false,"contactUrl":"https:\/\/www.researchgate.net\/contact","aboutUsUrl":"https:\/\/www.researchgate.net\/about","widgetId":"rgw32_56ab9d61e091d"},"id":"rgw32_56ab9d61e091d","partials":[],"templateName":"application\/stubs\/DefaultFooter.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.DefaultFooter.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"headerLogin":{"data":{"urlAfterLogin":"publication\/282570552_A_Bayesian_approach_to_constrained_single-_and_multi-objective_optimization","requestToken":"0xjqYPPWKVXIHSQM6lDfnD0CRYqjKwd3M\/Hshd19mnPq5v9bfNEMIA50eaAiTX9tPktx2jUTpLry+lbkEwUCpbBSfEfB9IU65QP61ajPg2dkUSuwlxKs3kDBxLfloCTRUkm4Wv0XBn95MCh4zKq3oakVr72aBqQJdfhdYEBUEif\/ft8MH4YgMiFPBBPKmroUDEJm7AqcjxBiQSbBgJr8DrVLdp1rEPXa+1jldd1ECguy+XM8KmgwrFerbHk8ci8svuzol2zCtis1ky3Kwh7sMu2\/jmTEpq3m9FIRSVi0Nho=","loginUrl":"https:\/\/www.researchgate.net\/application.Login.html","signupUrl":"https:\/\/www.researchgate.net\/signup.SignUp.html?ev=su_chnl_index&hdrsu=1&_sg=TXSisDefaqz6P6SDC7KWhRlR_x4Fp8Aaqw9ADbfcm8QMzfu5sBolGKa0W1KgqcpK","encodedUrlAfterLogin":"cHVibGljYXRpb24vMjgyNTcwNTUyX0FfQmF5ZXNpYW5fYXBwcm9hY2hfdG9fY29uc3RyYWluZWRfc2luZ2xlLV9hbmRfbXVsdGktb2JqZWN0aXZlX29wdGltaXphdGlvbg%3D%3D","signupCallToAction":"Join for free","widgetId":"rgw34_56ab9d61e091d"},"id":"rgw34_56ab9d61e091d","partials":{"partial":"application\/stubs\/partials\/headerLoginDefault.html"},"templateName":"application\/stubs\/HeaderLogin.html","templateExtensions":[],"attrs":{"goal":"milestoneHeaderLoginSeen"},"widgetUrl":"https:\/\/www.researchgate.net\/application.HeaderLogin.html","viewClass":"views.application.HeaderLoginView","yuiModules":["rg.views.application.HeaderLoginView"],"stylesheets":[],"_isYUI":true},"cookieConsent":null,"logoSvgSrc":"https:\/\/c5.rgstatic.net\/m\/235107188705592\/images\/template\/brand-header-logo.svg","logoFallbackSrc":"https:\/\/c5.rgstatic.net\/m\/238113351022438\/images\/template\/brand-header-logo.png","widgetId":"rgw33_56ab9d61e091d"},"id":"rgw33_56ab9d61e091d","partials":{"schemaSocialProfiles":"application\/stubs\/partials\/schemaSocialProfiles.html"},"templateName":"application\/stubs\/HeaderLoggedOut.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.HeaderLoggedOut.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"logEvent":"su_banner","specialCopy":false,"widgetId":"rgw35_56ab9d61e091d"},"id":"rgw35_56ab9d61e091d","partials":[],"templateName":"application\/stubs\/LoggedOutBanner.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.LoggedOutBanner.html","viewClass":"views.application.LoggedOutBannerView","yuiModules":["rg.views.application.LoggedOutBannerView"],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.core.util.ParameterFilter.filter(["ev","cp","ch","ref","dbw","pli","loginT","uid","claimChannel","enrichId","enrichSource","utm_source","utm_medium","utm_campaign","el","ci"]);})();
});}); } else { throw 'YRG was not loaded when attaching widgets'; }</script><script> dataLayer = [{"pageCategory":"publication slurped","publicationType":"Article","eventCategory":"Publication page"}]; </script> <noscript><iframe src="//www.googletagmanager.com/ns.html?id=GTM-MKVKH7" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-MKVKH7');</script><script>(function(e){function n(n,t,o,a){"use strict";var i=e.document.createElement("link"),r=t||e.document.getElementsByTagName("script")[0],d=e.document.styleSheets;return i.rel="stylesheet",i.href=n,i.media="only x",a&&(i.onload=a),r.parentNode.insertBefore(i,r),i.onloadcssdefined=function(e){for(var t,o=0;d.length>o;o++)d[o].href&&d[o].href.indexOf(n)>-1&&(t=!0);t?e():setTimeout(function(){i.onloadcssdefined(e)})},i.onloadcssdefined(function(){i.media=o||"all"}),i}function t(e,n){e.onload=function(){e.onload=null,n&&n.call(e)},"isApplicationInstalled"in navigator&&"onloadcssdefined"in e&&e.onloadcssdefined(n)}var o=function(a,i){"use strict";if(a&&3===a.length){var r=e.Image,d=!(!document.createElementNS||!document.createElementNS("http://www.w3.org/2000/svg","svg").createSVGRect||!document.implementation.hasFeature("http://www.w3.org/TR/SVG11/feature#Image","1.1")||e.opera&&-1===navigator.userAgent.indexOf("Chrome")||-1!==navigator.userAgent.indexOf("Series40")),c=new r;c.onerror=function(){o.method="png",o.href=a[2],n(a[2])},c.onload=function(){var e=1===c.width&&1===c.height,r=a[e&&d?0:e?1:2];o.method=e&&d?"svg":e?"datapng":"png",o.href=r,t(n(r),i)},c.src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///ywAAAAAAQABAAACAUwAOw==",document.documentElement.className+=" grunticon"}};o.loadCSS=n,o.onloadCSS=t,e.grunticon=o})(this);grunticon(["https://c5.rgstatic.net/c/o1q2er/styles/icons/_header-ico.svg.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_header-ico.png.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_header-ico.fallback.scss"]);grunticon(["https://c5.rgstatic.net/c/o1q2er/styles/icons/_admin-ico.svg.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_admin-ico.png.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_admin-ico.fallback.scss"]);grunticon(["https://c5.rgstatic.net/c/o1q2er/styles/icons/_ico.svg.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_ico.png.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_ico.fallback.scss"]);</script></body>
</html>
