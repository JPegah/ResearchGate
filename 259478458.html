<!DOCTYPE html> <html lang="en" class="" id="rgw33_56ab9e9f28d33"> <head > <meta charset="utf-8"/> <meta http-equiv="content-type" content="text/html; charset=UTF-8"/> <meta name="Rg-Request-Token" id="Rg-Request-Token" content="VwBIuDSqnajQLNPePQaewVo3hs8qFYol/Lebr6vOnZ065YkGchJFyY0f0DUrWcTbwq8wwDC+YXYh/zK+IloAeVY2D1wlk6AkvplmMxQ6xDnMqfJl+jLH6bbjeQj6u4wuB3expygIwsgVa+dcT7b381k/dvBA99AUiNfofCkcPQ9zIP6usDvNJ0vGTJfG3XBeons/x3BYzt+cPJCi8PEjqI1fSC+XQEXibmu118lw21BsnR8YkM+7HkvUhl9CuYn6kb9kWKT0xED3VTlcfXeK7eDn5kIGt5KxuSx6zno8CvI="/> <meta http-equiv="expires" content="0"/> <link rel="apple-touch-icon" sizes="57x57" href="https://www.researchgate.net/apple-touch-icon-57x57.png"> <link rel="apple-touch-icon" sizes="60x60" href="https://www.researchgate.net/apple-touch-icon-60x60.png"> <link rel="apple-touch-icon" sizes="72x72" href="https://www.researchgate.net/apple-touch-icon-72x72.png"> <link rel="apple-touch-icon" sizes="76x76" href="https://www.researchgate.net/apple-touch-icon-76x76.png"> <link rel="apple-touch-icon" sizes="114x114" href="https://www.researchgate.net/apple-touch-icon-114x114.png"> <link rel="apple-touch-icon" sizes="120x120" href="https://www.researchgate.net/apple-touch-icon-120x120.png"> <link rel="apple-touch-icon" sizes="144x144" href="https://www.researchgate.net/apple-touch-icon-144x144.png"> <link rel="apple-touch-icon" sizes="152x152" href="https://www.researchgate.net/apple-touch-icon-152x152.png"> <link rel="apple-touch-icon" sizes="180x180" href="https://www.researchgate.net/apple-touch-icon-180x180.png"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-32x32.png" sizes="32x32"> <link rel="icon" type="image/png" href="https://www.researchgate.net/android-chrome-192x192.png" sizes="192x192"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-96x96.png" sizes="96x96"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-16x16.png" sizes="16x16"> <link rel="shortcut icon" type="image/x-icon" href="https://c5.rgstatic.net/m/2390829798215018/images/favicon.ico"/> <link rel="manifest" href="https://www.researchgate.net/manifest.json"> <meta name="msapplication-TileColor" content="#da532c"> <meta name="msapplication-TileImage" content="https://www.researchgate.net/mstile-144x144.png"> <meta name="theme-color" content="#444444"> <link rel="search" type="application/opensearchdescription+xml" title="ResearchGate search" href="https://www.researchgate.net/application.DownloadOpenSearchPlugin.html"/> <link rel="meta" type="application/rdf+xml" title="ICRA labels" href="https://www.researchgate.net/application.DownloadLabels.html"/> <link rel="http://oexchange.org/spec/0.8/rel/related-target" type="application/xrd+xml" href="https://www.researchgate.net/application.DownloadOExchange.html"/> <base href="https://www.researchgate.net/"/> <script>
    var rgConfig = {
        correlationId: "rgreq-38eebf55-0611-448a-ae0e-415cff12bd4a",
        accountId: "",
        module: "publicliterature",
        action: "publicliterature.PublicPublicationDetails",
        page: "publicationDetail",
        product: "publications",
        continent: "Asia",
        stylesHome: "//c5.rgstatic.net/m/",
        staticHost: "c5.rgstatic.net",
        longRunningRequestIdentifier: "LongRunningRequest.publicliterature.PublicPublicationDetails",
        longRunningRequestFp: "e9e5bbe1366c7ee8c8e41d02f793c884ac9be19b"
    };
    window.rootUrl = "https://www.researchgate.net/";
</script> <link rel="canonical" href="https://www.researchgate.net/publication/259478458_lil'_UCB_An_Optimal_Exploration_Algorithm_for_Multi-Armed_Bandits" />
<link rel="dns-prefetch" href="//c5.rgstatic.net" />
<link rel="dns-prefetch" href="//i1.rgstatic.net" />
<meta property="twitter:card" content="summary" />
<meta property="twitter:site" content="@ResearchGate" />
<meta property="og:title" content="lil' UCB : An Optimal Exploration Algorithm for Multi-Armed Bandits" />
<meta property="og:description" content="The paper proposes a novel upper confidence bound (UCB) procedure for
identifying the arm with the largest mean in a multi-armed bandit game in the
fixed confidence setting using a small number of..." />
<meta property="og:site_name" content="ResearchGate" />
<meta property="og:image" content="https://i1.rgstatic.net/publication/259478458_lil'_UCB_An_Optimal_Exploration_Algorithm_for_Multi-Armed_Bandits/links/03032c260cf23a729b8645b8/smallpreview.png" />
<meta property="og:url" content="https://www.researchgate.net/publication/259478458_lil'_UCB_An_Optimal_Exploration_Algorithm_for_Multi-Armed_Bandits" />
<meta property="rg:id" content="PB:259478458" />
<meta name="DC.identifier" scheme="DCTERMS.URI" content="http://dx.doi.org/" />
<meta name="gs_meta_revision" content="1.1" />
<meta name="citation_title" content="lil' UCB : An Optimal Exploration Algorithm for Multi-Armed Bandits" />
<meta name="citation_author" content="Kevin Jamieson" />
<meta name="citation_author" content="Matthew Malloy" />
<meta name="citation_author" content="Robert Nowak" />
<meta name="citation_author" content="SÃ©bastien Bubeck" />
<meta name="citation_publication_date" content="2013/12/27" />
<meta name="citation_journal_title" content="Journal of Machine Learning Research" />
<meta name="citation_issn" content="1532-4435" />
<meta name="citation_volume" content="35" />
<meta name="citation_abstract_html_url" content="https://www.researchgate.net/publication/259478458_lil'_UCB_An_Optimal_Exploration_Algorithm_for_Multi-Armed_Bandits" />
<meta name="citation_fulltext_html_url" content="https://www.researchgate.net/publication/259478458_lil'_UCB_An_Optimal_Exploration_Algorithm_for_Multi-Armed_Bandits" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<link href="//c5.rgstatic.net/m/22664197317151888/styles/rg.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/21004998181197492/styles/rg2.css" type="text/css" rel="stylesheet"/>
<!--[if lt IE 9]><link href="//c5.rgstatic.net/m/238176252723686/styles/ie.css" type="text/css" rel="stylesheet"/><![endif]-->
<link href="//c5.rgstatic.net/m/217752362214895/styles/modules/publicprofile.css" type="text/css" rel="stylesheet"/>
<script src="//c5.rgstatic.net/m/2321000301012716/javascript/vendor/webfontloader/webfontloader.js" type="text/javascript"></script>
 <script>(function(i,s,o,g,r,a,m){i["GoogleAnalyticsObject"]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,"script","//www.google-analytics.com/analytics.js","ga");
 ga("create","UA-58591210-1");ga("set","anonymizeIp",true);ga('set', 'dimension1', 'publication slurped');ga('set', 'dimension2', 'Article');ga('set', 'dimension3', 'Logged out');ga('set', 'dimension4', 'https');ga("send","pageview");</script>
  <script> WebFontConfig = { custom: { families: ['source_sans_pro_italic', 'source_sans_pro_bold', 'source_sans_pro', 'martel'], urls : ['//c5.rgstatic.net/m/231392577336386/styles/fonts.css'] } }; WebFont.load(WebFontConfig); </script><noscript></noscript>

<title>lil' UCB : An Optimal Exploration Algorithm for Multi-Armed Bandits</title>
<meta name="description" content="lil' UCB : An Optimal Exploration Algorithm for Multi-Armed Bandits on ResearchGate, the professional network for scientists."/>
<meta name="keywords" content="scientific network, scientific platform, scientific community, research partner, research collaboration, journal articles, international collaboration, find researcher, lifescience researcher, interdisciplinary research, research collaboration"/>
</head>
<body class="use-svg-icons logged-out">
<div id="page-container">
<script type="text/javascript">var googletag = googletag || {}; googletag.cmd = googletag.cmd || [];
(function() { var gads = document.createElement("script"); gads.async = true; gads.type = "text/javascript"; var useSSL = "https:" == document.location.protocol; gads.src = (useSSL ? "https:" : "http:") + "//www.googletagservices.com/tag/js/gpt.js"; var node =document.getElementsByTagName("script")[0]; node.parentNode.insertBefore(gads, node); })();</script><div id="main" class="logged-out-header-support">
<div id="content" class="">

<noscript>
<div class="c-box-warning full-width-element" style="text-align: center; ">
    <div style="margin: auto; padding:10px;" class="container">
        <b>For full functionality of ResearchGate it is necessary to enable JavaScript.
            Here are the <a href="http://www.enable-javascript.com/" rel="nofollow" target="_blank">
                instructions how to enable JavaScript in your web browser</a>.</b>
    </div>
</div>
</noscript>

<div id="rgw1_56ab9e9f28d33" itemscope itemtype="http://schema.org/ScholarlyArticle"><div class="publication-wrapper publication-wrapper-onecol" id="rgw2_56ab9e9f28d33" itemscope itemtype="http://schema.org/ScholarlyArticle"> <div class="c-col-content"> <div class="c-content"> <div class="clearfix">  <div class="publication-header"> <div id="rgw7_56ab9e9f28d33">  <div class="type-label"> Article   </div> <span class="Z3988" title="ctx_ver=Z39.88-2004&rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&rfr_id=info%3Asid%2Fresearchgate.net%3Aresearchgate&rft.atitle=lil%26%2339%3B%20UCB%20%3A%20An%20Optimal%20Exploration%20Algorithm%20for%20Multi-Armed%20Bandits&rft.title=Journal%20of%20Machine%20Learning%20Research&rft.jtitle=Journal%20of%20Machine%20Learning%20Research&rft.volume=35&rft.date=2013&rft.issn=1532-4435&rft.au=Kevin%20Jamieson%2CMatthew%20Malloy%2CRobert%20Nowak%2CS%C3%A9bastien%20Bubeck&rft.genre=article"></span> <h1 class="pub-title" itemprop="name">lil&#39; UCB : An Optimal Exploration Algorithm for Multi-Armed Bandits</h1> <meta itemprop="headline" content="lil&#39; UCB : An Optimal Exploration Algorithm for Multi-Armed Bandits">  <meta itemprop="image" content="https://i1.rgstatic.net/publication/259478458_lil&#39;_UCB_An_Optimal_Exploration_Algorithm_for_Multi-Armed_Bandits/links/03032c260cf23a729b8645b8/smallpreview.png">  <div id="rgw10_56ab9e9f28d33" class="publication-detail-author-list"> <div> <ul class="clearfix js-people-list">  <li id="rgw11_56ab9e9f28d33"> <a href="researcher/2011869224_Kevin_Jamieson" class="pub-detail-item author-item" itemprop="author" itemscope itemtype="http://schema.org/Person"> <div class="indent-left"> <div class="people-img">  <img src="https://c5.rgstatic.net/m/2951093203564/images/template/default/profile/profile_default_s.jpg" title="Kevin Jamieson" alt="Kevin Jamieson" height="20px" width="20px" style="height: 20px;"/>  </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Kevin Jamieson</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item   not-claimed " id="rgw12_56ab9e9f28d33">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="researcher/2011869224_Kevin_Jamieson"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="Kevin Jamieson" alt="Kevin Jamieson" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">       </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="researcher/2011869224_Kevin_Jamieson" class="display-name">Kevin Jamieson</a>    </h5> <div class="truncate-single-line meta">   </div>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>  <li id="rgw13_56ab9e9f28d33"> <a href="researcher/71218256_Matthew_Malloy" class="pub-detail-item author-item" itemprop="author" itemscope itemtype="http://schema.org/Person"> <div class="indent-left"> <div class="people-img">  <img src="https://c5.rgstatic.net/m/2951093203564/images/template/default/profile/profile_default_s.jpg" title="Matthew Malloy" alt="Matthew Malloy" height="20px" width="20px" style="height: 20px;"/>  </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Matthew Malloy</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item   not-claimed " id="rgw14_56ab9e9f28d33">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="researcher/71218256_Matthew_Malloy"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="Matthew Malloy" alt="Matthew Malloy" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">       </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="researcher/71218256_Matthew_Malloy" class="display-name">Matthew Malloy</a>    </h5> <div class="truncate-single-line meta">   </div>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>  <li id="rgw15_56ab9e9f28d33"> <a href="researcher/9168935_Robert_Nowak" class="pub-detail-item author-item" itemprop="author" itemscope itemtype="http://schema.org/Person"> <div class="indent-left"> <div class="people-img">  <img src="https://c5.rgstatic.net/m/2951093203564/images/template/default/profile/profile_default_s.jpg" title="Robert Nowak" alt="Robert Nowak" height="20px" width="20px" style="height: 20px;"/>  </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Robert Nowak</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item   not-claimed " id="rgw16_56ab9e9f28d33">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="researcher/9168935_Robert_Nowak"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="Robert Nowak" alt="Robert Nowak" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">       </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="researcher/9168935_Robert_Nowak" class="display-name">Robert Nowak</a>    </h5> <div class="truncate-single-line meta">   </div>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>  <li id="rgw17_56ab9e9f28d33"> <a href="researcher/2007706959_Sebastien_Bubeck" class="pub-detail-item author-item" itemprop="author" itemscope itemtype="http://schema.org/Person"> <div class="indent-left"> <div class="people-img">  <img src="https://c5.rgstatic.net/m/2951093203564/images/template/default/profile/profile_default_s.jpg" title="SÃ©bastien Bubeck" alt="SÃ©bastien Bubeck" height="20px" width="20px" style="height: 20px;"/>  </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">SÃ©bastien Bubeck</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item   not-claimed " id="rgw18_56ab9e9f28d33">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="researcher/2007706959_Sebastien_Bubeck"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="SÃ©bastien Bubeck" alt="SÃ©bastien Bubeck" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">       </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="researcher/2007706959_Sebastien_Bubeck" class="display-name">SÃ©bastien Bubeck</a>    </h5> <div class="truncate-single-line meta">   </div>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>   </ul> <div class="js-loading"></div>  </div> </div> <div class="pub-details js-pub-details">      <span itemprop="isPartOf" itemscope itemtype="http://schema.org/Periodical"> <a itemprop="sameAs" href="journal/1532-4435_Journal_of_Machine_Learning_Research"><span itemprop="name">Journal of Machine Learning Research</span></a> </span>    (Impact Factor: 2.47).     <meta itemprop="datePublished" content="2013-12">  12/2013;  35.             <div class="pub-source"> Source: <a href="http://arxiv.org/abs/1312.7308" rel="nofollow">arXiv</a> </div>  </div> <div id="rgw19_56ab9e9f28d33" class="pub-abstract">  <div class="clearfix">   <div style="max-height: 54px;" class="js-expander-container js-expander-collapsed">  <p itemprop="description"> <strong>ABSTRACT</strong> <div>The paper proposes a novel upper confidence bound (UCB) procedure for<br />
identifying the arm with the largest mean in a multi-armed bandit game in the<br />
fixed confidence setting using a small number of total samples. The procedure<br />
cannot be improved in the sense that the number of samples required to identify<br />
the best arm is within a constant factor of a lower bound based on the law of<br />
the iterated logarithm (LIL). Inspired by the LIL, we construct our confidence<br />
bounds to explicitly account for the infinite time horizon of the algorithm. In<br />
addition, by using a novel stopping time for the algorithm we avoid a union<br />
bound over the arms that has been observed in other UCB-type algorithms. We<br />
prove that the algorithm is optimal up to constants and also show through<br />
simulations that it provides superior performance with respect to the<br />
state-of-the-art.</div> </p>  </div>  </div>   </div>      <div class="action-container">   <div class="clear"></div> <div class="share-dialog-container" style="display: none;">  </div> </div> </div> <div style="margin-left: -20px; margin-right: -20px;">  </div> </div>  <div class="publication-detail-dfp-container rf"> <div id="rgw32_56ab9e9f28d33">  </div> </div>  </div>  <div class="clearfix">  <noscript> <div id="rgw31_56ab9e9f28d33"  itemprop="articleBody">  <p>Page 1</p> <p>lilâ UCB : An Optimal Exploration Algorithm for<br />Multi-Armed Bandits<br />Kevin Jamiesonâ , Matthew Malloyâ , Robert Nowakâ , and SÂ´ ebastien Bubeckâ¡<br />â Department of Electrical and Computer Engineering,<br />University of Wisconsin-Madison<br />â¡Department of Operations Research and Financial Engineering,<br />Princeton University<br />Abstract<br />The paper proposes a novel upper confidence bound (UCB) procedure for identifying the<br />arm with the largest mean in a multi-armed bandit game in the fixed confidence setting using a<br />small number of total samples. The procedure cannot be improved in the sense that the number<br />of samples required to identify the best arm is within a constant factor of a lower bound based<br />on the law of the iterated logarithm (LIL). Inspired by the LIL, we construct our confidence<br />bounds to explicitly account for the infinite time horizon of the algorithm. In addition, by<br />using a novel stopping time for the algorithm we avoid a union bound over the arms that<br />has been observed in other UCB-type algorithms. We prove that the algorithm is optimal up to<br />constants and also show through simulations that it provides superior performance with respect<br />to the state-of-the-art.<br />1 Introduction<br />This paper introduces a new algorithm for the best arm problem in the stochastic multi-<br />armed bandit (MAB) setting. Consider a MAB with n arms, each with unknown mean payoff<br />Âµ1,...,Âµnin [0,1]. A sample of the ith arm is an independent realization of a sub-Gaussian<br />random variable with mean Âµi. In the fixed confidence setting, the goal of the best arm prob-<br />lem is to devise a sampling procedure with a single input Î´ that, regardless of the values of<br />Âµ1,...,Âµn, finds the arm with the largest mean with probability at least 1âÎ´. More precisely,<br />best arm procedures must satisfy supÂµ1,...,ÂµnP(?i ?= iâ) â¤ Î´, where iâis the best arm,?i an<br />a unique best arm. In this sense, best arm procedures must automatically adjust sampling to<br />ensure success when the mean of the best and second best arms are arbitrarily close. Contrast<br />this with the fixed budget setting where the total number of samples remains a constant and the<br />confidence in which the best arm is identified within the given budget varies with the setting<br />of the means. While the fixed budget and fixed confidence settings are related (see [1] for a<br />discussion) this paper focuses on the fixed confidence setting only.<br />The best arm problem has a long history dating back to the â50s with the work of [2,3].<br />In the fixed confidence setting, the last decade has seen a flurry of activity providing new<br />estimate of the best arm, and the supremum is taken over all set of means such that there exists<br />1<br />arXiv:1312.7308v1  [stat.ML]  27 Dec 2013</p>  <p>Page 2</p> <p>upper and lower bounds. In 2002, the successive elimination procedure of [4] was shown to<br />find the best arm with order?<br />bound was also obtained using a procedure known as LUCB1 that was originally designed<br />for finding the m-best arms [6]. Recently, [7] proposed a procedure called PRISM which<br />succeeds with?<br />The best sample complexity result for the fixed confidence setting comes from a procedure<br />similar to PRISM, called exponential-gap elimination [8], which guarantees identification of<br />the best arm with high probability using order?<br />the loglog term cannot be avoided, it remained unclear as to whether the upper bound of [8]<br />or the lower bound of [5] was loose.<br />The classic work of [9] answers this question. It shows that the doubly logarithmic factor<br />is necessary, implying that order?<br />?<br />are i.i.d. sub-Gaussian random variables with E[X?] = 0, E[X2<br />?t<br />limsup<br />tââ<br />almost surely. Here is the basic intuition behind the lower bound. Consider the two-arm<br />problem and let â be the difference between the means. In this case, it is reasonable to sample<br />both arms equally and consider the sum of differences of the samples, which is a random<br />walk with drift â. The deterministic drift crosses the LIL bound (for a zero-mean walk) when<br />tâ =â2tloglogt. Solving this equation for t yields t â 2ââ2loglogââ2. This intuition<br />will be formalized in the next section.<br />TheLILalsomotivatesanovelapproachtothebestarmproblem. Specifically, theLILsug-<br />gests a natural scaling for confidence bounds on empirical means, and we follow this intuition<br />to develop a new algorithm for the best-arm problem. The algorithm is an Upper Confidence<br />Bound (UCB) procedure [11] based on a finite sample version of the LIL. The new algorithm,<br />called lilâUCB, is described in Figure 1. By explicitly accounting for the loglog factor in the<br />confidence bound and using a novel stopping criterion, our analysis of lilâUCB avoids taking<br />naive union bounds over time, as encountered in some UCB algorithms [6,12], as well as the<br />wasteful âdoubling trickâ often employed in algorithms that proceed in epochs, such as the<br />PRISM and exponential-gap elimination procedures [4,7,8]. Also, in some analyses of best<br />arm algorithms the upper confidence bounds of each arm are designed to hold with high prob-<br />ability for all arms uniformly, incurring a log(n) term in the confidence bound as a result of<br />the necessary union bound over the n arms [4,6,12]. However, our stopping time allows for a<br />tighter analysis so that arms with larger gaps are allowed larger confidence bounds than those<br />arms with smaller gaps where higher confidence is required. Like exponential-gap elimination,<br />lilâUCB is order optimal in terms of sample complexity.<br />One of the main motivations for this work was to develop an algorithm that exhibits great<br />practical performance in addition to optimal sample complexity. While the sample complexity<br />of exponential-gap elimination is optimal up to constants, and PRISM up to small loglog fac-<br />i?=iâââ2<br />i<br />log(nââ2<br />i) samples, where âi= Âµiâ â Âµi, coming<br />i?=iâââ2<br />within a logarithmic factor of the lower bound of?<br />i, shown in 2004 in [5]. A similar<br />iââ2<br />i<br />loglog<br />??<br />jââ2<br />j<br />?<br />or?<br />iââ2<br />i<br />log?ââ2<br />i<br />?samples depending on the<br />parameterization of the algorithm, improving the result of [4] by at least a factor of log(n).<br />iââ2<br />i<br />loglogââ2<br />i<br />samples, coming within a<br />doubly logarithmic factor of the lower bound of [5]. While the authors of [8] conjecture that<br />iââ2<br />i<br />loglogââ2<br />i<br />samples are necessary and sufficient<br />in the sense that no procedure can satisfy supâ1,...,ânP(?i ?= iâ) â¤ Î´ and use fewer than<br />is a consequence of the law of the iterated logarithm (LIL) [10]. The LIL states that if X?<br />iââ2<br />i<br />loglogââ2<br />i<br />samplesinexpectationforallâ1,...,ân. Thedoublylogarithmicfactor<br />?] = Ï2and we define St =<br />?=1X?then<br />St<br />?2Ï2tloglog(t)<br />= 1 and<br />liminf<br />tââ<br />St<br />?2Ï2tloglog(t)<br />= â1<br />2</p>  <p>Page 3</p> <p>tors, the empirical performance of these methods is rather disappointing, even when compared<br />to non-sequential sampling. Both PRISM and exponential-gap elimination employ median<br />elimination [4] as a subroutine. Median elimination is used to find an arm that is within Îµ &gt; 0<br />of the largest, and has sample complexity within a constant factor of optimal for this subprob-<br />lem. However, the constant factors tend to be quite large, and repeated applications of median<br />elimination within PRISM and exponential-gap elimination are extremely wasteful. On the<br />contrary, lilâUCB does not invoke wasteful subroutines. As we will show, in addition to hav-<br />ing the best theoretical sample complexities bounds known to date, lilâUCB exhibits superior<br />performance in practice with respect to state-of-the-art algorithms.<br />2 Lower Bound<br />Before introducing the lilâUCB algorithm, we show that the loglog factor in the sample com-<br />plexity is necessary for best-arm identification. It suffices to consider a two armed bandit<br />problem with a gap â. If a lower bound on the gap is unknown, then the loglog factor is<br />necessary, as shown by the following result of [9].<br />Corollary 1 Consider the best arm problem in the fixed confidence setting with n = 2 and<br />expected number of samples Eâ[T]. Any procedure with supâ?=0P(?i ?= iâ) â¤ Î´, Î´ â (0,1/2),<br />limsup<br />ââ0<br />Proof Consider a reduction of the best arm problem with n = 2 in which the value of one<br />arm is known. In this case, the only strategy available is to sample the other arm some number<br />of times to determine if it is less than or greater than the known value. We have reduced the<br />problem precisely to that studied by Farrell in [9], restated below.<br />necessarily has<br />Eâ[T]<br />ââ2loglogââ2<br />â¥<br />2 â 4Î´.<br />Theorem 1 [9, Theorem 1]. Let Xi<br />testing whether â &gt; 0 or â &lt; 0. Let Y â {â1,1} be the decision of any such test based on<br />T samples (possibly a random number) and let Î´ â (0,1/2). If supâ?=0P(Y ?= sign(â)) â¤ Î´,<br />then<br />Eâ[T]<br />ââ2loglogââ2â¥ 2 â 4Î´.<br />Corollary 1 implies that in the fixed confidence setting, no best arm procedure can have<br />supP(?i ?= iâ) â¤ Î´ and use fewer than (2 â 4Î´)?<br />In brief, the result of Farrell follows by studying the form of a known optimal test, termed<br />a generalized sequential probability ratio test, which compares the running empirical mean of<br />X after t samples against a series of thresholds. In the limit as t increases, if the thresholds<br />are not at least<br />bility approaching 1/2 for small values of Âµ. Setting the thresholds to be just greater than<br />?(2/t)loglog(t), in the limit, one can show the expected number of samples must scale as<br />The proof in [9] is quite involved; to make this paper more self-contained we provide a<br />short argument for a slightly simpler result than above in Appendix A.<br />i.i.d.<br />â¼ N(â,1), where â ?= 0 is unknown. Consider<br />limsup<br />ââ0<br />iââ2<br />i<br />loglogââ2<br />i<br />samples in expectation<br />for all âi.<br />?(2/t)loglog(t) then the LIL implies the procedure will fail with proba-<br />ââ2loglogââ2.<br />3</p>  <p>Page 4</p> <p>3 Procedure<br />This section introduces lilâUCB. The procedure operates by sampling the arm with the largest<br />upper confidence bound; the confidence bounds are defined to account for the implications<br />of the LIL. The procedure terminates when an arm has been sampled more than a constant<br />fraction of the total number of samples. Fig. 1 details the algorithm and Theorem 2 quantifies<br />performance. In what follows, let Xi,s, s = 1,2,... denote independent samples from arm<br />i and let Ti(t) denote the number of times arm i has been sampled up to time t. Define<br />? Âµi,Ti(t):=<br />lilâ UCB<br />1<br />Ti(t)<br />?Ti(t)<br />s=1Xi,sto be the empirical mean of the Ti(t) samples from arm i up to<br />time t.<br />input: confidence Î´ &gt; 0, algorithm parameters Îµ, a, Î² &gt; 0<br />initialize: sample each arm once, set Ti(t) = 1 for all i and set t = n<br />while Ti(t) &lt; 1 + a?<br />sample arm<br />ï£±<br />ï£´<br />set<br />ï£±<br />ï£³<br />else stop and output argmaxiâ{1,...,n}Ti(t)<br />j?=iTj(t) for all i<br />It<br />= argmax<br />iâ{1,...,n}<br />ï£´<br />ï£³<br />ï£²<br />? Âµi,Ti(t)+ (1 + Î²)(1 +âÎµ)<br />?<br />?<br />?<br />?2(1 + Îµ)log<br />?log((1+Îµ)Ti(t))<br />Ti(t)<br />Î´<br />?<br />ï£¼<br />ï£´<br />ï£´<br />ï£¾<br />ï£½<br />.<br />Ti(t + 1) =<br />ï£²<br />Ti(t) + 1i = It<br />Ti(t)i ?= It<br />t = t + 1.<br />Figure 1: lilâ UCB<br />Define<br />H1=<br />?<br />i?=iâ<br />1<br />â2<br />i<br />and<br />H3=<br />?<br />i?=iâ<br />log(log(c/â2<br />â2<br />i))<br />i<br />where c &gt; 0 is a constant that appears in the analysis that makes the loglog term well defined<br />for all âiâ (0,1]. Our main result is the following.<br />Theorem 2 For any Îµ,Î² &gt; 0, Î´ â (0,log(1 + Îµ)/e)1and<br />log2log<br />Î²<br />a â¥<br />1 +<br />???2+Î²<br />log(1/Î´)<br />?âÎ´ log(1/Î´)<br />?2/Î´<br />??<br />1 â Î´ â<br />?2 + Î²<br />Î²<br />?2<br />,<br />1The range on Î´ is restricted to guarantee that log(log((1+Îµ)t)<br />but in practice one can allow the full range of Î´ by using log(log((1+Îµ)t+2)<br />guarantees.<br />Î´<br />) is well defined. This makes the analysis cleaner<br />) instead and obtain the same theoretical<br />Î´<br />4</p>  <p>Page 5</p> <p>with probability at least 1 ââÏÎ´ â<br />samples and outputs the optimal arm where Ï =2+Îµ<br />stants that depend only on Îµ,Î².<br />4ÏÎ´<br />1âÏÎ´, lilâ UCB stops after at most c1H1log(1/Î´) + c3H3<br />?<br />Îµ<br />1<br />log(1+Îµ)<br />?1+Îµ<br />and c1,c3&gt; 0 are con-<br />Note that regardless of the choice of Îµ,Î² the algorithm obtains the optimal query complex-<br />ity of H1log(1/Î´) + H3up to constant factors. However, in practice some settings of Îµ,Î²<br />perform better than others. We observe from the bounds in the proof that the optimal choice<br />for the exploration constant is Î² â 1.66 but we suggest using Î² = 1 and a =<br />optimal value for Îµ is less evident as it depends on Î´ but we suggest using Îµ = 0.01. If one is<br />willing to forego theoretical guarantees, we recommend taking a more aggressive setting with<br />Îµ = 0, Î² = 0.5, and a = 1 + 10/n which is motivated by simulation results presented later.<br />We prove the theorem via two lemmas, one for the total number of samples and one for the<br />correctness of the algorithm. In the lemmas we give precise constants.<br />?<br />Î²+2<br />Î²<br />?2. The<br />4 Proof of Theorem 2<br />Before stating the two main lemmas that imply the result, we first present a finite form of the<br />law of iterated logarithm. This finite LIL bound is necessary for our analysis and may also<br />prove useful for other applications.<br />Lemma 1 Let X1,X2,... be i.i.d. centered sub-Gaussian2random variables with scale pa-<br />rameter Ï. For any Îµ â (0,1) and Î´ â (0,log(1 + Îµ)/e)3one has with probability at least<br />1 â2+Îµ<br />?<br />Îµ<br />?<br />Î´<br />log(1+Îµ)<br />?1+Îµ<br />t<br />?<br />for any t â¥ 1,<br />s=1<br />Xsâ¤ (1 +âÎµ)2Ï2(1 + Îµ)tlog<br />?log((1 + Îµ)t)<br />Î´<br />?<br />.<br />Proof We denote St=?t<br />tion the sequence of integers (uk) as follows: u0= 1, uk+1= ?(1 + Îµ)uk?.<br />s=1Xs, and Ï(x) =<br />?<br />2Ï2xlog<br />?log(x)<br />Î´<br />?<br />. We also define by induc-<br />Step 1: Control of Suk,k â¥ 1. The following inequalities hold true thanks to an union<br />bound together with Chernoffâs bound, the fact that ukâ¥ (1 + Îµ)k, and a simple sum-integral<br />comparison:<br />P?âk â¥ 1 : Sukâ¥â1 + Îµ Ï(uk)?<br />â¤<br />â<br />?<br />â<br />?<br />?<br />k=1<br />exp<br />?<br />â(1 + Îµ)log<br />?log(uk)<br />?1+Îµ<br />?1+Îµ<br />Î´<br />??<br />â¤<br />k=1<br />?<br />Î´<br />klog(1 + Îµ)<br />??<br />â¤<br />1 +1<br />Îµ<br />Î´<br />log(1 + Îµ)<br />.<br />2A random variable X is said to be sub-Gaussian with scale parameter Ï if for all t â R we have E[exp{tX}] â¤<br />exp{Ï2t2/2}.<br />3See footnote 1<br />5</p>  <p>Page 6</p> <p>Step 2: Control of St,t â (uk,uk+1). Recall that Hoeffdingâs maximal inequality4states that<br />for any m â¥ 1 and x &gt; 0 one has<br />P(â t â [m] s.t. Stâ¥ x) â¤ exp<br />?<br />â<br />x2<br />2Ï2m<br />?<br />.<br />This implies that the following inequalities hold true (by using trivial manipulations on the<br />sequence (uk)):<br />P?â t â {uk+ 1,...,uk+1â 1} : Stâ Sukâ¥âÎµ Ï(uk+1)?<br />?<br />â¤ exp<br />Î´<br />?<br />= P?â t â [uk+1â ukâ 1] : Stâ¥âÎµ Ï(uk+1)?<br />â¤ exp<br />?<br />Î´<br />(k + 1)log(1 + Îµ)<br />âÎµ<br />uk+1<br />uk+1â ukâ 1log<br />â(1 + Îµ)log<br />?log(uk+1)<br />??<br />Î´<br />??<br />?log(uk+1)<br />?1+Îµ<br />â¤<br />.<br />Step 3: By putting together the results of Step 1 and Step 2 we obtain that with probability at<br />least 1 â2+Îµ<br />Îµ<br />?<br />Î´<br />log(1+Îµ)<br />?1+Îµ, one has for any k â¥ 0 and any t â {uk+ 1,...,uk+1},<br />St<br />=Stâ Suk+ Suk<br />â¤<br />â¤<br />â¤<br />which concludes the proof.<br />âÎµ Ï(uk+1) +â1 + Îµ Ï(uk)<br />âÎµ Ï((1 + Îµ)t) +â1 + Îµ Ï(t)<br />(1 +âÎµ) Ï((1 + Îµ)t),<br />Without loss of generality we assume that Âµ1&gt; Âµ2â¥ ... â¥ Âµn. To shorten notation we<br />denote<br />U(t,Ï) = (1 +âÎµ)<br />t<br />?<br />2(1 + Îµ)<br />log<br />?log((1 + Îµ)t)<br />Ï<br />?<br />.<br />The following events will be useful in the analysis:<br />Ei(Ï) = {ât â¥ 1,|? Âµi,tâ Âµi| â¤ U(t,Ï)}<br />where ? Âµi,t=1<br />4It is an easy exercise to verify that Azuma-Hoeffding holds for martingale differences with sub-Gaussian incre-<br />ments, which implies Hoeffdingâs maximal inequality for sub-Gaussian distributions.<br />t<br />?t<br />j=1xi,j. Note that Lemma 1 shows P(Ei(Ï)) = O(Ï). The following trivial<br />inequalities will also be useful (the second one is derived from the first inequality and the fact<br />6</p>  <p>Page 7</p> <p>thatx+a<br />x+bâ¤a<br />?log((1 + Îµ)t)<br />?log((1 + Îµ)t)<br />bfor a â¥ b, x â¥ 0). For t â¥ 1,<br />?<br />?<br />1<br />tlog<br />Ï<br />â¥ c â t â¤1<br />clog<br />?2log((1 + Îµ)/(cÏ))<br />?log((1 + Îµ)s)<br />Ï<br />?<br />,<br />(1)<br />1<br />tlog<br />Ï<br />â¥c<br />slog<br />Î´<br />?<br />and Ï â¤ Î´ â t â¤s<br />c<br />log?2log?1<br />log(1/Î´)<br />cÏ<br />?/Ï?<br />.<br />(2)<br />Lemma 2 Let Î³ = 2(2 + Î²)2(1 +âÎµ)2(1 + Îµ) and Ï =2+Îµ<br />at least 1 â 2ÏÎ´ one has for any t â¥ 1,<br />n<br />?<br />Proof We decompose the proof in two steps.<br />Îµ<br />?<br />1<br />log(1+Îµ)<br />?1+Îµ. With probability<br />i=2<br />Ti(t) â¤ n + Î³8eH1log(1/Î´) +<br />n<br />?<br />i=2<br />Î³log(2log(Î³(1 + Îµ)/â2<br />i))<br />â2<br />i<br />.<br />Step 1. Let i &gt; 1. Assuming that E1(Î´) and Ei(Ï) hold true and that It= i one has<br />Âµi+U(Ti(t),Ï)+(1+Î²)U(Ti(t),Î´) â¥ ? Âµi,Ti(t)+(1+Î²)U(Ti(t),Î´) â¥ ? Âµ1,T1(t)+(1+Î²)U(T1(t),Î´) â¥ Âµ1,<br />which implies (2+Î²)U(Ti(t),min(Ï,Î´)) â¥ âi. Thus using (1) with c =<br />one obtains that if E1(Î´) and Ei(Ï) hold true and It= i then<br />2(2 + Î²)2(1 +âÎµ)2(1 + Îµ)<br />â2<br />i<br />Î³<br />â2<br />i<br />Ï<br />â2<br />i<br />â2<br />i<br />2(2+Î²)2(1+âÎµ)2(1+Îµ)<br />Ti(t)<br />â¤<br />log<br />?2log(2(2 + Î²)2(1 +âÎµ)2(1 + Îµ)2/â2<br />â¤ Ïi+2Î³<br />Ï<br />?2log(Î³(1+Îµ)/â2<br />i/min(Ï,Î´))<br />min(Ï,Î´)<br />?<br />â¤<br />Ïi+<br />log<br />?log(e/Ï)<br />?<br />log<br />?1<br />?<br />,<br />where Î³ = 2(2 + Î²)2(1 +âÎµ)2(1 + Îµ), and Ïi=<br />Since Ti(t) only increases when Itis played the above argument shows that the following<br />inequality is true for any time t â¥ 1:<br />Ti(t)1{E1(Î´) â© Ei(Ï)} â¤ 1 + Ïi+2Î³<br />Î³<br />â2<br />ilog<br />i)<br />Î´<br />?<br />.<br />â2<br />i<br />log<br />?1<br />Ï<br />?<br />.<br />(3)<br />Step 2. We define the following random variable:<br />Î©i= max{Ï â¥ 0 : Ei(Ï) holds true}.<br />Note that Î©iis well-defined and by Lemma 1 it holds that P(Î©i &lt; Ï) â¤ ÏÏ where Ï =<br />2+Îµ<br />Îµ<br />log(1+Îµ)<br />?<br />1<br />?1+Îµ. Furthermore one can rewrite (3) as<br />Ti(t)1{E1(Î´)} â¤ 1 + Ïi+2Î³<br />â2<br />i<br />log<br />?1<br />Î©i<br />?<br />.<br />(4)<br />7</p>  <p>Page 8</p> <p>We use this equation as follows:<br />?<br />i=2<br />P<br />n<br />?<br />Ti(t) &gt; x +<br />n<br />?<br />i=2<br />(Ïi+ 1)<br />?<br />â¤<br />ÏÎ´ + P<br />?<br />?<br />n<br />?<br />n<br />?<br />i=2<br />Ti(t) &gt; x +<br />n<br />?<br />?<br />i=2<br />(Ïi+ 1)??E1(Î´)<br />&gt; x.<br />?<br />â¤<br />ÏÎ´ + P<br />i=2<br />2Î³<br />â2<br />i<br />log<br />?1<br />Î©i<br />?<br />(5)<br />Let Zi=<br />P(Î©i&lt; Ï) â¤ ÏÏ it holds that P(Zi&gt; x) â¤ exp(âx/ai) with ai= 2Î³/â2<br />techniques to bound the sum of sub-exponential random variables one directly obtains that<br />?<br />i=2<br />2<br />2Î³<br />â2<br />ilog<br />?<br />Ï<br />Î©i<br />?<br />, i â [n]. Observe that these are independent random variables and since<br />i. Using standard<br />P<br />n<br />?<br />Ziâ¥ x<br />?<br />â¤ exp<br />?<br />âmin<br />?<br />x2<br />8e2?a?2<br />,<br />x<br />4e?a?â<br />??<br />â¤ exp<br />?<br />âmin<br />?<br />x2<br />8e2?a?2<br />1<br />,<br />x<br />4e?a?1<br />??<br />.<br />(6)<br />Putting together (5) and (6) with x = 4e?a?1log(1/(ÏÎ´)) one obtains<br />?<br />i=2<br />which concludes the proof.<br />P<br />n<br />?<br />Ti(t) &gt;<br />n<br />?<br />i=2<br />?8eÎ³ log(1/Î´)<br />â2<br />i<br />+ Ïi+ 1<br />??<br />â¤ 2ÏÎ´,<br />Lemma 3 Let Ï =2+Îµ<br />Îµ<br />?<br />1<br />log(1+Îµ)<br />?1+Îµ. If<br />log<br />a â¥<br />1 +<br />?<br />2log<br />??2+Î²<br />log(1/Î´)<br />?âÎ´ log(1/Î´)<br />Î²<br />?2/Î´<br />??<br />1 â Î´ â<br />?2 + Î²<br />Î²<br />?2<br />,<br />then for all i = 2,...n and t = 1,2,...,<br />Ti(t) &lt; 1 + a<br />?<br />j?=i<br />Tj(t)<br />with probability at least 1 ââÏÎ´ â<br />Proof We decompose the proof in two steps.<br />2ÏÎ´<br />1âÏÎ´.<br />Step 1. Let i &gt; j. Assuming that Ei(Ï) and Ej(Î´) hold true and that It= i one has<br />Âµi+ U(Ti(t),Ï) + (1 + Î²)U(Ti(t),Î´)<br />â¥<br />â¥<br />â¥<br />? Âµi,Ti(t)+ (1 + Î²)U(Ti(t),Î´)<br />Âµj+ Î²U(Tj(t),Î´),<br />? Âµj,Tj(t)+ (1 + Î²)U(Tj(t),Î´)<br />which implies (2 + Î²)U(Ti(t),min(Ï,Î´)) â¥ Î²U(Tj(t),Î´). Thus using (2) with c =<br />one obtains that if Ei(Ï) and Ej(Î´) hold true and It= i then<br />?<br />?<br />Î²<br />2+Î²<br />?2<br />Ti(t)<br />â¤<br />?2 + Î²<br />Î²<br />?2log 2log<br />??<br />2+Î²<br />Î²<br />?2/min(Ï,Î´)<br />log(1/Î´)<br />?<br />/min(Ï,Î´)<br />?<br />Tj(t).<br />8</p>  <p>Page 9</p> <p>Similarly to Step 1 in the proof of Lemma 2 we use the fact that Ti(t) only increases when<br />Itis played and the above argument to obtain the following inequality for any time t â¥ 1:<br />?<br />(Ti(t)â1)1{Ei(Ï)â©Ej(Î´)} â¤<br />?2 + Î²<br />Î²<br />?2<br />2log<br />??<br />2+Î²<br />Î²<br />?2/min(Ï,Î´)<br />log(1/Î´)<br />?<br />/min(Ï,Î´)<br />?<br />Tj(t).<br />(7)<br />Step 2. Using (7) with Ï = Î´iâ1we see that<br />1{Ei(Î´iâ1)}<br />1<br />i â 1<br />ï£«<br />iâ1<br />?<br />j=1<br />1{Ej(Î´)} &gt; 1 â Î± â (1 â Î±)(Ti(t) â 1) â¤ Îº<br />?<br />j?=i<br />Tj(t)<br />where Îº =<br />?<br />2+Î²<br />Î²<br />?2<br />ï£­1 +<br />log<br />?<br />2log<br />??2+Î²<br />log(1/Î´)<br />Î²<br />?2/Î´<br />??<br />ï£¶<br />ï£¸. This implies the following, using that<br />P(Ei(Ï)) â¥ 1 â ÏÏ,<br />ï£«<br />ï£«<br />P<br />ï£­â (i,t) â {2,...,n} Ã {1,...} : (1 â Î±)(Ti(t) â 1) â¥ Îº<br />â¤ P<br />?<br />j?=i<br />Tj(t)<br />ï£¶<br />ï£¸<br />ï£­â i â {2,...,n} : 1{Ei(Î´iâ1)}<br />n<br />?<br />Let Î´?= ÏÎ´. Note that by a simple Hoeffdingâs inequality and a union bound one has<br />ï£«<br />i â 1<br />j=1<br />1<br />i â 1<br />iâ1<br />?<br />j=1<br />1{Ej(Î´)} â¤ 1 â Î±<br />ï£¶<br />ï£¸<br />â¤<br />i=2<br />P(Ei(Î´iâ1) does not hold) +<br />n<br />?<br />i=2<br />P<br />ï£«<br />ï£­<br />1<br />i â 1<br />iâ1<br />?<br />j=1<br />1{Ej(Î´)} â¤ 1 â ÏÎ´ â (Î± â ÏÎ´)<br />ï£¶<br />ï£¸.<br />P<br />ï£­<br />1<br />iâ1<br />?<br />1{Ej(Î´)} â¤ 1 â Î´?â (Î± â Î´?)<br />ï£¶<br />ï£¸â¤ min((i â 1)Î´?,exp(â2(i â 1)(Î± â Î´?)2),<br />and thus we obtain with the above calculations<br />ï£«<br />P<br />ï£­â (i,t) â {2,...,n} Ã {1,...} :<br />â¤<br />i=2<br />â<br />Î´?+<br />1 â Î´?=<br />?<br />1 â Î´?â<br />?â<br />â<br />Î´?log(1/Î´?)))<br />Î´?log(1/Î´?)<br />?<br />(Ti(t) â 1) â¥ Îº<br />?<br />j?=i<br />Tj(t)<br />ï£¶<br />ï£¸<br />n<br />?<br />?<br />Î´?iâ1+ min((i â 1)Î´?,exp(â2(i â 1)<br />?<br />?<br />â¤<br />2Î´?<br />ÏÎ´ +<br />2ÏÎ´<br />1 â ÏÎ´.<br />Treating Îµ and factors of loglog(Î²) as constants, Lemma 2 says that the total number<br />of times the suboptimal arms are sampled does not exceed (Î² + 2)2(c1H1log(1/Î´) + c3H3).<br />9</p>  <p>Page 10</p> <p>Lemma3statesthatonlytheoptimalarmwillmeetthestoppingconditionwitha = ca<br />Combining these results, we observe that the total number of times all the arms are sampled<br />?<br />2+Î²<br />Î²<br />?2.<br />does not exceed (Î²+2)2(c1H1log(1/Î´) + c3H3)<br />the theorem. We also observe using the approximation ca= 1, the optimal choice of Î² â 1.66.<br />?<br />1 + ca<br />?<br />2+Î²<br />Î²<br />?2?<br />, completing the proof of<br />5 Implementation and Simulations<br />In this section we investigate how the state of the art methods for solving the best arm problem<br />behave in practice. Before describing each of the algorithms in the comparison, we briefly<br />describe a LIL-based stopping criterion that can be applied to any of the algorithms.<br />LIL Stopping (LS) : For any algorithm and i â [n], after the t-th time we have that the<br />i-th arm has been sampled Ti(t) times and accumulated a mean ? Âµi,Ti(t). We can apply<br />Lemma 1 (with a union bound) so that with probability at least 1 â2+Îµ<br />Îµ<br />?<br />Î´<br />log(1+Îµ)<br />?1+Îµ<br />?<br />??? Âµi,Ti(t)â Âµi<br />for all t â¥ 1 and all i â [n]. We may then conclude that if?i := argmaxiâ[n]? Âµi,Ti(t)and<br />The LIL stopping condition is somewhat naive but often quite effective in practice for smaller<br />size problems when log(n) is negligible. To implement the strategy for any fixed confidence<br />algorithm, simply run the algorithm with Î´/2 in place of Î´ and assign the other Î´/2 confidence<br />to the LIL stopping criterion. The algorithms compared were:<br />â¢ Nonadaptive + LS : Draw a random permutation of [n] and sample the arms in an order<br />defined by cycling through the permutation until the LIL stopping criterion is met.<br />â¢ Exponential-Gap Elimination (+LS) [8] : This procedure proceeds in stages where at<br />each stage, median elimination [4] is used to find a Îµ-optimal arm whose mean is guar-<br />anteed (with large probability) to be within a specified Îµ &gt; 0 of the mean of the best arm,<br />and then arms are discarded if their empirical mean is sufficiently below the empirical<br />mean of the Îµ-optimal arm. The algorithm terminates when there is only one arm that<br />has not yet been discarded (or when the LIL stopping criterion is met).<br />â¢ Successive Elimination [4] : This procedure proceeds in the same spirit as Exponential-<br />Gap Elimination except the landmark arm is equal to?i := argmaxiâ[n]? Âµi,Ti(t). One<br />one in the same.<br />â¢ lilâUCB (+LS) : The procedure of Figure 1 is run with Îµ = 0.01, Î² = 1, a = (2 +<br />Î²)2/Î²2= 9, and Î´ =<br />5(2+Îµ)<br />for input confidence Î½. The algorithm terminates<br />according to Fig. 1 or when the LIL stopping criterion is met.<br />â¢ lilâUCB Heuristic : The procedure of Figure 1 is run with Îµ = 0, Î² = 1/2, a = 1 +<br />10/n, and Î´ = Î½/5 for input confidence Î½. These parameter settings do not satisfy the<br />conditions of Theorem 2, and thus there is no guarantee that this algorithm will find<br />??â¤ Bi,Ti(t):= (1 +âÎµ)<br />?<br />?<br />?<br />?2Ï2(1 + Îµ)log<br />?2nlog((1+Îµ)Ti(t)+2)<br />Ti(t)<br />Î´<br />? Âµ?i,T?i(t)â B?i,T?i(t)â¥ ? Âµj,Tj(t)+ Bj,Tj(t)then with high probability we have that?i = iâ.<br />observes that the algorithmâs usual stopping condition and the LIL stopping criterion are<br />?<br />Î½Îµ<br />?1/(1+Îµ)<br />10</p>  <p>Page 11</p> <p>the best arm. However, as the experiments show, this algorithm performs exceptionally<br />well in practice and therefore we recommend this lilâUCB algorithm in practice. The<br />algorithm terminates according to Fig. 1.<br />â¢ UCB1 + LS [11] : This is the classical UCB procedure that samples the arm<br />argmax<br />iâ[n]<br />? Âµi,Ti(t)+<br />?<br />2log(t)<br />Ti(t)<br />at each time t and terminates when the LIL stopping criterion is met.<br />We did not compare to PRISM of [7] because the algorithm and its empirical performance are<br />very similar to Exponential-Gap Elimination so its inclusion in the comparison would provide<br />very little added value. We remark that the first three algorithms require O(1) amortized<br />computation per time step, the lilâUCB algorithms require O(log(n)) computation per time<br />step using smart data structures5, and UCB1 requires O(n) computation per time step. Due<br />to the poor computational scaling of UCB1 with respect to the problem size n, UCB1 was not<br />run on all problem sizes due to practical time constraints.<br />Three problem scenarios were considered over a variety problem sizes (number of arms).<br />The â1-sparseâ scenario sets Âµ1= 1/4 and Âµi= 0 for all i = 2,...,n resulting in a hardness<br />of H1= 4n. The âÎ± = 0.3â and âÎ± = 0.6â scenarios consider n + 1 arms with Âµ0= 1 and<br />Âµi= 1 â (i/n)Î±for all i = 1,...,n with respective hardnesses of H1â 3/2n and H1â<br />6n1.2. That is, the Î± = 0.3 case should be about as hard as the sparse case with increasing<br />problem size while the Î± = 0.6 is considerably more challenging and grows super linearly<br />with the problem size. See [7] for an in-depth study of the Î± parameterization. All experiments<br />were run with input confidence Î´ = 0.1. All realizations of the arms were Gaussian random<br />variables with mean Âµiand variance 1/46.<br />Each algorithm terminates at some finite time with high probability so we first consider<br />the relative stopping times of each of the algorithms in Figure 2. Each algorithm was run on<br />each problem scenario and problem size 40 times. The first observation is that Exponential-<br />Gap Elimination (+LS) appears to barely perform better than uniform sampling with the LIL<br />stopping criterion. This confirms our suspicion that the constants in median elimination are<br />just too large to make this algorithm practically relevant. It should not come as a great surprise<br />that successive elimination performs so well because even though it is suboptimal in the prob-<br />lem parameters, its constants are small leading to a practical algorithm. The lilâUCB+LS and<br />UCB1+LS algorithms seem to behave comparably and lead the pack of algorithms with the-<br />oretical algorithms. The LIL stopping criterion seems to have a large impact on performance<br />of the regular lilâUCB algorithm, but it had no impact on the lilâUCB Heuristic variant (not<br />plotted). While lilâUCB Heuristic has no theoretical guarantees of outputting the best arm, we<br />remark that over the course of all of our tens of thousands of experiments, the algorithm never<br />failed to terminate with the best arm.<br />In reality, one cannot always wait for an algorithm to run until it terminates on its own<br />so we now explore how the algorithms perform if the algorithm must output an arm at every<br />5Toseethis, notethatthesufficientstatisticforlilâUCBfordecidingthenextarmtosampledependsonlyon ? Âµi,Ti(t)<br />the upper confidence bounds in which deleting, updating, and reinserting the arm requires just O(log(n)) computation.<br />Contrast this with a UCB procedure in which the upper confidence bounds depend explicitly on t so that the sufficient<br />statistics for pulling the next arm changes for all arms after each pull, requiring Î©(n) computation per time step.<br />6The variance was chosen such that the analyses of algorithms that assumed realizations were in [0,1] and used<br />Hoeffdingâs inequality were still valid using sub-Gaussian tail bounds with scale parameter 1/2.<br />and Ti(t) which only changes for an arm if that particular arm is pulled. Thus, it suffices to maintain an ordered list of<br />11</p>  <p>Page 12</p> <p>1-sparse, H1= 4nÎ± = 0.3, H1â3<br />2n<br />Î± = 0.6, H1â 6n1.2<br />Figure 2: Stopping times of the algorithms for the three scenarios for a variety of problem sizes.<br />time step before termination (this is similar to the setting studied in [13]). For each algorithm,<br />at each time we output the arm with the highest empirical mean. Because the procedure for<br />outputting the arm is the same across algorithms, measuring how often this output arm is the<br />best arm is a measure of how much information is being gathered by the algorithmâs sampling<br />procedure. Clearly in the beginning, the probability that a sub-optimal arm is output by any<br />algorithm is very close to 1. However, as time increases we know that this probability of error<br />should decrease to at least the desired input confidence, and likely, to zero. Figure 3 shows<br />the âanytimeâ performance of the algorithms for the three scenarios and unlike the empirical<br />stopping times of the algorithms, we now observe large differences between the algorithms.<br />Each experiment was repeated 5000 times. Again we see essentially no difference between<br />nonadaptive sampling and the exponential-gap procedure. While in the stopping time plots of<br />Figure 2 successive elimination appears neck-and-neck with the UCB algorithms, we observe<br />in Figure 3 that the UCB algorithms are collecting sufficient information to output the best arm<br />at least twice as fast as successive elimination. This tells us that the stopping conditions for the<br />UCB algorithms are still too conservative in practice which motivates the use of the lilâUCB<br />Heuristic algorithm which appears to perform very strongly across all metrics.<br />12</p>  <p>Page 13</p> <p>n = 10<br />1-sparse, H1= 4nÎ± = 0.3, H1â3<br />2n<br />Î± = 0.6, H1â 6n1.2<br />n = 100<br />n = 1000<br />n = 10000<br />Figure 3: At every time, each algorithm outputs an armËi that has the highest empirical mean.<br />The P(Ëi ?= iâ) is plotted with respect to the total number of pulls by the algorithm. The problem<br />sizes (number of arms) increase from top to bottom. The problem scenarios from left to right are<br />the 1-sparse problem (Âµ1= 0.5, Âµi= 0 âi &gt; 1) , Î± = 0.3 (Âµi= 1 â (i/n)Î±, i = 0,1,...,n),<br />and Î± = 0.6. The arrows indicate the stopping times (if not shown, those algorithms did not<br />terminate within the time window shown). Note that UCB1 is not plotted for n = 10000 due to<br />computational constraints. Also note that in some plots it is difficult to distinguish between the<br />nonadaptive sampling procedure, the exponential-gap algorithm, and successive elimination due<br />to the curves being on top of each other.<br />13</p>  <p>Page 14</p> <p>References<br />[1] Victor Gabillon, Mohammad Ghavamzadeh, Alessandro Lazaric, et al. Best arm identi-<br />fication: A unified approach to fixed budget and fixed confidence. 2012.<br />[2] Edward Paulson. A sequential procedure for selecting the population with the largest<br />mean from k normal populations. The Annals of Mathematical Statistics, 35(1):174â<br />180, 1964.<br />[3] Robert E Bechhofer. A sequential multiple-decision procedure for selecting the best one<br />of several normal populations with a common unknown variance, and its use with various<br />experimental designs. Biometrics, 14(3):408â429, 1958.<br />[4] Eyal Even-Dar, Shie Mannor, and Yishay Mansour. Pac bounds for multi-armed bandit<br />and markov decision processes. In Computational Learning Theory, pages 255â270.<br />Springer, 2002.<br />[5] Shie Mannor and John N Tsitsiklis. The sample complexity of exploration in the multi-<br />armed bandit problem. The Journal of Machine Learning Research, 5:623â648, 2004.<br />[6] Shivaram Kalyanakrishnan, Ambuj Tewari, Peter Auer, and Peter Stone. Pac subset se-<br />lection in stochastic multi-armed bandits. In Proceedings of the 29th International Con-<br />ference on Machine Learning (ICML-12), pages 655â662, 2012.<br />[7] Kevin Jamieson, Matthew Malloy, Robert Nowak, and Sebastien Bubeck. On finding the<br />largest mean among many. arXiv preprint arXiv:1306.3917, 2013.<br />[8] Zohar Karnin, Tomer Koren, and Oren Somekh. Almost optimal exploration in multi-<br />armed bandits. In Proceedings of the 30th International Conference on Machine Learn-<br />ing, 2013.<br />[9] R. H. Farrell. Asymptotic behavior of expected sample size in certain one sided tests.<br />The Annals of Mathematical Statistics, 35(1):pp. 36â72, 1964.<br />[10] DA Darling and Herbert Robbins. Iterated logarithm inequalities. In Herbert Robbins<br />Selected Papers, pages 254â258. Springer, 1985.<br />[11] Peter Auer, Nicol` o Cesa-Bianchi, and Paul Fischer. Finite-time analysis of the multi-<br />armed bandit problem. Machine learning, 47(2-3):235â256, 2002.<br />[12] Jean-Yves Audibert, SÂ´ ebastien Bubeck, and RÂ´ emi Munos. Best arm identification in<br />multi-armed bandits. COLT 2010-Proceedings, 2010.<br />[13] S. Bubeck, R. Munos, and G. Stoltz. Pure exploration in multi-armed bandits problems.<br />In Proceedings of the 20th International Conference on Algorithmic Learning Theory<br />(ALT), 2009.<br />14</p>  <p>Page 15</p> <p>A Condensed Proof of Lower Bound<br />In the following we show a weaker result than what is shown in [9]; nonetheless, it shows the<br />loglog term is necessary.<br />Theorem 3 Let Xi<br />or â &lt; 0. Let Y â {â1,1} be the decision of any such test based on T samples (possibly a<br />random number). If supâ?=0P(Y ?= sign(â)) &lt; 1/2, then<br />E[T]<br />ââ2loglogââ2<br />i.i.d.<br />â¼ N(â,1), where â ?= 0 is unknown. Consider testing whether â &gt; 0<br />limsup<br />ââ0<br />&gt;0 .<br />We rely on two intuitive facts, each which justified more formally in [9].<br />Fact 1. The form of an optimal test is a generalized sequential probability ratio test (GSPRT),<br />which continues sampling while<br />â Btâ¤<br />t<br />?<br />j=1<br />Xiâ¤ Bt<br />and stops otherwise, declaring â &gt; 0 if?t<br />Fact 2. If<br />j=1Xjâ¥ Bt, and â &lt; 0 if?t<br />j=1Xjâ¤ âBt<br />where Bt&gt; 0 is non-decreasing in t. This is made formal in [9].<br />lim<br />tââ<br />Bt<br />â2tloglogtâ¤ 1<br />(8)<br />then Y , the decision output by the GSPRT, satisfies supâ?=0Pâ(Y ?= sign â) = 1/2.<br />This follows from the LIL and a continuity argument (and note the limit exists as Bt<br />is non-decreasing). Intuitively, if the thresholds satisfy (8), a zero mean random walk<br />will eventually hit either the upper or lower threshold. The upper threshold is crossed<br />first with probability one half, as is the lower. By arguing that the error probabilities are<br />continuous functions of â, one concludes this assertion is true.<br />The argument proceeds as follows. If (8) is holds, then the error probability is 1/2. So we<br />can focus on threshold sequences satisfying limtââ<br />other words, for all t &gt; t1some Îµ &gt; 0, some sufficiently large t1<br />?<br />Define the function<br />Bt<br />â2tloglogtâ¥ (1 + Îµ) for some Îµ &gt; 0. In<br />Btâ¥ (1 + Îµ)2tloglogt.<br />t0(â) =Îµ2ââ2<br />2<br />loglog<br />?ââ2<br />2<br />?<br />and let T be the stopping time:<br />T := inf<br />?<br />t â N :<br />?????<br />t<br />?<br />i=1<br />Xi<br />?????â¥ Bt<br />?<br />.<br />15</p>  <p>Page 16</p> <p>Let S(â)<br />ditionally, suppose â is sufficiently small, such that both t0(â) &gt; t1(Îµ) and â â¤ Îµ (in the<br />following steps we consider the limit as â â 0). We have<br />Pâ(T â¥ t0(â))<br />ï£«<br />t=1<br />ï£«<br />t=1<br />t=t1(Îµ)+1<br />ï£«<br />t=1<br />t=t1(Îµ)+1<br />ï£«<br />t=1<br />t=t1(Îµ)+1<br />ï£«<br />t=1<br />t=t1(Îµ)+1<br />t<br />=?t<br />j=1Xjfor Xj<br />iid<br />â¼ N(â,1). Without loss of generality, assume â &gt; 0. Ad-<br />=<br />P<br />ï£­<br />ï£­<br />P<br />ï£­<br />P<br />ï£­<br />P<br />ï£­<br />t0(â)â1<br />?<br />t1(Îµ)<br />?<br />t1(Îµ)<br />?<br />t1(Îµ)<br />?<br />t1(Îµ)<br />?<br />|S(â)<br />t<br />| &lt; Bt<br />ï£¶<br />ï£¸<br />=<br />P<br />{|S(â)<br />t<br />| &lt; Bt} â©<br />t0(â)â1<br />?<br />t0(â)â1<br />?<br />ï£«<br />ï£«<br />{S(0)<br />t<br />&lt; Btâ ât} â© {S(0)<br />t<br />&gt; âBtâ ât}<br />ï£¶<br />??????<br />2tloglogt<br />ï£¶<br />ï£¸<br />â¥<br />{|S(â)<br />t<br />| &lt; Bt} â©<br />{|S(0)<br />t | &lt; (1 + Îµ/2)<br />?<br />?<br />?<br />2tloglogt}<br />ï£¸<br />t1(Îµ)<br />?<br />ï£¶<br />(9)<br />=<br />|S(â)<br />t<br />| &lt; Bt<br />ï£¶<br />ï£¶<br />ï£¸P<br />ï£¸P<br />ï£­<br />ï£­<br />t0(â)â1<br />?<br />â<br />?<br />|S(0)<br />t | â¤ (1 + Îµ/2)2tloglogt<br />t=1<br />|S(0)<br />t | &lt; Bt<br />ï£¶<br />ï£¸<br />â¥|S(â)<br />t<br />| &lt; Bt<br />|S(0)<br />t | &lt; (1 + Îµ/2)<br />ï£¸<br />(10)<br />where (9) holds when Îµ â¥ â and (10) holds by removing the conditioning, and then by<br />increasing the number of terms in the intersection. To see that (9) holds, note that2loglogt<br />?2â<br />loglog<br />2<br />loglog<br />?<br />Taking the limit as â â 0, for any Îµ &gt; 0, gives<br />t<br />â¥<br />Îµ<br />?2for all t â¤ t0(â), which is easily verified when Îµ â¥ â since<br />?<br />loglog<br />Îµ2ââ2<br />?<br />ââ2<br />2<br />??<br />ââ2<br />2<br />?<br />â¥<br />1.<br />lim<br />ââ0Pâ(T â¥ t0(â))<br />â¥<br />c(Îµ) &gt; 0<br />which follows from (10), as the first term is non-zero for any â (including â = 0) since<br />t1(Îµ) &lt; â and Bt&gt; 0, and the second term is non-zero by the LIL for any Îµ &gt; 0. Note that a<br />finite bound on the second term can be obtained as in Section 2.<br />By Markov, Eâ[T]/t0(â) â¥ Pâ(T â¥ t0(â)), and we conclude<br />Eâ[T]<br />ââ2loglogââ2â¥ Îµ2c(Îµ) &gt; 0<br />lim<br />ââ0<br />for any test with supâ?=0P(Y ?= sign(â)) &lt; 1/2.<br />16</p>   </div> <div id="rgw24_56ab9e9f28d33" class="c-box pub-resource-container js-toggle" style=""> <h4 class="lf js-expand-list"><small><a href="javascript:" class="lf">View other sources <span class="ico-expand-list"></span></a></small></h4> <h4 class="lf js-collapse-list hidden"><small><a href="javascript:" class="lf">Hide other sources <span class="ico-collapse-list"></span></a></small></h4> <div class="clear"></div> <div class="scroll-wrapper hidden"> <ul class="files-list c-list" id="rgw25_56ab9e9f28d33">  <li class="c-list-item pub-resource-item"  data-type="fulltext" id="rgw26_56ab9e9f28d33"> <span class="ico-pub"></span> <div class="file-content"> <div class="download"> <a href="http://export.arxiv.org/pdf/1312.7308" target="_blank" rel="nofollow" class="publication-viewer" title="lil&#39; UCB : An Optimal Exploration Algorithm for Multi-Armed Bandits">lil&#39; UCB : An Optimal Exploration Algorithm fo...</a> </div>  <div class="details">   Available from <a href="http://export.arxiv.org/pdf/1312.7308" target="_blank" rel="nofollow">export.arxiv.org</a>  </div>    </div> </li>  </ul> </div> </div> </noscript> <div class="clearfix"> <div class="action-container">  </div> <div class="pub-legal"> Data provided are for informational purposes only. Although carefully collected, accuracy cannot be guaranteed. The impact factor represents a rough estimation of the journal's impact factor and does not reflect the actual current impact factor. Publisher conditions are provided by RoMEO. Differing provisions from the publisher's actual policy or licence agreement may be applicable. </div>   </div> </div> <div class="clearfix">     <div id="rgw28_56ab9e9f28d33" class="c-box pub-resource-container js-toggle" style="display: none;"> <h4 class="lf js-expand-list"><small><a href="javascript:" class="lf">View other sources <span class="ico-expand-list"></span></a></small></h4> <h4 class="lf js-collapse-list hidden"><small><a href="javascript:" class="lf">Hide other sources <span class="ico-collapse-list"></span></a></small></h4> <div class="clear"></div> <div class="scroll-wrapper hidden"> <ul class="files-list c-list" id="rgw29_56ab9e9f28d33">  </ul> </div> </div>   <div id="rgw20_56ab9e9f28d33" class="similar-publications"> <h2>Similar Publications</h2> <ul class="list-bordered">  <li class="c-list-item li-publication-teaser" id="rgw21_56ab9e9f28d33"> <div> <h5> <a href="publication/221618385_The_Epoch-Greedy_Algorithm_for_Multi-armed_Bandits_with_Side_Information" class="color-inherit ga-similar-publication-title"><span class="publication-title">The Epoch-Greedy Algorithm for Multi-armed Bandits with Side Information.</span></a>  </h5>  <div class="authors"> <a href="researcher/15343358_John_Langford" class="authors ga-similar-publication-author">John Langford</a>, <a href="researcher/50607677_Tong_Zhang" class="authors ga-similar-publication-author">Tong Zhang</a>  </div>  </div> <div class="clear"></div> </li>  <li class="c-list-item li-publication-teaser" id="rgw22_56ab9e9f28d33"> <div> <h5> <a href="publication/224951754_Decoupling_Exploration_and_Exploitation_in_Multi-Armed_Bandits" class="color-inherit ga-similar-publication-title"><span class="publication-title">Decoupling Exploration and Exploitation in Multi-Armed Bandits</span></a>  </h5>  <div class="authors"> <a href="researcher/75774242_Orly_Avner" class="authors ga-similar-publication-author">Orly Avner</a>, <a href="researcher/8648699_Shie_Mannor" class="authors ga-similar-publication-author">Shie Mannor</a>, <a href="researcher/74586197_Ohad_Shamir" class="authors ga-similar-publication-author">Ohad Shamir</a>  </div>  </div> <div class="clear"></div> </li>  <li class="c-list-item li-publication-teaser" id="rgw23_56ab9e9f28d33"> <div> <h5> <a href="publication/221394179_Pure_Exploration_in_Multi-armed_Bandits_Problems" class="color-inherit ga-similar-publication-title"><span class="publication-title">Pure Exploration in Multi-armed Bandits Problems</span></a>  </h5>  <div class="authors"> <a href="researcher/14337290_Sebastien_Bubeck" class="authors ga-similar-publication-author">SÃ©bastien Bubeck</a>, <a href="researcher/14337289_Remi_Munos" class="authors ga-similar-publication-author">RÃ©mi Munos</a>, <a href="researcher/14337291_Gilles_Stoltz" class="authors ga-similar-publication-author">Gilles Stoltz</a>  </div>  </div> <div class="clear"></div> </li>  </ul> </div> </div> </div> </div> </div></div></div>
<div class="clear"></div><div id="rgw34_56ab9e9f28d33" class="default-footer"> <div id="footer" class="clearfix"> <span class="footer-left"> &copy; 2008&dash;2016 researchgate.net. All rights reserved. </span> <span class="footer-right"> <a href="https://www.researchgate.net/about">About us</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="https://www.researchgate.net/contact">Contact us</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="careers">Careers</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="developers">Developers</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="blog" target="_blank">News</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="application.PrivacyPolicy.html">Privacy</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="application.TermsAndConditions.html">Terms</a> <span class="footer-link-separator" style="padding: 0 5px;">&nbsp;|&nbsp;</span> <a href="advertising?_ref=ft">Advertising</a> <span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="recruiters?_ref=ft">Recruiting</a> </span> </div>  </div></div>
<div id="rgw35_56ab9e9f28d33">  <div class="header-wrapper-logged-out"> <div id="header"> <div class="header-content"> <a href="" class="g-l-logo"> <svg width="149" height="19"> <image xlink:href="https://c5.rgstatic.net/m/235107188705592/images/template/brand-header-logo.svg" src="https://c5.rgstatic.net/m/238113351022438/images/template/brand-header-logo.png" width="149" height="19"/> </svg> </a> <a href="" class="g-l-logo-ico"> <svg width="127" height="17" viewbox="0 0 127 22"> <image xlink:href="https://c5.rgstatic.net/m/235107188705592/images/template/brand-header-logo.svg" src="https://c5.rgstatic.net/m/238113351022438/images/template/brand-header-logo.png" width="127" height="17"/> </svg> </a> <div id="rgw36_56ab9e9f28d33" class="header-login-wrapper js-header-login"> <div class="dropdown-right-align"> <div class="login-signup-container lf"> <a href="https://www.researchgate.net/signup.SignUp.html?ev=su_chnl_index&amp;hdrsu=1&amp;_sg=GTkZn6UlLbHzFfVJzWW0Eez7UYd0gdR7N5svv8r-mZX341JUz0Dfjs4QV_bcAITg" class="dropdown-toggle lf">Join for free</a> </div> <div class="dropdown lf" style="height: 20px;"> <a href="https://www.researchgate.net/application.Login.html" class="js-login-url dropdown-toggle lf">Log in <span class="caret"></span></a> <div class="dropdown-menu"> <div class="header-login-form-wrapper"> <!--[if IE 6]><p class="box-warning" style="margin-bottom: 0;">Sorry, ResearchGate no longer supports the version of Internet Explorer you are using. <a href="http://whatbrowser.org/" rel="nofollow" target="_blank">Update your web browser</a> and then log in. </p><![endif]--> <form method="post" action="https://www.researchgate.net/application.Login.html" class="form-big header-login-form js-login-form" name="loginForm" id="headerLoginForm"> <input type="hidden" name="request_token" value="+R4NKza0K+369UNdTHExeJLycvIxF7upR5CUu2qWBM7bT9j+B1WHGWjHtOvtFqNeNRxxAzQr8rfWqD7lEG5ujuxguDS8O8wFm+rSUrwarxYTT5kD+WiOHR+R8BIseR36+uz/taTpBFfULdQVxG4daXquVi4TDzJF/EUvsxU71Vg4fwit8FNBBbUkHpdmmhlGcTPpk2c7U67TG7XdxlbnymKTR9wcUkJ0jFyDFQNweo2pu6/muQO1HYoWBAvMK6gfYdNholUxlSxpHUpefudqdsbH2Ve+KqmjjBPaxncgihc="/> <input type="hidden" name="urlAfterLogin" value="publication/259478458_lil&#39;_UCB_An_Optimal_Exploration_Algorithm_for_Multi-Armed_Bandits"/> <input type="hidden" name="invalidPasswordCount" value="0"/> <input type="hidden" name="headerLogin" value="yes"/> <label for="input-header-login">Email</label> <div class="login-input"> <div class="info-tip-wrapper"> <span class="ico-info js-info"></span> </div> <input type="email" value="" name="login" class="login js-login-input text" id="input-header-login" tabindex="1"/> </div> <div class="clear"></div> <label class="lf" for="input-header-password"> Password </label> <a class="rf forgot-password js-forgot-password" href="application.LostPassword.html">Forgot password?</a> <div class="clear"></div> <input type="password" value="" name="password" class="password js-password-input text" id="input-header-password" tabindex="2"/> <div class="clear"></div> <label class="remember-me" for="headerLoginCookie"> <input type="checkbox" checked="checked" value="yes" name="setLoginCookie" class="lf checkbox" id="headerLoginCookie" tabindex="3"/> Keep me logged in </label> <div class="clear"></div> <input value="Log in" name="loginSubmit" class="btn btn-promote btn-fullwidth btn-large allow-leave js-submit-button" type="submit" tabindex="4"/> </form> <div class="connectors"> <div class="text">or log in with</div> <div class="connector-actions"> <a href="connector/linkedin/" class="li-connect js-li-connect" data-redirect-url="cHVibGljYXRpb24vMjU5NDc4NDU4X2xpbCdfVUNCX0FuX09wdGltYWxfRXhwbG9yYXRpb25fQWxnb3JpdGhtX2Zvcl9NdWx0aS1Bcm1lZF9CYW5kaXRz"> <span class="icon ico-linkedin-round-grey"></span> <span class="icon ico-linkedin-round"></span> </a> <a href="connector/facebook/" class="fb-connect middle js-fb-connect" data-redirect-url="cHVibGljYXRpb24vMjU5NDc4NDU4X2xpbCdfVUNCX0FuX09wdGltYWxfRXhwbG9yYXRpb25fQWxnb3JpdGhtX2Zvcl9NdWx0aS1Bcm1lZF9CYW5kaXRz"> <span class="icon ico-facebook-round-grey"></span> <span class="icon ico-facebook-round"></span> </a> <a href="connector/google/" class="g-connect js-g-connect" data-redirect-url="cHVibGljYXRpb24vMjU5NDc4NDU4X2xpbCdfVUNCX0FuX09wdGltYWxfRXhwbG9yYXRpb25fQWxnb3JpdGhtX2Zvcl9NdWx0aS1Bcm1lZF9CYW5kaXRz"> <span class="icon ico-google-round-grey"></span> <span class="icon ico-google-round"></span> </a> </div> </div> </div> </div> </div> </div> </div> </div> </div> <script type="application/ld+json">
{ "@context" : "http://schema.org",
  "@type" : "Organization",
  "name" : "ResearchGate",
  "url" : "http://www.researchgate.net",
  "logo" : "http://www.researchgate.net/images/template/rg_logo_square_brand.png",
  "sameAs" : [ "https://www.facebook.com/ResearchGate",
    "https://twitter.com/ResearchGate",
    "https://plus.google.com/+researchgate",
    "https://www.linkedin.com/company/researchgate"] 
}
</script> </div> </div><div class="c-signup-bar" id="rgw37_56ab9e9f28d33"> <div class="banner-contents">   <span class="message">ResearchGate is the professional network for scientists and researchers.</span> <a href="signup.SignUp.html?ev=su_banner" class="btn btn-large btn-promote">Join for free</a>  </div> </div></div>
<script>
rgConfig.backendTime = 452;
</script>
<script src="//c5.rgstatic.net/m/2277196935388619/javascript/lib/yui3/yui/yui-min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/21832295316281274/javascript/yuiLoaderConfig-min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/23178613132105398/javascript/vendor/babel-core/browser-polyfill.min.js" type="text/javascript"></script>
<script>
(function (){
if (typeof YRG === "undefined") {
var xmlHttpRequest = new XMLHttpRequest();
xmlHttpRequest.open("post", "go.Error.html");
xmlHttpRequest.setRequestHeader("Content-Type", "application/json");
xmlHttpRequest.setRequestHeader("Accept", "application/json"); var loadedScripts = "";
if (window.performance && window.performance.getEntriesByType) {
    var result = [];
    var resources = performance.getEntriesByType("resource");
    for (var i in resources) {
        if (resources.hasOwnProperty(i)) {
            result.push({
                name: resources[i].name,
                duration: resources[i].duration
            });
        }
    }
    loadedScripts += "&loadedScripts=" + encodeURIComponent(JSON.stringify(result));
}
if (typeof YUI === "undefined") {
    loadedScripts += "&yuiLoaded=false";
} else {
    loadedScripts += "&yuiLoaded=true";
}
xmlHttpRequest.send("Type=InformationException&message=" + encodeURIComponent("Error loading YUI") + loadedScripts);
}
})();
</script>
<script>if (typeof YRG !== 'undefined') { YRG.use('rg-base',function(Y){Y.applyConfig({ignore: ["css-rg","css-rg2","css-ie","css-modules-publicprofile"]});Y.use(["rg.core.pagespeed.Monitoring"],function(Y){(function(){Y.rg.createInitialWidget({"data":{"content":{"data":{"profileSmallHeader":{"data":{"profileBadge":{"data":{"profileUrl":"researcher\/2011869224_Kevin_Jamieson","fullname":"Kevin Jamieson","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2549355721578\/images\/template\/default\/profile\/profile_default_m.png","profileStats":[{"data":{"impactPoints":"2.47","widgetId":"rgw5_56ab9e9f28d33"},"id":"rgw5_56ab9e9f28d33","partials":[],"templateName":"publicliterature\/stubs\/PublicLiteratureAuthorImpactPoints.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicLiteratureAuthorImpactPoints.html?authorUid=2011869224","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"publicationCount":9,"widgetId":"rgw6_56ab9e9f28d33"},"id":"rgw6_56ab9e9f28d33","partials":[],"templateName":"publicliterature\/stubs\/PublicLiteratureAuthorPublicationCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicLiteratureAuthorPublicationCount.html?authorUid=2011869224","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},null],"widgetId":"rgw4_56ab9e9f28d33"},"id":"rgw4_56ab9e9f28d33","partials":[],"templateName":"publicprofile\/stubs\/ProfileBadge.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicLiteratureAuthorBadge.html?authorUid=2011869224","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw3_56ab9e9f28d33"},"id":"rgw3_56ab9e9f28d33","partials":[],"templateName":"publicprofile\/stubs\/ProfileSmallHeader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicprofile.ProfileSmallHeader.html?publicationUid=259478458","viewClass":null,"yuiModules":["css-modules-publicprofile"],"stylesheets":["modules\/publicprofile.css"],"_isYUI":true},"publication":{"data":{"publicationUid":259478458,"title":"lil' UCB : An Optimal Exploration Algorithm for Multi-Armed Bandits","journalTitle":"Journal of Machine Learning Research","journalDetailsTooltip":{"data":{"journalTitle":"Journal of Machine Learning Research","journalAbbrev":"J MACH LEARN RES","publisher":false,"issn":"1532-4435","impactFactor":"2.47","fiveYearImpactFactor":"4.77","citedHalfLife":"8.30","immediacyIndex":"0.31","eigenFactor":"0.03","articleInfluence":"3.23","widgetId":"rgw8_56ab9e9f28d33"},"id":"rgw8_56ab9e9f28d33","partials":[],"templateName":"publicliterature\/stubs\/JournalInfo.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.JournalInfo.html?issn=1532-4435","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"affiliation":false,"type":"Article","details":{"journalInfos":{"journal":"","publicationDate":"12\/2013;","publicationDateRobot":"2013-12","article":"35.","journalTitle":"Journal of Machine Learning Research","journalUrl":"journal\/1532-4435_Journal_of_Machine_Learning_Research","impactFactor":2.47}},"source":{"sourceUrl":"http:\/\/arxiv.org\/abs\/1312.7308","sourceName":"arXiv"},"publicationActions":null,"publicationCoins":{"data":{"tags":[{"key":"ctx_ver","value":"Z39.88-2004"},{"key":"rft_val_fmt","value":"info:ofi\/fmt:kev:mtx:journal"},{"key":"rfr_id","value":"info:sid\/researchgate.net:researchgate"},{"key":"rft.atitle","value":"lil' UCB : An Optimal Exploration Algorithm for Multi-Armed Bandits"},{"key":"rft.title","value":"Journal of Machine Learning Research"},{"key":"rft.jtitle","value":"Journal of Machine Learning Research"},{"key":"rft.volume","value":"35"},{"key":"rft.date","value":"2013"},{"key":"rft.issn","value":"1532-4435"},{"key":"rft.au","value":"Kevin Jamieson,Matthew Malloy,Robert Nowak,S\u00e9bastien Bubeck"},{"key":"rft.genre","value":"article"}],"widgetId":"rgw9_56ab9e9f28d33"},"id":"rgw9_56ab9e9f28d33","partials":[],"templateName":"publicliterature\/stubs\/PublicationCoins.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationCoins.html?publicationUid=259478458","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationAuthors":{"data":{"publicationUid":259478458,"peopleItems":[{"data":{"authorUrl":"researcher\/2011869224_Kevin_Jamieson","authorNameOnPublication":"Kevin Jamieson","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg","imageSize":"s","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Kevin Jamieson","profile":{"professionalInstitution":{"professionalInstitutionName":false,"professionalInstitutionUrl":null}},"professionalInstitutionName":false,"professionalInstitutionUrl":null,"url":"researcher\/2011869224_Kevin_Jamieson","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":true,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":false,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"widgetId":"rgw12_56ab9e9f28d33"},"id":"rgw12_56ab9e9f28d33","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAuthorItem.html?entityId=2011869224&imageSize=l&enableAuthorInviteButton=0","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"largeTooltip":false,"useRebrandedImageStyle":null,"widgetId":"rgw11_56ab9e9f28d33"},"id":"rgw11_56ab9e9f28d33","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorItem.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorItem.html?authorUid=2011869224&authorNameOnPublication=Kevin%20Jamieson","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true},{"data":{"authorUrl":"researcher\/71218256_Matthew_Malloy","authorNameOnPublication":"Matthew Malloy","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg","imageSize":"s","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Matthew Malloy","profile":{"professionalInstitution":{"professionalInstitutionName":false,"professionalInstitutionUrl":null}},"professionalInstitutionName":false,"professionalInstitutionUrl":null,"url":"researcher\/71218256_Matthew_Malloy","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":true,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":false,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"widgetId":"rgw14_56ab9e9f28d33"},"id":"rgw14_56ab9e9f28d33","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAuthorItem.html?entityId=71218256&imageSize=l&enableAuthorInviteButton=0","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"largeTooltip":false,"useRebrandedImageStyle":null,"widgetId":"rgw13_56ab9e9f28d33"},"id":"rgw13_56ab9e9f28d33","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorItem.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorItem.html?authorUid=71218256&authorNameOnPublication=Matthew%20Malloy","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true},{"data":{"authorUrl":"researcher\/9168935_Robert_Nowak","authorNameOnPublication":"Robert Nowak","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg","imageSize":"s","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Robert Nowak","profile":{"professionalInstitution":{"professionalInstitutionName":false,"professionalInstitutionUrl":null}},"professionalInstitutionName":false,"professionalInstitutionUrl":null,"url":"researcher\/9168935_Robert_Nowak","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":true,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":false,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"widgetId":"rgw16_56ab9e9f28d33"},"id":"rgw16_56ab9e9f28d33","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAuthorItem.html?entityId=9168935&imageSize=l&enableAuthorInviteButton=0","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"largeTooltip":false,"useRebrandedImageStyle":null,"widgetId":"rgw15_56ab9e9f28d33"},"id":"rgw15_56ab9e9f28d33","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorItem.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorItem.html?authorUid=9168935&authorNameOnPublication=Robert%20Nowak","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true},{"data":{"authorUrl":"researcher\/2007706959_Sebastien_Bubeck","authorNameOnPublication":"S\u00e9bastien Bubeck","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg","imageSize":"s","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"S\u00e9bastien Bubeck","profile":{"professionalInstitution":{"professionalInstitutionName":false,"professionalInstitutionUrl":null}},"professionalInstitutionName":false,"professionalInstitutionUrl":null,"url":"researcher\/2007706959_Sebastien_Bubeck","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":true,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":false,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"widgetId":"rgw18_56ab9e9f28d33"},"id":"rgw18_56ab9e9f28d33","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAuthorItem.html?entityId=2007706959&imageSize=l&enableAuthorInviteButton=0","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"largeTooltip":false,"useRebrandedImageStyle":null,"widgetId":"rgw17_56ab9e9f28d33"},"id":"rgw17_56ab9e9f28d33","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorItem.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorItem.html?authorUid=2007706959&authorNameOnPublication=S%C3%A9bastien%20Bubeck","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true}],"hasMore":false,"nextOffset":6,"useRebrandedImageStyle":null,"widgetId":"rgw10_56ab9e9f28d33"},"id":"rgw10_56ab9e9f28d33","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorList.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorList.html?publicationUid=259478458&context=pubdetail_authors_xflw&showContactAuthorButton=1","viewClass":"views.publicliterature.PublicationDetailAuthorListView","yuiModules":["rg.views.publicliterature.PublicationDetailAuthorListView"],"stylesheets":[],"_isYUI":true},"publicationAbstract":{"data":{"publicationUid":259478458,"abstract":"<noscript><\/noscript><div>The paper proposes a novel upper confidence bound (UCB) procedure for<br \/>\nidentifying the arm with the largest mean in a multi-armed bandit game in the<br \/>\nfixed confidence setting using a small number of total samples. The procedure<br \/>\ncannot be improved in the sense that the number of samples required to identify<br \/>\nthe best arm is within a constant factor of a lower bound based on the law of<br \/>\nthe iterated logarithm (LIL). Inspired by the LIL, we construct our confidence<br \/>\nbounds to explicitly account for the infinite time horizon of the algorithm. In<br \/>\naddition, by using a novel stopping time for the algorithm we avoid a union<br \/>\nbound over the arms that has been observed in other UCB-type algorithms. We<br \/>\nprove that the algorithm is optimal up to constants and also show through<br \/>\nsimulations that it provides superior performance with respect to the<br \/>\nstate-of-the-art.<\/div>","canEdit":false,"isAdmin":false,"isArtifact":false,"showFullAbstract":false,"widgetId":"rgw19_56ab9e9f28d33"},"id":"rgw19_56ab9e9f28d33","partials":[],"templateName":"publicliterature\/stubs\/PublicationAbstract.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationAbstract.html?publicationUid=259478458","viewClass":"views.publicliterature.PublicationAbstractView","yuiModules":["rg.views.publicliterature.PublicationAbstractView"],"stylesheets":[],"_isYUI":true},"publicationKeywords":null,"publicationState":null,"isGuest":true,"isAdminEditingAllowed":false,"isArtifact":false,"figureListWidget":null,"previewImage":"https:\/\/i1.rgstatic.net\/publication\/259478458_lil'_UCB_An_Optimal_Exploration_Algorithm_for_Multi-Armed_Bandits\/links\/03032c260cf23a729b8645b8\/smallpreview.png","nativeAdDisclosure":null,"showFollowPublicationButton":false,"followPublicationPromo":"","widgetId":"rgw7_56ab9e9f28d33"},"id":"rgw7_56ab9e9f28d33","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailItem.html","templateExtensions":["generalHelpers"],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailItem.html?publicationUid=259478458&showActionBar=0&showContactAuthorButton=1&showRequestFulltextExperience=0&showNoRgAuthorsRequestFulltextExperience=0&showFollowPublicationPromo=0","viewClass":"views.publicliterature.PublicationDetailItemView","yuiModules":["rg.views.publicliterature.PublicationDetailItemView"],"stylesheets":[],"_isYUI":true},"similarPublications":{"data":{"publicationListItems":[{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":15343358,"url":"researcher\/15343358_John_Langford","fullname":"John Langford","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":50607677,"url":"researcher\/50607677_Tong_Zhang","fullname":"Tong Zhang","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Conference Paper","publicationDate":"Jan 2007","journal":null,"showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/221618385_The_Epoch-Greedy_Algorithm_for_Multi-armed_Bandits_with_Side_Information","usePlainButton":true,"publicationUid":221618385,"feedStubs":null,"hasFeedStubs":false,"impactPoints":false,"url":"publication\/221618385_The_Epoch-Greedy_Algorithm_for_Multi-armed_Bandits_with_Side_Information","title":"The Epoch-Greedy Algorithm for Multi-armed Bandits with Side Information.","displayTitleAsLink":true,"authors":[{"id":15343358,"url":"researcher\/15343358_John_Langford","fullname":"John Langford","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":50607677,"url":"researcher\/50607677_Tong_Zhang","fullname":"Tong Zhang","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["Advances in Neural Information Processing Systems 20, Proceedings of the Twenty-First Annual Conference on Neural Information Processing Systems, Vancouver, British Columbia, Canada, December 3-6, 2007; 01\/2007"],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Conference Paper","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/221618385_The_Epoch-Greedy_Algorithm_for_Multi-armed_Bandits_with_Side_Information","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/221618385_The_Epoch-Greedy_Algorithm_for_Multi-armed_Bandits_with_Side_Information\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw21_56ab9e9f28d33"},"id":"rgw21_56ab9e9f28d33","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=221618385","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":75774242,"url":"researcher\/75774242_Orly_Avner","fullname":"Orly Avner","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":8648699,"url":"researcher\/8648699_Shie_Mannor","fullname":"Shie Mannor","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":74586197,"url":"researcher\/74586197_Ohad_Shamir","fullname":"Ohad Shamir","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"May 2012","journal":null,"showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/224951754_Decoupling_Exploration_and_Exploitation_in_Multi-Armed_Bandits","usePlainButton":true,"publicationUid":224951754,"feedStubs":null,"hasFeedStubs":false,"impactPoints":false,"url":"publication\/224951754_Decoupling_Exploration_and_Exploitation_in_Multi-Armed_Bandits","title":"Decoupling Exploration and Exploitation in Multi-Armed Bandits","displayTitleAsLink":true,"authors":[{"id":75774242,"url":"researcher\/75774242_Orly_Avner","fullname":"Orly Avner","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":8648699,"url":"researcher\/8648699_Shie_Mannor","fullname":"Shie Mannor","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":74586197,"url":"researcher\/74586197_Ohad_Shamir","fullname":"Ohad Shamir","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":[],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/224951754_Decoupling_Exploration_and_Exploitation_in_Multi-Armed_Bandits","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/224951754_Decoupling_Exploration_and_Exploitation_in_Multi-Armed_Bandits\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw22_56ab9e9f28d33"},"id":"rgw22_56ab9e9f28d33","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=224951754","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":14337290,"url":"researcher\/14337290_Sebastien_Bubeck","fullname":"S\u00e9bastien Bubeck","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":14337289,"url":"researcher\/14337289_Remi_Munos","fullname":"R\u00e9mi Munos","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":14337291,"url":"researcher\/14337291_Gilles_Stoltz","fullname":"Gilles Stoltz","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Conference Paper","publicationDate":"Oct 2009","journal":null,"showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/221394179_Pure_Exploration_in_Multi-armed_Bandits_Problems","usePlainButton":true,"publicationUid":221394179,"feedStubs":null,"hasFeedStubs":false,"impactPoints":false,"url":"publication\/221394179_Pure_Exploration_in_Multi-armed_Bandits_Problems","title":"Pure Exploration in Multi-armed Bandits Problems","displayTitleAsLink":true,"authors":[{"id":14337290,"url":"researcher\/14337290_Sebastien_Bubeck","fullname":"S\u00e9bastien Bubeck","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":14337289,"url":"researcher\/14337289_Remi_Munos","fullname":"R\u00e9mi Munos","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":14337291,"url":"researcher\/14337291_Gilles_Stoltz","fullname":"Gilles Stoltz","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["Algorithmic Learning Theory, 20th International Conference, ALT 2009, Porto, Portugal, October 3-5, 2009. Proceedings; 10\/2009"],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Conference Paper","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/221394179_Pure_Exploration_in_Multi-armed_Bandits_Problems","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/221394179_Pure_Exploration_in_Multi-armed_Bandits_Problems\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw23_56ab9e9f28d33"},"id":"rgw23_56ab9e9f28d33","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=221394179","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"viewClass":"sidebar","widgetId":"rgw20_56ab9e9f28d33"},"id":"rgw20_56ab9e9f28d33","partials":[],"templateName":"publicliterature\/stubs\/SimilarPublications.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.SimilarPublications.html?referencePublicationId=259478458&view=sidebar","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationFulltextPreview":null,"publicationResourcesFulltext":{"data":{"publicationUid":259478458,"publicationResourceList":{"data":{"publicationResourceItems":[{"data":{"publicationUid":259478458,"publicationType":"article","linkId":"03032c260cf23a729b8645b8","fileName":"lil' UCB : An Optimal Exploration Algorithm for Multi-Armed Bandits","fileUrl":"http:\/\/export.arxiv.org\/pdf\/1312.7308","name":"export.arxiv.org","nameUrl":"http:\/\/export.arxiv.org\/pdf\/1312.7308","canRemove":false,"fileIcon":"ico-pub","canPreview":true,"hasPublisherLink":null,"hasMetaData":true,"hide":false,"fulltext":"ico-pub","origin":"publication_list","isLastLink":false,"isUserLink":false,"widgetId":"rgw26_56ab9e9f28d33"},"id":"rgw26_56ab9e9f28d33","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceItem.html","templateExtensions":["generalHelpers"],"attrs":{"fileRequiredPublicationTypes":["code","coverPage","experimentFindings","method","negativeResults","presentation","rawData","researchProposal","workingPaper","artifact","dataset"]},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceItem.html?publicationUid=259478458&linkId=03032c260cf23a729b8645b8&hide=0&disableJavascript=disableJavascript&useAlternativeTemplate=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"widgetId":"rgw25_56ab9e9f28d33"},"id":"rgw25_56ab9e9f28d33","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceList.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceList.html?publicationUid=259478458&limit=3&disableJavascript=disableJavascript&type=fulltextFile","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"resourceCount":1,"hidden":false,"showMore":false,"fulltext":true,"publicationDownloadCount":{"data":{"value":2,"valueFormatted":"2","widgetId":"rgw27_56ab9e9f28d33"},"id":"rgw27_56ab9e9f28d33","partials":[],"templateName":"publicliterature\/stubs\/PublicationDownloadCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDownloadCount.html?publicationUid=259478458","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw24_56ab9e9f28d33"},"id":"rgw24_56ab9e9f28d33","partials":[],"templateName":"publicliterature\/stubs\/PublicationResources.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResources.html?publicationUid=259478458&type=fulltextFile&disableJavascript=1","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationResourcesAttachments":{"data":{"publicationUid":259478458,"publicationResourceList":{"data":{"publicationResourceItems":[],"widgetId":"rgw29_56ab9e9f28d33"},"id":"rgw29_56ab9e9f28d33","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceList.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceList.html?publicationUid=259478458&limit=3&disableJavascript=disableJavascript&type=attachmentFile","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"resourceCount":0,"hidden":true,"showMore":false,"fulltext":false,"publicationDownloadCount":{"data":{"value":2,"valueFormatted":"2","widgetId":"rgw30_56ab9e9f28d33"},"id":"rgw30_56ab9e9f28d33","partials":[],"templateName":"publicliterature\/stubs\/PublicationDownloadCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDownloadCount.html?publicationUid=259478458","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw28_56ab9e9f28d33"},"id":"rgw28_56ab9e9f28d33","partials":[],"templateName":"publicliterature\/stubs\/PublicationResources.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResources.html?publicationUid=259478458&type=attachmentFile","viewClass":"views.publicliterature.PublicationResourcesView","yuiModules":["rg.views.publicliterature.PublicationResourcesView"],"stylesheets":[],"_isYUI":true},"publicationText":{"data":{"hide":false,"pages":[{"page":1,"text":"lil\u2019 UCB : An Optimal Exploration Algorithm for\nMulti-Armed Bandits\nKevin Jamieson\u2020, Matthew Malloy\u2020, Robert Nowak\u2020, and S\u00b4 ebastien Bubeck\u2021\n\u2020Department of Electrical and Computer Engineering,\nUniversity of Wisconsin-Madison\n\u2021Department of Operations Research and Financial Engineering,\nPrinceton University\nAbstract\nThe paper proposes a novel upper confidence bound (UCB) procedure for identifying the\narm with the largest mean in a multi-armed bandit game in the fixed confidence setting using a\nsmall number of total samples. The procedure cannot be improved in the sense that the number\nof samples required to identify the best arm is within a constant factor of a lower bound based\non the law of the iterated logarithm (LIL). Inspired by the LIL, we construct our confidence\nbounds to explicitly account for the infinite time horizon of the algorithm. In addition, by\nusing a novel stopping time for the algorithm we avoid a union bound over the arms that\nhas been observed in other UCB-type algorithms. We prove that the algorithm is optimal up to\nconstants and also show through simulations that it provides superior performance with respect\nto the state-of-the-art.\n1 Introduction\nThis paper introduces a new algorithm for the best arm problem in the stochastic multi-\narmed bandit (MAB) setting. Consider a MAB with n arms, each with unknown mean payoff\n\u00b51,...,\u00b5nin [0,1]. A sample of the ith arm is an independent realization of a sub-Gaussian\nrandom variable with mean \u00b5i. In the fixed confidence setting, the goal of the best arm prob-\nlem is to devise a sampling procedure with a single input \u03b4 that, regardless of the values of\n\u00b51,...,\u00b5n, finds the arm with the largest mean with probability at least 1\u2212\u03b4. More precisely,\nbest arm procedures must satisfy sup\u00b51,...,\u00b5nP(?i ?= i\u2217) \u2264 \u03b4, where i\u2217is the best arm,?i an\na unique best arm. In this sense, best arm procedures must automatically adjust sampling to\nensure success when the mean of the best and second best arms are arbitrarily close. Contrast\nthis with the fixed budget setting where the total number of samples remains a constant and the\nconfidence in which the best arm is identified within the given budget varies with the setting\nof the means. While the fixed budget and fixed confidence settings are related (see [1] for a\ndiscussion) this paper focuses on the fixed confidence setting only.\nThe best arm problem has a long history dating back to the \u201950s with the work of [2,3].\nIn the fixed confidence setting, the last decade has seen a flurry of activity providing new\nestimate of the best arm, and the supremum is taken over all set of means such that there exists\n1\narXiv:1312.7308v1  [stat.ML]  27 Dec 2013"},{"page":2,"text":"upper and lower bounds. In 2002, the successive elimination procedure of [4] was shown to\nfind the best arm with order?\nbound was also obtained using a procedure known as LUCB1 that was originally designed\nfor finding the m-best arms [6]. Recently, [7] proposed a procedure called PRISM which\nsucceeds with?\nThe best sample complexity result for the fixed confidence setting comes from a procedure\nsimilar to PRISM, called exponential-gap elimination [8], which guarantees identification of\nthe best arm with high probability using order?\nthe loglog term cannot be avoided, it remained unclear as to whether the upper bound of [8]\nor the lower bound of [5] was loose.\nThe classic work of [9] answers this question. It shows that the doubly logarithmic factor\nis necessary, implying that order?\n?\nare i.i.d. sub-Gaussian random variables with E[X?] = 0, E[X2\n?t\nlimsup\nt\u2192\u221e\nalmost surely. Here is the basic intuition behind the lower bound. Consider the two-arm\nproblem and let \u2206 be the difference between the means. In this case, it is reasonable to sample\nboth arms equally and consider the sum of differences of the samples, which is a random\nwalk with drift \u2206. The deterministic drift crosses the LIL bound (for a zero-mean walk) when\nt\u2206 =\u221a2tloglogt. Solving this equation for t yields t \u2248 2\u2206\u22122loglog\u2206\u22122. This intuition\nwill be formalized in the next section.\nTheLILalsomotivatesanovelapproachtothebestarmproblem. Specifically, theLILsug-\ngests a natural scaling for confidence bounds on empirical means, and we follow this intuition\nto develop a new algorithm for the best-arm problem. The algorithm is an Upper Confidence\nBound (UCB) procedure [11] based on a finite sample version of the LIL. The new algorithm,\ncalled lil\u2019UCB, is described in Figure 1. By explicitly accounting for the loglog factor in the\nconfidence bound and using a novel stopping criterion, our analysis of lil\u2019UCB avoids taking\nnaive union bounds over time, as encountered in some UCB algorithms [6,12], as well as the\nwasteful \u201cdoubling trick\u201d often employed in algorithms that proceed in epochs, such as the\nPRISM and exponential-gap elimination procedures [4,7,8]. Also, in some analyses of best\narm algorithms the upper confidence bounds of each arm are designed to hold with high prob-\nability for all arms uniformly, incurring a log(n) term in the confidence bound as a result of\nthe necessary union bound over the n arms [4,6,12]. However, our stopping time allows for a\ntighter analysis so that arms with larger gaps are allowed larger confidence bounds than those\narms with smaller gaps where higher confidence is required. Like exponential-gap elimination,\nlil\u2019UCB is order optimal in terms of sample complexity.\nOne of the main motivations for this work was to develop an algorithm that exhibits great\npractical performance in addition to optimal sample complexity. While the sample complexity\nof exponential-gap elimination is optimal up to constants, and PRISM up to small loglog fac-\ni?=i\u2217\u2206\u22122\ni\nlog(n\u2206\u22122\ni) samples, where \u2206i= \u00b5i\u2217 \u2212 \u00b5i, coming\ni?=i\u2217\u2206\u22122\nwithin a logarithmic factor of the lower bound of?\ni, shown in 2004 in [5]. A similar\ni\u2206\u22122\ni\nloglog\n??\nj\u2206\u22122\nj\n?\nor?\ni\u2206\u22122\ni\nlog?\u2206\u22122\ni\n?samples depending on the\nparameterization of the algorithm, improving the result of [4] by at least a factor of log(n).\ni\u2206\u22122\ni\nloglog\u2206\u22122\ni\nsamples, coming within a\ndoubly logarithmic factor of the lower bound of [5]. While the authors of [8] conjecture that\ni\u2206\u22122\ni\nloglog\u2206\u22122\ni\nsamples are necessary and sufficient\nin the sense that no procedure can satisfy sup\u22061,...,\u2206nP(?i ?= i\u2217) \u2264 \u03b4 and use fewer than\nis a consequence of the law of the iterated logarithm (LIL) [10]. The LIL states that if X?\ni\u2206\u22122\ni\nloglog\u2206\u22122\ni\nsamplesinexpectationforall\u22061,...,\u2206n. Thedoublylogarithmicfactor\n?] = \u03c32and we define St =\n?=1X?then\nSt\n?2\u03c32tloglog(t)\n= 1 and\nliminf\nt\u2192\u221e\nSt\n?2\u03c32tloglog(t)\n= \u22121\n2"},{"page":3,"text":"tors, the empirical performance of these methods is rather disappointing, even when compared\nto non-sequential sampling. Both PRISM and exponential-gap elimination employ median\nelimination [4] as a subroutine. Median elimination is used to find an arm that is within \u03b5 > 0\nof the largest, and has sample complexity within a constant factor of optimal for this subprob-\nlem. However, the constant factors tend to be quite large, and repeated applications of median\nelimination within PRISM and exponential-gap elimination are extremely wasteful. On the\ncontrary, lil\u2019UCB does not invoke wasteful subroutines. As we will show, in addition to hav-\ning the best theoretical sample complexities bounds known to date, lil\u2019UCB exhibits superior\nperformance in practice with respect to state-of-the-art algorithms.\n2 Lower Bound\nBefore introducing the lil\u2019UCB algorithm, we show that the loglog factor in the sample com-\nplexity is necessary for best-arm identification. It suffices to consider a two armed bandit\nproblem with a gap \u2206. If a lower bound on the gap is unknown, then the loglog factor is\nnecessary, as shown by the following result of [9].\nCorollary 1 Consider the best arm problem in the fixed confidence setting with n = 2 and\nexpected number of samples E\u2206[T]. Any procedure with sup\u2206?=0P(?i ?= i\u2217) \u2264 \u03b4, \u03b4 \u2208 (0,1\/2),\nlimsup\n\u2206\u21920\nProof Consider a reduction of the best arm problem with n = 2 in which the value of one\narm is known. In this case, the only strategy available is to sample the other arm some number\nof times to determine if it is less than or greater than the known value. We have reduced the\nproblem precisely to that studied by Farrell in [9], restated below.\nnecessarily has\nE\u2206[T]\n\u2206\u22122loglog\u2206\u22122\n\u2265\n2 \u2212 4\u03b4.\nTheorem 1 [9, Theorem 1]. Let Xi\ntesting whether \u2206 > 0 or \u2206 < 0. Let Y \u2208 {\u22121,1} be the decision of any such test based on\nT samples (possibly a random number) and let \u03b4 \u2208 (0,1\/2). If sup\u2206?=0P(Y ?= sign(\u2206)) \u2264 \u03b4,\nthen\nE\u2206[T]\n\u2206\u22122loglog\u2206\u22122\u2265 2 \u2212 4\u03b4.\nCorollary 1 implies that in the fixed confidence setting, no best arm procedure can have\nsupP(?i ?= i\u2217) \u2264 \u03b4 and use fewer than (2 \u2212 4\u03b4)?\nIn brief, the result of Farrell follows by studying the form of a known optimal test, termed\na generalized sequential probability ratio test, which compares the running empirical mean of\nX after t samples against a series of thresholds. In the limit as t increases, if the thresholds\nare not at least\nbility approaching 1\/2 for small values of \u00b5. Setting the thresholds to be just greater than\n?(2\/t)loglog(t), in the limit, one can show the expected number of samples must scale as\nThe proof in [9] is quite involved; to make this paper more self-contained we provide a\nshort argument for a slightly simpler result than above in Appendix A.\ni.i.d.\n\u223c N(\u2206,1), where \u2206 ?= 0 is unknown. Consider\nlimsup\n\u2206\u21920\ni\u2206\u22122\ni\nloglog\u2206\u22122\ni\nsamples in expectation\nfor all \u2206i.\n?(2\/t)loglog(t) then the LIL implies the procedure will fail with proba-\n\u2206\u22122loglog\u2206\u22122.\n3"},{"page":4,"text":"3 Procedure\nThis section introduces lil\u2019UCB. The procedure operates by sampling the arm with the largest\nupper confidence bound; the confidence bounds are defined to account for the implications\nof the LIL. The procedure terminates when an arm has been sampled more than a constant\nfraction of the total number of samples. Fig. 1 details the algorithm and Theorem 2 quantifies\nperformance. In what follows, let Xi,s, s = 1,2,... denote independent samples from arm\ni and let Ti(t) denote the number of times arm i has been sampled up to time t. Define\n? \u00b5i,Ti(t):=\nlil\u2019 UCB\n1\nTi(t)\n?Ti(t)\ns=1Xi,sto be the empirical mean of the Ti(t) samples from arm i up to\ntime t.\ninput: confidence \u03b4 > 0, algorithm parameters \u03b5, a, \u03b2 > 0\ninitialize: sample each arm once, set Ti(t) = 1 for all i and set t = n\nwhile Ti(t) < 1 + a?\nsample arm\n\uf8f1\n\uf8f4\nset\n\uf8f1\n\uf8f3\nelse stop and output argmaxi\u2208{1,...,n}Ti(t)\nj?=iTj(t) for all i\nIt\n= argmax\ni\u2208{1,...,n}\n\uf8f4\n\uf8f3\n\uf8f2\n? \u00b5i,Ti(t)+ (1 + \u03b2)(1 +\u221a\u03b5)\n?\n?\n?\n?2(1 + \u03b5)log\n?log((1+\u03b5)Ti(t))\nTi(t)\n\u03b4\n?\n\uf8fc\n\uf8f4\n\uf8f4\n\uf8fe\n\uf8fd\n.\nTi(t + 1) =\n\uf8f2\nTi(t) + 1i = It\nTi(t)i ?= It\nt = t + 1.\nFigure 1: lil\u2019 UCB\nDefine\nH1=\n?\ni?=i\u2217\n1\n\u22062\ni\nand\nH3=\n?\ni?=i\u2217\nlog(log(c\/\u22062\n\u22062\ni))\ni\nwhere c > 0 is a constant that appears in the analysis that makes the loglog term well defined\nfor all \u2206i\u2208 (0,1]. Our main result is the following.\nTheorem 2 For any \u03b5,\u03b2 > 0, \u03b4 \u2208 (0,log(1 + \u03b5)\/e)1and\nlog2log\n\u03b2\na \u2265\n1 +\n???2+\u03b2\nlog(1\/\u03b4)\n?\u221a\u03b4 log(1\/\u03b4)\n?2\/\u03b4\n??\n1 \u2212 \u03b4 \u2212\n?2 + \u03b2\n\u03b2\n?2\n,\n1The range on \u03b4 is restricted to guarantee that log(log((1+\u03b5)t)\nbut in practice one can allow the full range of \u03b4 by using log(log((1+\u03b5)t+2)\nguarantees.\n\u03b4\n) is well defined. This makes the analysis cleaner\n) instead and obtain the same theoretical\n\u03b4\n4"},{"page":5,"text":"with probability at least 1 \u2212\u221a\u03c1\u03b4 \u2212\nsamples and outputs the optimal arm where \u03c1 =2+\u03b5\nstants that depend only on \u03b5,\u03b2.\n4\u03c1\u03b4\n1\u2212\u03c1\u03b4, lil\u2019 UCB stops after at most c1H1log(1\/\u03b4) + c3H3\n?\n\u03b5\n1\nlog(1+\u03b5)\n?1+\u03b5\nand c1,c3> 0 are con-\nNote that regardless of the choice of \u03b5,\u03b2 the algorithm obtains the optimal query complex-\nity of H1log(1\/\u03b4) + H3up to constant factors. However, in practice some settings of \u03b5,\u03b2\nperform better than others. We observe from the bounds in the proof that the optimal choice\nfor the exploration constant is \u03b2 \u2248 1.66 but we suggest using \u03b2 = 1 and a =\noptimal value for \u03b5 is less evident as it depends on \u03b4 but we suggest using \u03b5 = 0.01. If one is\nwilling to forego theoretical guarantees, we recommend taking a more aggressive setting with\n\u03b5 = 0, \u03b2 = 0.5, and a = 1 + 10\/n which is motivated by simulation results presented later.\nWe prove the theorem via two lemmas, one for the total number of samples and one for the\ncorrectness of the algorithm. In the lemmas we give precise constants.\n?\n\u03b2+2\n\u03b2\n?2. The\n4 Proof of Theorem 2\nBefore stating the two main lemmas that imply the result, we first present a finite form of the\nlaw of iterated logarithm. This finite LIL bound is necessary for our analysis and may also\nprove useful for other applications.\nLemma 1 Let X1,X2,... be i.i.d. centered sub-Gaussian2random variables with scale pa-\nrameter \u03c3. For any \u03b5 \u2208 (0,1) and \u03b4 \u2208 (0,log(1 + \u03b5)\/e)3one has with probability at least\n1 \u22122+\u03b5\n?\n\u03b5\n?\n\u03b4\nlog(1+\u03b5)\n?1+\u03b5\nt\n?\nfor any t \u2265 1,\ns=1\nXs\u2264 (1 +\u221a\u03b5)2\u03c32(1 + \u03b5)tlog\n?log((1 + \u03b5)t)\n\u03b4\n?\n.\nProof We denote St=?t\ntion the sequence of integers (uk) as follows: u0= 1, uk+1= ?(1 + \u03b5)uk?.\ns=1Xs, and \u03c8(x) =\n?\n2\u03c32xlog\n?log(x)\n\u03b4\n?\n. We also define by induc-\nStep 1: Control of Suk,k \u2265 1. The following inequalities hold true thanks to an union\nbound together with Chernoff\u2019s bound, the fact that uk\u2265 (1 + \u03b5)k, and a simple sum-integral\ncomparison:\nP?\u2203k \u2265 1 : Suk\u2265\u221a1 + \u03b5 \u03c8(uk)?\n\u2264\n\u221e\n?\n\u221e\n?\n?\nk=1\nexp\n?\n\u2212(1 + \u03b5)log\n?log(uk)\n?1+\u03b5\n?1+\u03b5\n\u03b4\n??\n\u2264\nk=1\n?\n\u03b4\nklog(1 + \u03b5)\n??\n\u2264\n1 +1\n\u03b5\n\u03b4\nlog(1 + \u03b5)\n.\n2A random variable X is said to be sub-Gaussian with scale parameter \u03c3 if for all t \u2208 R we have E[exp{tX}] \u2264\nexp{\u03c32t2\/2}.\n3See footnote 1\n5"},{"page":6,"text":"Step 2: Control of St,t \u2208 (uk,uk+1). Recall that Hoeffding\u2019s maximal inequality4states that\nfor any m \u2265 1 and x > 0 one has\nP(\u2203 t \u2208 [m] s.t. St\u2265 x) \u2264 exp\n?\n\u2212\nx2\n2\u03c32m\n?\n.\nThis implies that the following inequalities hold true (by using trivial manipulations on the\nsequence (uk)):\nP?\u2203 t \u2208 {uk+ 1,...,uk+1\u2212 1} : St\u2212 Suk\u2265\u221a\u03b5 \u03c8(uk+1)?\n?\n\u2264 exp\n\u03b4\n?\n= P?\u2203 t \u2208 [uk+1\u2212 uk\u2212 1] : St\u2265\u221a\u03b5 \u03c8(uk+1)?\n\u2264 exp\n?\n\u03b4\n(k + 1)log(1 + \u03b5)\n\u2212\u03b5\nuk+1\nuk+1\u2212 uk\u2212 1log\n\u2212(1 + \u03b5)log\n?log(uk+1)\n??\n\u03b4\n??\n?log(uk+1)\n?1+\u03b5\n\u2264\n.\nStep 3: By putting together the results of Step 1 and Step 2 we obtain that with probability at\nleast 1 \u22122+\u03b5\n\u03b5\n?\n\u03b4\nlog(1+\u03b5)\n?1+\u03b5, one has for any k \u2265 0 and any t \u2208 {uk+ 1,...,uk+1},\nSt\n=St\u2212 Suk+ Suk\n\u2264\n\u2264\n\u2264\nwhich concludes the proof.\n\u221a\u03b5 \u03c8(uk+1) +\u221a1 + \u03b5 \u03c8(uk)\n\u221a\u03b5 \u03c8((1 + \u03b5)t) +\u221a1 + \u03b5 \u03c8(t)\n(1 +\u221a\u03b5) \u03c8((1 + \u03b5)t),\nWithout loss of generality we assume that \u00b51> \u00b52\u2265 ... \u2265 \u00b5n. To shorten notation we\ndenote\nU(t,\u03c9) = (1 +\u221a\u03b5)\nt\n?\n2(1 + \u03b5)\nlog\n?log((1 + \u03b5)t)\n\u03c9\n?\n.\nThe following events will be useful in the analysis:\nEi(\u03c9) = {\u2200t \u2265 1,|? \u00b5i,t\u2212 \u00b5i| \u2264 U(t,\u03c9)}\nwhere ? \u00b5i,t=1\n4It is an easy exercise to verify that Azuma-Hoeffding holds for martingale differences with sub-Gaussian incre-\nments, which implies Hoeffding\u2019s maximal inequality for sub-Gaussian distributions.\nt\n?t\nj=1xi,j. Note that Lemma 1 shows P(Ei(\u03c9)) = O(\u03c9). The following trivial\ninequalities will also be useful (the second one is derived from the first inequality and the fact\n6"},{"page":7,"text":"thatx+a\nx+b\u2264a\n?log((1 + \u03b5)t)\n?log((1 + \u03b5)t)\nbfor a \u2265 b, x \u2265 0). For t \u2265 1,\n?\n?\n1\ntlog\n\u03c9\n\u2265 c \u21d2 t \u22641\nclog\n?2log((1 + \u03b5)\/(c\u03c9))\n?log((1 + \u03b5)s)\n\u03c9\n?\n,\n(1)\n1\ntlog\n\u03c9\n\u2265c\nslog\n\u03b4\n?\nand \u03c9 \u2264 \u03b4 \u21d2 t \u2264s\nc\nlog?2log?1\nlog(1\/\u03b4)\nc\u03c9\n?\/\u03c9?\n.\n(2)\nLemma 2 Let \u03b3 = 2(2 + \u03b2)2(1 +\u221a\u03b5)2(1 + \u03b5) and \u03c1 =2+\u03b5\nat least 1 \u2212 2\u03c1\u03b4 one has for any t \u2265 1,\nn\n?\nProof We decompose the proof in two steps.\n\u03b5\n?\n1\nlog(1+\u03b5)\n?1+\u03b5. With probability\ni=2\nTi(t) \u2264 n + \u03b38eH1log(1\/\u03b4) +\nn\n?\ni=2\n\u03b3log(2log(\u03b3(1 + \u03b5)\/\u22062\ni))\n\u22062\ni\n.\nStep 1. Let i > 1. Assuming that E1(\u03b4) and Ei(\u03c9) hold true and that It= i one has\n\u00b5i+U(Ti(t),\u03c9)+(1+\u03b2)U(Ti(t),\u03b4) \u2265 ? \u00b5i,Ti(t)+(1+\u03b2)U(Ti(t),\u03b4) \u2265 ? \u00b51,T1(t)+(1+\u03b2)U(T1(t),\u03b4) \u2265 \u00b51,\nwhich implies (2+\u03b2)U(Ti(t),min(\u03c9,\u03b4)) \u2265 \u2206i. Thus using (1) with c =\none obtains that if E1(\u03b4) and Ei(\u03c9) hold true and It= i then\n2(2 + \u03b2)2(1 +\u221a\u03b5)2(1 + \u03b5)\n\u22062\ni\n\u03b3\n\u22062\ni\n\u03c9\n\u22062\ni\n\u22062\ni\n2(2+\u03b2)2(1+\u221a\u03b5)2(1+\u03b5)\nTi(t)\n\u2264\nlog\n?2log(2(2 + \u03b2)2(1 +\u221a\u03b5)2(1 + \u03b5)2\/\u22062\n\u2264 \u03c4i+2\u03b3\n\u03c9\n?2log(\u03b3(1+\u03b5)\/\u22062\ni\/min(\u03c9,\u03b4))\nmin(\u03c9,\u03b4)\n?\n\u2264\n\u03c4i+\nlog\n?log(e\/\u03c9)\n?\nlog\n?1\n?\n,\nwhere \u03b3 = 2(2 + \u03b2)2(1 +\u221a\u03b5)2(1 + \u03b5), and \u03c4i=\nSince Ti(t) only increases when Itis played the above argument shows that the following\ninequality is true for any time t \u2265 1:\nTi(t)1{E1(\u03b4) \u2229 Ei(\u03c9)} \u2264 1 + \u03c4i+2\u03b3\n\u03b3\n\u22062\nilog\ni)\n\u03b4\n?\n.\n\u22062\ni\nlog\n?1\n\u03c9\n?\n.\n(3)\nStep 2. We define the following random variable:\n\u03a9i= max{\u03c9 \u2265 0 : Ei(\u03c9) holds true}.\nNote that \u03a9iis well-defined and by Lemma 1 it holds that P(\u03a9i < \u03c9) \u2264 \u03c1\u03c9 where \u03c1 =\n2+\u03b5\n\u03b5\nlog(1+\u03b5)\n?\n1\n?1+\u03b5. Furthermore one can rewrite (3) as\nTi(t)1{E1(\u03b4)} \u2264 1 + \u03c4i+2\u03b3\n\u22062\ni\nlog\n?1\n\u03a9i\n?\n.\n(4)\n7"},{"page":8,"text":"We use this equation as follows:\n?\ni=2\nP\nn\n?\nTi(t) > x +\nn\n?\ni=2\n(\u03c4i+ 1)\n?\n\u2264\n\u03c1\u03b4 + P\n?\n?\nn\n?\nn\n?\ni=2\nTi(t) > x +\nn\n?\n?\ni=2\n(\u03c4i+ 1)??E1(\u03b4)\n> x.\n?\n\u2264\n\u03c1\u03b4 + P\ni=2\n2\u03b3\n\u22062\ni\nlog\n?1\n\u03a9i\n?\n(5)\nLet Zi=\nP(\u03a9i< \u03c9) \u2264 \u03c1\u03c9 it holds that P(Zi> x) \u2264 exp(\u2212x\/ai) with ai= 2\u03b3\/\u22062\ntechniques to bound the sum of sub-exponential random variables one directly obtains that\n?\ni=2\n2\n2\u03b3\n\u22062\nilog\n?\n\u03c1\n\u03a9i\n?\n, i \u2208 [n]. Observe that these are independent random variables and since\ni. Using standard\nP\nn\n?\nZi\u2265 x\n?\n\u2264 exp\n?\n\u2212min\n?\nx2\n8e2?a?2\n,\nx\n4e?a?\u221e\n??\n\u2264 exp\n?\n\u2212min\n?\nx2\n8e2?a?2\n1\n,\nx\n4e?a?1\n??\n.\n(6)\nPutting together (5) and (6) with x = 4e?a?1log(1\/(\u03c1\u03b4)) one obtains\n?\ni=2\nwhich concludes the proof.\nP\nn\n?\nTi(t) >\nn\n?\ni=2\n?8e\u03b3 log(1\/\u03b4)\n\u22062\ni\n+ \u03c4i+ 1\n??\n\u2264 2\u03c1\u03b4,\nLemma 3 Let \u03c1 =2+\u03b5\n\u03b5\n?\n1\nlog(1+\u03b5)\n?1+\u03b5. If\nlog\na \u2265\n1 +\n?\n2log\n??2+\u03b2\nlog(1\/\u03b4)\n?\u221a\u03b4 log(1\/\u03b4)\n\u03b2\n?2\/\u03b4\n??\n1 \u2212 \u03b4 \u2212\n?2 + \u03b2\n\u03b2\n?2\n,\nthen for all i = 2,...n and t = 1,2,...,\nTi(t) < 1 + a\n?\nj?=i\nTj(t)\nwith probability at least 1 \u2212\u221a\u03c1\u03b4 \u2212\nProof We decompose the proof in two steps.\n2\u03c1\u03b4\n1\u2212\u03c1\u03b4.\nStep 1. Let i > j. Assuming that Ei(\u03c9) and Ej(\u03b4) hold true and that It= i one has\n\u00b5i+ U(Ti(t),\u03c9) + (1 + \u03b2)U(Ti(t),\u03b4)\n\u2265\n\u2265\n\u2265\n? \u00b5i,Ti(t)+ (1 + \u03b2)U(Ti(t),\u03b4)\n\u00b5j+ \u03b2U(Tj(t),\u03b4),\n? \u00b5j,Tj(t)+ (1 + \u03b2)U(Tj(t),\u03b4)\nwhich implies (2 + \u03b2)U(Ti(t),min(\u03c9,\u03b4)) \u2265 \u03b2U(Tj(t),\u03b4). Thus using (2) with c =\none obtains that if Ei(\u03c9) and Ej(\u03b4) hold true and It= i then\n?\n?\n\u03b2\n2+\u03b2\n?2\nTi(t)\n\u2264\n?2 + \u03b2\n\u03b2\n?2log 2log\n??\n2+\u03b2\n\u03b2\n?2\/min(\u03c9,\u03b4)\nlog(1\/\u03b4)\n?\n\/min(\u03c9,\u03b4)\n?\nTj(t).\n8"},{"page":9,"text":"Similarly to Step 1 in the proof of Lemma 2 we use the fact that Ti(t) only increases when\nItis played and the above argument to obtain the following inequality for any time t \u2265 1:\n?\n(Ti(t)\u22121)1{Ei(\u03c9)\u2229Ej(\u03b4)} \u2264\n?2 + \u03b2\n\u03b2\n?2\n2log\n??\n2+\u03b2\n\u03b2\n?2\/min(\u03c9,\u03b4)\nlog(1\/\u03b4)\n?\n\/min(\u03c9,\u03b4)\n?\nTj(t).\n(7)\nStep 2. Using (7) with \u03c9 = \u03b4i\u22121we see that\n1{Ei(\u03b4i\u22121)}\n1\ni \u2212 1\n\uf8eb\ni\u22121\n?\nj=1\n1{Ej(\u03b4)} > 1 \u2212 \u03b1 \u21d2 (1 \u2212 \u03b1)(Ti(t) \u2212 1) \u2264 \u03ba\n?\nj?=i\nTj(t)\nwhere \u03ba =\n?\n2+\u03b2\n\u03b2\n?2\n\uf8ed1 +\nlog\n?\n2log\n??2+\u03b2\nlog(1\/\u03b4)\n\u03b2\n?2\/\u03b4\n??\n\uf8f6\n\uf8f8. This implies the following, using that\nP(Ei(\u03c9)) \u2265 1 \u2212 \u03c1\u03c9,\n\uf8eb\n\uf8eb\nP\n\uf8ed\u2203 (i,t) \u2208 {2,...,n} \u00d7 {1,...} : (1 \u2212 \u03b1)(Ti(t) \u2212 1) \u2265 \u03ba\n\u2264 P\n?\nj?=i\nTj(t)\n\uf8f6\n\uf8f8\n\uf8ed\u2203 i \u2208 {2,...,n} : 1{Ei(\u03b4i\u22121)}\nn\n?\nLet \u03b4?= \u03c1\u03b4. Note that by a simple Hoeffding\u2019s inequality and a union bound one has\n\uf8eb\ni \u2212 1\nj=1\n1\ni \u2212 1\ni\u22121\n?\nj=1\n1{Ej(\u03b4)} \u2264 1 \u2212 \u03b1\n\uf8f6\n\uf8f8\n\u2264\ni=2\nP(Ei(\u03b4i\u22121) does not hold) +\nn\n?\ni=2\nP\n\uf8eb\n\uf8ed\n1\ni \u2212 1\ni\u22121\n?\nj=1\n1{Ej(\u03b4)} \u2264 1 \u2212 \u03c1\u03b4 \u2212 (\u03b1 \u2212 \u03c1\u03b4)\n\uf8f6\n\uf8f8.\nP\n\uf8ed\n1\ni\u22121\n?\n1{Ej(\u03b4)} \u2264 1 \u2212 \u03b4?\u2212 (\u03b1 \u2212 \u03b4?)\n\uf8f6\n\uf8f8\u2264 min((i \u2212 1)\u03b4?,exp(\u22122(i \u2212 1)(\u03b1 \u2212 \u03b4?)2),\nand thus we obtain with the above calculations\n\uf8eb\nP\n\uf8ed\u2203 (i,t) \u2208 {2,...,n} \u00d7 {1,...} :\n\u2264\ni=2\n\u221a\n\u03b4?+\n1 \u2212 \u03b4?=\n?\n1 \u2212 \u03b4?\u2212\n?\u221a\n\u221a\n\u03b4?log(1\/\u03b4?)))\n\u03b4?log(1\/\u03b4?)\n?\n(Ti(t) \u2212 1) \u2265 \u03ba\n?\nj?=i\nTj(t)\n\uf8f6\n\uf8f8\nn\n?\n?\n\u03b4?i\u22121+ min((i \u2212 1)\u03b4?,exp(\u22122(i \u2212 1)\n?\n?\n\u2264\n2\u03b4?\n\u03c1\u03b4 +\n2\u03c1\u03b4\n1 \u2212 \u03c1\u03b4.\nTreating \u03b5 and factors of loglog(\u03b2) as constants, Lemma 2 says that the total number\nof times the suboptimal arms are sampled does not exceed (\u03b2 + 2)2(c1H1log(1\/\u03b4) + c3H3).\n9"},{"page":10,"text":"Lemma3statesthatonlytheoptimalarmwillmeetthestoppingconditionwitha = ca\nCombining these results, we observe that the total number of times all the arms are sampled\n?\n2+\u03b2\n\u03b2\n?2.\ndoes not exceed (\u03b2+2)2(c1H1log(1\/\u03b4) + c3H3)\nthe theorem. We also observe using the approximation ca= 1, the optimal choice of \u03b2 \u2248 1.66.\n?\n1 + ca\n?\n2+\u03b2\n\u03b2\n?2?\n, completing the proof of\n5 Implementation and Simulations\nIn this section we investigate how the state of the art methods for solving the best arm problem\nbehave in practice. Before describing each of the algorithms in the comparison, we briefly\ndescribe a LIL-based stopping criterion that can be applied to any of the algorithms.\nLIL Stopping (LS) : For any algorithm and i \u2208 [n], after the t-th time we have that the\ni-th arm has been sampled Ti(t) times and accumulated a mean ? \u00b5i,Ti(t). We can apply\nLemma 1 (with a union bound) so that with probability at least 1 \u22122+\u03b5\n\u03b5\n?\n\u03b4\nlog(1+\u03b5)\n?1+\u03b5\n?\n??? \u00b5i,Ti(t)\u2212 \u00b5i\nfor all t \u2265 1 and all i \u2208 [n]. We may then conclude that if?i := argmaxi\u2208[n]? \u00b5i,Ti(t)and\nThe LIL stopping condition is somewhat naive but often quite effective in practice for smaller\nsize problems when log(n) is negligible. To implement the strategy for any fixed confidence\nalgorithm, simply run the algorithm with \u03b4\/2 in place of \u03b4 and assign the other \u03b4\/2 confidence\nto the LIL stopping criterion. The algorithms compared were:\n\u2022 Nonadaptive + LS : Draw a random permutation of [n] and sample the arms in an order\ndefined by cycling through the permutation until the LIL stopping criterion is met.\n\u2022 Exponential-Gap Elimination (+LS) [8] : This procedure proceeds in stages where at\neach stage, median elimination [4] is used to find a \u03b5-optimal arm whose mean is guar-\nanteed (with large probability) to be within a specified \u03b5 > 0 of the mean of the best arm,\nand then arms are discarded if their empirical mean is sufficiently below the empirical\nmean of the \u03b5-optimal arm. The algorithm terminates when there is only one arm that\nhas not yet been discarded (or when the LIL stopping criterion is met).\n\u2022 Successive Elimination [4] : This procedure proceeds in the same spirit as Exponential-\nGap Elimination except the landmark arm is equal to?i := argmaxi\u2208[n]? \u00b5i,Ti(t). One\none in the same.\n\u2022 lil\u2019UCB (+LS) : The procedure of Figure 1 is run with \u03b5 = 0.01, \u03b2 = 1, a = (2 +\n\u03b2)2\/\u03b22= 9, and \u03b4 =\n5(2+\u03b5)\nfor input confidence \u03bd. The algorithm terminates\naccording to Fig. 1 or when the LIL stopping criterion is met.\n\u2022 lil\u2019UCB Heuristic : The procedure of Figure 1 is run with \u03b5 = 0, \u03b2 = 1\/2, a = 1 +\n10\/n, and \u03b4 = \u03bd\/5 for input confidence \u03bd. These parameter settings do not satisfy the\nconditions of Theorem 2, and thus there is no guarantee that this algorithm will find\n??\u2264 Bi,Ti(t):= (1 +\u221a\u03b5)\n?\n?\n?\n?2\u03c32(1 + \u03b5)log\n?2nlog((1+\u03b5)Ti(t)+2)\nTi(t)\n\u03b4\n? \u00b5?i,T?i(t)\u2212 B?i,T?i(t)\u2265 ? \u00b5j,Tj(t)+ Bj,Tj(t)then with high probability we have that?i = i\u2217.\nobserves that the algorithm\u2019s usual stopping condition and the LIL stopping criterion are\n?\n\u03bd\u03b5\n?1\/(1+\u03b5)\n10"},{"page":11,"text":"the best arm. However, as the experiments show, this algorithm performs exceptionally\nwell in practice and therefore we recommend this lil\u2019UCB algorithm in practice. The\nalgorithm terminates according to Fig. 1.\n\u2022 UCB1 + LS [11] : This is the classical UCB procedure that samples the arm\nargmax\ni\u2208[n]\n? \u00b5i,Ti(t)+\n?\n2log(t)\nTi(t)\nat each time t and terminates when the LIL stopping criterion is met.\nWe did not compare to PRISM of [7] because the algorithm and its empirical performance are\nvery similar to Exponential-Gap Elimination so its inclusion in the comparison would provide\nvery little added value. We remark that the first three algorithms require O(1) amortized\ncomputation per time step, the lil\u2019UCB algorithms require O(log(n)) computation per time\nstep using smart data structures5, and UCB1 requires O(n) computation per time step. Due\nto the poor computational scaling of UCB1 with respect to the problem size n, UCB1 was not\nrun on all problem sizes due to practical time constraints.\nThree problem scenarios were considered over a variety problem sizes (number of arms).\nThe \u201c1-sparse\u201d scenario sets \u00b51= 1\/4 and \u00b5i= 0 for all i = 2,...,n resulting in a hardness\nof H1= 4n. The \u201c\u03b1 = 0.3\u201d and \u201c\u03b1 = 0.6\u201d scenarios consider n + 1 arms with \u00b50= 1 and\n\u00b5i= 1 \u2212 (i\/n)\u03b1for all i = 1,...,n with respective hardnesses of H1\u2248 3\/2n and H1\u2248\n6n1.2. That is, the \u03b1 = 0.3 case should be about as hard as the sparse case with increasing\nproblem size while the \u03b1 = 0.6 is considerably more challenging and grows super linearly\nwith the problem size. See [7] for an in-depth study of the \u03b1 parameterization. All experiments\nwere run with input confidence \u03b4 = 0.1. All realizations of the arms were Gaussian random\nvariables with mean \u00b5iand variance 1\/46.\nEach algorithm terminates at some finite time with high probability so we first consider\nthe relative stopping times of each of the algorithms in Figure 2. Each algorithm was run on\neach problem scenario and problem size 40 times. The first observation is that Exponential-\nGap Elimination (+LS) appears to barely perform better than uniform sampling with the LIL\nstopping criterion. This confirms our suspicion that the constants in median elimination are\njust too large to make this algorithm practically relevant. It should not come as a great surprise\nthat successive elimination performs so well because even though it is suboptimal in the prob-\nlem parameters, its constants are small leading to a practical algorithm. The lil\u2019UCB+LS and\nUCB1+LS algorithms seem to behave comparably and lead the pack of algorithms with the-\noretical algorithms. The LIL stopping criterion seems to have a large impact on performance\nof the regular lil\u2019UCB algorithm, but it had no impact on the lil\u2019UCB Heuristic variant (not\nplotted). While lil\u2019UCB Heuristic has no theoretical guarantees of outputting the best arm, we\nremark that over the course of all of our tens of thousands of experiments, the algorithm never\nfailed to terminate with the best arm.\nIn reality, one cannot always wait for an algorithm to run until it terminates on its own\nso we now explore how the algorithms perform if the algorithm must output an arm at every\n5Toseethis, notethatthesufficientstatisticforlil\u2019UCBfordecidingthenextarmtosampledependsonlyon ? \u00b5i,Ti(t)\nthe upper confidence bounds in which deleting, updating, and reinserting the arm requires just O(log(n)) computation.\nContrast this with a UCB procedure in which the upper confidence bounds depend explicitly on t so that the sufficient\nstatistics for pulling the next arm changes for all arms after each pull, requiring \u03a9(n) computation per time step.\n6The variance was chosen such that the analyses of algorithms that assumed realizations were in [0,1] and used\nHoeffding\u2019s inequality were still valid using sub-Gaussian tail bounds with scale parameter 1\/2.\nand Ti(t) which only changes for an arm if that particular arm is pulled. Thus, it suffices to maintain an ordered list of\n11"},{"page":12,"text":"1-sparse, H1= 4n\u03b1 = 0.3, H1\u22483\n2n\n\u03b1 = 0.6, H1\u2248 6n1.2\nFigure 2: Stopping times of the algorithms for the three scenarios for a variety of problem sizes.\ntime step before termination (this is similar to the setting studied in [13]). For each algorithm,\nat each time we output the arm with the highest empirical mean. Because the procedure for\noutputting the arm is the same across algorithms, measuring how often this output arm is the\nbest arm is a measure of how much information is being gathered by the algorithm\u2019s sampling\nprocedure. Clearly in the beginning, the probability that a sub-optimal arm is output by any\nalgorithm is very close to 1. However, as time increases we know that this probability of error\nshould decrease to at least the desired input confidence, and likely, to zero. Figure 3 shows\nthe \u201canytime\u201d performance of the algorithms for the three scenarios and unlike the empirical\nstopping times of the algorithms, we now observe large differences between the algorithms.\nEach experiment was repeated 5000 times. Again we see essentially no difference between\nnonadaptive sampling and the exponential-gap procedure. While in the stopping time plots of\nFigure 2 successive elimination appears neck-and-neck with the UCB algorithms, we observe\nin Figure 3 that the UCB algorithms are collecting sufficient information to output the best arm\nat least twice as fast as successive elimination. This tells us that the stopping conditions for the\nUCB algorithms are still too conservative in practice which motivates the use of the lil\u2019UCB\nHeuristic algorithm which appears to perform very strongly across all metrics.\n12"},{"page":13,"text":"n = 10\n1-sparse, H1= 4n\u03b1 = 0.3, H1\u22483\n2n\n\u03b1 = 0.6, H1\u2248 6n1.2\nn = 100\nn = 1000\nn = 10000\nFigure 3: At every time, each algorithm outputs an arm\u02c6i that has the highest empirical mean.\nThe P(\u02c6i ?= i\u2217) is plotted with respect to the total number of pulls by the algorithm. The problem\nsizes (number of arms) increase from top to bottom. The problem scenarios from left to right are\nthe 1-sparse problem (\u00b51= 0.5, \u00b5i= 0 \u2200i > 1) , \u03b1 = 0.3 (\u00b5i= 1 \u2212 (i\/n)\u03b1, i = 0,1,...,n),\nand \u03b1 = 0.6. The arrows indicate the stopping times (if not shown, those algorithms did not\nterminate within the time window shown). Note that UCB1 is not plotted for n = 10000 due to\ncomputational constraints. Also note that in some plots it is difficult to distinguish between the\nnonadaptive sampling procedure, the exponential-gap algorithm, and successive elimination due\nto the curves being on top of each other.\n13"},{"page":14,"text":"References\n[1] Victor Gabillon, Mohammad Ghavamzadeh, Alessandro Lazaric, et al. Best arm identi-\nfication: A unified approach to fixed budget and fixed confidence. 2012.\n[2] Edward Paulson. A sequential procedure for selecting the population with the largest\nmean from k normal populations. The Annals of Mathematical Statistics, 35(1):174\u2013\n180, 1964.\n[3] Robert E Bechhofer. A sequential multiple-decision procedure for selecting the best one\nof several normal populations with a common unknown variance, and its use with various\nexperimental designs. Biometrics, 14(3):408\u2013429, 1958.\n[4] Eyal Even-Dar, Shie Mannor, and Yishay Mansour. Pac bounds for multi-armed bandit\nand markov decision processes. In Computational Learning Theory, pages 255\u2013270.\nSpringer, 2002.\n[5] Shie Mannor and John N Tsitsiklis. The sample complexity of exploration in the multi-\narmed bandit problem. The Journal of Machine Learning Research, 5:623\u2013648, 2004.\n[6] Shivaram Kalyanakrishnan, Ambuj Tewari, Peter Auer, and Peter Stone. Pac subset se-\nlection in stochastic multi-armed bandits. In Proceedings of the 29th International Con-\nference on Machine Learning (ICML-12), pages 655\u2013662, 2012.\n[7] Kevin Jamieson, Matthew Malloy, Robert Nowak, and Sebastien Bubeck. On finding the\nlargest mean among many. arXiv preprint arXiv:1306.3917, 2013.\n[8] Zohar Karnin, Tomer Koren, and Oren Somekh. Almost optimal exploration in multi-\narmed bandits. In Proceedings of the 30th International Conference on Machine Learn-\ning, 2013.\n[9] R. H. Farrell. Asymptotic behavior of expected sample size in certain one sided tests.\nThe Annals of Mathematical Statistics, 35(1):pp. 36\u201372, 1964.\n[10] DA Darling and Herbert Robbins. Iterated logarithm inequalities. In Herbert Robbins\nSelected Papers, pages 254\u2013258. Springer, 1985.\n[11] Peter Auer, Nicol` o Cesa-Bianchi, and Paul Fischer. Finite-time analysis of the multi-\narmed bandit problem. Machine learning, 47(2-3):235\u2013256, 2002.\n[12] Jean-Yves Audibert, S\u00b4 ebastien Bubeck, and R\u00b4 emi Munos. Best arm identification in\nmulti-armed bandits. COLT 2010-Proceedings, 2010.\n[13] S. Bubeck, R. Munos, and G. Stoltz. Pure exploration in multi-armed bandits problems.\nIn Proceedings of the 20th International Conference on Algorithmic Learning Theory\n(ALT), 2009.\n14"},{"page":15,"text":"A Condensed Proof of Lower Bound\nIn the following we show a weaker result than what is shown in [9]; nonetheless, it shows the\nloglog term is necessary.\nTheorem 3 Let Xi\nor \u2206 < 0. Let Y \u2208 {\u22121,1} be the decision of any such test based on T samples (possibly a\nrandom number). If sup\u2206?=0P(Y ?= sign(\u2206)) < 1\/2, then\nE[T]\n\u2206\u22122loglog\u2206\u22122\ni.i.d.\n\u223c N(\u2206,1), where \u2206 ?= 0 is unknown. Consider testing whether \u2206 > 0\nlimsup\n\u2206\u21920\n>0 .\nWe rely on two intuitive facts, each which justified more formally in [9].\nFact 1. The form of an optimal test is a generalized sequential probability ratio test (GSPRT),\nwhich continues sampling while\n\u2212 Bt\u2264\nt\n?\nj=1\nXi\u2264 Bt\nand stops otherwise, declaring \u2206 > 0 if?t\nFact 2. If\nj=1Xj\u2265 Bt, and \u2206 < 0 if?t\nj=1Xj\u2264 \u2212Bt\nwhere Bt> 0 is non-decreasing in t. This is made formal in [9].\nlim\nt\u2192\u221e\nBt\n\u221a2tloglogt\u2264 1\n(8)\nthen Y , the decision output by the GSPRT, satisfies sup\u2206?=0P\u2206(Y ?= sign \u2206) = 1\/2.\nThis follows from the LIL and a continuity argument (and note the limit exists as Bt\nis non-decreasing). Intuitively, if the thresholds satisfy (8), a zero mean random walk\nwill eventually hit either the upper or lower threshold. The upper threshold is crossed\nfirst with probability one half, as is the lower. By arguing that the error probabilities are\ncontinuous functions of \u2206, one concludes this assertion is true.\nThe argument proceeds as follows. If (8) is holds, then the error probability is 1\/2. So we\ncan focus on threshold sequences satisfying limt\u2192\u221e\nother words, for all t > t1some \u03b5 > 0, some sufficiently large t1\n?\nDefine the function\nBt\n\u221a2tloglogt\u2265 (1 + \u03b5) for some \u03b5 > 0. In\nBt\u2265 (1 + \u03b5)2tloglogt.\nt0(\u2206) =\u03b52\u2206\u22122\n2\nloglog\n?\u2206\u22122\n2\n?\nand let T be the stopping time:\nT := inf\n?\nt \u2208 N :\n?????\nt\n?\ni=1\nXi\n?????\u2265 Bt\n?\n.\n15"},{"page":16,"text":"Let S(\u2206)\nditionally, suppose \u2206 is sufficiently small, such that both t0(\u2206) > t1(\u03b5) and \u2206 \u2264 \u03b5 (in the\nfollowing steps we consider the limit as \u2206 \u2192 0). We have\nP\u2206(T \u2265 t0(\u2206))\n\uf8eb\nt=1\n\uf8eb\nt=1\nt=t1(\u03b5)+1\n\uf8eb\nt=1\nt=t1(\u03b5)+1\n\uf8eb\nt=1\nt=t1(\u03b5)+1\n\uf8eb\nt=1\nt=t1(\u03b5)+1\nt\n=?t\nj=1Xjfor Xj\niid\n\u223c N(\u2206,1). Without loss of generality, assume \u2206 > 0. Ad-\n=\nP\n\uf8ed\n\uf8ed\nP\n\uf8ed\nP\n\uf8ed\nP\n\uf8ed\nt0(\u2206)\u22121\n?\nt1(\u03b5)\n?\nt1(\u03b5)\n?\nt1(\u03b5)\n?\nt1(\u03b5)\n?\n|S(\u2206)\nt\n| < Bt\n\uf8f6\n\uf8f8\n=\nP\n{|S(\u2206)\nt\n| < Bt} \u2229\nt0(\u2206)\u22121\n?\nt0(\u2206)\u22121\n?\n\uf8eb\n\uf8eb\n{S(0)\nt\n< Bt\u2212 \u2206t} \u2229 {S(0)\nt\n> \u2212Bt\u2212 \u2206t}\n\uf8f6\n??????\n2tloglogt\n\uf8f6\n\uf8f8\n\u2265\n{|S(\u2206)\nt\n| < Bt} \u2229\n{|S(0)\nt | < (1 + \u03b5\/2)\n?\n?\n?\n2tloglogt}\n\uf8f8\nt1(\u03b5)\n?\n\uf8f6\n(9)\n=\n|S(\u2206)\nt\n| < Bt\n\uf8f6\n\uf8f6\n\uf8f8P\n\uf8f8P\n\uf8ed\n\uf8ed\nt0(\u2206)\u22121\n?\n\u221e\n?\n|S(0)\nt | \u2264 (1 + \u03b5\/2)2tloglogt\nt=1\n|S(0)\nt | < Bt\n\uf8f6\n\uf8f8\n\u2265|S(\u2206)\nt\n| < Bt\n|S(0)\nt | < (1 + \u03b5\/2)\n\uf8f8\n(10)\nwhere (9) holds when \u03b5 \u2265 \u2206 and (10) holds by removing the conditioning, and then by\nincreasing the number of terms in the intersection. To see that (9) holds, note that2loglogt\n?2\u2206\nloglog\n2\nloglog\n?\nTaking the limit as \u2206 \u2192 0, for any \u03b5 > 0, gives\nt\n\u2265\n\u03b5\n?2for all t \u2264 t0(\u2206), which is easily verified when \u03b5 \u2265 \u2206 since\n?\nloglog\n\u03b52\u2206\u22122\n?\n\u2206\u22122\n2\n??\n\u2206\u22122\n2\n?\n\u2265\n1.\nlim\n\u2206\u21920P\u2206(T \u2265 t0(\u2206))\n\u2265\nc(\u03b5) > 0\nwhich follows from (10), as the first term is non-zero for any \u2206 (including \u2206 = 0) since\nt1(\u03b5) < \u221e and Bt> 0, and the second term is non-zero by the LIL for any \u03b5 > 0. Note that a\nfinite bound on the second term can be obtained as in Section 2.\nBy Markov, E\u2206[T]\/t0(\u2206) \u2265 P\u2206(T \u2265 t0(\u2206)), and we conclude\nE\u2206[T]\n\u2206\u22122loglog\u2206\u22122\u2265 \u03b52c(\u03b5) > 0\nlim\n\u2206\u21920\nfor any test with sup\u2206?=0P(Y ?= sign(\u2206)) < 1\/2.\n16"}],"widgetId":"rgw31_56ab9e9f28d33"},"id":"rgw31_56ab9e9f28d33","partials":[],"templateName":"publicliterature\/stubs\/PublicationText.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationText.html?publicationUid=259478458&hide=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationDetailAd":{"data":{"googleDfpSlot":null,"widgetId":"rgw32_56ab9e9f28d33"},"id":"rgw32_56ab9e9f28d33","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAd.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAd.html?publicationUid=259478458&slotId=336x280_Publications_ATF_Right&collapseSlotMode=never&fallbackContainerEnabled=1","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationRelations":null,"publicationRelationsReverse":null,"publicationUid":259478458,"showSignUpDialog":false,"selectNewSignUpDialog":false,"publicationQuestions":null,"publicationCitations":null,"publicationReviewPromo":null,"publicationUsedInReviews":null,"publicationPdfJsReader":null,"useFulltextOptimizedLayout":false,"publicationActions":null,"requestFulltextPromo":null,"currentUrl":"publication\/259478458_lil'_UCB_An_Optimal_Exploration_Algorithm_for_Multi-Armed_Bandits","isLeaderboardAd":false,"enableStickyBox":null,"googleDfpSlotMobileBottom":null,"fullTextExitPopup":null,"showExitPopupDialog":false,"widgetId":"rgw2_56ab9e9f28d33"},"id":"rgw2_56ab9e9f28d33","partials":{"romeo_legal_notice":"publicliterature\/stubs\/partials\/romeo_legal_notice.html"},"templateName":"publicliterature\/stubs\/PublicPublicationDetails_NewLayout.html","templateExtensions":["generalHelpers"],"attrs":{"publicationUid":259478458},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicPublicationDetailsOld.html?publicationUid=259478458&isTestOldDesign=0","viewClass":"views.publicliterature.PublicPublicationDetailsOldView","yuiModules":["rg.views.publicliterature.PublicPublicationDetailsOldView"],"stylesheets":[],"_isYUI":true},"widgetId":"rgw1_56ab9e9f28d33"},"id":"rgw1_56ab9e9f28d33","partials":[],"templateName":"publicliterature\/stubs\/PublicPublicationDetails.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicPublicationDetails.html","viewClass":"views.publicliterature.PublicPublicationDetailsView","yuiModules":["rg.views.publicliterature.PublicPublicationDetailsView"],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"uaClass":"","headPrefix":[],"rootUrl":"https:\/\/www.researchgate.net\/","requestToken":"VwBIuDSqnajQLNPePQaewVo3hs8qFYol\/Lebr6vOnZ065YkGchJFyY0f0DUrWcTbwq8wwDC+YXYh\/zK+IloAeVY2D1wlk6AkvplmMxQ6xDnMqfJl+jLH6bbjeQj6u4wuB3expygIwsgVa+dcT7b381k\/dvBA99AUiNfofCkcPQ9zIP6usDvNJ0vGTJfG3XBeons\/x3BYzt+cPJCi8PEjqI1fSC+XQEXibmu118lw21BsnR8YkM+7HkvUhl9CuYn6kb9kWKT0xED3VTlcfXeK7eDn5kIGt5KxuSx6zno8CvI=","faviconCdnUrl":"https:\/\/c5.rgstatic.net\/m\/2390829798215018\/images\/favicon.ico","headerOutput":"<noscript><\/noscript><link rel=\"canonical\" href=\"https:\/\/www.researchgate.net\/publication\/259478458_lil'_UCB_An_Optimal_Exploration_Algorithm_for_Multi-Armed_Bandits\" \/>\n<link rel=\"dns-prefetch\" href=\"\/\/c5.rgstatic.net\" \/>\n<link rel=\"dns-prefetch\" href=\"\/\/i1.rgstatic.net\" \/>\n<meta property=\"twitter:card\" content=\"summary\" \/>\n<meta property=\"twitter:site\" content=\"@ResearchGate\" \/>\n<meta property=\"og:title\" content=\"lil' UCB : An Optimal Exploration Algorithm for Multi-Armed Bandits\" \/>\n<meta property=\"og:description\" content=\"The paper proposes a novel upper confidence bound (UCB) procedure for\nidentifying the arm with the largest mean in a multi-armed bandit game in the\nfixed confidence setting using a small number of...\" \/>\n<meta property=\"og:site_name\" content=\"ResearchGate\" \/>\n<meta property=\"og:image\" content=\"https:\/\/i1.rgstatic.net\/publication\/259478458_lil'_UCB_An_Optimal_Exploration_Algorithm_for_Multi-Armed_Bandits\/links\/03032c260cf23a729b8645b8\/smallpreview.png\" \/>\n<meta property=\"og:url\" content=\"https:\/\/www.researchgate.net\/publication\/259478458_lil'_UCB_An_Optimal_Exploration_Algorithm_for_Multi-Armed_Bandits\" \/>\n<meta property=\"rg:id\" content=\"PB:259478458\" \/>\n<meta name=\"DC.identifier\" scheme=\"DCTERMS.URI\" content=\"http:\/\/dx.doi.org\/\" \/>\n<meta name=\"gs_meta_revision\" content=\"1.1\" \/>\n<meta name=\"citation_title\" content=\"lil' UCB : An Optimal Exploration Algorithm for Multi-Armed Bandits\" \/>\n<meta name=\"citation_author\" content=\"Kevin Jamieson\" \/>\n<meta name=\"citation_author\" content=\"Matthew Malloy\" \/>\n<meta name=\"citation_author\" content=\"Robert Nowak\" \/>\n<meta name=\"citation_author\" content=\"S\u00e9bastien Bubeck\" \/>\n<meta name=\"citation_publication_date\" content=\"2013\/12\/27\" \/>\n<meta name=\"citation_journal_title\" content=\"Journal of Machine Learning Research\" \/>\n<meta name=\"citation_issn\" content=\"1532-4435\" \/>\n<meta name=\"citation_volume\" content=\"35\" \/>\n<meta name=\"citation_abstract_html_url\" content=\"https:\/\/www.researchgate.net\/publication\/259478458_lil'_UCB_An_Optimal_Exploration_Algorithm_for_Multi-Armed_Bandits\" \/>\n<meta name=\"citation_fulltext_html_url\" content=\"https:\/\/www.researchgate.net\/publication\/259478458_lil'_UCB_An_Optimal_Exploration_Algorithm_for_Multi-Armed_Bandits\" \/>\n<meta name=\"viewport\" content=\"width=device-width,initial-scale=1\" \/>\n<link href=\"\/\/c5.rgstatic.net\/m\/22664197317151888\/styles\/rg.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/21004998181197492\/styles\/rg2.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<!--[if lt IE 9]><link href=\"\/\/c5.rgstatic.net\/m\/238176252723686\/styles\/ie.css\" type=\"text\/css\" rel=\"stylesheet\"\/><![endif]-->\n<link href=\"\/\/c5.rgstatic.net\/m\/217752362214895\/styles\/modules\/publicprofile.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<script src=\"\/\/c5.rgstatic.net\/m\/2321000301012716\/javascript\/vendor\/webfontloader\/webfontloader.js\" type=\"text\/javascript\"><\/script>\n <script>(function(i,s,o,g,r,a,m){i[\"GoogleAnalyticsObject\"]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,\"script\",\"\/\/www.google-analytics.com\/analytics.js\",\"ga\");\n ga(\"create\",\"UA-58591210-1\");ga(\"set\",\"anonymizeIp\",true);ga('set', 'dimension1', 'publication slurped');ga('set', 'dimension2', 'Article');ga('set', 'dimension3', 'Logged out');ga('set', 'dimension4', 'https');ga(\"send\",\"pageview\");<\/script>\n","webfont":"<noscript><\/noscript><script> WebFontConfig = { custom: { families: ['source_sans_pro_italic', 'source_sans_pro_bold', 'source_sans_pro', 'martel'], urls : ['\/\/c5.rgstatic.net\/m\/231392577336386\/styles\/fonts.css'] } }; WebFont.load(WebFontConfig); <\/script>\n","correlationId":"rgreq-38eebf55-0611-448a-ae0e-415cff12bd4a","accountId":null,"module":"publicliterature","action":"publicliterature.PublicPublicationDetails","page":"publicationDetail","product":"publications","backendTime":436,"continent":"Asia","stylesHome":"\/\/c5.rgstatic.net\/m\/","staticHost":"c5.rgstatic.net","useEarlyFlush":false,"longRunningRequestIdentifier":"LongRunningRequest.publicliterature.PublicPublicationDetails","longRunningRequestFp":"e9e5bbe1366c7ee8c8e41d02f793c884ac9be19b","widgetId":"rgw33_56ab9e9f28d33"},"id":"rgw33_56ab9e9f28d33","partials":[],"templateName":"application\/stubs\/StaticHeader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.StaticHeader.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){
            Y.rg.core.pagespeed.Monitoring.monitorPage("\/\/glassmoni.researchgate.net", "publicliterature.PublicPublicationDetails.run.html.loggedOut.get", "59de9668d07aeb77ab4de5f24d382b5d199d2437", "rgreq-38eebf55-0611-448a-ae0e-415cff12bd4a", "8f83c2b6a9cd04ebd108064f6ec3fc319c7ca3bf");
        
            Y.rg.core.pagespeed.Monitoring.monitorPage("\/\/glassmoni.researchgate.net", "publicationDetail.loggedOut", "ed1993d9e20f6cefa83edacaa24401a18c071aea", "rgreq-38eebf55-0611-448a-ae0e-415cff12bd4a", "8f83c2b6a9cd04ebd108064f6ec3fc319c7ca3bf");
        })();
(function(){Y.rg.createInitialWidget({"data":{"year":"2016","inlinePromo":null,"isAdmin":false,"contactUrl":"https:\/\/www.researchgate.net\/contact","aboutUsUrl":"https:\/\/www.researchgate.net\/about","widgetId":"rgw34_56ab9e9f28d33"},"id":"rgw34_56ab9e9f28d33","partials":[],"templateName":"application\/stubs\/DefaultFooter.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.DefaultFooter.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"headerLogin":{"data":{"urlAfterLogin":"publication\/259478458_lil'_UCB_An_Optimal_Exploration_Algorithm_for_Multi-Armed_Bandits","requestToken":"+R4NKza0K+369UNdTHExeJLycvIxF7upR5CUu2qWBM7bT9j+B1WHGWjHtOvtFqNeNRxxAzQr8rfWqD7lEG5ujuxguDS8O8wFm+rSUrwarxYTT5kD+WiOHR+R8BIseR36+uz\/taTpBFfULdQVxG4daXquVi4TDzJF\/EUvsxU71Vg4fwit8FNBBbUkHpdmmhlGcTPpk2c7U67TG7XdxlbnymKTR9wcUkJ0jFyDFQNweo2pu6\/muQO1HYoWBAvMK6gfYdNholUxlSxpHUpefudqdsbH2Ve+KqmjjBPaxncgihc=","loginUrl":"https:\/\/www.researchgate.net\/application.Login.html","signupUrl":"https:\/\/www.researchgate.net\/signup.SignUp.html?ev=su_chnl_index&hdrsu=1&_sg=GTkZn6UlLbHzFfVJzWW0Eez7UYd0gdR7N5svv8r-mZX341JUz0Dfjs4QV_bcAITg","encodedUrlAfterLogin":"cHVibGljYXRpb24vMjU5NDc4NDU4X2xpbCdfVUNCX0FuX09wdGltYWxfRXhwbG9yYXRpb25fQWxnb3JpdGhtX2Zvcl9NdWx0aS1Bcm1lZF9CYW5kaXRz","signupCallToAction":"Join for free","widgetId":"rgw36_56ab9e9f28d33"},"id":"rgw36_56ab9e9f28d33","partials":{"partial":"application\/stubs\/partials\/headerLoginDefault.html"},"templateName":"application\/stubs\/HeaderLogin.html","templateExtensions":[],"attrs":{"goal":"milestoneHeaderLoginSeen"},"widgetUrl":"https:\/\/www.researchgate.net\/application.HeaderLogin.html","viewClass":"views.application.HeaderLoginView","yuiModules":["rg.views.application.HeaderLoginView"],"stylesheets":[],"_isYUI":true},"cookieConsent":null,"logoSvgSrc":"https:\/\/c5.rgstatic.net\/m\/235107188705592\/images\/template\/brand-header-logo.svg","logoFallbackSrc":"https:\/\/c5.rgstatic.net\/m\/238113351022438\/images\/template\/brand-header-logo.png","widgetId":"rgw35_56ab9e9f28d33"},"id":"rgw35_56ab9e9f28d33","partials":{"schemaSocialProfiles":"application\/stubs\/partials\/schemaSocialProfiles.html"},"templateName":"application\/stubs\/HeaderLoggedOut.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.HeaderLoggedOut.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"logEvent":"su_banner","specialCopy":false,"widgetId":"rgw37_56ab9e9f28d33"},"id":"rgw37_56ab9e9f28d33","partials":[],"templateName":"application\/stubs\/LoggedOutBanner.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.LoggedOutBanner.html","viewClass":"views.application.LoggedOutBannerView","yuiModules":["rg.views.application.LoggedOutBannerView"],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.core.util.ParameterFilter.filter(["ev","cp","ch","ref","dbw","pli","loginT","uid","claimChannel","enrichId","enrichSource","utm_source","utm_medium","utm_campaign","el","ci"]);})();
});}); } else { throw 'YRG was not loaded when attaching widgets'; }</script><script> dataLayer = [{"pageCategory":"publication slurped","publicationType":"Article","eventCategory":"Publication page"}]; </script> <noscript><iframe src="//www.googletagmanager.com/ns.html?id=GTM-MKVKH7" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-MKVKH7');</script><script>(function(e){function n(n,t,o,a){"use strict";var i=e.document.createElement("link"),r=t||e.document.getElementsByTagName("script")[0],d=e.document.styleSheets;return i.rel="stylesheet",i.href=n,i.media="only x",a&&(i.onload=a),r.parentNode.insertBefore(i,r),i.onloadcssdefined=function(e){for(var t,o=0;d.length>o;o++)d[o].href&&d[o].href.indexOf(n)>-1&&(t=!0);t?e():setTimeout(function(){i.onloadcssdefined(e)})},i.onloadcssdefined(function(){i.media=o||"all"}),i}function t(e,n){e.onload=function(){e.onload=null,n&&n.call(e)},"isApplicationInstalled"in navigator&&"onloadcssdefined"in e&&e.onloadcssdefined(n)}var o=function(a,i){"use strict";if(a&&3===a.length){var r=e.Image,d=!(!document.createElementNS||!document.createElementNS("http://www.w3.org/2000/svg","svg").createSVGRect||!document.implementation.hasFeature("http://www.w3.org/TR/SVG11/feature#Image","1.1")||e.opera&&-1===navigator.userAgent.indexOf("Chrome")||-1!==navigator.userAgent.indexOf("Series40")),c=new r;c.onerror=function(){o.method="png",o.href=a[2],n(a[2])},c.onload=function(){var e=1===c.width&&1===c.height,r=a[e&&d?0:e?1:2];o.method=e&&d?"svg":e?"datapng":"png",o.href=r,t(n(r),i)},c.src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///ywAAAAAAQABAAACAUwAOw==",document.documentElement.className+=" grunticon"}};o.loadCSS=n,o.onloadCSS=t,e.grunticon=o})(this);grunticon(["https://c5.rgstatic.net/c/o1q2er/styles/icons/_header-ico.svg.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_header-ico.png.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_header-ico.fallback.scss"]);grunticon(["https://c5.rgstatic.net/c/o1q2er/styles/icons/_admin-ico.svg.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_admin-ico.png.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_admin-ico.fallback.scss"]);grunticon(["https://c5.rgstatic.net/c/o1q2er/styles/icons/_ico.svg.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_ico.png.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_ico.fallback.scss"]);</script></body>
</html>
