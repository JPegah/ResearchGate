<!DOCTYPE html> <html lang="en" class="" id="rgw27_56aba281167b0"> <head > <meta charset="utf-8"/> <meta http-equiv="content-type" content="text/html; charset=UTF-8"/> <meta name="Rg-Request-Token" id="Rg-Request-Token" content="vQuCRmnMzKfecDJjQymYGCrstkBI7dOfL8mePyDITnbl4Wq0Q6iV1xHX4c9kRb3PqDyhIxivWnoSTYq3xNNL42EVgGMieYt55nSYacr4q4gt9o+w4Bvs9wZ+5YiYp019ptacYX3wLIMNCp7X2lupnHuryjOeU61ZnVTfdrbLvdDIVBD/zdD7VMn3JJudMYkBepS9Co8qRNbaBYHgrIJ4dizn9ZTwNAVF2hrujrhWWixAuGRiyabhFw0XnyFPNtq1ZY49NGcHuzFHrJd8M1Gr5dFnDh44iUV/DRay9vE1kRE="/> <meta http-equiv="expires" content="0"/> <link rel="apple-touch-icon" sizes="57x57" href="https://www.researchgate.net/apple-touch-icon-57x57.png"> <link rel="apple-touch-icon" sizes="60x60" href="https://www.researchgate.net/apple-touch-icon-60x60.png"> <link rel="apple-touch-icon" sizes="72x72" href="https://www.researchgate.net/apple-touch-icon-72x72.png"> <link rel="apple-touch-icon" sizes="76x76" href="https://www.researchgate.net/apple-touch-icon-76x76.png"> <link rel="apple-touch-icon" sizes="114x114" href="https://www.researchgate.net/apple-touch-icon-114x114.png"> <link rel="apple-touch-icon" sizes="120x120" href="https://www.researchgate.net/apple-touch-icon-120x120.png"> <link rel="apple-touch-icon" sizes="144x144" href="https://www.researchgate.net/apple-touch-icon-144x144.png"> <link rel="apple-touch-icon" sizes="152x152" href="https://www.researchgate.net/apple-touch-icon-152x152.png"> <link rel="apple-touch-icon" sizes="180x180" href="https://www.researchgate.net/apple-touch-icon-180x180.png"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-32x32.png" sizes="32x32"> <link rel="icon" type="image/png" href="https://www.researchgate.net/android-chrome-192x192.png" sizes="192x192"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-96x96.png" sizes="96x96"> <link rel="icon" type="image/png" href="https://www.researchgate.net/favicon-16x16.png" sizes="16x16"> <link rel="shortcut icon" type="image/x-icon" href="https://c5.rgstatic.net/m/2390829798215018/images/favicon.ico"/> <link rel="manifest" href="https://www.researchgate.net/manifest.json"> <meta name="msapplication-TileColor" content="#da532c"> <meta name="msapplication-TileImage" content="https://www.researchgate.net/mstile-144x144.png"> <meta name="theme-color" content="#444444"> <link rel="search" type="application/opensearchdescription+xml" title="ResearchGate search" href="https://www.researchgate.net/application.DownloadOpenSearchPlugin.html"/> <link rel="meta" type="application/rdf+xml" title="ICRA labels" href="https://www.researchgate.net/application.DownloadLabels.html"/> <link rel="http://oexchange.org/spec/0.8/rel/related-target" type="application/xrd+xml" href="https://www.researchgate.net/application.DownloadOExchange.html"/> <base href="https://www.researchgate.net/"/> <script>
    var rgConfig = {
        correlationId: "rgreq-6ca38958-116a-46c9-9c7f-f3252a4e1983",
        accountId: "",
        module: "publicliterature",
        action: "publicliterature.PublicPublicationDetails",
        page: "publicationDetail",
        product: "publications",
        continent: "Asia",
        stylesHome: "//c5.rgstatic.net/m/",
        staticHost: "c5.rgstatic.net",
        longRunningRequestIdentifier: "LongRunningRequest.publicliterature.PublicPublicationDetails",
        longRunningRequestFp: "e9e5bbe1366c7ee8c8e41d02f793c884ac9be19b"
    };
    window.rootUrl = "https://www.researchgate.net/";
</script> <link rel="canonical" href="https://www.researchgate.net/publication/228789130_Examples_of_adaptive_MCMC" />
<link rel="dns-prefetch" href="//c5.rgstatic.net" />
<link rel="dns-prefetch" href="//i1.rgstatic.net" />
<meta property="twitter:card" content="summary" />
<meta property="twitter:site" content="@ResearchGate" />
<meta property="og:title" content="Examples of adaptive MCMC" />
<meta property="og:description" content="We investigate the use of adaptive MCMC algorithms to automatically tune the Markov chain parameters during a run. Examples include the Adaptive Metropolis (AM) multivariate algorithm of Haario,..." />
<meta property="og:site_name" content="ResearchGate" />
<meta property="og:image" content="https://i1.rgstatic.net/publication/228789130_Examples_of_adaptive_MCMC/links/000473b10cf2847a19ef7d86/smallpreview.png" />
<meta property="og:url" content="https://www.researchgate.net/publication/228789130_Examples_of_adaptive_MCMC" />
<meta property="rg:id" content="PB:228789130" />
<meta name="DC.identifier" scheme="DCTERMS.URI" content="http://dx.doi.org/10.1198/jcgs.2009.06134" />
<meta name="gs_meta_revision" content="1.1" />
<meta name="citation_title" content="Examples of adaptive MCMC" />
<meta name="citation_author" content="Gareth O. Roberts" />
<meta name="citation_author" content="Jeffrey S. Rosenthal" />
<meta name="citation_publication_date" content="2009/06/01" />
<meta name="citation_journal_title" content="Journal of Computational and Graphical Statistics" />
<meta name="citation_issn" content="1061-8600" />
<meta name="citation_volume" content="18" />
<meta name="citation_issue" content="2" />
<meta name="citation_doi" content="10.1198/jcgs.2009.06134" />
<meta name="citation_abstract_html_url" content="https://www.researchgate.net/publication/228789130_Examples_of_adaptive_MCMC" />
<meta name="citation_fulltext_html_url" content="https://www.researchgate.net/publication/228789130_Examples_of_adaptive_MCMC" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<link href="//c5.rgstatic.net/m/22664197317151888/styles/rg.css" type="text/css" rel="stylesheet"/>
<link href="//c5.rgstatic.net/m/21004998181197492/styles/rg2.css" type="text/css" rel="stylesheet"/>
<!--[if lt IE 9]><link href="//c5.rgstatic.net/m/238176252723686/styles/ie.css" type="text/css" rel="stylesheet"/><![endif]-->
<link href="//c5.rgstatic.net/m/217752362214895/styles/modules/publicprofile.css" type="text/css" rel="stylesheet"/>
<script src="//c5.rgstatic.net/m/2321000301012716/javascript/vendor/webfontloader/webfontloader.js" type="text/javascript"></script>
 <script>(function(i,s,o,g,r,a,m){i["GoogleAnalyticsObject"]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,"script","//www.google-analytics.com/analytics.js","ga");
 ga("create","UA-58591210-1");ga("set","anonymizeIp",true);ga('set', 'dimension1', 'publication slurped');ga('set', 'dimension2', 'Article');ga('set', 'dimension3', 'Logged out');ga('set', 'dimension4', 'https');ga("send","pageview");</script>
  <script> WebFontConfig = { custom: { families: ['source_sans_pro_italic', 'source_sans_pro_bold', 'source_sans_pro', 'martel'], urls : ['//c5.rgstatic.net/m/231392577336386/styles/fonts.css'] } }; WebFont.load(WebFontConfig); </script><noscript></noscript>

<title>Examples of adaptive MCMC</title>
<meta name="description" content="Examples of adaptive MCMC on ResearchGate, the professional network for scientists."/>
<meta name="keywords" content="scientific network, scientific platform, scientific community, research partner, research collaboration, journal articles, international collaboration, find researcher, lifescience researcher, interdisciplinary research, research collaboration"/>
</head>
<body class="use-svg-icons logged-out">
<div id="page-container">
<script type="text/javascript">var googletag = googletag || {}; googletag.cmd = googletag.cmd || [];
(function() { var gads = document.createElement("script"); gads.async = true; gads.type = "text/javascript"; var useSSL = "https:" == document.location.protocol; gads.src = (useSSL ? "https:" : "http:") + "//www.googletagservices.com/tag/js/gpt.js"; var node =document.getElementsByTagName("script")[0]; node.parentNode.insertBefore(gads, node); })();</script><div id="main" class="logged-out-header-support">
<div id="content" class="">

<noscript>
<div class="c-box-warning full-width-element" style="text-align: center; ">
    <div style="margin: auto; padding:10px;" class="container">
        <b>For full functionality of ResearchGate it is necessary to enable JavaScript.
            Here are the <a href="http://www.enable-javascript.com/" rel="nofollow" target="_blank">
                instructions how to enable JavaScript in your web browser</a>.</b>
    </div>
</div>
</noscript>

<div id="rgw1_56aba281167b0" itemscope itemtype="http://schema.org/ScholarlyArticle"><div class="publication-wrapper publication-wrapper-onecol" id="rgw2_56aba281167b0" itemscope itemtype="http://schema.org/ScholarlyArticle"> <div class="c-col-content"> <div class="c-content"> <div class="clearfix">  <div class="publication-header"> <div id="rgw5_56aba281167b0">  <div class="type-label"> Article   </div> <span class="Z3988" title="ctx_ver=Z39.88-2004&rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&rfr_id=info%3Asid%2Fresearchgate.net%3Aresearchgate&rft_id=info%3Adoi%2F10.1198%2Fjcgs.2009.06134&rft.atitle=Examples%20of%20adaptive%20MCMC&rft.title=Journal%20of%20Computational%20and%20Graphical%20Statistics%20-%20J%20COMPUT%20GRAPH%20STAT&rft.jtitle=Journal%20of%20Computational%20and%20Graphical%20Statistics%20-%20J%20COMPUT%20GRAPH%20STAT&rft.volume=18&rft.issue=2&rft.date=2009&rft.issn=1061-8600&rft.au=Gareth%20O.%20Roberts%2CJeffrey%20S.%20Rosenthal&rft.genre=article"></span> <h1 class="pub-title" itemprop="name">Examples of adaptive MCMC</h1> <meta itemprop="headline" content="Examples of adaptive MCMC">  <meta itemprop="image" content="https://i1.rgstatic.net/publication/228789130_Examples_of_adaptive_MCMC/links/000473b10cf2847a19ef7d86/smallpreview.png">  <div id="rgw8_56aba281167b0" class="publication-detail-author-list"> <div> <ul class="clearfix js-people-list">  <li id="rgw9_56aba281167b0"> <a href="researcher/7075391_Gareth_O_Roberts" class="pub-detail-item author-item" itemprop="author" itemscope itemtype="http://schema.org/Person"> <div class="indent-left"> <div class="people-img">  <img src="https://c5.rgstatic.net/m/2951093203564/images/template/default/profile/profile_default_s.jpg" title="Gareth O. Roberts" alt="Gareth O. Roberts" height="20px" width="20px" style="height: 20px;"/>  </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Gareth O. Roberts</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item   not-claimed " id="rgw10_56aba281167b0">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="researcher/7075391_Gareth_O_Roberts"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="Gareth O. Roberts" alt="Gareth O. Roberts" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">       </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="researcher/7075391_Gareth_O_Roberts" class="display-name">Gareth O. Roberts</a>    </h5> <div class="truncate-single-line meta">   </div>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>  <li id="rgw11_56aba281167b0" itemprop="author" itemscope itemtype="http://schema.org/Person"> <a itemprop="sameAs" href="profile/Jeffrey_Rosenthal" class="pub-detail-item account-item"> <div class="indent-left"> <div class="people-img"> <img  src="https://c5.rgstatic.net/m/2671872220764/images/template/default/profile/profile_default_m.jpg" title="Jeffrey S. Rosenthal" alt="Jeffrey S. Rosenthal" height="20px" width="20px" style="height: 20px;"/> </div> </div> <div class="indent-content"> <div class="item-name"> <span itemprop="name">Jeffrey S. Rosenthal</span> </div> </div> </a>  <div style="display: none"> <div class="js-tooltip-content"> <ul class="pub-detail-item-tooltip"> <li class="people-item js-list-item  remove-action-indent   " id="rgw12_56aba281167b0" data-account-key="Jeffrey_Rosenthal">   <div class="indent-left"> <div class="c-img-l people-img ga-top-coauthor-image">  <a href="profile/Jeffrey_Rosenthal"> <img class="lazyload" data-src="https://c5.rgstatic.net/m/237738464651637/images/template/default/profile/profile_default_l.jpg" title="Jeffrey S. Rosenthal" alt="Jeffrey S. Rosenthal" height="90px" width="90px"/> </a>   </div> </div> <div class="indent-right">     </div> <div class="indent-content"> <h5 class="ga-top-coauthor-name">  <a href="profile/Jeffrey_Rosenthal" class="display-name">Jeffrey S. Rosenthal</a>    </h5> <div class="truncate-single-line meta">   <a class="meta ga-top-coauthor-institution" href="institution/University_of_Toronto" title="University of Toronto">University of Toronto</a>     </div>  <a href="javascript:" class="btn btn-promote btn-large people-item-contact-author js-contact-author">Message author</a>  <div class="hide-button-container hide-button" style="display: none;"> <a href="javascript:" class="details js-hide action-hide">Remove suggestion</a> </div>  </div>    </li> </ul> </div> </div>  </li>   </ul> <div class="js-loading"></div>  </div> </div> <div class="pub-details js-pub-details">      <span itemprop="isPartOf" itemscope itemtype="http://schema.org/Periodical"> <a itemprop="sameAs" href="journal/1061-8600_Journal_of_Computational_and_Graphical_Statistics"><span itemprop="name">Journal of Computational and Graphical Statistics</span></a> </span>    (Impact Factor: 1.22).     <meta itemprop="datePublished" content="2009-06">  06/2009;  18(2).    DOI:&nbsp;10.1198/jcgs.2009.06134           </div> <div id="rgw13_56aba281167b0" class="pub-abstract">  <div class="clearfix">   <div style="max-height: 54px;" class="js-expander-container js-expander-collapsed">  <p itemprop="description"> <strong>ABSTRACT</strong> <div>We investigate the use of adaptive MCMC algorithms to automatically tune the Markov chain parameters during a run. Examples include the Adaptive Metropolis (AM) multivariate algorithm of Haario, Saksman, and Tamminen (2001), Metropoliswithin- Gibbs algorithms for nonconjugate hierarchical models, regionally adjusted Metropolis algorithms, and logarithmic scalings. Computer simulations indicate that the algorithms perform very well compared to nonadaptive algorithms, even in high dimension. &copy; 2009 American Statistical Association, Institute of Mathematical Statistics, and Interface Foundation of North America.</div> </p>  </div>  </div>   </div>      <div class="action-container">   <div class="clear"></div> <div class="share-dialog-container" style="display: none;">  </div> </div> </div> <div style="margin-left: -20px; margin-right: -20px;">  </div> </div>  <div class="publication-detail-dfp-container rf"> <div id="rgw26_56aba281167b0">  </div> </div>  </div>  <div class="clearfix">  <noscript> <div id="rgw25_56aba281167b0"  itemprop="articleBody">  <p>Page 1</p> <p>Examples of Adaptive MCMC<br />by<br />Gareth O. Roberts*<br />andJeffrey S. Rosenthal**<br />(September 2006; revised January 2008.)<br />Abstract.<br />matically tune the Markov chain parameters during a run. Examples include<br />the Adaptive Metropolis (AM) multivariate algorithm of Haario et al. (2001),<br />Metropolis-within-Gibbs algorithms for non-conjugate hierarchical models, re-<br />gionally adjusted Metropolis algorithms, and logarithmic scalings. Computer<br />simulations indicate that the algorithms perform very well compared to non-<br />adaptive algorithms, even in high dimension.<br />We investigate the use of adaptive MCMC algorithms to auto-<br />1. Introduction.<br />MCMC algorithms such as the Metropolis-Hastings algorithm (Metropolis et al., 1953;<br />Hastings, 1970) are extremely widely used in statistical inference, to sample from complicated<br />high-dimensional distributions. Tuning of associated parameters such as proposal variances<br />is crucial to achieve efficient mixing, but can also be very difficult.<br />Adaptive MCMC algorithms attempt to deal with this problem by automatically “learn-<br />ing” better parameter values of Markov chain Monte Carlo algorithms while they run. In<br />this paper, we consider a number of examples of such algorithms, including some in high<br />dimensions. We shall see that adaptive MCMC can be very successful at finding good pa-<br />rameter values with little user intervention. In our context, good will be defined in terms of<br />some appropriate measure of Markov chain mixing, such as the integrated autocorrelation<br />of a functional of interest.<br />It is known that adaptive MCMC algorithms will not always preserve stationarity of π(·),<br />see e.g. Rosenthal (2004) and Proposition 3 of Roberts and Rosenthal (2005). However, they<br />will converge if the adaptions are done at regeneration times (Gilks et al., 1998; Brockwell<br />and Kadane, 2005), or under various technical conditions about the adaption procedure<br />*Department of Mathematics and Statistics, Fylde College, Lancaster University, Lancaster, LA1 4YF,<br />England. Email: g.o.roberts@lancaster.ac.uk.<br />**Department of Statistics, University of Toronto, Toronto, Ontario, Canada<br />jeff@math.toronto.edu. Web: http://probability.ca/jeff/ Supported in part by NSERC of Canada.<br />M5S 3G3. Email:<br />1</p>  <p>Page 2</p> <p>(Haario et al., 2001; Atchad´ e and Rosenthal, 2005; Andrieu and Moulines, 2003; Andrieu<br />and Atchad´ e, 2006).<br />Roberts and Rosenthal (2005) proved ergodicity of adaptive MCMC under conditions<br />which we find simpler to apply, and which do not require that the adaptive parameters<br />converge. To state their result precisely, suppose the algorithm updates Xnto Xn+1using<br />the kernel PΓn, where each fixed kernel Pγ has stationary distribution π(·), but where the<br />Γnare random indices, chosen iteratively from some collection Y based on past algorithm<br />output. Write ?···? for total variation distance, X for the state space, and M?(x,γ) =<br />inf{n ≥ 1 : ?Pn<br />in state x ∈ X. Then Theorem 13 of Roberts and Rosenthal (2005), combined slightly<br />with their Corollaries 8 and 9 and Theorem 23 guarantee that limn→∞?L(Xn) − π(·)? = 0<br />(asymptotic convergence), and also limn→∞<br />n<br />(WLLN), assuming only the Diminishing Adaptation condition<br />γ(x,·) − π(·)? ≤ ?} for the convergence time of the kernel Pγwhen beginning<br />1<br />?n<br />i=1g(Xi) = π(g) for all bounded g : X → R<br />lim<br />n→∞sup<br />x∈X?PΓn+1(x,·) − PΓn(x,·)? = 0 in probability, (1)<br />and the Bounded Convergence condition<br />{M?(Xn,Γn)}∞<br />n=0<br />is bounded in probability, ? &gt; 0. (2)<br />Furthermore, they prove that (2) is satisfied whenever X × Y is finite, or is compact in<br />some topology in which either the transition kernels Pγ, or the Metropolis-Hastings proposal<br />kernels Qγ, have jointly continuous densities. (Condition (1) can be ensured directly, by<br />appropriate design of the adaptive algorithm.) A SLLN is precluded since the convergence<br />statements above are only stated “in probability”, while CLTs do not necessarily hold since<br />Γndoes not necessarily converge at all.<br />Such results provide a “hunting license” to look for useful adaptive MCMC algorithms. In<br />this paper, we shall consider a variety of such algorithms. We shall see that they do indeed<br />converge correctly, and often have significantly better mixing properties than comparable<br />non-adaptive algorithms.<br />We present a collection of examples. For each one, our adaptive strategy steers the<br />algorithm towards a desired operational “optimal” according to some prescribed criterion.<br />Crucially, our approach differs from that of Andrieu and Moulines, 2003 and Andrieu and<br />Atchad´ e, in that unlike our method, convergence of the adaptive strategy is specifically<br />sought in their approach. Our regularity conditions are thus weaker and easier to verify,<br />though as a result, the results we can demonstrate are necessarily weaker also.<br />2</p>  <p>Page 3</p> <p>2. Adaptive Metropolis (AM).<br />In this section, we consider a version of the Adaptive Metropolis (AM) algorithm of Haario<br />et al. (2001). We begin with a d-dimensional target distribution π(·). We perform a Metropo-<br />lis algorithm with proposal distribution given at iteration n by Qn(x,·) = N(x, (0.1)2Id/d)<br />for n ≤ 2d, while for n &gt; 2d,<br />Qn(x,·) = (1 − β)N(x, (2.38)2Σn/d) + β N(x, (0.1)2Id/d),(3)<br />where Σnis the current empirical estimate of the covariance structure of the target distri-<br />bution based on the run so far, and where β is a small positive constant (we take β = 0.05).<br />It is known from Roberts et al. (1997) and Roberts and Rosenthal (2001) that the pro-<br />posal N(x, (2.38)2Σ/d) is optimal in a particular large-dimensional context. Thus, the<br />N(x, (2.38)2Σn/d) proposal is an effort to approximate this.<br />Since empirical estimates change at the nthiteration by only O(1/n), it follows that (1)<br />will be satisfied. Restricting β &gt; 0 in (3) ensures that (2) is satisfied, at least for a large family<br />of target densities which includes all those which are log-concave outside some arbitrary<br />bounded region (see Section 8). Hence, this algorithm will indeed converge to π(·) and<br />satisfy the WLLN. (Haario et al. instead let Qn(x,·) = N(x, Σn+ ?Id) for small ?, to force<br />c1Id≤ Σn≤ c2Idfor some c1,c2&gt; 0, which also ensures (1) and (2) for target distributions<br />with bounded support, but we prefer to avoid this strong assumption.)<br />To test this algorithm, we let π(·) = N(0, M Mt), where M is a d × d matrix generated<br />randomly by letting {Mij}d<br />matrix Σ = M Mtwill be highly erratic, so that sampling from π(·) presents a significant<br />challenge for sampling if the dimension is at all high.<br />The resulting trace plot of the first coordinate of the Markov chain is presented in Figure 1<br />for dimension d = 100, and in Figure 2 for dimension d = 200. In both cases, the Markov<br />chain takes a long time to adapt properly and settle down to rapid mixing. In the early<br />stages, the algorithm vastly underestimates the true stationary variance, thus illustrating<br />the pitfalls of premature diagnoses of MCMC convergence. In the later stages, by contrast,<br />the algorithm has “learned” how to sample from π(·), and does so much more successfully.<br />Another way of monitoring the success of this algorithm’s adapting is as follows. Con-<br />sider a multi-dimensional random-walk Metropolis algorithm with proposal covariance ma-<br />trix (2.38)2Σp/d, acting on a normal target distribution with true covariance matrix Σ.<br />Theorem 5 of Roberts and Rosenthal (2001) prove that it is optimal to take Σp= Σ, and for<br />i,j=1be i.i.d. ∼ N(0,1). This ensures that the target covariance<br />3</p>  <p>Page 4</p> <p>0e+004e+05 8e+05<br />−2<br />−1<br />0<br />1<br />2<br /> <br /> <br />Figure 1. The first coordinate of the AM Markov chain in dimension 100, plotted<br />against iteration number.<br />0 10000002500000<br />−4<br />−2<br />0<br />2<br />4<br />Figure 2. The first coordinate of the AM Markov chain in dimension 200, plotted<br />against iteration number.<br />4</p>  <p>Page 5</p> <p>0e+004e+05 8e+05<br />0<br />50<br />100<br />150<br />200<br /> <br /> <br />Figure 3. The suboptimality factor b for the AM algorithm in dimension 100,<br />plotted against iteration number.<br />other Σpthe mixing rate will be slower than this by a sub-optimality factor of<br />b ≡ d<br />?d<br />i=1λ−2<br />i=1λ−1<br />i<br />(?d<br />i )2,<br />where {λi} are the eigenvalues of the matrix Σ1/2<br />closer b is to 1, the better. The criterion being optimised in AM is therefore b−1.<br />So how does the AM algorithm perform by this measure? For the run in dimension 100,<br />the value of this sub-optimality coefficient b begins at the huge value of 193.53, and then even-<br />tually decreases towards 1, reaching 1.086 after 500,000 iterations, and 1.024 after 1,000,000<br />iterations (Figure 3). In dimension 200, the value of b is even more erratic, starting around<br />183,000 and oscillating wildly before decreasing to about 1.04 after 800000 iterations.<br />We conclude from this that the AM algorithm does indeed “learn” about the true tar-<br />get covariance matrix, and converge to an algorithm which samples very (almost optimally)<br />efficiently from π(·). It is true that it takes many iterations for the algorithm to learn<br />this information (nearly 400,000 iterations in dimension 100, and nearly 2,000,000 in dimen-<br />sion 200). On the other hand, what the algorithm is learning is a d×d covariance matrix with<br />many parameters (5,050 parameters in dimension 100, and 20,100 in dimension 200). We<br />feel that this indicates very impressive performance of the AM algorithm in high dimensions.<br />p<br />Σ−1/2. Usually we will have b &gt; 1, and the<br />5</p>  <p>Page 6</p> <p>0e+002e+06 4e+06<br />−15<br />−5 0<br />5 10<br /> <br /> <br />Figure 4. Trace plot of the first coordinate in the banana-shaped example.<br />2.1. An irregularly shaped example.<br />AM can be expected to work well on target densities in which the density contours form<br />roughly elliptical contours. In such examples the global covariance gives a good measure of<br />dependence valid in all parts of the state space. However, it is interesting to see how the<br />approach performs on a more challenging problem with more irregularly shaped contours.<br />We also applied our full Adaptive Metropolis algorithm to a “banana-shaped” distribu-<br />tion, as proposed by Haario et al. (1999, 2001), with density<br />fB= fd◦ φB<br />where fdis the d-dimensional density of a N(0, diag(100,1,1,...,1)) distribution, and where<br />φB(x1,...,xd) = (x1,x2+ Bx2<br />So,<br />1− 100B,x3,...,xd) with B &gt; 0 the “bananicity” constant.<br />fB(x1,...,xd) ∝ exp<br />?<br />− x2<br />1/200 −1<br />2(x2+ Bx2<br />1− 100B)2−1<br />2(x2<br />3+ x2<br />4+ ... + x2<br />d)<br />?<br />.<br />Specifically, we take dimension d = 20, and take B = 0.1, and run the algorithm for<br />5,000,000 iterations. A trace plot of the first coordinate is given in Figure 4.<br />It is clear that the adaptation has improved mixing here. However mixing is still very<br />poor after 5000000 iterations which is to be expected given that ant Metropolis method<br />6</p>  <p>Page 7</p> <p>struggles to traverse this distributions support. Whilst the AM algorithm attempts to move<br />around as effectively as it can, classes of algorithms which can adjust the covariance of the<br />proposal distribution according to the current state of the algorithm should be required.<br />This in part motivates some of the methods we shall introduce in later sections.<br />3. Adaptive Metropolis-Within-Gibbs.<br />Consider the following statistical model:<br />µ<br />↓??<br />θ1<br />↓<br />... ... θK<br />↓<br />θi∼ Cauchy(µ,A) [1 ≤ i ≤ K]<br />↓<br />Y11,...,Y1r1<br />YK1,...,YKrK<br />Yij∼ N(θi,V )[1 ≤ j ≤ ri]<br />with priors N(0,1) on µ, and IG(1,1) on A and V . Here {Yij} are observed data, IG(a,b) is<br />the inverse gamma distribution with density proportional to e−b/xx−(a+1), and Cauchy(m,s)<br />is a translated and scaled Cauchy distribution with density proportional to [1 + ((x −<br />m)/s)2]−1. This model gives rise to a posterior distribution π(·) on the (K +3)-dimensional<br />vector (A,V,µ,θ1,...,θK), conditional on the observed data {Yij}.<br />We take K = 500, and let the rivary between 5 and 500. The resulting model is too<br />complicated for analytic computation, and far too high-dimensional for numerical integra-<br />tion. Furthermore, the presence of the Cauchy (as opposed to Normal) distribution destroys<br />conjugacy, and thus makes a classical Gibbs sampler (as in Gelfand and Smith, 1990) infea-<br />sible. Instead, a Metropolis-within-Gibbs algorithm (Metropolis et al., 1953; Tierney, 1994)<br />seems appropriate.<br />Such an algorithm might proceed as follows. We consider each of the 503 variables in<br />turn. For each, we propose updating its value by adding a N(0,σ2) increment. That proposal<br />is then accepted or rejected according to the usual Metropolis ratio. This process is repeated<br />many times, allowing the variables to hopefully converge in distribution to π(·). But how<br />should σ2be chosen? Should it be different for different variables? How can we feasibly<br />determine appropriate scalings in such high dimension?<br />To answer these questions, an adaptive algorithm can be used. We proceed as follows.<br />For each of the variables i [1 ≤ i ≤ K + 3], we create an associated variable lsi giving<br />the logarithm of the standard deviation to be used when proposing a normal increment to<br />variable i. We begin with lsi= 0 for all i (corresponding to unit proposal variance). After<br />the nth“batch” of 50 iterations, we update each lsiby adding or subtracting an adaption<br />amount δ(n). The adapting attempts to make the acceptance rate of proposals for variable i<br />7</p>  <p>Page 8</p> <p>050000 150000250000<br />0.0<br />0.5<br />1.0<br />1.5<br />2.0<br />2.5<br />Figure 5.<br />Metropolis-within-Gibbs variable θ1, plotted against batch number.<br />The log proposal standard deviation ls1 corresponding to the<br />as close as possible to 0.44 (which is optimal for one-dimensional proposals in certain settings,<br />cf. Roberts et al., 1997; Roberts and Rosenthal, 2001). Specifically, we increase lsiby δ(n)<br />if the fraction of acceptances of variable i was more than 0.44 on the nthbatch, or decrease<br />lsiby δ(n) if it was less.<br />Condition (1) is satisfied provided δ(n) → 0; we take δ(n) = min(0.01, n−1/2). Our<br />approach is to specify a global maximal parameter value M &lt; ∞, and restrict each lsito<br />the interval [−M,M]. For a large class of target densities (which includes all those which<br />are log-concave outside an arbitrary bounded region) this ensures (2) hold. In practice, the<br />lsistabilise nicely so the bound on M is not actually needed.<br />To test this adaptive algorithm, we generate independent test data Yij∼ N(i − 1, 102),<br />for 1 ≤ i ≤ 500 and 1 ≤ j ≤ ri. For such data, our simulations show that the scaling<br />variables quickly settle down near “good” values where acceptance rates are roughly 0.44.<br />Indeed, for the location variables θ1, θ2, and θ3, the corresponding ls variables converge to<br />values near 2.4, 1.2, and 0.1, respectively (Figures 5, 6, 7). So the algorithm appears to be<br />converging well.<br />Just how good are the values chosen? The following table presents the integrated auto-<br />correlation times (ACT) and average squared jumping distances (after discarding the first<br />fifth of the run as burn-in), for both the adaptive algorithm, and the corresponding “fixed”<br />8</p>  <p>Page 9</p> <p>050000 150000250000<br />0.0<br />0.4<br />0.8<br />1.2<br />Figure 6.<br />Metropolis-within-Gibbs variable θ2, plotted against batch number.<br />The log proposal standard deviation ls2 corresponding to the<br />0 50000150000250000<br />0.00<br />0.10<br />0.20<br />0.30<br />Figure 7.<br />Metropolis-within-Gibbs variable θ3, plotted against batch number.<br />The log proposal standard deviation ls3 corresponding to the<br />9</p>  <p>Page 10</p> <p>algorithm where each lsiis fixed at 0:<br />Variable<br />θ1<br />θ1<br />θ2<br />θ2<br />θ3<br />θ3<br />ri<br />5<br />5<br />50<br />50<br />500<br />500<br />Algorithm<br />Adaptive<br />Fixed<br />Adaptive<br />Fixed<br />Adaptive<br />Fixed<br />ACT<br />2.59<br />31.69<br />2.72<br />7.33<br />2.72<br />2.67<br />Avr Sq Dist<br />14.932<br />0.863<br />1.508<br />0.581<br />0.150<br />0.147<br />This table shows that, when comparing adaptive to fixed algorithms, for variables θ1<br />and θ2, the autocorrelation times are significantly smaller (better) and the average squared<br />jumping distances are significantly larger (better), Thus, adapting has significantly improved<br />the MCMC algorithm, by automatically choosing appropriate proposal scalings separately for<br />each coordinate. For variable θ3the performance of the two algorithms is virtually identical,<br />which is not surprising since (Figure 7) the optimal log proposal standard deviation happens<br />to be very close to 0 in that case.<br />In summary, this adaptive algorithm appears to correctly scale the proposal standard<br />deviations, leading to a Metropolis-within-Gibbs algorithm which mixes much faster than<br />a naive one with unit proposal scalings. Coordinates are improved wherever possible, and<br />are left about the same when they happen to already be optimal. This works even in high<br />dimensions, and does not require any direct user intervention or high-dimensional insight.<br />This algorithm has recently been applied to a statistical genetics problem (Turro et al.,<br />2007).<br />3.1. A comparison with SCAM.<br />A different component-wise adaptive scaling method, the Single Component Adaptive<br />Metropolis (SCAM) algorithm, is presented in Haario et al. (2005). That algorithm, which<br />resembles the Adaptive Metropolis algorithm of Haario et al. (2001), is very interesting and<br />promising, but differs significantly from ours since the SCAM adapting is done based on the<br />empirical variance of each component based on the run so far.<br />For comparative purposes, we also ran the SCAM algorithm of Haario et al. (2005) on the<br />same example as that above for adaptive Metropolis-within-Gibbs. The SCAM algorithm<br />uses the proposal distribution Yi<br />n∼ N(Xi<br />?<br />(2.4)2(gi<br />n−1,vi<br />n) for the ithcoordinate, where<br />vi<br />n=<br />52,n ≤ 10<br />n ≥ 11<br />n+ 0.05),<br />10</p>  <p>Page 11</p> <p>0e+002e+05 4e+05<br />2.4<br />2.5<br />2.6<br />2.7<br />2.8<br /> <br /> <br />Figure 8. The log proposal standard deviation ls1corresponding to the SCAM<br />variable θ1, plotted against iteration number.<br />Here gi<br />mimic an “optimal” one-dimensional variance (2.38)2Varπ(Xi) similar to what was discussed<br />above; the published version of SCAM omits the square in “2.4” but we assume the above is<br />what was intended.) Writing xi<br />n<br />use the recursive equations<br />xi<br />n<br />and<br />gi<br />n − 1gi<br />We again consider the first three coordinates, as above. The graphs of their proposal<br />variances (again on a log scale, for consistency with the above) are presented here.<br />We also compute the mean log σ, ACT, and average squared jumping distance:<br />nis the sample variance of X(i)<br />0,X(i)<br />1,...,X(i)<br />n−1. (Intuitively, for n ≥ 11, vi<br />nattempts to<br />n=<br />1<br />?n−1<br />n − 1<br />j=0x(i)<br />j, we see (cf. Haario et al., 2005) that we can<br />n=xi<br />n−1+1<br />nxi<br />n−1<br />n=<br />n − 2<br />n−1+ (xi<br />n−1)2+<br />1<br />n − 1(xi<br />n)2−<br />n<br />n − 1(xi<br />n)2.<br />11</p>  <p>Page 12</p> <p>0e+002e+05 4e+05<br />1.2<br />1.6<br />2.0<br />2.4<br /> <br /> <br />Figure 9. The log proposal standard deviation ls2corresponding to the SCAM<br />variable θ2, plotted against iteration number.<br />0e+00 2e+054e+05<br />0.5<br />1.0<br />1.5<br />2.0<br /> <br /> <br />Figure 10. The log proposal standard deviation ls3corresponding to the SCAM<br />variable θ3, plotted against iteration number.<br />12</p>  <p>Page 13</p> <p>Variable<br />θ1<br />θ1<br />θ1<br />θ2<br />θ2<br />θ2<br />θ3<br />θ3<br />θ3<br />ri<br />5<br />5<br />5<br />50<br />50<br />50<br />500<br />500<br />500<br />Algorithm<br />Adaptive<br />Fixed<br />SCAM<br />Adaptive<br />Fixed<br />SCAM<br />Adaptive<br />Fixed<br />SCAM<br />log(σ)<br />2.35<br />0<br />2.38<br />1.21<br />0<br />1.27<br />0.08<br />0<br />0.26<br />ACT<br />2.59<br />31.69<br />2.77<br />2.72<br />7.33<br />2.77<br />2.72<br />2.67<br />2.77<br />Avr Sq Dist<br />14.932<br />0.863<br />14.951<br />1.508<br />0.581<br />1.486<br />0.150<br />0.147<br />0.145<br />The table shows that the results of SCAM are comparable to those of our adaptive<br />Metropolis-within-Gibbs algorithm. In this case, they were virtually identical for θ1, and<br />just slightly worse for θ2 and θ3. As for choice of proposal variance σ2, there are some<br />differences, with the SCAM choices generally larger than those for our algorithm. Overall,<br />we feel that both of these algorithms are useful approaches to high-dimensional adaptive<br />MCMC, and both should be kept in the applied user’s arsenal.<br />4. State-Dependent Scaling.<br />We next consider examples of full-dimensional Metropolis-Hastings algorithms, where<br />the proposal distribution is given by Q(x,·) = N(x, σ2<br />ance depends on the current state x ∈ X. For such an algorithm, according to the usual<br />Metropolis-Hastings formula (Hastings, 1970), a proposal from x to y is accepted with prob-<br />ability<br />?<br />As a first case, we let X = R, and π(·) = N(0,1). We consider proposal kernels of the<br />form<br />?<br />x), i.e. such that the proposal vari-<br />α(x,y) = min1,<br />π(y)<br />π(x)(σx/σy)dexp( −1<br />2(x − y)2(σ−2<br />y − σ−2<br />x))<br />?<br />. (4)<br />Qa,b(x,·) = N x, ea?1 + |x|<br />exp(ˆ π)<br />?b?<br />,<br />where ˆ π is our current empirical estimate of π(g) where g(x) = log(1 + |x|). (We divide by<br />exp(ˆ π) to make the choices of a and b “orthogonal” in some sense.) After the nthbatch of<br />100 iterations, we update a by adding or subtracting δ(n) in an effort to, again, make the<br />acceptance rate as close as possible to 0.44. We also add or subtract δ(n) to b to make the<br />acceptance rates, acc−and acc+respectively, in the regions A−= {x ∈ X : log(1+|x|) &gt; ˆ π}<br />and A+= {x ∈ X : log(1 + |x|) ≤ ˆ π} as equal as possible. This then increases the proposal<br />variance in the region where acceptance rates are highest (thus lowering the acceptance rate)<br />13</p>  <p>Page 14</p> <p>0e+004e+048e+04<br />0.0<br />0.5<br />1.0<br />1.5<br />Figure 11. The tuning parameter a in the State-Dependent Scaling example,<br />plotted against batch number, showing quick approach to “good” values near 1.5.<br />and correspondingly increasing the acceptance rate where the acceptance rate is lowest. The<br />criterion being minimised here is therefore acc2<br />As in previous examples, condition (1) is automatically satisfied, at least if we insist on<br />δ(n) → 0. In order for us to be able to demonstrated (2) however (at least for a particular<br />family of target densities), we shall impose an extra condition, requiring that a and b be<br />constrained within [−M,M] for some global parameter M &lt; ∞.<br />So how does this algorithm perform in practice?<br />converge to their true values, showing excellent mixing. Furthermore, the tuning parameters<br />a and b quickly find their “good” values (Figures 11 and 12), though they do continue to<br />oscillate due to the extremely slow rate at which δ(n) → 0.<br />To determine how well the adaptive algorithm is performing, we compare its integrated<br />autocorrelation time and average squared jumping distance to corresponding non-adaptive<br />algorithms, having either fixed constant variance σ2(including the optimal constant value,<br />(2.38)2), and to the corresponding variable-variance algorithm. The results are as follows:<br />++ acc2<br />−.<br />Empirical expected values quickly<br />14</p>  <p>Page 15</p> <p>0e+00 4e+048e+04<br />0.8<br />1.2<br />1.6<br />Figure 12. The tuning parameter b in the State-Dependent Scaling example,<br />plotted against batch number, showing quick approach to “good” values near 1.6,<br />but with significant oscillation.<br />Algorithm<br />Adaptive (as above)<br />σ2= exp(−5)<br />σ2= exp(−1)<br />σ2= 1<br />σ2= (2.38)2<br />σ2= exp(5)<br />σ2<br />Acceptance Rate<br />0.456<br />0.973<br />0.813<br />0.704<br />0.445<br />0.237<br />ACT<br />2.63<br />49.92<br />8.95<br />4.67<br />2.68<br />7.22<br />Avr Sq Dist<br />0.769<br />0.006<br />0.234<br />0.450<br />0.748<br />0.305<br />x= e1.5?<br />1+|x|<br />0.534822<br />?1.6<br />0.456 2.580.778<br />We see that our adaptive scheme is much better than arbitrarily-chosen fixed-variance<br />algorithms, slightly better than the optimally-chosen fixed-variance algorithm (chosen by<br />an ad-hoc search for maximising Average Square Jumping Distance, and given on the 5th<br />line), and nearly as good as an ideally-chosen variable-σ2scheme chosen using a similar<br />maximisation of average squared jumping distance on a grid of possible (a,b) values (bottom<br />line). The results are quite impressive, since we didn’t do any manual tuning of our algorithm<br />at all other than telling the computer to seek a 0.44 acceptance rate.<br />While these functional forms of σ2<br />to higher dimensional problems. Instead, we next consider a different algorithm in which<br />the σ2<br />xseem promising, it is not clear how to generalise them<br />xare piecewise constant over various regions of the state space.<br />15</p>  <p>Page 16</p> <p>5. Regional Adaptive Metropolis Algorithm (RAMA).<br />The Regional Adaptive Metropolis Algorithm (RAMA) begins by partitioning the state<br />space X into a finite number of disjoint regions: X = X1<br />proceeds by running a Metropolis algorithm with proposal Q(x,·) = N(x, exp(2ai)) when-<br />ever x ∈ Xi. Thus, if x ∈ Xiand y ∈ Xj, then σ2<br />that a proposal from x to y is accepted with probability<br />•∪ ...<br />•∪Xm. The algorithm then<br />x= e2aiand σ2<br />y= e2aj, and it follows from (4)<br />α(x,y) = min<br />?<br />1,<br />π(y)<br />π(x)<br />exp(d(ai− aj) −1<br />2(x − y)2[exp(−2aj) − exp(−2ai)])<br />?<br />.<br />The adaptions proceed as follows, in an effort to make the acceptance probability close<br />to 0.234 in each region. (Such an acceptance rate is optimal in certain high-dimensional<br />settings; see Roberts et al., 1997; Roberts and Rosenthal, 1998, 2001; B´ edard, 2006a, 2006b,<br />and we envisage that typically Xi would be a space of the same dimension as X.) For<br />1 ≤ i ≤ d, the parameter aiis updated by, after the nthbatch of 100 iterations, considering<br />the fraction of acceptances of those proposals which originated from Xi. If that fraction is<br />less than 0.234 then aiis decreased by δ(n), while if it is more than aiis increased by δ(n).<br />Then, if ai&gt; M we set ai= M, while if ai&lt; −M we set ai= −M. Finally, if there were<br />no proposals from Xiduring the entire batch, then aiis left unchanged. Thus the algorithm<br />attempts to minimise?m<br />in the region Xi.<br />Provided that δ(n) → 0, condition (1) will trivially hold. Moreover, if we assume that<br />M &lt; ∞ then it is natural to demonstrate (2) again by using a simultaneous drift condi-<br />tion. Such an argument will require some conditions on the target density, but is easy to<br />demonstrate for log-concave densities such as the example below. See Section 8 for further<br />discussion.<br />i=1acc2<br />iwhere accirepresents the acceptance rate for moves starting<br />For a first example, we let X = Rd, and π(·) = N(0, Id). We consider proposal kernels<br />of the form<br />Qa,b(x,·) = N<br />Once every 100 iterations, we update a by adding or subtracting δ(n) to make the acceptance<br />rate in the region {?x?2≤ d} as close as possible to 0.234. We also add or subtract δ(n) to b<br />to make the acceptance rate in the region {?x? &gt; d} as close as possible to 0.234. We again<br />restrict a and b to some [−M,M]. (We take δ(n) = min(0.01, n−1/2) ≡ 0.01 and M = 100.)<br />We choose dimension d = 10, and begin with a = b = 0.<br />?<br />x, e2a1?x?2≤d+ e2b1?x?2&gt;d<br />?<br />.<br />16</p>  <p>Page 17</p> <p>0e+004e+04 8e+04<br />−0.4<br />−0.3<br />−0.2<br />−0.1<br />0.0<br />Figure 13.<br />against batch number.<br />The tuning parameter a in the Normal RAMA example, plotted<br />How well does it work? The tuning parameters a and b quickly migrate towards their<br />“good” values of −0.3 and −0.13, respectively, but they continue to oscillate somewhat<br />around these values (Figures 13 and 14).<br />How good are the values of a and b found by the computer? The following table gives<br />comparisons of the integrated autocorrelation time and average squared jumping distance<br />for various choices of a and b:<br />a, b ACT<br />15.54<br />15.07<br />15.44<br />17.04<br />17.037<br />Avr Sq Dist<br />0.1246<br />0.1258<br />0.1213<br />0.1118<br />0.1100<br />adaptive (as above)<br />−0.3, −0.13<br />−0.3, 0.0<br />0.0, −0.13<br />0.0, 0.0<br />The table indicates that the adaptive algorithm (top line) is quite competitive with the<br />corresponding fixed-parameter choice (second line), which in turn has smaller integrated<br />autocorrelation time, and larger average squared jumping distance, than any of the other<br />choices of a and b. This indicates that the computer has again succeeded in finding good<br />values for the tuning parameters.<br />Next, we consider the following statistical model related to James-Stein estimators, as<br />17</p>  <p>Page 18</p> <p>0e+004e+04 8e+04<br />−0.20<br />−0.10<br />0.00<br />Figure 14.<br />against batch number.<br />The tuning parameter b in the Normal RAMA example, plotted<br />studied in e.g. Rosenthal (1996):<br />µ<br />↓??<br />θ1 ...<br />↓ ...<br />Y1 ...<br />... θK<br />...<br />... YK<br />θi∼ N(µ,A) [1 ≤ i ≤ K]<br />↓<br />Yi∼ N(θi,V )[1 ≤ i ≤ K]<br />Here the {Yi} are observed data. We use the prior distributions µ ∼ N(µ0,σ2<br />IG(a1,b1), and replace V by its (fixed) empirical Bayes estimate. We let π(·) be the resulting<br />posterior distribution for (A,µ,θ1,...,θK), on the (K + 2)-dimensional state space X =<br />[0,∞) × RK+1. The density of π(·), with respect to Lebesgue measure, is then given by<br />0) and A ∼<br />f(A,µ,θ1,...,θK) = N(µ0,σ2<br />0;µ) IG(a1,b1;A) ×<br />K<br />?<br />i=1<br />?<br />N(µ,A;θi) N(θi,V ;Yi)<br />?<br />∝ exp(−(µ − µ0)2/2σ2<br />0) exp(−b1/A)/Aa1+1×<br />×<br />K<br />?<br />i=1<br />?<br />A−1/2exp(−(θi− µ)2/2A) V−1/2exp(−(Yi− θi)2/2V )<br />?<br />.<br />For a numerical example, we let K = 18, and let Y1,...,Y18be the (real) baseball data<br />of Table 1 of Morris (1983) (see also Efron and Morris, 1975). Thus, X ⊆ R20. We choose<br />the prior parameters as µ0= 0, σ2<br />0= 1, a1= −1, and b1= 2.<br />18</p>  <p>Page 19</p> <p>0e+004e+04 8e+04<br />−3.4<br />−3.3<br />−3.2<br />−3.1<br />−3.0<br />Figure 15. The tuning parameter a in the James-Stein RAMA example, plotted<br />against batch number.<br />We again perform the RAMA algorithm. Specifically, after the nthbatch of 100 iterations,<br />we update a by adding or subtracting δ(n) to make the acceptance rate in the region {?<br />µ0)2≤ 0.15} as close as possible to 0.234. We also add or subtract δ(n) to b to make the<br />acceptance rate in the region {?<br />The simulations again show good mixing, and rapid convergence of functional averages<br />to their true posterior means. Furthermore, the adaptive parameters a and b quickly settle<br />down to near −3.3 and −3.2 respectively (Figures 15, 16).<br />How good are the values of the tuning parameters chosen? We again compare integrated<br />autocorrelation times and average squared jumping distances, as follows (acceptance rates<br />are also shown):<br />i(θ1−<br />i(θ1− µ0)2&gt; 0.15} as close as possible to 0.234.<br />a, bAcc Rate<br />0.228<br />0.194<br />0.003<br />0.655<br />0.647<br />0.281<br />2.5 ×10−5<br />ACT<br />31.60<br />25.75<br />50.67<br />38.92<br />36.91<br />38.04<br />53.97<br />Avr Sq Dist ×104<br />2.756<br />2.793<br />0.192<br />1.168<br />1.153<br />2.407<br />0.010<br />adaptive (as above)<br />−3.3, −3.2<br />−2.3, −2.3<br />−4.3, −4.3<br />−3.3, −4.3<br />−4.3, −3.3<br />−0.6, −0.6<br />19</p>  <p>Page 20</p> <p>0e+004e+04 8e+04<br />−3.35 −3.25 −3.15 −3.05<br />Figure 16. The tuning parameter b in the James-Stein RAMA example, plotted<br />against batch number.<br />We again see that the adaptive algorithm (top line) is quite competitive with the corre-<br />sponding fixed-parameter choice (second line), which in turn is better than any of the other<br />choices of a and b. This shows that, once again, the adaptive algorithm has automatically<br />chosen good values of the MCMC tuning parameters, without requiring user intervention.<br />Remarks.<br />1. In our simulations, the condition M &lt; ∞ has never been necessary, since RAMA has<br />never tried to push any of the {aj} towards unbounded values. Indeed, we conjecture<br />that under appropriate regularity assumptions (e.g. if the densities are jointly continu-<br />ous), condition (2) will be satisfied automatically due to drifting of the parameters ai<br />back to reasonable values due to the adaptive process (cf. Roberts and Rosenthal, 2005,<br />Corollary 14).<br />2. If some value ajis much too large, then α(x,y) may be very small for all y ∈ Xjand x ?∈<br />Xj. This means that the region Xjmay virtually never be entered, so that ajwill remain<br />virtually constant, leading to isolation of Xjand thus very poor convergence. Hence, it is<br />important with RAMA to begin with sufficiently small values of the {ai}. Alternatively,<br />it might be wise to decrease each aislightly (rather than leaving it unchanged) after each<br />batch in which there were no proposals from Xi.<br />3. The version of RAMA presented here requires that the user specify the regions {Xi}m<br />i=1<br />20</p>  <p>Page 21</p> <p>by hand. However, it may also be possible to have the computer automatically select<br />appropriate regions, by e.g. doing a preliminary run with fixed proposal variance, and<br />then grouping together state space subsets which appear to have similar acceptance rates.<br />4. Roberts et al. (1997) show that in certain situations the optimal scaling for Metropolis<br />algorithms can be characterised as that which has acceptance probability 0.234. One<br />can ask whether these results carry over to RAMA, and whether equal acceptance rates<br />on different regions (as sought by RAMA) truly leads to optimality. We believe this<br />to be true quite generally, but can only prove it for very specific settings (e.g. birth-<br />death processes). The method of proof of Roberts et al. (see also B´ edard, 2006a, 2006b)<br />appears to carry over away from the region boundaries, but the behaviour at the region<br />boundaries is more complicated.<br />5. If we set δ(n) to a constant, as opposed to having δ(n) → 0, then condition 1 might fail,<br />so the chain might not converge to π(·). On the other hand, the chain together with the<br />parameter values {aj} is jointly Markovian, and under appropriate scaling may have its<br />own joint diffusion limit. It would be interesting (Stewart, 2006) to study that diffusion<br />limit, to e.g. see how much asymptotic error results from failing to satisfy (1).<br />6. To Log or Not To Log.<br />Suppose π is the density function for a real-valued random variable W. Then if π is<br />heavy-tailed, it may be advantageous to take logarithms, i.e. to instead consider the density<br />function for?<br />in place of W? Once again, adaptive algorithms can provide insights into this question.<br />To avoid problems of negative or near-negative values, we modify the logarithm function<br />and instead consider the function<br />W ≡ logW. This leads to the question, when is it advantageous to consider?<br />W<br />?(w) ≡ sgn(w) log(1 + |w|),<br />where sgn(w) = 1 for w &gt; 0, and sgn(w) = −1 for w &lt; 0. The function ? is an increasing,<br />continuously differentiable mapping from R onto R, with inverse ?−1(w) = sgn(w)(e|w|−1),<br />and graph as follows:<br />21</p>  <p>Page 22</p> <p>−10−50510<br />−4<br />−2<br />0<br />2<br />4<br /> <br /> <br />Figure 17. Graph of the modified log function ?.<br />If π is the density for W, and?<br />A result of Mengersen and Tweedie (1996) says, essentially, that a random-walk Met-<br />ropolis (RWM) algorithm for a density π will be geometrically ergodic if and only if π has<br />exponential or sub-exponential tails, i.e. satisfies<br />W = log(W), then taking Jacobians shows that the density<br />W is given by ˜ π(w) = e|w|π(e|w|− 1).for?<br />logπ(x) − logπ(y) ≥ η(y − x), y &gt; x ≥ x1<br />(5)<br />for some x1 &gt; 0 and η &gt; 0 (and similarly for y &lt; x ≤ −x1). (A similar result holds in<br />multi-dimensional contexts , cf. Roberts and Tweedie, 1996.) But if π on R satisfies (5),<br />then so does ˜ π, since if y &gt; x ≥ −log(η) + β ≥ x1&gt; 0, then<br />log ˜ π(x) − log ˜ π(y) = (x − y) + logπ(ex− 1) − logπ(ey− 1)<br />≥ (x − y) + η((ey− 1) − (ex− 1)) = −(y − x) + ηex(ey−x− 1)<br />≥ −(y − x) + ηx(y − x) = (y − x)(ηex− 1) ≥ (y − x)(eβ− 1).<br />Hence, (5) is satisfied for ˜ π with ˜ η = eβ− 1. In fact, by making β arbitrarily large, we can<br />make ˜ η as large as we like, showing that the tails of ˜ π are in fact sub-exponential.<br />This suggests that, at least as far as geometric ergodicity is concerned, it is essentially<br />always better to work with ˜ π than with π. As a specific example, if π is the standard Cauchy<br />distribution, then RWM on π is not geometrically ergodic, but RWM on ˜ π is.<br />22</p>  <p>Page 23</p> <p>Despite this evidence in favour of log transforms for RWM, it is not clear that taking<br />logarithms (or applying ?) necessarily helps with the quantitative convergence of RWM. To<br />investigate this, we use an adaptive algorithm.<br />Specifically, given π, we consider two different algorithms: one a RWM on π, and the<br />other a RWM on ˜ π, each using proposal distributions of the form Q(x,·) = N(x,σ2). After<br />the nthbatch of 100 iterations, we allow each version to adapt its own scaling parameter σ<br />by adding or subtracting δ(n) to log(σ), in an effort to achieve acceptance rate near 0.44 for<br />each version. Then, once every 100 batches, we consider whether to switch versions (i.e., to<br />apply ? if we currently haven’t, or to undo ? if we currently have), based on whether the<br />current average squared jumping distance is smaller than that from the last time we used<br />the other version. (We force the switch to the other version if it fails 100 times in succession,<br />to avoid getting stuck forever with just one version.)<br />How does this adaptive algorithm work in practice? In the following table we considered<br />three different one-dimensional symmetric target distributions: a standard Normal, a stan-<br />dard Cauchy, and a Uniform[−100,100]. For each target, we report the percentage of the<br />time that the adaptive algorithm spent on the logged density ˜ π (as opposed to the regular<br />density π). We also report the mean value of the log proposal standard deviation for both<br />the regular and the logged RWM versions.<br />Target<br />Normal<br />Cauchy<br />Uniform<br />Log %<br />3.62%<br />99.0%<br />4.95%<br />lsreg<br />2.52<br />3.49<br />6.66<br />lslog<br />2.08<br />2.66<br />2.65<br />We see from this table that, for the Normal and Uniform distributions, the adaptive<br />algorithm saw no particular advantage to taking logarithms, and indeed stayed in the regular<br />(unlogged) π version the vast majority of the time. On the other hand, for the Cauchy target,<br />the algorithm uses the logged ˜ π essentially as much as possible. This shows that this adaptive<br />algorithm is able to distinguish between when taking logs is helpful (e.g. for the heavy-tailed<br />Cauchy target), and when it is not (e.g. for the light-tailed Normal and Uniform targets).<br />For multi-dimensional target distributions, it is possible to take logs (or apply the func-<br />tion ?) separately to each coordinate. Since lighter tails are still advantageous in multi-<br />dimensional settings (Roberts and Tweedie, 1996), it seems likely to be advantageous to<br />apply ? to precisely those coordinates which correspond to heavy tails in the target distribu-<br />tion. In high dimensions, this cannot feasibly be done by hand, but an adaptive algorithm<br />23</p>  <p>Page 24</p> <p>could still do it automatically. Such multi-dimensional versions of this adaptive logarithm<br />algorithm appear worthy of further investigation.<br />7. How to adapt.<br />Whilst the theory of adaptation has progressed significantly in recent years, practical<br />implementation raises many important and largely unstudied problems. One issue is that<br />we still know very little about how to optimise MCMC algorithms. The use of monitored<br />acceptance probabilities has the appeal of simplicity and the support of some theory. In 1-<br />dimension the use of 0.44 and in higher-dimensional problems the adoption of 0.234 together<br />with the scaling rule σ = 2.38/d1/2are based on results in Gelman et al (1996). However<br />the use of these simple rules, although often effective, are based on approximations and are<br />not rigorously proved for complex non-homogeneous models used in statistical analysis. In<br />our two heterogeneous scaling examples, we are guided by established theoretical properties<br />of MCMC - particularly that Metropolis algorithms are not geometrically ergodic for heavy<br />tailed target densities. We believe that there is considerable further scope for algorithm<br />development based on MCMC theory.<br />One important question asks whether an effective adaptive scheme should require that<br />Γ converges. It is intuitively appealing to think of the adaptive scheme searching for ”the<br />best” algorithm from a collection of candidates. Our approach here is, however, not to<br />require convergence of Γ since we are eager to have adaptive procedures which work in as<br />general a context as possible. It may well be (and we suspect so) that all the examples in this<br />paper involve situations where Γndoes converge, but we have not attempted to demonstrate<br />this. A complementary approach to our work in this respect is that adopted by Andrieu<br />and Moulines (2003). This has the appeal of generality, but it may be that an algorithm in<br />which we do not have convergence of Γnconverges less rapidly than one in which Γndoes<br />converge. More experience with practical examples is necessary to resolve these issues.<br />AM and RAMA are set up naturally in a multi-dimensional context. Multivariate gener-<br />alisations of the state-dependent strategy used in Section 4 are clearly possible. The simplest<br />idea is to apply the same strategy to each of the d components, obtaining a collection of<br />parameters, (a1,b1)...(ad,bd) defining a proposal of independent components with variance<br />in the ith direction given by ea(1 + |xi|)b. More complex proposals which try to respect the<br />dependence in the target density (as in AM) are also possible.<br />24</p>  <p>Page 25</p> <p>8. Checking the Bounded Convergence condition.<br />The Diminishing Adaptation condition is relatively easy to check, and in fact adaptive<br />procedures are generally constructed with this condition directly in mind. On the other<br />hand, the Bounded Convergence condition is typically more difficult to check.<br />One way of showing this is to show that all MCMC kernels satisfy the same Lyapunov<br />drift condition. For instance, Roberts and Rosenthal (2005) show that an adaptive MCMC<br />algorithm satisfying Diminishing Adaptation satisfies Bounded Convergence (and is hence<br />ergodic) if the family {Pγ}γ∈Ysimultaneously strongly aperiodically geometrically ergodic, ie<br />there is C ∈ F, V : X → [1,∞), δ &gt; 0, λ &lt; 1, and b &lt; ∞, such that supCV = v &lt; ∞, and<br />(i) for each γ ∈ Y, there exists a probability measure νγ(·) on C with Pγ(x,·) ≥ δ νγ(·) for<br />all x ∈ C; and<br />(ii) (Pγ)V ≤ λV + b1C.<br />A natural approach to the establishment of simultaneously strongly aperiodically geomet-<br />rically ergodicity is to use the drift function π−1/2as in Roberts and Tweedie (1996) for AM<br />and Roberts and Rosenthal (1997) for Adaptive Metropolis-within-Gibbs. As an example of<br />a precise result which can be shown in this way, for the AM algorithm, the condition will<br />hold by this argument for all target densities which are log-concave (except perhaps on some<br />bounded region).<br />The state-dependent proposal variance case can also be analysed to give a drift condition<br />with Lyapunov function π−1/2, at least for b &lt; 2. This is essentially because asymptotically<br />(as |x| → ∞) the accept/reject ratio is dominated by the ratio π(y)/π(x) and thus all moves<br />to smaller |x| values are accepted with all moves to larger π(x) values are possibly rejected.<br />Then standard calculation as those in Roberts and Tweedie (1996), together with continuity<br />and compactness arguments for the parameters a and b are sufficient to demonstrate the<br />simultaneous drift condition.<br />It seems that these results will be easily generalisable to the other examples in this paper,<br />essentially because all methods are essentially constructed from random walk Metropolis.<br />These extensions are subject to further work (Bai, Roberts, and Rosenthal, 2008).<br />9. Conclusion.<br />This paper has considered automated tuning of MCMC algorithms, especially Metropolis-<br />Hastings algorithms, with quite positive results.<br />For example, for Metropolis-within-Gibbs algorithms, the following (generally well-known)<br />statements are all reinforced through our simulation. (1) The choice of proposal variance<br />25</p>  <p>Page 26</p> <p>σ2is crucial to the success of the algorithm. (2) Good values of σ2can vary greatly from<br />one coordinate to the next. (3) There are far too many coordinates to be able to select<br />good values of σ2for each coordinate by hand. (4) Adaptive methods can be used to get the<br />computer to find good values of σ2automatically. (5) If done carefully, the adaptive methods<br />can be provably ergodic, and quite effective in practice, thus allowing for good tuning and<br />rapid convergence of MCMC algorithms that would otherwise be impractical.<br />The practical experience of this paper, though very promising, also raises important<br />questions. In particular, how robust are the strategies suggested in the various methods<br />here? For example, in the adaptive Metropolis-within-Gibbs example, how crucial is the<br />choice of δ(n) in the success of the method, and how does this vary from problem to problem?<br />We still know comparatively little about what adaptive strategies to use in any particular<br />context. Our feeling is that the choice of adaptive strategy should be guided by theoretical<br />knowledge about MCMC. For instance, when using RWM, particular problems are observed<br />with heavy-tailed target distributions (such as lack of geometric ergodicity, breakdown of<br />CLTs etc). In this case it makes sense to use a strategy which attempts to stabilise the<br />algorithm excursions, and this points to the use of heterogeneous scaling and/or a strategy<br />which lightens the tails (such as that introduced in Section 6).<br />One important issue for adaptive scaling concerns the practical issue that scaling the<br />proposal correlation structure to match that of the target will be a very poor strategy<br />when some of the target distribution variances are infinite. Typically in practical MCMC<br />situations, this may not be very easy to check analytically by inspection of the target density.<br />For this reason, perhaps it makes more sense to scale according to acceptance rate criteria<br />rather than variances. However it is impossible to use this to match correlation structure,<br />and further work is required to introduce robust versions of the AM and other methods.<br />Adaptive strategies are generally simple to implement. However it is very important<br />that such a strategy is constructed in such a way that the conditions for ergodicity are<br />satisfied. Further work is clearly required to give sufficiently simple conditions to enable<br />routine adaptation to take place in applied problems. In terms of adaptive strategies, there is<br />now extensive MCMC theory to help guide the construction of suitable adaptive algorithms.<br />One potential problem evolves from an adaptive strategy which is too “greedy” in that it<br />tries to adapt too closely to initial information from the output. Such algorithms can take<br />considerable time to “recover” from misleading initial information.<br />Overall, we feel that these results indicate the widespread applicability of adaptive<br />MCMC algorithms to many different MCMC settings, including complicated high-dimensional<br />distributions. We hope that this paper will inspire users of MCMC to experiment with adap-<br />26</p>  <p>Page 27</p> <p>tive algorithms in their future applications (e.g. Turro et al., 2007). All of the software used<br />to run the algorithms described herein is freely available at probability.ca/adapt.<br />Acknowledgements.<br />thank the editors and referees for many constructive comments that greatly improved the<br />paper.<br />We thank Sylvia Richardson for a very helpful suggestion, and<br />REFERENCES<br />C. Andrieu and Y.F. Atchad´ e (2005), On the efficiency of adaptive MCMC algorithms.<br />Preprint.<br />C. Andrieu and E. Moulines (2003), On the ergodicity properties of some adaptive Markov<br />Chain Monte Carlo algorithms. Preprint.<br />Y.F. Atchad´ e and J.S. Rosenthal (2005), On Adaptive Markov Chain Monte Carlo Algo-<br />rithms. Bernoulli 11, 815–828.<br />Y. Bai, G.O. Roberts, and J.S. Rosenthal (2008), On the containment condition for adaptive<br />Markov chain Monte Carlo algorithms. Preprint.<br />M. B´ edard (2006a), Weak convergence of Metropolis algorithms for non-iid target distribu-<br />tions. Preprint.<br />M. B´ edard (2006b), Optimal acceptance rates for Metropolis algorithms: moving beyond<br />0.234. Preprint.<br />A.E. Brockwell and J.B. Kadane (2005), Identification of regeneration times in MCMC sim-<br />ulation, with application to adaptive schemes. J. Comp. Graph. Stat. 14, 436–458.<br />B. Efron and C. Morris (1975), Data analysis using Stein’s estimator and its generalizations.<br />J. Amer. Stat. Assoc., Vol. 70, No. 350, 311-319.<br />A.E. Gelfand and A.F.M. Smith (1990), Sampling based approaches to calculating marginal<br />densities. J. Amer. Stat. Assoc. 85, 398-409.<br />W.R. Gilks, G.O. Roberts, and S.K. Sahu (1998), Adaptive Markov Chain Monte Carlo. J.<br />Amer. Stat. Assoc. 93, 1045–1054.<br />H. Haario, E. Saksman, and J. Tamminen (1999). Adaptive proposal distribution for random<br />walk Metropolis algorithm. Comput. Stat. 14 375-395.<br />H. Haario, E. Saksman, and J. Tamminen (2001), An adaptive Metropolis algorithm. Bernoulli<br />7, 223–242.<br />H. Haario, E. Saksman, and J. Tamminen (2005), Componentwise adaptation for high di-<br />mensional MCMC. Comput. Stat. 20, 265–274.<br />27</p>  <p>Page 28</p> <p>W.K. Hastings (1970), Monte Carlo sampling methods using Markov chains and their appli-<br />cations. Biometrika 57, 97–109.<br />K.L. Mengersen and R.L. Tweedie (1996), Rates of convergence of the Hastings and Metro-<br />polis algorithms. Ann. Statist. 24, 101–121.<br />N. Metropolis, A. Rosenbluth, M. Rosenbluth, A. Teller, and E. Teller (1953), Equations of<br />state calculations by fast computing machines. J. Chem. Phys. 21, 1087–1091.<br />C. Morris (1983), Parametric empirical Bayes confidence intervals. Scientific Inference, Data<br />Analysis, and Robustness, 25-50.<br />G.O. Roberts, A. Gelman, and W.R. Gilks (1997), Weak convergence and optimal scaling of<br />random walk Metropolis algorithms. Ann. Appl. Prob. 7, 110–120.<br />G.O. Roberts and J.S. Rosenthal (1998), Optimal scaling of discrete approximations to<br />Langevin diffusions. J. Roy. Stat. Soc. B 60, 255–268.<br />G.O. Roberts and J.S. Rosenthal (2001), Optimal scaling for various Metropolis-Hastings<br />algorithms. Stat. Sci. 16, 351–367.<br />G.O. Roberts and J.S. Rosenthal (2005), Coupling and Ergodicity of Adaptive MCMC.<br />Preprint.<br />G.O. Roberts and R.L. Tweedie (1996), Geometric Convergence and Central Limit Theorems<br />for Multidimensional Hastings and Metropolis Algorithms. Biometrika 83, 95–110.<br />J.S. Rosenthal (1996), Analysis of the Gibbs sampler for a model related to James-Stein<br />estimators. Stat. and Comp. 6, 269–275.<br />J.S. Rosenthal (2004), Adaptive MCMC Java Applet. Available at:<br />http://probability.ca/jeff/java/adapt.html<br />A. Stewart (2006), Personal communication.<br />L. Tierney (1994), Markov chains for exploring posterior distributions (with discussion).<br />Ann. Stat. 22, 1701–1762.<br />E. Turro, N. Bochkina, A.M.K. Hein, and S. Richardson (2007), BGX: a Bioconductor pack-<br />age for the Bayesian integrated analysis of Affymetrix GeneChips. BMC Bioinformatics 8,<br />439–448. Available at: http://www.biomedcentral.com/1471-2105/8/439<br />28</p>   </div> <div id="rgw18_56aba281167b0" class="c-box pub-resource-container js-toggle" style=""> <h4 class="lf js-expand-list"><small><a href="javascript:" class="lf">View other sources <span class="ico-expand-list"></span></a></small></h4> <h4 class="lf js-collapse-list hidden"><small><a href="javascript:" class="lf">Hide other sources <span class="ico-collapse-list"></span></a></small></h4> <div class="clear"></div> <div class="scroll-wrapper hidden"> <ul class="files-list c-list" id="rgw19_56aba281167b0">  <li class="c-list-item pub-resource-item"  data-type="fulltext" id="rgw20_56aba281167b0"> <span class="ico-pub"></span> <div class="file-content"> <div class="download"> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.151.4452&amp;amp;rep=rep1&amp;amp;type=pdf" target="_blank" rel="nofollow" class="publication-viewer" title="Examples of adaptive MCMC">Examples of adaptive MCMC</a> </div>  <div class="details">   Available from <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.151.4452&amp;amp;rep=rep1&amp;amp;type=pdf" target="_blank" rel="nofollow">psu.edu</a>  </div>    </div> </li>  </ul> </div> </div> </noscript> <div class="clearfix"> <div class="action-container">  </div> <div class="pub-legal"> Data provided are for informational purposes only. Although carefully collected, accuracy cannot be guaranteed. The impact factor represents a rough estimation of the journal's impact factor and does not reflect the actual current impact factor. Publisher conditions are provided by RoMEO. Differing provisions from the publisher's actual policy or licence agreement may be applicable. </div>   </div> </div> <div class="clearfix">     <div id="rgw22_56aba281167b0" class="c-box pub-resource-container js-toggle" style="display: none;"> <h4 class="lf js-expand-list"><small><a href="javascript:" class="lf">View other sources <span class="ico-expand-list"></span></a></small></h4> <h4 class="lf js-collapse-list hidden"><small><a href="javascript:" class="lf">Hide other sources <span class="ico-collapse-list"></span></a></small></h4> <div class="clear"></div> <div class="scroll-wrapper hidden"> <ul class="files-list c-list" id="rgw23_56aba281167b0">  </ul> </div> </div>   <div id="rgw14_56aba281167b0" class="similar-publications"> <h2>Similar Publications</h2> <ul class="list-bordered">  <li class="c-list-item li-publication-teaser" id="rgw15_56aba281167b0"> <div> <h5> <a href="publication/277575740_Smoothness_of_marginal_log-linear_parameterizations" class="color-inherit ga-similar-publication-title"><span class="publication-title">Smoothness of marginal log-linear parameterizations</span></a>  </h5>  <div class="authors"> <a href="researcher/59314167_Robin_J_Evans" class="authors ga-similar-publication-author">Robin J. Evans</a>  </div>  </div> <div class="clear"></div> </li>  <li class="c-list-item li-publication-teaser" id="rgw16_56aba281167b0"> <div> <h5> <a href="publication/283813602_Bayesian_models_A_statistical_primer_for_ecologists" class="color-inherit ga-similar-publication-title"><span class="publication-title">Bayesian models: A statistical primer for ecologists</span></a>  </h5>  <div class="authors"> <a href="researcher/48346895_NT_Hobbs" class="authors ga-similar-publication-author">N.T. Hobbs</a>, <a href="researcher/48097951_MB_Hooten" class="authors ga-similar-publication-author">M.B. Hooten</a>  </div>  </div> <div class="clear"></div> </li>  <li class="c-list-item li-publication-teaser" id="rgw17_56aba281167b0"> <div> <h5> <a href="publication/276248234_Analysis_of_proteomics_data_Bayesian_alignment_of_functions" class="color-inherit ga-similar-publication-title"><span class="publication-title">Analysis of proteomics data: Bayesian alignment of functions</span></a>  </h5>  <div class="authors"> <a href="researcher/2035835650_Wen_Cheng" class="authors ga-similar-publication-author">Wen Cheng</a>, <a href="researcher/45507941_Ian_L_Dryden" class="authors ga-similar-publication-author">Ian L. Dryden</a>, <a href="researcher/14235310_David_B_Hitchcock" class="authors ga-similar-publication-author">David B. Hitchcock</a>, <a href="researcher/13317304_Huiling_Le" class="authors ga-similar-publication-author">Huiling Le</a>  </div>  </div> <div class="clear"></div> </li>  </ul> </div> </div> </div> </div> </div></div></div>
<div class="clear"></div><div id="rgw28_56aba281167b0" class="default-footer"> <div id="footer" class="clearfix"> <span class="footer-left"> &copy; 2008&dash;2016 researchgate.net. All rights reserved. </span> <span class="footer-right"> <a href="https://www.researchgate.net/about">About us</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="https://www.researchgate.net/contact">Contact us</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="careers">Careers</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="developers">Developers</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="blog" target="_blank">News</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="application.PrivacyPolicy.html">Privacy</a><span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="application.TermsAndConditions.html">Terms</a> <span class="footer-link-separator" style="padding: 0 5px;">&nbsp;|&nbsp;</span> <a href="advertising?_ref=ft">Advertising</a> <span class="footer-link-separator">&nbsp;&middot;&nbsp;</span> <a href="recruiters?_ref=ft">Recruiting</a> </span> </div>  </div></div>
<div id="rgw29_56aba281167b0">  <div class="header-wrapper-logged-out"> <div id="header"> <div class="header-content"> <a href="" class="g-l-logo"> <svg width="149" height="19"> <image xlink:href="https://c5.rgstatic.net/m/235107188705592/images/template/brand-header-logo.svg" src="https://c5.rgstatic.net/m/238113351022438/images/template/brand-header-logo.png" width="149" height="19"/> </svg> </a> <a href="" class="g-l-logo-ico"> <svg width="127" height="17" viewbox="0 0 127 22"> <image xlink:href="https://c5.rgstatic.net/m/235107188705592/images/template/brand-header-logo.svg" src="https://c5.rgstatic.net/m/238113351022438/images/template/brand-header-logo.png" width="127" height="17"/> </svg> </a> <div id="rgw30_56aba281167b0" class="header-login-wrapper js-header-login"> <div class="dropdown-right-align"> <div class="login-signup-container lf"> <a href="https://www.researchgate.net/signup.SignUp.html?ev=su_chnl_index&amp;hdrsu=1&amp;_sg=SEiqNWWrSxzFjL-WD6xWZGLbwKcm6GKDLo-G-9qgCJdHXYjmjA2qhmRA1rTvzkCu" class="dropdown-toggle lf">Join for free</a> </div> <div class="dropdown lf" style="height: 20px;"> <a href="https://www.researchgate.net/application.Login.html" class="js-login-url dropdown-toggle lf">Log in <span class="caret"></span></a> <div class="dropdown-menu"> <div class="header-login-form-wrapper"> <!--[if IE 6]><p class="box-warning" style="margin-bottom: 0;">Sorry, ResearchGate no longer supports the version of Internet Explorer you are using. <a href="http://whatbrowser.org/" rel="nofollow" target="_blank">Update your web browser</a> and then log in. </p><![endif]--> <form method="post" action="https://www.researchgate.net/application.Login.html" class="form-big header-login-form js-login-form" name="loginForm" id="headerLoginForm"> <input type="hidden" name="request_token" value="OUWFZHTHWPGA7SWyRkZCE+H96EnlvVsufRNAqXMQ3tP9y3PuzL99C9IUsi/OutK8XTkhAf3aIP7DyqvpAFRBPv11O8OmGNzfWWZr5AuWbSS4Lm0kNMXOCCMg9DXciijCK0Q0+yEqcu3YIIAO8NikP8gb4pFhZJy5G7o2E7mhkMt+goa5ISbU09Lw60ZzPx4LdzToxvtiDNe8yZ5Z0ZqQZrNyqXfYtmG8ZmQ+DoWbjkAQhhDu2ZTFJykQy9L2bfXONfe1cuBBrAHjlvp0p7LntKHA1Bzcr29e6v/OCss+M3U="/> <input type="hidden" name="urlAfterLogin" value="publication/228789130_Examples_of_adaptive_MCMC"/> <input type="hidden" name="invalidPasswordCount" value="0"/> <input type="hidden" name="headerLogin" value="yes"/> <label for="input-header-login">Email</label> <div class="login-input"> <div class="info-tip-wrapper"> <span class="ico-info js-info"></span> </div> <input type="email" value="" name="login" class="login js-login-input text" id="input-header-login" tabindex="1"/> </div> <div class="clear"></div> <label class="lf" for="input-header-password"> Password </label> <a class="rf forgot-password js-forgot-password" href="application.LostPassword.html">Forgot password?</a> <div class="clear"></div> <input type="password" value="" name="password" class="password js-password-input text" id="input-header-password" tabindex="2"/> <div class="clear"></div> <label class="remember-me" for="headerLoginCookie"> <input type="checkbox" checked="checked" value="yes" name="setLoginCookie" class="lf checkbox" id="headerLoginCookie" tabindex="3"/> Keep me logged in </label> <div class="clear"></div> <input value="Log in" name="loginSubmit" class="btn btn-promote btn-fullwidth btn-large allow-leave js-submit-button" type="submit" tabindex="4"/> </form> <div class="connectors"> <div class="text">or log in with</div> <div class="connector-actions"> <a href="connector/linkedin/" class="li-connect js-li-connect" data-redirect-url="cHVibGljYXRpb24vMjI4Nzg5MTMwX0V4YW1wbGVzX29mX2FkYXB0aXZlX01DTUM%3D"> <span class="icon ico-linkedin-round-grey"></span> <span class="icon ico-linkedin-round"></span> </a> <a href="connector/facebook/" class="fb-connect middle js-fb-connect" data-redirect-url="cHVibGljYXRpb24vMjI4Nzg5MTMwX0V4YW1wbGVzX29mX2FkYXB0aXZlX01DTUM%3D"> <span class="icon ico-facebook-round-grey"></span> <span class="icon ico-facebook-round"></span> </a> <a href="connector/google/" class="g-connect js-g-connect" data-redirect-url="cHVibGljYXRpb24vMjI4Nzg5MTMwX0V4YW1wbGVzX29mX2FkYXB0aXZlX01DTUM%3D"> <span class="icon ico-google-round-grey"></span> <span class="icon ico-google-round"></span> </a> </div> </div> </div> </div> </div> </div> </div> </div> </div> <script type="application/ld+json">
{ "@context" : "http://schema.org",
  "@type" : "Organization",
  "name" : "ResearchGate",
  "url" : "http://www.researchgate.net",
  "logo" : "http://www.researchgate.net/images/template/rg_logo_square_brand.png",
  "sameAs" : [ "https://www.facebook.com/ResearchGate",
    "https://twitter.com/ResearchGate",
    "https://plus.google.com/+researchgate",
    "https://www.linkedin.com/company/researchgate"] 
}
</script> </div> </div><div class="c-signup-bar" id="rgw31_56aba281167b0"> <div class="banner-contents">   <span class="message">ResearchGate is the professional network for scientists and researchers.</span> <a href="signup.SignUp.html?ev=su_banner" class="btn btn-large btn-promote">Join for free</a>  </div> </div></div>
<script>
rgConfig.backendTime = 432;
</script>
<script src="//c5.rgstatic.net/m/2277196935388619/javascript/lib/yui3/yui/yui-min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/21832295316281274/javascript/yuiLoaderConfig-min.js" type="text/javascript"></script>
        <script src="//c5.rgstatic.net/m/23178613132105398/javascript/vendor/babel-core/browser-polyfill.min.js" type="text/javascript"></script>
<script>
(function (){
if (typeof YRG === "undefined") {
var xmlHttpRequest = new XMLHttpRequest();
xmlHttpRequest.open("post", "go.Error.html");
xmlHttpRequest.setRequestHeader("Content-Type", "application/json");
xmlHttpRequest.setRequestHeader("Accept", "application/json"); var loadedScripts = "";
if (window.performance && window.performance.getEntriesByType) {
    var result = [];
    var resources = performance.getEntriesByType("resource");
    for (var i in resources) {
        if (resources.hasOwnProperty(i)) {
            result.push({
                name: resources[i].name,
                duration: resources[i].duration
            });
        }
    }
    loadedScripts += "&loadedScripts=" + encodeURIComponent(JSON.stringify(result));
}
if (typeof YUI === "undefined") {
    loadedScripts += "&yuiLoaded=false";
} else {
    loadedScripts += "&yuiLoaded=true";
}
xmlHttpRequest.send("Type=InformationException&message=" + encodeURIComponent("Error loading YUI") + loadedScripts);
}
})();
</script>
<script>if (typeof YRG !== 'undefined') { YRG.use('rg-base',function(Y){Y.applyConfig({ignore: ["css-rg","css-rg2","css-ie","css-modules-publicprofile"]});Y.use(["rg.core.pagespeed.Monitoring"],function(Y){(function(){Y.rg.createInitialWidget({"data":{"content":{"data":{"profileSmallHeader":{"data":{"profileBadge":{"data":{"fullname":"Jeffrey S. Rosenthal","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2671872220764\/images\/template\/default\/profile\/profile_default_m.jpg","profileStats":[],"profileFollowButton":null,"profileReputationScoreNumber":null,"profileUrl":"profile\/Jeffrey_Rosenthal","institution":"University of Toronto","institutionUrl":false,"widgetId":"rgw4_56aba281167b0"},"id":"rgw4_56aba281167b0","partials":[],"templateName":"publicprofile\/stubs\/ProfileBadge.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicprofile.ProfileBadge.html?accountId=1906625","viewClass":null,"yuiModules":["css-modules-publicprofile"],"stylesheets":["modules\/publicprofile.css"],"_isYUI":true},"widgetId":"rgw3_56aba281167b0"},"id":"rgw3_56aba281167b0","partials":[],"templateName":"publicprofile\/stubs\/ProfileSmallHeader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicprofile.ProfileSmallHeader.html?publicationUid=228789130","viewClass":null,"yuiModules":["css-modules-publicprofile"],"stylesheets":["modules\/publicprofile.css"],"_isYUI":true},"publication":{"data":{"publicationUid":228789130,"title":"Examples of adaptive MCMC","journalTitle":"Journal of Computational and Graphical Statistics","journalDetailsTooltip":{"data":{"journalTitle":"Journal of Computational and Graphical Statistics","journalAbbrev":"J COMPUT GRAPH STAT","publisher":"American Statistical Association; Institute of Mathematical Statistics; Interface Foundation of North America, Taylor & Francis","issn":"1061-8600","impactFactor":"1.22","fiveYearImpactFactor":"1.81","citedHalfLife":">10.0","immediacyIndex":"0.27","eigenFactor":"0.01","articleInfluence":"1.88","widgetId":"rgw6_56aba281167b0"},"id":"rgw6_56aba281167b0","partials":[],"templateName":"publicliterature\/stubs\/JournalInfo.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.JournalInfo.html?issn=1061-8600","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"affiliation":false,"type":"Article","details":{"doi":"10.1198\/jcgs.2009.06134","journalInfos":{"journal":"","publicationDate":"06\/2009;","publicationDateRobot":"2009-06","article":"18(2).","journalTitle":"Journal of Computational and Graphical Statistics","journalUrl":"journal\/1061-8600_Journal_of_Computational_and_Graphical_Statistics","impactFactor":1.22}},"source":false,"publicationActions":null,"publicationCoins":{"data":{"tags":[{"key":"ctx_ver","value":"Z39.88-2004"},{"key":"rft_val_fmt","value":"info:ofi\/fmt:kev:mtx:journal"},{"key":"rfr_id","value":"info:sid\/researchgate.net:researchgate"},{"key":"rft_id","value":"info:doi\/10.1198\/jcgs.2009.06134"},{"key":"rft.atitle","value":"Examples of adaptive MCMC"},{"key":"rft.title","value":"Journal of Computational and Graphical Statistics - J COMPUT GRAPH STAT"},{"key":"rft.jtitle","value":"Journal of Computational and Graphical Statistics - J COMPUT GRAPH STAT"},{"key":"rft.volume","value":"18"},{"key":"rft.issue","value":"2"},{"key":"rft.date","value":"2009"},{"key":"rft.issn","value":"1061-8600"},{"key":"rft.au","value":"Gareth O. Roberts,Jeffrey S. Rosenthal"},{"key":"rft.genre","value":"article"}],"widgetId":"rgw7_56aba281167b0"},"id":"rgw7_56aba281167b0","partials":[],"templateName":"publicliterature\/stubs\/PublicationCoins.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationCoins.html?publicationUid=228789130","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationAuthors":{"data":{"publicationUid":228789130,"peopleItems":[{"data":{"authorUrl":"researcher\/7075391_Gareth_O_Roberts","authorNameOnPublication":"Gareth O. Roberts","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg","imageSize":"s","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Gareth O. Roberts","profile":{"professionalInstitution":{"professionalInstitutionName":false,"professionalInstitutionUrl":null}},"professionalInstitutionName":false,"professionalInstitutionUrl":null,"url":"researcher\/7075391_Gareth_O_Roberts","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":true,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":false,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"widgetId":"rgw10_56aba281167b0"},"id":"rgw10_56aba281167b0","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAuthorItem.html?entityId=7075391&imageSize=l&enableAuthorInviteButton=0","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"largeTooltip":false,"useRebrandedImageStyle":null,"widgetId":"rgw9_56aba281167b0"},"id":"rgw9_56aba281167b0","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorItem.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorItem.html?authorUid=7075391&authorNameOnPublication=Gareth%20O.%20Roberts","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true},{"data":{"authorNameOnPublication":"Jeffrey S. Rosenthal","accountUrl":"profile\/Jeffrey_Rosenthal","accountKey":"Jeffrey_Rosenthal","imageUrl":"https:\/\/c5.rgstatic.net\/m\/2671872220764\/images\/template\/default\/profile\/profile_default_m.jpg","imageWidth":20,"imageHeight":20,"peopleItem":{"data":{"displayName":"Jeffrey S. Rosenthal","profile":{"professionalInstitution":{"professionalInstitutionName":"University of Toronto","professionalInstitutionUrl":"institution\/University_of_Toronto"}},"professionalInstitutionName":"University of Toronto","professionalInstitutionUrl":"institution\/University_of_Toronto","url":"profile\/Jeffrey_Rosenthal","imageUrl":"https:\/\/c5.rgstatic.net\/m\/237738464651637\/images\/template\/default\/profile\/profile_default_l.jpg","imageSize":"l","imageHeight":90,"imageWidth":90,"enableFollowButton":false,"enableHideButton":false,"enableConnectionButton":false,"followButton":null,"isClaimedAuthor":true,"hasExtraContainer":false,"showStatsWidgets":false,"statsWidgets":[],"additionalCssClasses":null,"contentWidgetsRight":[],"contentWidgetsMain":[],"showHideButton":false,"accountKey":"Jeffrey_Rosenthal","hasInfoPopup":false,"hasTeaserPopup":true,"showContactAuthorButton":true,"widgetId":"rgw12_56aba281167b0"},"id":"rgw12_56aba281167b0","partials":[],"templateName":"application\/stubs\/PeopleItem.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.PeopleAccountItem.html?entityId=1906625&enableUnfollow=0&imageSize=l&enableFollowButton=0&showContactAuthorButton=1","viewClass":"views.application.PeopleItemView","yuiModules":["rg.views.application.PeopleItemView"],"stylesheets":[],"_isYUI":true},"peopleItemRenderable":true,"accountInstitution":"University of Toronto","score":null,"largeTooltip":false,"useRebrandedImageStyle":null,"authorCount":2,"accountCount":1,"publicationUid":228789130,"widgetId":"rgw11_56aba281167b0"},"id":"rgw11_56aba281167b0","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAccountItem.html","templateExtensions":[],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAccountItem.html?accountId=1906625&context=pubdetail_authors_xflw&showContactAuthorButton=1&authorCount=2&accountCount=1&publicationUid=228789130","viewClass":"views.publicliterature.PublicationDetailAccountItemView","yuiModules":["rg.views.publicliterature.PublicationDetailAccountItemView"],"stylesheets":[],"_isYUI":true}],"hasMore":false,"nextOffset":6,"useRebrandedImageStyle":null,"widgetId":"rgw8_56aba281167b0"},"id":"rgw8_56aba281167b0","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAuthorList.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAuthorList.html?publicationUid=228789130&context=pubdetail_authors_xflw&showContactAuthorButton=1","viewClass":"views.publicliterature.PublicationDetailAuthorListView","yuiModules":["rg.views.publicliterature.PublicationDetailAuthorListView"],"stylesheets":[],"_isYUI":true},"publicationAbstract":{"data":{"publicationUid":228789130,"abstract":"<noscript><\/noscript><div>We investigate the use of adaptive MCMC algorithms to automatically tune the Markov chain parameters during a run. Examples include the Adaptive Metropolis (AM) multivariate algorithm of Haario, Saksman, and Tamminen (2001), Metropoliswithin- Gibbs algorithms for nonconjugate hierarchical models, regionally adjusted Metropolis algorithms, and logarithmic scalings. Computer simulations indicate that the algorithms perform very well compared to nonadaptive algorithms, even in high dimension. &copy; 2009 American Statistical Association, Institute of Mathematical Statistics, and Interface Foundation of North America.<\/div>","canEdit":false,"isAdmin":false,"isArtifact":false,"showFullAbstract":false,"widgetId":"rgw13_56aba281167b0"},"id":"rgw13_56aba281167b0","partials":[],"templateName":"publicliterature\/stubs\/PublicationAbstract.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationAbstract.html?publicationUid=228789130","viewClass":"views.publicliterature.PublicationAbstractView","yuiModules":["rg.views.publicliterature.PublicationAbstractView"],"stylesheets":[],"_isYUI":true},"publicationKeywords":null,"publicationState":null,"isGuest":true,"isAdminEditingAllowed":false,"isArtifact":false,"figureListWidget":null,"previewImage":"https:\/\/i1.rgstatic.net\/publication\/228789130_Examples_of_adaptive_MCMC\/links\/000473b10cf2847a19ef7d86\/smallpreview.png","nativeAdDisclosure":null,"showFollowPublicationButton":false,"followPublicationPromo":"","widgetId":"rgw5_56aba281167b0"},"id":"rgw5_56aba281167b0","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailItem.html","templateExtensions":["generalHelpers"],"attrs":{"preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailItem.html?publicationUid=228789130&showActionBar=0&showContactAuthorButton=1&showRequestFulltextExperience=0&showNoRgAuthorsRequestFulltextExperience=0&showFollowPublicationPromo=0","viewClass":"views.publicliterature.PublicationDetailItemView","yuiModules":["rg.views.publicliterature.PublicationDetailItemView"],"stylesheets":[],"_isYUI":true},"similarPublications":{"data":{"publicationListItems":[{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":59314167,"url":"researcher\/59314167_Robin_J_Evans","fullname":"Robin J. Evans","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Jan 2015","journal":"Electronic Journal of Statistics","showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/277575740_Smoothness_of_marginal_log-linear_parameterizations","usePlainButton":true,"publicationUid":277575740,"feedStubs":null,"hasFeedStubs":false,"impactPoints":"0.96","url":"publication\/277575740_Smoothness_of_marginal_log-linear_parameterizations","title":"Smoothness of marginal log-linear parameterizations","displayTitleAsLink":true,"authors":[{"id":59314167,"url":"researcher\/59314167_Robin_J_Evans","fullname":"Robin J. Evans","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["Electronic Journal of Statistics 01\/2015; 9:475-491. DOI:10.1214\/15-EJS1009"],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/277575740_Smoothness_of_marginal_log-linear_parameterizations","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/277575740_Smoothness_of_marginal_log-linear_parameterizations\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw15_56aba281167b0"},"id":"rgw15_56aba281167b0","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=277575740","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":48346895,"url":"researcher\/48346895_NT_Hobbs","fullname":"N.T. Hobbs","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":48097951,"url":"researcher\/48097951_MB_Hooten","fullname":"M.B. Hooten","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Jan 2015","journal":null,"showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/283813602_Bayesian_models_A_statistical_primer_for_ecologists","usePlainButton":true,"publicationUid":283813602,"feedStubs":null,"hasFeedStubs":false,"impactPoints":false,"url":"publication\/283813602_Bayesian_models_A_statistical_primer_for_ecologists","title":"Bayesian models: A statistical primer for ecologists","displayTitleAsLink":true,"authors":[{"id":48346895,"url":"researcher\/48346895_NT_Hobbs","fullname":"N.T. Hobbs","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":48097951,"url":"researcher\/48097951_MB_Hooten","fullname":"M.B. Hooten","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":[],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/283813602_Bayesian_models_A_statistical_primer_for_ecologists","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/283813602_Bayesian_models_A_statistical_primer_for_ecologists\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw16_56aba281167b0"},"id":"rgw16_56aba281167b0","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=283813602","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},{"data":{"milestones":{"moreContext":"experimentMilestoneClickedCitationContextReadMore"},"nextPublicationMilestone":"experimentMilestoneRequestFulltextNoPreview","nextPublicationViewId":null,"authorsPartOne":[{"id":2035835650,"url":"researcher\/2035835650_Wen_Cheng","fullname":"Wen Cheng","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":45507941,"url":"researcher\/45507941_Ian_L_Dryden","fullname":"Ian L. Dryden","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":14235310,"url":"researcher\/14235310_David_B_Hitchcock","fullname":"David B. Hitchcock","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":13317304,"url":"researcher\/13317304_Huiling_Le","fullname":"Huiling Le","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"authorsPartTwo":null,"surplusAuthors":null,"additionalCssClasses":null,"isFulltext":null,"isSlurp":false,"isNoText":true,"publicationType":"Article","publicationDate":"Jan 2014","journal":"Electronic Journal of Statistics","showEnrichedPublicationItem":false,"citationCount":0,"commentCount":0,"requestFulltextButton":null,"publicationUrl":"publication\/276248234_Analysis_of_proteomics_data_Bayesian_alignment_of_functions","usePlainButton":true,"publicationUid":276248234,"feedStubs":null,"hasFeedStubs":false,"impactPoints":"0.96","url":"publication\/276248234_Analysis_of_proteomics_data_Bayesian_alignment_of_functions","title":"Analysis of proteomics data: Bayesian alignment of functions","displayTitleAsLink":true,"authors":[{"id":2035835650,"url":"researcher\/2035835650_Wen_Cheng","fullname":"Wen Cheng","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":45507941,"url":"researcher\/45507941_Ian_L_Dryden","fullname":"Ian L. Dryden","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":14235310,"url":"researcher\/14235310_David_B_Hitchcock","fullname":"David B. Hitchcock","last":false,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"},{"id":13317304,"url":"researcher\/13317304_Huiling_Le","fullname":"Huiling Le","last":true,"imageUrl":"https:\/\/c5.rgstatic.net\/m\/2951093203564\/images\/template\/default\/profile\/profile_default_s.jpg"}],"displayAuthorsAsLinks":true,"displayAuthors":true,"displayJournalMetadata":true,"collapseTitle":false,"collapseAuthors":false,"collapseAbstract":false,"details":["Electronic Journal of Statistics 01\/2014; 8(2):1734-1741. DOI:10.1214\/14-EJS900C"],"abstract":false,"description":false,"swapJournalAndAuthorPositions":false,"showAbstract":false,"type":"Article","showType":true,"showPublicationIcon":false,"showSeeInContextCta":false,"publicationUrlWithContext":"publication\/276248234_Analysis_of_proteomics_data_Bayesian_alignment_of_functions","isReader":null,"isAuthor":null,"isRequester":false,"hasFulltext":null,"actions":[],"actionWidgets":[],"publicationItemFulltext":null,"linkId":null,"context":null,"contextId":null,"eventCode":"","isCitation":false,"isPendingCitationRequest":false,"canRemoveCitation":false,"citationSourcePublicationUid":false,"publicationCitationUid":false,"showPublicationDownloadDataUsagePermissionDialog":false,"origin":"publication_list","keywordList":null,"hasKeywordList":false,"showOpenReviewButton":false,"openReviewUrl":"publication\/276248234_Analysis_of_proteomics_data_Bayesian_alignment_of_functions\/review","additionalRightSideTopWidgets":[],"additionalRightSideBottomWidgets":[],"requestEndpointPrimary":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","requestEndpointImage":"literature.PublicationPromoRequestFulltextAction.html?dbw=true","doi":false,"hasMicrodata":false,"microdataPropertyName":null,"showPublicationPreview":true,"showPublicationPreviewOnRightSide":false,"showActionsOnRightSide":false,"swapJournalAndAbstractPositions":false,"displayUpdatedExpanderPlugin":false,"showActions":false,"showAuthors":true,"isResearch":false,"publicationLinkText":"Read preview","widgetId":"rgw17_56aba281167b0"},"id":"rgw17_56aba281167b0","partials":{"publicationItem":"publicliterature\/stubs\/partials\/publicationItem.html"},"templateName":"publicliterature\/stubs\/PublicationTeaserItem.html","templateExtensions":["generalHelpers"],"attrs":{"opensViewer":false,"requestFulltextInvitationDialogUrl":"literature.PublicationRequestFulltextInvitationDialog.html","followContext":"publication_item","publicationBookmarkEndpointUrl":"literature.AjaxFollowPublication.html","preSignUpDialogContext":null},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationTeaserItem.html?options%5BshowImpactPoints%5D=1&options%5BshowActorActions%5D=1&options%5BshowAbstract%5D=0&options%5BeventCode%5D=&publicationUid=276248234","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"viewClass":"sidebar","widgetId":"rgw14_56aba281167b0"},"id":"rgw14_56aba281167b0","partials":[],"templateName":"publicliterature\/stubs\/SimilarPublications.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.SimilarPublications.html?referencePublicationId=228789130&view=sidebar","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationFulltextPreview":null,"publicationResourcesFulltext":{"data":{"publicationUid":228789130,"publicationResourceList":{"data":{"publicationResourceItems":[{"data":{"publicationUid":228789130,"publicationType":"article","linkId":"000473b10cf2847a19ef7d86","fileName":"Examples of adaptive MCMC","fileUrl":"http:\/\/citeseerx.ist.psu.edu\/viewdoc\/download?doi=10.1.1.151.4452&amp;rep=rep1&amp;type=pdf","name":"psu.edu","nameUrl":"http:\/\/citeseerx.ist.psu.edu\/viewdoc\/download?doi=10.1.1.151.4452&amp;rep=rep1&amp;type=pdf","canRemove":false,"fileIcon":"ico-pub","canPreview":true,"hasPublisherLink":null,"hasMetaData":true,"hide":false,"fulltext":"ico-pub","origin":"publication_list","isLastLink":true,"isUserLink":false,"widgetId":"rgw20_56aba281167b0"},"id":"rgw20_56aba281167b0","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceItem.html","templateExtensions":["generalHelpers"],"attrs":{"fileRequiredPublicationTypes":["code","coverPage","experimentFindings","method","negativeResults","presentation","rawData","researchProposal","workingPaper","artifact","dataset"]},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceItem.html?publicationUid=228789130&linkId=000473b10cf2847a19ef7d86&hide=0&disableJavascript=disableJavascript&useAlternativeTemplate=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true}],"widgetId":"rgw19_56aba281167b0"},"id":"rgw19_56aba281167b0","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceList.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceList.html?publicationUid=228789130&limit=3&disableJavascript=disableJavascript&type=fulltextFile","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"resourceCount":1,"hidden":false,"showMore":false,"fulltext":true,"publicationDownloadCount":{"data":{"value":13,"valueFormatted":"13","widgetId":"rgw21_56aba281167b0"},"id":"rgw21_56aba281167b0","partials":[],"templateName":"publicliterature\/stubs\/PublicationDownloadCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDownloadCount.html?publicationUid=228789130","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw18_56aba281167b0"},"id":"rgw18_56aba281167b0","partials":[],"templateName":"publicliterature\/stubs\/PublicationResources.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResources.html?publicationUid=228789130&type=fulltextFile&disableJavascript=1","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationResourcesAttachments":{"data":{"publicationUid":228789130,"publicationResourceList":{"data":{"publicationResourceItems":[],"widgetId":"rgw23_56aba281167b0"},"id":"rgw23_56aba281167b0","partials":[],"templateName":"publicliterature\/stubs\/PublicationResourceList.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResourceList.html?publicationUid=228789130&limit=3&disableJavascript=disableJavascript&type=attachmentFile","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"resourceCount":0,"hidden":true,"showMore":false,"fulltext":false,"publicationDownloadCount":{"data":{"value":13,"valueFormatted":"13","widgetId":"rgw24_56aba281167b0"},"id":"rgw24_56aba281167b0","partials":[],"templateName":"publicliterature\/stubs\/PublicationDownloadCount.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDownloadCount.html?publicationUid=228789130","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"widgetId":"rgw22_56aba281167b0"},"id":"rgw22_56aba281167b0","partials":[],"templateName":"publicliterature\/stubs\/PublicationResources.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationResources.html?publicationUid=228789130&type=attachmentFile","viewClass":"views.publicliterature.PublicationResourcesView","yuiModules":["rg.views.publicliterature.PublicationResourcesView"],"stylesheets":[],"_isYUI":true},"publicationText":{"data":{"hide":false,"pages":[{"page":1,"text":"Examples of Adaptive MCMC\nby\nGareth O. Roberts*\nandJeffrey S. Rosenthal**\n(September 2006; revised January 2008.)\nAbstract.\nmatically tune the Markov chain parameters during a run. Examples include\nthe Adaptive Metropolis (AM) multivariate algorithm of Haario et al. (2001),\nMetropolis-within-Gibbs algorithms for non-conjugate hierarchical models, re-\ngionally adjusted Metropolis algorithms, and logarithmic scalings. Computer\nsimulations indicate that the algorithms perform very well compared to non-\nadaptive algorithms, even in high dimension.\nWe investigate the use of adaptive MCMC algorithms to auto-\n1. Introduction.\nMCMC algorithms such as the Metropolis-Hastings algorithm (Metropolis et al., 1953;\nHastings, 1970) are extremely widely used in statistical inference, to sample from complicated\nhigh-dimensional distributions. Tuning of associated parameters such as proposal variances\nis crucial to achieve efficient mixing, but can also be very difficult.\nAdaptive MCMC algorithms attempt to deal with this problem by automatically \u201clearn-\ning\u201d better parameter values of Markov chain Monte Carlo algorithms while they run. In\nthis paper, we consider a number of examples of such algorithms, including some in high\ndimensions. We shall see that adaptive MCMC can be very successful at finding good pa-\nrameter values with little user intervention. In our context, good will be defined in terms of\nsome appropriate measure of Markov chain mixing, such as the integrated autocorrelation\nof a functional of interest.\nIt is known that adaptive MCMC algorithms will not always preserve stationarity of \u03c0(\u00b7),\nsee e.g. Rosenthal (2004) and Proposition 3 of Roberts and Rosenthal (2005). However, they\nwill converge if the adaptions are done at regeneration times (Gilks et al., 1998; Brockwell\nand Kadane, 2005), or under various technical conditions about the adaption procedure\n*Department of Mathematics and Statistics, Fylde College, Lancaster University, Lancaster, LA1 4YF,\nEngland. Email: g.o.roberts@lancaster.ac.uk.\n**Department of Statistics, University of Toronto, Toronto, Ontario, Canada\njeff@math.toronto.edu. Web: http:\/\/probability.ca\/jeff\/ Supported in part by NSERC of Canada.\nM5S 3G3. Email:\n1"},{"page":2,"text":"(Haario et al., 2001; Atchad\u00b4 e and Rosenthal, 2005; Andrieu and Moulines, 2003; Andrieu\nand Atchad\u00b4 e, 2006).\nRoberts and Rosenthal (2005) proved ergodicity of adaptive MCMC under conditions\nwhich we find simpler to apply, and which do not require that the adaptive parameters\nconverge. To state their result precisely, suppose the algorithm updates Xnto Xn+1using\nthe kernel P\u0393n, where each fixed kernel P\u03b3 has stationary distribution \u03c0(\u00b7), but where the\n\u0393nare random indices, chosen iteratively from some collection Y based on past algorithm\noutput. Write ?\u00b7\u00b7\u00b7? for total variation distance, X for the state space, and M?(x,\u03b3) =\ninf{n \u2265 1 : ?Pn\nin state x \u2208 X. Then Theorem 13 of Roberts and Rosenthal (2005), combined slightly\nwith their Corollaries 8 and 9 and Theorem 23 guarantee that limn\u2192\u221e?L(Xn) \u2212 \u03c0(\u00b7)? = 0\n(asymptotic convergence), and also limn\u2192\u221e\nn\n(WLLN), assuming only the Diminishing Adaptation condition\n\u03b3(x,\u00b7) \u2212 \u03c0(\u00b7)? \u2264 ?} for the convergence time of the kernel P\u03b3when beginning\n1\n?n\ni=1g(Xi) = \u03c0(g) for all bounded g : X \u2192 R\nlim\nn\u2192\u221esup\nx\u2208X?P\u0393n+1(x,\u00b7) \u2212 P\u0393n(x,\u00b7)? = 0 in probability, (1)\nand the Bounded Convergence condition\n{M?(Xn,\u0393n)}\u221e\nn=0\nis bounded in probability, ? > 0. (2)\nFurthermore, they prove that (2) is satisfied whenever X \u00d7 Y is finite, or is compact in\nsome topology in which either the transition kernels P\u03b3, or the Metropolis-Hastings proposal\nkernels Q\u03b3, have jointly continuous densities. (Condition (1) can be ensured directly, by\nappropriate design of the adaptive algorithm.) A SLLN is precluded since the convergence\nstatements above are only stated \u201cin probability\u201d, while CLTs do not necessarily hold since\n\u0393ndoes not necessarily converge at all.\nSuch results provide a \u201chunting license\u201d to look for useful adaptive MCMC algorithms. In\nthis paper, we shall consider a variety of such algorithms. We shall see that they do indeed\nconverge correctly, and often have significantly better mixing properties than comparable\nnon-adaptive algorithms.\nWe present a collection of examples. For each one, our adaptive strategy steers the\nalgorithm towards a desired operational \u201coptimal\u201d according to some prescribed criterion.\nCrucially, our approach differs from that of Andrieu and Moulines, 2003 and Andrieu and\nAtchad\u00b4 e, in that unlike our method, convergence of the adaptive strategy is specifically\nsought in their approach. Our regularity conditions are thus weaker and easier to verify,\nthough as a result, the results we can demonstrate are necessarily weaker also.\n2"},{"page":3,"text":"2. Adaptive Metropolis (AM).\nIn this section, we consider a version of the Adaptive Metropolis (AM) algorithm of Haario\net al. (2001). We begin with a d-dimensional target distribution \u03c0(\u00b7). We perform a Metropo-\nlis algorithm with proposal distribution given at iteration n by Qn(x,\u00b7) = N(x, (0.1)2Id\/d)\nfor n \u2264 2d, while for n > 2d,\nQn(x,\u00b7) = (1 \u2212 \u03b2)N(x, (2.38)2\u03a3n\/d) + \u03b2 N(x, (0.1)2Id\/d),(3)\nwhere \u03a3nis the current empirical estimate of the covariance structure of the target distri-\nbution based on the run so far, and where \u03b2 is a small positive constant (we take \u03b2 = 0.05).\nIt is known from Roberts et al. (1997) and Roberts and Rosenthal (2001) that the pro-\nposal N(x, (2.38)2\u03a3\/d) is optimal in a particular large-dimensional context. Thus, the\nN(x, (2.38)2\u03a3n\/d) proposal is an effort to approximate this.\nSince empirical estimates change at the nthiteration by only O(1\/n), it follows that (1)\nwill be satisfied. Restricting \u03b2 > 0 in (3) ensures that (2) is satisfied, at least for a large family\nof target densities which includes all those which are log-concave outside some arbitrary\nbounded region (see Section 8). Hence, this algorithm will indeed converge to \u03c0(\u00b7) and\nsatisfy the WLLN. (Haario et al. instead let Qn(x,\u00b7) = N(x, \u03a3n+ ?Id) for small ?, to force\nc1Id\u2264 \u03a3n\u2264 c2Idfor some c1,c2> 0, which also ensures (1) and (2) for target distributions\nwith bounded support, but we prefer to avoid this strong assumption.)\nTo test this algorithm, we let \u03c0(\u00b7) = N(0, M Mt), where M is a d \u00d7 d matrix generated\nrandomly by letting {Mij}d\nmatrix \u03a3 = M Mtwill be highly erratic, so that sampling from \u03c0(\u00b7) presents a significant\nchallenge for sampling if the dimension is at all high.\nThe resulting trace plot of the first coordinate of the Markov chain is presented in Figure 1\nfor dimension d = 100, and in Figure 2 for dimension d = 200. In both cases, the Markov\nchain takes a long time to adapt properly and settle down to rapid mixing. In the early\nstages, the algorithm vastly underestimates the true stationary variance, thus illustrating\nthe pitfalls of premature diagnoses of MCMC convergence. In the later stages, by contrast,\nthe algorithm has \u201clearned\u201d how to sample from \u03c0(\u00b7), and does so much more successfully.\nAnother way of monitoring the success of this algorithm\u2019s adapting is as follows. Con-\nsider a multi-dimensional random-walk Metropolis algorithm with proposal covariance ma-\ntrix (2.38)2\u03a3p\/d, acting on a normal target distribution with true covariance matrix \u03a3.\nTheorem 5 of Roberts and Rosenthal (2001) prove that it is optimal to take \u03a3p= \u03a3, and for\ni,j=1be i.i.d. \u223c N(0,1). This ensures that the target covariance\n3"},{"page":4,"text":"0e+004e+05 8e+05\n\u22122\n\u22121\n0\n1\n2\n \n \nFigure 1. The first coordinate of the AM Markov chain in dimension 100, plotted\nagainst iteration number.\n0 10000002500000\n\u22124\n\u22122\n0\n2\n4\nFigure 2. The first coordinate of the AM Markov chain in dimension 200, plotted\nagainst iteration number.\n4"},{"page":5,"text":"0e+004e+05 8e+05\n0\n50\n100\n150\n200\n \n \nFigure 3. The suboptimality factor b for the AM algorithm in dimension 100,\nplotted against iteration number.\nother \u03a3pthe mixing rate will be slower than this by a sub-optimality factor of\nb \u2261 d\n?d\ni=1\u03bb\u22122\ni=1\u03bb\u22121\ni\n(?d\ni )2,\nwhere {\u03bbi} are the eigenvalues of the matrix \u03a31\/2\ncloser b is to 1, the better. The criterion being optimised in AM is therefore b\u22121.\nSo how does the AM algorithm perform by this measure? For the run in dimension 100,\nthe value of this sub-optimality coefficient b begins at the huge value of 193.53, and then even-\ntually decreases towards 1, reaching 1.086 after 500,000 iterations, and 1.024 after 1,000,000\niterations (Figure 3). In dimension 200, the value of b is even more erratic, starting around\n183,000 and oscillating wildly before decreasing to about 1.04 after 800000 iterations.\nWe conclude from this that the AM algorithm does indeed \u201clearn\u201d about the true tar-\nget covariance matrix, and converge to an algorithm which samples very (almost optimally)\nefficiently from \u03c0(\u00b7). It is true that it takes many iterations for the algorithm to learn\nthis information (nearly 400,000 iterations in dimension 100, and nearly 2,000,000 in dimen-\nsion 200). On the other hand, what the algorithm is learning is a d\u00d7d covariance matrix with\nmany parameters (5,050 parameters in dimension 100, and 20,100 in dimension 200). We\nfeel that this indicates very impressive performance of the AM algorithm in high dimensions.\np\n\u03a3\u22121\/2. Usually we will have b > 1, and the\n5"},{"page":6,"text":"0e+002e+06 4e+06\n\u221215\n\u22125 0\n5 10\n \n \nFigure 4. Trace plot of the first coordinate in the banana-shaped example.\n2.1. An irregularly shaped example.\nAM can be expected to work well on target densities in which the density contours form\nroughly elliptical contours. In such examples the global covariance gives a good measure of\ndependence valid in all parts of the state space. However, it is interesting to see how the\napproach performs on a more challenging problem with more irregularly shaped contours.\nWe also applied our full Adaptive Metropolis algorithm to a \u201cbanana-shaped\u201d distribu-\ntion, as proposed by Haario et al. (1999, 2001), with density\nfB= fd\u25e6 \u03c6B\nwhere fdis the d-dimensional density of a N(0, diag(100,1,1,...,1)) distribution, and where\n\u03c6B(x1,...,xd) = (x1,x2+ Bx2\nSo,\n1\u2212 100B,x3,...,xd) with B > 0 the \u201cbananicity\u201d constant.\nfB(x1,...,xd) \u221d exp\n?\n\u2212 x2\n1\/200 \u22121\n2(x2+ Bx2\n1\u2212 100B)2\u22121\n2(x2\n3+ x2\n4+ ... + x2\nd)\n?\n.\nSpecifically, we take dimension d = 20, and take B = 0.1, and run the algorithm for\n5,000,000 iterations. A trace plot of the first coordinate is given in Figure 4.\nIt is clear that the adaptation has improved mixing here. However mixing is still very\npoor after 5000000 iterations which is to be expected given that ant Metropolis method\n6"},{"page":7,"text":"struggles to traverse this distributions support. Whilst the AM algorithm attempts to move\naround as effectively as it can, classes of algorithms which can adjust the covariance of the\nproposal distribution according to the current state of the algorithm should be required.\nThis in part motivates some of the methods we shall introduce in later sections.\n3. Adaptive Metropolis-Within-Gibbs.\nConsider the following statistical model:\n\u00b5\n\u2193??\n\u03b81\n\u2193\n... ... \u03b8K\n\u2193\n\u03b8i\u223c Cauchy(\u00b5,A) [1 \u2264 i \u2264 K]\n\u2193\nY11,...,Y1r1\nYK1,...,YKrK\nYij\u223c N(\u03b8i,V )[1 \u2264 j \u2264 ri]\nwith priors N(0,1) on \u00b5, and IG(1,1) on A and V . Here {Yij} are observed data, IG(a,b) is\nthe inverse gamma distribution with density proportional to e\u2212b\/xx\u2212(a+1), and Cauchy(m,s)\nis a translated and scaled Cauchy distribution with density proportional to [1 + ((x \u2212\nm)\/s)2]\u22121. This model gives rise to a posterior distribution \u03c0(\u00b7) on the (K +3)-dimensional\nvector (A,V,\u00b5,\u03b81,...,\u03b8K), conditional on the observed data {Yij}.\nWe take K = 500, and let the rivary between 5 and 500. The resulting model is too\ncomplicated for analytic computation, and far too high-dimensional for numerical integra-\ntion. Furthermore, the presence of the Cauchy (as opposed to Normal) distribution destroys\nconjugacy, and thus makes a classical Gibbs sampler (as in Gelfand and Smith, 1990) infea-\nsible. Instead, a Metropolis-within-Gibbs algorithm (Metropolis et al., 1953; Tierney, 1994)\nseems appropriate.\nSuch an algorithm might proceed as follows. We consider each of the 503 variables in\nturn. For each, we propose updating its value by adding a N(0,\u03c32) increment. That proposal\nis then accepted or rejected according to the usual Metropolis ratio. This process is repeated\nmany times, allowing the variables to hopefully converge in distribution to \u03c0(\u00b7). But how\nshould \u03c32be chosen? Should it be different for different variables? How can we feasibly\ndetermine appropriate scalings in such high dimension?\nTo answer these questions, an adaptive algorithm can be used. We proceed as follows.\nFor each of the variables i [1 \u2264 i \u2264 K + 3], we create an associated variable lsi giving\nthe logarithm of the standard deviation to be used when proposing a normal increment to\nvariable i. We begin with lsi= 0 for all i (corresponding to unit proposal variance). After\nthe nth\u201cbatch\u201d of 50 iterations, we update each lsiby adding or subtracting an adaption\namount \u03b4(n). The adapting attempts to make the acceptance rate of proposals for variable i\n7"},{"page":8,"text":"050000 150000250000\n0.0\n0.5\n1.0\n1.5\n2.0\n2.5\nFigure 5.\nMetropolis-within-Gibbs variable \u03b81, plotted against batch number.\nThe log proposal standard deviation ls1 corresponding to the\nas close as possible to 0.44 (which is optimal for one-dimensional proposals in certain settings,\ncf. Roberts et al., 1997; Roberts and Rosenthal, 2001). Specifically, we increase lsiby \u03b4(n)\nif the fraction of acceptances of variable i was more than 0.44 on the nthbatch, or decrease\nlsiby \u03b4(n) if it was less.\nCondition (1) is satisfied provided \u03b4(n) \u2192 0; we take \u03b4(n) = min(0.01, n\u22121\/2). Our\napproach is to specify a global maximal parameter value M < \u221e, and restrict each lsito\nthe interval [\u2212M,M]. For a large class of target densities (which includes all those which\nare log-concave outside an arbitrary bounded region) this ensures (2) hold. In practice, the\nlsistabilise nicely so the bound on M is not actually needed.\nTo test this adaptive algorithm, we generate independent test data Yij\u223c N(i \u2212 1, 102),\nfor 1 \u2264 i \u2264 500 and 1 \u2264 j \u2264 ri. For such data, our simulations show that the scaling\nvariables quickly settle down near \u201cgood\u201d values where acceptance rates are roughly 0.44.\nIndeed, for the location variables \u03b81, \u03b82, and \u03b83, the corresponding ls variables converge to\nvalues near 2.4, 1.2, and 0.1, respectively (Figures 5, 6, 7). So the algorithm appears to be\nconverging well.\nJust how good are the values chosen? The following table presents the integrated auto-\ncorrelation times (ACT) and average squared jumping distances (after discarding the first\nfifth of the run as burn-in), for both the adaptive algorithm, and the corresponding \u201cfixed\u201d\n8"},{"page":9,"text":"050000 150000250000\n0.0\n0.4\n0.8\n1.2\nFigure 6.\nMetropolis-within-Gibbs variable \u03b82, plotted against batch number.\nThe log proposal standard deviation ls2 corresponding to the\n0 50000150000250000\n0.00\n0.10\n0.20\n0.30\nFigure 7.\nMetropolis-within-Gibbs variable \u03b83, plotted against batch number.\nThe log proposal standard deviation ls3 corresponding to the\n9"},{"page":10,"text":"algorithm where each lsiis fixed at 0:\nVariable\n\u03b81\n\u03b81\n\u03b82\n\u03b82\n\u03b83\n\u03b83\nri\n5\n5\n50\n50\n500\n500\nAlgorithm\nAdaptive\nFixed\nAdaptive\nFixed\nAdaptive\nFixed\nACT\n2.59\n31.69\n2.72\n7.33\n2.72\n2.67\nAvr Sq Dist\n14.932\n0.863\n1.508\n0.581\n0.150\n0.147\nThis table shows that, when comparing adaptive to fixed algorithms, for variables \u03b81\nand \u03b82, the autocorrelation times are significantly smaller (better) and the average squared\njumping distances are significantly larger (better), Thus, adapting has significantly improved\nthe MCMC algorithm, by automatically choosing appropriate proposal scalings separately for\neach coordinate. For variable \u03b83the performance of the two algorithms is virtually identical,\nwhich is not surprising since (Figure 7) the optimal log proposal standard deviation happens\nto be very close to 0 in that case.\nIn summary, this adaptive algorithm appears to correctly scale the proposal standard\ndeviations, leading to a Metropolis-within-Gibbs algorithm which mixes much faster than\na naive one with unit proposal scalings. Coordinates are improved wherever possible, and\nare left about the same when they happen to already be optimal. This works even in high\ndimensions, and does not require any direct user intervention or high-dimensional insight.\nThis algorithm has recently been applied to a statistical genetics problem (Turro et al.,\n2007).\n3.1. A comparison with SCAM.\nA different component-wise adaptive scaling method, the Single Component Adaptive\nMetropolis (SCAM) algorithm, is presented in Haario et al. (2005). That algorithm, which\nresembles the Adaptive Metropolis algorithm of Haario et al. (2001), is very interesting and\npromising, but differs significantly from ours since the SCAM adapting is done based on the\nempirical variance of each component based on the run so far.\nFor comparative purposes, we also ran the SCAM algorithm of Haario et al. (2005) on the\nsame example as that above for adaptive Metropolis-within-Gibbs. The SCAM algorithm\nuses the proposal distribution Yi\nn\u223c N(Xi\n?\n(2.4)2(gi\nn\u22121,vi\nn) for the ithcoordinate, where\nvi\nn=\n52,n \u2264 10\nn \u2265 11\nn+ 0.05),\n10"},{"page":11,"text":"0e+002e+05 4e+05\n2.4\n2.5\n2.6\n2.7\n2.8\n \n \nFigure 8. The log proposal standard deviation ls1corresponding to the SCAM\nvariable \u03b81, plotted against iteration number.\nHere gi\nmimic an \u201coptimal\u201d one-dimensional variance (2.38)2Var\u03c0(Xi) similar to what was discussed\nabove; the published version of SCAM omits the square in \u201c2.4\u201d but we assume the above is\nwhat was intended.) Writing xi\nn\nuse the recursive equations\nxi\nn\nand\ngi\nn \u2212 1gi\nWe again consider the first three coordinates, as above. The graphs of their proposal\nvariances (again on a log scale, for consistency with the above) are presented here.\nWe also compute the mean log \u03c3, ACT, and average squared jumping distance:\nnis the sample variance of X(i)\n0,X(i)\n1,...,X(i)\nn\u22121. (Intuitively, for n \u2265 11, vi\nnattempts to\nn=\n1\n?n\u22121\nn \u2212 1\nj=0x(i)\nj, we see (cf. Haario et al., 2005) that we can\nn=xi\nn\u22121+1\nnxi\nn\u22121\nn=\nn \u2212 2\nn\u22121+ (xi\nn\u22121)2+\n1\nn \u2212 1(xi\nn)2\u2212\nn\nn \u2212 1(xi\nn)2.\n11"},{"page":12,"text":"0e+002e+05 4e+05\n1.2\n1.6\n2.0\n2.4\n \n \nFigure 9. The log proposal standard deviation ls2corresponding to the SCAM\nvariable \u03b82, plotted against iteration number.\n0e+00 2e+054e+05\n0.5\n1.0\n1.5\n2.0\n \n \nFigure 10. The log proposal standard deviation ls3corresponding to the SCAM\nvariable \u03b83, plotted against iteration number.\n12"},{"page":13,"text":"Variable\n\u03b81\n\u03b81\n\u03b81\n\u03b82\n\u03b82\n\u03b82\n\u03b83\n\u03b83\n\u03b83\nri\n5\n5\n5\n50\n50\n50\n500\n500\n500\nAlgorithm\nAdaptive\nFixed\nSCAM\nAdaptive\nFixed\nSCAM\nAdaptive\nFixed\nSCAM\nlog(\u03c3)\n2.35\n0\n2.38\n1.21\n0\n1.27\n0.08\n0\n0.26\nACT\n2.59\n31.69\n2.77\n2.72\n7.33\n2.77\n2.72\n2.67\n2.77\nAvr Sq Dist\n14.932\n0.863\n14.951\n1.508\n0.581\n1.486\n0.150\n0.147\n0.145\nThe table shows that the results of SCAM are comparable to those of our adaptive\nMetropolis-within-Gibbs algorithm. In this case, they were virtually identical for \u03b81, and\njust slightly worse for \u03b82 and \u03b83. As for choice of proposal variance \u03c32, there are some\ndifferences, with the SCAM choices generally larger than those for our algorithm. Overall,\nwe feel that both of these algorithms are useful approaches to high-dimensional adaptive\nMCMC, and both should be kept in the applied user\u2019s arsenal.\n4. State-Dependent Scaling.\nWe next consider examples of full-dimensional Metropolis-Hastings algorithms, where\nthe proposal distribution is given by Q(x,\u00b7) = N(x, \u03c32\nance depends on the current state x \u2208 X. For such an algorithm, according to the usual\nMetropolis-Hastings formula (Hastings, 1970), a proposal from x to y is accepted with prob-\nability\n?\nAs a first case, we let X = R, and \u03c0(\u00b7) = N(0,1). We consider proposal kernels of the\nform\n?\nx), i.e. such that the proposal vari-\n\u03b1(x,y) = min1,\n\u03c0(y)\n\u03c0(x)(\u03c3x\/\u03c3y)dexp( \u22121\n2(x \u2212 y)2(\u03c3\u22122\ny \u2212 \u03c3\u22122\nx))\n?\n. (4)\nQa,b(x,\u00b7) = N x, ea?1 + |x|\nexp(\u02c6 \u03c0)\n?b?\n,\nwhere \u02c6 \u03c0 is our current empirical estimate of \u03c0(g) where g(x) = log(1 + |x|). (We divide by\nexp(\u02c6 \u03c0) to make the choices of a and b \u201corthogonal\u201d in some sense.) After the nthbatch of\n100 iterations, we update a by adding or subtracting \u03b4(n) in an effort to, again, make the\nacceptance rate as close as possible to 0.44. We also add or subtract \u03b4(n) to b to make the\nacceptance rates, acc\u2212and acc+respectively, in the regions A\u2212= {x \u2208 X : log(1+|x|) > \u02c6 \u03c0}\nand A+= {x \u2208 X : log(1 + |x|) \u2264 \u02c6 \u03c0} as equal as possible. This then increases the proposal\nvariance in the region where acceptance rates are highest (thus lowering the acceptance rate)\n13"},{"page":14,"text":"0e+004e+048e+04\n0.0\n0.5\n1.0\n1.5\nFigure 11. The tuning parameter a in the State-Dependent Scaling example,\nplotted against batch number, showing quick approach to \u201cgood\u201d values near 1.5.\nand correspondingly increasing the acceptance rate where the acceptance rate is lowest. The\ncriterion being minimised here is therefore acc2\nAs in previous examples, condition (1) is automatically satisfied, at least if we insist on\n\u03b4(n) \u2192 0. In order for us to be able to demonstrated (2) however (at least for a particular\nfamily of target densities), we shall impose an extra condition, requiring that a and b be\nconstrained within [\u2212M,M] for some global parameter M < \u221e.\nSo how does this algorithm perform in practice?\nconverge to their true values, showing excellent mixing. Furthermore, the tuning parameters\na and b quickly find their \u201cgood\u201d values (Figures 11 and 12), though they do continue to\noscillate due to the extremely slow rate at which \u03b4(n) \u2192 0.\nTo determine how well the adaptive algorithm is performing, we compare its integrated\nautocorrelation time and average squared jumping distance to corresponding non-adaptive\nalgorithms, having either fixed constant variance \u03c32(including the optimal constant value,\n(2.38)2), and to the corresponding variable-variance algorithm. The results are as follows:\n++ acc2\n\u2212.\nEmpirical expected values quickly\n14"},{"page":15,"text":"0e+00 4e+048e+04\n0.8\n1.2\n1.6\nFigure 12. The tuning parameter b in the State-Dependent Scaling example,\nplotted against batch number, showing quick approach to \u201cgood\u201d values near 1.6,\nbut with significant oscillation.\nAlgorithm\nAdaptive (as above)\n\u03c32= exp(\u22125)\n\u03c32= exp(\u22121)\n\u03c32= 1\n\u03c32= (2.38)2\n\u03c32= exp(5)\n\u03c32\nAcceptance Rate\n0.456\n0.973\n0.813\n0.704\n0.445\n0.237\nACT\n2.63\n49.92\n8.95\n4.67\n2.68\n7.22\nAvr Sq Dist\n0.769\n0.006\n0.234\n0.450\n0.748\n0.305\nx= e1.5?\n1+|x|\n0.534822\n?1.6\n0.456 2.580.778\nWe see that our adaptive scheme is much better than arbitrarily-chosen fixed-variance\nalgorithms, slightly better than the optimally-chosen fixed-variance algorithm (chosen by\nan ad-hoc search for maximising Average Square Jumping Distance, and given on the 5th\nline), and nearly as good as an ideally-chosen variable-\u03c32scheme chosen using a similar\nmaximisation of average squared jumping distance on a grid of possible (a,b) values (bottom\nline). The results are quite impressive, since we didn\u2019t do any manual tuning of our algorithm\nat all other than telling the computer to seek a 0.44 acceptance rate.\nWhile these functional forms of \u03c32\nto higher dimensional problems. Instead, we next consider a different algorithm in which\nthe \u03c32\nxseem promising, it is not clear how to generalise them\nxare piecewise constant over various regions of the state space.\n15"},{"page":16,"text":"5. Regional Adaptive Metropolis Algorithm (RAMA).\nThe Regional Adaptive Metropolis Algorithm (RAMA) begins by partitioning the state\nspace X into a finite number of disjoint regions: X = X1\nproceeds by running a Metropolis algorithm with proposal Q(x,\u00b7) = N(x, exp(2ai)) when-\never x \u2208 Xi. Thus, if x \u2208 Xiand y \u2208 Xj, then \u03c32\nthat a proposal from x to y is accepted with probability\n\u2022\u222a ...\n\u2022\u222aXm. The algorithm then\nx= e2aiand \u03c32\ny= e2aj, and it follows from (4)\n\u03b1(x,y) = min\n?\n1,\n\u03c0(y)\n\u03c0(x)\nexp(d(ai\u2212 aj) \u22121\n2(x \u2212 y)2[exp(\u22122aj) \u2212 exp(\u22122ai)])\n?\n.\nThe adaptions proceed as follows, in an effort to make the acceptance probability close\nto 0.234 in each region. (Such an acceptance rate is optimal in certain high-dimensional\nsettings; see Roberts et al., 1997; Roberts and Rosenthal, 1998, 2001; B\u00b4 edard, 2006a, 2006b,\nand we envisage that typically Xi would be a space of the same dimension as X.) For\n1 \u2264 i \u2264 d, the parameter aiis updated by, after the nthbatch of 100 iterations, considering\nthe fraction of acceptances of those proposals which originated from Xi. If that fraction is\nless than 0.234 then aiis decreased by \u03b4(n), while if it is more than aiis increased by \u03b4(n).\nThen, if ai> M we set ai= M, while if ai< \u2212M we set ai= \u2212M. Finally, if there were\nno proposals from Xiduring the entire batch, then aiis left unchanged. Thus the algorithm\nattempts to minimise?m\nin the region Xi.\nProvided that \u03b4(n) \u2192 0, condition (1) will trivially hold. Moreover, if we assume that\nM < \u221e then it is natural to demonstrate (2) again by using a simultaneous drift condi-\ntion. Such an argument will require some conditions on the target density, but is easy to\ndemonstrate for log-concave densities such as the example below. See Section 8 for further\ndiscussion.\ni=1acc2\niwhere accirepresents the acceptance rate for moves starting\nFor a first example, we let X = Rd, and \u03c0(\u00b7) = N(0, Id). We consider proposal kernels\nof the form\nQa,b(x,\u00b7) = N\nOnce every 100 iterations, we update a by adding or subtracting \u03b4(n) to make the acceptance\nrate in the region {?x?2\u2264 d} as close as possible to 0.234. We also add or subtract \u03b4(n) to b\nto make the acceptance rate in the region {?x? > d} as close as possible to 0.234. We again\nrestrict a and b to some [\u2212M,M]. (We take \u03b4(n) = min(0.01, n\u22121\/2) \u2261 0.01 and M = 100.)\nWe choose dimension d = 10, and begin with a = b = 0.\n?\nx, e2a1?x?2\u2264d+ e2b1?x?2>d\n?\n.\n16"},{"page":17,"text":"0e+004e+04 8e+04\n\u22120.4\n\u22120.3\n\u22120.2\n\u22120.1\n0.0\nFigure 13.\nagainst batch number.\nThe tuning parameter a in the Normal RAMA example, plotted\nHow well does it work? The tuning parameters a and b quickly migrate towards their\n\u201cgood\u201d values of \u22120.3 and \u22120.13, respectively, but they continue to oscillate somewhat\naround these values (Figures 13 and 14).\nHow good are the values of a and b found by the computer? The following table gives\ncomparisons of the integrated autocorrelation time and average squared jumping distance\nfor various choices of a and b:\na, b ACT\n15.54\n15.07\n15.44\n17.04\n17.037\nAvr Sq Dist\n0.1246\n0.1258\n0.1213\n0.1118\n0.1100\nadaptive (as above)\n\u22120.3, \u22120.13\n\u22120.3, 0.0\n0.0, \u22120.13\n0.0, 0.0\nThe table indicates that the adaptive algorithm (top line) is quite competitive with the\ncorresponding fixed-parameter choice (second line), which in turn has smaller integrated\nautocorrelation time, and larger average squared jumping distance, than any of the other\nchoices of a and b. This indicates that the computer has again succeeded in finding good\nvalues for the tuning parameters.\nNext, we consider the following statistical model related to James-Stein estimators, as\n17"},{"page":18,"text":"0e+004e+04 8e+04\n\u22120.20\n\u22120.10\n0.00\nFigure 14.\nagainst batch number.\nThe tuning parameter b in the Normal RAMA example, plotted\nstudied in e.g. Rosenthal (1996):\n\u00b5\n\u2193??\n\u03b81 ...\n\u2193 ...\nY1 ...\n... \u03b8K\n...\n... YK\n\u03b8i\u223c N(\u00b5,A) [1 \u2264 i \u2264 K]\n\u2193\nYi\u223c N(\u03b8i,V )[1 \u2264 i \u2264 K]\nHere the {Yi} are observed data. We use the prior distributions \u00b5 \u223c N(\u00b50,\u03c32\nIG(a1,b1), and replace V by its (fixed) empirical Bayes estimate. We let \u03c0(\u00b7) be the resulting\nposterior distribution for (A,\u00b5,\u03b81,...,\u03b8K), on the (K + 2)-dimensional state space X =\n[0,\u221e) \u00d7 RK+1. The density of \u03c0(\u00b7), with respect to Lebesgue measure, is then given by\n0) and A \u223c\nf(A,\u00b5,\u03b81,...,\u03b8K) = N(\u00b50,\u03c32\n0;\u00b5) IG(a1,b1;A) \u00d7\nK\n?\ni=1\n?\nN(\u00b5,A;\u03b8i) N(\u03b8i,V ;Yi)\n?\n\u221d exp(\u2212(\u00b5 \u2212 \u00b50)2\/2\u03c32\n0) exp(\u2212b1\/A)\/Aa1+1\u00d7\n\u00d7\nK\n?\ni=1\n?\nA\u22121\/2exp(\u2212(\u03b8i\u2212 \u00b5)2\/2A) V\u22121\/2exp(\u2212(Yi\u2212 \u03b8i)2\/2V )\n?\n.\nFor a numerical example, we let K = 18, and let Y1,...,Y18be the (real) baseball data\nof Table 1 of Morris (1983) (see also Efron and Morris, 1975). Thus, X \u2286 R20. We choose\nthe prior parameters as \u00b50= 0, \u03c32\n0= 1, a1= \u22121, and b1= 2.\n18"},{"page":19,"text":"0e+004e+04 8e+04\n\u22123.4\n\u22123.3\n\u22123.2\n\u22123.1\n\u22123.0\nFigure 15. The tuning parameter a in the James-Stein RAMA example, plotted\nagainst batch number.\nWe again perform the RAMA algorithm. Specifically, after the nthbatch of 100 iterations,\nwe update a by adding or subtracting \u03b4(n) to make the acceptance rate in the region {?\n\u00b50)2\u2264 0.15} as close as possible to 0.234. We also add or subtract \u03b4(n) to b to make the\nacceptance rate in the region {?\nThe simulations again show good mixing, and rapid convergence of functional averages\nto their true posterior means. Furthermore, the adaptive parameters a and b quickly settle\ndown to near \u22123.3 and \u22123.2 respectively (Figures 15, 16).\nHow good are the values of the tuning parameters chosen? We again compare integrated\nautocorrelation times and average squared jumping distances, as follows (acceptance rates\nare also shown):\ni(\u03b81\u2212\ni(\u03b81\u2212 \u00b50)2> 0.15} as close as possible to 0.234.\na, bAcc Rate\n0.228\n0.194\n0.003\n0.655\n0.647\n0.281\n2.5 \u00d710\u22125\nACT\n31.60\n25.75\n50.67\n38.92\n36.91\n38.04\n53.97\nAvr Sq Dist \u00d7104\n2.756\n2.793\n0.192\n1.168\n1.153\n2.407\n0.010\nadaptive (as above)\n\u22123.3, \u22123.2\n\u22122.3, \u22122.3\n\u22124.3, \u22124.3\n\u22123.3, \u22124.3\n\u22124.3, \u22123.3\n\u22120.6, \u22120.6\n19"},{"page":20,"text":"0e+004e+04 8e+04\n\u22123.35 \u22123.25 \u22123.15 \u22123.05\nFigure 16. The tuning parameter b in the James-Stein RAMA example, plotted\nagainst batch number.\nWe again see that the adaptive algorithm (top line) is quite competitive with the corre-\nsponding fixed-parameter choice (second line), which in turn is better than any of the other\nchoices of a and b. This shows that, once again, the adaptive algorithm has automatically\nchosen good values of the MCMC tuning parameters, without requiring user intervention.\nRemarks.\n1. In our simulations, the condition M < \u221e has never been necessary, since RAMA has\nnever tried to push any of the {aj} towards unbounded values. Indeed, we conjecture\nthat under appropriate regularity assumptions (e.g. if the densities are jointly continu-\nous), condition (2) will be satisfied automatically due to drifting of the parameters ai\nback to reasonable values due to the adaptive process (cf. Roberts and Rosenthal, 2005,\nCorollary 14).\n2. If some value ajis much too large, then \u03b1(x,y) may be very small for all y \u2208 Xjand x ?\u2208\nXj. This means that the region Xjmay virtually never be entered, so that ajwill remain\nvirtually constant, leading to isolation of Xjand thus very poor convergence. Hence, it is\nimportant with RAMA to begin with sufficiently small values of the {ai}. Alternatively,\nit might be wise to decrease each aislightly (rather than leaving it unchanged) after each\nbatch in which there were no proposals from Xi.\n3. The version of RAMA presented here requires that the user specify the regions {Xi}m\ni=1\n20"},{"page":21,"text":"by hand. However, it may also be possible to have the computer automatically select\nappropriate regions, by e.g. doing a preliminary run with fixed proposal variance, and\nthen grouping together state space subsets which appear to have similar acceptance rates.\n4. Roberts et al. (1997) show that in certain situations the optimal scaling for Metropolis\nalgorithms can be characterised as that which has acceptance probability 0.234. One\ncan ask whether these results carry over to RAMA, and whether equal acceptance rates\non different regions (as sought by RAMA) truly leads to optimality. We believe this\nto be true quite generally, but can only prove it for very specific settings (e.g. birth-\ndeath processes). The method of proof of Roberts et al. (see also B\u00b4 edard, 2006a, 2006b)\nappears to carry over away from the region boundaries, but the behaviour at the region\nboundaries is more complicated.\n5. If we set \u03b4(n) to a constant, as opposed to having \u03b4(n) \u2192 0, then condition 1 might fail,\nso the chain might not converge to \u03c0(\u00b7). On the other hand, the chain together with the\nparameter values {aj} is jointly Markovian, and under appropriate scaling may have its\nown joint diffusion limit. It would be interesting (Stewart, 2006) to study that diffusion\nlimit, to e.g. see how much asymptotic error results from failing to satisfy (1).\n6. To Log or Not To Log.\nSuppose \u03c0 is the density function for a real-valued random variable W. Then if \u03c0 is\nheavy-tailed, it may be advantageous to take logarithms, i.e. to instead consider the density\nfunction for?\nin place of W? Once again, adaptive algorithms can provide insights into this question.\nTo avoid problems of negative or near-negative values, we modify the logarithm function\nand instead consider the function\nW \u2261 logW. This leads to the question, when is it advantageous to consider?\nW\n?(w) \u2261 sgn(w) log(1 + |w|),\nwhere sgn(w) = 1 for w > 0, and sgn(w) = \u22121 for w < 0. The function ? is an increasing,\ncontinuously differentiable mapping from R onto R, with inverse ?\u22121(w) = sgn(w)(e|w|\u22121),\nand graph as follows:\n21"},{"page":22,"text":"\u221210\u221250510\n\u22124\n\u22122\n0\n2\n4\n \n \nFigure 17. Graph of the modified log function ?.\nIf \u03c0 is the density for W, and?\nA result of Mengersen and Tweedie (1996) says, essentially, that a random-walk Met-\nropolis (RWM) algorithm for a density \u03c0 will be geometrically ergodic if and only if \u03c0 has\nexponential or sub-exponential tails, i.e. satisfies\nW = log(W), then taking Jacobians shows that the density\nW is given by \u02dc \u03c0(w) = e|w|\u03c0(e|w|\u2212 1).for?\nlog\u03c0(x) \u2212 log\u03c0(y) \u2265 \u03b7(y \u2212 x), y > x \u2265 x1\n(5)\nfor some x1 > 0 and \u03b7 > 0 (and similarly for y < x \u2264 \u2212x1). (A similar result holds in\nmulti-dimensional contexts , cf. Roberts and Tweedie, 1996.) But if \u03c0 on R satisfies (5),\nthen so does \u02dc \u03c0, since if y > x \u2265 \u2212log(\u03b7) + \u03b2 \u2265 x1> 0, then\nlog \u02dc \u03c0(x) \u2212 log \u02dc \u03c0(y) = (x \u2212 y) + log\u03c0(ex\u2212 1) \u2212 log\u03c0(ey\u2212 1)\n\u2265 (x \u2212 y) + \u03b7((ey\u2212 1) \u2212 (ex\u2212 1)) = \u2212(y \u2212 x) + \u03b7ex(ey\u2212x\u2212 1)\n\u2265 \u2212(y \u2212 x) + \u03b7x(y \u2212 x) = (y \u2212 x)(\u03b7ex\u2212 1) \u2265 (y \u2212 x)(e\u03b2\u2212 1).\nHence, (5) is satisfied for \u02dc \u03c0 with \u02dc \u03b7 = e\u03b2\u2212 1. In fact, by making \u03b2 arbitrarily large, we can\nmake \u02dc \u03b7 as large as we like, showing that the tails of \u02dc \u03c0 are in fact sub-exponential.\nThis suggests that, at least as far as geometric ergodicity is concerned, it is essentially\nalways better to work with \u02dc \u03c0 than with \u03c0. As a specific example, if \u03c0 is the standard Cauchy\ndistribution, then RWM on \u03c0 is not geometrically ergodic, but RWM on \u02dc \u03c0 is.\n22"},{"page":23,"text":"Despite this evidence in favour of log transforms for RWM, it is not clear that taking\nlogarithms (or applying ?) necessarily helps with the quantitative convergence of RWM. To\ninvestigate this, we use an adaptive algorithm.\nSpecifically, given \u03c0, we consider two different algorithms: one a RWM on \u03c0, and the\nother a RWM on \u02dc \u03c0, each using proposal distributions of the form Q(x,\u00b7) = N(x,\u03c32). After\nthe nthbatch of 100 iterations, we allow each version to adapt its own scaling parameter \u03c3\nby adding or subtracting \u03b4(n) to log(\u03c3), in an effort to achieve acceptance rate near 0.44 for\neach version. Then, once every 100 batches, we consider whether to switch versions (i.e., to\napply ? if we currently haven\u2019t, or to undo ? if we currently have), based on whether the\ncurrent average squared jumping distance is smaller than that from the last time we used\nthe other version. (We force the switch to the other version if it fails 100 times in succession,\nto avoid getting stuck forever with just one version.)\nHow does this adaptive algorithm work in practice? In the following table we considered\nthree different one-dimensional symmetric target distributions: a standard Normal, a stan-\ndard Cauchy, and a Uniform[\u2212100,100]. For each target, we report the percentage of the\ntime that the adaptive algorithm spent on the logged density \u02dc \u03c0 (as opposed to the regular\ndensity \u03c0). We also report the mean value of the log proposal standard deviation for both\nthe regular and the logged RWM versions.\nTarget\nNormal\nCauchy\nUniform\nLog %\n3.62%\n99.0%\n4.95%\nlsreg\n2.52\n3.49\n6.66\nlslog\n2.08\n2.66\n2.65\nWe see from this table that, for the Normal and Uniform distributions, the adaptive\nalgorithm saw no particular advantage to taking logarithms, and indeed stayed in the regular\n(unlogged) \u03c0 version the vast majority of the time. On the other hand, for the Cauchy target,\nthe algorithm uses the logged \u02dc \u03c0 essentially as much as possible. This shows that this adaptive\nalgorithm is able to distinguish between when taking logs is helpful (e.g. for the heavy-tailed\nCauchy target), and when it is not (e.g. for the light-tailed Normal and Uniform targets).\nFor multi-dimensional target distributions, it is possible to take logs (or apply the func-\ntion ?) separately to each coordinate. Since lighter tails are still advantageous in multi-\ndimensional settings (Roberts and Tweedie, 1996), it seems likely to be advantageous to\napply ? to precisely those coordinates which correspond to heavy tails in the target distribu-\ntion. In high dimensions, this cannot feasibly be done by hand, but an adaptive algorithm\n23"},{"page":24,"text":"could still do it automatically. Such multi-dimensional versions of this adaptive logarithm\nalgorithm appear worthy of further investigation.\n7. How to adapt.\nWhilst the theory of adaptation has progressed significantly in recent years, practical\nimplementation raises many important and largely unstudied problems. One issue is that\nwe still know very little about how to optimise MCMC algorithms. The use of monitored\nacceptance probabilities has the appeal of simplicity and the support of some theory. In 1-\ndimension the use of 0.44 and in higher-dimensional problems the adoption of 0.234 together\nwith the scaling rule \u03c3 = 2.38\/d1\/2are based on results in Gelman et al (1996). However\nthe use of these simple rules, although often effective, are based on approximations and are\nnot rigorously proved for complex non-homogeneous models used in statistical analysis. In\nour two heterogeneous scaling examples, we are guided by established theoretical properties\nof MCMC - particularly that Metropolis algorithms are not geometrically ergodic for heavy\ntailed target densities. We believe that there is considerable further scope for algorithm\ndevelopment based on MCMC theory.\nOne important question asks whether an effective adaptive scheme should require that\n\u0393 converges. It is intuitively appealing to think of the adaptive scheme searching for \u201dthe\nbest\u201d algorithm from a collection of candidates. Our approach here is, however, not to\nrequire convergence of \u0393 since we are eager to have adaptive procedures which work in as\ngeneral a context as possible. It may well be (and we suspect so) that all the examples in this\npaper involve situations where \u0393ndoes converge, but we have not attempted to demonstrate\nthis. A complementary approach to our work in this respect is that adopted by Andrieu\nand Moulines (2003). This has the appeal of generality, but it may be that an algorithm in\nwhich we do not have convergence of \u0393nconverges less rapidly than one in which \u0393ndoes\nconverge. More experience with practical examples is necessary to resolve these issues.\nAM and RAMA are set up naturally in a multi-dimensional context. Multivariate gener-\nalisations of the state-dependent strategy used in Section 4 are clearly possible. The simplest\nidea is to apply the same strategy to each of the d components, obtaining a collection of\nparameters, (a1,b1)...(ad,bd) defining a proposal of independent components with variance\nin the ith direction given by ea(1 + |xi|)b. More complex proposals which try to respect the\ndependence in the target density (as in AM) are also possible.\n24"},{"page":25,"text":"8. Checking the Bounded Convergence condition.\nThe Diminishing Adaptation condition is relatively easy to check, and in fact adaptive\nprocedures are generally constructed with this condition directly in mind. On the other\nhand, the Bounded Convergence condition is typically more difficult to check.\nOne way of showing this is to show that all MCMC kernels satisfy the same Lyapunov\ndrift condition. For instance, Roberts and Rosenthal (2005) show that an adaptive MCMC\nalgorithm satisfying Diminishing Adaptation satisfies Bounded Convergence (and is hence\nergodic) if the family {P\u03b3}\u03b3\u2208Ysimultaneously strongly aperiodically geometrically ergodic, ie\nthere is C \u2208 F, V : X \u2192 [1,\u221e), \u03b4 > 0, \u03bb < 1, and b < \u221e, such that supCV = v < \u221e, and\n(i) for each \u03b3 \u2208 Y, there exists a probability measure \u03bd\u03b3(\u00b7) on C with P\u03b3(x,\u00b7) \u2265 \u03b4 \u03bd\u03b3(\u00b7) for\nall x \u2208 C; and\n(ii) (P\u03b3)V \u2264 \u03bbV + b1C.\nA natural approach to the establishment of simultaneously strongly aperiodically geomet-\nrically ergodicity is to use the drift function \u03c0\u22121\/2as in Roberts and Tweedie (1996) for AM\nand Roberts and Rosenthal (1997) for Adaptive Metropolis-within-Gibbs. As an example of\na precise result which can be shown in this way, for the AM algorithm, the condition will\nhold by this argument for all target densities which are log-concave (except perhaps on some\nbounded region).\nThe state-dependent proposal variance case can also be analysed to give a drift condition\nwith Lyapunov function \u03c0\u22121\/2, at least for b < 2. This is essentially because asymptotically\n(as |x| \u2192 \u221e) the accept\/reject ratio is dominated by the ratio \u03c0(y)\/\u03c0(x) and thus all moves\nto smaller |x| values are accepted with all moves to larger \u03c0(x) values are possibly rejected.\nThen standard calculation as those in Roberts and Tweedie (1996), together with continuity\nand compactness arguments for the parameters a and b are sufficient to demonstrate the\nsimultaneous drift condition.\nIt seems that these results will be easily generalisable to the other examples in this paper,\nessentially because all methods are essentially constructed from random walk Metropolis.\nThese extensions are subject to further work (Bai, Roberts, and Rosenthal, 2008).\n9. Conclusion.\nThis paper has considered automated tuning of MCMC algorithms, especially Metropolis-\nHastings algorithms, with quite positive results.\nFor example, for Metropolis-within-Gibbs algorithms, the following (generally well-known)\nstatements are all reinforced through our simulation. (1) The choice of proposal variance\n25"},{"page":26,"text":"\u03c32is crucial to the success of the algorithm. (2) Good values of \u03c32can vary greatly from\none coordinate to the next. (3) There are far too many coordinates to be able to select\ngood values of \u03c32for each coordinate by hand. (4) Adaptive methods can be used to get the\ncomputer to find good values of \u03c32automatically. (5) If done carefully, the adaptive methods\ncan be provably ergodic, and quite effective in practice, thus allowing for good tuning and\nrapid convergence of MCMC algorithms that would otherwise be impractical.\nThe practical experience of this paper, though very promising, also raises important\nquestions. In particular, how robust are the strategies suggested in the various methods\nhere? For example, in the adaptive Metropolis-within-Gibbs example, how crucial is the\nchoice of \u03b4(n) in the success of the method, and how does this vary from problem to problem?\nWe still know comparatively little about what adaptive strategies to use in any particular\ncontext. Our feeling is that the choice of adaptive strategy should be guided by theoretical\nknowledge about MCMC. For instance, when using RWM, particular problems are observed\nwith heavy-tailed target distributions (such as lack of geometric ergodicity, breakdown of\nCLTs etc). In this case it makes sense to use a strategy which attempts to stabilise the\nalgorithm excursions, and this points to the use of heterogeneous scaling and\/or a strategy\nwhich lightens the tails (such as that introduced in Section 6).\nOne important issue for adaptive scaling concerns the practical issue that scaling the\nproposal correlation structure to match that of the target will be a very poor strategy\nwhen some of the target distribution variances are infinite. Typically in practical MCMC\nsituations, this may not be very easy to check analytically by inspection of the target density.\nFor this reason, perhaps it makes more sense to scale according to acceptance rate criteria\nrather than variances. However it is impossible to use this to match correlation structure,\nand further work is required to introduce robust versions of the AM and other methods.\nAdaptive strategies are generally simple to implement. However it is very important\nthat such a strategy is constructed in such a way that the conditions for ergodicity are\nsatisfied. Further work is clearly required to give sufficiently simple conditions to enable\nroutine adaptation to take place in applied problems. In terms of adaptive strategies, there is\nnow extensive MCMC theory to help guide the construction of suitable adaptive algorithms.\nOne potential problem evolves from an adaptive strategy which is too \u201cgreedy\u201d in that it\ntries to adapt too closely to initial information from the output. Such algorithms can take\nconsiderable time to \u201crecover\u201d from misleading initial information.\nOverall, we feel that these results indicate the widespread applicability of adaptive\nMCMC algorithms to many different MCMC settings, including complicated high-dimensional\ndistributions. We hope that this paper will inspire users of MCMC to experiment with adap-\n26"},{"page":27,"text":"tive algorithms in their future applications (e.g. Turro et al., 2007). All of the software used\nto run the algorithms described herein is freely available at probability.ca\/adapt.\nAcknowledgements.\nthank the editors and referees for many constructive comments that greatly improved the\npaper.\nWe thank Sylvia Richardson for a very helpful suggestion, and\nREFERENCES\nC. Andrieu and Y.F. Atchad\u00b4 e (2005), On the efficiency of adaptive MCMC algorithms.\nPreprint.\nC. Andrieu and E. Moulines (2003), On the ergodicity properties of some adaptive Markov\nChain Monte Carlo algorithms. Preprint.\nY.F. Atchad\u00b4 e and J.S. Rosenthal (2005), On Adaptive Markov Chain Monte Carlo Algo-\nrithms. Bernoulli 11, 815\u2013828.\nY. Bai, G.O. Roberts, and J.S. Rosenthal (2008), On the containment condition for adaptive\nMarkov chain Monte Carlo algorithms. Preprint.\nM. B\u00b4 edard (2006a), Weak convergence of Metropolis algorithms for non-iid target distribu-\ntions. Preprint.\nM. B\u00b4 edard (2006b), Optimal acceptance rates for Metropolis algorithms: moving beyond\n0.234. Preprint.\nA.E. Brockwell and J.B. Kadane (2005), Identification of regeneration times in MCMC sim-\nulation, with application to adaptive schemes. J. Comp. Graph. Stat. 14, 436\u2013458.\nB. Efron and C. Morris (1975), Data analysis using Stein\u2019s estimator and its generalizations.\nJ. Amer. Stat. Assoc., Vol. 70, No. 350, 311-319.\nA.E. Gelfand and A.F.M. Smith (1990), Sampling based approaches to calculating marginal\ndensities. J. Amer. Stat. Assoc. 85, 398-409.\nW.R. Gilks, G.O. Roberts, and S.K. Sahu (1998), Adaptive Markov Chain Monte Carlo. J.\nAmer. Stat. Assoc. 93, 1045\u20131054.\nH. Haario, E. Saksman, and J. Tamminen (1999). Adaptive proposal distribution for random\nwalk Metropolis algorithm. Comput. Stat. 14 375-395.\nH. Haario, E. Saksman, and J. Tamminen (2001), An adaptive Metropolis algorithm. Bernoulli\n7, 223\u2013242.\nH. Haario, E. Saksman, and J. Tamminen (2005), Componentwise adaptation for high di-\nmensional MCMC. Comput. Stat. 20, 265\u2013274.\n27"},{"page":28,"text":"W.K. Hastings (1970), Monte Carlo sampling methods using Markov chains and their appli-\ncations. Biometrika 57, 97\u2013109.\nK.L. Mengersen and R.L. Tweedie (1996), Rates of convergence of the Hastings and Metro-\npolis algorithms. Ann. Statist. 24, 101\u2013121.\nN. Metropolis, A. Rosenbluth, M. Rosenbluth, A. Teller, and E. Teller (1953), Equations of\nstate calculations by fast computing machines. J. Chem. Phys. 21, 1087\u20131091.\nC. Morris (1983), Parametric empirical Bayes confidence intervals. Scientific Inference, Data\nAnalysis, and Robustness, 25-50.\nG.O. Roberts, A. Gelman, and W.R. Gilks (1997), Weak convergence and optimal scaling of\nrandom walk Metropolis algorithms. Ann. Appl. Prob. 7, 110\u2013120.\nG.O. Roberts and J.S. Rosenthal (1998), Optimal scaling of discrete approximations to\nLangevin diffusions. J. Roy. Stat. Soc. B 60, 255\u2013268.\nG.O. Roberts and J.S. Rosenthal (2001), Optimal scaling for various Metropolis-Hastings\nalgorithms. Stat. Sci. 16, 351\u2013367.\nG.O. Roberts and J.S. Rosenthal (2005), Coupling and Ergodicity of Adaptive MCMC.\nPreprint.\nG.O. Roberts and R.L. Tweedie (1996), Geometric Convergence and Central Limit Theorems\nfor Multidimensional Hastings and Metropolis Algorithms. Biometrika 83, 95\u2013110.\nJ.S. Rosenthal (1996), Analysis of the Gibbs sampler for a model related to James-Stein\nestimators. Stat. and Comp. 6, 269\u2013275.\nJ.S. Rosenthal (2004), Adaptive MCMC Java Applet. Available at:\nhttp:\/\/probability.ca\/jeff\/java\/adapt.html\nA. Stewart (2006), Personal communication.\nL. Tierney (1994), Markov chains for exploring posterior distributions (with discussion).\nAnn. Stat. 22, 1701\u20131762.\nE. Turro, N. Bochkina, A.M.K. Hein, and S. Richardson (2007), BGX: a Bioconductor pack-\nage for the Bayesian integrated analysis of Affymetrix GeneChips. BMC Bioinformatics 8,\n439\u2013448. Available at: http:\/\/www.biomedcentral.com\/1471-2105\/8\/439\n28"}],"widgetId":"rgw25_56aba281167b0"},"id":"rgw25_56aba281167b0","partials":[],"templateName":"publicliterature\/stubs\/PublicationText.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationText.html?publicationUid=228789130&hide=0","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationDetailAd":{"data":{"googleDfpSlot":null,"widgetId":"rgw26_56aba281167b0"},"id":"rgw26_56aba281167b0","partials":[],"templateName":"publicliterature\/stubs\/PublicationDetailAd.html","templateExtensions":["generalHelpers"],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicationDetailAd.html?publicationUid=228789130&slotId=336x280_Publications_ATF_Right&collapseSlotMode=never&fallbackContainerEnabled=1","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true},"publicationRelations":null,"publicationRelationsReverse":null,"publicationUid":228789130,"showSignUpDialog":false,"selectNewSignUpDialog":false,"publicationQuestions":null,"publicationCitations":null,"publicationReviewPromo":null,"publicationUsedInReviews":null,"publicationPdfJsReader":null,"useFulltextOptimizedLayout":false,"publicationActions":null,"requestFulltextPromo":null,"currentUrl":"publication\/228789130_Examples_of_adaptive_MCMC","isLeaderboardAd":false,"enableStickyBox":null,"googleDfpSlotMobileBottom":null,"fullTextExitPopup":null,"showExitPopupDialog":false,"widgetId":"rgw2_56aba281167b0"},"id":"rgw2_56aba281167b0","partials":{"romeo_legal_notice":"publicliterature\/stubs\/partials\/romeo_legal_notice.html"},"templateName":"publicliterature\/stubs\/PublicPublicationDetails_NewLayout.html","templateExtensions":["generalHelpers"],"attrs":{"publicationUid":228789130},"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicPublicationDetailsOld.html?publicationUid=228789130&isTestOldDesign=0","viewClass":"views.publicliterature.PublicPublicationDetailsOldView","yuiModules":["rg.views.publicliterature.PublicPublicationDetailsOldView"],"stylesheets":[],"_isYUI":true},"widgetId":"rgw1_56aba281167b0"},"id":"rgw1_56aba281167b0","partials":[],"templateName":"publicliterature\/stubs\/PublicPublicationDetails.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/publicliterature.PublicPublicationDetails.html","viewClass":"views.publicliterature.PublicPublicationDetailsView","yuiModules":["rg.views.publicliterature.PublicPublicationDetailsView"],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"uaClass":"","headPrefix":[],"rootUrl":"https:\/\/www.researchgate.net\/","requestToken":"vQuCRmnMzKfecDJjQymYGCrstkBI7dOfL8mePyDITnbl4Wq0Q6iV1xHX4c9kRb3PqDyhIxivWnoSTYq3xNNL42EVgGMieYt55nSYacr4q4gt9o+w4Bvs9wZ+5YiYp019ptacYX3wLIMNCp7X2lupnHuryjOeU61ZnVTfdrbLvdDIVBD\/zdD7VMn3JJudMYkBepS9Co8qRNbaBYHgrIJ4dizn9ZTwNAVF2hrujrhWWixAuGRiyabhFw0XnyFPNtq1ZY49NGcHuzFHrJd8M1Gr5dFnDh44iUV\/DRay9vE1kRE=","faviconCdnUrl":"https:\/\/c5.rgstatic.net\/m\/2390829798215018\/images\/favicon.ico","headerOutput":"<noscript><\/noscript><link rel=\"canonical\" href=\"https:\/\/www.researchgate.net\/publication\/228789130_Examples_of_adaptive_MCMC\" \/>\n<link rel=\"dns-prefetch\" href=\"\/\/c5.rgstatic.net\" \/>\n<link rel=\"dns-prefetch\" href=\"\/\/i1.rgstatic.net\" \/>\n<meta property=\"twitter:card\" content=\"summary\" \/>\n<meta property=\"twitter:site\" content=\"@ResearchGate\" \/>\n<meta property=\"og:title\" content=\"Examples of adaptive MCMC\" \/>\n<meta property=\"og:description\" content=\"We investigate the use of adaptive MCMC algorithms to automatically tune the Markov chain parameters during a run. Examples include the Adaptive Metropolis (AM) multivariate algorithm of Haario,...\" \/>\n<meta property=\"og:site_name\" content=\"ResearchGate\" \/>\n<meta property=\"og:image\" content=\"https:\/\/i1.rgstatic.net\/publication\/228789130_Examples_of_adaptive_MCMC\/links\/000473b10cf2847a19ef7d86\/smallpreview.png\" \/>\n<meta property=\"og:url\" content=\"https:\/\/www.researchgate.net\/publication\/228789130_Examples_of_adaptive_MCMC\" \/>\n<meta property=\"rg:id\" content=\"PB:228789130\" \/>\n<meta name=\"DC.identifier\" scheme=\"DCTERMS.URI\" content=\"http:\/\/dx.doi.org\/10.1198\/jcgs.2009.06134\" \/>\n<meta name=\"gs_meta_revision\" content=\"1.1\" \/>\n<meta name=\"citation_title\" content=\"Examples of adaptive MCMC\" \/>\n<meta name=\"citation_author\" content=\"Gareth O. Roberts\" \/>\n<meta name=\"citation_author\" content=\"Jeffrey S. Rosenthal\" \/>\n<meta name=\"citation_publication_date\" content=\"2009\/06\/01\" \/>\n<meta name=\"citation_journal_title\" content=\"Journal of Computational and Graphical Statistics\" \/>\n<meta name=\"citation_issn\" content=\"1061-8600\" \/>\n<meta name=\"citation_volume\" content=\"18\" \/>\n<meta name=\"citation_issue\" content=\"2\" \/>\n<meta name=\"citation_doi\" content=\"10.1198\/jcgs.2009.06134\" \/>\n<meta name=\"citation_abstract_html_url\" content=\"https:\/\/www.researchgate.net\/publication\/228789130_Examples_of_adaptive_MCMC\" \/>\n<meta name=\"citation_fulltext_html_url\" content=\"https:\/\/www.researchgate.net\/publication\/228789130_Examples_of_adaptive_MCMC\" \/>\n<meta name=\"viewport\" content=\"width=device-width,initial-scale=1\" \/>\n<link href=\"\/\/c5.rgstatic.net\/m\/22664197317151888\/styles\/rg.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<link href=\"\/\/c5.rgstatic.net\/m\/21004998181197492\/styles\/rg2.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<!--[if lt IE 9]><link href=\"\/\/c5.rgstatic.net\/m\/238176252723686\/styles\/ie.css\" type=\"text\/css\" rel=\"stylesheet\"\/><![endif]-->\n<link href=\"\/\/c5.rgstatic.net\/m\/217752362214895\/styles\/modules\/publicprofile.css\" type=\"text\/css\" rel=\"stylesheet\"\/>\n<script src=\"\/\/c5.rgstatic.net\/m\/2321000301012716\/javascript\/vendor\/webfontloader\/webfontloader.js\" type=\"text\/javascript\"><\/script>\n <script>(function(i,s,o,g,r,a,m){i[\"GoogleAnalyticsObject\"]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,\"script\",\"\/\/www.google-analytics.com\/analytics.js\",\"ga\");\n ga(\"create\",\"UA-58591210-1\");ga(\"set\",\"anonymizeIp\",true);ga('set', 'dimension1', 'publication slurped');ga('set', 'dimension2', 'Article');ga('set', 'dimension3', 'Logged out');ga('set', 'dimension4', 'https');ga(\"send\",\"pageview\");<\/script>\n","webfont":"<noscript><\/noscript><script> WebFontConfig = { custom: { families: ['source_sans_pro_italic', 'source_sans_pro_bold', 'source_sans_pro', 'martel'], urls : ['\/\/c5.rgstatic.net\/m\/231392577336386\/styles\/fonts.css'] } }; WebFont.load(WebFontConfig); <\/script>\n","correlationId":"rgreq-6ca38958-116a-46c9-9c7f-f3252a4e1983","accountId":null,"module":"publicliterature","action":"publicliterature.PublicPublicationDetails","page":"publicationDetail","product":"publications","backendTime":415,"continent":"Asia","stylesHome":"\/\/c5.rgstatic.net\/m\/","staticHost":"c5.rgstatic.net","useEarlyFlush":false,"longRunningRequestIdentifier":"LongRunningRequest.publicliterature.PublicPublicationDetails","longRunningRequestFp":"e9e5bbe1366c7ee8c8e41d02f793c884ac9be19b","widgetId":"rgw27_56aba281167b0"},"id":"rgw27_56aba281167b0","partials":[],"templateName":"application\/stubs\/StaticHeader.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.StaticHeader.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){
            Y.rg.core.pagespeed.Monitoring.monitorPage("\/\/glassmoni.researchgate.net", "publicliterature.PublicPublicationDetails.run.html.loggedOut.get", "59de9668d07aeb77ab4de5f24d382b5d199d2437", "rgreq-6ca38958-116a-46c9-9c7f-f3252a4e1983", "0a5da4490d0a3f7137cb301fe1f17cb20f778582");
        
            Y.rg.core.pagespeed.Monitoring.monitorPage("\/\/glassmoni.researchgate.net", "publicationDetail.loggedOut", "ed1993d9e20f6cefa83edacaa24401a18c071aea", "rgreq-6ca38958-116a-46c9-9c7f-f3252a4e1983", "0a5da4490d0a3f7137cb301fe1f17cb20f778582");
        })();
(function(){Y.rg.createInitialWidget({"data":{"year":"2016","inlinePromo":null,"isAdmin":false,"contactUrl":"https:\/\/www.researchgate.net\/contact","aboutUsUrl":"https:\/\/www.researchgate.net\/about","widgetId":"rgw28_56aba281167b0"},"id":"rgw28_56aba281167b0","partials":[],"templateName":"application\/stubs\/DefaultFooter.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.DefaultFooter.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"headerLogin":{"data":{"urlAfterLogin":"publication\/228789130_Examples_of_adaptive_MCMC","requestToken":"OUWFZHTHWPGA7SWyRkZCE+H96EnlvVsufRNAqXMQ3tP9y3PuzL99C9IUsi\/OutK8XTkhAf3aIP7DyqvpAFRBPv11O8OmGNzfWWZr5AuWbSS4Lm0kNMXOCCMg9DXciijCK0Q0+yEqcu3YIIAO8NikP8gb4pFhZJy5G7o2E7mhkMt+goa5ISbU09Lw60ZzPx4LdzToxvtiDNe8yZ5Z0ZqQZrNyqXfYtmG8ZmQ+DoWbjkAQhhDu2ZTFJykQy9L2bfXONfe1cuBBrAHjlvp0p7LntKHA1Bzcr29e6v\/OCss+M3U=","loginUrl":"https:\/\/www.researchgate.net\/application.Login.html","signupUrl":"https:\/\/www.researchgate.net\/signup.SignUp.html?ev=su_chnl_index&hdrsu=1&_sg=SEiqNWWrSxzFjL-WD6xWZGLbwKcm6GKDLo-G-9qgCJdHXYjmjA2qhmRA1rTvzkCu","encodedUrlAfterLogin":"cHVibGljYXRpb24vMjI4Nzg5MTMwX0V4YW1wbGVzX29mX2FkYXB0aXZlX01DTUM%3D","signupCallToAction":"Join for free","widgetId":"rgw30_56aba281167b0"},"id":"rgw30_56aba281167b0","partials":{"partial":"application\/stubs\/partials\/headerLoginDefault.html"},"templateName":"application\/stubs\/HeaderLogin.html","templateExtensions":[],"attrs":{"goal":"milestoneHeaderLoginSeen"},"widgetUrl":"https:\/\/www.researchgate.net\/application.HeaderLogin.html","viewClass":"views.application.HeaderLoginView","yuiModules":["rg.views.application.HeaderLoginView"],"stylesheets":[],"_isYUI":true},"cookieConsent":null,"logoSvgSrc":"https:\/\/c5.rgstatic.net\/m\/235107188705592\/images\/template\/brand-header-logo.svg","logoFallbackSrc":"https:\/\/c5.rgstatic.net\/m\/238113351022438\/images\/template\/brand-header-logo.png","widgetId":"rgw29_56aba281167b0"},"id":"rgw29_56aba281167b0","partials":{"schemaSocialProfiles":"application\/stubs\/partials\/schemaSocialProfiles.html"},"templateName":"application\/stubs\/HeaderLoggedOut.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.HeaderLoggedOut.html","viewClass":null,"yuiModules":[],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.createInitialWidget({"data":{"logEvent":"su_banner","specialCopy":false,"widgetId":"rgw31_56aba281167b0"},"id":"rgw31_56aba281167b0","partials":[],"templateName":"application\/stubs\/LoggedOutBanner.html","templateExtensions":[],"attrs":[],"widgetUrl":"https:\/\/www.researchgate.net\/application.LoggedOutBanner.html","viewClass":"views.application.LoggedOutBannerView","yuiModules":["rg.views.application.LoggedOutBannerView"],"stylesheets":[],"_isYUI":true,"initState":[]});})();
(function(){Y.rg.core.util.ParameterFilter.filter(["ev","cp","ch","ref","dbw","pli","loginT","uid","claimChannel","enrichId","enrichSource","utm_source","utm_medium","utm_campaign","el","ci"]);})();
});}); } else { throw 'YRG was not loaded when attaching widgets'; }</script><script> dataLayer = [{"pageCategory":"publication slurped","publicationType":"Article","eventCategory":"Publication page"}]; </script> <noscript><iframe src="//www.googletagmanager.com/ns.html?id=GTM-MKVKH7" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-MKVKH7');</script><script>(function(e){function n(n,t,o,a){"use strict";var i=e.document.createElement("link"),r=t||e.document.getElementsByTagName("script")[0],d=e.document.styleSheets;return i.rel="stylesheet",i.href=n,i.media="only x",a&&(i.onload=a),r.parentNode.insertBefore(i,r),i.onloadcssdefined=function(e){for(var t,o=0;d.length>o;o++)d[o].href&&d[o].href.indexOf(n)>-1&&(t=!0);t?e():setTimeout(function(){i.onloadcssdefined(e)})},i.onloadcssdefined(function(){i.media=o||"all"}),i}function t(e,n){e.onload=function(){e.onload=null,n&&n.call(e)},"isApplicationInstalled"in navigator&&"onloadcssdefined"in e&&e.onloadcssdefined(n)}var o=function(a,i){"use strict";if(a&&3===a.length){var r=e.Image,d=!(!document.createElementNS||!document.createElementNS("http://www.w3.org/2000/svg","svg").createSVGRect||!document.implementation.hasFeature("http://www.w3.org/TR/SVG11/feature#Image","1.1")||e.opera&&-1===navigator.userAgent.indexOf("Chrome")||-1!==navigator.userAgent.indexOf("Series40")),c=new r;c.onerror=function(){o.method="png",o.href=a[2],n(a[2])},c.onload=function(){var e=1===c.width&&1===c.height,r=a[e&&d?0:e?1:2];o.method=e&&d?"svg":e?"datapng":"png",o.href=r,t(n(r),i)},c.src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///ywAAAAAAQABAAACAUwAOw==",document.documentElement.className+=" grunticon"}};o.loadCSS=n,o.onloadCSS=t,e.grunticon=o})(this);grunticon(["https://c5.rgstatic.net/c/o1q2er/styles/icons/_header-ico.svg.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_header-ico.png.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_header-ico.fallback.scss"]);grunticon(["https://c5.rgstatic.net/c/o1q2er/styles/icons/_admin-ico.svg.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_admin-ico.png.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_admin-ico.fallback.scss"]);grunticon(["https://c5.rgstatic.net/c/o1q2er/styles/icons/_ico.svg.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_ico.png.css", "https://c5.rgstatic.net/c/o1q2er/styles/icons/_ico.fallback.scss"]);</script></body>
</html>
